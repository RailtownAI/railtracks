# Prompt Injection

Passing details of a prompt data up the chain can be costly in tokens and latency. Sometimes it is better if you can
inject the text into a prompt using our [context](../context). 

For more details on how to use prompt injection, visit [prompt injection](../../llm_support/prompt_injection.md).