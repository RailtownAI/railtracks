[
  {
    "id": "camera_lidar/cameraradarlidarcomp.txt",
    "content": "Skip to content\n\n[ ![AUTOCRYPT\nLOGO](data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==)\n![AUTOCRYPT LOGO](https://autocrypt.io/wp-content/uploads/2022/06/autocrypt-\nlogo_svg.svg) ](https://autocrypt.io/) __\n\n  * [ Home ](https://autocrypt.io/)\n  * [ Products  ](https://autocrypt.io/products/)\n    * [ In-Vehicle Systems Security  ](https://autocrypt.io/solutions/in-vehicle-systems-security/)\n      * [ AutoCrypt\u00ae IDS ](https://autocrypt.io/products/ids/)\n      * [ AutoCrypt\u00ae HSM ](https://autocrypt.io/products/hsm/)\n      * [ AutoCrypt\u00ae ASL ](https://autocrypt.io/products/asl/)\n      * [ AutoCrypt\u00ae TEE ](https://autocrypt.io/products/tee/)\n      * [ AutoCrypt\u00ae TLS ](https://autocrypt.io/products/tls/)\n    * [ V2X Security  ](https://autocrypt.io/solutions/secure-v2x-communications/)\n      * [ AutoCrypt\u00ae V2X-EE ](https://autocrypt.io/products/v2x/)\n      * [ AutoCrypt\u00ae V2X-PKI ](https://autocrypt.io/products/v2x-pki/)\n      * [ AutoCrypt\u00ae MBD ](https://autocrypt.io/products/mbd/)\n      * [ AutoCrypt\u00ae CLS ](https://autocrypt.io/products/cls/)\n    * Fleet and Mobility \n      * [ AutoCrypt\u00ae Digital Key ](https://autocrypt.io/products/digital-key/)\n      * [ AutoCrypt\u00ae RODAS ](https://autocrypt.io/products/rodas/)\n      * [ AutoCrypt\u00ae FMS ](https://autocrypt.io/products/fms/)\n      * [ Mobility Platform Solutions - MOVE\u2122 ](https://autocrypt.io/solutions/move/)\n    * Automotive Security Testing \n      * [ Cybersecurity Testing Platform ](https://autocrypt.io/products/cstp/)\n      * [ Security Analyzer\u2122 ](https://autocrypt.io/products/security-analyzer/)\n      * [ Security Fuzzer\u2122 ](https://autocrypt.io/products/security-fuzzer/)\n    * [ EV and Charging  ](https://autocrypt.io/solutions/ev-charging/)\n      * [ AutoCrypt\u00ae PnC ](https://autocrypt.io/products/pnc/)\n      * [ Charging Solutions - EVIQ\u2122 ](https://autocrypt.io/solutions/eviq/)\n    * PKI and Key Management \n      * [ AutoCrypt\u00ae PKI ](https://autocrypt.io/products/pki/)\n      * [ AutoCrypt\u00ae KEY ](https://autocrypt.io/products/key/)\n  * Services \n    * [ Automotive Fuzz Testing ](https://autocrypt.io/services/automotive-fuzz-testing/)\n    * [ Automotive Penetration Testing ](https://autocrypt.io/services/automotive-penetration-testing/)\n    * [ UN R155/156 Consulting ](https://autocrypt.io/services/wp-29/)\n    * [ CSMS Consulting ](https://autocrypt.io/services/csms-consulting/)\n    * [ TARA Consulting ](https://autocrypt.io/services/tara-consulting/)\n    * [ Security Testing ](https://autocrypt.io/services/testing/)\n  * Demo \n    * [ IMS for SCMS ](https://autocrypt.io/demo/ims-for-scms/)\n    * [ SCMS Interoperability Test ](https://autocrypt.io/demo/scms-test/)\n    * [ PnC Cloud Test ](https://autocrypt.io/demo/pnc-cloud/)\n  * Resources \n    * [ News ](https://autocrypt.io/news/)\n    * [ Blog ](https://autocrypt.io/blog/)\n    * [ Downloads ](https://autocrypt.io/downloads/)\n    * [ Brochures ](https://autocrypt.io/digital-brochures/)\n  * Company \n    * [ About Us ](https://autocrypt.io/company/about-us/)\n    * [ Locations ](https://autocrypt.io/company/locations/)\n    * [ Partnership ](https://autocrypt.io/company/partnership/)\n    * [ Events ](https://autocrypt.io/company/events/)\n    * [ Careers ](https://autocrypt.io/company/careers/)\n  * [ Contact Us ](https://autocrypt.io/contact-us/)\n\n![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAYAQAAAADIDABVAAAAAnRSTlMAAHaTzTgAAAAMSURBVAjXY2CgLQAAAGAAATeQF3gAAAAASUVORK5CYII=)\n![](https://autocrypt.io/wp-\ncontent/themes/webalive/assets/source/images/globe.png)\n\n  * [ KR ](https://autocrypt.co.kr/)\n  * [ JP ](https://autocrypt.jp/)\n\n__\n\nSearch for:  __\n\n[ Contact Us ](https://autocrypt.io/contact-us)\n\nAUTOCRYPT Launches Cybersecurity Testing Platform for UN R155/156 and GB\nCompliance. [ Learn More ](https://autocrypt.io/cybersecurity-testing-\nplatform-r155-156/)\n\n10 August, 2021  .  6 mins read\n\n#  Camera, Radar and LiDAR: A Comparison of the Three Types of Sensors and\nTheir Limitations\n\nAutonomous driving is enabled by two sets of technologies: V2X and ADAS. V2X\n(vehicle-to-everything) utilizes wireless communication technology to\nfacilitate real-time interactions between the vehicle and its surrounding\nobjects and infrastructure. On the other hand, ADAS (advanced driver-\nassistance systems) make use of built-in sensors to detect and calculate the\nsurrounding environment. Both technologies complement each other to ensure a\nsafe and seamless autonomous driving experience. We have so far explained how\nV2X technology works and the different wireless communication standards\ninvolved, see: [ _DSRC vs. C-V2X: A Detailed Comparison of the 2 Types of V2X\nTechnologies_ ](https://autocrypt.io/dsrc-vs-c-v2x-a-detailed-comparison-of-\nthe-2-types-of-v2x-technologies/) . In this article, we will focus on the\ntechnologies behind ADAS and take a deep dive into the three types of commonly\nused sensors: camera, radar, and LiDAR.\n\n###  **Camera**\n\nFirst introduced in the form of a backup camera by Toyota in 1991, camera is\nthe oldest type of sensor used in vehicles. It is also the most intuitive\nsensor since it works just like our eyes do. After decades of usage for backup\nassistance, car cameras had undergone significant improvements in the 2010s as\nthey were applied for lane keep and lane centering assists. Today, camera has\nbecome the most essential component of the ADAS and can be found in every\nvehicle.\n\n**Advantages of Camera:**\n\n**Vision-like sensory.** Just like our vision, cameras can easily distinguish\nshapes, colours, and quickly identify the type of object based on such\ninformation. Hence, cameras can produce an autonomous driving experience that\nis very similar to the one produced by a human driver.\n\n**Recognizing 2D information.** Since camera is based on imagery, it is the\nonly sensor with the capability of detecting 2D shapes and colours, making it\ncrucial to reading lanes and pavement markings. With higher resolutions, even\nfading lines and shapes can be read very accurately. Infrared lighting is also\nequipped with most modern cameras, making it just as easy to navigate at\nnight.\n\n**Low cost.** Camera is relatively cheaper compared to other types of sensors.\nThis made it possible for OEMs to introduce better autonomous driving features\nto mid-range and even lower-end vehicles.\n\n**Disadvantages of Camera:**\n\n**Poor vision under extreme weather events.** Its similarity to the human eye\nalso makes it a major disadvantage under severe weather conditions like\nsnowstorms, sandstorms, or other conditions leading to low visibility.\nTherefore, the camera is only as good as the human eye. Nevertheless, most\npeople do not expect their car to see better than their eyes and would not\nfully rely on their car under such extreme conditions. In fact, [ Tesla\n](https://www.reuters.com/business/autos-transportation/tesla-drops-radar-is-\nautopilot-system-safe-2021-06-02/) had decided to abandon radar and use camera\nonly for its Autopilot system, starting with its newly produced Model 3 and\nModel Y vehicles. Named Tesla Vision, the system is expected to decrease the\nfrequency of system glitches because of the reduction of confusing signals\nfrom radar.\n\n###  **Radar**\n\nRadar (radio detection and ranging) was first invented prior to World War II\nand has been widely used since then to precisely track the position, speed,\nand direction of aircraft and ships. It was first brought into cars by\nMercedes-Benz in 1999 to support its adaptive speed feature. Radar technology\ncan be broken down into a transmitter and a receiver. The transmitter blasts\nradio waves in a targeted direction. These radio waves then get reflected when\nthey reach any significant object. The receiver picks up these reflected waves\nand analyzes them to identify the location, speed, and direction of the\nobject.\n\n**Advantages of Radar:**\n\n**Unaffected by weather conditions.** The greatest advantage of radar is that\nthe transmission of radio waves is not affected by visibility, lighting, and\nnoise. Therefore, radar performance is consistent across all environmental\nconditions.\n\n**Default sensor for emergency braking.** The radar system has been used as\nthe default sensor for emergency braking due to its ability to detect and\nforecast moving objects coming into the vehicle\u2019s path.\n\n**Disadvantages of Radar:**\n\n**Low-definition modeling.** The radio waves are highly accurate at detecting\nobjects. Yet, compared to the camera, radar is relatively weak at modeling a\nperfectly precise shape of the object. As a result, the system might not be\nable to identify exactly what the object is. For instance, unlike the camera,\nthe radar system normally cannot distinguish bicycles from motorcycles, even\nthough it has no problem determining their speeds.\n\n###  **LiDAR**\n\nLiDAR (light detection and ranging) adopted its name the same way as radar\ndid. Despite its underlying mechanism being similar to radar, LiDAR utilizes\nlaser lights instead of radio waves. Invisible laser lights are fired to the\nvehicle\u2019s surroundings. The computer then uses the reflection time paired with\nthe speed of light to calculate the distance of the reflector.\n\n**Advantages of LiDAR:**\n\n**High-definition 3D modeling.** LiDAR can be seen as a more advanced version\nof radar. It has a detection range of as far as 100 meters away with a\ncalculation error of less than two centimeters. Hence it is capable of\nmeasuring thousands of points at any moment, allowing it to model up a very\nprecise 3D depiction of the surrounding environment.\n\n**Unaffected by weather conditions.** Same as radar, LiDAR\u2019s efficacy is not\naffected by the environmental condition.\n\n**Disadvantages of LiDAR:**\n\n**Highly sophisticated.** In order to provide an accurate 3D model of the\nenvironment, LiDAR calculates hundreds of thousands of points every second and\ntransforms them into actions. This means that LiDAR requires a significant\namount of computing power compared to camera and radar. It also makes LiDAR\nprone to system malfunctions and software glitches.\n\n**High cost.** As expected, due to the sophistication of the software and the\ncomputing resources needed, the price to implement a set of LiDAR sensors is\nthe highest among the three.\n\n###  **Are Sensors Reliable?**\n\nAll three types of sensors have their pros and cons. Therefore, most OEMs use\na mix of at least two of the three to complement each other and outweigh their\nweaknesses. As sensor technologies become more mature, more and more vehicles\nare expected to reach [ _autonomous driving levels_\n](https://autocrypt.io/6-levels-of-autonomous-driving-where-are-we-now-\nin-2020/) 3 to 4 in the next five years.\n\nYet, no matter how advanced and sophisticated sensor technologies become, they\nare nothing more than computers; and connected computers are always at risk of\ncyberattacks. Therefore, just as we trust these sensors to take over our\nwheels, cybersecurity measures must be in place to ensure they do not get\ntampered with by malicious actors. The automotive cybersecurity regulation\noutlined by [ _WP.29_ ](https://autocrypt.io/services/wp-29/) ensures that all\nOEMs build their vehicles with secure cybersecurity systems in place, so that\nwe can all trust the sensors to do their job.\n\n[ **AutoCrypt IVS** ](https://autocrypt.io/solutions/in-vehicle-systems-\nsecurity/) is an in-vehicle security solution chosen by some of the top ten\nOEMs in the world for vehicular cybersecurity type approval. Not only does IVS\nblock malicious threats from outside the vehicle, but it also monitors\ncommunications within the vehicle, and responds to abnormal and malicious\nactivity in real-time.\n\nTo stay informed with the latest news on mobility tech and automotive\ncybersecurity, _[ subscribe ](https://www.autocrypt.io/subscribe) _ to\nAUTOCRYPT\u2019s monthly newsletter.\n\nShare This Article\n\n  * [ __ ](https://www.facebook.com/sharer/sharer.php?u=https://autocrypt.io/camera-radar-lidar-comparison-three-types-of-sensors/)\n  * [ __ ](http://www.twitter.com/intent/tweet?url=https://autocrypt.io/camera-radar-lidar-comparison-three-types-of-sensors&text=Camera, Radar and LiDAR: A Comparison of the Three Types of Sensors and Their Limitations)\n  * [ __ ](https://www.linkedin.com/shareArticle?mini=true&url=https://autocrypt.io/camera-radar-lidar-comparison-three-types-of-sensors/&title=&summary=&source=)\n  * [ __ ](mailto:?subject=Camera, Radar and LiDAR: A Comparison of the Three Types of Sensors and Their Limitations -EventBookings &body=Check out this site https://autocrypt.io/camera-radar-lidar-comparison-three-types-of-sensors/ \"Camera, Radar and LiDAR: A Comparison of the Three Types of Sensors and Their Limitations\")\n\nRelated Articles\n\n[ ![CSMS for UN\nR155](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAmUAAAFeAQAAAADsoVV5AAAAAnRSTlMAAHaTzTgAAAAxSURBVHja7cEBDQAAAMKg909tDwcUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABvBmqkAAEPmmcYAAAAAElFTkSuQmCC)\n![CSMS for UN R155](https://autocrypt.io/wp-\ncontent/uploads/2024/04/UNR155-blog-thumbnail.jpg) ](\nhttps://autocrypt.io/cybersecurity-management-system-for-unr155/)\n\n###  [ Cybersecurity Management System for UNECE Regulation 155 ](\nhttps://autocrypt.io/cybersecurity-management-system-for-unr155/)\n\n12 April, 2024\n\n[ ![Automotive penetration\ntesting](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAv4AAAG2AQAAAAAv/b+IAAAAAnRSTlMAAHaTzTgAAABASURBVHja7cEBDQAAAMKg909tDjegAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACeDKX2AAEzxC0CAAAAAElFTkSuQmCC)\n![Automotive penetration testing](https://autocrypt.io/wp-\ncontent/uploads/2024/02/Automotive-penetration-testing.jpg) ](\nhttps://autocrypt.io/role-of-automotive-penetration-testing/)\n\n###  [ The Role of Penetration Testing in the Automotive Industry ](\nhttps://autocrypt.io/role-of-automotive-penetration-testing/)\n\n22 February, 2024\n\n[ ![ces 2024\nsdv](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAH0AQAAAACLXWKGAAAAAnRSTlMAAHaTzTgAAABUSURBVHja7cEBAQAAAIIg/69uSEABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPBu+/QAAaBQRaAAAAAASUVORK5CYII=)\n![ces 2024 sdv](https://autocrypt.io/wp-content/uploads/2024/01/AC-Vehicle-\nTech-at-CES-2024-The-Official-Introduction-of-Software-Defined-Vehicles-Cover-\nImage.jpg) ]( https://autocrypt.io/ces-2024-software-defined-vehicles/)\n\n###  [ Vehicle Tech at CES 2024: The Official Introduction of Software-Defined\nVehicles ]( https://autocrypt.io/ces-2024-software-defined-vehicles/)\n\n24 January, 2024\n\n###  Interested in what we do?  \nLet\u2019s see how we can work together.\n\n[ Contact Us ](https://autocrypt.io/contact-us)\n\nSewoo Building B1-1, 6-8F,  \n115, Yeouigongwon-ro,  \nYeongdeungpo-gu,  \nSeoul, Korea\n\n[ Sales: global@autocrypt.io ](mailto:global@autocrypt.io) [ HR:\nhr.legal@autocrypt.io ](mailto:hr.legal@autocrypt.io)\n\n###  Company\n\n  * [ About Us ](https://autocrypt.io/company/about-us/)\n  * [ Careers ](https://autocrypt.io/company/careers/)\n\n###  Resources\n\n  * [ Downloads ](https://autocrypt.io/downloads/)\n  * [ Latest News ](https://autocrypt.io/news/)\n  * [ Blog ](https://autocrypt.io/blog/)\n\n###  Solutions\n\n  * [ AutoCrypt\u00ae IVS ](https://autocrypt.io/solutions/in-vehicle-systems-security/)\n  * [ AutoCrypt\u00ae V2X ](https://autocrypt.io/solutions/secure-v2x-communications/)\n  * [ AutoCrypt\u00ae PnC ](https://autocrypt.io/solutions/ev-charging/)\n\n###  Demo\n\n  * [ SCMS Interoperability Test ](https://autocrypt.io/demo/scms-test/)\n  * [ PnC Cloud Test ](https://autocrypt.io/demo/pnc-cloud/)\n\n###  Subscribe To Our Newsletter\n\n###  Social Links\n\n[ __ ](https://www.linkedin.com/company/34767964/)\n\n\u00a9 2023 AUTOCRYPT Co., Ltd. All rights reserved.\n\n  * [ Terms & Conditions ](https://autocrypt.io/terms-and-conditions/)\n  * [ Privacy Policy ](https://autocrypt.io/privacy-policy/)\n\nScroll to top\n\n**  \nPlease fill in the information below to receive your login credential for the\nIMS for SCMS demo.  \n**\n\nReturning user? Please proceed to the [ login ](http://ims.autocrypt.io:13000)\npage.\n\n  \nFull Name*  \n\n  \nCompany  \n\n  \nEmail*  \n\nSubscribe Check  \n\n  \nYes, I\u2019d like to receive updates and news from AUTOCRYPT.  \n\n  \nPlease verify your request*  \n\n  \nRequest Demo  \n\nMarketing by\n\n[  \n  \nActiveCampaign  \n  \n](https://www.activecampaign.com/?utm_medium=referral&utm_campaign=acforms)\n\n\u00d7\n\n  \n  \n  \n  \n  \n  \n  \n\n**  \nPlease fill in the information below to receive your login credential for the\nIMS for SCMS demo.  \n**\n\nReturning user? Please proceed to the [ login ](ims.autocrypt.io:13000) page.\n\n  \n  \n  \nYes, I'd like to receive updates and news from AUTOCRYPT.  \n  \n\n  \nRequest Demo  \n\nCLOSE\n\n**Use and collection of cookies**\n\nAUTOCRYPT collects cookies to ensure you get the best experience on our\nwebsite. Our user cookies collect and process your personal data for analytics\nand marketing purposes. We use the data to continuously improve our content\nand adapt to evolving user and market needs.\n\nThe data will be processed by AUTOCRYPT and third parties outside the EEA.\n\nYou can learn more about the purposes of data processing and our privacy\npolicy [ [here] ](https://autocrypt.io/privacy-policy/) .\n\nGiving consent is optional and is not mandatory for using our website. Your\ncookie consent settings can be revoked or modified in your browser settings at\nany moment going forward.\n\nClose GDPR Cookie Banner  __\n\nConsent  Decline  Close GDPR Cookie Banner  __\n\nClose GDPR Cookie Settings\n\n![AUTOCRYPT](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAV4AAADpAQAAAABE6GLOAAAAAnRSTlMAAHaTzTgAAAAhSURBVGje7cEBDQAAAMKg909tDjegAAAAAAAAAAAAAA4MKPUAAWjLC1sAAAAASUVORK5CYII=)\n![AUTOCRYPT](https://autocrypt.io/wp-content/plugins/gdpr-cookie-\ncompliance/dist/images/gdpr-logo.png)\n\n  * Privacy Overview \n  * Strictly Necessary Cookies \n  * 3rd Party Cookies \n  * Cookie Policy \n\n[ Powered by  GDPR Cookie Compliance  ](https://wordpress.org/plugins/gdpr-\ncookie-compliance/)\n\nPrivacy Overview\n\nThis website uses cookies so that we can provide you with the best user\nexperience possible. Cookie information is stored in your browser and performs\nfunctions such as recognising you when you return to our website and helping\nour team to understand which sections of the website you find most interesting\nand useful.\n\nStrictly Necessary Cookies\n\nStrictly Necessary Cookie should be enabled at all times so that we can save\nyour preferences for cookie settings.\n\nEnable or Disable Cookies\n\nIf you disable this cookie, we will not be able to save your preferences. This\nmeans that every time you visit this website you will need to enable or\ndisable cookies again.\n\n3rd Party Cookies\n\nThis website uses Google Analytics to collect anonymous information such as\nthe number of visitors to the site, and the most popular pages.\n\nKeeping this cookie enabled helps us to improve our website.\n\nEnable or Disable Cookies\n\nPlease enable Strictly Necessary Cookies first so that we can save your\npreferences!\n\nCookie Policy\n\nMore information about our [ Cookie Policy ](https://autocrypt.io/privacy-\npolicy/)\n\nEnable All  Save Settings\n\n"
  },
  {
    "id": "teleopanel/layouthtml1.txt",
    "content": "[ Home ](index.html)\n\n[ Qt Reference Documentation  ](index.html)\n\n  * [ Qt HOME ](http://qt.digia.com/)\n  * [ DEV ](http://qt-project.org/)\n  * [ DOC ](http://qt-project.org/doc/)\n  * [ BLOG ](http://blog.qt.digia.com/)\n\n  * [ Qt 4.8 ](index.html)\n  * [ ALL VERSIONS ](http://qt-project.org/doc/)\n\n  * API Lookup \n    * [ Class index ](classes.html)\n    * [ Function index ](functions.html)\n    * [ Modules ](modules.html)\n    * [ Namespaces ](namespaces.html)\n    * [ Global Declarations ](qtglobal.html)\n    * [ QML elements ](qdeclarativeelements.html)\n  * Qt Topics \n    * [ Programming with Qt ](qt-basic-concepts.html)\n    * [ Device UIs & Qt Quick ](qtquick.html)\n    * [ UI Design with Qt ](qt-gui-concepts.html)\n    * [ Supported Platforms ](supported-platforms.html)\n    * [ Qt and Key Technologies ](technology-apis.html)\n    * [ How-To's and Best Practices ](best-practices.html)\n  * Examples \n    * [ Examples ](all-examples.html)\n    * [ Tutorials ](tutorials.html)\n    * [ Demos ](demos.html)\n    * [ QML Examples ](qdeclarativeexamples.html)\n\nSearch index:\n\nClose\n\nAll  |  API  |  Articles  |  Examples\n\nresults:\n\n##  API Lookup\n\n  * [ Class index ](classes.html)\n  * [ Function index ](functions.html)\n  * [ Modules ](modules.html)\n  * [ Namespaces ](namespaces.html)\n  * [ Global Declarations ](qtglobal.html)\n  * [ QML elements ](qdeclarativeelements.html)\n\n##  Qt Topics\n\n  * [ Programming with Qt ](qt-basic-concepts.html)\n  * [ Device UIs & Qt Quick ](qtquick.html)\n  * [ UI Design with Qt ](qt-gui-concepts.html)\n  * [ Supported Platforms ](supported-platforms.html)\n  * [ Qt and Key Technologies ](technology-apis.html)\n  * [ How-To's and Best Practices ](best-practices.html)\n\n##  Examples\n\n  * [ Examples ](all-examples.html)\n  * [ Tutorials ](tutorials.html)\n  * [ Demos ](demos.html)\n  * [ QML Examples ](qdeclarativeexamples.html)\n\n  * [ Home ](index.html)\n  * Layout Management \n\n  * A \n  * A \n  * A \n  * [ Print  ](javascript:this.print\\(\\);)\n\n[ Widgets and Layouts ](widgets-and-layouts.html) [ Styles ](style-\nreference.html)\n\n###  Contents\n\n  * Introduction \n  * Qt's Layout Classes \n  * Horizontal, Vertical, Grid, and Form Layouts \n  * Laying Out Widgets in Code \n  * Tips for Using Layouts \n  * Adding Widgets to a Layout \n  * Stretch Factors \n  * Custom Widgets in Layouts \n  * Layout Issues \n  * Manual Layout \n  * How to Write A Custom Layout Manager \n  * The Header File ( ` card.h ` ) \n  * The Implementation File ( ` card.cpp ` ) \n  * Further Notes \n\n#  Layout Management\n\nThe Qt layout system provides a simple and powerful way of automatically\narranging child widgets within a widget to ensure that they make good use of\nthe available space.\n\n##  Introduction\n\nQt includes a set of layout management classes that are used to describe how\nwidgets are laid out in an application's user interface. These layouts\nautomatically position and resize widgets when the amount of space available\nfor them changes, ensuring that they are consistently arranged and that the\nuser interface as a whole remains usable.\n\nAll [ QWidget ](qwidget.html) subclasses can use layouts to manage their\nchildren. The [ QWidget::setLayout ](qwidget.html#setLayout) () function\napplies a layout to a widget. When a layout is set on a widget in this way, it\ntakes charge of the following tasks:\n\n  * Positioning of child widgets. \n  * Sensible default sizes for windows. \n  * Sensible minimum sizes for windows. \n  * Resize handling. \n  * Automatic updates when contents change: \n    * Font size, text or other contents of child widgets. \n    * Hiding or showing a child widget. \n    * Removal of child widgets. \n\n##  Qt's Layout Classes\n\nQt's layout classes were designed for hand-written C++ code, allowing\nmeasurements to be specified in pixels for simplicity, so they are easy to\nunderstand and use. The code generated for forms created using _Qt Designer_\nalso uses the layout classes. _Qt Designer_ is useful to use when\nexperimenting with the design of a form since it avoids the compile, link and\nrun cycle usually involved in user interface development.\n\n[ QBoxLayout ](qboxlayout.html)\n\n|\n\nLines up child widgets horizontally or vertically  \n  \n---|---  \n  \n[ QButtonGroup ](qbuttongroup.html)\n\n|\n\nContainer to organize groups of button widgets  \n  \n[ QFormLayout ](qformlayout.html)\n\n|\n\nManages forms of input widgets and their associated labels  \n  \n[ QGraphicsAnchor ](qgraphicsanchor.html)\n\n|\n\nRepresents an anchor between two items in a QGraphicsAnchorLayout  \n  \n[ QGraphicsAnchorLayout ](qgraphicsanchorlayout.html)\n\n|\n\nLayout where one can anchor widgets together in Graphics View  \n  \n[ QGridLayout ](qgridlayout.html)\n\n|\n\nLays out widgets in a grid  \n  \n[ QGroupBox ](qgroupbox.html)\n\n|\n\nGroup box frame with a title  \n  \n[ QHBoxLayout ](qhboxlayout.html)\n\n|\n\nLines up widgets horizontally  \n  \n[ QLayout ](qlayout.html)\n\n|\n\nThe base class of geometry managers  \n  \n[ QLayoutItem ](qlayoutitem.html)\n\n|\n\nAbstract item that a QLayout manipulates  \n  \n[ QSizePolicy ](qsizepolicy.html)\n\n|\n\nLayout attribute describing horizontal and vertical resizing policy  \n  \n[ QSpacerItem ](qspaceritem.html)\n\n|\n\nBlank space in a layout  \n  \n[ QStackedLayout ](qstackedlayout.html)\n\n|\n\nStack of widgets where only one widget is visible at a time  \n  \n[ QStackedWidget ](qstackedwidget.html)\n\n|\n\nStack of widgets where only one widget is visible at a time  \n  \n[ QVBoxLayout ](qvboxlayout.html)\n\n|\n\nLines up widgets vertically  \n  \n[ QWidgetItem ](qwidgetitem.html)\n\n|\n\nLayout item that represents a widget  \n  \n##  Horizontal, Vertical, Grid, and Form Layouts\n\nThe easiest way to give your widgets a good layout is to use the built-in\nlayout managers: [ QHBoxLayout ](qhboxlayout.html) , [ QVBoxLayout\n](qvboxlayout.html) , [ QGridLayout ](qgridlayout.html) , and [ QFormLayout\n](qformlayout.html) . These classes inherit from [ QLayout ](qlayout.html) ,\nwhich in turn derives from [ QObject ](qobject.html) (not [ QWidget\n](qwidget.html) ). They take care of geometry management for a set of widgets.\nTo create more complex layouts, you can nest layout managers inside each\nother.\n\n  * A [ QHBoxLayout ](qhboxlayout.html) lays out widgets in a horizontal row, from left to right (or right to left for right-to-left languages). \n\n![](images/qhboxlayout-with-5-children.png)\n\n  * A [ QVBoxLayout ](qvboxlayout.html) lays out widgets in a vertical column, from top to bottom. \n\n![](images/qvboxlayout-with-5-children.png)\n\n  * A [ QGridLayout ](qgridlayout.html) lays out widgets in a two-dimensional grid. Widgets can occupy multiple cells. \n\n![](images/qgridlayout-with-5-children.png)\n\n  * A [ QFormLayout ](qformlayout.html) lays out widgets in a 2-column descriptive label- field style. \n\n![](images/qformlayout-with-6-children.png)\n\n###  Laying Out Widgets in Code\n\nThe following code creates a [ QHBoxLayout ](qhboxlayout.html) that manages\nthe geometry of five [ QPushButtons ](qpushbutton.html) , as shown on the\nfirst screenshot above:\n\n    \n    \n         [QWidget](qwidget.html) *window = new [QWidget](qwidget.html);\n         [QPushButton](qpushbutton.html) *button1 = new [QPushButton](qpushbutton.html)(\"One\");\n         [QPushButton](qpushbutton.html) *button2 = new [QPushButton](qpushbutton.html)(\"Two\");\n         [QPushButton](qpushbutton.html) *button3 = new [QPushButton](qpushbutton.html)(\"Three\");\n         [QPushButton](qpushbutton.html) *button4 = new [QPushButton](qpushbutton.html)(\"Four\");\n         [QPushButton](qpushbutton.html) *button5 = new [QPushButton](qpushbutton.html)(\"Five\");\n    \n         [QHBoxLayout](qhboxlayout.html) *layout = new [QHBoxLayout](qhboxlayout.html);\n         layout->addWidget(button1);\n         layout->addWidget(button2);\n         layout->addWidget(button3);\n         layout->addWidget(button4);\n         layout->addWidget(button5);\n    \n         window->setLayout(layout);\n         window->show();\n\nThe code for [ QVBoxLayout ](qvboxlayout.html) is identical, except the line\nwhere the layout is created. The code for [ QGridLayout ](qgridlayout.html) is\na bit different, because we need to specify the row and column position of the\nchild widget:\n\n    \n    \n         [QWidget](qwidget.html) *window = new [QWidget](qwidget.html);\n         [QPushButton](qpushbutton.html) *button1 = new [QPushButton](qpushbutton.html)(\"One\");\n         [QPushButton](qpushbutton.html) *button2 = new [QPushButton](qpushbutton.html)(\"Two\");\n         [QPushButton](qpushbutton.html) *button3 = new [QPushButton](qpushbutton.html)(\"Three\");\n         [QPushButton](qpushbutton.html) *button4 = new [QPushButton](qpushbutton.html)(\"Four\");\n         [QPushButton](qpushbutton.html) *button5 = new [QPushButton](qpushbutton.html)(\"Five\");\n    \n         [QGridLayout](qgridlayout.html) *layout = new [QGridLayout](qgridlayout.html);\n         layout->addWidget(button1, 0, 0);\n         layout->addWidget(button2, 0, 1);\n         layout->addWidget(button3, 1, 0, 1, 2);\n         layout->addWidget(button4, 2, 0);\n         layout->addWidget(button5, 2, 1);\n    \n         window->setLayout(layout);\n         window->show();\n\nThe third [ QPushButton ](qpushbutton.html) spans 2 columns. This is possible\nby specifying 2 as the fifth argument to [ QGridLayout::addWidget\n](qgridlayout.html#addWidget) ().\n\n[ QFormLayout ](qformlayout.html) will add two widgets on a row, commonly a [\nQLabel ](qlabel.html) and a [ QLineEdit ](qlineedit.html) to create forms.\nAdding a [ QLabel ](qlabel.html) and a [ QLineEdit ](qlineedit.html) on the\nsame row will set the [ QLineEdit ](qlineedit.html) as the [ QLabel\n](qlabel.html) 's buddy. The following code will use the [ QFormLayout\n](qformlayout.html) to place three [ QPushButtons ](qpushbutton.html) and a\ncorresponding [ QLineEdit ](qlineedit.html) on a row.\n\n    \n    \n         [QWidget](qwidget.html) *window = new [QWidget](qwidget.html);\n         [QPushButton](qpushbutton.html) *button1 = new [QPushButton](qpushbutton.html)(\"One\");\n         [QLineEdit](qlineedit.html) *lineEdit1 = new [QLineEdit](qlineedit.html)();\n         [QPushButton](qpushbutton.html) *button2 = new [QPushButton](qpushbutton.html)(\"Two\");\n         [QLineEdit](qlineedit.html) *lineEdit2 = new [QLineEdit](qlineedit.html)();\n         [QPushButton](qpushbutton.html) *button3 = new [QPushButton](qpushbutton.html)(\"Three\");\n         [QLineEdit](qlineedit.html) *lineEdit3 = new [QLineEdit](qlineedit.html)();\n    \n         [QFormLayout](qformlayout.html) *layout = new [QFormLayout](qformlayout.html);\n         layout->addRow(button1, lineEdit1);\n         layout->addRow(button2, lineEdit2);\n         layout->addRow(button3, lineEdit3);\n    \n         window->setLayout(layout);\n         window->show();\n\n###  Tips for Using Layouts\n\nWhen you use a layout, you do not need to pass a parent when constructing the\nchild widgets. The layout will automatically reparent the widgets (using [\nQWidget::setParent ](qwidget.html#setParent) ()) so that they are children of\nthe widget on which the layout is installed.\n\n**Note:** Widgets in a layout are children of the widget on which the layout\nis installed, _not_ of the layout itself. Widgets can only have other widgets\nas parent, not layouts.\n\nYou can nest layouts using ` addLayout() ` on a layout; the inner layout then\nbecomes a child of the layout it is inserted into.\n\n##  Adding Widgets to a Layout\n\nWhen you add widgets to a layout, the layout process works as follows:\n\n  1. All the widgets will initially be allocated an amount of space in accordance with their [ QWidget::sizePolicy ](qwidget.html#sizePolicy-prop) () and [ QWidget::sizeHint ](qwidget.html#sizeHint-prop) (). \n  2. If any of the widgets have stretch factors set, with a value greater than zero, then they are allocated space in proportion to their stretch factor (explained below). \n  3. If any of the widgets have stretch factors set to zero they will only get more space if no other widgets want the space. Of these, space is allocated to widgets with an [ Expanding ](qsizepolicy.html#Policy-enum) size policy first. \n  4. Any widgets that are allocated less space than their minimum size (or minimum size hint if no minimum size is specified) are allocated this minimum size they require. (Widgets don't have to have a minimum size or minimum size hint in which case the strech factor is their determining factor.) \n  5. Any widgets that are allocated more space than their maximum size are allocated the maximum size space they require. (Widgets do not have to have a maximum size in which case the strech factor is their determining factor.) \n\n###  Stretch Factors\n\nWidgets are normally created without any stretch factor set. When they are\nlaid out in a layout the widgets are given a share of space in accordance with\ntheir [ QWidget::sizePolicy ](qwidget.html#sizePolicy-prop) () or their\nminimum size hint whichever is the greater. Stretch factors are used to change\nhow much space widgets are given in proportion to one another.\n\nIf we have three widgets laid out using a [ QHBoxLayout ](qhboxlayout.html)\nwith no stretch factors set we will get a layout like this:\n\n![Three widgets in a row](images/layout1.png)\n\nIf we apply stretch factors to each widget, they will be laid out in\nproportion (but never less than their minimum size hint), e.g.\n\n![Three widgets with different stretch factors in a row](images/layout2.png)\n\n##  Custom Widgets in Layouts\n\nWhen you make your own widget class, you should also communicate its layout\nproperties. If the widget has a one of Qt's layouts, this is already taken\ncare of. If the widget does not have any child widgets, or uses manual layout,\nyou can change the behavior of the widget using any or all of the following\nmechanisms:\n\n  * Reimplement [ QWidget::sizeHint ](qwidget.html#sizeHint-prop) () to return the preferred size of the widget. \n  * Reimplement [ QWidget::minimumSizeHint ](qwidget.html#minimumSizeHint-prop) () to return the smallest size the widget can have. \n  * Call [ QWidget::setSizePolicy ](qwidget.html#sizePolicy-prop) () to specify the space requirements of the widget. \n\nCall [ QWidget::updateGeometry ](qwidget.html#updateGeometry) () whenever the\nsize hint, minimum size hint or size policy changes. This will cause a layout\nrecalculation. Multiple consecutive calls to [ QWidget::updateGeometry\n](qwidget.html#updateGeometry) () will only cause one layout recalculation.\n\nIf the preferred height of your widget depends on its actual width (e.g., a\nlabel with automatic word-breaking), set the [ height-for-width\n](qsizepolicy.html#hasHeightForWidth) flag in the widget's [ size policy\n](qwidget.html#sizePolicy-prop) and reimplement [ QWidget::heightForWidth\n](qwidget.html#heightForWidth) ().\n\nEven if you implement [ QWidget::heightForWidth ](qwidget.html#heightForWidth)\n(), it is still a good idea to provide a reasonable sizeHint().\n\nFor further guidance when implementing these functions, see the _Qt Quarterly_\narticle [ Trading Height for Width ](http://doc.qt.nokia.com/qq/qq04-height-\nfor-width.html) .\n\n##  Layout Issues\n\nThe use of rich text in a label widget can introduce some problems to the\nlayout of its parent widget. Problems occur due to the way rich text is\nhandled by Qt's layout managers when the label is word wrapped.\n\nIn certain cases the parent layout is put into [ QLayout::FreeResize\n](qlayout.html#SizeConstraint-enum) mode, meaning that it will not adapt the\nlayout of its contents to fit inside small sized windows, or even prevent the\nuser from making the window too small to be usable. This can be overcome by\nsubclassing the problematic widgets, and implementing suitable [ sizeHint()\n](qwidget.html#sizeHint-prop) and [ minimumSizeHint()\n](qwidget.html#minimumSizeHint-prop) functions.\n\nIn some cases, it is relevant when a layout is added to a widget. When you set\nthe widget of a [ QDockWidget ](qdockwidget.html) or a [ QScrollArea\n](qscrollarea.html) (with [ QDockWidget::setWidget\n](qdockwidget.html#setWidget) () and [ QScrollArea::setWidget\n](qscrollarea.html#setWidget) ()), the layout must already have been set on\nthe widget. If not, the widget will not be visible.\n\n##  Manual Layout\n\nIf you are making a one-of-a-kind special layout, you can also make a custom\nwidget as described above. Reimplement [ QWidget::resizeEvent\n](qwidget.html#resizeEvent) () to calculate the required distribution of sizes\nand call [ setGeometry() ](qwidget.html#geometry-prop) on each child.\n\nThe widget will get an event of type [ QEvent::LayoutRequest\n](qevent.html#Type-enum) when the layout needs to be recalculated. Reimplement\n[ QWidget::event ](qwidget.html#event) () to handle [ QEvent::LayoutRequest\n](qevent.html#Type-enum) events.\n\n##  How to Write A Custom Layout Manager\n\nAn alternative to manual layout is to write your own layout manager by\nsubclassing [ QLayout ](qlayout.html) . The [ Border Layout ](layouts-\nborderlayout.html) and [ Flow Layout ](layouts-flowlayout.html) examples show\nhow to do this.\n\nHere we present an example in detail. The ` CardLayout ` class is inspired by\nthe Java layout manager of the same name. It lays out the items (widgets or\nnested layouts) on top of each other, each item offset by [ QLayout::spacing\n](qlayout.html#spacing-prop) ().\n\nTo write your own layout class, you must define the following:\n\n  * A data structure to store the items handled by the layout. Each item is a [ QLayoutItem ](qlayoutitem.html) . We will use a [ QList ](qlist.html) in this example. \n  * [ addItem() ](qlayout.html#addItem) , how to add items to the layout. \n  * [ setGeometry() ](qlayout.html#setGeometry) , how to perform the layout. \n  * [ sizeHint() ](qlayoutitem.html#sizeHint) , the preferred size of the layout. \n  * [ itemAt() ](qlayout.html#itemAt) , how to iterate over the layout. \n  * [ takeAt() ](qlayout.html#takeAt) , how to remove items from the layout. \n\nIn most cases, you will also implement [ minimumSize()\n](qlayout.html#minimumSize) .\n\n###  The Header File ( ` card.h ` )\n\n    \n    \n     #ifndef CARD_H\n     #define CARD_H\n    \n     #include <QtGui>\n     #include <QList>\n    \n     class CardLayout : public [QLayout](qlayout.html)\n     {\n     public:\n         CardLayout([QWidget](qwidget.html) *parent, int dist): [QLayout](qlayout.html)(parent, 0, dist) {}\n         CardLayout([QLayout](qlayout.html) *parent, int dist): [QLayout](qlayout.html)(parent, dist) {}\n         CardLayout(int dist): [QLayout](qlayout.html)(dist) {}\n         ~CardLayout();\n    \n         void addItem([QLayoutItem](qlayoutitem.html) *item);\n         [QSize](qsize.html) sizeHint() const;\n         [QSize](qsize.html) minimumSize() const;\n             [QLayoutItem](qlayoutitem.html) *count() const;\n         [QLayoutItem](qlayoutitem.html) *itemAt(int) const;\n         [QLayoutItem](qlayoutitem.html) *takeAt(int);\n         void setGeometry(const [QRect](qrect.html) &rect);\n    \n     private:\n         [QList](qlist.html)<[QLayoutItem](qlayoutitem.html)*> list;\n     };\n     #endif\n\n###  The Implementation File ( ` card.cpp ` )\n\n    \n    \n     //#include \"card.h\"\n\nFirst we define ` count() ` to fetch the number of items in the list.\n\n    \n    \n     [QLayoutItem](qlayoutitem.html) *CardLayout::count() const\n     {\n             // QList::size() returns the number of QLayoutItems in the list\n         return list.size();\n     }\n\nThen we define two functions that iterate over the layout: ` itemAt() ` and `\ntakeAt() ` . These functions are used internally by the layout system to\nhandle deletion of widgets. They are also available for application\nprogrammers.\n\n` itemAt() ` returns the item at the given index. ` takeAt() ` removes the\nitem at the given index, and returns it. In this case we use the list index as\nthe layout index. In other cases where we have a more complex data structure,\nwe may have to spend more effort defining a linear order for the items.\n\n    \n    \n     [QLayoutItem](qlayoutitem.html) *CardLayout::itemAt(int idx) const\n     {\n         // QList::value() performs index checking, and returns 0 if we are\n         // outside the valid range\n         return list.value(idx);\n     }\n    \n     [QLayoutItem](qlayoutitem.html) *CardLayout::takeAt(int idx)\n     {\n         // QList::take does not do index checking\n         return idx >= 0 && idx < list.size() ? list.takeAt(idx) : 0;\n     }\n\n` addItem() ` implements the default placement strategy for layout items. This\nfunction must be implemented. It is used by [ QLayout::add ](qlayout-\nqt3.html#add) (), by the [ QLayout ](qlayout.html) constructor that takes a\nlayout as parent. If your layout has advanced placement options that require\nparameters, you must provide extra access functions such as the row and column\nspanning overloads of [ QGridLayout::addItem ](qgridlayout.html#addItem) (), [\nQGridLayout::addWidget ](qgridlayout.html#addWidget) (), and [\nQGridLayout::addLayout ](qgridlayout.html#addLayout) ().\n\n    \n    \n     void CardLayout::addItem([QLayoutItem](qlayoutitem.html) *item)\n     {\n         list.append(item);\n     }\n\nThe layout takes over responsibility of the items added. Since [ QLayoutItem\n](qlayoutitem.html) does not inherit [ QObject ](qobject.html) , we must\ndelete the items manually. In the destructor, we remove each item from the\nlist using ` takeAt() ` , and then delete it.\n\n    \n    \n     CardLayout::~CardLayout()\n     {\n          [QLayoutItem](qlayoutitem.html) *item;\n          while ((item = takeAt(0)))\n              delete item;\n     }\n\nThe ` setGeometry() ` function actually performs the layout. The rectangle\nsupplied as an argument does not include ` margin() ` . If relevant, use `\nspacing() ` as the distance between items.\n\n    \n    \n     void CardLayout::setGeometry(const [QRect](qrect.html) &r)\n     {\n         [QLayout](qlayout.html)::setGeometry(r);\n    \n         if (list.size() == 0)\n             return;\n    \n         int w = r.width() - (list.count() - 1) * spacing();\n         int h = r.height() - (list.count() - 1) * spacing();\n         int i = 0;\n         while (i < list.size()) {\n             [QLayoutItem](qlayoutitem.html) *o = list.at(i);\n             [QRect](qrect.html) geom(r.x() + i * spacing(), r.y() + i * spacing(), w, h);\n             o->setGeometry(geom);\n             ++i;\n         }\n     }\n\n` sizeHint() ` and ` minimumSize() ` are normally very similar in\nimplementation. The sizes returned by both functions should include `\nspacing() ` , but not ` margin() ` .\n\n    \n    \n     [QSize](qsize.html) CardLayout::sizeHint() const\n     {\n         [QSize](qsize.html) s(0,0);\n         int n = list.count();\n         if (n > 0)\n             s = [QSize](qsize.html)(100,70); //start with a nice default size\n         int i = 0;\n         while (i < n) {\n             [QLayoutItem](qlayoutitem.html) *o = list.at(i);\n             s = s.expandedTo(o->sizeHint());\n             ++i;\n         }\n         return s + n*[QSize](qsize.html)(spacing(), spacing());\n     }\n    \n     [QSize](qsize.html) CardLayout::minimumSize() const\n     {\n         [QSize](qsize.html) s(0,0);\n         int n = list.count();\n         int i = 0;\n         while (i < n) {\n             [QLayoutItem](qlayoutitem.html) *o = list.at(i);\n             s = s.expandedTo(o->minimumSize());\n             ++i;\n         }\n         return s + n*[QSize](qsize.html)(spacing(), spacing());\n     }\n\n###  Further Notes\n\n  * This custom layout does not handle height for width. \n  * We ignore [ QLayoutItem::isEmpty ](qlayoutitem.html#isEmpty) (); this means that the layout will treat hidden widgets as visible. \n  * For complex layouts, speed can be greatly increased by caching calculated values. In that case, implement [ QLayoutItem::invalidate ](qlayoutitem.html#invalidate) () to mark the cached data is dirty. \n  * Calling [ QLayoutItem::sizeHint ](qlayoutitem.html#sizeHint) (), etc. may be expensive. So, you should store the value in a local variable if you need it again later within in the same function. \n  * You should not call [ QLayoutItem::setGeometry ](qlayoutitem.html#setGeometry) () twice on the same item in the same function. This call can be very expensive if the item has several child widgets, because the layout manager must do a complete layout every time. Instead, calculate the geometry and then set it. (This does not only apply to layouts, you should do the same if you implement your own resizeEvent(), for example.) \n\n[ Widgets and Layouts ](widgets-and-layouts.html) [ Styles ](style-\nreference.html)\n\n\u00a9  2013 Digia Plc and/or its subsidiaries. Documentation contributions\nincluded herein are the copyrights of their respective owners.\n\n  \n\nThe documentation provided herein is licensed under the terms of the [ GNU\nFree Documentation License version 1.3 ](http://www.gnu.org/licenses/fdl.html)\nas published by the Free Software Foundation.\n\nDocumentation sources may be obtained from [ www.qt-project.org\n](http://www.qt-project.org) .\n\n  \n\nDigia, Qt and their respective logos are trademarks of Digia Plc in Finland\nand/or other countries worldwide. All other trademarks are property of their\nrespective owners. [ Privacy Policy ](http://en.gitorious.org/privacy_policy/\n\"Privacy Policy\")\n\n"
  },
  {
    "id": "ros_instantiate/reading20msgs20from2.txt",
    "content": "[ ![ros.org](/custom/images/ros_org.png) ](/) |  [ About\n](http://www.ros.org/about-ros) | [ Support ](/Support) | [ Discussion Forum\n](http://discourse.ros.org/) | [ Index ](http://index.ros.org/) | [ Service\nStatus ](http://status.ros.org/) | [ ros @ Robotics Stack Exchange\n](https://robotics.stackexchange.com/questions/tagged/ros)  \n---|---  \n![](/custom/images/menu_left.png) [\n![Documentation](/custom/images/menu_documentation.png) ](/)\n![](/custom/images/menu_spacer.png) [ ![Browse\nSoftware](/custom/images/menu_browse_software.png)\n](https://index.ros.org/packages) ![](/custom/images/menu_spacer.png) [\n![News](/custom/images/menu_news.png) ](https://discourse.ros.org/c/general)\n![](/custom/images/menu_spacer.png) [\n![Download](/custom/images/menu_download.png) ](/ROS/Installation)\n![](/custom/images/menu_right.png)  \n  \n  * [ rosbag ](/rosbag)\n  * [ Tutorials ](/rosbag/Tutorials)\n  * [ reading msgs from a bag file ](/rosbag/Tutorials/reading%20msgs%20from%20a%20bag%20file)\n\n####  ROS 2 Documentation\n\nThe ROS Wiki is for ROS 1. Are you using ROS 2 ( [ Humble\n](http://docs.ros.org/en/humble/) , [ Iron ](http://docs.ros.org/en/iron/) ,\nor [ Rolling ](http://docs.ros.org/en/rolling/) )?  \n[ Check out the ROS 2 Project Documentation ](http://docs.ros.org)  \nPackage specific documentation can be found on [ index.ros.org\n](https://index.ros.org)\n\n#  Wiki\n\n  * [ Distributions ](/Distributions)\n  * [ ROS/Installation ](/ROS/Installation)\n  * [ ROS/Tutorials ](/ROS/Tutorials)\n  * [ RecentChanges ](/RecentChanges)\n  * [ reading msg... a bag file ](/rosbag/Tutorials/reading%20msgs%20from%20a%20bag%20file)\n\n#  Page\n\n  * Immutable Page \n  * Comments \n  * [ Info ](/action/info/rosbag/Tutorials/reading%20msgs%20from%20a%20bag%20file?action=info)\n  * [ Attachments ](/action/AttachFile/rosbag/Tutorials/reading%20msgs%20from%20a%20bag%20file?action=AttachFile)\n  * More Actions:  Raw Text  Print View  Render as Docbook  Delete Cache  \\------------------------  Check Spelling  Like Pages  Local Site Map  \\------------------------  Rename Page  Copy Page  Delete Page  \\------------------------  My Pages  Subscribe User  \\------------------------  Remove Spam  Revert to this revision  Package Pages  Sync Pages  \\------------------------  CreatePdfDocument  Load  RawFile  Save  SlideShow \n\n#  User\n\n  * [ Login ](/action/login/rosbag/Tutorials/reading%20msgs%20from%20a%20bag%20file?action=login)\n\n**Note:** This tutorial assumes that you have completed the previous\ntutorials: [ Recording and playing back data\n](/rosbag/Tutorials/Recording%20and%20playing%20back%20data) .  \n---  \n  \n![\\(!\\)](/moin_static197/rostheme/img/idea.png) Please ask about problems and\nquestions regarding this tutorial on [ answers.ros.org\n](http://answers.ros.org) . Don't forget to include in your question the link\nto this page, the versions of your OS & ROS, and also add appropriate tags.  \n---  \n  \n#  Reading messages from a bag file\n\n**Description:** Learn two ways to read messages from desired topics in a bag\nfile, including using the really handy **ros_readbagfile** script.  \n  \n**Keywords:** data, rosbag, extract, play, info, bag, messages, readbagfile,\nros_readbagfile  \n  \n**Tutorial Level:** BEGINNER  \n  \n**Next Tutorial:** [ Producing filtered bag files\n](/rosbag/Tutorials/Producing%20filtered%20bag%20files)  \n  \n\nContents\n\n  1. Download or record a bag file \n  2. Option 1: play back the messages immediately and look at the output in multiple terminals \n  3. Option 2: use the ros_readbagfile script to easily extract the topics of interest \n    1. More .yaml file analysis \n      1. Example 1: \n      2. Example 2: \n  4. Why use `ros_readbagfile` for this purpose instead of `rostopic echo -b`? \n\n#  Download or record a bag file\n\nFirst, you need a bag file. Produce your own by following this tutorial ( [\nROS/Tutorials/Recording and playing back data\n](/ROS/Tutorials/Recording%20and%20playing%20back%20data) ).\n\nAssuming you are on a system with ROS already running, here is a quick command\nto record a 30 second snippet of data into a bag file for just topics you are\ninterested in, ex: ` /topic1 ` , ` /topic2 ` , and ` /topic3 ` . Since we are\nsetting a duration of 30 seconds, the recording will automatically stop after\nthis time:\n\n    \n    \n    rosbag record --duration=30 --output-name=/tmp/mybagfile.bag \\\n        /topic1 /topic2 /topic3\n\n\\---\n\nThe rest of this tutorial will be done assuming you've downloaded the\nwebviz.io demo bag file using the ` wget ` command as shown above. You will go\nthrough two options to read/extract messages from the bag file.\n\n_Note that in any of the commands below, the` time ` command is prepended\nsimply because it will print out how long each command takes, and since\nsometimes these commands can take a long time, it is useful to use the ` time\n` command to gain an idea of how long a given command should take. If you\ndon't want to use it, you may remove the ` time ` part of any of the commands\nbelow. _\n\n#  Option 1: play back the messages immediately and look at the output in\nmultiple terminals\n\n[ Source: this material was adapted from instructions first published in this\ndocument here.\n](https://github.com/ElectricRCAircraftGuy/eRCaGuy_dotfiles/blob/master/git%20%26%20Linux%20cmds%2C%20help%2C%20tips%20%26%20tricks%20-%20Gabriel.txt)\n\n  1. You need to know the _exact_ topic names you'd like to read from the bag file. So, let's see what's in the bag file. In any terminal, manually inspect all published topics and how many messages were published to each topic with this command: \n    \n        time rosbag info demo.bag  \n    # OR (if you know part of the topic names of interest before-hand):\n    time rosbag info mybag.bag | grep -E \"(topic1|topic2|topic3)\"\n\nSample output:\n\n    \n        $ time rosbag info demo.bag  \n    path:        demo.bag\n    version:     2.0\n    duration:    20.0s\n    start:       Mar 21 2017 19:37:58.00 (1490150278.00)\n    end:         Mar 21 2017 19:38:17.00 (1490150298.00)\n    size:        696.2 MB\n    messages:    5390\n    compression: none [600/600 chunks]\n    types:       bond/Status                      [eacc84bf5d65b6777d4c50f463dfb9c8]\n                 diagnostic_msgs/DiagnosticArray  [60810da900de1dd6ddd437c3503511da]\n                 diagnostic_msgs/DiagnosticStatus [d0ce08bc6e5ba34c7754f563a9cabaf1]\n                 nav_msgs/Odometry                [cd5e73d190d741a2f92e81eda573aca7]\n                 radar_driver/RadarTracks         [6a2de2f790cb8bb0e149d45d297462f8]\n                 sensor_msgs/Image                [060021388200f6f0f447d0fcd9c64743]\n                 sensor_msgs/NavSatFix            [2d3a8cd499b9b4a0249fb98fd05cfa48]\n                 sensor_msgs/PointCloud2          [1158d486dd51d683ce2f1be655c3c181]\n                 sensor_msgs/Range                [c005c34273dc426c67a020a87bc24148]\n                 sensor_msgs/TimeReference        [fded64a0265108ba86c3d38fb11c0c16]\n                 tf2_msgs/TFMessage               [94810edda583a504dfda3829e70d7eec]\n                 velodyne_msgs/VelodyneScan       [50804fc9533a0e579e6322c04ae70566]\n    topics:      /diagnostics                      140 msgs    : diagnostic_msgs/DiagnosticArray \n                 /diagnostics_agg                   40 msgs    : diagnostic_msgs/DiagnosticArray \n                 /diagnostics_toplevel_state        40 msgs    : diagnostic_msgs/DiagnosticStatus\n                 /gps/fix                          146 msgs    : sensor_msgs/NavSatFix           \n                 /gps/rtkfix                       200 msgs    : nav_msgs/Odometry               \n                 /gps/time                         192 msgs    : sensor_msgs/TimeReference       \n                 /image_raw                        600 msgs    : sensor_msgs/Image               \n                 /obs1/gps/fix                      30 msgs    : sensor_msgs/NavSatFix           \n                 /obs1/gps/rtkfix                  200 msgs    : nav_msgs/Odometry               \n                 /obs1/gps/time                    136 msgs    : sensor_msgs/TimeReference       \n                 /radar/points                     400 msgs    : sensor_msgs/PointCloud2         \n                 /radar/range                      400 msgs    : sensor_msgs/Range               \n                 /radar/tracks                     400 msgs    : radar_driver/RadarTracks        \n                 /tf                              1986 msgs    : tf2_msgs/TFMessage              \n                 /velodyne_nodelet_manager/bond     80 msgs    : bond/Status                     \n                 /velodyne_packets                 200 msgs    : velodyne_msgs/VelodyneScan      \n                 /velodyne_points                  200 msgs    : sensor_msgs/PointCloud2\n    \n    real    0m1.003s\n    user    0m0.620s\n    sys 0m0.283s\n\nNotice that there are 30 messages published on topic ` /obs1/gps/fix ` , and\n40 on topic ` /diagnostics_agg ` . Let's just extract those.\n\n  2. In terminal 1 (this terminal, for example), start up a ros core, which runs the required ROS master node: \n    \n        roscore\n\n  3. Open up another terminal. Note: to open up another terminal tab in the same terminal window you can use **Ctrl + Shift + T** on Ubuntu. Subscribe to the ` /obs1/gps/fix ` topic, echoing (printing) everything published on this topic, while also ` tee ` ing it to a file for later review, all in yaml format: \n    \n        rostopic echo /obs1/gps/fix | tee topic1.yaml\n\nYou'll see:\n\n    \n        $ rostopic echo /obs1/gps/fix | tee topic1.yaml\n    WARNING: topic [/obs1/gps/fix] does not appear to be published yet\n\n  4. Open up another terminal. Subscribe to the other topic: ` /diagnostics_agg ` . \n    \n        rostopic echo /diagnostics_agg | tee topic2.yaml\n\nYou'll see:\n\n    \n        $ rostopic echo /diagnostics_agg | tee topic2.yaml\n    WARNING: topic [/diagnostics_agg] does not appear to be published yet\n\n  5. Repeat this process for as many topics as you like. Each topic must have its own terminal. \n  6. Open up another terminal to play the bag file. We will now play back the bag file as quickly as possible (using the ` --immediate ` option), publishing ONLY the topics of interest. The format is: \n    \n        time rosbag play --immediate demo.bag --topics /topic1 /topic2 /topic3 /topicN\n\nSo in our case, the command would be:\n\n    \n        time rosbag play --immediate demo.bag --topics /obs1/gps/fix /diagnostics_agg\n\nYou'll see:\n\n    \n        $ time rosbag play --immediate demo.bag --topics /obs1/gps/fix /diagnostics_agg\n    [ INFO] [1591916465.758724557]: Opening demo.bag\n    \n    Waiting 0.2 seconds after advertising topics... done.\n    \n    Hit space to toggle paused, or 's' to step.\n     [RUNNING]  Bag Time: 1490150297.770734   Duration: 19.703405 / 19.703405               \n    Done.\n    \n    real  0m1.570s\n    user  0m0.663s\n    sys 0m0.394s\n\n  7. Done! Now go look at your two terminals which were each subsribed to a topic, and you'll see the output of all messages for each topic type, in YAML format, with a ` --- ` line between each message. Use a text editor of your choice, preferably with Syntax Highlighting for YAML file types (ex: Sublime Text 3) to view the messages in the files. The last two messages in **topic1.yaml** , for instance, look like this: \n    \n        ---\n    header: \n      seq: 4027\n      stamp: \n        secs: 1490150296\n        nsecs:  66947432\n      frame_id: \"gps\"\n    status: \n      status: 0\n      service: 1\n    latitude: 37.4008017844\n    longitude: -122.108119889\n    altitude: -6.4380177824\n    position_covariance: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n    position_covariance_type: 0\n    ---\n    header: \n      seq: 4028\n      stamp: \n        secs: 1490150297\n        nsecs: 744347249\n      frame_id: \"gps\"\n    status: \n      status: 0\n      service: 1\n    latitude: 37.4007565466\n    longitude: -122.108159482\n    altitude: -6.35130467023\n    position_covariance: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n    position_covariance_type: 0\n    ---\n\nIf for some reason one of your ` rostopic ` processes missed the messages,\njust kill its process with **Ctrl + C** , restart it, and call the ` rosbag\nplay ` command again.\n\n#  Option 2: use the ros_readbagfile script to easily extract the topics of\ninterest\n\nSource: [ this material was adapted from instructions first published in this\ndocument here\n](https://github.com/ElectricRCAircraftGuy/eRCaGuy_dotfiles/blob/master/git%20%26%20Linux%20cmds%2C%20help%2C%20tips%20%26%20tricks%20-%20Gabriel.txt)\n, and [ the Python script is from here: ros_readbag.py\n](https://github.com/ElectricRCAircraftGuy/eRCaGuy_dotfiles/blob/master/useful_scripts/ros_readbagfile.py)\n.\n\nNote: you can kill any running processes. No ` roscore ` , for instance, is\nrequired.\n\n  1. Download and install [ `ros_readbag.py` ](https://github.com/ElectricRCAircraftGuy/eRCaGuy_dotfiles/blob/master/useful_scripts/ros_readbagfile.py) using these commands. Be sure to read the comments in the top of the file for the latest information on installation instructions and python dependencies. \n    \n        # Download the file\n    wget https://raw.githubusercontent.com/ElectricRCAircraftGuy/eRCaGuy_dotfiles/master/useful_scripts/ros_readbagfile.py\n    # Make it executable\n    chmod +x ros_readbagfile.py\n    # Ensure you have the ~/bin directory for personal binaries\n    mkdir -p ~/bin\n    # Move this executable script into that directory as `ros_readbagfile`, so that it will\n    # be available as that command\n    mv ros_readbagfile.py ~/bin/ros_readbagfile\n    # Re-source your ~/.profile file to ensure ~/bin is in your PATH, so you can use this\n    # new `ros_readbagfile` command you just installed\n    # Note: this assumes you are on Linux Ubuntu with a default `~/.profile` file. If you're\n    # on some other Linux distribution, such as Arch Linux, you can manually create the\n    # `~/.profile` file. See here for details: \n    # https://answers.ros.org/question/371583/ros_readbagfile-command-not-found/?answer=403354#post-id-403354\n    . ~/.profile\n    #\n    # Install python dependencies (see the comments at the top of the ros_readbagfile.py \n    # file for the latest dependencies and instructions)\n    pip install bagpy\n    pip3 install bagpy\n\nNote: if your terminal still says it cannot find the command when trying to\nrun it, you may need to ensure ` ~/bin ` is part of your ` PATH ` variable.\nSee [ my answer here for details\n](https://answers.ros.org/question/371583/ros_readbagfile-command-not-\nfound/?answer=403354#post-id-403354) .\n\n  2. Determine the _exact_ topic names you'd like to read from the bag file, by using ` rosbag info ` , as shown in Step 1 of Option 1 above. \n\n  3. Now use ` ros_readbagfile ` . The general format is: \n    \n        # read these topics and print them to stdout\n    time ros_readbagfile <mybagfile.bag> [topic1] [topic2] [topic3] [...]\n    \n    # Write to the topics.yaml file withOUT also printing to stdout\n    time ros_readbagfile <mybagfile.bag> [topic1] [topic2] [topic3] [...] > topics.yaml\n    \n    # OR (preferred, so you can easily see it is still running): write to the\n    # topics.yaml file AND print to stdout\n    time ros_readbagfile <mybagfile.bag> [topic1] [topic2] [topic3] [...] | tee topics.yaml\n\nTo read the same messages shown in Option 1 above, use:\n\n    \n        # (preferred, so you can easily see it is still running): write to the\n    # topics.yaml file AND print to stdout\n    time ros_readbagfile demo.bag /obs1/gps/fix /diagnostics_agg | tee topics.yaml\n\nOptionally, to see \"progress\" by watching the yaml file grow in size, in a new\nterminal, run the following. Note: the yaml text file will be about 2x as\nlarge as the original binary .bag file when complete.\n\n    \n        watch -n 1 'du -sk topics.yaml | awk '\\''{printf \"%.3f MiB %s\\n\", $1/1024, $2}'\\'''\n\nThat's it! You'll see it print out all 70 messages quickly. Here is what the\nlast little bit of the terminal output looks like:\n\n    \n                key: \"Early diagnostic update count:\"\n            value: \"0\"\n          - \n            key: \"Zero seen diagnostic update count:\"\n            value: \"0\"\n    \n    # =======================================\n    # topic:           /obs1/gps/fix\n    # msg_count:       30\n    # timestamp (sec): 1490150297.770734310\n    # - - -\n    header: \n      seq: 4028\n      stamp: \n        secs: 1490150297\n        nsecs: 744347249\n      frame_id: \"gps\"\n    status: \n      status: 0\n      service: 1\n    latitude: 37.40075654660259\n    longitude: -122.10815948235131\n    altitude: -6.351304670230949\n    position_covariance: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n    position_covariance_type: 0\n    \n    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    # Total messages found:               70\n    #\n    #    /diagnostics_agg:                40\n    #    /obs1/gps/fix:                   30\n    #\n    # DONE.\n    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    \n    real    0m0.812s\n    user    0m0.599s\n    sys 0m0.077s\n\nNow view **topics.yaml** with your preferred text editor or viewer (ex:\nSublime Text 4, gedit, emacs, vim, ` less ` , etc) to see all of the messages\nit extracted from the bag file.\n\n_Note that topics.yaml is a true YAML-formatted file. All non-YAML content,\nsuch as message separators, is commented out with the` # ` symbol. _\n\n##  More .yaml file analysis\n\nNow that you have the .yaml file (produced from the .bag file), here are some\ndemonstrations of how to scan it for a list of keys or text strings you are\ninterested in to see if certain data is present.\n\n_Note that the following examples require the ripgrep (` rg ` ) command, which\nis like ` grep ` only waaay faster. See here: [\nhttps://github.com/BurntSushi/ripgrep#installation\n](https://github.com/BurntSushi/ripgrep#installation) . Install ripgrep ( ` rg\n` ) with:\n\n    \n    \n    sudo apt update && sudo apt install ripgrep\n\n###  Example 1:\n\nLet's say you want to find a list of all key entries which begin with\n\"piksi_\". You can do so by searching for the string \" ` key: \"piksi_ ` \", as\nfollows.\n\n    \n    \n    time rg 'key: \"piksi_' topics.yaml | sort -V | awk '!seen[$0]++'\n\nThe ` rg 'key: \"piksi_' topics.yaml ` part searches the \"topics.yaml\" text\nfile for the ` 'key: \"piksi_' ` string, the ` sort -V ` part sorts all of the\noutput lines, and the ` awk '!seen[$0]++' ` part removes duplicate entries, so\nthat you only see one line of each match.\n\nCommand and output:\n\n    \n    \n    $ time rg 'key: \"piksi_' topics.yaml | sort -V | awk '!seen[$0]++'\n            key: \"piksi_llh_diag: Frequency Status\"\n            key: \"piksi_rtk_diag: Frequency Status\"\n            key: \"piksi_rtk_diag: Piksi Status\"\n            key: \"piksi_time_diag: Frequency Status\"\n    \n    real    0m0.009s\n    user    0m0.003s\n    sys     0m0.011s\n\n###  Example 2:\n\nLet's search for all key data entries which begin with \"GPS\", \"Duration\", or\n\"Minimum\". \"OR\" type regular expression searches take the general format: `\n(str1|str2|str3|etc) ` , with ` | ` being read as \"or\" in this case. So,\nsearching for \"GPS\", \"Duration\", or \"Minimum\" can be done with the following\nregular expression search string: ` '(key: \"GPS|key: \"Duration|key: \"Minimum)'\n` .\n\nHere is the command to run:\n\n    \n    \n    time rg '(key: \"GPS|key: \"Duration|key: \"Minimum)' topics.yaml | sort -V | awk '!seen[$0]++'\n\n...and here is the full output:\n\n    \n    \n    $ time rg '(key: \"GPS|key: \"Duration|key: \"Minimum)' topics.yaml | sort -V | awk '!seen[$0]++'\n            key: \"Duration of window (s)\"\n            key: \"GPS RTK height difference (m)\"\n            key: \"GPS RTK horizontal accuracy (m)\"\n            key: \"GPS RTK meters east\"\n            key: \"GPS RTK meters north\"\n            key: \"GPS RTK orientation east\"\n            key: \"GPS RTK orientation north\"\n            key: \"GPS RTK orientation up\"\n            key: \"GPS RTK solution status (4 = good)\"\n            key: \"GPS RTK velocity east\"\n            key: \"GPS RTK velocity flags\"\n            key: \"GPS RTK velocity north\"\n            key: \"GPS RTK velocity up\"\n            key: \"GPS altitude\"\n            key: \"GPS latitude\"\n            key: \"GPS lat/lon horizontal accuracy (m)\"\n            key: \"GPS lat/lon solution status\"\n            key: \"GPS longitude\"\n            key: \"Minimum acceptable frequency (Hz)\"\n    \n    real    0m0.023s\n    user    0m0.023s\n    sys     0m0.008s\n\n#  Why use `ros_readbagfile` for this purpose instead of `rostopic echo -b`?\n\nAnswer:\n\n  1. Because ` rostopic ` is **extremley slow!** This command, running on a fast computer (4-core/8-thread Pentium i7 w/m.2 SSD), for instance, takes **11.5 minutes** to read an 18 GB bag file! \n    \n        time rostopic echo -b large_bag_file.bag /topic1\n\nThe ` ros_readbagfile ` script, however, takes only **1 min 37 sec** on the\nsame computer to read the same topic from the same 18 GB bag file! Therefore,\n` ros_readbagfile ` is 11.5/(1+37/60) = **~7x faster!**\n\n    \n        time ros_readbagfile large_bag_file.bag /topic1\n\n  2. Because ` rostopic ` can only read **1 single topic at a time** , whereas ` ros_readbagfile ` can read **any number of topics at once!**\n    \n        ros_readbagfile <mybagfile.bag> [topic1] [topic2] [topic3] [...] [topic1000]\n\nEND.\n\n_\n\nWiki: rosbag/Tutorials/reading msgs from a bag file (last edited 2024-04-16\n15:57:36 by  [ KatherineScott ](/KatherineScott \"KatherineScott @\n157.131.162.29\\[157.131.162.29\\]\") )\n\nExcept where otherwise noted, the ROS wiki is licensed under the  \n[ Creative Commons Attribution 3.0\n](http://creativecommons.org/licenses/by/3.0/)\n\n* * *\n\n[ ![](/custom/images/brought_by_horiz.png) ](https://www.openrobotics.org/)\n\n"
  },
  {
    "id": "set_position_ros2/usingros1transformst.txt",
    "content": "[ ![Foxglove](/images/logo-white.svg) ](/)\n\n[ Product ](/product) [ Blog ](/blog) [ Customers ](/customers) [ Pricing\n](/pricing) [ Docs ](https://docs.foxglove.dev) [ Download\n](https://foxglove.dev/download) [ Sign in ](https://app.foxglove.dev/signin)\n[ Get started ](https://app.foxglove.dev/signup)\n\nOpen menu\n\n[ Product ](/product) [ Blog ](/blog) [ Customers ](/customers) [ Pricing\n](/pricing) [ Docs ](https://docs.foxglove.dev) [ Download\n](https://foxglove.dev/download) [ Sign in ](https://app.foxglove.dev/signin)\n[ Get started ](https://app.foxglove.dev/signup)\n\n#  Using ROS 1 Transforms to Calculate Object Positions\n\nUse the ROS 1 tf2 library to calculate the relative positions of detected\nobjects\n\n![Jos\u00e9 L. Mill\u00e1n](/images/blog/authors/joselmillan.webp) Jos\u00e9 L. Mill\u00e1n  \u00b7\n\n![Esther Weon](/images/blog/authors/estherweon.webp) Esther Weon  \u00b7\n\n10 min  read\n\nPublished  March 20, 2023\n\n![Using ROS 1 Transforms to Calculate Object Positions](/images/blog/using-\nros1-transforms-to-calculate-object-positions/hero.png)\n\nIn previous posts, we've covered how [ visualizing ROS 1 transforms in\nFoxglove Studio ](/blog/publishing-and-visualizing-ros1-transforms) can help\nus [ describe the relative positions of a robot\u2019s components\n](/blog/understanding-ros-transforms) .\n\nIn this tutorial, we'll learn how ROS 1 transforms can help us calculate the\nposition of an object not explicitly linked to a robot \u2013 in relation to both\nthe sensor that detected it and the actuator that will interact with it.\n\n##  Calculating positions in different frames\n\nLet\u2019s consider the robot model from our previous ROS transforms tutorials:\n\n![example robot model](/images/blog/using-ros1-transforms-to-calculate-object-\npositions/robot.png)\n\nIf our robot\u2019s sensor were to detect an object, we'd have that object\u2019s\nposition in the ` sensor_link ` frame. To use our robot\u2019s arm to grab it,\nhowever, we\u2019d then need to calculate the object\u2019s position in the `\narm_end_link ` frame.\n\nWith the ROS 1 [ ` tf2 ` library ](http://wiki.ros.org/tf2) , we can easily\ntransform our object\u2019s position across frames \u2013 all without worrying about any\nof the complicated mathematical operations happening under the hood \u2013 and\ndeduce how our arm needs to move to complete this task.\n\n###  Create a sensor node to simulate object detection\n\nFirst, let\u2019s create a node that simulates our robot\u2019s sensor.\n\nIn a ` sensor.cpp ` file, include the following libraries:\n\n    \n    \n    #include <ros/ros.h>\n    #include \"geometry_msgs/PoseStamped.h\"\n    \n\nDefine a ` Sensor ` class with the following private variables:\n\n    \n    \n    class Sensor:  ros::NodeHandle{\n    private:\n      // Timer for the simulated detected object\n      ros::Timer object_timer_;\n      // Publisher for the simulated detected object\n      ros::Publisher pose_pub_;\n      // Pose to publish\n      geometry_msgs::PoseStamped pose_;\n      // Aux variable that determines the detected object\u2019s position\n      int count_ = 0;\n    \n\nIt should also include a timer callback, to periodically publish the detected\nobject\u2019s position:\n\n    \n    \n      void objectCallback(){\n        // All transforms must be correctly time-stamped\n        pose_.header.stamp = ros::Time::now();\n        pose_.header.frame_id = \"sensor_link\";\n    \n        if (count_ % 2) {\n          pose_.pose.position.x = 1.0;\n          pose_.pose.position.y = 1.0;\n        } else {\n          pose_.pose.position.x = 2.0;\n          pose_.pose.position.y = 3.0;\n        }\n    \n        // Change the detected object\u2019s position, depending on whether count_ is even or odd\n        count_++;\n        pose_pub_.publish(pose_);\n      }\n    \n\nNext, write a class constructor that publishes the detected object\u2019s pose on a\ntimer (every second). Since poses are not transform messages, they will be\npublished on a ` /detected_object ` topic (instead of ` /tf ` or ` /tf_static\n` ):\n\n    \n    \n    public:\n      Sensor():\n      NodeHandle(\"~\"){\n        // Initialize timer for object detection\n        object_timer_ = createTimer(ros::Duration(1),\n          std::bind(&Sensor::objectCallback, this));\n    \n        // Initialize pub for object detection\n        pose_pub_ = advertise<geometry_msgs::PoseStamped>(\n          \"/detected_object\", 10);\n      }\n    \n      ~Sensor(){}\n    };\n    \n\nFinally, add the ` main ` function that declares and spins the node:\n\n    \n    \n    int main(int argc, char **argv){\n      ros::init(argc, argv, \"sensor\");\n      auto node = Sensor();\n      ros::spin();\n      return 0;\n    }\n    \n\n###  Create a listener node to calculate the object\u2019s position\n\nNext, let\u2019s create a listener node to transform the object\u2019s position from the\n` sensor_link ` frame to the ` arm_end_link ` frame.\n\nIn a ` tf_listener.cpp ` file, include the following libraries:\n\n    \n    \n    #include <ros/ros.h>\n    #include \"geometry_msgs/PoseStamped.h\"\n    #include \"tf2_geometry_msgs/tf2_geometry_msgs.h\"\n    #include \"tf2/exceptions.h\"\n    #include \"tf2_ros/transform_listener.h\"\n    #include \"tf2_ros/buffer.h\"\n    \n\nDefine a ` TfListener ` class with the following private variables:\n\n    \n    \n    class TfListener : ros::NodeHandle{\n    private:\n      // Subscription to pose published by sensor node\n      ros::Subscriber pose_sub_;\n      // Buffer that stores several seconds of transforms for easy lookup by the listener\n      tf2_ros::Buffer tf_buffer_;\n      // Listener for the broadcast transform message\n      tf2_ros::TransformListener* tf_listener_;\n      // Pose in source frame (`sensor_link`)\n      geometry_msgs::PoseStamped pose_in_;\n      // Pose in target frame (`arm_end_link`)\n      geometry_msgs::PoseStamped pose_out_;\n    \n\nIt should also include a ` poseCallback ` function, which looks up the\ntransform between the source and target frames every time the sensor sends a\nnew pose:\n\n    \n    \n      void poseCallback(const geometry_msgs::PoseStamped msg) {\n        try {\n          // Store the incoming pose in pose_in_\n          pose_in_ = msg;\n          // Transforms the pose between the source frame and target frame\n          tf_buffer_.transform<geometry_msgs::PoseStamped>(pose_in_, pose_out_,\n            \"arm_end_link\", ros::Duration(1));\n          // Log coordinates of pose in target frame\n          ROS_INFO(\"Object pose in 'arm_end_link' is:\\n x,y,z = %.1f,%.1f,%.1f\",\n            pose_out_.pose.position.x,\n            pose_out_.pose.position.y,\n            pose_out_.pose.position.z);\n        } catch (const tf2::TransformException & ex) {\n          ROS_WARN(\"Could not find object position in 'arm_end_link' frame.\");\n          return;\n        }\n      }\n    \n\nNext, write a class constructor that loads and listens to your buffer of\ntransforms, and then subscribe\u2019s to the sensor\u2019s ` /detected_object ` pose\ntopic:\n\n    \n    \n    public:\n      TfListener():\n      NodeHandle(\"~\") {\n        // Listen to the buffer of transforms\n        tf_listener_ = new tf2_ros::TransformListener(tf_buffer_);\n        // Subscribe to pose published by sensor node (check every second)\n        pose_sub_ = subscribe<geometry_msgs::PoseStamped>\n          (\"/detected_object\", 10, &TfListener::poseCallback, this);\n      }\n    \n      ~TfListener(){}\n    };\n    \n\nLastly, write a ` main ` function that declares and spins the node:\n\n    \n    \n    int main(int argc, char **argv) {\n      ros::init(argc, argv, \"tf_listener\");\n      TfListener node;\n      ros::spin();\n      return 0;\n    }\n    \n\nAdd the following lines to your ` CMakeLists.txt ` to add the executables to\nthe compilation list:\n\n    \n    \n    add_executable(sensor src/sensor.cpp)\n    add_executable(tf_listener src/tf_listener.cpp)\n    \n    target_link_libraries(sensor\n      ${catkin_LIBRARIES}\n    )\n    target_link_libraries(tf_listener\n      ${catkin_LIBRARIES}\n    )\n    \n\nCompile your package with ` $ catkin_make ` .\n\n###  Launch nodes and visualize transforms\n\nLet\u2019s first publish the transforms between our ` base_link ` and both `\narm_base_link ` and ` sensor_link ` . Use the ` static_transform_publisher `\nwe\u2019ve learned in the [ previous post ](/blog/publishing-and-visualizing-\nros1-transforms) :\n\n    \n    \n    $ rosrun tf2_ros static_transform_publisher 1 1 0 0 0 0 base_link arm_base_link\n    $ rosrun tf2_ros static_transform_publisher 1 -1 0 0 0 0 base_link sensor_link\n    \n\nYou will also need the ` tf_broadcaster ` that publishes the ` arm_end_link `\nframe:\n\n    \n    \n    $ rosrun transforms tf_broadcaster\n    \n\nFinally, run your new nodes:\n\n    \n    \n    $ rosrun transforms sensor_node\n    $ rosrun transforms tf_listener\n    \n\nOpen a connection to your data in Foxglove Studio using the [ Foxglove bridge\n](/blog/announcing-the-new-foxglove-bridge-for-live-ros-data) . Open a [ 3D\npanel ](https://docs.foxglove.dev/docs/visualization/panels/3d) to visualize\nthe frames and detected object positions, and a [ Log panel\n](https://docs.foxglove.dev/docs/visualization/panels/log) to see the printout\nof our object\u2019s position.\n\n![visualizing in Foxglove Studio](/images/blog/using-ros1-transforms-to-\ncalculate-object-positions/studio.gif) _The object is represented by a purple\narrow in the 3D panel. Its position in the` arm_end_link ` frame is printed by\nthe ` tf_listener ` node in the Log panel. _\n\nNotice that the object arrow is different from the axes arrows that represent\neach frame. This is because the object is not a transform, but a [ ` Pose `\n](http://docs.ros.org/en/noetic/api/geometry_msgs/html/msg/PoseStamped.html) .\nIf you use the [ Teleop panel\n](https://docs.foxglove.dev/docs/visualization/panels/teleop) to move the `\narm_end_link ` frame around, you can see firsthand how the position of your\ndetected object changes.\n\n###  Create a launch file\n\nIn a ` launch ` folder, let\u2019s create a ` tf_launch.launch ` file to launch all\nnodes together:\n\n    \n    \n    <?xml version=\"1.0\"?>\n    <launch>\n    \n      <!-- Two static transforms publishers -->\n      <node pkg=\"tf2_ros\" type=\"static_transform_publisher\" name=\"sensor_link\" args=\"1 -1 0 0 0 0 base_link sensor_link\" />\n      <node pkg=\"tf2_ros\" type=\"static_transform_publisher\" name=\"arm_base_link\" args=\"1 1 0 0 0 0 base_link arm_base_link\" />\n    \n      <!-- Three nodes from transform package-->\n      <node pkg=\"transforms\" type=\"tf_broadcaster\" name=\"tf_broadcaster\" output=\"screen\"/>\n      <node pkg=\"transforms\" type=\"sensor\" name=\"sensor\" output=\"screen\"/>\n      <node pkg=\"transforms\" type=\"tf_listener\" name=\"tf_listener\" output=\"screen\"/>\n    \n      <!-- Foxglove Bridge node -->\n      <node pkg=\"foxglove_bridge\" type=\"foxglove_bridge\" name=\"foxglove_bridge\" output=\"screen\"/>\n    \n    </launch>\n    \n\nNow you can start all nodes, the [ Foxglove bridge connection\n](https://docs.foxglove.dev/docs/connecting-to-data/ros-foxglove-bridge) , and\nFoxglove Studio with a single command.\n\n![launching in Foxglove Studio](/images/blog/using-ros1-transforms-to-\ncalculate-object-positions/launch.gif)\n\n##  Stay in touch\n\nBy leveraging ROS 1 transforms and the [ ` tf2 ` library\n](http://wiki.ros.org/tf2) , you can easily integrate your robots' sensors and\nactuators to work better together.\n\nFor a reference to all the code covered in this post, check out our [ `\nfoxglove/tutorials ` GitHub repo\n](https://github.com/foxglove/tutorials/tree/main/ros1/transforms) . And as\nalways, feel free to reach out to us directly in our [ Slack community\n](/slack) to request a topic for the next tutorial!\n\n[ Share on Twitter\n](https://twitter.com/intent/tweet?text=Using%20ROS%201%20Transforms%20to%20Calculate%20Object%20Positions%3A%20https%3A%2F%2Ffoxglove.dev%2Fblog%2Fusing-\nros1-transforms-to-calculate-object-positions%20%40foxglove) [ Share on\nLinkedIn\n](http://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Ffoxglove.dev%2Fblog%2Fusing-\nros1-transforms-to-calculate-object-positions)\n\n* * *\n\n###  Read more:\n\n[ ![Announcing the Team Trial for New Foxglove Users](/images/blog/announcing-\nthe-team-trial-for-new-foxglove-users/hero.webp) ](/blog/announcing-the-team-\ntrial-for-new-foxglove-users)\n\narticle\n\ndata management\n\n[ Announcing the Team Trial for New Foxglove Users  ](/blog/announcing-the-\nteam-trial-for-new-foxglove-users)\n\nExperience Foxglove\u2019s data storage and collaboration features for 14 days\n\n![Esther Weon](/images/blog/authors/estherweon.webp) Esther Weon  Esther Weon\n\nMarch 21, 2023  \u00b7  1 min  read\n\n[ ![Announcing EU Hosting for Foxglove Data](/images/blog/announcing-eu-\nhosting-for-foxglove-data/hero.jpeg) ](/blog/announcing-eu-hosting-for-\nfoxglove-data)\n\narticle\n\ndata management\n\n[ Announcing EU Hosting for Foxglove Data  ](/blog/announcing-eu-hosting-for-\nfoxglove-data)\n\nConfigure your storage region for Foxglove-hosted data\n\n![Esther Weon](/images/blog/authors/estherweon.webp) Esther Weon  Esther Weon\n\nMarch 16, 2023  \u00b7  3 min  read\n\n[ All blog posts ](/blog)\n\nGet blog posts sent directly to your inbox.\n\nEmail address\n\nSubscribe\n\n##  Ready to try Foxglove?\n\n[ Get started for free ](https://app.foxglove.dev/signup)\n\n###  Product\n\n  * [ Foxglove ](/product)\n  * [ MCAP ](/mcap)\n\n* * *\n\n  * [ Download ](/download)\n  * [ Documentation ](/docs)\n  * [ Tutorials ](/tutorials)\n  * [ ROS visualization ](/ros)\n  * [ Rosbridge ](/rosbridge)\n  * [ URDF visualization ](/urdf)\n\n###  Get in touch\n\n  * [ Community ](/community)\n  * [ Newsletter ](/newsletter)\n  * [ Schedule a demo ](/demo)\n  * [ Contact us ](/contact)\n\n* * *\n\n  * [ Discussions ](https://github.com/orgs/foxglove/discussions)\n  * [ Slack ](/slack)\n  * [ Twitter ](https://twitter.com/foxglove)\n\n###  Company\n\n  * [ About ](/about)\n  * [ Blog ](/blog)\n  * [ Careers ](/careers)\n  * [ Customers ](/customers)\n  * [ Media ](/media)\n\n* * *\n\n  * [ Security ](/security)\n  * [ Privacy ](/legal/privacy)\n  * [ Terms of Service ](/legal/terms)\n\n###  Developers\n\n  * [ API ](/docs/data-platform/api/introduction)\n  * [ Status ](https://foxglovestatus.com/)\n  * [ GitHub ](https://github.com/foxglove)\n\n###  Subscribe to our newsletter\n\nCatch our latest news and features, sent directly to your inbox.\n\nEmail address\n\nSubscribe\n\n[ Twitter  ](https://twitter.com/foxglove) [ GitHub\n](https://github.com/foxglove)\n\nMade with  by [ Foxglove ](/about)\n\n![](https://px.ads.linkedin.com/collect/?pid=6049740&fmt=gif)\n\n"
  },
  {
    "id": "takeoff_rotation/07afhch6pdf.txt",
    "content": "Airplane Flying Handbook (FAA-H-8083-3C)\nChapter 6: Takeoffs and Departure Climbs\nIntroduction\nAbout twenty percent of all yearly general aviation (GA) accidents occur during takeoff and departure climbs, and more than half of\nthose accidents are the result of some sort of failure of the pilot. A significant number of takeoff accidents are the result of loss of\ncontrol of the airplane. When compared to the entire profile of a normal flight, this phase of a flight is relatively short, but the pilot\nworkload is intense. This chapter discusses takeoffs and departure climbs in airplanes under normal conditions and under conditions\nthat require maximum performance.\nThough it may seem relatively simple, the takeoff often presents the most hazards of any part of a flight. The importance of thorough\nknowledge of procedures and techniques coupled with proficiency in performance cannot be overemphasized.\nThe discussion in this chapter is centered on airplanes with tricycle landing gear (nose-wheel). Procedures for conventional gear\nairplanes (tail-wheel) are discussed in Chapter 14: Transition to Tailwheel Airplanes. The manufacturer\u2019s recommended procedures\npertaining to airplane configuration, airspeeds, and other information relevant to takeoffs and departure climbs in a specific make and\nmodel airplane are contained in the Federal Aviation Administration (FAA)-approved Airplane Flight Manual and/or Pilot\u2019s\nOperating Handbook (AFM/POH) for that airplane. If any of the information in this chapter differs from the airplane manufacturer\u2019s\nrecommendations as contained in the AFM/POH, the airplane manufacturer\u2019s recommendations take precedence.\nTerms and Definitions\nAlthough the takeoff and climb is one continuous maneuver, it will be divided into three separate steps for purposes of explanation:\n1.) takeoff roll; 2.) lift-off; and 3.) initial climb after becoming airborne. Refer to Figure 6-1 and the detail below.\n\u2981 Takeoff roll (ground roll) is the portion of the takeoff procedure during which the airplane is accelerated\nfrom a standstill to an airspeed that provides sufficient lift for it to become airborne.\n\u2981 Lift-off is when the wings are lifting the weight of the airplane off the surface. In most airplanes, this is the\nresult of the pilot rotating the nose up to increase the angle of attack (AOA).\n\u2981 The initial climb begins when the airplane leaves the surface and a climb pitch attitude has been established.\nNormally, it is considered complete when the airplane has reached a safe maneuvering altitude or an en\nroute climb has been established.\nPrior to Takeoff\nBefore going to the airplane, the pilot should check the POH/AFM performance charts to determine the predicted performance and\ndecide if the airplane is capable of a safe takeoff and climb for the conditions and location. [Figure 6-2] High density altitudes reduce\nengine and propeller performance, increase takeoff rolls, and decrease climb performance. A more detailed discussion of density\naltitude and how it affects airplane performance can be found in the Pilot\u2019s Handbook of Aeronautical Knowledge (FAA-H-8083-25,\nas revised).\nAll run-up and pre-takeoff checklist items should be completed before taxiing onto the runway or takeoff area. As a minimum before\nevery takeoff, all engine instruments should be checked for proper and usual indications, and all controls should be checked for full,\nfree, and correct movement. The pilot should also consider available options if an engine failure occurs after takeoff. These options\ninclude the preferred direction for any emergency turns to landing sites based on the departure path, altitude, wind conditions, and\nterrain. In addition, the pilot should make certain that the approach and takeoff paths are clear of other aircraft. At nontowered\nairports, pilots should announce their intentions on the common traffic advisory frequency (CTAF) assigned to that airport. When\noperating from a towered airport, pilots need to contact the tower operator and receive a takeoff clearance before taxiing onto the\nactive runway.\n\n\n\nTaking off immediately behind another aircraft, particularly a large and heavy transport airplane, creates the risk of a wake turbulence\nencounter, and a possible loss of control. However, if an immediate takeoff behind a large heavy aircraft is necessary, the pilot should\nplan to minimize the chances of flying through an aircraft\u2019s wake turbulence by avoiding the other aircraft\u2019s flightpath or rotating\nprior to the point at which the preceding aircraft rotated. While taxiing onto the runway, the pilot should select ground reference\npoints that are aligned with the runway direction to aid in maintaining directional control and alignment with the runway center line\nduring the climb out. These may be runway centerline markings, runway lighting, distant trees, towers, buildings, or mountain peaks.\n6-1\nFigure 6-1. Takeoff and climb.\nFigure 6-2. Performance chart examples.\n6-2\nNormal Takeoff\nA normal takeoff is one in which the airplane is headed into the wind; there are times that a takeoff with a tail wind is necessary.\nHowever, the pilot should consult the POH/AFM to ensure the aircraft is approved for a takeoff with a tail wind and that there is\nsufficient performance and runway length for the takeoff. The pilot should also ensure that the takeoff surfaces are firm and of\nsufficient length to permit the airplane to gradually accelerate to normal lift-off and climb-out speed, and there are no obstructions\nalong the takeoff path.\nThere are two reasons for making a takeoff as nearly into the wind as possible. First, since the airplane depends on airspeed, a\nheadwind provides some of that airspeed even before the airplane begins to accelerate into the wind. Second, a headwind decreases\nthe ground speed necessary to achieve flying speed. Slower ground speeds yield shorter ground roll distances and allow use of shorter\nrunways while reducing wear and stress on the landing gear.\nTakeoff Roll\nFor takeoff, the pilot uses the rudder pedals in most general aviation airplanes to steer the airplane\u2019s nose-wheel onto the runway\ncenterline to align the airplane and nose-wheel with the runway. After releasing the brakes, the pilot should advance the throttle\nsmoothly and continuously to takeoff power. An abrupt application of power may cause the airplane to yaw sharply to the left because\nof the torque effects of the engine and propeller. This is most apparent in high horsepower engines. As the airplane starts to roll\nforward, assure both feet are on the rudder pedals so that the toes or balls of the feet are on the rudder portions, not on the brake.\nCheck the engine instruments for indications of a malfunction during the takeoff roll.\nIn nose-wheel type airplanes, pressures on the elevator control are not necessary beyond those needed to steady it. Applying\nunnecessary pressure only aggravates the takeoff and prevents the pilot from recognizing when elevator control pressure is actually\nneeded to establish the takeoff attitude.\nAs the airplane gains speed, the elevator control tends to assume a neutral position if the airplane is correctly trimmed. At the same\ntime, the rudder pedals are used to keep the nose of the airplane pointed down the runway and parallel to the centerline. The effects of\nengine torque and P-factor at the initial speeds tend to pull the nose to the left. The pilot should use whatever rudder pressure is\nneeded to correct for these effects or winds. The pilot should use aileron controls into any crosswind to keep the airplane centered on\nthe runway centerline. The pilot should avoid using the brakes for steering purposes as this will slow acceleration, lengthen the\ntakeoff distance, and possibly result in severe swerving.\nAs the speed of the takeoff roll increases, more and more pressure will be felt on the flight controls, particularly the elevators and\nrudder. If the tail surfaces are affected by the propeller slipstream, they become effective first. As the speed continues to increase, all\nof the flight controls will gradually become effective enough to maneuver the airplane about its three axes. At this point, the airplane\nis being flown more than it is being taxied. As this occurs, progressively smaller rudder deflections are needed to maintain direction.\n\n\n\nThe feel of resistance to the movement of the controls and the airplane\u2019s reaction to such movements are the only real indicators of\nthe degree of control attained. This feel of resistance is not a measure of the airplane\u2019s speed, but rather of its controllability. To\ndetermine the degree of controllability, the pilot should be conscious of the reaction of the airplane to the control pressures and\nimmediately adjust the pressures as needed to control the airplane. The pilot should wait for the reaction of the airplane to the applied\ncontrol pressures and attempt to sense the control resistance to pressure rather than attempt to control the airplane by movement of the\ncontrols.\nA student pilot does not normally have a full appreciation of the variations of control pressures with the speed of the airplane. The\nstudent may tend to move the controls through wide ranges seeking the pressures that are familiar and expected and, as a\nconsequence, over-control the airplane.\nThe situation may be aggravated by the sluggish reaction of the airplane to these movements. The flight instructor should help the\nstudent learn proper response to control actions and airplane reactions. The instructor should always stress using the proper outside\nreference to judge airplane motion. For takeoff, the student should always be looking far down the runway at two points aligned with\nthe runway. The flight instructor should have the student pilot follow through lightly on the controls, feel for resistance, and point out\nthe outside references that provide the clues for how much control movement is needed and how the pressure and response changes as\nairspeed increases. With practice, the student pilot should become familiar with the airplane\u2019s response to acceleration up to lift-off\nspeed, corrective control movements needed, and the outside references necessary to accomplish the takeoff maneuver.\n6-3\nLift-Off\nSince a good takeoff depends on the proper takeoff attitude, it is important to know how this attitude appears and how it is attained.\nThe ideal takeoff attitude requires only minimum pitch adjustments shortly after the airplane lifts off to attain the speed for the best\nrate of climb (VY). [Figure 6-3] The pitch attitude necessary for the airplane to accelerate to VY speed should be demonstrated by the\ninstructor and memorized by the student. Flight instructors should be aware that initially, the student pilot may have a tendency to\nhold excessive back-elevator pressure just after lift-off, resulting in an abrupt pitch-up.\nFigure 6-3. Initial roll and takeoff attitude.\nEach type of airplane has a best pitch attitude for normal lift-off; however, varying conditions may make a difference in the required\ntakeoff technique. A rough field, a smooth field, a hard surface runway, or a short or soft, muddy field all call for a slightly different\ntechnique, as will smooth air in contrast to a strong, gusty wind. The different techniques for those other-than-normal conditions are\ndiscussed later in this chapter.\n6-4\nWhen all the flight controls become effective during the takeoff roll in a nose-wheel type airplane, the pilot should gradually apply\nback-elevator pressure to raise the nose-wheel slightly off the runway, thus establishing the takeoff or lift-off attitude. This is the\n\u201crotation\u201d for lift-off and climb. As the airplane lifts off the surface, the pitch attitude to hold the climb airspeed should be held with\nelevator control and trimmed to maintain that pitch attitude without excessive control pressures. The wings should be leveled after\nlift-off and the rudder used to ensure coordinated flight.\nAfter rotation, the slightly nose-high pitch attitude should be held until the airplane lifts off. Rudder control should be used to\nmaintain the track of the airplane along the runway centerline until any required crab angle in level flight is established. Forcing it\ninto the air by applying excessive back-elevator pressure would only result in an excessively high-pitch attitude and may delay the\ntakeoff. As discussed earlier, excessive and rapid changes in pitch attitude result in proportionate changes in the effects of torque,\nthus making the airplane more difficult to control.\nAlthough the airplane can be forced into the air, this is considered an unsafe practice and should be avoided under normal\n\n\n\ncircumstances. If the airplane is forced to leave the ground by using too much back-elevator pressure before adequate flying speed is\nattained, the wing\u2019s AOA may become excessive, causing the airplane to settle back to the runway or even to stall. On the other hand,\nif sufficient back-elevator pressure is not held to maintain the correct takeoff attitude after becoming airborne, or the nose is allowed\nto lower excessively, the airplane may also settle back to the runway. This would occur because the AOA is decreased and lift\ndiminished to the degree where it will not support the airplane. It is important, then, to hold the correct attitude constant after rotation\nor lift-off.\nAs the airplane leaves the ground, the pilot should keep the wings in a level attitude and hold the proper pitch attitude. Outside visual\nscans should be intensified at this critical point to attain/maintain proper airplane pitch and bank attitude. Due to the minimum\nairspeed, the flight controls are not as responsive, requiring more control movement to achieve an expected response. A novice pilot\noften has a tendency to fixate on the airplane\u2019s pitch attitude and/or the airspeed indicator and neglect bank control of the airplane.\nTorque from the engine tends to impart a rolling force that is most evident as the landing gear is leaving the surface.\nDuring takeoffs in a strong, gusty wind, it is advisable that an extra margin of speed be obtained before the airplane is allowed to\nleave the ground. A takeoff at the normal takeoff speed may result in a lack of positive control, or a stall, when the airplane\nencounters a sudden lull in strong, gusty wind, or other turbulent air currents. In this case, the pilot should allow the airplane to stay\non the ground longer to attain more speed, then make a smooth, positive rotation to leave the ground.\nInitial Climb\nUpon liftoff, the airplane should be flying at approximately the pitch attitude that allows it to accelerate to VY. This is the speed at\nwhich the airplane gains the most altitude in the shortest period of time.\nIf the airplane has been properly trimmed for takeoff, some back-elevator pressure may be required to hold this attitude until the\nproper climb speed is established. Relaxation of any back-elevator pressure before this time may result in the airplane settling, even to\nthe extent that it contacts the runway.\nThe airplane\u2019s speed will increase rapidly after it becomes airborne. Once a positive rate of climb is established, the pilot should\nretract the flaps and landing gear (if equipped). It is recommended that takeoff power be maintained until reaching an altitude of at\nleast 500 feet above the surrounding terrain or obstacles. The combination of VY and takeoff power assures the maximum altitude\ngained in a minimum amount of time. This gives the pilot more altitude from which the airplane can be safely maneuvered in case of\nan engine failure or other emergency. The pilot should also consider flying at a lower pitch for cruise climb since flying at VY\nrequires much quicker pilot response in the event of a powerplant failure to preclude a stall.\nSince the power on the initial climb is set at the takeoff power setting, the airspeed should be controlled by making slight pitch\nadjustments using the elevators. However, the pilot should not fixate on the airspeed indicator when making these pitch changes, but\nshould continue to scan outside to adjust the airplane\u2019s attitude in relation to the horizon. In accordance with the principles of attitude\nflying, the pilot should first make the necessary pitch change with reference to the natural horizon, hold the new attitude momentarily,\nand then glance at the airspeed indicator to verify if the new attitude is correct. Due to inertia, the airplane will not accelerate or\ndecelerate immediately as the pitch is changed. It takes a little time for the airspeed to change. If the pitch attitude has been over or\nunder corrected, the airspeed indicator will show a speed that is higher or lower than that desired. When this occurs, the crosschecking and appropriate pitch-changing process needs to be repeated until the desired climbing attitude is established. Pilots should\nremember the climb pitch will be lower when the airplane is heavily loaded, or power is limited by density altitude.\nWhen the correct pitch attitude has been attained, the pilot should hold it constant while cross-checking it against the horizon and\nother outside visual references. The airspeed indicator should be used only as a check to determine if the attitude is correct.\nAfter the recommended climb airspeed has been established and a safe maneuvering altitude has been reached, the pilot should adjust\nthe power to the recommended climb setting and trim the airplane to relieve the control pressures. This makes it easier to hold a\nconstant attitude and airspeed.\n\n\n\n6-5\nDuring initial climb, it is important that the takeoff path remain aligned with the runway to avoid drifting into obstructions or into the\npath of another aircraft that may be taking off from a parallel runway. A flight instructor should help the student identify two points\ninline ahead of the runway to use as a tracking reference. As long as those two points are inline, the airplane is remaining on the\ndesired track. Proper scanning techniques are essential to a safe takeoff and climb, not only for maintaining attitude and direction, but\nalso for avoiding collisions near the airport.\nWhen the student pilot nears the solo stage of flight training, it should be explained that the airplane\u2019s takeoff performance will be\nmuch different when the instructor is not in the airplane. Due to decreased load, the airplane will become airborne earlier and climb\nmore rapidly. The pitch attitude that the student has learned to associate with initial climb may also differ due to decreased weight,\nand the flight controls may seem more sensitive. If the situation is unexpected, it may result in increased anxiety that may remain until\nafter the landing. Frequently, the existence of this anxiety and the uncertainty that develops due to the perception of an \u201cabnormal\u201d\ntakeoff results in poor performance on the subsequent landing.\nCommon Errors\nCommon errors in the performance of normal takeoffs and departure climbs are:\n\u2981 Failure to review AFM/POH and performance charts prior to takeoff.\n\u2981 Failure to adequately clear the area prior to taxiing into position on the active runway.\n\u2981 Abrupt use of the throttle.\n\u2981 Failure to check engine instruments for signs of malfunction after applying takeoff power.\n\u2981 Failure to anticipate the airplane\u2019s left turning tendency on initial acceleration.\n\u2981 Overcorrecting for left turning tendency.\n\u2981 Relying solely on the airspeed indicator rather than developing an understanding of visual references and\ntracking clues of airplane airspeed and controllability during acceleration and lift-off.\n\u2981 Failure to attain proper lift-off attitude.\n\u2981 Inadequate compensation for torque/P-factor during initial climb resulting in a sideslip.\n\u2981 Over-control of elevators during initial climb-out and lack of elevator trimming.\n\u2981 Limiting scan to areas directly ahead of the airplane (pitch attitude and direction), causing a wing\n(usually the left) to drop immediately after lift-off.\n\u2981 Failure to attain/maintain best rate-of-climb airspeed (VY) or desired climb airspeed.\n\u2981 Failure to employ the principles of attitude flying during climb-out, resulting in \u201cchasing\u201d the airspeed\nindicator.\nCrosswind Takeoff\nWhile it is usually preferable to take off directly into the wind whenever possible or practical, there are many instances when\ncircumstances or judgment indicate otherwise. Therefore, the pilot must be familiar with the principles and techniques involved in\ncrosswind takeoffs, as well as those for normal takeoffs. A crosswind affects the airplane during takeoff much as it does during\ntaxiing. With this in mind, the pilot should be aware that the technique used for crosswind correction during takeoffs closely parallels\nthe crosswind correction techniques used for taxiing.\nTakeoff Roll\nThe technique used during the initial takeoff roll in a crosswind is generally the same as the technique used in a normal takeoff roll,\nexcept that the pilot needs to apply aileron pressure into the crosswind. This raises the aileron on the upwind wing, imposes a\ndownward force on that wing to counteract the lifting force of the crosswind, and thus prevents the wing from rising. The pilot should\n\n\n\nremember that since the ailerons and rudder are deflected, drag will increase; therefore, less initial takeoff performance should be\nexpected until the airplane is wings-level in coordinated flight in the climb.\nWhile taxiing into takeoff position, it is essential that the pilot check the windsock and other wind direction indicators for the\npresence of a crosswind. If a crosswind is present, the pilot should apply full aileron pressure into the wind while beginning the\ntakeoff roll. The pilot should maintain this control position, as the airplane accelerates, and until the ailerons become effective in\nmaneuvering the airplane about its longitudinal axis. As the ailerons become effective, the pilot will feel an increase in pressure on\nthe aileron control.\n6-6\nWhile holding aileron pressure into the wind, the pilot should use the rudder to maintain a straight takeoff path. [Figure 6-4] Since\nthe airplane tends to weathervane into the wind while on the ground, the pilot will typically apply downwind rudder pressure. When\nthe pilot increases power for takeoff, the resulting P-factor causes the airplane to yaw to the left. While this yaw may be sufficient to\ncounteract the airplane\u2019s tendency to weathervane into the wind in a crosswind from the right, it may aggravate this tendency in a\ncrosswind from the left. In any case, the pilot should apply rudder pressure in the appropriate direction to keep the airplane rolling\nstraight down the runway.\nFigure 6-4. Crosswind roll and takeoff climb.\nAs the forward speed of the airplane increases, the pilot should apply sufficient aileron pressure into the crosswind to keep the wings\nlevel. The effect of the crosswind component will not completely vanish; therefore, the pilot needs to maintain some aileron pressure\nthroughout the takeoff roll. If the upwind wing rises, the amount of wing surface exposed to the crosswind will increase, which may\ncause the airplane to lose lateral alignment with the runway centerline and to \"skip.\" [Figure 6-5] The pilot uses rudder pressure to\nkeep the airplane\u2019s longitudinal axis parallel to the runway centerline.\nThis \u201cskipping\u201d is usually indicated by a series of very small bounces caused by the airplane attempting to fly and then settling back\nonto the runway. During these bounces, the crosswind also tends to move the airplane sideways, and these bounces develop into sideskipping. This side-skipping imposes severe side stresses on the landing gear and may result in structural failure.\nDuring a crosswind takeoff roll, it is important that the pilot hold sufficient aileron pressure into the wind not only to keep the upwind\nwing from rising but to hold that wing down so that the airplane sideslips into the wind enough to counteract drift immediately after\nlift-off.\nLift-Off\nAs the nose-wheel raises off of the runway, the pilot should hold aileron pressure into the wind. This may cause the downwind wing\nto rise and the downwind main wheel to lift off the runway first, with the remainder of the takeoff roll being made on that one main\nwheel. This is acceptable and is preferable to side-skipping.\nIf a significant crosswind exists, the pilot should hold the main wheels on the ground slightly longer than in a normal takeoff so that a\nsmooth but very definite lift-off can be made. This allows the airplane to leave the ground under more positive control and helps it\nremain airborne while the pilot establishes the proper amount of wind correction. More importantly, this procedure avoids imposing\nexcessive side-loads on the landing gear and prevents possible damage that would result from the airplane settling back to the runway\nwhile drifting.\n6-7\nAs both main wheels leave the runway, the airplane begins to drift sideways with the wind, as ground friction is no longer a factor in\npreventing lateral movement. To minimize this lateral movement and to keep the upwind wing from rising, the pilot should establish\nand maintain the proper amount of crosswind correction prior to lift-off by applying aileron pressure into the wind. The pilot should\nalso apply rudder pressure, as needed, to prevent weathervaning.\nFigure 6-5. Crosswind effect.\n\n\n\nInitial Climb\nIf a proper crosswind correction is applied, the aircraft will maintain alignment with the runway while accelerating to takeoff speed\nand then maintain that alignment once airborne. As takeoff acceleration occurs, the efficiency of the up-aileron will increase with\naircraft speed causing the upwind wing to produce greater downward force and, as a result, counteract the effect of the crosswind.\nThe yoke, having been initially turned into the wind, can be relaxed to the extent necessary to keep the aircraft aligned with the\nrunway. As the aircraft becomes flyable and airborne, the wing that is upwind will have a tendency to be lower relative the other\nwing, requiring simultaneous rudder input to maintain runway alignment. This will initially cause the aircraft to sideslip. However, as\nthe aircraft establishes its climb, the nose should be turned into the wind to offset the crosswind, wings brought to level, and rudder\ninput adjusted to maintain runway alignment (crabbing). [Figure 6-6] Firm and positive use of the rudder may be required to keep the\nairplane pointed down the runway or parallel to the centerline. Unlike landing, the runway alignment (staying over the runway and its\nextended centerline) is paramount to keeping the aircraft parallel to the centerline. The pilot should then apply rudder pressure firmly\nand aggressively to keep the airplane headed straight down the runway. However, because the force of a crosswind may vary\nmarkedly within a few hundred feet of the ground, the pilot should check the ground track frequently and adjust the wind correction\nangle, as necessary. The remainder of the climb technique is the same used for normal takeoffs and climbs.\n6-8\nFigure 6-6. Crosswind climb flightpath.\n6-9\nThe most common errors made while performing crosswind takeoffs include the following:\n\u2981 Failure to review AFM/POH performance and charts prior to takeoff.\n\u2981 Failure to adequately clear the area prior to taxiing onto the active runway.\n\u2981 Using less than full aileron pressure into the wind initially on the takeoff roll.\n\u2981 Mechanical use of aileron control rather than judging lateral position of airplane on runway from\nvisual clues and applying sufficient aileron to keep airplane centered laterally on runway.\n\u2981 Side-skipping due to improper aileron application.\n\u2981 Inadequate rudder control to maintain airplane parallel to centerline and pointed straight ahead in\nalignment with visual references.\n\u2981 Excessive aileron input in the latter stage of the takeoff roll resulting in a steep bank into the wind at\nlift-off.\n\u2981 Inadequate drift correction after lift-off.\nGround Effect on Takeoff\nGround effect is a condition of improved performance encountered when the airplane is operating very close to the ground. Ground\neffect can be detected and normally occurs up to an altitude equal to one wingspan above the surface. [Figure 6-7] Ground effect is\nmost significant when the airplane maintains a constant attitude at low airspeed at low altitude (for example, during takeoff when the\nairplane lifts off and accelerates to climb speed, and during the landing flare before touchdown).\nFigure 6-7. Takeoff in ground effect area.\nWhen the wing is under the influence of ground effect, there is a reduction in upwash, downwash, and wingtip vortices. As a result of\nthe reduced wingtip vortices, induced drag is reduced. When the wing is at a height equal to 1/4 the span, the reduction in induced\ndrag is about 25 percent. When the wing is at a height equal to 1/10 the span, the reduction in induced drag is about 50 percent. At\nhigh speeds where parasite drag dominates, induced drag is a small part of the total drag. Consequently, ground effect is a greater\nconcern during takeoff and landing.\n\n\n\nAt takeoff, the takeoff roll, lift-off, and the beginning of the initial climb are accomplished within the ground effect area. The ground\neffect causes local increases in static pressure, which cause the airspeed indicator and altimeter to indicate slightly lower values than\nthey should and usually cause the vertical speed indicator to indicate a descent. As the airplane lifts off and climbs out of the ground\neffect area, the following occurs:\n\u2981 The airplane requires an increase in AOA to maintain lift coefficient.\n\u2981 The airplane experiences an increase in induced drag and thrust required.\n\u2981 The airplane experiences a pitch-up tendency and requires less elevator travel because of an increase\nin downwash at the horizontal tail.\n\u2981 The airplane experiences a reduction in static source pressure and a corresponding increase in\nindicated airspeed.\nVX is the speed at which the airplane achieves the greatest gain in altitude for a given distance over the ground. It is usually slightly\nless than VY, which is the greatest gain in altitude per unit of time. The specific speeds to be used for a given airplane are stated in the\nFAA-approved AFM/POH. The pilot should be aware that, in some airplanes, a deviation of 5 knots from the recommended speed\nmay result in a significant reduction in climb performance; therefore, the pilot should maintain precise control of the airspeed to\nensure the maneuver is executed safely and successfully.\n6-10\nDue to the reduced drag in ground effect, the airplane may seem to be able to take off below the recommended airspeed. However, as\nthe airplane climbs out of ground effect below the recommended climb speed, initial climb performance will be much less than at VY\nor even VX. Under conditions of high density altitude, high temperature, and/or maximum gross weight, the airplane may be able to\nlift off but will be unable to climb out of ground effect. Consequently, the airplane may not be able to clear obstructions. Lift-off\nbefore attaining recommended flight airspeed incurs more drag, which requires more power to overcome. Since the initial takeoff and\nclimb is based on maximum power, reducing drag is the only option. To reduce drag, pitch should be reduced which means losing\naltitude. Pilots should remember that many airplanes cannot safely takeoff at maximum gross weight at certain altitudes and\ntemperatures, due to lack of performance. Therefore, under marginal conditions, it is important that the airplane takes off at the speed\nrecommended for adequate initial climb performance.\nGround effect is important to normal flight operations. If the runway is long enough or if no obstacles exist, ground effect can be used\nto the pilot\u2019s advantage by using the reduced drag to improve initial acceleration.\nWhen taking off from an unsatisfactory surface, the pilot should apply as much weight to the wings as possible during the ground run\nand lift-off, using ground effect as an aid, prior to attaining true flying speed. The pilot should reduce AOA to attain normal airspeed\nbefore attempting to fly out of the ground effect areas.\nShort-Field Takeoff and Maximum Performance Climb\nWhen performing takeoffs and climbs from fields where the takeoff area is short or the available takeoff area is restricted by\nobstructions, the pilot should operate the airplane at the maximum limit of its takeoff performance capabilities. To depart from such\nan area safely, the pilot needs to exercise positive and precise control of airplane attitude and airspeed, so that takeoff and climb\nperformance result in the shortest ground roll and the steepest angle of climb. [Figure 6-8] The pilot should consult and follow the\nperformance section of the AFM/POH to obtain the power setting, flap setting, airspeed, and procedures prescribed by the airplane\u2019s\nmanufacturer.\nFigure 6-8. Short-field takeoff.\nThe pilot should have adequate knowledge in the use and effectiveness of the best angle-of-climb speed (VX) and the best rate-ofclimb speed (VY) for the specific make and model of airplane being flown in order to safely accomplish a takeoff at maximum\nperformance.\n\n\n\nTakeoff Roll\nTaking off from a short field requires the takeoff to be started from the very beginning of the takeoff area. At this point, the airplane is\naligned with the intended takeoff path. If the airplane manufacturer recommends the use of flaps, they are extended the proper amount\nbefore beginning the takeoff roll. This allows the pilot to devote full attention to the proper technique and the airplane\u2019s performance\nthroughout the takeoff.\nThe pilot should apply takeoff power smoothly and continuously, without hesitation, to accelerate the airplane as rapidly as possible.\nSome pilots prefer to hold the brakes until the maximum obtainable engine revolutions per minute (rpm) are achieved before allowing\nthe airplane to begin its takeoff run. However, it has not been established that this procedure results in a shorter takeoff run in all\nlight, single-engine airplanes. The airplane is allowed to roll with its full weight on the main wheels and accelerate to the lift-off\nspeed. As the takeoff roll progresses, the pilot should adjust the airplane\u2019s pitch attitude and AOA to attain minimum drag and\nmaximum acceleration. In nose-wheel type airplanes, this involves little use of the elevator control since the airplane is already in a\nlow-drag attitude.\n6-11\nLift-Off\nAs VX approaches, the pilot should apply back-elevator pressure until reaching the appropriate VX attitude to ensure a smooth and\nfirm lift-off, or rotation. Since the airplane accelerates more rapidly after lift-off, the pilot should apply additional backelevator pressure to hold a constant airspeed. After becoming airborne, the pilot will maintain a wings-level climb at VX until all\nobstacles have been cleared, or if no obstacles are present, until reaching an altitude of at least 50 feet above the takeoff surface.\nThereafter, the pilot may lower the pitch attitude slightly and continue the climb at VY until reaching a safe maneuvering altitude. The\npilot should always remember that an attempt to pull the airplane off the ground prematurely, or to climb too steeply, may cause\nthe airplane to settle back to the runway or make contact with obstacles. Even if the airplane remains airborne, until the pilot reaches\nVX, the initial climb will remain flat, which diminishes the pilot's ability to successfully perform the climb and/or clear obstacles.\n[Figure 6-9]\nFigure 6-9. Effect of premature lift-off.\nThe objective is to rotate to the appropriate pitch attitude at (or near) VX. The pilot should be aware that some airplanes have a\nnatural tendency to lift off well before reaching VX. In these airplanes, it may be necessary to allow the airplane to lift off in ground\neffect and then reduce pitch attitude to level until the airplane accelerates to VX with the wheels just clear of the runway surface. This\nmethod is preferable to forcing the airplane to remain on the ground with forward elevator-control pressure until VX is attained.\nHolding the airplane on the ground unnecessarily puts excessive pressure on the nose-wheel and may result in \u201cwheel barrowing.\u201d It\nalso hinders both acceleration and overall airplane performance.\nInitial Climb\nOn short-field takeoffs, the landing gear and flaps should remain in takeoff position until the airplane is clear of obstacles (or\nas recommended by the manufacturer) and VY has been established. Until all obstacles have been cleared, the pilot should\nmaintain focus outside the airplane instead of reaching for landing gear or flap controls or looking inside the airplane for any reason.\nWhen the airplane is stabilized at VY, the landing gear (if retractable) and flaps should be retracted. It is usually advisable to raise the\nflaps in increments to avoid sudden loss of lift and settling of the airplane. The pilot should next reduce the power to the normal climb\nsetting or as recommended by the airplane manufacturer.\nCommon errors in the performance of short-field takeoffs and maximum performance climbs are:\n\u2981 Failure to review AFM/POH and performance charts prior to takeoff.\n\u2981 Failure to adequately clear the area.\n\u2981 Failure to utilize all available runway/takeoff area.\n\n\n\n\u2981 Failure to have the airplane properly trimmed prior to takeoff.\n\u2981 Premature lift-off resulting in high drag.\n\u2981 Holding the airplane on the ground unnecessarily with excessive forward-elevator pressure.\n\u2981 Inadequate rotation resulting in excessive speed after lift-off.\n\u2981 Inability to attain/maintain VX.\n\u2981 Fixation on the airspeed indicator during initial climb.\n\u2981 Premature retraction of landing gear and/or wing flaps.\n6-12\nSoft/Rough-Field Takeoff and Climb\nTakeoffs and climbs from soft fields require the use of operational techniques for getting the airplane airborne as quickly as possible\nto eliminate the drag caused by tall grass, soft sand, mud, and snow and may require climbing over an obstacle. The technique makes\njudicious use of ground effect to reduce landing gear drag and requires an understanding of the airplane\u2019s slow speed characteristics\nand responses. These same techniques are also useful on a rough field where the pilot should get the airplane off the ground as soon\nas possible to avoid damaging the landing gear.\nTaking off from a soft surface or through soft surfaces or long, wet grass reduces the airplane\u2019s ability to accelerate during the takeoff\nroll and may prevent the airplane from reaching adequate takeoff speed if the pilot applies normal takeoff techniques. The pilot\nshould be aware that the correct takeoff procedure for soft fields is quite different from the takeoff procedures used for short fields\nwith firm, smooth surfaces. To minimize the hazards associated with takeoffs from soft or rough fields, the pilot should transfer the\nsupport of the airplane\u2019s weight as rapidly as possible from the wheels to the wings as the takeoff roll proceeds by establishing and\nmaintaining a relatively high AOA or nose-high pitch attitude as early as possible. The pilot should lower the wing flaps prior to\nstarting the takeoff (if recommended by the manufacturer) to provide additional lift and to transfer the airplane\u2019s weight from the\nwheels to the wings as early as possible. The pilot should maintain a continuous motion with sufficient power while lining up for the\ntakeoff roll as stopping on a soft surface, such as mud or snow, might bog the airplane down.\nTakeoff Roll\nAs the airplane is aligned with the takeoff path, the pilot should apply takeoff power smoothly and as rapidly as the powerplant can\naccept without faltering. As the airplane accelerates, the pilot should apply enough back-elevator pressure to establish a positive AOA\nand to reduce the weight supported by the nose-wheel.\nWhen the airplane is held at a nose-high attitude throughout the takeoff run, the wings increasingly relieve the wheels of the airplane\u2019s\nweight as speed increases and lift develops, thereby minimizing the drag caused by surface irregularities or adhesion. If this attitude is\naccurately maintained, the airplane virtually flies itself off the ground, becoming airborne but at an airspeed slower than a safe climb\nspeed because of ground effect. [Figure 6-10]\nFigure 6-10. Soft-field takeoff.\nLift-Off\nAfter the airplane becomes airborne, the pilot should gently lower the nose with the wheels clear of the surface to allow the airplane\nto accelerate to a minimum safe climb out speed, Immediately after the airplane becomes airborne and while it accelerates, the pilot\nshould be aware that, while transitioning out of the ground effect area, the airplane will have a tendency to settle back onto\nthe surface, even with full power applied. Therefore, it is essential that the airplane remain in ground effect until at least VX is\nreached. This requires a good understanding of the control pressures, aircraft responses, visual clues, and acceleration\ncharacteristics of that particular airplane.\nInitial Climb\n\n\n\nAfter a positive rate of climb is established, and the airplane has accelerated to VY, the pilot should retract the landing gear and flaps,\nif equipped. If departing from an airstrip with wet snow or slush on the takeoff surface, the gear should not be retracted immediately\nso that any wet snow or slush can be air-dried. In the event an obstacle needs to be cleared after a soft-field takeoff, the pilot should\nperform the climb-out at VX until the obstacle has been cleared. The pilot should then adjust the pitch attitude to VY and retract the\ngear and flaps. The power can then be reduced to the normal climb setting.\nCommon errors in the performance of soft/rough field takeoff and climbs are:\n6-13\n\u2981 Failure to review AFM/POH and performance charts prior to takeoff.\n\u2981 Failure to adequately clear the area.\n\u2981 Insufficient back-elevator pressure during initial takeoff roll resulting in inadequate AOA.\n\u2981 Failure to cross-check engine instruments for indications of proper operation after applying power.\n\u2981 Poor directional control.\n\u2981 Climbing too high after lift-off and not levelng off low enough to maintain ground effect attitude.\n\u2981 Abrupt and/or excessive elevator control while attempting to level off and accelerate after liftoff.\n\u2981 Allowing the airplane to \"mush\" or settle resulting in an inadvertant touchdown after lift-off.\n\u2981 Attempting to climb our of ground effect area before attaining sufficient climb speed.\n\u2981 Failure to anticipate an increase in pitch attitude as the airplane climbs our of ground effect.\nRejected Takeoff/Engine Failure\nEmergency or abnormal situations can occur during a takeoff that require a pilot to reject the takeoff while still on the runway.\nCircumstances such as a malfunctioning powerplant, inadequate acceleration, runway incursion, or air traffic conflict may be reasons\nfor a rejected takeoff.\nPrior to takeoff, the pilot should identify a point along the runway at which the airplane should be airborne. If that point is reached\nand the airplane is not airborne, immediate action should be taken to discontinue the takeoff. When properly planned and executed,\nthe airplane can be stopped on the remaining runway without using extraordinary measures, such as excessive braking that may result\nin loss of directional control, airplane damage, and/or personal injury. The POH/AFM ground roll distances for take-off and landing\nadded together provide a good estimate of the total runway needed to accelerate and then stop.\nIn the event a takeoff is rejected, the power is reduced to idle and maximum braking applied while maintaining directional control. If\nit is necessary to shut down the engine due to a fire, the mixture control should be brought to the idle cutoff position and the magnetos\nturned off. In all cases, the manufacturer\u2019s emergency procedure should be followed.\nUrgency characterizes all power loss or engine failure occurrences after lift-off. In most instances, the pilot has only a few seconds\nafter an engine failure to decide what course of action to take and to execute it.\nIn the event of an engine failure on initial climb-out, the pilot\u2019s first responsibility is to maintain aircraft control. At a climb pitch\nattitude without power, the airplane is at or near a stalling AOA. At the same time, the pilot may still be holding right rudder. The\npilot should immediately lower the nose to prevent a stall while moving the rudder to ensure coordinated flight. The pilot should\nestablish a controlled glide toward a plausible landing area, preferably straight ahead. Attempting to turn back to the takeoff runway\nshould not be attempted unless the pilot previously trained for an emergency turn-back and sufficient altitude exists.\nNoise Abatement\nAircraft noise problems are a major concern at many airports throughout the country. Many local communities have pressured\nairports into developing specific operational procedures that help limit aircraft noise while operating over nearby areas. As a result,\nnoise abatement procedures have been developed for many of these airports that include standardized profiles and procedures to\n\n\n\nachieve these lower noise goals.\nAirports that have noise abatement procedures provide information to pilots, operators, air carriers, air traffic facilities, and other\nspecial groups that are applicable to their airport. These procedures are available to the aviation community by various means. Most\nof this information comes from the Chart Supplements, local and regional publications, printed handouts, operator bulletin boards,\nsafety briefings, and local air traffic facilities.\nAt airports that use noise abatement procedures, reminder signs may be installed at the taxiway hold positions for applicable runways\nto remind pilots to use and comply with noise abatement procedures on departure. Pilots who are unfamiliar with these procedures\nshould ask the tower or air traffic facility for the recommended procedures. In any case, pilots should be considerate of the\nsurrounding community while operating their airplane to and from such an airport. This includes operating as quietly, and safely as\npossible.\nChapter Summary\nThe takeoff and initial climb are relatively short phases required for every flight and are often taken for granted, yet 1 out of 5\naccidents occur during this phase and half the mishaps are the result of pilot error. Becoming proficient in and applying the\ntechniques and principles discussed in this chapter help pilots reduce their susceptibility to becoming a mishap statistic.\n6-14\n\n\n"
  },
  {
    "id": "camera_lidar/howdoeslidarcompares.txt",
    "content": "[ ](/)\n\n[ Insights  ](/insights)\n\n![Graphical image of Lidar, camera, and Radar](https://www-\nassets.outsight.ai/ghost/2023/08/Comparison-of-Devices-Cover.png)\n\n#  An in-depth comparison of LiDAR, Cameras, and Radars' technology\n\nThis article explores the capabilities and limitations of each type of sensor,\nto provide a clear understanding of why LiDAR has emerged as a strong\ncontender in computer vision tech race.\n\n![](https://www-assets.outsight.ai/ghost/2023/01/Kevin-Vincent---Black---\nWhite.png)\n\nJul 31, 2023\n\nKevin Vincent\n\n[ ](mailto:?subject=An%20in-\ndepth%20comparison%20of%20LiDAR%2C%20Cameras%2C%20and%20Radars'%20technology&body=https%3A%2F%2Fwww.outsight.ai%2Finsights%2Fhow-\ndoes-lidar-compares-to-cameras-and-radars)\n\nThis article delves into **the technology aspects** and differences of these\nsensors in general, not for a specific market segment like Automotive _(as\nexplained[ here ](/insights/63-of-2027-lidar-applications-will-be-outside-\nautomotive) , most applications of LiDAR are not in this field). _\n\nIf you're seeking a concise overview specifically for **People Counting\napplications** , download our comparative guide [ here ](https://share-\neu1.hsforms.com/1uwwxPTjfTpaVpiSifU7chQf7e7l) .\n\n##  Unique Perspectives: How Diverse Sensors See the World\n\nBefore delving into the relative strengths and weaknesses of these\ntechnologies, let's first provide a brief overview of how cameras, radars, and\nLiDAR systems operate and perceive the world around them.\n\n##  Active vs. Passive Sensors\n\nGenerally speaking, sensors are devices that measure physical properties and\ntransform them into signals suitable for processing, displaying, or storing.\n\nRadar and LiDAR are **Active sensors** , different from Cameras, that are\n**Passive** .\n\nActive sensors emit energy _(e.g. Radio Waves or Laser light)_ and measure the\nreflected or scattered signal, while passive sensors detect the natural\nradiation or emission from the target or the environment _(e.g. Sunlight or\nartificial light for Cameras)_ .\n\n![GIF demonstrating how lidar works by sending laser pulses to an object and\nmeasuring the distance when the pulses are reflected back](https://www-\nassets.outsight.ai/ghost/2023/08/Laser-pulses-1.gif)\n\nEach sensing modality has its advantages and inconveniences.\n\n  * As active sensors generate their own signals, external lighting conditions do not affect them. **Both Radar and LiDAR function perfectly in total darkness and in direct sunlight** , which is not the case for Cameras. \n\n####  Click here to see an example of why this is important\n\nThe Insurance Institute for Highway Safety (\u201cIIHS\u201d) found that in darkness\nconditions camera- and radar-based Pedestrian Automatic Emergency Braking\nsystems fail in every instance to detect pedestrians.  [1]\n\nAdditionally, the Governor\u2019s Highway Safety Association (\u201cGHSA\u201d) of the USA\nfound in an evaluation of roadway fatalities in 2020, that 75% of pedestrian\nfatalities occur at night.  [2]\n\n_ [1]  Jessica B. Cicchino, Insurance Institute for Highway Safety, Effects of\nAutomatic Emergency Braking Systems on Pedestrian Crash Risk 20 (2022). _\n\n_ [2]  Governor\u2019s Highway Safety Association, Pedestrian Traffic Fatalities by\nState: 2020 Preliminary Data 16 (2021). _\n\nBeyond night vision, the impact of external lighting on cameras has far-\nreaching consequences. For instance, Computer Vision algorithms may fail in\nareas with shadows caused by objects (moving or static _e.g. trees or\nbuildings_ ) and even in indoor settings when lighting conditions change\n_(e.g., a door opening adding more light to the scene)._\n\n  * **Weather conditions can significantly affect passive sensors** since their sensing doesn't directly interact with physical phenomena like rain or fog. Instead, they can only work with the resulting image, making them more susceptible to weather-related limitations. However, active sensors can also be affected by adverse conditions, depending on their wavelength. \n\n![Image of a rainy day highlighting lidar's capability to function is multiple\nweather scenarios\n](https://images.unsplash.com/photo-1558409057-bbe679023136?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDJ8fHJhaW5pbmd8ZW58MHx8fHwxNjkwODg4NTI5fDA&ixlib=rb-4.0.3&q=80&w=2000)\n\n  * **Passive sensors are typically more energy-efficient** , whereas active sensors allocate a significant portion of their energy budget to emit laser light or radar waves. The same principle applies to their size and weight. \n  * **Passive sensors like Cameras are highly stealthy and difficult to detect** . On the contrary, active sensors like Lidar or Radar emit signals that can be detected by other sensors, making them more conspicuous. This aspect holds paramount importance in Defense applications. \n  * Similarly, **Active sensors can encounter signal interference** , known as cross-talking. Nevertheless, with the ongoing advancement of technology, this issue is progressively becoming less of a concern for LiDAR. \n\nHowever, the most crucial disparities among these sensing modalities lie in\ntwo key aspects that warrant further exploration:\n\n1) the inherently **different types of perception** they provide, and 2) the\npotential **privacy concerns** they may give rise to or help evade.\n\n##  Perceiving Various Dimensions of the World\n\nEach type of sensor operates in distinct sections of the electromagnetic\nspectrum, utilising signals with varying wavelengths.\n\n![Graphic table showing the difference between cameras, lidar, and\nradar](https://www-assets.outsight.ai/ghost/2023/08/Camera-vs-Lidar-vs-\nRadar.png)\n\n**Cameras capture colours in two dimensions** , lacking any notion of depth.\nConsequently, a large object positioned far away from the device can have the\nsame number of pixels as a small object situated close to the camera.\n\n![Image showing cameras lack of depth ](https://www-\nassets.outsight.ai/ghost/2023/08/optical-illusions-of-camera.jpg)\n\nThis depth perception is not required in many simple Computer Vision tasks,\nsuch as classifying objects, where Cameras excel:\n\n![Image of camera's ability classifying objects](https://www-\nassets.outsight.ai/ghost/2023/08/Classification-using-Camera-1.png)\n\nIndeed, the lack of depth perception in Computer Vision software can pose\nchallenges in tasks that require precise detection of object position, size,\nor movement.\n\nThis capability is especially important for applications such a precise crowd\nmonitoring at scale:\n\n[ LiDAR Software Helps Airports to Manage Increased Traffic  See how and why\nAirports are increasingly using LiDAR-based software solutions to tackle their\nbiggest challenges, leveraging the unique value of Spatial Intelligence.\n![](https://www2.outsight.ai/favicon.png) LEFIGARO  ![](https://www-\nassets.outsight.ai/ghost/2023/02/Airport-Blog-Cover.jpg) ](/insights/lidar-\nsoftware-helps-airports-to-manage-increased-traffic)\n\nIn this example real persons and a printed representation are both displayed\nto the camera:\n\n![Image showing how camera's classifying can be faulty](https://www-\nassets.outsight.ai/ghost/2023/08/Computer-Vision-fail.png)\n\n**Active sensors like LiDAR and Radar can detect the distance of each object**\n, in the case of LiDAR these measurements are done in 3 dimensions*, that is\nnot only the depth but also the exact position of any object in the space.\n\n* _Indeed, this is only applicable to 3D LiDAR, which is frequently referred to as \"LiDAR\" due to its recent popularity, largely attributed to self-driving cars. 2D LiDAR has existed for decades prior to that, functioning more like conventional Radar, where only depth information in 2 dimensions was accessible._\n\nIn a nutshell, 3D LiDAR provides Spatial Data but can't detect colours:\n\n![Table showing all the aspects that lidars can detect vs.\ncameras](https://www-assets.outsight.ai/ghost/2023/08/Lidar-vs-Camera-1.png)\nThe right sensor to use will depend on what aspects do you need to detect\n\nThat means that tasks such as tracking people at scale, individually and with\ncm accuracy, are much more appropriate for 3D Spatial sensors like LiDAR:\n\nOutsight's software processes raw data from LiDAR to extract information like\nObject Position\n\n##  Radar vs. LiDAR\n\nAs we've seen both sensors share many characteristics, mostly being active and\nable to detect distance.\n\n**The Key Differences Lie in Precision: Lidar's Laser-Level Accuracy versus\nRadar's Lower Resolution\"**\n\nLidar boasts laser-level accuracy, providing cm-level precision (mm precision\nin some 2D Lidars), while Radar's resolution is significantly lower, posing\nchallenges in precise tracking and distinguishing individuals or objects in\ncrowded environments.\n\nOne of the main reasons being the wavelengths or radio waves compared to\nlaser:\n\n![Image of why beam divergence matters](https://www-\nassets.outsight.ai/ghost/2023/08/Beam-divergence-of-LiDAR-vs-Radar.jpg)\n\nWhile Imaging Radar, the 3D version of Radar, shows promising potential and is\ncurrently in development, its capabilities are still limited.\n\nPresently, Radar primarily detects information in 2D, making it suitable for\nvarious Automotive use cases but less applicable in many other contexts.\n\n##  Respect for Privacy\n\nCameras were purposefully designed for human consumption of images, enabling\nthem to capture and deliver information that closely mirrors what a person\nwould perceive in reality ( _e.g. cinema, TV, portable cameras,\nsmartphones..._ )\n\n![Image of a man holding a picture in front of his\nface](https://images.unsplash.com/photo-1529974445367-5b9bf0a0586e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDJ8fGZhY2UlMjBpZGVudGlmaWNhdGlvbnxlbnwwfHx8fDE2OTA4OTIzMTV8MA&ixlib=rb-4.0.3&q=80&w=2000)\n\nOnly recently have the same images taken by cameras found applications in\nautomated processing by computers, utilising technologies such as Computer\nVision and Image Processing AI.\n\nThis remarkable capability has expanded to encompass the identification of\nindividuals through advanced techniques like FaceID.\n\n![Image showing Face ID](https://www-\nassets.outsight.ai/ghost/2023/08/faceID.png)\n\nThe use of cameras in facial recognition technology raises legitimate\napprehensions about data security and personal privacy.\n\nConsequently, the significance of safeguarding privacy has gained considerable\nattention from policymakers and regulators worldwide. State policies, such as\nthe General Data Protection Regulation (GDPR) in the European Union, have been\nput in place to address these concerns by imposing strict guidelines and\nlimitations on the usage of cameras and biometric data.\n\nLiDAR stands out from cameras in this crucial aspect, thanks to its remarkable\nability to uphold privacy.  \n  \nUnlike cameras, LiDAR devices generate point-cloud images that do not contain\npersonally identifiable information or reveal sensitive characteristics such\nas gender.\n\n![Image of 3D point cloud scan highlighting lidar's innate anonymity\n](https://www-assets.outsight.ai/ghost/2023/08/Lidar-does-not-capture-\npersonal-information.png) Point-cloud data doesn't allow to identify an\nindividual\n\n##  Other aspects to consider\n\nThe following chart presents a summary of the previous comparison points,\nalong with some additional ones:\n\n![Spider chart showing the capabilities of radar vs. lidar vs.\ncamera](https://www-assets.outsight.ai/ghost/2023/08/Sensors-comparison.png)\n\n  * **Cost:** Cameras exhibit the lowest cost, while LiDAR costs are rapidly decreasing, especially considering that 3D LiDAR sensors require fewer units per square meter compared to Cameras (refer to the **Low density** criteria in the chart), which translates into much less setup, wiring and networking costs. \n  * **Flexible mounting** : 3D sensors offer the advantage of versatile installation options, enabling placement in various positions and granting many of them the ability to perceive in 360\u00ba. This feature significantly reduces setup constraints, making 3D LiDAR ideal for large infrastructure projects. \n  * **Range detection** : Certain sensors, such as Stereovision Cameras, suffer from diminishing performance as the detection distance increases. In contrast, LiDAR sensors maintain consistent and reliable range detection capabilities even at greater distances. \n\n##  Conclusion\n\nIn the world of automated processing, cameras have become a ubiquitous choice\nnot necessarily due to their superiority as sensors for the task, but rather\nbecause of their widespread availability.  \n  \nAs we explored earlier in this article, the use of cameras may be suitable for\ncertain applications like object classification, where their effectiveness is\nevident. However, when it comes to capturing complex Spatial Data of the\nphysical world, these sensors reveal their limitations.  \n  \nThe intricacies of spatial data processing necessitate more specialised and\nsophisticated sensor technologies to overcome challenges and provide more\naccurate and comprehensive results.  \n  \nWhile Radar shares the benefits of being an active sensor, akin to LiDAR, and\nequally excels in preserving privacy, its significantly lower resolution and\nprecision disqualify it as a viable candidate for numerous use cases, such as\ncrowd monitoring and precise traffic management.  \n  \nThe orders of magnitude difference in resolution makes Radar less capable of\ncapturing intricate details and spatial data with the same level of accuracy\nas LiDAR.\n\nIn conclusion, the rapid advancements in LiDAR technology have ushered in a\nnew era of affordability, reliability, and performance.  \n  \nAs we have explored the numerous benefits it offers, from its active sensing\ncapabilities to the preservation of privacy, it becomes evident that LiDAR has\nemerged as the optimal choice for a wide array of use cases and applications,\nbut also in enabling new ones that were previously unimaginable with other\nsensors.\n\nAs LiDAR continues to evolve and find wider integration, it holds the key to\nunlocking unprecedented insights and driving us into a more advanced and\ninterconnected world.\n\nHowever, while LiDAR data, in the form of point-cloud information, provides a\nwealth of Spatial data, this raw data alone is essentially useless without\neffective processing and analysis.\n\nExtracting actionable insights and valuable information from point-cloud data\nrequires sophisticated processing software that can interpret, analyze, and\ntransform the data into meaningful outputs.  \n  \nThis is precisely where Outsight comes into play.\n\nThrough advanced algorithms, cutting-edge techniques and a full set of tools,\nOutsight can derive valuable insights from LiDAR point-cloud data, enabling [\na wide range of applications across industries. ](/insights/the-top-101-lidar-\napplications)\n\nOne such tool is the first Multi-Vendor LiDAR Simulator, an online platform\nthat empowers our partners and customers to make informed decisions about\nwhich LiDAR to utilize, their optimal placement, and the projected performance\nand cost for any given project.\n\n[ Introducing the first multi-vendor 3D LiDAR Simulator  Outsight has\ndeveloped a LiDAR simulator for any use case and application, from airports to\nmobile robotics, smart cities and industrial applications.\n![](https://www.outsight.ai/favicon.png) ![](https://www-\nassets.outsight.ai/ghost/2023/02/1669292171332.gif) ](/insights/introducing-\nsimulator)\n\n* * *\n\n[ ![](https://www-assets.outsight.ai/ghost/2023/09/Whitepaper-Real-time-\napplications-1.png) ](https://share-\neu1.hsforms.com/14_ay1wg4T3uKptspgMcJCQf7e7l)\n\n![](/_nuxt/subscription-box.97127db1.png)\n\n####  Newsletter\n\nReceive the latest updates in your inbox.\n\nSubscribe\n\nFeatured Articles\n\n[ ![](https://www-assets.outsight.ai/ghost/2023/09/Outsight-Cover.gif)\nOutsight in a nutshell  ](/insights/outsight-in-a-nutshell) [ ![](https://www-\nassets.outsight.ai/ghost/2023/11/Why-3D-LiDAR-is-a-Transformative-Technology-\nfor-Airports.jpg) The Seven reasons why 3D LiDAR is Transforming Airports\n](/insights/why-3d-lidar-is-a-transformative-technology-for-airports) [\n![](https://www-assets.outsight.ai/ghost/2023/01/Tree.jpg) The Top 101\nApplications of LiDAR  ](/insights/the-top-101-lidar-applications) [\n![](https://www-assets.outsight.ai/ghost/2023/01/Laser-light-cover.jpg)\nUnderstanding the Basics of 3D LiDAR Technology  ](/insights/understanding-\nthe-basics-of-3d-lidar-technology) [\n![](https://images.unsplash.com/photo-1573509078860-0196070b81dd?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDg4fHx0ZW4lMjBkd2FyZmVzfGVufDB8fHx8MTY2ODg3MDA5Nw&ixlib=rb-4.0.3&q=80&w=2000)\nThe 10 Reasons to Use a 3D Software Processor  ](/insights/10-reasons-to-\nuse-a-3d-software-processor)\n\nOutsight\n\n\u00a9 2019-2024 Outsight SA. All Rights Reserved.\n\n"
  },
  {
    "id": "Odometry/23051.txt",
    "content": "[ The Construct ROS Community ](/)\n\n#  [ Error compiling send_goal function of action client - WallFollower\nProject ](/t/error-compiling-send-goal-function-of-action-client-wallfollower-\nproject/23051)\n\n[ Course Support  ](/c/course-support/ros2-basics-in-5-days-galactic-c/108) [\nROS2 Basics in 5 Days (C++)  ](/c/course-support/ros2-basics-in-5-days-\ngalactic-c/108)\n\n[ error ](https://get-help.theconstruct.ai/tag/error)\n\n[ w.ronaldo.cd  ](https://get-help.theconstruct.ai/u/w.ronaldo.cd) March 13,\n2023, 6:09pm  1\n\nHi,  \nI am working on part3 of the WallFollower project. While adding the Action\nClient to my main node, I am getting the following compilation error:  \n\n[ ![image](https://get-\nhelp.robotigniteacademy.com/uploads/default/optimized/2X/2/24add0ecd024a7f5276e15181b6dc454d3e48661_2_690x173.png)\nimage  1069\u00d7269 73.9 KB  ](https://get-\nhelp.robotigniteacademy.com/uploads/default/original/2X/2/24add0ecd024a7f5276e15181b6dc454d3e48661.png\n\"image\")\n\nI tried to follow the instructions of the course, I don\u2019t understand what\ncould be the problem. My code related to the constructor and action client\nfunction is posted bellow:\n\n    \n    \n    class WallFollower : public rclcpp::Node\n    {\n    public:\n        using OdomRecord = custom_interfaces::action::OdomRecord;\n        using GoalHandleOdomRecord = rclcpp_action::ClientGoalHandle<OdomRecord>;\n    \n        explicit WallFollower(const rclcpp::NodeOptions & node_options = rclcpp::NodeOptions())\n        : Node(\"wall_follower\", node_options), goal_done_(false)\n        {\n            subscribers_callback_group =this->create_callback_group(rclcpp::CallbackGroupType::MutuallyExclusive);\n            publishers_callback_group =this->create_callback_group(rclcpp::CallbackGroupType::MutuallyExclusive);\n            action_client_callback_group =this->create_callback_group(rclcpp::CallbackGroupType::MutuallyExclusive);\n            \n            rclcpp::SubscriptionOptions options1;\n            options1.callback_group = subscribers_callback_group;\n    \n            vel_publisher = this->create_publisher<geometry_msgs::msg::Twist>(\"cmd_vel\", 10);\n            odom_subscriber = this->create_subscription<nav_msgs::msg::Odometry>(\n                \"odom\", 10, std::bind(&WallFollower::odom_subs_callback, this, _7), options1);\n            scan_subscriber = this->create_subscription<sensor_msgs::msg::LaserScan>(\n                \"scan\", rclcpp::SensorDataQoS(), std::bind(&WallFollower::scan_subs_callback, this, _7), options1);\n            timer_ = this->create_wall_timer(500ms, std::bind(&WallFollower::robot_motion, this), publishers_callback_group);\n            print_timer = this->create_wall_timer(2000ms, std::bind(&WallFollower::print_function, this), publishers_callback_group);\n            \n            this->client_ptr_ = rclcpp_action::create_client<OdomRecord>(\n                this->get_node_base_interface(),\n                this->get_node_graph_interface(),\n                this->get_node_logging_interface(),\n                this->get_node_waitables_interface(),\n                \"record_odom\");\n    \n            this->action_client_timer_ = this->create_wall_timer(std::chrono::milliseconds(500), std::bind(&WallFollower::send_goal, this), action_client_callback_group);\n    \n            this->rotation_z = 0.0;\n            this->distance_to_wall = 0.0;\n            this->distance_to_front_wall= 0.0;\n            this->offset_angle = 0.0;\n            this->linear_vel = 0.1;\n            this->angular_vel = 0.1;\n            this->dist_tol = 0.02;\n            this->angle_tol = 3.0*M_PI/180;\n            this->timer_period = 0.5;\n    \n        }\n    \n        bool is_goal_done() const\n        {\n            return this->goal_done_;\n        }\n    \n        void send_goal()\n        {\n            using namespace std::placeholders;\n    \n            this->action_client_timer_->cancel();\n    \n            this->goal_done_ = false;\n    \n            if (!this->client_ptr_) {\n                RCLCPP_ERROR(this->get_logger(), \"Action client not initialized\");\n            }\n    \n            if (!this->client_ptr_->wait_for_action_server(std::chrono::seconds(10))) {\n                RCLCPP_ERROR(this->get_logger(), \"Action server not available after waiting\");\n                this->goal_done_ = true;\n                return;\n            }\n    \n            auto goal_msg = OdomRecord::Goal();\n    \n            RCLCPP_INFO(this->get_logger(), \"Sending goal\");\n    \n            auto send_goal_options = rclcpp_action::Client<OdomRecord>::SendGoalOptions();\n                        \n            send_goal_options.goal_response_callback = \n            std::bind(&WallFollower::goal_response_callback, this, _1);\n    \n            send_goal_options.feedback_callback =\n            std::bind(&WallFollower::feedback_callback, this, _1, _2);\n    \n            send_goal_options.result_callback =\n            std::bind(&WallFollower::result_callback, this, _1);\n            \n            auto goal_handle_future = this->client_ptr_->async_send_goal(goal_msg, send_goal_options);\n        }\n    \n    \n    void goal_response_callback(const GoalHandleOdomRecord::SharedPtr & goal_handle)\n        {\n            if (!goal_handle) {\n            RCLCPP_ERROR(this->get_logger(), \"Goal was rejected by server\");\n            } else {\n            RCLCPP_INFO(this->get_logger(), \"Goal accepted by server, waiting for result\");\n            }\n        }\n    \n        void feedback_callback(\n            GoalHandleOdomRecord::SharedPtr,\n            const std::shared_ptr<const OdomRecord::Feedback> feedback)\n        {\n            RCLCPP_INFO(\n            this->get_logger(), \"Feedback received: Total current distance = %f\", feedback->current_total);\n        }\n    \n        void result_callback(const GoalHandleOdomRecord::WrappedResult & result)\n        {\n            this->goal_done_ = true;\n            switch (result.code) {\n            case rclcpp_action::ResultCode::SUCCEEDED:\n                break;\n            case rclcpp_action::ResultCode::ABORTED:\n                RCLCPP_ERROR(this->get_logger(), \"Goal was aborted\");\n                return;\n            case rclcpp_action::ResultCode::CANCELED:\n                RCLCPP_ERROR(this->get_logger(), \"Goal was canceled\");\n                return;\n            default:\n                RCLCPP_ERROR(this->get_logger(), \"Unknown result code\");\n                return;\n            }\n    \n            RCLCPP_INFO(this->get_logger(), \"RESULT RECEIVED\");\n        }\n    \n\n[ girishkumar.kannan  ](https://get-help.theconstruct.ai/u/girishkumar.kannan)\nMarch 14, 2023, 4:41am  2\n\nHi [ @w.ronaldo.cd ](/u/w.ronaldo.cd) ,\n\nI have not gone through your code yet, but from what I did, I am telling you.  \nThat error what the IDE produces is a false-positive.\n\nA error would be a true error only if the error is produced during actual\ncompilation - ` colcon build ... ` in your case since you are working with\nROS2.  \nDo not be carried away by the IDE false-positives.\n\nIf you get the same error during ` colcon build ... ` then post the complete\nerror here as code-block.\n\nRegards,  \nGirish\n\n[ w.ronaldo.cd  ](https://get-help.theconstruct.ai/u/w.ronaldo.cd) March 14,\n2023, 3:25pm  3\n\nHi [ @girishkumar.kannan ](/u/girishkumar.kannan) ,  \nThe error appears during compilation ( _colcon build_ ) I posted that image\nbecause it shows where the problem is and the error. I will keep reviewing my\ncode.  \nBest regards\n\n[ bayodesegun  ](https://get-help.theconstruct.ai/u/bayodesegun) March 15,\n2023, 2:15pm  4\n\nPaste the errors that occur during compilation carefully here, screenshot or\njust copy and paste in a code block (better).\n\n[ w.ronaldo.cd  ](https://get-help.theconstruct.ai/u/w.ronaldo.cd) March 15,\n2023, 9:00pm  5\n\nHi [ @bayodesegun ](/u/bayodesegun)  \nThe error is quite large\n\n    \n    \n    /home/user/ros2_ws/src/Wall Follower/wall_follower/src/wall_follower_part3.cpp: In member function 'void WallFollower::send_goal()':\n    /home/user/ros2_ws/src/Wall Follower/wall_follower/src/wall_follower_part3.cpp:119:66: error: no match for 'operator=' (operand types are 'rclcpp_action::Client<custom_interfaces::action::OdomRecord>::GoalResponseCallback' {aka 'std::function<void(std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > >)>'} and 'std::_Bind_helper<false, void (WallFollower::*)(const std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> >&), WallFollower*, const std::_Placeholder<1>&>::type' {aka 'std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<1>))(const std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> >&)>'})\n      119 |         std::bind(&WallFollower::goal_response_callback, this, _1);\n          |                                                                  ^\n    In file included from /usr/include/c++/9/functional:59,\n                     from /opt/ros/foxy/include/rclcpp/utilities.hpp:19,\n                     from /opt/ros/foxy/include/rclcpp/logging.hpp:25,\n                     from /home/user/ros2_ws/src/Wall Follower/wall_follower/src/wall_follower_part3.cpp:3:\n    /usr/include/c++/9/bits/std_function.h:462:7: note: candidate: 'std::function<_Res(_ArgTypes ...)>& std::function<_Res(_ArgTypes ...)>::operator=(const std::function<_Res(_ArgTypes ...)>&) [with _Res = void; _ArgTypes = {std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > >}]'\n      462 |       operator=(const function& __x)\n          |       ^~~~~~~~\n    /usr/include/c++/9/bits/std_function.h:462:33: note:   no known conversion for argument 1 from 'std::_Bind_helper<false, void (WallFollower::*)(const std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> >&), WallFollower*, const std::_Placeholder<1>&>::type' {aka 'std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<1>))(const std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> >&)>'} to 'const std::function<void(std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > >)>&'\n      462 |       operator=(const function& __x)\n          |                 ~~~~~~~~~~~~~~~~^~~\n    /usr/include/c++/9/bits/std_function.h:480:7: note: candidate: 'std::function<_Res(_ArgTypes ...)>& std::function<_Res(_ArgTypes ...)>::operator=(std::function<_Res(_ArgTypes ...)>&&) [with _Res = void; _ArgTypes = {std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > >}]'\n      480 |       operator=(function&& __x) noexcept\n          |       ^~~~~~~~\n    /usr/include/c++/9/bits/std_function.h:480:28: note:   no known conversion for argument 1 from 'std::_Bind_helper<false, void (WallFollower::*)(const std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> >&), WallFollower*, const std::_Placeholder<1>&>::type' {aka 'std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<1>))(const std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> >&)>'} to 'std::function<void(std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > >)>&&'\n      480 |       operator=(function&& __x) noexcept\n          |                 ~~~~~~~~~~~^~~\n    /usr/include/c++/9/bits/std_function.h:494:7: note: candidate: 'std::function<_Res(_ArgTypes ...)>& std::function<_Res(_ArgTypes ...)>::operator=(std::nullptr_t) [with _Res = void; _ArgTypes = {std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > >}; std::nullptr_t = std::nullptr_t]'\n      494 |       operator=(nullptr_t) noexcept\n          |       ^~~~~~~~\n    /usr/include/c++/9/bits/std_function.h:494:17: note:   no known conversion for argument 1 from 'std::_Bind_helper<false, void (WallFollower::*)(const std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> >&), WallFollower*, const std::_Placeholder<1>&>::type' {aka 'std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<1>))(const std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> >&)>'} to 'std::nullptr_t'\n      494 |       operator=(nullptr_t) noexcept\n          |                 ^~~~~~~~~\n    /usr/include/c++/9/bits/std_function.h:523:2: note: candidate: 'template<class _Functor> std::function<_Res(_ArgTypes ...)>::_Requires<std::function<_Res(_ArgTypes ...)>::_Callable<typename std::decay<_Functor>::type>, std::function<_Res(_ArgTypes ...)>&> std::function<_Res(_ArgTypes ...)>::operator=(_Functor&&) [with _Functor = _Functor; _Res = void; _ArgTypes = {std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > >}]'\n      523 |  operator=(_Functor&& __f)\n          |  ^~~~~~~~\n    /usr/include/c++/9/bits/std_function.h:523:2: note:   template argument deduction/substitution failed:\n    /usr/include/c++/9/bits/std_function.h: In substitution of 'template<class _Res, class ... _ArgTypes> template<class _Cond, class _Tp> using _Requires = typename std::enable_if<_Cond::value, _Tp>::type [with _Cond = std::function<void(std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > >)>::_Callable<std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<1>))(const std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> >&)>, std::__invoke_result<std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<1>))(const std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> >&)>&, std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > > > >; _Tp = std::function<void(std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > >)>&; _Res = void; _ArgTypes = {std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > >}]':\n    /usr/include/c++/9/bits/std_function.h:523:2:   required by substitution of 'template<class _Functor> std::function<void(std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > >)>::_Requires<std::function<void(std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > >)>::_Callable<typename std::decay<_Tp>::type, std::__invoke_result<typename std::decay<_Tp>::type&, std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > > > >, std::function<void(std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > >)>&> std::function<void(std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > >)>::operator=<_Functor>(_Functor&&) [with _Functor = std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<1>))(const std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> >&)>]'\n    /home/user/ros2_ws/src/Wall Follower/wall_follower/src/wall_follower_part3.cpp:119:66:   required from here\n    /usr/include/c++/9/bits/std_function.h:385:8: error: no type named 'type' in 'struct std::enable_if<false, std::function<void(std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord> > >)>&>'\n      385 |  using _Requires = typename enable_if<_Cond::value, _Tp>::type;\n    \n\n[ w.ronaldo.cd  ](https://get-help.theconstruct.ai/u/w.ronaldo.cd) March 15,\n2023, 9:02pm  6\n\nIt continues with:\n\n    \n    \n    /opt/ros/foxy/include/rclcpp/any_subscription_callback.hpp: In instantiation of 'void rclcpp::AnySubscriptionCallback<MessageT, Alloc>::set(CallbackT) [with CallbackT = std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<7>))(std::shared_ptr<nav_msgs::msg::Odometry_<std::allocator<void> > >)>; typename std::enable_if<rclcpp::function_traits::same_arguments<CallbackT, std::function<void(std::shared_ptr<_Tp>)> >::value>::type* <anonymous> = 0; MessageT = nav_msgs::msg::Odometry_<std::allocator<void> >; Alloc = std::allocator<void>]':\n    /opt/ros/foxy/include/rclcpp/subscription_factory.hpp:97:3:   required from 'rclcpp::SubscriptionFactory rclcpp::create_subscription_factory(CallbackT&&,const rclcpp::SubscriptionOptionsWithAllocator<AllocatorT>&, typename MessageMemoryStrategyT::SharedPtr, std::shared_ptr<rclcpp::topic_statistics::SubscriptionTopicStatistics<CallbackMessageT> >) [with MessageT = nav_msgs::msg::Odometry_<std::allocator<void> >; CallbackT = std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<7>))(std::shared_ptr<nav_msgs::msg::Odometry_<std::allocator<void> > >)>; AllocatorT = std::allocator<void>; CallbackMessageT = nav_msgs::msg::Odometry_<std::allocator<void> >; SubscriptionT = rclcpp::Subscription<nav_msgs::msg::Odometry_<std::allocator<void> > >; MessageMemoryStrategyT = rclcpp::message_memory_strategy::MessageMemoryStrategy<nav_msgs::msg::Odometry_<std::allocator<void> >, std::allocator<void> >; typename MessageMemoryStrategyT::SharedPtr = std::shared_ptr<rclcpp::message_memory_strategy::MessageMemoryStrategy<nav_msgs::msg::Odometry_<std::allocator<void> >, std::allocator<void> > >]'\n    /opt/ros/foxy/include/rclcpp/create_subscription.hpp:144:63:   required from 'std::shared_ptr<SubscriptionT> rclcpp::create_subscription(NodeT&&, const string&, const rclcpp::QoS&, CallbackT&&, const rclcpp::SubscriptionOptionsWithAllocator<AllocatorT>&, typename MessageMemoryStrategyT::SharedPtr) [with MessageT = nav_msgs::msg::Odometry_<std::allocator<void> >; CallbackT = std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<7>))(std::shared_ptr<nav_msgs::msg::Odometry_<std::allocator<void> > >)>; AllocatorT = std::allocator<void>; CallbackMessageT = nav_msgs::msg::Odometry_<std::allocator<void> >; SubscriptionT = rclcpp::Subscription<nav_msgs::msg::Odometry_<std::allocator<void> > >; MessageMemoryStrategyT = rclcpp::message_memory_strategy::MessageMemoryStrategy<nav_msgs::msg::Odometry_<std::allocator<void> >, std::allocator<void> >; NodeT = rclcpp::Node&; std::string = std::__cxx11::basic_string<char>; typename MessageMemoryStrategyT::SharedPtr = std::shared_ptr<rclcpp::message_memory_strategy::MessageMemoryStrategy<nav_msgs::msg::Odometry_<std::allocator<void> >, std::allocator<void> > >]'\n    /opt/ros/foxy/include/rclcpp/node_impl.hpp:98:47:   required from 'std::shared_ptr<SubscriptionT> rclcpp::Node::create_subscription(const string&, const rclcpp::QoS&, CallbackT&&, const rclcpp::SubscriptionOptionsWithAllocator<AllocatorT>&, typename MessageMemoryStrategyT::SharedPtr) [with MessageT = nav_msgs::msg::Odometry_<std::allocator<void> >; CallbackT = std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<7>))(std::shared_ptr<nav_msgs::msg::Odometry_<std::allocator<void> > >)>; AllocatorT = std::allocator<void>; CallbackMessageT = nav_msgs::msg::Odometry_<std::allocator<void> >; SubscriptionT = rclcpp::Subscription<nav_msgs::msg::Odometry_<std::allocator<void> > >; MessageMemoryStrategyT = rclcpp::message_memory_strategy::MessageMemoryStrategy<nav_msgs::msg::Odometry_<std::allocator<void> >, std::allocator<void> >; std::string = std::__cxx11::basic_string<char>; typename MessageMemoryStrategyT::SharedPtr = std::shared_ptr<rclcpp::message_memory_strategy::MessageMemoryStrategy<nav_msgs::msg::Odometry_<std::allocator<void> >, std::allocator<void> > >]'\n    /home/user/ros2_ws/src/Wall Follower/wall_follower/src/wall_follower_part3.cpp:62:89:   required from here\n    /usr/include/c++/9/bits/std_function.h:532:2: note: candidate: 'template<class _Functor> std::function<_Res(_ArgTypes ...)>& std::function<_Res(_ArgTypes...)>::operator=(std::reference_wrapper<_Functor>) [with _Functor = _Functor; _Res = void; _ArgTypes = {std::shared_ptr<nav_msgs::msg::Odometry_<std::allocator<void> > >}]'\n      532 |  operator=(reference_wrapper<_Functor> __f) noexcept\n          |  ^~~~~~~~\n    /usr/include/c++/9/bits/std_function.h:532:2: note:   template argument deduction/substitution failed:\n    In file included from /opt/ros/foxy/include/rclcpp/subscription_base.hpp:29,\n                     from /opt/ros/foxy/include/rclcpp/callback_group.hpp:26,\n                     from /opt/ros/foxy/include/rclcpp/any_executable.hpp:20,\n                     from /opt/ros/foxy/include/rclcpp/memory_strategy.hpp:24,\n                     from /opt/ros/foxy/include/rclcpp/memory_strategies.hpp:18,\n                     from /opt/ros/foxy/include/rclcpp/executor_options.hpp:20,\n                     from /opt/ros/foxy/include/rclcpp/executor.hpp:33,\n                     from /opt/ros/foxy/include/rclcpp/executors/multi_threaded_executor.hpp:26,\n                     from /opt/ros/foxy/include/rclcpp/executors.hpp:21,\n                     from /opt/ros/foxy/include/rclcpp/rclcpp.hpp:146,\n                     from /home/user/ros2_ws/src/Wall Follower/wall_follower/src/wall_follower_part3.cpp:5:\n    /opt/ros/foxy/include/rclcpp/any_subscription_callback.hpp:85:26: note:   'std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<7>))(std::shared_ptr<nav_msgs::msg::Odometry_<std::allocator<void> > >)>' is not derived from 'std::reference_wrapper<_Tp>'\n       85 |     shared_ptr_callback_ = callback;\n          |     ~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~\n    /opt/ros/foxy/include/rclcpp/any_subscription_callback.hpp: In instantiation of 'void rclcpp::AnySubscriptionCallback<MessageT, Alloc>::set(CallbackT) [with CallbackT = std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<7>))(std::shared_ptr<sensor_msgs::msg::LaserScan_<std::allocator<void> >>)>; typename std::enable_if<rclcpp::function_traits::same_arguments<CallbackT, std::function<void(std::shared_ptr<_Tp>)> >::value>::type* <anonymous> = 0; MessageT = sensor_msgs::msg::LaserScan_<std::allocator<void> >; Alloc = std::allocator<void>]':\n    /opt/ros/foxy/include/rclcpp/subscription_factory.hpp:97:3:   required from 'rclcpp::SubscriptionFactory rclcpp::create_subscription_factory(CallbackT&&,const rclcpp::SubscriptionOptionsWithAllocator<AllocatorT>&, typename MessageMemoryStrategyT::SharedPtr, std::shared_ptr<rclcpp::topic_statistics::SubscriptionTopicStatistics<CallbackMessageT> >) [with MessageT = sensor_msgs::msg::LaserScan_<std::allocator<void> >; CallbackT = std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<7>))(std::shared_ptr<sensor_msgs::msg::LaserScan_<std::allocator<void> > >)>; AllocatorT = std::allocator<void>; CallbackMessageT = sensor_msgs::msg::LaserScan_<std::allocator<void> >; SubscriptionT = rclcpp::Subscription<sensor_msgs::msg::LaserScan_<std::allocator<void>> >; MessageMemoryStrategyT = rclcpp::message_memory_strategy::MessageMemoryStrategy<sensor_msgs::msg::LaserScan_<std::allocator<void> >, std::allocator<void> >; typename MessageMemoryStrategyT::SharedPtr = std::shared_ptr<rclcpp::message_memory_strategy::MessageMemoryStrategy<sensor_msgs::msg::LaserScan_<std::allocator<void> >, std::allocator<void> > >]'\n    /opt/ros/foxy/include/rclcpp/create_subscription.hpp:144:63:   required from 'std::shared_ptr<SubscriptionT> rclcpp::create_subscription(NodeT&&, const string&, const rclcpp::QoS&, CallbackT&&, const rclcpp::SubscriptionOptionsWithAllocator<AllocatorT>&, typename MessageMemoryStrategyT::SharedPtr) [with MessageT = sensor_msgs::msg::LaserScan_<std::allocator<void> >; CallbackT = std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<7>))(std::shared_ptr<sensor_msgs::msg::LaserScan_<std::allocator<void> > >)>; AllocatorT = std::allocator<void>; CallbackMessageT = sensor_msgs::msg::LaserScan_<std::allocator<void> >; SubscriptionT = rclcpp::Subscription<sensor_msgs::msg::LaserScan_<std::allocator<void> > >; MessageMemoryStrategyT = rclcpp::message_memory_strategy::MessageMemoryStrategy<sensor_msgs::msg::LaserScan_<std::allocator<void> >, std::allocator<void> >; NodeT = rclcpp::Node&; std::string = std::__cxx11::basic_string<char>; typename MessageMemoryStrategyT::SharedPtr = std::shared_ptr<rclcpp::message_memory_strategy::MessageMemoryStrategy<sensor_msgs::msg::LaserScan_<std::allocator<void> >, std::allocator<void> > >]'\n    /opt/ros/foxy/include/rclcpp/node_impl.hpp:98:47:   required from 'std::shared_ptr<SubscriptionT> rclcpp::Node::create_subscription(const string&, const rclcpp::QoS&, CallbackT&&, const rclcpp::SubscriptionOptionsWithAllocator<AllocatorT>&, typename MessageMemoryStrategyT::SharedPtr) [with MessageT = sensor_msgs::msg::LaserScan_<std::allocator<void> >; CallbackT = std::_Bind<void (WallFollower::*(WallFollower*, std::_Placeholder<7>))(std::shared_ptr<sensor_msgs::msg::LaserScan_<std::allocator<void> > >)>; AllocatorT = std::allocator<void>; CallbackMessageT = sensor_msgs::msg::LaserScan_<std::allocator<void> >; SubscriptionT = rclcpp::Subscription<sensor_msgs::msg::LaserScan_<std::allocator<void> > >; MessageMemoryStrategyT = rclcpp::message_memory_strategy::MessageMemoryStrategy<sensor_msgs::msg::LaserScan_<std::allocator<void> >, std::allocator<void> >; std::string = std::__cxx11::basic_string<char>; typenameMessageMemoryStrategyT::SharedPtr = std::shared_ptr<rclcpp::message_memory_strategy::MessageMemoryStrategy<sensor_msgs::msg::LaserScan_<std::allocator<void> >, std::allocator<void> > >]'\n    \n\n[ girishkumar.kannan  ](https://get-help.theconstruct.ai/u/girishkumar.kannan)\nMarch 16, 2023, 4:44am  7\n\nHi [ @w.ronaldo.cd ](/u/w.ronaldo.cd) ,\n\nHere is a simple trick to understand long error outputs: It is usually the\nreference to the first line of error that has the actual bug. The remaining\nerrors are caused because of the first error.\n\nIn your case, The first error is this part:\n\n![](https://get-\nhelp.robotigniteacademy.com/letter_avatar_proxy/v4/letter/w/9d8465/48.png)\nw.ronaldo.cd:\n\n>\n>     /home/user/ros2_ws/src/Wall\n> Follower/wall_follower/src/wall_follower_part3.cpp: In member function 'void\n> WallFollower::send_goal()':\n>     /home/user/ros2_ws/src/Wall\n> Follower/wall_follower/src/wall_follower_part3.cpp:119:66: error: no match\n> for 'operator=' (operand types are\n> 'rclcpp_action::Client<custom_interfaces::action::OdomRecord>::GoalResponseCallback'\n> {aka\n> 'std::function<void(std::shared_future<std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord>\n> > >)>'} and 'std::_Bind_helper<false, void (WallFollower::*)(const\n> std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord>\n> >&), WallFollower*, const std::_Placeholder<1>&>::type' {aka\n> 'std::_Bind<void (WallFollower::*(WallFollower*,\n> std::_Placeholder<1>))(const\n> std::shared_ptr<rclcpp_action::ClientGoalHandle<custom_interfaces::action::OdomRecord>\n> >&)>'})\n>       119 |         std::bind(&WallFollower::goal_response_callback, this,\n> _1);\n>           |  \n>  \n\nThe other error outputs are just irrelevant and will just make you nervous. So\ndon\u2019t panic!\n\nSo the error says operator mismatch in the line:  \n` std::bind(&WallFollower::goal_response_callback, this, _1); ` .\n\nI know exactly, why you are getting this error.  \n**Reason:** The rosject uses ` Foxy ` as ROS2 version while You have learned\nROS2 Basics with ` Humble ` .  \nThere was a major syntax difference in Goal Response Callback function.  \nSo the error is not in the reported line but the function itself!  \nHandling these errors requires some finesse which you will develop as you\ncode.\n\nROS2 Foxy GoalResponseCallback:\n\n    \n    \n    void goal_response_callback(std::shared_future<GoalHandleOdomRecord::SharedPtr> future)\n    {\n        // ...\n    }\n    \n\nROS2 Humble GoalResponseCallback:\n\n    \n    \n    void goal_response_callback(const GoalHandleOdomRecord::SharedPtr & goal_handle)\n    {\n        // ...\n    }\n    \n\nDo you notice the function definition difference here?\n\nSo just use the ` Foxy ` version\u2019s definition in your Rosject. This will fix\nyour issue.\n\nSorry, I could not identify this error earlier. My bad. Thanks for your\npatience. Much appreciated!\n\nLet me know if this gets your problem fixed. I believe this should get your\nissue fixed.\n\nRegards,  \nGirish\n\n[ How to call action with an empty goal? ](https://get-\nhelp.robotigniteacademy.com/t/how-to-call-action-with-an-empty-goal/23944/9)\n\n[ w.ronaldo.cd  ](https://get-help.theconstruct.ai/u/w.ronaldo.cd) March 16,\n2023, 10:25pm  8\n\nThank you, it worked.\n\nBest Regards\n\n[ system  ](https://get-help.theconstruct.ai/u/system) Closed  March 21, 2023,\n10:26pm  9\n\nThis topic was automatically closed 5 days after the last reply. New replies\nare no longer allowed.\n\n  * [ Home ](/)\n  * [ Categories ](/categories)\n  * [ FAQ/Guidelines ](/guidelines)\n  * [ Terms of Service ](http://www.theconstructsim.com/terms_and_conditions/)\n  * [ Privacy Policy ](http://www.theconstructsim.com/privacy_policy/)\n\nPowered by [ Discourse ](https://www.discourse.org) , best viewed with\nJavaScript enabled\n\n"
  },
  {
    "id": "ros_yaml/UsingParametersInACl.txt",
    "content": "[ ROS 2 Documentation: Foxy ![Logo](../../_static/foxy-small.png)\n](../../index.html)\n\n  * [ Installation ](../../Installation.html)\n    * [ Ubuntu (Debian) ](../../Installation/Ubuntu-Install-Debians.html)\n    * [ Windows (binary) ](../../Installation/Windows-Install-Binary.html)\n    * [ Alternatives ](../../Installation/Alternatives.html)\n      * [ Ubuntu (source) ](../../Installation/Alternatives/Ubuntu-Development-Setup.html)\n      * [ Ubuntu (binary) ](../../Installation/Alternatives/Ubuntu-Install-Binary.html)\n      * [ Windows (source) ](../../Installation/Alternatives/Windows-Development-Setup.html)\n      * [ macOS (source) ](../../Installation/Alternatives/macOS-Development-Setup.html)\n      * [ macOS (binary) ](../../Installation/Alternatives/macOS-Install-Binary.html)\n      * [ Fedora (source) ](../../Installation/Alternatives/Fedora-Development-Setup.html)\n      * [ Latest development (source) ](../../Installation/Alternatives/Latest-Development-Setup.html)\n    * [ Maintain source checkout ](../../Installation/Maintaining-a-Source-Checkout.html)\n    * [ Testing with pre-release binaries ](../../Installation/Testing.html)\n    * [ DDS implementations ](../../Installation/DDS-Implementations.html)\n      * [ Connext security plugins ](../../Installation/DDS-Implementations/Install-Connext-Security-Plugins.html)\n      * [ RTI Connext DDS ](../../Installation/DDS-Implementations/Install-Connext-University-Eval.html)\n      * [ Eclipse Cyclone DDS ](../../Installation/DDS-Implementations/Working-with-Eclipse-CycloneDDS.html)\n      * [ GurumNetworks GurumDDS ](../../Installation/DDS-Implementations/Working-with-GurumNetworks-GurumDDS.html)\n      * [ eProsima Fast DDS ](../../Installation/DDS-Implementations/Working-with-eProsima-Fast-DDS.html)\n  * [ Distributions ](../../Releases.html)\n    * [ Iron Irwini ( ` iron  ` ) ](../../Releases/Release-Iron-Irwini.html)\n      * [ Iron Irwini Changelog ](../../Releases/Iron-Irwini-Complete-Changelog.html)\n    * [ Humble Hawksbill ( ` humble  ` ) ](../../Releases/Release-Humble-Hawksbill.html)\n      * [ Humble Hawksbill changelog ](../../Releases/Humble-Hawksbill-Complete-Changelog.html)\n    * [ Rolling Ridley ( ` rolling  ` ) ](../../Releases/Release-Rolling-Ridley.html)\n    * [ Development Distribution ](../../Releases/Development.html)\n      * [ Jazzy Jalisco (codename \u00e2\u0080\u0098jazzy\u00e2\u0080\u0099; May, 2024) ](../../Releases/Release-Jazzy-Jalisco.html)\n    * [ End-of-Life Distributions ](../../Releases/End-of-Life.html)\n      * [ Galactic Geochelone ( ` galactic  ` ) ](../../Releases/Release-Galactic-Geochelone.html)\n        * [ Galactic Geochelone changelog ](../../Releases/Galactic-Geochelone-Complete-Changelog.html)\n      * [ Foxy Fitzroy ( ` foxy  ` ) ](../../Releases/Release-Foxy-Fitzroy.html)\n      * [ Eloquent Elusor ( ` eloquent  ` ) ](../../Releases/Release-Eloquent-Elusor.html)\n      * [ Dashing Diademata ( ` dashing  ` ) ](../../Releases/Release-Dashing-Diademata.html)\n      * [ Crystal Clemmys ( ` crystal  ` ) ](../../Releases/Release-Crystal-Clemmys.html)\n      * [ Bouncy Bolson ( ` bouncy  ` ) ](../../Releases/Release-Bouncy-Bolson.html)\n      * [ Ardent Apalone ( ` ardent  ` ) ](../../Releases/Release-Ardent-Apalone.html)\n      * [ Beta 3 ( ` r2b3  ` ) ](../../Releases/Beta3-Overview.html)\n      * [ Beta 2 ( ` r2b2  ` ) ](../../Releases/Beta2-Overview.html)\n      * [ Beta 1 ( ` Asphalt  ` ) ](../../Releases/Beta1-Overview.html)\n      * [ Alphas ](../../Releases/Alpha-Overview.html)\n    * [ Development process for a release ](../../Releases/Release-Process.html)\n  * [ Tutorials ](../../Tutorials.html)\n    * [ Beginner: CLI tools ](../Beginner-CLI-Tools.html)\n      * [ Configuring environment ](../Beginner-CLI-Tools/Configuring-ROS2-Environment.html)\n      * [ Using ` turtlesim  ` , ` ros2  ` , and ` rqt  ` ](../Beginner-CLI-Tools/Introducing-Turtlesim/Introducing-Turtlesim.html)\n      * [ Understanding nodes ](../Beginner-CLI-Tools/Understanding-ROS2-Nodes/Understanding-ROS2-Nodes.html)\n      * [ Understanding topics ](../Beginner-CLI-Tools/Understanding-ROS2-Topics/Understanding-ROS2-Topics.html)\n      * [ Understanding services ](../Beginner-CLI-Tools/Understanding-ROS2-Services/Understanding-ROS2-Services.html)\n      * [ Understanding parameters ](../Beginner-CLI-Tools/Understanding-ROS2-Parameters/Understanding-ROS2-Parameters.html)\n      * [ Understanding actions ](../Beginner-CLI-Tools/Understanding-ROS2-Actions/Understanding-ROS2-Actions.html)\n      * [ Using ` rqt_console  ` to view logs ](../Beginner-CLI-Tools/Using-Rqt-Console/Using-Rqt-Console.html)\n      * [ Launching nodes ](../Beginner-CLI-Tools/Launching-Multiple-Nodes/Launching-Multiple-Nodes.html)\n      * [ Recording and playing back data ](../Beginner-CLI-Tools/Recording-And-Playing-Back-Data/Recording-And-Playing-Back-Data.html)\n    * [ Beginner: Client libraries ](../Beginner-Client-Libraries.html)\n      * [ Using ` colcon  ` to build packages ](Colcon-Tutorial.html)\n      * [ Creating a workspace ](Creating-A-Workspace/Creating-A-Workspace.html)\n      * [ Creating a package ](Creating-Your-First-ROS2-Package.html)\n      * [ Writing a simple publisher and subscriber (C++) ](Writing-A-Simple-Cpp-Publisher-And-Subscriber.html)\n      * [ Writing a simple publisher and subscriber (Python) ](Writing-A-Simple-Py-Publisher-And-Subscriber.html)\n      * [ Writing a simple service and client (C++) ](Writing-A-Simple-Cpp-Service-And-Client.html)\n      * [ Writing a simple service and client (Python) ](Writing-A-Simple-Py-Service-And-Client.html)\n      * [ Creating custom msg and srv files ](Custom-ROS2-Interfaces.html)\n      * [ Implementing custom interfaces ](Single-Package-Define-And-Use-Interface.html)\n      * [ Using parameters in a class (C++) ](Using-Parameters-In-A-Class-CPP.html)\n      * Using parameters in a class (Python) \n      * [ Using ` ros2doctor  ` to identify issues ](Getting-Started-With-Ros2doctor.html)\n      * [ Creating and using plugins (C++) ](Pluginlib.html)\n    * [ Intermediate ](../Intermediate.html)\n      * [ Managing Dependencies with rosdep ](../Intermediate/Rosdep.html)\n      * [ Creating an action ](../Intermediate/Creating-an-Action.html)\n      * [ Writing an action server and client (C++) ](../Intermediate/Writing-an-Action-Server-Client/Cpp.html)\n      * [ Writing an action server and client (Python) ](../Intermediate/Writing-an-Action-Server-Client/Py.html)\n      * [ Composing multiple nodes in a single process ](../Intermediate/Composition.html)\n      * [ Launch ](../Intermediate/Launch/Launch-Main.html)\n        * [ Creating a launch file ](../Intermediate/Launch/Creating-Launch-Files.html)\n        * [ Integrating launch files into ROS 2 packages ](../Intermediate/Launch/Launch-system.html)\n        * [ Using substitutions ](../Intermediate/Launch/Using-Substitutions.html)\n        * [ Using event handlers ](../Intermediate/Launch/Using-Event-Handlers.html)\n        * [ Managing large projects ](../Intermediate/Launch/Using-ROS2-Launch-For-Large-Projects.html)\n      * [ ` tf2  ` ](../Intermediate/Tf2/Tf2-Main.html)\n        * [ Introducing ` tf2  ` ](../Intermediate/Tf2/Introduction-To-Tf2.html)\n        * [ Writing a static broadcaster (Python) ](../Intermediate/Tf2/Writing-A-Tf2-Static-Broadcaster-Py.html)\n        * [ Writing a static broadcaster (C++) ](../Intermediate/Tf2/Writing-A-Tf2-Static-Broadcaster-Cpp.html)\n        * [ Writing a broadcaster (Python) ](../Intermediate/Tf2/Writing-A-Tf2-Broadcaster-Py.html)\n        * [ Writing a broadcaster (C++) ](../Intermediate/Tf2/Writing-A-Tf2-Broadcaster-Cpp.html)\n        * [ Writing a listener (Python) ](../Intermediate/Tf2/Writing-A-Tf2-Listener-Py.html)\n        * [ Writing a listener (C++) ](../Intermediate/Tf2/Writing-A-Tf2-Listener-Cpp.html)\n        * [ Adding a frame (Python) ](../Intermediate/Tf2/Adding-A-Frame-Py.html)\n        * [ Adding a frame (C++) ](../Intermediate/Tf2/Adding-A-Frame-Cpp.html)\n        * [ Using time (Python) ](../Intermediate/Tf2/Learning-About-Tf2-And-Time-Py.html)\n        * [ Using time (C++) ](../Intermediate/Tf2/Learning-About-Tf2-And-Time-Cpp.html)\n        * [ Traveling in time (Python) ](../Intermediate/Tf2/Time-Travel-With-Tf2-Py.html)\n        * [ Traveling in time (C++) ](../Intermediate/Tf2/Time-Travel-With-Tf2-Cpp.html)\n        * [ Debugging ](../Intermediate/Tf2/Debugging-Tf2-Problems.html)\n        * [ Quaternion fundamentals ](../Intermediate/Tf2/Quaternion-Fundamentals.html)\n        * [ Using stamped datatypes with ` tf2_ros::MessageFilter  ` ](../Intermediate/Tf2/Using-Stamped-Datatypes-With-Tf2-Ros-MessageFilter.html)\n      * [ Testing ](../Intermediate/Testing/Testing-Main.html)\n        * [ Running Tests in ROS 2 from the Command Line ](../Intermediate/Testing/CLI.html)\n        * [ Writing Basic Tests with C++ with GTest ](../Intermediate/Testing/Cpp.html)\n        * [ Writing Basic Tests with Python ](../Intermediate/Testing/Python.html)\n      * [ URDF ](../Intermediate/URDF/URDF-Main.html)\n        * [ Building a visual robot model from scratch ](../Intermediate/URDF/Building-a-Visual-Robot-Model-with-URDF-from-Scratch.html)\n        * [ Building a movable robot model ](../Intermediate/URDF/Building-a-Movable-Robot-Model-with-URDF.html)\n        * [ Adding physical and collision properties ](../Intermediate/URDF/Adding-Physical-and-Collision-Properties-to-a-URDF-Model.html)\n        * [ Using Xacro to clean up your code ](../Intermediate/URDF/Using-Xacro-to-Clean-Up-a-URDF-File.html)\n        * [ Using URDF with ` robot_state_publisher  ` ](../Intermediate/URDF/Using-URDF-with-Robot-State-Publisher.html)\n    * [ Advanced ](../Advanced.html)\n      * [ Enabling topic statistics (C++) ](../Advanced/Topic-Statistics-Tutorial/Topic-Statistics-Tutorial.html)\n      * [ Using Fast DDS Discovery Server as discovery protocol [community-contributed] ](../Advanced/Discovery-Server/Discovery-Server.html)\n      * [ Implementing a custom memory allocator ](../Advanced/Allocator-Template-Tutorial.html)\n      * [ Recording a bag from a node (C++) ](../Advanced/Recording-A-Bag-From-Your-Own-Node-CPP.html)\n      * [ Simulators ](../Advanced/Simulators/Simulation-Main.html)\n        * [ Webots ](../Advanced/Simulators/Webots/Simulation-Webots.html)\n          * [ Installation (Ubuntu) ](../Advanced/Simulators/Webots/Installation-Ubuntu.html)\n          * [ Installation (Windows) ](../Advanced/Simulators/Webots/Installation-Windows.html)\n          * [ Installation (macOS) ](../Advanced/Simulators/Webots/Installation-MacOS.html)\n          * [ Setting up a robot simulation (Basic) ](../Advanced/Simulators/Webots/Setting-Up-Simulation-Webots-Basic.html)\n          * [ Setting up a robot simulation (Advanced) ](../Advanced/Simulators/Webots/Setting-Up-Simulation-Webots-Advanced.html)\n        * [ Ignition ](../Advanced/Simulators/Ignition/Simulation-Ignition.html)\n          * [ Setting up a robot simulation (Ignition Gazebo) ](../Advanced/Simulators/Ignition/Ignition.html)\n    * [ Demos ](../Demos.html)\n      * [ Using quality-of-service settings for lossy networks ](../Demos/Quality-of-Service.html)\n      * [ Managing nodes with managed lifecycles ](../Demos/Managed-Nodes.html)\n      * [ Setting up efficient intra-process communication ](../Demos/Intra-Process-Communication.html)\n      * [ Recording and playing back data with ` rosbag  ` using the ROS 1 bridge ](../Demos/Rosbag-with-ROS1-Bridge.html)\n      * [ Understanding real-time programming ](../Demos/Real-Time-Programming.html)\n      * [ Experimenting with a dummy robot ](../Demos/dummy-robot-demo.html)\n      * [ Logging ](../Demos/Logging-and-logger-configuration.html)\n    * [ Miscellaneous ](../Miscellaneous.html)\n      * [ Packaging your ROS 2 application as a snap [community-contributed] ](../Miscellaneous/Packaging-your-ROS-2-application-as-a-snap.html)\n      * [ Deploying on IBM Cloud Kubernetes [community-contributed] ](../Miscellaneous/Deploying-ROS-2-on-IBM-Cloud.html)\n      * [ Using Eclipse Oxygen with ` rviz2  ` [community-contributed] ](../Miscellaneous/Eclipse-Oxygen-with-ROS-2-and-rviz2.html)\n      * [ Building a real-time Linux kernel [community-contributed] ](../Miscellaneous/Building-Realtime-rt_preempt-kernel-for-ROS-2.html)\n      * [ Building a package with Eclipse 2021-06 ](../Miscellaneous/Building-ROS2-Package-with-eclipse-2021-06.html)\n  * [ How-to Guides ](../../How-To-Guides.html)\n    * [ Installation troubleshooting ](../../How-To-Guides/Installation-Troubleshooting.html)\n    * [ Developing a ROS 2 package ](../../How-To-Guides/Developing-a-ROS-2-Package.html)\n    * [ ament_cmake user documentation ](../../How-To-Guides/Ament-CMake-Documentation.html)\n    * [ ament_cmake_python user documentation ](../../How-To-Guides/Ament-CMake-Python-Documentation.html)\n    * [ Migrating launch files from ROS 1 to ROS 2 ](../../How-To-Guides/Launch-files-migration-guide.html)\n    * [ Using Python, XML, and YAML for ROS 2 Launch Files ](../../How-To-Guides/Launch-file-different-formats.html)\n    * [ Using ROS 2 launch to launch composable nodes ](../../How-To-Guides/Launching-composable-nodes.html)\n    * [ Migrating YAML parameter files from ROS 1 to ROS 2 ](../../How-To-Guides/Parameters-YAML-files-migration-guide.html)\n    * [ Passing ROS arguments to nodes via the command-line ](../../How-To-Guides/Node-arguments.html)\n    * [ Synchronous vs. asynchronous service clients ](../../How-To-Guides/Sync-Vs-Async.html)\n    * [ DDS tuning information ](../../How-To-Guides/DDS-tuning.html)\n    * [ rosbag2: Overriding QoS Policies ](../../How-To-Guides/Overriding-QoS-Policies-For-Recording-And-Playback.html)\n    * [ Working with multiple ROS 2 middleware implementations ](../../How-To-Guides/Working-with-multiple-RMW-implementations.html)\n    * [ Cross-compilation ](../../How-To-Guides/Cross-compilation.html)\n    * [ Releasing a Package ](../../How-To-Guides/Releasing/Releasing-a-Package.html)\n      * [ First Time Release ](../../How-To-Guides/Releasing/First-Time-Release.html)\n      * [ Subsequent Releases ](../../How-To-Guides/Releasing/Subsequent-Releases.html)\n      * [ Release Team / Repository ](../../How-To-Guides/Releasing/Release-Team-Repository.html)\n      * [ Release Track ](../../How-To-Guides/Releasing/Release-Track.html)\n    * [ Using Python Packages with ROS 2 ](../../How-To-Guides/Using-Python-Packages.html)\n    * [ Porting RQt plugins to Windows ](../../How-To-Guides/RQt-Port-Plugin-Windows.html)\n    * [ Running ROS 2 nodes in Docker [community-contributed] ](../../How-To-Guides/Run-2-nodes-in-single-or-separate-docker-containers.html)\n    * [ Visualizing ROS 2 data with Foxglove Studio ](../../How-To-Guides/Visualizing-ROS-2-Data-With-Foxglove-Studio.html)\n    * [ ROS 2 Package Maintainer Guide ](../../How-To-Guides/Package-maintainer-guide.html)\n    * [ Building a custom Debian package ](../../How-To-Guides/Building-a-Custom-Debian-Package.html)\n    * [ Building ROS 2 with tracing instrumentation ](../../How-To-Guides/Building-ROS-2-with-Tracing-Instrumentation.html)\n    * [ Topics vs Services vs Actions ](../../How-To-Guides/Topics-Services-Actions.html)\n    * [ Using variants ](../../How-To-Guides/Using-Variants.html)\n    * [ Using the ` ros2  param  ` command-line tool ](../../How-To-Guides/Using-ros2-param.html)\n    * [ ROS 2 on Raspberry Pi ](../../How-To-Guides/Installing-on-Raspberry-Pi.html)\n    * [ Using Callback Groups ](../../How-To-Guides/Using-callback-groups.html)\n    * [ Setup ROS 2 with VSCode and Docker [community-contributed] ](../../How-To-Guides/Setup-ROS-2-with-VSCode-and-Docker-Container.html)\n    * [ Building RQt from source ](../../How-To-Guides/RQt-Source-Install.html)\n      * [ Building RQt from source on macOS ](../../How-To-Guides/RQt-Source-Install-MacOS.html)\n      * [ Building RQt from source on Windows 10 ](../../How-To-Guides/RQt-Source-Install-Windows10.html)\n  * [ Concepts ](../../Concepts.html)\n    * [ The ROS_DOMAIN_ID ](../../Concepts/About-Domain-ID.html)\n    * [ About different ROS 2 DDS/RTPS vendors ](../../Concepts/About-Different-Middleware-Vendors.html)\n    * [ About logging and logger configuration ](../../Concepts/About-Logging.html)\n    * [ About Quality of Service settings ](../../Concepts/About-Quality-of-Service-Settings.html)\n    * [ About ROS 2 client libraries ](../../Concepts/About-ROS-2-Client-Libraries.html)\n    * [ About ROS 2 interfaces ](../../Concepts/About-ROS-Interfaces.html)\n    * [ About parameters in ROS 2 ](../../Concepts/About-ROS-2-Parameters.html)\n    * [ Executors ](../../Concepts/About-Executors.html)\n    * [ About topic statistics ](../../Concepts/About-Topic-Statistics.html)\n    * [ Introspection with command line tools ](../../Concepts/About-Command-Line-Tools.html)\n    * [ Overview and usage of RQt ](../../Concepts/About-RQt.html)\n    * [ About Composition ](../../Concepts/About-Composition.html)\n    * [ On the mixing of ament and catkin (catment) ](../../Concepts/About-Catment.html)\n    * [ About Cross-compilation ](../../Concepts/About-Cross-Compilation.html)\n    * [ About tf2 ](../../Concepts/About-Tf2.html)\n    * [ About the build system ](../../Concepts/About-Build-System.html)\n    * [ About internal ROS 2 interfaces ](../../Concepts/About-Internal-Interfaces.html)\n    * [ About ROS 2 middleware implementations ](../../Concepts/About-Middleware-Implementations.html)\n    * [ About ROS 2 client libraries ](../../Concepts/About-ROS-2-Client-Libraries.html)\n  * [ Contact ](../../Contact.html)\n  * [ The ROS 2 Project ](../../The-ROS2-Project.html)\n    * [ Contributing ](../../The-ROS2-Project/Contributing.html)\n      * [ ROS 2 developer guide ](../../The-ROS2-Project/Contributing/Developer-Guide.html)\n      * [ Code style and language versions ](../../The-ROS2-Project/Contributing/Code-Style-Language-Versions.html)\n      * [ Quality guide: ensuring code quality ](../../The-ROS2-Project/Contributing/Quality-Guide.html)\n      * [ Migration guide from ROS 1 ](../../The-ROS2-Project/Contributing/Migration-Guide.html)\n        * [ Python migration guide from ROS 1 ](../../The-ROS2-Project/Contributing/Migration-Guide-Python.html)\n      * [ ROS Build Farms ](../../The-ROS2-Project/Contributing/Build-Farms.html)\n      * [ Windows Tips and Tricks ](../../The-ROS2-Project/Contributing/Windows-Tips-and-Tricks.html)\n      * [ Contributing to ROS 2 Documentation ](../../The-ROS2-Project/Contributing/Contributing-To-ROS-2-Documentation.html)\n    * [ Features Status ](../../The-ROS2-Project/Features.html)\n    * [ Feature Ideas ](../../The-ROS2-Project/Feature-Ideas.html)\n    * [ Roadmap ](../../The-ROS2-Project/Roadmap.html)\n    * [ ROSCon Talks ](../../The-ROS2-Project/ROSCon-Content.html)\n    * [ Project Governance ](../../The-ROS2-Project/Governance.html)\n      * [ ROS 2 Technical Steering Committee Charter ](../../The-ROS2-Project/Governance/ROS2-TSC-Charter.html)\n      * [ ROS 2 TSC applicant intake process ](../../The-ROS2-Project/Governance/ROS2-TSC-Intake-process.html)\n      * [ How to Start a Community Working Group ](../../The-ROS2-Project/Governance/How-To-Start-A-Community-Working-Group.html)\n    * [ Marketing ](../../The-ROS2-Project/Marketing.html)\n  * [ Related Projects ](../../Related-Projects.html)\n    * [ Intel ROS 2 Projects ](../../Related-Projects/Intel-ROS2-Projects.html)\n    * [ NVIDIA ROS 2 Projects ](../../Related-Projects/Nvidia-ROS2-Projects.html)\n  * [ Glossary ](../../Glossary.html)\n  * [ Citations ](../../Citations.html)\n\n__ [ ROS 2 Documentation: Foxy ](../../index.html)\n\n  * [ ](../../index.html)\n  * [ Tutorials ](../../Tutorials.html)\n  * [ Beginner: Client libraries ](../Beginner-Client-Libraries.html)\n  * Using parameters in a class (Python) \n  * [ Edit on GitHub ](https://github.com/ros2/ros2_documentation/blob/foxy/source/Tutorials/Beginner-Client-Libraries/Using-Parameters-In-A-Class-Python.rst)\n\n* * *\n\n**You're reading the documentation for a version of ROS 2 that has reached its\nEOL (end-of-life), and is no longer officially supported. If you want up-to-\ndate information, please have a look at[ Iron\n](../../../iron/Tutorials/Beginner-Client-Libraries/Using-Parameters-In-A-\nClass-Python.html) . **\n\n#  Using parameters in a class (Python)  \u00ef\u0083\u0081\n\n**Goal:** Create and run a class with ROS parameters using Python.\n\n**Tutorial level:** Beginner\n\n**Time:** 20 minutes\n\nContents\n\n  * Background \n\n  * Prerequisites \n\n  * Tasks \n\n    * 1 Create a package \n\n    * 2 Write the Python node \n\n    * 3 Build and run \n\n  * Summary \n\n  * Next steps \n\n##  Background  \u00ef\u0083\u0081\n\nWhen making your own [ nodes  ](../Beginner-CLI-Tools/Understanding-\nROS2-Nodes/Understanding-ROS2-Nodes.html) you will sometimes need to add\nparameters that can be set from the launch file.\n\nThis tutorial will show you how to create those parameters in a Python class,\nand how to set them in a launch file.\n\n##  Prerequisites  \u00ef\u0083\u0081\n\nIn previous tutorials, you learned how to [ create a workspace  ](Creating-A-\nWorkspace/Creating-A-Workspace.html) and [ create a package  ](Creating-Your-\nFirst-ROS2-Package.html) . You have also learned about [ parameters\n](../Beginner-CLI-Tools/Understanding-ROS2-Parameters/Understanding-\nROS2-Parameters.html) and their function in a ROS 2 system.\n\n##  Tasks  \u00ef\u0083\u0081\n\n###  1 Create a package  \u00ef\u0083\u0081\n\nOpen a new terminal and [ source your ROS 2 installation  ](../Beginner-CLI-\nTools/Configuring-ROS2-Environment.html) so that ` ros2  ` commands will work.\n\nFollow [ these instructions  ](Creating-A-Workspace/Creating-A-\nWorkspace.html#new-directory) to create a new workspace named ` ros2_ws  ` .\n\nRecall that packages should be created in the ` src  ` directory, not the root\nof the workspace. Navigate into ` ros2_ws/src  ` and create a new package:\n\n    \n    \n    ros2 pkg create --build-type ament_python python_parameters --dependencies rclpy\n    \n\nYour terminal will return a message verifying the creation of your package `\npython_parameters  ` and all its necessary files and folders.\n\nThe ` --dependencies  ` argument will automatically add the necessary\ndependency lines to ` package.xml  ` and ` CMakeLists.txt  ` .\n\n####  1.1 Update ` package.xml  ` \u00ef\u0083\u0081\n\nBecause you used the ` --dependencies  ` option during package creation, you\ndon\u00e2\u0080\u0099t have to manually add dependencies to ` package.xml  ` or `\nCMakeLists.txt  ` .\n\nAs always, though, make sure to add the description, maintainer email and\nname, and license information to ` package.xml  ` .\n\n    \n    \n    <description>Python parameter tutorial</description>\n    <maintainer email=\"you@email.com\">Your Name</maintainer>\n    <license>Apache License 2.0</license>\n    \n\n###  2 Write the Python node  \u00ef\u0083\u0081\n\nInside the ` ros2_ws/src/python_parameters/python_parameters  ` directory,\ncreate a new file called ` python_parameters_node.py  ` and paste the\nfollowing code within:\n\n    \n    \n    import rclpy\n    import rclpy.node\n    \n    class MinimalParam(rclpy.node.Node):\n        def __init__(self):\n            super().__init__('minimal_param_node')\n    \n            self.declare_parameter('my_parameter', 'world')\n    \n            self.timer = self.create_timer(1, self.timer_callback)\n    \n        def timer_callback(self):\n            my_param = self.get_parameter('my_parameter').get_parameter_value().string_value\n    \n            self.get_logger().info('Hello %s!' % my_param)\n    \n            my_new_param = rclpy.parameter.Parameter(\n                'my_parameter',\n                rclpy.Parameter.Type.STRING,\n                'world'\n            )\n            all_new_parameters = [my_new_param]\n            self.set_parameters(all_new_parameters)\n    \n    def main():\n        rclpy.init()\n        node = MinimalParam()\n        rclpy.spin(node)\n    \n    if __name__ == '__main__':\n        main()\n    \n\n####  2.1 Examine the code  \u00ef\u0083\u0081\n\nThe ` import  ` statements at the top are used to import the package\ndependencies.\n\nThe next piece of code creates the class and the constructor. The line `\nself.declare_parameter('my_parameter',  'world')  ` of the constructor creates\na parameter with the name ` my_parameter  ` and a default value of ` world  `\n. The parameter type is inferred from the default value, so in this case it\nwould be set to a string type. Next the ` timer  ` is initialized with a\nperiod of 1, which causes the ` timer_callback  ` function to be executed once\na second.\n\n    \n    \n    class MinimalParam(rclpy.node.Node):\n        def __init__(self):\n            super().__init__('minimal_param_node')\n    \n            self.declare_parameter('my_parameter', 'world')\n    \n            self.timer = self.create_timer(1, self.timer_callback)\n    \n\nThe first line of our ` timer_callback  ` function gets the parameter `\nmy_parameter  ` from the node, and stores it in ` my_param  ` . Next the `\nget_logger  ` function ensures the event is logged. The ` set_parameters  `\nfunction then sets the parameter ` my_parameter  ` back to the default string\nvalue ` world  ` . In the case that the user changed the parameter externally,\nthis ensures it is always reset back to the original.\n\n    \n    \n    def timer_callback(self):\n        my_param = self.get_parameter('my_parameter').get_parameter_value().string_value\n    \n        self.get_logger().info('Hello %s!' % my_param)\n    \n        my_new_param = rclpy.parameter.Parameter(\n            'my_parameter',\n            rclpy.Parameter.Type.STRING,\n            'world'\n        )\n        all_new_parameters = [my_new_param]\n        self.set_parameters(all_new_parameters)\n    \n\nFollowing the ` timer_callback  ` is our ` main  ` . Here ROS 2 is\ninitialized, an instance of the ` MinimalParam  ` class is constructed, and `\nrclpy.spin  ` starts processing data from the node.\n\n    \n    \n    def main():\n        rclpy.init()\n        node = MinimalParam()\n        rclpy.spin(node)\n    \n    if __name__ == '__main__':\n        main()\n    \n\n#####  2.1.1 (Optional) Add ParameterDescriptor  \u00ef\u0083\u0081\n\nOptionally, you can set a descriptor for the parameter. Descriptors allow you\nto specify a text description of the parameter and its constraints, like\nmaking it read-only, specifying a range, etc. For that to work, the ` __init__\n` code has to be changed to:\n\n    \n    \n    # ...\n    \n    class MinimalParam(rclpy.node.Node):\n        def __init__(self):\n            super().__init__('minimal_param_node')\n    \n            from rcl_interfaces.msg import ParameterDescriptor\n            my_parameter_descriptor = ParameterDescriptor(description='This parameter is mine!')\n    \n            self.declare_parameter('my_parameter', 'world', my_parameter_descriptor)\n    \n            self.timer = self.create_timer(1, self.timer_callback)\n    \n\nThe rest of the code remains the same. Once you run the node, you can then run\n` ros2  param  describe  /minimal_param_node  my_parameter  ` to see the type\nand description.\n\n####  2.2 Add an entry point  \u00ef\u0083\u0081\n\nOpen the ` setup.py  ` file. Again, match the ` maintainer  ` , `\nmaintainer_email  ` , ` description  ` and ` license  ` fields to your `\npackage.xml  ` :\n\n    \n    \n    maintainer='YourName',\n    maintainer_email='you@email.com',\n    description='Python parameter tutorial',\n    license='Apache License 2.0',\n    \n\nAdd the following line within the ` console_scripts  ` brackets of the `\nentry_points  ` field:\n\n    \n    \n    entry_points={\n        'console_scripts': [\n            'minimal_param_node = python_parameters.python_parameters_node:main',\n        ],\n    },\n    \n\nDon\u00e2\u0080\u0099t forget to save.\n\n###  3 Build and run  \u00ef\u0083\u0081\n\nIt\u00e2\u0080\u0099s good practice to run ` rosdep  ` in the root of your workspace ( `\nros2_ws  ` ) to check for missing dependencies before building:\n\nLinux  macOS  Windows\n\n    \n    \n    rosdep install -i --from-path src --rosdistro foxy -y\n    \n\nrosdep only runs on Linux, so you can skip ahead to next step.\n\nrosdep only runs on Linux, so you can skip ahead to next step.\n\nNavigate back to the root of your workspace, ` ros2_ws  ` , and build your new\npackage:\n\nLinux  macOS  Windows\n\n    \n    \n    colcon build --packages-select python_parameters\n    \n    \n    \n    colcon build --packages-select python_parameters\n    \n    \n    \n    colcon build --merge-install --packages-select python_parameters\n    \n\nOpen a new terminal, navigate to ` ros2_ws  ` , and source the setup files:\n\nLinux  macOS  Windows\n\n    \n    \n    source install/setup.bash\n    \n    \n    \n    . install/setup.bash\n    \n    \n    \n    call install/setup.bat\n    \n\nNow run the node:\n\n    \n    \n    ros2 run python_parameters minimal_param_node\n    \n\nThe terminal should return the following message every second:\n\n    \n    \n    [INFO] [parameter_node]: Hello world!\n    \n\nNow you can see the default value of your parameter, but you want to be able\nto set it yourself. There are two ways to accomplish this.\n\n####  3.1 Change via the console  \u00ef\u0083\u0081\n\nThis part will use the knowledge you have gained from the [ tutoral about\nparameters  ](../Beginner-CLI-Tools/Understanding-\nROS2-Parameters/Understanding-ROS2-Parameters.html) and apply it to the node\nyou have just created.\n\nMake sure the node is running:\n\n    \n    \n    ros2 run python_parameters minimal_param_node\n    \n\nOpen another terminal, source the setup files from inside ` ros2_ws  ` again,\nand enter the following line:\n\n    \n    \n    ros2 param list\n    \n\nThere you will see the custom parameter ` my_parameter  ` . To change it,\nsimply run the following line in the console:\n\n    \n    \n    ros2 param set /minimal_param_node my_parameter earth\n    \n\nYou know it went well if you get the output ` Set  parameter  successful  ` .\nIf you look at the other terminal, you should see the output change to `\n[INFO]  [minimal_param_node]:  Hello  earth!  `\n\nSince the node afterwards set the parameter back to ` world  ` , further\noutputs show ` [INFO]  [minimal_param_node]:  Hello  world!  `\n\n####  3.2 Change via a launch file  \u00ef\u0083\u0081\n\nYou can also set parameters in a launch file, but first you will need to add a\nlaunch directory. Inside the ` ros2_ws/src/python_parameters/  ` directory,\ncreate a new directory called ` launch  ` . In there, create a new file called\n` python_parameters_launch.py  `\n\n    \n    \n    from launch import LaunchDescription\n    from launch_ros.actions import Node\n    \n    def generate_launch_description():\n        return LaunchDescription([\n            Node(\n                package='python_parameters',\n                executable='minimal_param_node',\n                name='custom_minimal_param_node',\n                output='screen',\n                emulate_tty=True,\n                parameters=[\n                    {'my_parameter': 'earth'}\n                ]\n            )\n        ])\n    \n\nHere you can see that we set ` my_parameter  ` to ` earth  ` when we launch\nour node ` parameter_node  ` . By adding the two lines below, we ensure our\noutput is printed in our console.\n\n    \n    \n    output=\"screen\",\n    emulate_tty=True,\n    \n\nNow open the ` setup.py  ` file. Add the ` import  ` statements to the top of\nthe file, and the other new statement to the ` data_files  ` parameter to\ninclude all launch files:\n\n    \n    \n    import os\n    from glob import glob\n    # ...\n    \n    setup(\n      # ...\n      data_files=[\n          # ...\n          (os.path.join('share', package_name), glob('launch/*launch.[pxy][yma]*')),\n        ]\n      )\n    \n\nOpen a console and navigate to the root of your workspace, ` ros2_ws  ` , and\nbuild your new package:\n\nLinux  macOS  Windows\n\n    \n    \n    colcon build --packages-select python_parameters\n    \n    \n    \n    colcon build --packages-select python_parameters\n    \n    \n    \n    colcon build --merge-install --packages-select python_parameters\n    \n\nThen source the setup files in a new terminal:\n\nLinux  macOS  Windows\n\n    \n    \n    source install/setup.bash\n    \n    \n    \n    . install/setup.bash\n    \n    \n    \n    call install/setup.bat\n    \n\nNow run the node using the launch file we have just created:\n\n    \n    \n    ros2 launch python_parameters python_parameters_launch.py\n    \n\nThe terminal should return the following message every second:\n\n    \n    \n    [INFO] [custom_minimal_param_node]: Hello earth!\n    \n\n##  Summary  \u00ef\u0083\u0081\n\nYou created a node with a custom parameter that can be set either from a\nlaunch file or the command line. You added the dependencies, executables, and\na launch file to the package configuration files so that you could build and\nrun them, and see the parameter in action.\n\n##  Next steps  \u00ef\u0083\u0081\n\nNow that you have some packages and ROS 2 systems of your own, the [ next\ntutorial  ](Getting-Started-With-Ros2doctor.html) will show you how to examine\nissues in your environment and systems in case you have problems.\n\n[ Previous ](Using-Parameters-In-A-Class-CPP.html \"Using parameters in a class\n\\(C++\\)\") [ Next  ](Getting-Started-With-Ros2doctor.html \"Using ros2doctor to\nidentify issues\")\n\n* * *\n\n\u00a9 Copyright 2024, Open Robotics.\n\nBuilt with [ Sphinx ](https://www.sphinx-doc.org/) using a [ theme\n](https://github.com/readthedocs/sphinx_rtd_theme) provided by [ Read the Docs\n](https://readthedocs.org) .\n\nOther Versions  v: foxy\n\nReleases\n\n     [ Iron (latest) ](../../../iron/Tutorials/Beginner-Client-Libraries/Using-Parameters-In-A-Class-Python.html)\n     [ Humble ](../../../humble/Tutorials/Beginner-Client-Libraries/Using-Parameters-In-A-Class-Python.html)\n     [ Galactic (EOL) ](../../../galactic/Tutorials/Beginner-Client-Libraries/Using-Parameters-In-A-Class-Python.html)\n     [ Foxy (EOL) ](Using-Parameters-In-A-Class-Python.html)\n     [ Eloquent (EOL) ](../../../eloquent/index.html)\n     [ Dashing (EOL) ](../../../dashing/index.html)\n     [ Crystal (EOL) ](../../../crystal/index.html)\n\nIn Development\n\n     [ Rolling ](../../../rolling/Tutorials/Beginner-Client-Libraries/Using-Parameters-In-A-Class-Python.html)\n\n"
  },
  {
    "id": "rviz_browser/rosbridgesuite.txt",
    "content": "[ ![ros.org](/custom/images/ros_org.png) ](/) |  [ About\n](http://www.ros.org/about-ros) | [ Support ](/Support) | [ Discussion Forum\n](http://discourse.ros.org/) | [ Index ](http://index.ros.org/) | [ Service\nStatus ](http://status.ros.org/) | [ ros @ Robotics Stack Exchange\n](https://robotics.stackexchange.com/questions/tagged/ros)  \n---|---  \n![](/custom/images/menu_left.png) [\n![Documentation](/custom/images/menu_documentation.png) ](/)\n![](/custom/images/menu_spacer.png) [ ![Browse\nSoftware](/custom/images/menu_browse_software.png)\n](https://index.ros.org/packages) ![](/custom/images/menu_spacer.png) [\n![News](/custom/images/menu_news.png) ](https://discourse.ros.org/c/general)\n![](/custom/images/menu_spacer.png) [\n![Download](/custom/images/menu_download.png) ](/ROS/Installation)\n![](/custom/images/menu_right.png)  \n  \n  * [ rosbridge_suite ](/rosbridge_suite)\n####  ROS 2 Documentation\nThe ROS Wiki is for ROS 1. Are you using ROS 2 ( [ Humble\n](http://docs.ros.org/en/humble/) , [ Iron ](http://docs.ros.org/en/iron/) ,\nor [ Rolling ](http://docs.ros.org/en/rolling/) )?  \n[ Check out the ROS 2 Project Documentation ](http://docs.ros.org)  \nPackage specific documentation can be found on [ index.ros.org\n](https://index.ros.org)\n#  Wiki\n  * [ Distributions ](/Distributions)\n  * [ ROS/Installation ](/ROS/Installation)\n  * [ ROS/Tutorials ](/ROS/Tutorials)\n  * [ RecentChanges ](/RecentChanges)\n  * [ rosbridge_suite ](/rosbridge_suite)\n#  Page\n  * Immutable Page \n  * Comments \n  * [ Info ](/action/info/rosbridge_suite?action=info)\n  * [ Attachments ](/action/AttachFile/rosbridge_suite?action=AttachFile)\n  * More Actions:  Raw Text  Print View  Render as Docbook  Delete Cache  \\------------------------  Check Spelling  Like Pages  Local Site Map  \\------------------------  Rename Page  Copy Page  Delete Page  \\------------------------  My Pages  Subscribe User  \\------------------------  Remove Spam  Revert to this revision  Package Pages  Sync Pages  \\------------------------  CreatePdfDocument  Load  RawFile  Save  SlideShow \n#  User\n  * [ Login ](/action/login/rosbridge_suite?action=login)\nmelodic  noetic  _Show EOL distros:_\n_EOL distros:_ fuerte  groovy  hydro  indigo  jade  kinetic  lunar\n\n\n\n[ Documentation Status ](javascript:toggleDocStatus\\(\\))\n  * **fuerte:** _Documentation generated on January 02, 2014 at 11:52 AM_\n  \n  * **groovy:** _Documentation generated on October 06, 2014 at 06:58 AM_\n  \n  * **hydro:** _Documentation generated on August 27, 2015 at 02:50 PM_ ( [ doc job ](http://jenkins.ros.org/job/doc-hydro-rosbridge_suite/) ). \n  \n  * **indigo:** _Documentation generated on June 07, 2019 at 05:45 AM_ ( [ doc job ](http://build.ros.org/view/Idoc/job/Idoc__rosbridge_suite__ubuntu_trusty_amd64) ). \n  \n  * **jade:** _Documentation generated on September 13, 2017 at 11:00 AM_ ( [ doc job ](http://build.ros.org/view/Jdoc/job/Jdoc__rosbridge_suite__ubuntu_trusty_amd64) ). \n  \n  * **kinetic:** _Documentation generated on June 03, 2020 at 03:52 AM_ ( [ doc job ](http://build.ros.org/view/Kdoc/job/Kdoc__rosbridge_suite__ubuntu_xenial_amd64) ). \n  \n  * **lunar:** _Documentation generated on May 10, 2019 at 10:14 AM_ ( [ doc job ](http://build.ros.org/view/Ldoc/job/Ldoc__rosbridge_suite__ubuntu_xenial_amd64) ). \n  \n  * **melodic:** _Documentation generated on October 21, 2022 at 10:41 AM_ ( [ doc job ](https://build.ros.org/view/Mdoc/job/Mdoc__rosbridge_suite__ubuntu_bionic_amd64) ). \n  \n  * **noetic:** _Documentation generated on October 03, 2023 at 10:09 AM_ ( [ doc job ](https://build.ros.org/view/Ndoc/job/Ndoc__rosbridge_suite__ubuntu_focal_amd64) ). \n  \n_**rosbridge_suite** : [ rosapi ](/rosapi?distro=fuerte) | [ rosbridge_launch\n](/rosbridge_launch?distro=fuerte) | [ rosbridge_library\n](/rosbridge_library?distro=fuerte) | [ rosbridge_server\n](/rosbridge_server?distro=fuerte) | [ rosbridge_test\n](/rosbridge_test?distro=fuerte) | [ roswww ](/roswww?distro=fuerte) | [\ntf_smart_throttle ](/tf_smart_throttle?distro=fuerte) _  \n**Package Links**\n  * [ rosbridge_suite website ](http://www.rosbridge.org)\n  * [ Tutorials ](/rosbridge_suite/Tutorials)\n  * [ FAQ ](http://answers.ros.org/questions/scope:all/sort:activity-desc/tags:rosbridge_suite/page:1/)\n  * [ Change List ](/rosbridge_suite/ChangeList)\n  * [ Reviews ](/rosbridge_suite/Reviews)\n** Dependencies  (4) **  \n  * [ geometry ](/geometry?distro=fuerte)\n  * [ ros ](/ros?distro=fuerte)\n  * [ ros_comm ](/ros_comm?distro=fuerte)\n  * [ std_msgs ](/std_msgs?distro=fuerte)\n** Used by  (1) **  \n  * [ bosch_web_visualizat... ](/bosch_web_visualization?distro=fuerte)\n#  Package Summary\nDocumented\n\n\n\nA set of packages which provide various web-related functionality and expose\nvarious aspects of ROS to the outside world. At its core, rosbridge is a\nwebsockets server with a JSON API exposing ROS service and pub/sub\nfunctionality. Additional packages provide convenience functions, and handling\nfor specific datatypes.\n  * Author: Maintained by Jonathan Mace \n  * License: BSD \n  * External website: [ http://www.rosbridge.org ](http://www.rosbridge.org)\n  * Source: git [ https://github.com/RobotWebTools/rosbridge_suite.git ](https://github.com/RobotWebTools/rosbridge_suite) (branch: fuerte-devel) \n_**rosbridge_suite** : [ rosapi ](/rosapi?distro=groovy) | [ rosbridge_library\n](/rosbridge_library?distro=groovy) | [ rosbridge_server\n](/rosbridge_server?distro=groovy) _  \n**Package Links**\n  * [ rosbridge_suite website ](https://github.com/RobotWebTools/rosbridge_suite)\n  * [ Tutorials ](/rosbridge_suite/Tutorials)\n  * [ FAQ ](http://answers.ros.org/questions/scope:all/sort:activity-desc/tags:rosbridge_suite/page:1/)\n  * [ Changelog ](http://docs.ros.org/en/groovy/changelogs/rosbridge_suite/changelog.html)\n  * [ Change List ](/rosbridge_suite/ChangeList)\n  * [ Reviews ](/rosbridge_suite/Reviews)\n** Dependencies  (4) **  \n  * [ catkin ](/catkin?distro=groovy)\n  * [ rosapi ](/rosapi?distro=groovy)\n  * [ rosbridge_library ](/rosbridge_library?distro=groovy)\n  * [ rosbridge_server ](/rosbridge_server?distro=groovy)\n** Used by  (1) **  \n  * [ robot_web_tools ](/robot_web_tools?distro=groovy)\n#  Package Summary\nReleased\nContinuous Integration\nDocumented\nRosbridge provides a JSON API to ROS functionality for non-ROS programs. There\nare a variety of front ends that interface with rosbridge, including a\nWebSocket server for web browsers to interact with. Rosbridge_suite is a meta-\npackage containing rosbridge, various front end packages for rosbridge like a\nWebSocket package, and helper packages.\n  * Maintainer status: maintained \n  * Maintainer: Brandon Alexander <baalexander AT gmail DOT com>, Jihoon Lee <jihoonlee.in AT gmail DOT com>, Russell Toris <rctoris AT wpi DOT edu>\n  * Author: Jonathan Mace <jonathan.c.mace AT gmail DOT com>\n  * License: BSD \n  * External website: [ https://github.com/RobotWebTools/rosbridge_suite ](https://github.com/RobotWebTools/rosbridge_suite)\n\n\n\n  * Source: git [ https://github.com/RobotWebTools/rosbridge_suite.git ](https://github.com/RobotWebTools/rosbridge_suite) (branch: master) \n_**rosbridge_suite** : [ rosapi ](/rosapi?distro=hydro) | [ rosbridge_library\n](/rosbridge_library?distro=hydro) | [ rosbridge_server\n](/rosbridge_server?distro=hydro) _  \n**Package Links**\n  * [ Tutorials ](/rosbridge_suite/Tutorials)\n  * [ FAQ ](http://answers.ros.org/questions/scope:all/sort:activity-desc/tags:rosbridge_suite/page:1/)\n  * [ Changelog ](http://docs.ros.org/en/hydro/changelogs/rosbridge_suite/changelog.html)\n  * [ Change List ](/rosbridge_suite/ChangeList)\n  * [ Reviews ](/rosbridge_suite/Reviews)\n** Dependencies  (4) **  \n  * [ catkin ](/catkin?distro=hydro)\n  * [ rosapi ](/rosapi?distro=hydro)\n  * [ rosbridge_library ](/rosbridge_library?distro=hydro)\n  * [ rosbridge_server ](/rosbridge_server?distro=hydro)\n** Used by  (1) **  \n  * [ robot_web_tools ](/robot_web_tools?distro=hydro)\n#  Package Summary\nReleased\nContinuous Integration\nDocumented\nRosbridge provides a JSON API to ROS functionality for non-ROS programs. There\nare a variety of front ends that interface with rosbridge, including a\nWebSocket server for web browsers to interact with. Rosbridge_suite is a meta-\npackage containing rosbridge, various front end packages for rosbridge like a\nWebSocket package, and helper packages.\n  * Maintainer status: maintained \n  * Maintainer: Russell Toris <rctoris AT wpi DOT edu>, Jihoon Lee <jihoonlee.in AT gmail DOT com>\n  * Author: Jonathan Mace <jonathan.c.mace AT gmail DOT com>\n  * License: BSD \n  * Bug / feature tracker: [ https://github.com/RobotWebTools/rosbridge_suite/issues ](https://github.com/RobotWebTools/rosbridge_suite/issues)\n  * Source: git [ https://github.com/RobotWebTools/rosbridge_suite.git ](https://github.com/RobotWebTools/rosbridge_suite) (branch: master) \n_**rosbridge_suite** : [ rosapi ](/rosapi?distro=indigo) | [ rosbridge_library\n](/rosbridge_library?distro=indigo) | [ rosbridge_server\n](/rosbridge_server?distro=indigo) _  \n**Package Links**\n  * [ Tutorials ](/rosbridge_suite/Tutorials)\n  * [ FAQ ](http://answers.ros.org/questions/scope:all/sort:activity-desc/tags:rosbridge_suite/page:1/)\n  * [ Changelog ](http://docs.ros.org/en/indigo/changelogs/rosbridge_suite/changelog.html)\n  * [ Change List ](/rosbridge_suite/ChangeList)\n\n\n\n  * [ Reviews ](/rosbridge_suite/Reviews)\n** Dependencies  (4) **  \n  * [ catkin ](/catkin?distro=indigo)\n  * [ rosapi ](/rosapi?distro=indigo)\n  * [ rosbridge_library ](/rosbridge_library?distro=indigo)\n  * [ rosbridge_server ](/rosbridge_server?distro=indigo)\n#  Package Summary\nReleased\nContinuous Integration\nDocumented\nRosbridge provides a JSON API to ROS functionality for non-ROS programs. There\nare a variety of front ends that interface with rosbridge, including a\nWebSocket server for web browsers to interact with. Rosbridge_suite is a meta-\npackage containing rosbridge, various front end packages for rosbridge like a\nWebSocket package, and helper packages.\n  * Maintainer status: maintained \n  * Maintainer: Russell Toris <rctoris AT wpi DOT edu>, Jihoon Lee <jihoonlee.in AT gmail DOT com>\n  * Author: Jonathan Mace <jonathan.c.mace AT gmail DOT com>\n  * License: BSD \n  * Bug / feature tracker: [ https://github.com/RobotWebTools/rosbridge_suite/issues ](https://github.com/RobotWebTools/rosbridge_suite/issues)\n  * Source: git [ https://github.com/RobotWebTools/rosbridge_suite.git ](https://github.com/RobotWebTools/rosbridge_suite) (branch: indigo) \n_**rosbridge_suite** : [ rosapi ](/rosapi?distro=jade) | [ rosbridge_library\n](/rosbridge_library?distro=jade) | [ rosbridge_server\n](/rosbridge_server?distro=jade) _  \n**Package Links**\n  * [ Tutorials ](/rosbridge_suite/Tutorials)\n  * [ FAQ ](http://answers.ros.org/questions/scope:all/sort:activity-desc/tags:rosbridge_suite/page:1/)\n  * [ Changelog ](http://docs.ros.org/en/jade/changelogs/rosbridge_suite/changelog.html)\n  * [ Change List ](/rosbridge_suite/ChangeList)\n  * [ Reviews ](/rosbridge_suite/Reviews)\n** Dependencies  (4) **  \n  * [ catkin ](/catkin?distro=jade)\n  * [ rosapi ](/rosapi?distro=jade)\n  * [ rosbridge_library ](/rosbridge_library?distro=jade)\n  * [ rosbridge_server ](/rosbridge_server?distro=jade)\n#  Package Summary\nReleased\nContinuous Integration\nDocumented\nRosbridge provides a JSON API to ROS functionality for non-ROS programs. There\n\n\n\nare a variety of front ends that interface with rosbridge, including a\nWebSocket server for web browsers to interact with. Rosbridge_suite is a meta-\npackage containing rosbridge, various front end packages for rosbridge like a\nWebSocket package, and helper packages.\n  * Maintainer status: maintained \n  * Maintainer: Russell Toris <rctoris AT wpi DOT edu>, Jihoon Lee <jihoonlee.in AT gmail DOT com>\n  * Author: Jonathan Mace <jonathan.c.mace AT gmail DOT com>\n  * License: BSD \n  * Bug / feature tracker: [ https://github.com/RobotWebTools/rosbridge_suite/issues ](https://github.com/RobotWebTools/rosbridge_suite/issues)\n  * Source: git [ https://github.com/RobotWebTools/rosbridge_suite.git ](https://github.com/RobotWebTools/rosbridge_suite) (branch: master) \n_**rosbridge_suite** : [ rosapi ](/rosapi?distro=kinetic) | [\nrosbridge_library ](/rosbridge_library?distro=kinetic) | [ rosbridge_server\n](/rosbridge_server?distro=kinetic) _  \n**Package Links**\n  * [ Tutorials ](/rosbridge_suite/Tutorials)\n  * [ FAQ ](http://answers.ros.org/questions/scope:all/sort:activity-desc/tags:rosbridge_suite/page:1/)\n  * [ Changelog ](http://docs.ros.org/en/kinetic/changelogs/rosbridge_suite/changelog.html)\n  * [ Change List ](/rosbridge_suite/ChangeList)\n  * [ Reviews ](/rosbridge_suite/Reviews)\n** Dependencies  (4) **  \n  * [ catkin ](/catkin?distro=kinetic)\n  * [ rosapi ](/rosapi?distro=kinetic)\n  * [ rosbridge_library ](/rosbridge_library?distro=kinetic)\n  * [ rosbridge_server ](/rosbridge_server?distro=kinetic)\n#  Package Summary\nReleased\nContinuous Integration\nDocumented\nRosbridge provides a JSON API to ROS functionality for non-ROS programs. There\nare a variety of front ends that interface with rosbridge, including a\nWebSocket server for web browsers to interact with. Rosbridge_suite is a meta-\npackage containing rosbridge, various front end packages for rosbridge like a\nWebSocket package, and helper packages.\n  * Maintainer status: maintained \n  * Maintainer: Russell Toris <rctoris AT wpi DOT edu>, Jihoon Lee <jihoonlee.in AT gmail DOT com>\n  * Author: Jonathan Mace <jonathan.c.mace AT gmail DOT com>\n  * License: BSD \n  * Bug / feature tracker: [ https://github.com/RobotWebTools/rosbridge_suite/issues ](https://github.com/RobotWebTools/rosbridge_suite/issues)\n  * Source: git [ https://github.com/RobotWebTools/rosbridge_suite.git ](https://github.com/RobotWebTools/rosbridge_suite) (branch: master) \n_**rosbridge_suite** : [ rosapi ](/rosapi?distro=lunar) | [ rosbridge_library\n\n\n\n](/rosbridge_library?distro=lunar) | [ rosbridge_server\n](/rosbridge_server?distro=lunar) _  \n**Package Links**\n  * [ Tutorials ](/rosbridge_suite/Tutorials)\n  * [ FAQ ](http://answers.ros.org/questions/scope:all/sort:activity-desc/tags:rosbridge_suite/page:1/)\n  * [ Changelog ](http://docs.ros.org/en/lunar/changelogs/rosbridge_suite/changelog.html)\n  * [ Change List ](/rosbridge_suite/ChangeList)\n  * [ Reviews ](/rosbridge_suite/Reviews)\n** Dependencies  (4) **  \n  * [ catkin ](/catkin?distro=lunar)\n  * [ rosapi ](/rosapi?distro=lunar)\n  * [ rosbridge_library ](/rosbridge_library?distro=lunar)\n  * [ rosbridge_server ](/rosbridge_server?distro=lunar)\n#  Package Summary\nReleased\nContinuous Integration\nDocumented\nRosbridge provides a JSON API to ROS functionality for non-ROS programs. There\nare a variety of front ends that interface with rosbridge, including a\nWebSocket server for web browsers to interact with. Rosbridge_suite is a meta-\npackage containing rosbridge, various front end packages for rosbridge like a\nWebSocket package, and helper packages.\n  * Maintainer status: maintained \n  * Maintainer: Russell Toris <rctoris AT wpi DOT edu>, Jihoon Lee <jihoonlee.in AT gmail DOT com>\n  * Author: Jonathan Mace <jonathan.c.mace AT gmail DOT com>\n  * License: BSD \n  * Bug / feature tracker: [ https://github.com/RobotWebTools/rosbridge_suite/issues ](https://github.com/RobotWebTools/rosbridge_suite/issues)\n  * Source: git [ https://github.com/RobotWebTools/rosbridge_suite.git ](https://github.com/RobotWebTools/rosbridge_suite) (branch: master) \n_**rosbridge_suite** : [ rosapi ](/rosapi?distro=melodic) | [\nrosbridge_library ](/rosbridge_library?distro=melodic) | [ rosbridge_server\n](/rosbridge_server?distro=melodic) _  \n**Package Links**\n  * [ Tutorials ](/rosbridge_suite/Tutorials)\n  * [ FAQ ](http://answers.ros.org/questions/scope:all/sort:activity-desc/tags:rosbridge_suite/page:1/)\n  * [ Changelog ](http://docs.ros.org/en/melodic/changelogs/rosbridge_suite/changelog.html)\n  * [ Change List ](/rosbridge_suite/ChangeList)\n  * [ Reviews ](/rosbridge_suite/Reviews)\n** Dependencies  (4) **  \n  * [ catkin ](/catkin?distro=melodic)\n  * [ rosapi ](/rosapi?distro=melodic)\n\n\n\n  * [ rosbridge_library ](/rosbridge_library?distro=melodic)\n  * [ rosbridge_server ](/rosbridge_server?distro=melodic)\n** Jenkins jobs  (6) **  \n  * [ source ubuntu bionic ](https://build.ros.org/view/Msrc_uB/job/Msrc_uB__rosbridge_suite__ubuntu_bionic__source)\n  * [ binary ubuntu bionic amd64 ](https://build.ros.org/view/Mbin_uB64/job/Mbin_uB64__rosbridge_suite__ubuntu_bionic_amd64__binary)\n  * [ binary ubuntu bionic armhf ](https://build.ros.org/view/Mbin_ubhf_uBhf/job/Mbin_ubhf_uBhf__rosbridge_suite__ubuntu_bionic_armhf__binary)\n  * [ binary ubuntu bionic arm64 ](https://build.ros.org/view/Mbin_ubv8_uBv8/job/Mbin_ubv8_uBv8__rosbridge_suite__ubuntu_bionic_arm64__binary)\n  * [ devel ubuntu bionic amd64 ](https://build.ros.org/view/Mdev/job/Mdev__rosbridge_suite__ubuntu_bionic_amd64)\n  * [ doc ](https://build.ros.org/view/Mdoc/job/Mdoc__rosbridge_suite__ubuntu_bionic_amd64)\n#  Package Summary\nReleased\nContinuous Integration:  144 / 144\n  * Build history (last 5 of 10 builds): \n  * [ #54  18-Oct-2022 19:00  144 / 144  ](https://build.ros.org//job/Mdev__rosbridge_suite__ubuntu_bionic_amd64/54/)\n  * [ #53  18-Oct-2022 13:00  144 / 144  ](https://build.ros.org//job/Mdev__rosbridge_suite__ubuntu_bionic_amd64/53/)\n  * [ #52  17-Oct-2022 18:00  144 / 144  ](https://build.ros.org//job/Mdev__rosbridge_suite__ubuntu_bionic_amd64/52/)\n  * [ #51  06-Oct-2022 19:00  144 / 144  ](https://build.ros.org//job/Mdev__rosbridge_suite__ubuntu_bionic_amd64/51/)\n  * [ #50  04-Oct-2022 20:00  144 / 144  ](https://build.ros.org//job/Mdev__rosbridge_suite__ubuntu_bionic_amd64/50/)\nDocumented\nRosbridge provides a JSON API to ROS functionality for non-ROS programs. There\nare a variety of front ends that interface with rosbridge, including a\nWebSocket server for web browsers to interact with. Rosbridge_suite is a meta-\npackage containing rosbridge, various front end packages for rosbridge like a\nWebSocket package, and helper packages.\n  * Maintainer status: maintained \n  * Maintainer: Russell Toris <rctoris AT wpi DOT edu>, Jihoon Lee <jihoonlee.in AT gmail DOT com>\n  * Author: Jonathan Mace <jonathan.c.mace AT gmail DOT com>\n  * License: BSD \n  * Bug / feature tracker: [ https://github.com/RobotWebTools/rosbridge_suite/issues ](https://github.com/RobotWebTools/rosbridge_suite/issues)\n  * Source: git [ https://github.com/RobotWebTools/rosbridge_suite.git ](https://github.com/RobotWebTools/rosbridge_suite) (branch: ros1) \n_**rosbridge_suite** : [ rosapi ](/rosapi?distro=noetic) | [ rosbridge_library\n](/rosbridge_library?distro=noetic) | [ rosbridge_server\n](/rosbridge_server?distro=noetic) _  \n**Package Links**\n  * [ Tutorials ](/rosbridge_suite/Tutorials)\n  * [ FAQ ](http://answers.ros.org/questions/scope:all/sort:activity-desc/tags:rosbridge_suite/page:1/)\n  * [ Changelog ](http://docs.ros.org/en/noetic/changelogs/rosbridge_suite/changelog.html)\n  * [ Change List ](/rosbridge_suite/ChangeList)\n  * [ Reviews ](/rosbridge_suite/Reviews)\n** Dependencies  (4) **  \n\n\n\n  * [ catkin ](/catkin?distro=noetic)\n  * [ rosapi ](/rosapi?distro=noetic)\n  * [ rosbridge_library ](/rosbridge_library?distro=noetic)\n  * [ rosbridge_server ](/rosbridge_server?distro=noetic)\n** Used by  (1) **  \n  * [ vizanti ](/vizanti?distro=noetic)\n** Jenkins jobs  (6) **  \n  * [ source ubuntu focal ](https://build.ros.org/view/Nsrc_uF/job/Nsrc_uF__rosbridge_suite__ubuntu_focal__source)\n  * [ binary ubuntu focal amd64 ](https://build.ros.org/view/Nbin_uF64/job/Nbin_uF64__rosbridge_suite__ubuntu_focal_amd64__binary)\n  * [ binary ubuntu focal armhf ](https://build.ros.org/view/Nbin_ufhf_uFhf/job/Nbin_ufhf_uFhf__rosbridge_suite__ubuntu_focal_armhf__binary)\n  * [ binary ubuntu focal arm64 ](https://build.ros.org/view/Nbin_ufv8_uFv8/job/Nbin_ufv8_uFv8__rosbridge_suite__ubuntu_focal_arm64__binary)\n  * [ devel ubuntu focal amd64 ](https://build.ros.org/view/Ndev/job/Ndev__rosbridge_suite__ubuntu_focal_amd64)\n  * [ doc ](https://build.ros.org/view/Ndoc/job/Ndoc__rosbridge_suite__ubuntu_focal_amd64)\n#  Package Summary\nReleased\nContinuous Integration:  144 / 144\n  * Build history (last 5 of 9 builds): \n  * [ #21  27-Sep-2023 14:45  144 / 144  ](https://build.ros.org//job/Ndev__rosbridge_suite__ubuntu_focal_amd64/21/)\n  * [ #20  26-Sep-2023 14:45  144 / 144  ](https://build.ros.org//job/Ndev__rosbridge_suite__ubuntu_focal_amd64/20/)\n  * [ #19  18-Oct-2022 18:45  144 / 144  ](https://build.ros.org//job/Ndev__rosbridge_suite__ubuntu_focal_amd64/19/)\n  * [ #18  18-Oct-2022 12:45  144 / 144  ](https://build.ros.org//job/Ndev__rosbridge_suite__ubuntu_focal_amd64/18/)\n  * [ #17  17-Oct-2022 17:45  144 / 144  ](https://build.ros.org//job/Ndev__rosbridge_suite__ubuntu_focal_amd64/17/)\nDocumented\nRosbridge provides a JSON API to ROS functionality for non-ROS programs. There\nare a variety of front ends that interface with rosbridge, including a\nWebSocket server for web browsers to interact with. Rosbridge_suite is a meta-\npackage containing rosbridge, various front end packages for rosbridge like a\nWebSocket package, and helper packages.\n  * Maintainer status: maintained \n  * Maintainer: Russell Toris <rctoris AT wpi DOT edu>, Jihoon Lee <jihoonlee.in AT gmail DOT com>\n  * Author: Jonathan Mace <jonathan.c.mace AT gmail DOT com>\n  * License: BSD \n  * Bug / feature tracker: [ https://github.com/RobotWebTools/rosbridge_suite/issues ](https://github.com/RobotWebTools/rosbridge_suite/issues)\n  * Source: git [ https://github.com/RobotWebTools/rosbridge_suite.git ](https://github.com/RobotWebTools/rosbridge_suite) (branch: ros1) \n##  About\nThere's two parts to rosbridge: the protocol and the implementation.\n###  Rosbridge Protocol\nThe [ rosbridge protocol\n](https://github.com/RobotWebTools/rosbridge_suite/blob/ros1/ROSBRIDGE_PROTOCOL.md)\nis a specification for sending JSON based commands to ROS (and in theory, any\n\n\n\nother robot middleware). An example of the protocol for subscribing to a\ntopic:\n    \n    \n    { \"op\": \"subscribe\",\n      \"topic\": \"/cmd_vel\",\n      \"type\": \"geometry_msgs/Twist\"\n    }\nThe specification is programming language and transport agnostic. The idea is\nthat any language or transport that can send JSON can talk the rosbridge\nprotocol and interact with ROS. The protocol covers subscribing and publishing\ntopics, service calls, getting and setting params, and even compressing\nmessages and more.\n###  Rosbridge Implementation\nThe rosbridge_suite package is a collection of packages that implement the\nrosbridge protocol and provides a [ WebSocket ](/WebSocket) transport layer.\nThe packages include:\n  * [ rosbridge_library ](/rosbridge_library) \\- The core rosbridge package. The rosbridge_library is responsible for taking the JSON string and sending the commands to ROS and vice versa. \n  * [ rosapi ](/rosapi) \\- Makes certain ROS actions accessible via service calls that are normally reserved for [ ROS client libraries ](/Client%20Libraries) . This includes getting and setting params, getting topics list, and more. \n  * [ rosbridge_server ](/rosbridge_server) \\- While rosbridge_library provides the JSON<->ROS conversion, it leaves the transport layer to others. Rosbridge_server provides a [ WebSocket ](/WebSocket) connection so browsers can \"talk rosbridge.\" [ Roslibjs ](/roslibjs) is a [ JavaScript ](/JavaScript) library for the browser that can talk to ROS via rosbridge_server. \n##  Source Code\nSource code is available at [ https://github.com/RobotWebTools/rosbridge_suite\n](https://github.com/RobotWebTools/rosbridge_suite) . Please file issues and\npull requests there.\n##  Installation\nRosbridge is available as a debian. To install:\n    \n    \n    sudo apt-get install ros-<rosdistro>-rosbridge-server\n##  Tutorials\n###  Beginner Tutorials\n  1. [ Running Rosbridge ](/rosbridge_suite/Tutorials/RunningRosbridge)\nThis tutorial shows you how to launch a rosbridge server and talk to it.\n###  Intermediate Tutorials\n  1. [ Developing Rosbridge ](/rosbridge_suite/Tutorials/DevelopingRosbridge)\nThis tutorial shows you how to develop on rosbridge itself.\n##  Community\nRosbridge is a community project and involvement is encouraged! In addition to\nthe [ GitHub ](https://github.com/RobotWebTools/rosbridge_suite) repository,\ncheck out the [ Google Group\n\n\n\n](https://groups.google.com/forum/?fromgroups=#!forum/rosbridge-users) and [\nROS Answers ](http://answers.ros.org) .\nWiki: rosbridge_suite (last edited 2022-09-07 18:33:59 by  [ Carter Schultz\n](/Carter%20Schultz \"Carter Schultz @\nc-73-243-79-45.hsd1.co.comcast.net\\[73.243.79.45\\]\") )\nExcept where otherwise noted, the ROS wiki is licensed under the  \n[ Creative Commons Attribution 3.0\n](http://creativecommons.org/licenses/by/3.0/)\n* * *\n[ ![](/custom/images/brought_by_horiz.png) ](https://www.openrobotics.org/)\n\n\n"
  },
  {
    "id": "vscode_gazebo/cpp.txt",
    "content": "Skip to content __ [ Visual Studio Code ](/)\n\n  * [ Docs ](/docs)\n  * [ Updates ](/updates)\n  * [ Blog ](/blogs)\n  * [ API ](/api)\n  * [ Extensions ](https://marketplace.visualstudio.com/VSCode)\n  * [ FAQ ](/docs/supporting/faq)\n  * [ Learn ](/learn)\n  * [ Search ](/Search)\n\n  * [ ![Search](/assets/icons/search.svg) ![Search](/assets/icons/search_dark.svg) ](/Search \"Search\")\n  * ![Search](/assets/icons/search.svg) ![Search](/assets/icons/search_dark.svg)\n\n  * [ ![Download VS Code](/assets/icons/download.svg) ![Download VS Code](/assets/icons/download-black.svg) Download  ](/Download)\n\n[ Version 1.88 ](/updates) is now available! Read about the new features and\nfixes from March.\n\nDismiss this update\n\n  * [ Overview ](/docs)\n  * Setup \n    * [ Overview ](/docs/setup/setup-overview)\n    * [ Linux ](/docs/setup/linux)\n    * [ macOS ](/docs/setup/mac)\n    * [ Windows ](/docs/setup/windows)\n    * [ Raspberry Pi ](/docs/setup/raspberry-pi)\n    * [ Network ](/docs/setup/network)\n    * [ Additional Components ](/docs/setup/additional-components)\n    * [ Enterprise ](/docs/setup/enterprise)\n    * [ Uninstall ](/docs/setup/uninstall)\n  * Get Started \n    * [ Intro Videos ](/docs/getstarted/introvideos)\n    * [ Tips and Tricks ](/docs/getstarted/tips-and-tricks)\n    * [ User Interface ](/docs/getstarted/userinterface)\n    * [ Themes ](/docs/getstarted/themes)\n    * [ Settings ](/docs/getstarted/settings)\n    * [ Key Bindings ](/docs/getstarted/keybindings)\n    * [ Display Language ](/docs/getstarted/locales)\n    * [ Telemetry ](/docs/getstarted/telemetry)\n  * User Guide \n    * [ Basic Editing ](/docs/editor/codebasics)\n    * [ Extension Marketplace ](/docs/editor/extension-marketplace)\n    * [ IntelliSense ](/docs/editor/intellisense)\n    * [ Code Navigation ](/docs/editor/editingevolved)\n    * [ Refactoring ](/docs/editor/refactoring)\n    * [ Debugging ](/docs/editor/debugging)\n    * [ VS Code for the Web ](/docs/editor/vscode-web)\n    * [ Tasks ](/docs/editor/tasks)\n    * [ Profiles ](/docs/editor/profiles)\n    * [ Settings Sync ](/docs/editor/settings-sync)\n    * [ Snippets ](/docs/editor/userdefinedsnippets)\n    * [ Emmet ](/docs/editor/emmet)\n    * [ Command Line Interface ](/docs/editor/command-line)\n    * [ Workspace Trust ](/docs/editor/workspace-trust)\n    * [ Multi-root Workspaces ](/docs/editor/multi-root-workspaces)\n    * [ Accessibility ](/docs/editor/accessibility)\n    * [ Voice interactions ](/docs/editor/voice)\n    * [ Custom Layout ](/docs/editor/custom-layout)\n    * [ Port Forwarding ](/docs/editor/port-forwarding)\n  * Source Control \n    * [ Overview ](/docs/sourcecontrol/overview)\n    * [ Introduction to Git ](/docs/sourcecontrol/intro-to-git)\n    * [ Collaborate on GitHub ](/docs/sourcecontrol/github)\n    * [ FAQ ](/docs/sourcecontrol/faq)\n  * Terminal \n    * [ Terminal Basics ](/docs/terminal/basics)\n    * [ Terminal Profiles ](/docs/terminal/profiles)\n    * [ Shell Integration ](/docs/terminal/shell-integration)\n    * [ Appearance ](/docs/terminal/appearance)\n    * [ Advanced ](/docs/terminal/advanced)\n  * GitHub Copilot \n    * [ Overview ](/docs/copilot/overview)\n    * [ Setup ](/docs/copilot/setup)\n    * [ Getting Started Tutorial ](/docs/copilot/getting-started)\n    * [ Copilot Chat Tutorial ](/docs/copilot/getting-started-chat)\n    * [ Code Completions ](/docs/copilot/ai-powered-suggestions)\n    * [ Copilot Chat ](/docs/copilot/copilot-chat)\n    * [ Best Practices ](/docs/copilot/prompt-crafting)\n    * [ Workspace Context ](/docs/copilot/workspace-context)\n    * [ FAQ ](/docs/copilot/faq)\n  * Languages \n    * [ Overview ](/docs/languages/overview)\n    * [ JavaScript ](/docs/languages/javascript)\n    * [ JSON ](/docs/languages/json)\n    * [ HTML ](/docs/languages/html)\n    * [ CSS, SCSS and Less ](/docs/languages/css)\n    * [ TypeScript ](/docs/languages/typescript)\n    * [ Markdown ](/docs/languages/markdown)\n    * [ PowerShell ](/docs/languages/powershell)\n    * [ C++ ](/docs/languages/cpp)\n    * [ Java ](/docs/languages/java)\n    * [ PHP ](/docs/languages/php)\n    * [ Python ](/docs/languages/python)\n    * [ Julia ](/docs/languages/julia)\n    * [ R ](/docs/languages/r)\n    * [ Ruby ](/docs/languages/ruby)\n    * [ Rust ](/docs/languages/rust)\n    * [ Go ](/docs/languages/go)\n    * [ T-SQL ](/docs/languages/tsql)\n    * [ C# ](/docs/languages/csharp)\n    * [ .NET ](/docs/languages/dotnet)\n    * [ Polyglot ](/docs/languages/polyglot)\n  * Node.js / JavaScript \n    * [ Working with JavaScript ](/docs/nodejs/working-with-javascript)\n    * [ Node.js Tutorial ](/docs/nodejs/nodejs-tutorial)\n    * [ Node.js Debugging ](/docs/nodejs/nodejs-debugging)\n    * [ Deploy Node.js Apps ](/docs/nodejs/nodejs-deployment)\n    * [ Browser Debugging ](/docs/nodejs/browser-debugging)\n    * [ Angular Tutorial ](/docs/nodejs/angular-tutorial)\n    * [ React Tutorial ](/docs/nodejs/reactjs-tutorial)\n    * [ Vue Tutorial ](/docs/nodejs/vuejs-tutorial)\n    * [ Debugging Recipes ](/docs/nodejs/debugging-recipes)\n    * [ Performance Profiling ](/docs/nodejs/profiling)\n    * [ Extensions ](/docs/nodejs/extensions)\n  * TypeScript \n    * [ Tutorial ](/docs/typescript/typescript-tutorial)\n    * [ Compiling ](/docs/typescript/typescript-compiling)\n    * [ Editing ](/docs/typescript/typescript-editing)\n    * [ Refactoring ](/docs/typescript/typescript-refactoring)\n    * [ Debugging ](/docs/typescript/typescript-debugging)\n  * Python \n    * [ Quick Start ](/docs/python/python-quick-start)\n    * [ Tutorial ](/docs/python/python-tutorial)\n    * [ Editing Code ](/docs/python/editing)\n    * [ Linting ](/docs/python/linting)\n    * [ Formatting ](/docs/python/formatting)\n    * [ Debugging ](/docs/python/debugging)\n    * [ Environments ](/docs/python/environments)\n    * [ Testing ](/docs/python/testing)\n    * [ Python Interactive ](/docs/python/jupyter-support-py)\n    * [ Django Tutorial ](/docs/python/tutorial-django)\n    * [ FastAPI Tutorial ](/docs/python/tutorial-fastapi)\n    * [ Flask Tutorial ](/docs/python/tutorial-flask)\n    * [ Create containers ](/docs/python/tutorial-create-containers)\n    * [ Deploy Python Apps ](/docs/python/python-on-azure)\n    * [ Python in the Web ](/docs/python/python-web)\n    * [ Settings Reference ](/docs/python/settings-reference)\n  * Java \n    * [ Getting Started ](/docs/java/java-tutorial)\n    * [ Navigate and Edit ](/docs/java/java-editing)\n    * [ Refactoring ](/docs/java/java-refactoring)\n    * [ Formatting and Linting ](/docs/java/java-linting)\n    * [ Project Management ](/docs/java/java-project)\n    * [ Build Tools ](/docs/java/java-build)\n    * [ Run and Debug ](/docs/java/java-debugging)\n    * [ Testing ](/docs/java/java-testing)\n    * [ Spring Boot ](/docs/java/java-spring-boot)\n    * [ Application Servers ](/docs/java/java-tomcat-jetty)\n    * [ Deploy Java Apps ](/docs/java/java-on-azure)\n    * [ GUI Applications ](/docs/java/java-gui)\n    * [ Extensions ](/docs/java/extensions)\n    * [ FAQ ](/docs/java/java-faq)\n  * C++ \n    * [ Intro Videos ](/docs/cpp/introvideos-cpp)\n    * [ GCC on Linux ](/docs/cpp/config-linux)\n    * [ GCC on Windows ](/docs/cpp/config-mingw)\n    * [ GCC on Windows Subsystem for Linux ](/docs/cpp/config-wsl)\n    * [ Clang on macOS ](/docs/cpp/config-clang-mac)\n    * [ Microsoft C++ on Windows ](/docs/cpp/config-msvc)\n    * [ Build with CMake ](/docs/cpp/build-with-cmake)\n    * [ CMake Tools on Linux ](/docs/cpp/cmake-linux)\n    * [ Editing and Navigating ](/docs/cpp/cpp-ide)\n    * [ Debugging ](/docs/cpp/cpp-debug)\n    * [ Refactoring ](/docs/cpp/cpp-refactoring)\n    * [ Configure debugging ](/docs/cpp/launch-json-reference)\n    * [ Settings ](/docs/cpp/customize-default-settings-cpp)\n    * [ Configure IntelliSense ](/docs/cpp/configure-intellisense)\n    * [ Configure IntelliSense for cross-compiling ](/docs/cpp/configure-intellisense-crosscompilation)\n    * [ FAQ ](/docs/cpp/faq-cpp)\n  * C# \n    * [ Intro Videos ](/docs/csharp/introvideos-csharp)\n    * [ Get Started ](/docs/csharp/get-started)\n    * [ Navigate and Edit ](/docs/csharp/navigate-edit)\n    * [ IntelliCode ](/docs/csharp/intellicode)\n    * [ Refactoring ](/docs/csharp/refactoring)\n    * [ Formatting and Linting ](/docs/csharp/formatting-linting)\n    * [ Project Management ](/docs/csharp/project-management)\n    * [ Build Tools ](/docs/csharp/build-tools)\n    * [ Package Management ](/docs/csharp/package-management)\n    * [ Run and Debug ](/docs/csharp/debugging)\n    * [ Testing ](/docs/csharp/testing)\n    * [ FAQ ](/docs/csharp/cs-dev-kit-faq)\n  * Docker \n    * [ Overview ](/docs/containers/overview)\n    * [ Node.js ](/docs/containers/quickstart-node)\n    * [ Python ](/docs/containers/quickstart-python)\n    * [ ASP.NET Core ](/docs/containers/quickstart-aspnet-core)\n    * [ Debug ](/docs/containers/debug-common)\n    * [ Docker Compose ](/docs/containers/docker-compose)\n    * [ Registries ](/docs/containers/quickstart-container-registries)\n    * [ Deploy to Azure ](/docs/containers/app-service)\n    * [ Choose a dev environment ](/docs/containers/choosing-dev-environment)\n    * [ Customize ](/docs/containers/reference)\n    * [ Develop with Kubernetes ](/docs/containers/bridge-to-kubernetes)\n    * [ Tips and Tricks ](/docs/containers/troubleshooting)\n  * Data Science \n    * [ Overview ](/docs/datascience/overview)\n    * [ Jupyter Notebooks ](/docs/datascience/jupyter-notebooks)\n    * [ Data Science Tutorial ](/docs/datascience/data-science-tutorial)\n    * [ Python Interactive ](/docs/datascience/python-interactive)\n    * [ Data Wrangler Quick Start ](/docs/datascience/data-wrangler-quick-start)\n    * [ Data Wrangler ](/docs/datascience/data-wrangler)\n    * [ PyTorch Support ](/docs/datascience/pytorch-support)\n    * [ Azure Machine Learning ](/docs/datascience/azure-machine-learning)\n    * [ Manage Jupyter Kernels ](/docs/datascience/jupyter-kernel-management)\n    * [ Jupyter Notebooks on the web ](/docs/datascience/notebooks-web)\n  * Azure \n    * [ Extensions ](/docs/azure/extensions)\n    * [ Deployment ](/docs/azure/deployment)\n    * [ Remote Debugging for Node.js ](/docs/azure/remote-debugging)\n    * [ Docker ](/docs/azure/docker)\n    * [ MongoDB ](/docs/azure/mongodb)\n    * [ Kubernetes ](/docs/azure/kubernetes)\n    * [ Azure Kubernetes Service ](/docs/azure/aksextensions)\n  * Remote \n    * [ Overview ](/docs/remote/remote-overview)\n    * [ SSH ](/docs/remote/ssh)\n    * [ Dev Containers ](/docs/remote/dev-containers)\n    * [ Windows Subsystem for Linux ](/docs/remote/wsl)\n    * [ GitHub Codespaces ](/docs/remote/codespaces)\n    * [ VS Code Server ](/docs/remote/vscode-server)\n    * [ Tunnels ](/docs/remote/tunnels)\n    * [ SSH Tutorial ](/docs/remote/ssh-tutorial)\n    * [ WSL Tutorial ](/docs/remote/wsl-tutorial)\n    * [ Tips and Tricks ](/docs/remote/troubleshooting)\n    * [ FAQ ](/docs/remote/faq)\n  * Dev Containers \n    * [ Overview ](/docs/devcontainers/containers)\n    * [ Tutorial ](/docs/devcontainers/tutorial)\n    * [ Attach to Container ](/docs/devcontainers/attach-container)\n    * [ Create a Dev Container ](/docs/devcontainers/create-dev-container)\n    * [ Advanced Containers ](/docs/devcontainers/containers-advanced)\n    * [ devcontainer.json ](/docs/devcontainers/devcontainerjson-reference)\n    * [ Dev Container CLI ](/docs/devcontainers/devcontainer-cli)\n    * [ Tips and Tricks ](/docs/devcontainers/tips-and-tricks)\n    * [ FAQ ](/docs/devcontainers/faq)\n\nTopics  Overview  Overview  Linux  macOS  Windows  Raspberry Pi  Network\nAdditional Components  Enterprise  Uninstall  Intro Videos  Tips and Tricks\nUser Interface  Themes  Settings  Key Bindings  Display Language  Telemetry\nBasic Editing  Extension Marketplace  IntelliSense  Code Navigation\nRefactoring  Debugging  VS Code for the Web  Tasks  Profiles  Settings Sync\nSnippets  Emmet  Command Line Interface  Workspace Trust  Multi-root\nWorkspaces  Accessibility  Voice interactions  Custom Layout  Port Forwarding\nOverview  Introduction to Git  Collaborate on GitHub  FAQ  Terminal Basics\nTerminal Profiles  Shell Integration  Appearance  Advanced  Overview  Setup\nGetting Started Tutorial  Copilot Chat Tutorial  Code Completions  Copilot\nChat  Best Practices  Workspace Context  FAQ  Overview  JavaScript  JSON  HTML\nCSS, SCSS and Less  TypeScript  Markdown  PowerShell  C++  Java  PHP  Python\nJulia  R  Ruby  Rust  Go  T-SQL  C#  .NET  Polyglot  Working with JavaScript\nNode.js Tutorial  Node.js Debugging  Deploy Node.js Apps  Browser Debugging\nAngular Tutorial  React Tutorial  Vue Tutorial  Debugging Recipes  Performance\nProfiling  Extensions  Tutorial  Compiling  Editing  Refactoring  Debugging\nQuick Start  Tutorial  Editing Code  Linting  Formatting  Debugging\nEnvironments  Testing  Python Interactive  Django Tutorial  FastAPI Tutorial\nFlask Tutorial  Create containers  Deploy Python Apps  Python in the Web\nSettings Reference  Getting Started  Navigate and Edit  Refactoring\nFormatting and Linting  Project Management  Build Tools  Run and Debug\nTesting  Spring Boot  Application Servers  Deploy Java Apps  GUI Applications\nExtensions  FAQ  Intro Videos  GCC on Linux  GCC on Windows  GCC on Windows\nSubsystem for Linux  Clang on macOS  Microsoft C++ on Windows  Build with\nCMake  CMake Tools on Linux  Editing and Navigating  Debugging  Refactoring\nConfigure debugging  Settings  Configure IntelliSense  Configure IntelliSense\nfor cross-compiling  FAQ  Intro Videos  Get Started  Navigate and Edit\nIntelliCode  Refactoring  Formatting and Linting  Project Management  Build\nTools  Package Management  Run and Debug  Testing  FAQ  Overview  Node.js\nPython  ASP.NET Core  Debug  Docker Compose  Registries  Deploy to Azure\nChoose a dev environment  Customize  Develop with Kubernetes  Tips and Tricks\nOverview  Jupyter Notebooks  Data Science Tutorial  Python Interactive  Data\nWrangler Quick Start  Data Wrangler  PyTorch Support  Azure Machine Learning\nManage Jupyter Kernels  Jupyter Notebooks on the web  Extensions  Deployment\nRemote Debugging for Node.js  Docker  MongoDB  Kubernetes  Azure Kubernetes\nService  Overview  SSH  Dev Containers  Windows Subsystem for Linux  GitHub\nCodespaces  VS Code Server  Tunnels  SSH Tutorial  WSL Tutorial  Tips and\nTricks  FAQ  Overview  Tutorial  Attach to Container  Create a Dev Container\nAdvanced Containers  devcontainer.json  Dev Container CLI  Tips and Tricks\nFAQ\n\nIn this article  Install the extension  Set up your C++ Environment  Example:\nInstall MinGW-x64 on Windows  Create a Hello World App  Run helloworld.cpp\nTutorials  Documentation  Remote Development  Enhance completions with AI\nFeedback\n\n[ Edit  ](https://vscode.dev/github/microsoft/vscode-\ndocs/blob/main/docs/languages/cpp.md \"Edit this document in vscode.dev\")\n\n#  C/C++ for Visual Studio Code\n\nC/C++ support for Visual Studio Code is provided by a [ Microsoft C/C++\nextension ](https://marketplace.visualstudio.com/items?itemName=ms-\nvscode.cpptools) to enable cross-platform C and C++ development on Windows,\nLinux, and macOS. When you create a ` *.cpp ` file, the extension adds\nfeatures such as syntax highlighting (colorization), smart completions and\nhovers (IntelliSense), and error checking.\n\n![C++ language features](/assets/docs/languages/cpp/msg-intellisense.png)\n\n##  Install the extension\n\n  1. Open VS Code. \n  2. Select the Extensions view icon on the Activity bar or use the keyboard shortcut (  \u21e7\u2318X  (Windows, Linux  Ctrl+Shift+X  )  ). \n  3. Search for ` 'C++' ` . \n  4. Select **Install** . \n\n![C/C++ extension](/assets/docs/languages/cpp/cpp-extension.png)\n\n##  Set up your C++ Environment\n\nC++ is a compiled language meaning your program's source code must be\ntranslated (compiled) before it can be run on your computer. The C/C++\nextension doesn't include a C++ compiler or debugger, since VS Code as an\neditor relies on command-line tools for the development workflow. You need to\ninstall these tools or use the tools already installed on your computer.\n\n###  Check if you have a compiler installed\n\n> **Note** : There may already be a C++ compiler and debugger provided by your\n> academic or work development environment. Check with your instructors or\n> colleagues for guidance on installing the recommended C++ toolset (compiler,\n> debugger, project system, linter).\n\nCommon compilers that already come preinstalled on some platforms are the [\nGNU Compiler Collection ](https://wikipedia.org/wiki/GNU_Compiler_Collection)\n(GCC) on Linux and the [ Clang ](https://wikipedia.org/wiki/Clang) tools with\n[ Xcode ](https://developer.apple.com/xcode/) on macOS.\n\nTo check if you already have them installed:\n\n  1. Open a new VS Code terminal window using (  \u2303\u21e7`  (Windows, Linux  Ctrl+Shift+`  )  ) \n\n  2. Use the following command to check for the GCC compiler ` g++ ` : \n    \n        g++ --version\n    \n\nOr this command for the Clang compiler ` clang ` :\n\n    \n        clang --version\n    \n\nThe output should show you the compiler version and details. If neither are\nfound, make sure your compiler executable is in your platform path ( ` %PATH `\non Windows, ` $PATH ` on Linux and macOS) so that the C/C++ extension can find\nit. Otherwise, use the instructions in the section below to install a\ncompiler.\n\n###  Install a compiler\n\nIf you don't have a compiler installed, you can follow one of our installation\ntutorials:\n\n**Windows** :\n\n[ Go to the MSVC tutorial ](/docs/cpp/config-msvc#_prerequisites)\n\n[ Go to the MinGW tutorial ](/docs/cpp/config-mingw#_prerequisites)\n\n**Linux** :\n\n[ Go to the GCC tutorial ](/docs/cpp/config-linux#_prerequisites)\n\n**macOS** :\n\n[ Go to the Clang tutorial ](/docs/cpp/config-clang-mac#_prerequisites)\n\n> **Note** : If you would prefer a full Integrated Development Environment\n> (IDE), with built-in compilation, debugging, and project templates (File >\n> New Project), there are many options available, such as the [ Visual Studio\n> Community ](https://visualstudio.microsoft.com/vs/community) edition.\n\n##  Example: Install MinGW-x64 on Windows\n\nTo understand the process, let's install Mingw-w64 via [ MSYS2\n](https://www.msys2.org/) . Mingw-w64 is a popular, free toolset on Windows.\nIt provides up-to-date native builds of GCC, Mingw-w64, and other helpful C++\ntools and libraries.\n\n  1. Download using [ **this direct link to the MinGW installer** ](https://github.com/msys2/msys2-installer/releases/download/2023-05-26/msys2-x86_64-20230526.exe) . \n\n  2. Run the installer and follow the steps of the installation wizard. Note, MSYS2 requires 64 bit Windows 8.1 or newer. \n\n  3. In the wizard, choose your desired Installation Folder. Record this directory for later. In most cases, the recommended directory is acceptable. The same applies when you get to setting the start menu shortcuts step. When complete, ensure the **Run MSYS2 now** box is checked and select **Finish** . A MSYS2 terminal window will then automatically open. \n\n  4. In this terminal, install the MinGW-w64 toolchain by running the following command: \n    \n        pacman -S --needed base-devel mingw-w64-ucrt-x86_64-toolchain\n    \n\n  5. Accept the default number of packages in the ` toolchain ` group by pressing  Enter  . \n\n![MYSS2 Installer](/assets/docs/languages/cpp/cpp-install-msys2-toolchain.png)\n\n  6. Enter ` Y ` when prompted whether to proceed with the installation. \n\n  7. Add the path to your MinGW-w64 ` bin ` folder to the Windows ` PATH ` environment variable by using the following steps: \n\n    1. In the Windows search bar, type **Settings** to open your Windows Settings. \n    2. Search for **Edit environment variables for your account** . \n    3. In your **User variables** , select the ` Path ` variable and then select **Edit** . \n    4. Select **New** and add the MinGW-w64 destination folder you recorded during the installation process to the list. If you selected the default installation steps, the path is: ` C:\\msys64\\ucrt64\\bin ` . \n    5. Select **OK** to save the updated PATH. For the new ` PATH ` to be available, reopen your console windows. \n  8. Check that your MinGW-w64 tools are correctly installed and available, open a **new** Command Prompt and type: \n\n    \n    \n    gcc --version\n    g++ --version\n    gdb --version\n    \n\nYou should see output that states which versions of GCC, g++ and GDB you have\ninstalled. If this is not the case, make sure your PATH entry matches the\nMingw-w64 binary location where the compiler tools are located or reference\nthe [ troubleshooting section ](/docs/cpp/config-mingw#__check-your-mingw-\ninstallation) .\n\n##  Create a Hello World App\n\nTo make sure the compiler is installed and configured correctly, lets create a\nHello World C++ program.\n\n###  Create a C++ file\n\n  1. On Windows, launch a Windows command prompt (Enter **Windows command prompt** in the Windows search bar). On macOS and Linux, you can enter these commands in the terminal. \n  2. Run the following commands. They are creating an empty folder called ` projects ` where you can place all your VS Code projects. The next commands create and navigate you to a subfolder called ` helloworld ` . From there, you are opening ` helloworld ` directly in VS Code using the ` code ` command. \n\n    \n    \n    mkdir projects\n    cd projects\n    mkdir helloworld\n    cd helloworld\n    code .\n    \n\nThe \"code .\" command opens VS Code in the current working folder, which\nbecomes your \"workspace\". Accept the [ Workspace Trust\n](/docs/editor/workspace-trust) dialog by selecting **Yes, I trust the\nauthors** since this is a folder you created.\n\nNow create a new file called ` helloworld.cpp ` with the **New File** button\nin the File Explorer or **File** > **New File** command.\n\n![File Explorer New File button](/assets/docs/languages/cpp/new-file.png)\n\n###  Add Hello World source code\n\nPaste in the following source code:\n\n    \n    \n    #include <iostream>\n    \n    int main()\n    {\n        std::cout << \"Hello World\" << std::endl;\n    }\n    \n\nNow press  \u2318S  (Windows, Linux  Ctrl+S  )  to save the file. You can also\nenable [ AutoSave ](/docs/editor/codebasics#_save-auto-save) to automatically\nsave your file changes, by checking **Auto Save** in the main **File** menu.\n\n##  Run helloworld.cpp\n\n  1. Make sure you have ` helloworld.cpp ` open so it is the active file in your editor. \n\n  2. Press the play button in the top right corner of the editor. \n\n![Screenshot of helloworld.cpp and play\nbutton](/assets/docs/languages/cpp/run-play-button.png)\n\n  3. Choose **C/C++: g++.exe build and debug active file** from the list of detected compilers on your system. \n\n![C++ debug configuration dropdown](/assets/docs/languages/cpp/select-gcc-\ncompiler.png)\n\nYou are only prompted to choose a compiler the first time you run `\nhelloworld.cpp ` . This compiler becomes \"default\" compiler set in your `\ntasks.json ` file.\n\n  4. After the build succeeds, you should see \"Hello World\" appear in the integrated **Terminal** . \n\n![screenshot of program output](/assets/docs/languages/cpp/helloworld-\nterminal-output.png)\n\nCongratulations! You've just run your first C++ program in VS Code! The next\nstep is to learn more about the Microsoft C/C++ extension's language features\nsuch as IntelliSense, code navigation, build configuration, and debugging\nusing one of the Tutorials in the next section.\n\n##  Tutorials\n\nGet started with C++ and VS Code with tutorials for your environment:\n\n  * [ GCC on Windows via MinGW ](/docs/cpp/config-mingw)\n  * [ Microsoft C++ on Windows ](/docs/cpp/config-msvc)\n  * [ GCC on Linux ](/docs/cpp/config-linux)\n  * [ GCC on Windows Subsystem For Linux ](/docs/cpp/config-wsl)\n  * [ Clang/LLVM on macOS ](/docs/cpp/config-clang-mac)\n  * [ CMake Tools on Linux ](/docs/cpp/cmake-linux)\n\n##  Documentation\n\nYou can find more documentation on using the Microsoft C/C++ extension under\nthe [ C++ section ](/docs/cpp) of the VS Code website, where you can find\narticles on:\n\n  * [ Debugging ](/docs/cpp/cpp-debug)\n  * [ Editing ](/docs/cpp/cpp-ide)\n  * [ Settings ](/docs/cpp/customize-default-settings-cpp)\n  * [ FAQ ](/docs/cpp/faq-cpp)\n\n![C++ TOC on code.visualstudio.com](/assets/docs/languages/cpp/cpp-toc.png)\n\n##  Remote Development\n\nVS Code and the C++ extension support [ Remote Development\n](/docs/remote/remote-overview) allowing you to work over SSH on a remote\nmachine or VM, inside a Docker container, or in the [ Windows Subsystem for\nLinux ](https://learn.microsoft.com/windows/wsl) (WSL).\n\nTo install support for Remote Development:\n\n  1. Install the VS Code [ Remote Development Extension Pack ](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack) . \n  2. If the remote source files are hosted in WSL, use the **WSL** extension. \n  3. If you are connecting to a remote machine with SSH, use the **Remote - SSH** extension. \n  4. If the remote source files are hosted in a container (for example, Docker), use the **Dev Containers** extension. \n\n##  Enhance completions with AI\n\n[ GitHub Copilot ](https://copilot.github.com/) is an AI-powered code\ncompletion tool that helps you write code faster and smarter. You can use the\n[ GitHub Copilot extension\n](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot) in VS\nCode to generate code, or to learn from the code it generates.\n\n[ ![GitHub Copilot extension in the VS Code\nMarketplace](/assets/docs/languages/cpp/copilot-extension.png)\n](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot)\n\nGitHub Copilot provides suggestions for numerous languages and a wide variety\nof frameworks, and it works especially well for Python, JavaScript,\nTypeScript, Ruby, Go, C# and C++.\n\nYou can learn more about how to get started with Copilot in the [ Copilot\ndocumentation ](/docs/editor/github-copilot) .\n\n##  Feedback\n\nIf you run into any issues or have suggestions for the Microsoft C/C++\nextension, please file [ issues and suggestions on GitHub\n](https://github.com/microsoft/vscode-cpptools/issues) . If you haven't\nalready provided feedback, you can take this [ quick survey\n](https://www.research.net/r/VBVV6C6) .\n\n7/24/2023\n\n####  In this article there are 10 sections  In this article\n\n  * Install the extension \n  * Set up your C++ Environment \n  * Example: Install MinGW-x64 on Windows \n  * Create a Hello World App \n  * Run helloworld.cpp \n  * Tutorials \n  * Documentation \n  * Remote Development \n  * Enhance completions with AI \n  * Feedback \n\n  * Hello from Seattle. \n  * [ Follow @code ](https://go.microsoft.com/fwlink/?LinkID=533687)\n  * \n\n  * [ Support ](https://support.serviceshub.microsoft.com/supportforbusiness/create?sapId=d66407ed-3967-b000-4cfb-2c318cad363d)\n  * [ Privacy ](https://go.microsoft.com/fwlink/?LinkId=521839)\n  * Manage Cookies \n  * [ Terms of Use ](https://www.microsoft.com/legal/terms-of-use)\n  * [ License ](/License)\n\n[ ![Microsoft homepage](/assets/images/microsoft-logo.png) ![Microsoft\nhomepage](/assets/images/microsoft-logo-inverted.png)\n](https://www.microsoft.com) \u00a9 2024 Microsoft\n\n"
  },
  {
    "id": "ros_convert/rosbag2storagemcap.txt",
    "content": "  \nROS Resources: [ Documentation ](http://docs.ros.org/) | [ Support\n](http://wiki.ros.org/Support) | [ Discussion Forum\n](http://discourse.ros.org/) | [ Service Status ](http://status.ros.org/) | [\nros @ Robotics Stack Exchange\n](https://robotics.stackexchange.com/questions/tagged/ros)  \n---  \n  \n[ ROS Index ](/)\n\n  * [ About ](/about)\n  * Index \n    * [ Package List ](/packages/page/1/time/)\n    * [ Repository List ](/repos/page/1/time/)\n    *     * [ Nodes ](/srvs/)\n    * [ Messages ](/msgs/)\n    * [ Services ](/srvs/)\n    * [ Plugins ](/srvs/)\n    *     * [ System Dependencies ](/deps/)\n  * [ Contribute ](/contribute)\n  * [ Stats ](/stats)\n\n[ ](https://lunrjs.com/guides/searching.html \"Help to Search\")\n\n  1. [ Home ](/)\n  2. [ Packages ](/packages)\n  3. rosbag2_storage_mcap \n\nhumble  iron  rolling  noetic\n\nOlder\n\n  * ardent \n  * bouncy \n  * crystal \n  * eloquent \n  * dashing \n  * galactic \n  * foxy \n  * lunar \n  * jade \n  * indigo \n  * hydro \n  * kinetic \n  * melodic \n\n![](/assets/package.png) |\n\n###  [ rosbag2_storage_mcap ](/p/rosbag2_storage_mcap) package from [ rosbag2\n](/r/rosbag2/github-ros2-rosbag2) repo\n\n[ mcap_vendor ](/p/mcap_vendor/github-ros2-rosbag2) [ ros2bag\n](/p/ros2bag/github-ros2-rosbag2) [ rosbag2 ](/p/rosbag2/github-ros2-rosbag2)\n[ rosbag2_compression ](/p/rosbag2_compression/github-ros2-rosbag2) [\nrosbag2_compression_zstd ](/p/rosbag2_compression_zstd/github-ros2-rosbag2) [\nrosbag2_cpp ](/p/rosbag2_cpp/github-ros2-rosbag2) [ rosbag2_interfaces\n](/p/rosbag2_interfaces/github-ros2-rosbag2) [\nrosbag2_performance_benchmarking ](/p/rosbag2_performance_benchmarking/github-\nros2-rosbag2) [ rosbag2_py ](/p/rosbag2_py/github-ros2-rosbag2) [\nrosbag2_storage ](/p/rosbag2_storage/github-ros2-rosbag2) [\nrosbag2_storage_default_plugins ](/p/rosbag2_storage_default_plugins/github-\nros2-rosbag2) rosbag2_storage_mcap  [ rosbag2_storage_mcap_testdata\n](/p/rosbag2_storage_mcap_testdata/github-ros2-rosbag2) [ rosbag2_test_common\n](/p/rosbag2_test_common/github-ros2-rosbag2) [ rosbag2_tests\n](/p/rosbag2_tests/github-ros2-rosbag2) [ rosbag2_transport\n](/p/rosbag2_transport/github-ros2-rosbag2) [ shared_queues_vendor\n](/p/shared_queues_vendor/github-ros2-rosbag2) [ sqlite3_vendor\n](/p/sqlite3_vendor/github-ros2-rosbag2) [ zstd_vendor\n](/p/zstd_vendor/github-ros2-rosbag2)  \n---|---  \n  \ngithub-ros2-rosbag2\n\n  * [ github-ros2-rosbag2 ](/p/rosbag2_storage_mcap/github-ros2-rosbag2)\n  * [ github-ros-tooling-rosbag2_storage_mcap ](/p/rosbag2_storage_mcap/github-ros-tooling-rosbag2_storage_mcap)\n\n  \n  \n---  \n  \n[  \nAPI Docs ](http://docs.ros.org/en/humble/p/rosbag2_storage_mcap \"View API\ndocumentation on docs.ros.org\") [  \nBrowse Code ](https://github.com/ros2/rosbag2/tree/humble/rosbag2_storage_mcap\n\"View source code on repository\")\n\n  * Overview \n  * 0  Assets \n  * 14  Dependencies \n  * 0  Tutorials \n  * 0  Q & A \n\n####  Package Summary\n\n**Tags** |  _No category tags._  \n---|---  \n**Version** |  0.15.9  \n**License** |  Apache-2.0  \n**Build type** |  AMENT_CMAKE  \n**Use** |  RECOMMENDED  \n  \n###  Repository Summary\n\n**Checkout URI** |  [ https://github.com/ros2/rosbag2.git\n](https://github.com/ros2/rosbag2.git)  \n---|---  \n**VCS Type** |  git  \n**VCS Version** |  humble  \n**Last Updated**  \n  \n2024-02-23  |  **Dev Status** |  DEVELOPED  \n**CI status** |  No Continuous Integration  \n**Released** |  RELEASED  \n**Tags** |  _No category tags._  \n**Contributing** |  [ Help Wanted (  0  ) ](/r/rosbag2/#humble-contribute-\nlists-help-wanted)  \n[ Good First Issues (  0  ) ](/r/rosbag2/#humble-contribute-lists-good-first-\nissue)  \n[ Pull Requests to Review (  0  ) ](/r/rosbag2/#humble-contribute-lists-pull-\nrequests)  \n  \n###  Package Description\n\nrosbag2 storage plugin using the MCAP file format\n\n####  Additional Links\n\n_No additional links._\n\n####  Maintainers\n\n  * Foxglove \n  * Michael Orlov \n  * ROS Tooling Working Group \n\n####  Authors\n\n_No additional authors._\n\n[ rosbag2_storage_mcap/README.md\n](https://github.com/ros2/rosbag2/tree/humble/rosbag2_storage_mcap/README.md\n\"Open in git repository\")\n\n#  rosbag2_storage_mcap\n\nThis package provides a [ storage plugin\n](https://github.com/ros2/rosbag2#storage-format-plugin-architecture) for\nrosbag2 which extends it with support for the [ MCAP ](https://mcap.dev) file\nformat.\n\n[ ![ROS Foxy version](https://img.shields.io/ros/v/foxy/rosbag2_storage_mcap)\n](https://index.ros.org/p/rosbag2_storage_mcap/github-ros2-rosbag2/#foxy) [\n![ROS Galactic\nversion](https://img.shields.io/ros/v/galactic/rosbag2_storage_mcap)\n](https://index.ros.org/p/rosbag2_storage_mcap/github-ros2-rosbag2/#galactic)\n[ ![ROS Humble\nversion](https://img.shields.io/ros/v/humble/rosbag2_storage_mcap)\n](https://index.ros.org/p/rosbag2_storage_mcap/github-ros2-rosbag2/#humble) [\n![ROS Rolling\nversion](https://img.shields.io/ros/v/rolling/rosbag2_storage_mcap)\n](https://index.ros.org/p/rosbag2_storage_mcap/github-ros2-rosbag2/#rolling)\n\n##  \u26a0\ufe0f Move from ` ros-tooling ` organization\n\nThis package was recently merged into [ https://github.com/ros2/rosbag2\n](https://github.com/ros2/rosbag2/tree/humble/rosbag2_storage_mcap/ros2/rosbag2)\nfrom [ https://github.com/ros-tooling/rosbag2_storage_mcap\n](https://github.com/ros2/rosbag2/tree/humble/rosbag2_storage_mcap/ros-\ntooling/rosbag2_storage_mcap) . To view historical pull requests and git\nhistory of this package, check [ here ](https://github.com/ros-\ntooling/rosbag2_storage_mcap/commits/main) .\n\n##  Installation\n\nrosbag2_storage_mcap is available as part of the [ current ROS 2 distributions\n](https://docs.ros.org/en/rolling/Releases.html) . On Ubuntu, after following\nthe [ ROS 2 installation instructions\n](https://docs.ros.org/en/humble/Installation.html) , you can use:\n\n    \n    \n    # Replace \"rolling\" with your ROS distro (`echo $ROS_DISTRO`)\n    $ sudo apt install ros-rolling-rosbag2-storage-mcap\n    \n    \n\n##  Usage\n\nUse MCAP files with regular [ ` ros2 bag ` commands\n](https://docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools/Recording-And-\nPlaying-Back-Data/Recording-And-Playing-Back-Data.html) by adding the `\n--storage mcap ` option (abbreviated as ` -s mcap ` ):\n\n    \n    \n    $ ros2 bag record -s mcap /topic1 /topic2 ...\n    \n    $ ros2 bag play -s mcap path/to/your_recording.mcap\n    \n    $ ros2 bag info -s mcap path/to/your_recording.mcap\n    \n    \n\n###  Writer Configuration\n\nTo configure details of the MCAP writer for ` ros2 bag record ` , use the `\n--storage-config-file ` options to provide a YAML file describing `\nmcap::McapWriterOptions ` . Field descriptions below copied from [\nMcapWriterOptions declaration\n](https://github.com/foxglove/mcap/blob/main/cpp/mcap/include/mcap/writer.hpp#L18)\n\nField  |  Type / Values  |  Description  \n---|---|---  \nnoChunkCRC  |  bool  |  Disable CRC calculation for Chunks. Ignored if `\nnoChunking=true ` .  \nnoAttachmentCRC  |  bool  |  Disable CRC calculation for Attachments.  \nenableDataCRC  |  bool  |  Enables CRC calculation for the entire Data\nsection. Useful when ` noChunking=True ` .  \nnoSummaryCRC  |  bool  |  Disable CRC calculation for the Summary section.  \nnoChunking  |  bool  |  Do not write Chunks to the file, instead writing\nSchema, Channel, and Message records directly into the Data section.  \nnoMessageIndex  |  bool  |  Do not write Message Index records to the file. If\n` noSummary=true ` and ` noChunkIndex=false ` , Chunk Index records will still\nbe written to the Summary section, providing a coarse message index.  \nnoSummary  |  bool  |  Do not write Summary or Summary Offset sections to the\nfile, placing the Footer record immediately after DataEnd. This can provide\nsome speed boost to file writing and produce smaller files, at the expense of\nrequiring a conversion process later if fast summarization or indexed access\nis desired.  \nchunkSize  |  unsigned int  |  Target uncompressed Chunk payload size in\nbytes. Once a Chunk's uncompressed data meets or exceeds this size, the Chunk\nwill be compressed (if compression is enabled) and written to disk. Note that\nsmaller Chunks may be written, such as the last Chunk in the Data section.\nThis option is ignored if ` noChunking=true ` .  \ncompression  |  \"None\", \"Lz4\", \"Zstd\"  |  Compression algorithm to use when\nwriting Chunks. This option is ignored if ` noChunking=true ` .  \ncompressionLevel  |  \"Fastest\", \"Fast\", \"Default\", \"Slow\", \"Slowest\"  |\nCompression level to use when writing Chunks. Slower generally produces\nsmaller files, at the expense of more CPU time. These levels map to different\ninternal settings for each compression algorithm.  \nforceCompression  |  bool  |  By default, Chunks that do not benefit from\ncompression will be written uncompressed. This option can be used to force\ncompression on all Chunks. This option is ignored if ` noChunking=true ` .  \nnoRepeatedSchemas  |  bool  |  Advanced option.  \nnoRepeatedChannels  |  bool  |  Advanced option.  \nnoMetadataIndex  |  bool  |  Advanced option.  \nnoChunkIndex  |  bool  |  Advanced option.  \nnoStatistics  |  bool  |  Advanced option.  \nnoSummaryOffsets  |  bool  |  Advanced option.  \n  \nExample:\n\n    \n    \n    # mcap_writer_options.yml\n    noChunkCRC: false\n    noChunking: false\n    noMessageIndex: false\n    noSummary: false\n    chunkSize: 786432\n    compression: \"Zstd\"\n    compressionLevel: \"Fast\"\n    forceCompression: false\n    \n    \n    \n    \n    $ ros2 bag record -s mcap -o my_bag --all --storage-config-file mcap_writer_options.yml\n    \n    \n\n###  Storage Preset Profiles\n\nYou can also use one of the preset profiles described below, for example:\n\n    \n    \n    $ ros2 bag record -s mcap -o my_bag --all --storage-preset-profile fastwrite\n    \n    \n\n####  ` fastwrite `\n\nConfigures the MCAP writer for the highest possible write throughput and\nlowest resource utilization. This preset does not calculate CRCs for integrity\nchecking, and does not write a message index. This preset profile is useful\nfor resource-constrained robots.\n\nEquivalent to this storage configuration:\n\n    \n    \n    noChunking: true\n    noSummaryCRC: true\n    \n    \n\nUsing MCAPs written with ` fastwrite ` as a long-term storage format is not\nrecommended. Some features will not work when reading MCAP files without a\nmessage index, such as reading messages from a subset of topics or seeking.\nWhen recording MCAPs on your robot with ` fastwrite ` , it is a good idea to\npost-process these files afterwards, to restore the message index and also\nsave storage space:\n\n    \n    \n    # Using the MCAP CLI https://github.com/foxglove/mcap/tree/main/go/cli/mcap\n    $ mcap compress fast.mcap -o compressed.mcap\n    # Using `ros2 bag convert`\n    $ cat << EOF > convert.yaml\n    output_bags:\n      - uri: compressed\n        storage_id: mcap\n        storage_preset_profile: zstd_small\n    EOF\n    $ ros2 bag convert -i fast.mcap -o convert.yaml\n    \n    \n\nEquivalent to this storage configuration:\n\n    \n    \n    noChunking: true\n    noSummaryCRC: true\n    \n    \n\n####  ` zstd_fast `\n\nConfigures the MCAP writer to use chunk compression with [ zstd\n](http://facebook.github.io/zstd/) . Chunk compression yields file sizes\ncomparable to bags compressed with file-level compression, but allows tools to\nefficiently read messages without decompressing the entire bag. This preset\nuses the lowest compression ratio and disables CRC calculation, to achieve\nhigh throughput while conserving disk space.\n\nEquivalent to this storage configuration:\n\n    \n    \n    compression: \"Zstd\"\n    compressionLevel: \"Fastest\"\n    noChunkCRC: true\n    \n    \n\n####  ` zstd_small `\n\nConfigures the MCAP writer to write 4MB chunks, compressed with zstd using its\nhighest compression ratio. This produces very small bags, but can be resource-\nintensive to write. This preset also calculates chunk CRCs, which allow a\nreader to determine if a chunk is corrupted. This preset is useful when using\n` ros2 bag convert ` as a post-processing step.\n\nEquivalent to this storage configuration:\n\n    \n    \n    compression: \"Zstd\"\n    compressionLevel: \"Slowest\"\n    chunkSize: 4194304 # 4 * 1024 * 1024\n    \n    \n\n###  ROS 2 Distro maintenance\n\nWhenever a ROS 2 distribution reaches EOL, search for comments marked\nCOMPATIBILITY - which may no longer be needed when no new releases will be\nmade for that distro.\n\nCHANGELOG\n\n#  Changelog for package rosbag2_storage_mcap\n\n##  0.15.9 (2024-01-24)\n\n  * Link and compile against rosbag2_storage_mcap: Fixed issue 1492 ( [ #1496 ](https://github.com/ros2/rosbag2/issues/1496) ) ( [ #1498 ](https://github.com/ros2/rosbag2/issues/1498) ) \n  * Contributors: mergify[bot] \n\n##  0.15.8 (2023-09-19)\n\n##  0.15.7 (2023-07-18)\n\n  * [humble] Don\\'t crash when type definition cannot be found, and find srv defs if available ( [ #1398 ](https://github.com/ros2/rosbag2/issues/1398) ) \n  * [humble] Add ROS_DISTRO metadata record to mcap file when opening for writing (backport [ #1371 ](https://github.com/ros2/rosbag2/issues/1371) ) ( [ #1393 ](https://github.com/ros2/rosbag2/issues/1393) ) \n  * Contributors: Emerson Knapp, Michael Orlov, mergify[bot] \n\n##  0.15.6 (2023-06-05)\n\n##  0.15.5 (2023-04-25)\n\n  * Add Michael Orlov as maintainer in rosbag2 packages ( [ #1215 ](https://github.com/ros2/rosbag2/issues/1215) ) ( [ #1224 ](https://github.com/ros2/rosbag2/issues/1224) ) \n  * Contributors: mergify[bot] \n\n##  0.15.4 (2023-01-10)\n\n  * rosbag2_storage_mcap: fix rosbag2_cpp tests ( [ #1205 ](https://github.com/ros2/rosbag2/issues/1205) ) \n  * [Humble backport] rosbag2_storage_mcap: merge into rosbag2 repo ( [ #1163 ](https://github.com/ros2/rosbag2/issues/1163) ) ( [ #1189 ](https://github.com/ros2/rosbag2/issues/1189) ) \n  * Contributors: james-rms \n\n##  0.6.0 (2022-11-28)\n\n  * mcap_storage: \\'none\\' is a valid storage preset profile ( [ #86 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/86) ) \n  * mcap_storage: handle update_metadata call ( [ #83 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/83) ) \n  * Update clang-format rules to fit ROS 2 style guide ( [ #80 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/80) ) \n  * Revert \\\"read_order: throw exception from set_read_order for unsupported orders\\\" This reverts commit aef9b9a65293f9e5d80a858ef84e485a8655a0c0. \n  * read_order: throw exception from set_read_order for unsupported orders \n  * Fix compile flags to work on rosbag_storage:0.17.x ( [ #78 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/78) ) This fixes the compile flags for rolling, which has two versions -- one that does not support read order (0.17.x) and one that does support read order (0.18.x). \n  * Fix Windows build ( [ #73 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/73) ) Update mcap version to newest windows-compatible release. Add visibility macros for tests. Add clang-format preprocessor indentation for visibility_control to be readable. \n  * Contributors: Andrew Symington, Emerson Knapp, James Smith, james-rms \n\n##  0.5.0 (2022-11-02)\n\n  * set defaults for SQLite plugin parity ( [ #68 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/68) ) \n  * rosbag2_storage_mcap: add storage preset profiles ( [ #57 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/57) ) \n  * rename test_fixture_interfaces package to testdata ( [ #64 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/64) ) \n  * Switch to using the vendored zstd library. ( [ #59 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/59) ) \n  * Add set_read_order reader API ( [ #54 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/54) ) \n  * Contributors: Chris Lalancette, Emerson Knapp, James Smith \n\n##  0.4.0 (2022-10-06)\n\n  * Some minor improvements in rosbag2_storage_mcap after review ( [ #58 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/58) ) \n\n    1. Fixed some findings from Clang-Tidy \n    2. Some renames according to the ROS2 coding style \n    3. Add default initializations for member variables \n\n1\\. Moved code responsible for adding schema and channel from write(msg) to\ncreate_topic(topic) method to reduce performance burden on first message write\nand in lieu to preparation for moving schema collection process to upper\nSequentialWriter layer.\n\n  * Revert \\\"rosbag2_storage_mcap: add storage preset profiles\\\" This reverts commit 38830add3935b978968fe2703d3180b413ccc8c2. \n\n  * rosbag2_storage_mcap: add storage preset profiles \n\n  * Contributors: James Smith, Michael Orlov \n\n##  0.3.0 (2022-09-09)\n\n  * Store IDL message definitions in Schema records when no MSG definition is available ( [ #43 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/43) ) \n  * Contributors: James Smith \n\n##  0.2.0 (2022-09-08)\n\n  * Support timestamp-ordered playback ( [ #50 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/50) ) \n  * Support regex topic filtering \n  * Contributors: James Smith \n\n##  0.1.7 (2022-08-15)\n\n  * Add all lz4 sources to fix undefined symbols at runtime ( [ #46 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/46) ) \n  * Contributors: Emerson Knapp \n\n##  0.1.6 (2022-07-22)\n\n  * Upgrade mcap to fix LZ4 error and segfault ( [ #42 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/42) ) Incorporates fixes from [ https://github.com/foxglove/mcap/pull/478 ](https://github.com/foxglove/mcap/pull/478) and [ https://github.com/foxglove/mcap/pull/482 ](https://github.com/foxglove/mcap/pull/482)\n  * Contributors: Jacob Bandes-Storch \n\n##  0.1.5 (2022-04-25)\n\n  * Fix build for Foxy ( [ #34 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/34) ) \n  * Contributors: Jacob Bandes-Storch \n\n##  0.1.4 (2022-04-21)\n\n  * fix: minor issues ( [ #31 ](https://github.com/wep21/rosbag2_storage_mcap/issues/31) ) \n    * remove unnecessary block \n    * use target_link_libraries instead of ament_target_dependencies \n    * remove ros environment \n    * add prefix to compile definition \n  * Update email address for Foxglove maintainers ( [ #32 ](https://github.com/wep21/rosbag2_storage_mcap/issues/32) ) \n  * Contributors: Daisuke Nishimatsu, Jacob Bandes-Storch \n\n##  0.1.3 (2022-04-20)\n\n##  0.1.2 (2022-04-20)\n\n  * Added mcap_vendor package. Updated CMakeLists.txt to fetch dependencies with FetchContent rather than Conan. \n  * Contributors: Jacob Bandes-Storch \n\n##  0.1.1 (2022-04-01)\n\n  * CMake build script will now execute pip install conan automatically. \n  * Contributors: Daisuke Nishimatsu \n\n##  0.1.0 (2022-03-24)\n\n  * [1.0.0] Use Summary section for get_metadata() and seek(), implement remaining methods ( [ #17 ](https://github.com/wep21/rosbag2_storage_mcap/issues/17) ) \n  * feat: add play impl ( [ #16 ](https://github.com/wep21/rosbag2_storage_mcap/issues/16) ) \n  * chore: refine package.xml ( [ #15 ](https://github.com/wep21/rosbag2_storage_mcap/issues/15) ) \n  * Don\\'t throw when READ_WRITE mode is used; add .mcap file extension to recorded files ( [ #14 ](https://github.com/wep21/rosbag2_storage_mcap/issues/14) ) I may be missing something, but from a cursory glance at [this code]( [ https://github.com/ros2/rosbag2/blob/342d8ed3c1c4ae0411a4a92b60e79a728b8974b8/rosbag2_storage/src/rosbag2_storage/impl/storage_factory_impl.hpp#L108-L135 ](https://github.com/ros2/rosbag2/blob/342d8ed3c1c4ae0411a4a92b60e79a728b8974b8/rosbag2_storage/src/rosbag2_storage/impl/storage_factory_impl.hpp#L108-L135) ), it appears that the [APPEND]{.title-ref} mode is never used. This means we need to support [READ_WRITE]{.title-ref}. This also adds a [.mcap]{.title-ref} extension to recorded file names. \n  * Add dynamic message definition lookup ( [ #13 ](https://github.com/wep21/rosbag2_storage_mcap/issues/13) ) Currently, an exception will be thrown if lookup fails. \n  * Switch C++ formatter to clang-format ( [ #12 ](https://github.com/wep21/rosbag2_storage_mcap/issues/12) ) Remove uncrustify linter in favor of clang-format, which is easier to configure for use in VS Code format-on-save. \n  * Merge pull request [ #7 ](https://github.com/wep21/rosbag2_storage_mcap/issues/7) from ros-tooling/jhurliman/reader-writer Reader and writer implementation \n  * uninitialized struct \n  * lint \n  * lint \n  * lint \n  * Reader and writer implementation \n  * Merge pull request [ #6 ](https://github.com/wep21/rosbag2_storage_mcap/issues/6) from wep21/add-metadata-impl feat: add metadata impl \n  * feat: add metadata impl \n  * Merge pull request [ #5 ](https://github.com/wep21/rosbag2_storage_mcap/issues/5) from wep21/mcap-storage-impl feat: mcap storage impl \n  * chore: update cmake minimum version \n  * chore: install mcap header \n  * chore: include mcap header \n  * fix: move fetch content into rosbag2 storage mcap \n  * Merge pull request [ #3 ](https://github.com/wep21/rosbag2_storage_mcap/issues/3) from ros-tooling/emersonknapp/mcap_plugin_skeleton Add mcap storage plugin skeleton and CI \n  * Add rosbag2_storage_mcap skeleton \n  * Contributors: Daisuke Nishimatsu, Emerson Knapp, Jacob Bandes-Storch, John Hurliman, wep21 \n\n###  Wiki Tutorials\n\n_See[ ROS Wiki Tutorials ](http://wiki.ros.org/rosbag2_storage_mcap/Tutorials)\nfor more details. _\n\n###  Source Tutorials\n\n_Not currently indexed._\n\n###  Package Dependencies\n\nDeps  |  |  Name  |  [ ](/p/ament_cmake#humble-deps) |  [ 1\n](/packages/ament_cmake) |  [ ament_cmake ](/p/ament_cmake#humble)  \n---|---|---  \n[ ](/p/ament_cmake_clang_format#humble-deps) |  [ 1\n](/packages/ament_cmake_clang_format) |  [ ament_cmake_clang_format\n](/p/ament_cmake_clang_format#humble)  \n[ ](/p/ament_cmake_gmock#humble-deps) |  [ 1 ](/packages/ament_cmake_gmock) |\n[ ament_cmake_gmock ](/p/ament_cmake_gmock#humble)  \n[ ](/p/ament_lint_auto#humble-deps) |  [ 1 ](/packages/ament_lint_auto) |  [\nament_lint_auto ](/p/ament_lint_auto#humble)  \n[ ](/p/ament_lint_common#humble-deps) |  [ 1 ](/packages/ament_lint_common) |\n[ ament_lint_common ](/p/ament_lint_common#humble)  \n[ ](/p/rcpputils#humble-deps) |  [ 1 ](/packages/rcpputils) |  [ rcpputils\n](/p/rcpputils#humble)  \n[ ](/p/rosbag2_test_common#humble-deps) |  [ 1\n](/packages/rosbag2_test_common) |  [ rosbag2_test_common\n](/p/rosbag2_test_common#humble)  \n[ ](/p/std_msgs#humble-deps) |  [ 2 ](/packages/std_msgs) |  [ std_msgs\n](/p/std_msgs#humble)  \n[ ](/p/rosbag2_storage_mcap_testdata#humble-deps) |  [ 2\n](/packages/rosbag2_storage_mcap_testdata) |  [ rosbag2_storage_mcap_testdata\n](/p/rosbag2_storage_mcap_testdata#humble)  \n[ ](/p/ament_index_cpp#humble-deps) |  [ 1 ](/packages/ament_index_cpp) |  [\nament_index_cpp ](/p/ament_index_cpp#humble)  \n[ ](/p/mcap_vendor#humble-deps) |  [ 2 ](/packages/mcap_vendor) |  [\nmcap_vendor ](/p/mcap_vendor#humble)  \n[ ](/p/pluginlib#humble-deps) |  [ 1 ](/packages/pluginlib) |  [ pluginlib\n](/p/pluginlib#humble)  \n[ ](/p/rcutils#humble-deps) |  [ 1 ](/packages/rcutils) |  [ rcutils\n](/p/rcutils#humble)  \n[ ](/p/rosbag2_storage#humble-deps) |  [ 1 ](/packages/rosbag2_storage) |  [\nrosbag2_storage ](/p/rosbag2_storage#humble)  \n  \n###  System Dependencies\n\n_No direct system dependencies._\n\n###  Dependant Packages\n\nName  |  Repo  |  Deps  |  [ andino_bringup ](/p/andino_bringup/github-Ekumen-\nOS-andino#humble) |  [ github-Ekumen-OS-andino ](/r/andino/github-Ekumen-OS-\nandino) |  [ ](/p/andino_bringup/github-Ekumen-OS-andino#humble-deps)  \n---|---|---  \n  \n###  Launch files\n\n_No launch files found_\n\n###  Messages\n\n_No message files found._\n\n###  Services\n\n_No service files found_\n\n###  Plugins\n\n_No plugins found._\n\n###  Recent questions tagged ` rosbag2_storage_mcap ` at **[ Robotics Stack\nExchange ](https://robotics.stackexchange.com/) **\n\nNo questions yet, you can ask one [ here\n](https://robotics.stackexchange.com/questions/tagged/rosbag2_storage_mcap+humble)\n.\n\nFailed to get question list, you can ticket an issue [ here\n](https://github.com/ros-infrastructure/rosindex/issues/new)\n\n[ API Docs ](http://docs.ros.org/en/humble/p/rosbag2_storage_mcap \"View API\ndocumentation on docs.ros.org\") [ Browse Code\n](https://github.com/ros2/rosbag2/tree/humble/rosbag2_storage_mcap \"View\nsource code on repository\")\n\n![](/assets/package.png) |\n\n###  [ rosbag2_storage_mcap ](/p/rosbag2_storage_mcap) package from [ rosbag2\n](/r/rosbag2/github-ros2-rosbag2) repo\n\n[ mcap_vendor ](/p/mcap_vendor/github-ros2-rosbag2) [ ros2bag\n](/p/ros2bag/github-ros2-rosbag2) [ rosbag2 ](/p/rosbag2/github-ros2-rosbag2)\n[ rosbag2_compression ](/p/rosbag2_compression/github-ros2-rosbag2) [\nrosbag2_compression_zstd ](/p/rosbag2_compression_zstd/github-ros2-rosbag2) [\nrosbag2_cpp ](/p/rosbag2_cpp/github-ros2-rosbag2) [ rosbag2_examples_cpp\n](/p/rosbag2_examples_cpp/github-ros2-rosbag2) [ rosbag2_examples_py\n](/p/rosbag2_examples_py/github-ros2-rosbag2) [ rosbag2_interfaces\n](/p/rosbag2_interfaces/github-ros2-rosbag2) [\nrosbag2_performance_benchmarking ](/p/rosbag2_performance_benchmarking/github-\nros2-rosbag2) [ rosbag2_performance_benchmarking_msgs\n](/p/rosbag2_performance_benchmarking_msgs/github-ros2-rosbag2) [ rosbag2_py\n](/p/rosbag2_py/github-ros2-rosbag2) [ rosbag2_storage\n](/p/rosbag2_storage/github-ros2-rosbag2) [ rosbag2_storage_default_plugins\n](/p/rosbag2_storage_default_plugins/github-ros2-rosbag2) rosbag2_storage_mcap\n[ rosbag2_storage_sqlite3 ](/p/rosbag2_storage_sqlite3/github-ros2-rosbag2) [\nrosbag2_test_common ](/p/rosbag2_test_common/github-ros2-rosbag2) [\nrosbag2_test_msgdefs ](/p/rosbag2_test_msgdefs/github-ros2-rosbag2) [\nrosbag2_tests ](/p/rosbag2_tests/github-ros2-rosbag2) [ rosbag2_transport\n](/p/rosbag2_transport/github-ros2-rosbag2) [ shared_queues_vendor\n](/p/shared_queues_vendor/github-ros2-rosbag2) [ sqlite3_vendor\n](/p/sqlite3_vendor/github-ros2-rosbag2) [ zstd_vendor\n](/p/zstd_vendor/github-ros2-rosbag2)  \n---|---  \n  \ngithub-ros2-rosbag2\n\n  * [ github-ros2-rosbag2 ](/p/rosbag2_storage_mcap/github-ros2-rosbag2)\n  * [ github-ros-tooling-rosbag2_storage_mcap ](/p/rosbag2_storage_mcap/github-ros-tooling-rosbag2_storage_mcap)\n\n  \n  \n---  \n  \n[  \nAPI Docs ](http://docs.ros.org/en/iron/p/rosbag2_storage_mcap \"View API\ndocumentation on docs.ros.org\") [  \nBrowse Code ](https://github.com/ros2/rosbag2/tree/iron/rosbag2_storage_mcap\n\"View source code on repository\")\n\n  * Overview \n  * 0  Assets \n  * 13  Dependencies \n  * 0  Tutorials \n  * 0  Q & A \n\n####  Package Summary\n\n**Tags** |  _No category tags._  \n---|---  \n**Version** |  0.22.6  \n**License** |  Apache-2.0  \n**Build type** |  AMENT_CMAKE  \n**Use** |  RECOMMENDED  \n  \n###  Repository Summary\n\n**Checkout URI** |  [ https://github.com/ros2/rosbag2.git\n](https://github.com/ros2/rosbag2.git)  \n---|---  \n**VCS Type** |  git  \n**VCS Version** |  iron  \n**Last Updated**  \n  \n2024-02-08  |  **Dev Status** |  DEVELOPED  \n**CI status** |  No Continuous Integration  \n**Released** |  RELEASED  \n**Tags** |  _No category tags._  \n**Contributing** |  [ Help Wanted (  0  ) ](/r/rosbag2/#iron-contribute-lists-\nhelp-wanted)  \n[ Good First Issues (  0  ) ](/r/rosbag2/#iron-contribute-lists-good-first-\nissue)  \n[ Pull Requests to Review (  0  ) ](/r/rosbag2/#iron-contribute-lists-pull-\nrequests)  \n  \n###  Package Description\n\nrosbag2 storage plugin using the MCAP file format\n\n####  Additional Links\n\n_No additional links._\n\n####  Maintainers\n\n  * Foxglove \n  * Michael Orlov \n  * ROS Tooling Working Group \n\n####  Authors\n\n_No additional authors._\n\n[ rosbag2_storage_mcap/README.md\n](https://github.com/ros2/rosbag2/tree/iron/rosbag2_storage_mcap/README.md\n\"Open in git repository\")\n\n#  rosbag2_storage_mcap\n\nThis package provides a [ storage plugin\n](https://github.com/ros2/rosbag2#storage-format-plugin-architecture) for\nrosbag2 which extends it with support for the [ MCAP ](https://mcap.dev) file\nformat.\n\n[ ![ROS Foxy version](https://img.shields.io/ros/v/foxy/rosbag2_storage_mcap)\n](https://index.ros.org/p/rosbag2_storage_mcap/github-ros2-rosbag2/#foxy) [\n![ROS Galactic\nversion](https://img.shields.io/ros/v/galactic/rosbag2_storage_mcap)\n](https://index.ros.org/p/rosbag2_storage_mcap/github-ros2-rosbag2/#galactic)\n[ ![ROS Humble\nversion](https://img.shields.io/ros/v/humble/rosbag2_storage_mcap)\n](https://index.ros.org/p/rosbag2_storage_mcap/github-ros2-rosbag2/#humble) [\n![ROS Rolling\nversion](https://img.shields.io/ros/v/rolling/rosbag2_storage_mcap)\n](https://index.ros.org/p/rosbag2_storage_mcap/github-ros2-rosbag2/#rolling)\n\n##  \u26a0\ufe0f Move from ` ros-tooling ` organization\n\nThis package was recently merged into [ https://github.com/ros2/rosbag2\n](https://github.com/ros2/rosbag2/tree/iron/rosbag2_storage_mcap/ros2/rosbag2)\nfrom [ https://github.com/ros-tooling/rosbag2_storage_mcap\n](https://github.com/ros2/rosbag2/tree/iron/rosbag2_storage_mcap/ros-\ntooling/rosbag2_storage_mcap) . To view historical pull requests and git\nhistory of this package, check [ here ](https://github.com/ros-\ntooling/rosbag2_storage_mcap/commits/main) .\n\n##  Installation\n\nrosbag2_storage_mcap is available as part of the [ current ROS 2 distributions\n](https://docs.ros.org/en/rolling/Releases.html) . On Ubuntu, after following\nthe [ ROS 2 installation instructions\n](https://docs.ros.org/en/humble/Installation.html) , you can use:\n\n    \n    \n    # Replace \"rolling\" with your ROS distro (`echo $ROS_DISTRO`)\n    $ sudo apt install ros-rolling-rosbag2-storage-mcap\n    \n    \n\n##  Usage\n\nUse MCAP files with regular [ ` ros2 bag ` commands\n](https://docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools/Recording-And-\nPlaying-Back-Data/Recording-And-Playing-Back-Data.html) by adding the `\n--storage mcap ` option (abbreviated as ` -s mcap ` ):\n\n    \n    \n    $ ros2 bag record -s mcap /topic1 /topic2 ...\n    \n    $ ros2 bag play -s mcap path/to/your_recording.mcap\n    \n    $ ros2 bag info -s mcap path/to/your_recording.mcap\n    \n    \n\n###  Writer Configuration\n\nTo configure details of the MCAP writer for ` ros2 bag record ` , use the `\n--storage-config-file ` options to provide a YAML file describing `\nmcap::McapWriterOptions ` . Field descriptions below copied from [\nMcapWriterOptions declaration\n](https://github.com/foxglove/mcap/blob/main/cpp/mcap/include/mcap/writer.hpp#L18)\n\nField  |  Type / Values  |  Description  \n---|---|---  \nnoChunkCRC  |  bool  |  Disable CRC calculation for Chunks. Ignored if `\nnoChunking=true ` .  \nnoAttachmentCRC  |  bool  |  Disable CRC calculation for Attachments.  \nenableDataCRC  |  bool  |  Enables CRC calculation for the entire Data\nsection. Useful when ` noChunking=True ` .  \nnoSummaryCRC  |  bool  |  Disable CRC calculation for the Summary section.  \nnoChunking  |  bool  |  Do not write Chunks to the file, instead writing\nSchema, Channel, and Message records directly into the Data section.  \nnoMessageIndex  |  bool  |  Do not write Message Index records to the file. If\n` noSummary=true ` and ` noChunkIndex=false ` , Chunk Index records will still\nbe written to the Summary section, providing a coarse message index.  \nnoSummary  |  bool  |  Do not write Summary or Summary Offset sections to the\nfile, placing the Footer record immediately after DataEnd. This can provide\nsome speed boost to file writing and produce smaller files, at the expense of\nrequiring a conversion process later if fast summarization or indexed access\nis desired.  \nchunkSize  |  unsigned int  |  Target uncompressed Chunk payload size in\nbytes. Once a Chunk's uncompressed data meets or exceeds this size, the Chunk\nwill be compressed (if compression is enabled) and written to disk. Note that\nsmaller Chunks may be written, such as the last Chunk in the Data section.\nThis option is ignored if ` noChunking=true ` .  \ncompression  |  \"None\", \"Lz4\", \"Zstd\"  |  Compression algorithm to use when\nwriting Chunks. This option is ignored if ` noChunking=true ` .  \ncompressionLevel  |  \"Fastest\", \"Fast\", \"Default\", \"Slow\", \"Slowest\"  |\nCompression level to use when writing Chunks. Slower generally produces\nsmaller files, at the expense of more CPU time. These levels map to different\ninternal settings for each compression algorithm.  \nforceCompression  |  bool  |  By default, Chunks that do not benefit from\ncompression will be written uncompressed. This option can be used to force\ncompression on all Chunks. This option is ignored if ` noChunking=true ` .  \nnoRepeatedSchemas  |  bool  |  Advanced option.  \nnoRepeatedChannels  |  bool  |  Advanced option.  \nnoMetadataIndex  |  bool  |  Advanced option.  \nnoChunkIndex  |  bool  |  Advanced option.  \nnoStatistics  |  bool  |  Advanced option.  \nnoSummaryOffsets  |  bool  |  Advanced option.  \n  \nExample:\n\n    \n    \n    # mcap_writer_options.yml\n    noChunkCRC: false\n    noChunking: false\n    noMessageIndex: false\n    noSummary: false\n    chunkSize: 786432\n    compression: \"Zstd\"\n    compressionLevel: \"Fast\"\n    forceCompression: false\n    \n    \n    \n    \n    $ ros2 bag record -s mcap -o my_bag --all --storage-config-file mcap_writer_options.yml\n    \n    \n\n###  Storage Preset Profiles\n\nYou can also use one of the preset profiles described below, for example:\n\n    \n    \n    $ ros2 bag record -s mcap -o my_bag --all --storage-preset-profile fastwrite\n    \n    \n\n####  ` fastwrite `\n\nConfigures the MCAP writer for the highest possible write throughput and\nlowest resource utilization. This preset does not calculate CRCs for integrity\nchecking, and does not write a message index. This preset profile is useful\nfor resource-constrained robots.\n\nEquivalent to this storage configuration:\n\n    \n    \n    noChunking: true\n    noSummaryCRC: true\n    \n    \n\nUsing MCAPs written with ` fastwrite ` as a long-term storage format is not\nrecommended. Some features will not work when reading MCAP files without a\nmessage index, such as reading messages from a subset of topics or seeking.\nWhen recording MCAPs on your robot with ` fastwrite ` , it is a good idea to\npost-process these files afterwards, to restore the message index and also\nsave storage space:\n\n    \n    \n    # Using the MCAP CLI https://github.com/foxglove/mcap/tree/main/go/cli/mcap\n    $ mcap compress fast.mcap -o compressed.mcap\n    # Using `ros2 bag convert`\n    $ cat << EOF > convert.yaml\n    output_bags:\n      - uri: compressed\n        storage_id: mcap\n        storage_preset_profile: zstd_small\n    EOF\n    $ ros2 bag convert -i fast.mcap -o convert.yaml\n    \n    \n\nEquivalent to this storage configuration:\n\n    \n    \n    noChunking: true\n    noSummaryCRC: true\n    \n    \n\n####  ` zstd_fast `\n\nConfigures the MCAP writer to use chunk compression with [ zstd\n](http://facebook.github.io/zstd/) . Chunk compression yields file sizes\ncomparable to bags compressed with file-level compression, but allows tools to\nefficiently read messages without decompressing the entire bag. This preset\nuses the lowest compression ratio and disables CRC calculation, to achieve\nhigh throughput while conserving disk space.\n\nEquivalent to this storage configuration:\n\n    \n    \n    compression: \"Zstd\"\n    compressionLevel: \"Fastest\"\n    noChunkCRC: true\n    \n    \n\n####  ` zstd_small `\n\nConfigures the MCAP writer to write 4MB chunks, compressed with zstd using its\nhighest compression ratio. This produces very small bags, but can be resource-\nintensive to write. This preset also calculates chunk CRCs, which allow a\nreader to determine if a chunk is corrupted. This preset is useful when using\n` ros2 bag convert ` as a post-processing step.\n\nEquivalent to this storage configuration:\n\n    \n    \n    compression: \"Zstd\"\n    compressionLevel: \"Slowest\"\n    chunkSize: 4194304 # 4 * 1024 * 1024\n    \n    \n\n###  ROS 2 Distro maintenance\n\nWhenever a ROS 2 distribution reaches EOL, search for comments marked\nCOMPATIBILITY - which may no longer be needed when no new releases will be\nmade for that distro.\n\nCHANGELOG\n\n#  Changelog for package rosbag2_storage_mcap\n\n##  0.22.6 (2024-02-07)\n\n  * Use rw_lock to protect mcap metadata lists. ( [ #1566 ](https://github.com/ros2/rosbag2/issues/1566) ) \n  * Remove rcpputils::fs dependencies from rosbag2_storages ( [ #1564 ](https://github.com/ros2/rosbag2/issues/1564) ) \n  * Link and compile against rosbag2_storage_mcap: Fixed issue 1492 ( [ #1497 ](https://github.com/ros2/rosbag2/issues/1497) ) \n  * Contributors: Alejandro Hern \n\n###  Wiki Tutorials\n\n_See[ ROS Wiki Tutorials ](http://wiki.ros.org/rosbag2_storage_mcap/Tutorials)\nfor more details. _\n\n###  Source Tutorials\n\n_Not currently indexed._\n\n###  Package Dependencies\n\nDeps  |  |  Name  |  [ ](/p/ament_cmake#iron-deps) |  [ 1\n](/packages/ament_cmake) |  [ ament_cmake ](/p/ament_cmake#iron)  \n---|---|---  \n[ ](/p/ament_cmake_python#iron-deps) |  [ 1 ](/packages/ament_cmake_python) |\n[ ament_cmake_python ](/p/ament_cmake_python#iron)  \n[ ](/p/ament_cmake_clang_format#iron-deps) |  [ 1\n](/packages/ament_cmake_clang_format) |  [ ament_cmake_clang_format\n](/p/ament_cmake_clang_format#iron)  \n[ ](/p/ament_cmake_gmock#iron-deps) |  [ 1 ](/packages/ament_cmake_gmock) |  [\nament_cmake_gmock ](/p/ament_cmake_gmock#iron)  \n[ ](/p/ament_lint_auto#iron-deps) |  [ 1 ](/packages/ament_lint_auto) |  [\nament_lint_auto ](/p/ament_lint_auto#iron)  \n[ ](/p/ament_lint_common#iron-deps) |  [ 1 ](/packages/ament_lint_common) |  [\nament_lint_common ](/p/ament_lint_common#iron)  \n[ ](/p/rosbag2_test_common#iron-deps) |  [ 1 ](/packages/rosbag2_test_common)\n|  [ rosbag2_test_common ](/p/rosbag2_test_common#iron)  \n[ ](/p/std_msgs#iron-deps) |  [ 2 ](/packages/std_msgs) |  [ std_msgs\n](/p/std_msgs#iron)  \n[ ](/p/ament_index_cpp#iron-deps) |  [ 1 ](/packages/ament_index_cpp) |  [\nament_index_cpp ](/p/ament_index_cpp#iron)  \n[ ](/p/mcap_vendor#iron-deps) |  [ 2 ](/packages/mcap_vendor) |  [ mcap_vendor\n](/p/mcap_vendor#iron)  \n[ ](/p/pluginlib#iron-deps) |  [ 1 ](/packages/pluginlib) |  [ pluginlib\n](/p/pluginlib#iron)  \n[ ](/p/rcutils#iron-deps) |  [ 1 ](/packages/rcutils) |  [ rcutils\n](/p/rcutils#iron)  \n[ ](/p/rosbag2_storage#iron-deps) |  [ 1 ](/packages/rosbag2_storage) |  [\nrosbag2_storage ](/p/rosbag2_storage#iron)  \n  \n###  System Dependencies\n\n_No direct system dependencies._\n\n###  Dependant Packages\n\nName  |  Repo  |  Deps  |  [ rosbag2_storage_default_plugins\n](/p/rosbag2_storage_default_plugins/github-ros2-rosbag2#iron) |  [ github-\nros2-rosbag2 ](/r/rosbag2/github-ros2-rosbag2) |  [\n](/p/rosbag2_storage_default_plugins/github-ros2-rosbag2#iron-deps)  \n---|---|---  \n  \n###  Launch files\n\n_No launch files found_\n\n###  Messages\n\n_No message files found._\n\n###  Services\n\n_No service files found_\n\n###  Plugins\n\n_No plugins found._\n\n###  Recent questions tagged ` rosbag2_storage_mcap ` at **[ Robotics Stack\nExchange ](https://robotics.stackexchange.com/) **\n\nNo questions yet, you can ask one [ here\n](https://robotics.stackexchange.com/questions/tagged/rosbag2_storage_mcap+iron)\n.\n\nFailed to get question list, you can ticket an issue [ here\n](https://github.com/ros-infrastructure/rosindex/issues/new)\n\n[ API Docs ](http://docs.ros.org/en/iron/p/rosbag2_storage_mcap \"View API\ndocumentation on docs.ros.org\") [ Browse Code\n](https://github.com/ros2/rosbag2/tree/iron/rosbag2_storage_mcap \"View source\ncode on repository\")\n\n![](/assets/package.png) |\n\n###  [ rosbag2_storage_mcap ](/p/rosbag2_storage_mcap) package from [ rosbag2\n](/r/rosbag2/github-ros2-rosbag2) repo\n\n[ liblz4_vendor ](/p/liblz4_vendor/github-ros2-rosbag2) [ mcap_vendor\n](/p/mcap_vendor/github-ros2-rosbag2) [ ros2bag ](/p/ros2bag/github-\nros2-rosbag2) [ rosbag2 ](/p/rosbag2/github-ros2-rosbag2) [\nrosbag2_compression ](/p/rosbag2_compression/github-ros2-rosbag2) [\nrosbag2_compression_zstd ](/p/rosbag2_compression_zstd/github-ros2-rosbag2) [\nrosbag2_cpp ](/p/rosbag2_cpp/github-ros2-rosbag2) [ rosbag2_examples_cpp\n](/p/rosbag2_examples_cpp/github-ros2-rosbag2) [ rosbag2_examples_py\n](/p/rosbag2_examples_py/github-ros2-rosbag2) [ rosbag2_interfaces\n](/p/rosbag2_interfaces/github-ros2-rosbag2) [\nrosbag2_performance_benchmarking ](/p/rosbag2_performance_benchmarking/github-\nros2-rosbag2) [ rosbag2_performance_benchmarking_msgs\n](/p/rosbag2_performance_benchmarking_msgs/github-ros2-rosbag2) [ rosbag2_py\n](/p/rosbag2_py/github-ros2-rosbag2) [ rosbag2_storage\n](/p/rosbag2_storage/github-ros2-rosbag2) [ rosbag2_storage_default_plugins\n](/p/rosbag2_storage_default_plugins/github-ros2-rosbag2) rosbag2_storage_mcap\n[ rosbag2_storage_sqlite3 ](/p/rosbag2_storage_sqlite3/github-ros2-rosbag2) [\nrosbag2_test_common ](/p/rosbag2_test_common/github-ros2-rosbag2) [\nrosbag2_test_msgdefs ](/p/rosbag2_test_msgdefs/github-ros2-rosbag2) [\nrosbag2_tests ](/p/rosbag2_tests/github-ros2-rosbag2) [ rosbag2_transport\n](/p/rosbag2_transport/github-ros2-rosbag2) [ shared_queues_vendor\n](/p/shared_queues_vendor/github-ros2-rosbag2) [ sqlite3_vendor\n](/p/sqlite3_vendor/github-ros2-rosbag2) [ zstd_vendor\n](/p/zstd_vendor/github-ros2-rosbag2)  \n---|---  \n  \ngithub-ros2-rosbag2\n\n  * [ github-ros2-rosbag2 ](/p/rosbag2_storage_mcap/github-ros2-rosbag2)\n  * [ github-ros-tooling-rosbag2_storage_mcap ](/p/rosbag2_storage_mcap/github-ros-tooling-rosbag2_storage_mcap)\n\n  \n  \n---  \n  \n[  \nAPI Docs ](http://docs.ros.org/en/rolling/p/rosbag2_storage_mcap \"View API\ndocumentation on docs.ros.org\") [  \nBrowse Code\n](https://github.com/ros2/rosbag2/tree/rolling/rosbag2_storage_mcap \"View\nsource code on repository\")\n\n  * Overview \n  * 0  Assets \n  * 14  Dependencies \n  * 0  Tutorials \n  * 0  Q & A \n\n####  Package Summary\n\n**Tags** |  _No category tags._  \n---|---  \n**Version** |  0.26.0  \n**License** |  Apache-2.0  \n**Build type** |  AMENT_CMAKE  \n**Use** |  RECOMMENDED  \n  \n###  Repository Summary\n\n**Checkout URI** |  [ https://github.com/ros2/rosbag2.git\n](https://github.com/ros2/rosbag2.git)  \n---|---  \n**VCS Type** |  git  \n**VCS Version** |  rolling  \n**Last Updated**  \n  \n2024-04-17  |  **Dev Status** |  DEVELOPED  \n**CI status** |  No Continuous Integration  \n**Released** |  RELEASED  \n**Tags** |  _No category tags._  \n**Contributing** |  [ Help Wanted (  0  ) ](/r/rosbag2/#rolling-contribute-\nlists-help-wanted)  \n[ Good First Issues (  0  ) ](/r/rosbag2/#rolling-contribute-lists-good-first-\nissue)  \n[ Pull Requests to Review (  0  ) ](/r/rosbag2/#rolling-contribute-lists-pull-\nrequests)  \n  \n###  Package Description\n\nrosbag2 storage plugin using the MCAP file format\n\n####  Additional Links\n\n_No additional links._\n\n####  Maintainers\n\n  * Foxglove \n  * Michael Orlov \n  * ROS Tooling Working Group \n\n####  Authors\n\n_No additional authors._\n\n[ rosbag2_storage_mcap/README.md\n](https://github.com/ros2/rosbag2/tree/rolling/rosbag2_storage_mcap/README.md\n\"Open in git repository\")\n\n#  rosbag2_storage_mcap\n\nThis package provides a [ storage plugin\n](https://github.com/ros2/rosbag2#storage-format-plugin-architecture) for\nrosbag2 which extends it with support for the [ MCAP ](https://mcap.dev) file\nformat.\n\n[ ![ROS Foxy version](https://img.shields.io/ros/v/foxy/rosbag2_storage_mcap)\n](https://index.ros.org/p/rosbag2_storage_mcap/github-ros2-rosbag2/#foxy) [\n![ROS Galactic\nversion](https://img.shields.io/ros/v/galactic/rosbag2_storage_mcap)\n](https://index.ros.org/p/rosbag2_storage_mcap/github-ros2-rosbag2/#galactic)\n[ ![ROS Humble\nversion](https://img.shields.io/ros/v/humble/rosbag2_storage_mcap)\n](https://index.ros.org/p/rosbag2_storage_mcap/github-ros2-rosbag2/#humble) [\n![ROS Rolling\nversion](https://img.shields.io/ros/v/rolling/rosbag2_storage_mcap)\n](https://index.ros.org/p/rosbag2_storage_mcap/github-ros2-rosbag2/#rolling)\n\n##  \u26a0\ufe0f Move from ` ros-tooling ` organization\n\nThis package was recently merged into [ https://github.com/ros2/rosbag2\n](https://github.com/ros2/rosbag2/tree/rolling/rosbag2_storage_mcap/ros2/rosbag2)\nfrom [ https://github.com/ros-tooling/rosbag2_storage_mcap\n](https://github.com/ros2/rosbag2/tree/rolling/rosbag2_storage_mcap/ros-\ntooling/rosbag2_storage_mcap) . To view historical pull requests and git\nhistory of this package, check [ here ](https://github.com/ros-\ntooling/rosbag2_storage_mcap/commits/main) .\n\n##  Installation\n\nrosbag2_storage_mcap is available as part of the [ current ROS 2 distributions\n](https://docs.ros.org/en/rolling/Releases.html) . On Ubuntu, after following\nthe [ ROS 2 installation instructions\n](https://docs.ros.org/en/humble/Installation.html) , you can use:\n\n    \n    \n    # Replace \"rolling\" with your ROS distro (`echo $ROS_DISTRO`)\n    $ sudo apt install ros-rolling-rosbag2-storage-mcap\n    \n    \n\n##  Usage\n\nUse MCAP files with regular [ ` ros2 bag ` commands\n](https://docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools/Recording-And-\nPlaying-Back-Data/Recording-And-Playing-Back-Data.html) by adding the `\n--storage mcap ` option (abbreviated as ` -s mcap ` ):\n\n    \n    \n    $ ros2 bag record -s mcap /topic1 /topic2 ...\n    \n    $ ros2 bag play -s mcap path/to/your_recording.mcap\n    \n    $ ros2 bag info -s mcap path/to/your_recording.mcap\n    \n    \n\n###  Writer Configuration\n\nTo configure details of the MCAP writer for ` ros2 bag record ` , use the `\n--storage-config-file ` options to provide a YAML file describing `\nmcap::McapWriterOptions ` . Field descriptions below copied from [\nMcapWriterOptions declaration\n](https://github.com/foxglove/mcap/blob/main/cpp/mcap/include/mcap/writer.hpp#L18)\n\nField  |  Type / Values  |  Description  \n---|---|---  \nnoChunkCRC  |  bool  |  Disable CRC calculation for Chunks. Ignored if `\nnoChunking=true ` .  \nnoAttachmentCRC  |  bool  |  Disable CRC calculation for Attachments.  \nenableDataCRC  |  bool  |  Enables CRC calculation for the entire Data\nsection. Useful when ` noChunking=True ` .  \nnoSummaryCRC  |  bool  |  Disable CRC calculation for the Summary section.  \nnoChunking  |  bool  |  Do not write Chunks to the file, instead writing\nSchema, Channel, and Message records directly into the Data section.  \nnoMessageIndex  |  bool  |  Do not write Message Index records to the file. If\n` noSummary=true ` and ` noChunkIndex=false ` , Chunk Index records will still\nbe written to the Summary section, providing a coarse message index.  \nnoSummary  |  bool  |  Do not write Summary or Summary Offset sections to the\nfile, placing the Footer record immediately after DataEnd. This can provide\nsome speed boost to file writing and produce smaller files, at the expense of\nrequiring a conversion process later if fast summarization or indexed access\nis desired.  \nchunkSize  |  unsigned int  |  Target uncompressed Chunk payload size in\nbytes. Once a Chunk's uncompressed data meets or exceeds this size, the Chunk\nwill be compressed (if compression is enabled) and written to disk. Note that\nsmaller Chunks may be written, such as the last Chunk in the Data section.\nThis option is ignored if ` noChunking=true ` .  \ncompression  |  \"None\", \"Lz4\", \"Zstd\"  |  Compression algorithm to use when\nwriting Chunks. This option is ignored if ` noChunking=true ` .  \ncompressionLevel  |  \"Fastest\", \"Fast\", \"Default\", \"Slow\", \"Slowest\"  |\nCompression level to use when writing Chunks. Slower generally produces\nsmaller files, at the expense of more CPU time. These levels map to different\ninternal settings for each compression algorithm.  \nforceCompression  |  bool  |  By default, Chunks that do not benefit from\ncompression will be written uncompressed. This option can be used to force\ncompression on all Chunks. This option is ignored if ` noChunking=true ` .  \nnoRepeatedSchemas  |  bool  |  Advanced option.  \nnoRepeatedChannels  |  bool  |  Advanced option.  \nnoMetadataIndex  |  bool  |  Advanced option.  \nnoChunkIndex  |  bool  |  Advanced option.  \nnoStatistics  |  bool  |  Advanced option.  \nnoSummaryOffsets  |  bool  |  Advanced option.  \n  \nExample:\n\n    \n    \n    # mcap_writer_options.yml\n    noChunkCRC: false\n    noChunking: false\n    noMessageIndex: false\n    noSummary: false\n    chunkSize: 786432\n    compression: \"Zstd\"\n    compressionLevel: \"Fast\"\n    forceCompression: false\n    \n    \n    \n    \n    $ ros2 bag record -s mcap -o my_bag --all --storage-config-file mcap_writer_options.yml\n    \n    \n\n###  Storage Preset Profiles\n\nYou can also use one of the preset profiles described below, for example:\n\n    \n    \n    $ ros2 bag record -s mcap -o my_bag --all --storage-preset-profile fastwrite\n    \n    \n\n####  ` fastwrite `\n\nConfigures the MCAP writer for the highest possible write throughput and\nlowest resource utilization. This preset does not calculate CRCs for integrity\nchecking, and does not write a message index. This preset profile is useful\nfor resource-constrained robots.\n\nEquivalent to this storage configuration:\n\n    \n    \n    noChunking: true\n    noSummaryCRC: true\n    \n    \n\nUsing MCAPs written with ` fastwrite ` as a long-term storage format is not\nrecommended. Some features will not work when reading MCAP files without a\nmessage index, such as reading messages from a subset of topics or seeking.\nWhen recording MCAPs on your robot with ` fastwrite ` , it is a good idea to\npost-process these files afterwards, to restore the message index and also\nsave storage space:\n\n    \n    \n    # Using the MCAP CLI https://github.com/foxglove/mcap/tree/main/go/cli/mcap\n    $ mcap compress fast.mcap -o compressed.mcap\n    # Using `ros2 bag convert`\n    $ cat << EOF > convert.yaml\n    output_bags:\n      - uri: compressed\n        storage_id: mcap\n        storage_preset_profile: zstd_small\n    EOF\n    $ ros2 bag convert -i fast.mcap -o convert.yaml\n    \n    \n\nEquivalent to this storage configuration:\n\n    \n    \n    noChunking: true\n    noSummaryCRC: true\n    \n    \n\n####  ` zstd_fast `\n\nConfigures the MCAP writer to use chunk compression with [ zstd\n](http://facebook.github.io/zstd/) . Chunk compression yields file sizes\ncomparable to bags compressed with file-level compression, but allows tools to\nefficiently read messages without decompressing the entire bag. This preset\nuses the lowest compression ratio and disables CRC calculation, to achieve\nhigh throughput while conserving disk space.\n\nEquivalent to this storage configuration:\n\n    \n    \n    compression: \"Zstd\"\n    compressionLevel: \"Fastest\"\n    noChunkCRC: true\n    \n    \n\n####  ` zstd_small `\n\nConfigures the MCAP writer to write 4MB chunks, compressed with zstd using its\nhighest compression ratio. This produces very small bags, but can be resource-\nintensive to write. This preset also calculates chunk CRCs, which allow a\nreader to determine if a chunk is corrupted. This preset is useful when using\n` ros2 bag convert ` as a post-processing step.\n\nEquivalent to this storage configuration:\n\n    \n    \n    compression: \"Zstd\"\n    compressionLevel: \"Slowest\"\n    chunkSize: 4194304 # 4 * 1024 * 1024\n    \n    \n\n###  ROS 2 Distro maintenance\n\nWhenever a ROS 2 distribution reaches EOL, search for comments marked\nCOMPATIBILITY - which may no longer be needed when no new releases will be\nmade for that distro.\n\nCHANGELOG\n\n#  Changelog for package rosbag2_storage_mcap\n\n##  0.26.0 (2024-04-16)\n\n  * Support service 2/2 --- rosbag2 service play ( [ #1481 ](https://github.com/ros2/rosbag2/issues/1481) ) \n  * Use middleware send and receive timestamps from message_info during recording ( [ #1531 ](https://github.com/ros2/rosbag2/issues/1531) ) \n  * Update to use yaml-cpp version 0.8.0. ( [ #1605 ](https://github.com/ros2/rosbag2/issues/1605) ) \n  * Check existence of a file before passing it to the mcap reader ( [ #1594 ](https://github.com/ros2/rosbag2/issues/1594) ) \n  * Contributors: Barry Xu, Chris Lalancette, Christopher Wecht, jmachowinski, Michael Orlov \n\n##  0.25.0 (2024-03-27)\n\n  * Add topic_id returned by storage to the TopicMetadata ( [ #1538 ](https://github.com/ros2/rosbag2/issues/1538) ) \n  * Use rw_lock to protect mcap metadata lists. ( [ #1561 ](https://github.com/ros2/rosbag2/issues/1561) ) \n  * Remove rcpputils::fs dependencies from rosbag2_storages ( [ #1558 ](https://github.com/ros2/rosbag2/issues/1558) ) \n  * remove unused headers ( [ #1544 ](https://github.com/ros2/rosbag2/issues/1544) ) \n  * Link and compile against rosbag2_storage_mcap: Fixed issue 1492 ( [ #1496 ](https://github.com/ros2/rosbag2/issues/1496) ) \n  * Use enum values for offered_qos_profiles in code and string names in serialized metadata ( [ #1476 ](https://github.com/ros2/rosbag2/issues/1476) ) \n  * Store serialized metadata in MCAP file ( [ #1423 ](https://github.com/ros2/rosbag2/issues/1423) ) \n  * Contributors: Alejandro Hern \n\n###  Wiki Tutorials\n\n_See[ ROS Wiki Tutorials ](http://wiki.ros.org/rosbag2_storage_mcap/Tutorials)\nfor more details. _\n\n###  Source Tutorials\n\n_Not currently indexed._\n\n###  Package Dependencies\n\nDeps  |  |  Name  |  [ ](/p/ament_cmake#rolling-deps) |  [ 1\n](/packages/ament_cmake) |  [ ament_cmake ](/p/ament_cmake#rolling)  \n---|---|---  \n[ ](/p/ament_cmake_python#rolling-deps) |  [ 1 ](/packages/ament_cmake_python)\n|  [ ament_cmake_python ](/p/ament_cmake_python#rolling)  \n[ ](/p/ament_cmake_clang_format#rolling-deps) |  [ 1\n](/packages/ament_cmake_clang_format) |  [ ament_cmake_clang_format\n](/p/ament_cmake_clang_format#rolling)  \n[ ](/p/ament_cmake_gmock#rolling-deps) |  [ 1 ](/packages/ament_cmake_gmock) |\n[ ament_cmake_gmock ](/p/ament_cmake_gmock#rolling)  \n[ ](/p/ament_lint_auto#rolling-deps) |  [ 1 ](/packages/ament_lint_auto) |  [\nament_lint_auto ](/p/ament_lint_auto#rolling)  \n[ ](/p/ament_lint_common#rolling-deps) |  [ 1 ](/packages/ament_lint_common) |\n[ ament_lint_common ](/p/ament_lint_common#rolling)  \n[ ](/p/rosbag2_test_common#rolling-deps) |  [ 1\n](/packages/rosbag2_test_common) |  [ rosbag2_test_common\n](/p/rosbag2_test_common#rolling)  \n[ ](/p/std_msgs#rolling-deps) |  [ 2 ](/packages/std_msgs) |  [ std_msgs\n](/p/std_msgs#rolling)  \n[ ](/p/ament_index_cpp#rolling-deps) |  [ 1 ](/packages/ament_index_cpp) |  [\nament_index_cpp ](/p/ament_index_cpp#rolling)  \n[ ](/p/mcap_vendor#rolling-deps) |  [ 2 ](/packages/mcap_vendor) |  [\nmcap_vendor ](/p/mcap_vendor#rolling)  \n[ ](/p/pluginlib#rolling-deps) |  [ 1 ](/packages/pluginlib) |  [ pluginlib\n](/p/pluginlib#rolling)  \n[ ](/p/rcutils#rolling-deps) |  [ 1 ](/packages/rcutils) |  [ rcutils\n](/p/rcutils#rolling)  \n[ ](/p/rosbag2_storage#rolling-deps) |  [ 1 ](/packages/rosbag2_storage) |  [\nrosbag2_storage ](/p/rosbag2_storage#rolling)  \n[ ](/p/yaml_cpp_vendor#rolling-deps) |  [ 1 ](/packages/yaml_cpp_vendor) |  [\nyaml_cpp_vendor ](/p/yaml_cpp_vendor#rolling)  \n  \n###  System Dependencies\n\n_No direct system dependencies._\n\n###  Dependant Packages\n\nName  |  Repo  |  Deps  |  [ rosbag2_storage_default_plugins\n](/p/rosbag2_storage_default_plugins/github-ros2-rosbag2#rolling) |  [ github-\nros2-rosbag2 ](/r/rosbag2/github-ros2-rosbag2) |  [\n](/p/rosbag2_storage_default_plugins/github-ros2-rosbag2#rolling-deps)  \n---|---|---  \n  \n###  Launch files\n\n_No launch files found_\n\n###  Messages\n\n_No message files found._\n\n###  Services\n\n_No service files found_\n\n###  Plugins\n\n_No plugins found._\n\n###  Recent questions tagged ` rosbag2_storage_mcap ` at **[ Robotics Stack\nExchange ](https://robotics.stackexchange.com/) **\n\nNo questions yet, you can ask one [ here\n](https://robotics.stackexchange.com/questions/tagged/rosbag2_storage_mcap+rolling)\n.\n\nFailed to get question list, you can ticket an issue [ here\n](https://github.com/ros-infrastructure/rosindex/issues/new)\n\n[ API Docs ](http://docs.ros.org/en/rolling/p/rosbag2_storage_mcap \"View API\ndocumentation on docs.ros.org\") [ Browse Code\n](https://github.com/ros2/rosbag2/tree/rolling/rosbag2_storage_mcap \"View\nsource code on repository\")\n\nNo version for distro **noetic** . Known supported distros are highlighted in\nthe buttons above.\n\nNo version for distro **ardent** . Known supported distros are highlighted in\nthe buttons above.\n\nNo version for distro **bouncy** . Known supported distros are highlighted in\nthe buttons above.\n\nNo version for distro **crystal** . Known supported distros are highlighted in\nthe buttons above.\n\nNo version for distro **eloquent** . Known supported distros are highlighted\nin the buttons above.\n\nNo version for distro **dashing** . Known supported distros are highlighted in\nthe buttons above.\n\n![](/assets/package.png) |\n\n###  [ rosbag2_storage_mcap ](/p/rosbag2_storage_mcap) package from [\nrosbag2_storage_mcap ](/r/rosbag2_storage_mcap/github-ros-tooling-\nrosbag2_storage_mcap) repo\n\n[ mcap_vendor ](/p/mcap_vendor/github-ros-tooling-rosbag2_storage_mcap)\nrosbag2_storage_mcap  [ rosbag2_storage_mcap_testdata\n](/p/rosbag2_storage_mcap_testdata/github-ros-tooling-rosbag2_storage_mcap)  \n---|---  \n  \ngithub-ros-tooling-rosbag2_storage_mcap\n\n  * [ github-ros2-rosbag2 ](/p/rosbag2_storage_mcap/github-ros2-rosbag2)\n  * [ github-ros-tooling-rosbag2_storage_mcap ](/p/rosbag2_storage_mcap/github-ros-tooling-rosbag2_storage_mcap)\n\n  \n  \n---  \n  \n[  \nAPI Docs ](http://docs.ros.org/en/galactic/p/rosbag2_storage_mcap \"View API\ndocumentation on docs.ros.org\") [  \nBrowse Code ](https://github.com/ros-\ntooling/rosbag2_storage_mcap/tree/main/rosbag2_storage_mcap \"View source code\non repository\")\n\n  * Overview \n  * 0  Assets \n  * 15  Dependencies \n  * 0  Tutorials \n  * 0  Q & A \n\n####  Package Summary\n\n**Tags** |  _No category tags._  \n---|---  \n**Version** |  0.6.0  \n**License** |  Apache-2.0  \n**Build type** |  AMENT_CMAKE  \n**Use** |  RECOMMENDED  \n  \n###  Repository Summary\n\n**Checkout URI** |  [ https://github.com/ros-tooling/rosbag2_storage_mcap.git\n](https://github.com/ros-tooling/rosbag2_storage_mcap.git)  \n---|---  \n**VCS Type** |  git  \n**VCS Version** |  main  \n**Last Updated**  \n  \n2022-11-29  |  **Dev Status** |  DEVELOPED  \n**CI status** |  No Continuous Integration  \n**Released** |  RELEASED  \n**Tags** |  _No category tags._  \n**Contributing** |  [ Help Wanted (  0  ) ](/r/rosbag2_storage_mcap/#galactic-\ncontribute-lists-help-wanted)  \n[ Good First Issues (  0  ) ](/r/rosbag2_storage_mcap/#galactic-contribute-\nlists-good-first-issue)  \n[ Pull Requests to Review (  0  ) ](/r/rosbag2_storage_mcap/#galactic-\ncontribute-lists-pull-requests)  \n  \n###  Package Description\n\nrosbag2 storage plugin using the MCAP file format\n\n####  Additional Links\n\n_No additional links._\n\n####  Maintainers\n\n  * Foxglove \n\n####  Authors\n\n_No additional authors._\n\nREADME\n\n_No README found._ _[ See repository README. ](/r/rosbag2_storage_mcap/github-\nros-tooling-rosbag2_storage_mcap/#galactic) _\n\nCHANGELOG\n\n#  Changelog for package rosbag2_storage_mcap\n\n##  0.6.0 (2022-11-28)\n\n  * mcap_storage: \\'none\\' is a valid storage preset profile ( [ #86 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/86) ) \n  * mcap_storage: handle update_metadata call ( [ #83 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/83) ) \n  * Update clang-format rules to fit ROS 2 style guide ( [ #80 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/80) ) \n  * Revert \\\"read_order: throw exception from set_read_order for unsupported orders\\\" This reverts commit aef9b9a65293f9e5d80a858ef84e485a8655a0c0. \n  * read_order: throw exception from set_read_order for unsupported orders \n  * Fix compile flags to work on rosbag_storage:0.17.x ( [ #78 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/78) ) This fixes the compile flags for rolling, which has two versions -- one that does not support read order (0.17.x) and one that does support read order (0.18.x). \n  * Fix Windows build ( [ #73 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/73) ) Update mcap version to newest windows-compatible release. Add visibility macros for tests. Add clang-format preprocessor indentation for visibility_control to be readable. \n  * Contributors: Andrew Symington, Emerson Knapp, James Smith, james-rms \n\n##  0.5.0 (2022-11-02)\n\n  * set defaults for SQLite plugin parity ( [ #68 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/68) ) \n  * rosbag2_storage_mcap: add storage preset profiles ( [ #57 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/57) ) \n  * rename test_fixture_interfaces package to testdata ( [ #64 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/64) ) \n  * Switch to using the vendored zstd library. ( [ #59 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/59) ) \n  * Add set_read_order reader API ( [ #54 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/54) ) \n  * Contributors: Chris Lalancette, Emerson Knapp, James Smith \n\n##  0.4.0 (2022-10-06)\n\n  * Some minor improvements in rosbag2_storage_mcap after review ( [ #58 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/58) ) \n\n    1. Fixed some findings from Clang-Tidy \n    2. Some renames according to the ROS2 coding style \n    3. Add default initializations for member variables \n\n1\\. Moved code responsible for adding schema and channel from write(msg) to\ncreate_topic(topic) method to reduce performance burden on first message write\nand in lieu to preparation for moving schema collection process to upper\nSequentialWriter layer.\n\n  * Revert \\\"rosbag2_storage_mcap: add storage preset profiles\\\" This reverts commit 38830add3935b978968fe2703d3180b413ccc8c2. \n\n  * rosbag2_storage_mcap: add storage preset profiles \n\n  * Contributors: James Smith, Michael Orlov \n\n##  0.3.0 (2022-09-09)\n\n  * Store IDL message definitions in Schema records when no MSG definition is available ( [ #43 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/43) ) \n  * Contributors: James Smith \n\n##  0.2.0 (2022-09-08)\n\n  * Support timestamp-ordered playback ( [ #50 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/50) ) \n  * Support regex topic filtering \n  * Contributors: James Smith \n\n##  0.1.7 (2022-08-15)\n\n  * Add all lz4 sources to fix undefined symbols at runtime ( [ #46 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/46) ) \n  * Contributors: Emerson Knapp \n\n##  0.1.6 (2022-07-22)\n\n  * Upgrade mcap to fix LZ4 error and segfault ( [ #42 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/42) ) Incorporates fixes from [ https://github.com/foxglove/mcap/pull/478 ](https://github.com/foxglove/mcap/pull/478) and [ https://github.com/foxglove/mcap/pull/482 ](https://github.com/foxglove/mcap/pull/482)\n  * Contributors: Jacob Bandes-Storch \n\n##  0.1.5 (2022-04-25)\n\n  * Fix build for Foxy ( [ #34 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/34) ) \n  * Contributors: Jacob Bandes-Storch \n\n##  0.1.4 (2022-04-21)\n\n  * fix: minor issues ( [ #31 ](https://github.com/wep21/rosbag2_storage_mcap/issues/31) ) \n    * remove unnecessary block \n    * use target_link_libraries instead of ament_target_dependencies \n    * remove ros environment \n    * add prefix to compile definition \n  * Update email address for Foxglove maintainers ( [ #32 ](https://github.com/wep21/rosbag2_storage_mcap/issues/32) ) \n  * Contributors: Daisuke Nishimatsu, Jacob Bandes-Storch \n\n##  0.1.3 (2022-04-20)\n\n##  0.1.2 (2022-04-20)\n\n  * Added mcap_vendor package. Updated CMakeLists.txt to fetch dependencies with FetchContent rather than Conan. \n  * Contributors: Jacob Bandes-Storch \n\n##  0.1.1 (2022-04-01)\n\n  * CMake build script will now execute pip install conan automatically. \n  * Contributors: Daisuke Nishimatsu \n\n##  0.1.0 (2022-03-24)\n\n  * [1.0.0] Use Summary section for get_metadata() and seek(), implement remaining methods ( [ #17 ](https://github.com/wep21/rosbag2_storage_mcap/issues/17) ) \n  * feat: add play impl ( [ #16 ](https://github.com/wep21/rosbag2_storage_mcap/issues/16) ) \n  * chore: refine package.xml ( [ #15 ](https://github.com/wep21/rosbag2_storage_mcap/issues/15) ) \n  * Don\\'t throw when READ_WRITE mode is used; add .mcap file extension to recorded files ( [ #14 ](https://github.com/wep21/rosbag2_storage_mcap/issues/14) ) I may be missing something, but from a cursory glance at [this code]( [ https://github.com/ros2/rosbag2/blob/342d8ed3c1c4ae0411a4a92b60e79a728b8974b8/rosbag2_storage/src/rosbag2_storage/impl/storage_factory_impl.hpp#L108-L135 ](https://github.com/ros2/rosbag2/blob/342d8ed3c1c4ae0411a4a92b60e79a728b8974b8/rosbag2_storage/src/rosbag2_storage/impl/storage_factory_impl.hpp#L108-L135) ), it appears that the [APPEND]{.title-ref} mode is never used. This means we need to support [READ_WRITE]{.title-ref}. This also adds a [.mcap]{.title-ref} extension to recorded file names. \n  * Add dynamic message definition lookup ( [ #13 ](https://github.com/wep21/rosbag2_storage_mcap/issues/13) ) Currently, an exception will be thrown if lookup fails. \n  * Switch C++ formatter to clang-format ( [ #12 ](https://github.com/wep21/rosbag2_storage_mcap/issues/12) ) Remove uncrustify linter in favor of clang-format, which is easier to configure for use in VS Code format-on-save. \n  * Merge pull request [ #7 ](https://github.com/wep21/rosbag2_storage_mcap/issues/7) from ros-tooling/jhurliman/reader-writer Reader and writer implementation \n  * uninitialized struct \n  * lint \n  * lint \n  * lint \n  * Reader and writer implementation \n  * Merge pull request [ #6 ](https://github.com/wep21/rosbag2_storage_mcap/issues/6) from wep21/add-metadata-impl feat: add metadata impl \n  * feat: add metadata impl \n  * Merge pull request [ #5 ](https://github.com/wep21/rosbag2_storage_mcap/issues/5) from wep21/mcap-storage-impl feat: mcap storage impl \n  * chore: update cmake minimum version \n  * chore: install mcap header \n  * chore: include mcap header \n  * fix: move fetch content into rosbag2 storage mcap \n  * Merge pull request [ #3 ](https://github.com/wep21/rosbag2_storage_mcap/issues/3) from ros-tooling/emersonknapp/mcap_plugin_skeleton Add mcap storage plugin skeleton and CI \n  * Add rosbag2_storage_mcap skeleton \n  * Contributors: Daisuke Nishimatsu, Emerson Knapp, Jacob Bandes-Storch, John Hurliman, wep21 \n\n###  Wiki Tutorials\n\n_See[ ROS Wiki Tutorials ](http://wiki.ros.org/rosbag2_storage_mcap/Tutorials)\nfor more details. _\n\n###  Source Tutorials\n\n_Not currently indexed._\n\n###  Package Dependencies\n\nDeps  |  |  Name  |  [ ](/p/ament_cmake#galactic-deps) |  [ 1\n](/packages/ament_cmake) |  [ ament_cmake ](/p/ament_cmake#galactic)  \n---|---|---  \n[ ](/p/ament_cmake_clang_format#galactic-deps) |  [ 1\n](/packages/ament_cmake_clang_format) |  [ ament_cmake_clang_format\n](/p/ament_cmake_clang_format#galactic)  \n[ ](/p/ament_cmake_gmock#galactic-deps) |  [ 1 ](/packages/ament_cmake_gmock)\n|  [ ament_cmake_gmock ](/p/ament_cmake_gmock#galactic)  \n[ ](/p/ament_lint_auto#galactic-deps) |  [ 1 ](/packages/ament_lint_auto) |  [\nament_lint_auto ](/p/ament_lint_auto#galactic)  \n[ ](/p/ament_lint_common#galactic-deps) |  [ 1 ](/packages/ament_lint_common)\n|  [ ament_lint_common ](/p/ament_lint_common#galactic)  \n[ ](/p/rcpputils#galactic-deps) |  [ 1 ](/packages/rcpputils) |  [ rcpputils\n](/p/rcpputils#galactic)  \n[ ](/p/rosbag2_cpp#galactic-deps) |  [ 1 ](/packages/rosbag2_cpp) |  [\nrosbag2_cpp ](/p/rosbag2_cpp#galactic)  \n[ ](/p/rosbag2_test_common#galactic-deps) |  [ 1\n](/packages/rosbag2_test_common) |  [ rosbag2_test_common\n](/p/rosbag2_test_common#galactic)  \n[ ](/p/std_msgs#galactic-deps) |  [ 2 ](/packages/std_msgs) |  [ std_msgs\n](/p/std_msgs#galactic)  \n[ ](/p/rosbag2_storage_mcap_testdata#galactic-deps) |  [ 2\n](/packages/rosbag2_storage_mcap_testdata) |  [ rosbag2_storage_mcap_testdata\n](/p/rosbag2_storage_mcap_testdata#galactic)  \n[ ](/p/ament_index_cpp#galactic-deps) |  [ 1 ](/packages/ament_index_cpp) |  [\nament_index_cpp ](/p/ament_index_cpp#galactic)  \n[ ](/p/mcap_vendor#galactic-deps) |  [ 2 ](/packages/mcap_vendor) |  [\nmcap_vendor ](/p/mcap_vendor#galactic)  \n[ ](/p/pluginlib#galactic-deps) |  [ 1 ](/packages/pluginlib) |  [ pluginlib\n](/p/pluginlib#galactic)  \n[ ](/p/rcutils#galactic-deps) |  [ 1 ](/packages/rcutils) |  [ rcutils\n](/p/rcutils#galactic)  \n[ ](/p/rosbag2_storage#galactic-deps) |  [ 1 ](/packages/rosbag2_storage) |  [\nrosbag2_storage ](/p/rosbag2_storage#galactic)  \n  \n###  System Dependencies\n\n_No direct system dependencies._\n\n###  Dependant Packages\n\n_No known dependants._\n\n###  Launch files\n\n_No launch files found_\n\n###  Messages\n\n_No message files found._\n\n###  Services\n\n_No service files found_\n\n###  Plugins\n\n_No plugins found._\n\n###  Recent questions tagged ` rosbag2_storage_mcap ` at **[ Robotics Stack\nExchange ](https://robotics.stackexchange.com/) **\n\nNo questions yet, you can ask one [ here\n](https://robotics.stackexchange.com/questions/tagged/rosbag2_storage_mcap+galactic)\n.\n\nFailed to get question list, you can ticket an issue [ here\n](https://github.com/ros-infrastructure/rosindex/issues/new)\n\n[ API Docs ](http://docs.ros.org/en/galactic/p/rosbag2_storage_mcap \"View API\ndocumentation on docs.ros.org\") [ Browse Code ](https://github.com/ros-\ntooling/rosbag2_storage_mcap/tree/main/rosbag2_storage_mcap \"View source code\non repository\")\n\n![](/assets/package.png) |\n\n###  [ rosbag2_storage_mcap ](/p/rosbag2_storage_mcap) package from [\nrosbag2_storage_mcap ](/r/rosbag2_storage_mcap/github-ros-tooling-\nrosbag2_storage_mcap) repo\n\n[ mcap_vendor ](/p/mcap_vendor/github-ros-tooling-rosbag2_storage_mcap)\nrosbag2_storage_mcap  [ rosbag2_storage_mcap_testdata\n](/p/rosbag2_storage_mcap_testdata/github-ros-tooling-rosbag2_storage_mcap)  \n---|---  \n  \ngithub-ros-tooling-rosbag2_storage_mcap\n\n  * [ github-ros2-rosbag2 ](/p/rosbag2_storage_mcap/github-ros2-rosbag2)\n  * [ github-ros-tooling-rosbag2_storage_mcap ](/p/rosbag2_storage_mcap/github-ros-tooling-rosbag2_storage_mcap)\n\n  \n  \n---  \n  \n[  \nAPI Docs ](http://docs.ros.org/en/foxy/p/rosbag2_storage_mcap \"View API\ndocumentation on docs.ros.org\") [  \nBrowse Code ](https://github.com/ros-\ntooling/rosbag2_storage_mcap/tree/main/rosbag2_storage_mcap \"View source code\non repository\")\n\n  * Overview \n  * 0  Assets \n  * 15  Dependencies \n  * 0  Tutorials \n  * 0  Q & A \n\n####  Package Summary\n\n**Tags** |  _No category tags._  \n---|---  \n**Version** |  0.6.0  \n**License** |  Apache-2.0  \n**Build type** |  AMENT_CMAKE  \n**Use** |  RECOMMENDED  \n  \n###  Repository Summary\n\n**Checkout URI** |  [ https://github.com/ros-tooling/rosbag2_storage_mcap.git\n](https://github.com/ros-tooling/rosbag2_storage_mcap.git)  \n---|---  \n**VCS Type** |  git  \n**VCS Version** |  main  \n**Last Updated**  \n  \n2022-11-29  |  **Dev Status** |  DEVELOPED  \n**CI status** |  No Continuous Integration  \n**Released** |  RELEASED  \n**Tags** |  _No category tags._  \n**Contributing** |  [ Help Wanted (  0  ) ](/r/rosbag2_storage_mcap/#foxy-\ncontribute-lists-help-wanted)  \n[ Good First Issues (  0  ) ](/r/rosbag2_storage_mcap/#foxy-contribute-lists-\ngood-first-issue)  \n[ Pull Requests to Review (  0  ) ](/r/rosbag2_storage_mcap/#foxy-contribute-\nlists-pull-requests)  \n  \n###  Package Description\n\nrosbag2 storage plugin using the MCAP file format\n\n####  Additional Links\n\n_No additional links._\n\n####  Maintainers\n\n  * Foxglove \n\n####  Authors\n\n_No additional authors._\n\nREADME\n\n_No README found._ _[ See repository README. ](/r/rosbag2_storage_mcap/github-\nros-tooling-rosbag2_storage_mcap/#foxy) _\n\nCHANGELOG\n\n#  Changelog for package rosbag2_storage_mcap\n\n##  0.6.0 (2022-11-28)\n\n  * mcap_storage: \\'none\\' is a valid storage preset profile ( [ #86 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/86) ) \n  * mcap_storage: handle update_metadata call ( [ #83 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/83) ) \n  * Update clang-format rules to fit ROS 2 style guide ( [ #80 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/80) ) \n  * Revert \\\"read_order: throw exception from set_read_order for unsupported orders\\\" This reverts commit aef9b9a65293f9e5d80a858ef84e485a8655a0c0. \n  * read_order: throw exception from set_read_order for unsupported orders \n  * Fix compile flags to work on rosbag_storage:0.17.x ( [ #78 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/78) ) This fixes the compile flags for rolling, which has two versions -- one that does not support read order (0.17.x) and one that does support read order (0.18.x). \n  * Fix Windows build ( [ #73 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/73) ) Update mcap version to newest windows-compatible release. Add visibility macros for tests. Add clang-format preprocessor indentation for visibility_control to be readable. \n  * Contributors: Andrew Symington, Emerson Knapp, James Smith, james-rms \n\n##  0.5.0 (2022-11-02)\n\n  * set defaults for SQLite plugin parity ( [ #68 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/68) ) \n  * rosbag2_storage_mcap: add storage preset profiles ( [ #57 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/57) ) \n  * rename test_fixture_interfaces package to testdata ( [ #64 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/64) ) \n  * Switch to using the vendored zstd library. ( [ #59 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/59) ) \n  * Add set_read_order reader API ( [ #54 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/54) ) \n  * Contributors: Chris Lalancette, Emerson Knapp, James Smith \n\n##  0.4.0 (2022-10-06)\n\n  * Some minor improvements in rosbag2_storage_mcap after review ( [ #58 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/58) ) \n\n    1. Fixed some findings from Clang-Tidy \n    2. Some renames according to the ROS2 coding style \n    3. Add default initializations for member variables \n\n1\\. Moved code responsible for adding schema and channel from write(msg) to\ncreate_topic(topic) method to reduce performance burden on first message write\nand in lieu to preparation for moving schema collection process to upper\nSequentialWriter layer.\n\n  * Revert \\\"rosbag2_storage_mcap: add storage preset profiles\\\" This reverts commit 38830add3935b978968fe2703d3180b413ccc8c2. \n\n  * rosbag2_storage_mcap: add storage preset profiles \n\n  * Contributors: James Smith, Michael Orlov \n\n##  0.3.0 (2022-09-09)\n\n  * Store IDL message definitions in Schema records when no MSG definition is available ( [ #43 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/43) ) \n  * Contributors: James Smith \n\n##  0.2.0 (2022-09-08)\n\n  * Support timestamp-ordered playback ( [ #50 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/50) ) \n  * Support regex topic filtering \n  * Contributors: James Smith \n\n##  0.1.7 (2022-08-15)\n\n  * Add all lz4 sources to fix undefined symbols at runtime ( [ #46 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/46) ) \n  * Contributors: Emerson Knapp \n\n##  0.1.6 (2022-07-22)\n\n  * Upgrade mcap to fix LZ4 error and segfault ( [ #42 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/42) ) Incorporates fixes from [ https://github.com/foxglove/mcap/pull/478 ](https://github.com/foxglove/mcap/pull/478) and [ https://github.com/foxglove/mcap/pull/482 ](https://github.com/foxglove/mcap/pull/482)\n  * Contributors: Jacob Bandes-Storch \n\n##  0.1.5 (2022-04-25)\n\n  * Fix build for Foxy ( [ #34 ](https://github.com/ros-tooling/rosbag2_storage_mcap/issues/34) ) \n  * Contributors: Jacob Bandes-Storch \n\n##  0.1.4 (2022-04-21)\n\n  * fix: minor issues ( [ #31 ](https://github.com/wep21/rosbag2_storage_mcap/issues/31) ) \n    * remove unnecessary block \n    * use target_link_libraries instead of ament_target_dependencies \n    * remove ros environment \n    * add prefix to compile definition \n  * Update email address for Foxglove maintainers ( [ #32 ](https://github.com/wep21/rosbag2_storage_mcap/issues/32) ) \n  * Contributors: Daisuke Nishimatsu, Jacob Bandes-Storch \n\n##  0.1.3 (2022-04-20)\n\n##  0.1.2 (2022-04-20)\n\n  * Added mcap_vendor package. Updated CMakeLists.txt to fetch dependencies with FetchContent rather than Conan. \n  * Contributors: Jacob Bandes-Storch \n\n##  0.1.1 (2022-04-01)\n\n  * CMake build script will now execute pip install conan automatically. \n  * Contributors: Daisuke Nishimatsu \n\n##  0.1.0 (2022-03-24)\n\n  * [1.0.0] Use Summary section for get_metadata() and seek(), implement remaining methods ( [ #17 ](https://github.com/wep21/rosbag2_storage_mcap/issues/17) ) \n  * feat: add play impl ( [ #16 ](https://github.com/wep21/rosbag2_storage_mcap/issues/16) ) \n  * chore: refine package.xml ( [ #15 ](https://github.com/wep21/rosbag2_storage_mcap/issues/15) ) \n  * Don\\'t throw when READ_WRITE mode is used; add .mcap file extension to recorded files ( [ #14 ](https://github.com/wep21/rosbag2_storage_mcap/issues/14) ) I may be missing something, but from a cursory glance at [this code]( [ https://github.com/ros2/rosbag2/blob/342d8ed3c1c4ae0411a4a92b60e79a728b8974b8/rosbag2_storage/src/rosbag2_storage/impl/storage_factory_impl.hpp#L108-L135 ](https://github.com/ros2/rosbag2/blob/342d8ed3c1c4ae0411a4a92b60e79a728b8974b8/rosbag2_storage/src/rosbag2_storage/impl/storage_factory_impl.hpp#L108-L135) ), it appears that the [APPEND]{.title-ref} mode is never used. This means we need to support [READ_WRITE]{.title-ref}. This also adds a [.mcap]{.title-ref} extension to recorded file names. \n  * Add dynamic message definition lookup ( [ #13 ](https://github.com/wep21/rosbag2_storage_mcap/issues/13) ) Currently, an exception will be thrown if lookup fails. \n  * Switch C++ formatter to clang-format ( [ #12 ](https://github.com/wep21/rosbag2_storage_mcap/issues/12) ) Remove uncrustify linter in favor of clang-format, which is easier to configure for use in VS Code format-on-save. \n  * Merge pull request [ #7 ](https://github.com/wep21/rosbag2_storage_mcap/issues/7) from ros-tooling/jhurliman/reader-writer Reader and writer implementation \n  * uninitialized struct \n  * lint \n  * lint \n  * lint \n  * Reader and writer implementation \n  * Merge pull request [ #6 ](https://github.com/wep21/rosbag2_storage_mcap/issues/6) from wep21/add-metadata-impl feat: add metadata impl \n  * feat: add metadata impl \n  * Merge pull request [ #5 ](https://github.com/wep21/rosbag2_storage_mcap/issues/5) from wep21/mcap-storage-impl feat: mcap storage impl \n  * chore: update cmake minimum version \n  * chore: install mcap header \n  * chore: include mcap header \n  * fix: move fetch content into rosbag2 storage mcap \n  * Merge pull request [ #3 ](https://github.com/wep21/rosbag2_storage_mcap/issues/3) from ros-tooling/emersonknapp/mcap_plugin_skeleton Add mcap storage plugin skeleton and CI \n  * Add rosbag2_storage_mcap skeleton \n  * Contributors: Daisuke Nishimatsu, Emerson Knapp, Jacob Bandes-Storch, John Hurliman, wep21 \n\n###  Wiki Tutorials\n\n_See[ ROS Wiki Tutorials ](http://wiki.ros.org/rosbag2_storage_mcap/Tutorials)\nfor more details. _\n\n###  Source Tutorials\n\n_Not currently indexed._\n\n###  Package Dependencies\n\nDeps  |  |  Name  |  [ ](/p/ament_cmake#foxy-deps) |  [ 1\n](/packages/ament_cmake) |  [ ament_cmake ](/p/ament_cmake#foxy)  \n---|---|---  \n[ ](/p/ament_cmake_clang_format#foxy-deps) |  [ 1\n](/packages/ament_cmake_clang_format) |  [ ament_cmake_clang_format\n](/p/ament_cmake_clang_format#foxy)  \n[ ](/p/ament_cmake_gmock#foxy-deps) |  [ 1 ](/packages/ament_cmake_gmock) |  [\nament_cmake_gmock ](/p/ament_cmake_gmock#foxy)  \n[ ](/p/ament_lint_auto#foxy-deps) |  [ 1 ](/packages/ament_lint_auto) |  [\nament_lint_auto ](/p/ament_lint_auto#foxy)  \n[ ](/p/ament_lint_common#foxy-deps) |  [ 1 ](/packages/ament_lint_common) |  [\nament_lint_common ](/p/ament_lint_common#foxy)  \n[ ](/p/rcpputils#foxy-deps) |  [ 1 ](/packages/rcpputils) |  [ rcpputils\n](/p/rcpputils#foxy)  \n[ ](/p/rosbag2_cpp#foxy-deps) |  [ 1 ](/packages/rosbag2_cpp) |  [ rosbag2_cpp\n](/p/rosbag2_cpp#foxy)  \n[ ](/p/rosbag2_test_common#foxy-deps) |  [ 1 ](/packages/rosbag2_test_common)\n|  [ rosbag2_test_common ](/p/rosbag2_test_common#foxy)  \n[ ](/p/std_msgs#foxy-deps) |  [ 2 ](/packages/std_msgs) |  [ std_msgs\n](/p/std_msgs#foxy)  \n[ ](/p/rosbag2_storage_mcap_testdata#foxy-deps) |  [ 2\n](/packages/rosbag2_storage_mcap_testdata) |  [ rosbag2_storage_mcap_testdata\n](/p/rosbag2_storage_mcap_testdata#foxy)  \n[ ](/p/ament_index_cpp#foxy-deps) |  [ 1 ](/packages/ament_index_cpp) |  [\nament_index_cpp ](/p/ament_index_cpp#foxy)  \n[ ](/p/mcap_vendor#foxy-deps) |  [ 2 ](/packages/mcap_vendor) |  [ mcap_vendor\n](/p/mcap_vendor#foxy)  \n[ ](/p/pluginlib#foxy-deps) |  [ 1 ](/packages/pluginlib) |  [ pluginlib\n](/p/pluginlib#foxy)  \n[ ](/p/rcutils#foxy-deps) |  [ 1 ](/packages/rcutils) |  [ rcutils\n](/p/rcutils#foxy)  \n[ ](/p/rosbag2_storage#foxy-deps) |  [ 1 ](/packages/rosbag2_storage) |  [\nrosbag2_storage ](/p/rosbag2_storage#foxy)  \n  \n###  System Dependencies\n\n_No direct system dependencies._\n\n###  Dependant Packages\n\n_No known dependants._\n\n###  Launch files\n\n_No launch files found_\n\n###  Messages\n\n_No message files found._\n\n###  Services\n\n_No service files found_\n\n###  Plugins\n\n_No plugins found._\n\n###  Recent questions tagged ` rosbag2_storage_mcap ` at **[ Robotics Stack\nExchange ](https://robotics.stackexchange.com/) **\n\nNo questions yet, you can ask one [ here\n](https://robotics.stackexchange.com/questions/tagged/rosbag2_storage_mcap+foxy)\n.\n\nFailed to get question list, you can ticket an issue [ here\n](https://github.com/ros-infrastructure/rosindex/issues/new)\n\n[ API Docs ](http://docs.ros.org/en/foxy/p/rosbag2_storage_mcap \"View API\ndocumentation on docs.ros.org\") [ Browse Code ](https://github.com/ros-\ntooling/rosbag2_storage_mcap/tree/main/rosbag2_storage_mcap \"View source code\non repository\")\n\nNo version for distro **lunar** . Known supported distros are highlighted in\nthe buttons above.\n\nNo version for distro **jade** . Known supported distros are highlighted in\nthe buttons above.\n\nNo version for distro **indigo** . Known supported distros are highlighted in\nthe buttons above.\n\nNo version for distro **hydro** . Known supported distros are highlighted in\nthe buttons above.\n\nNo version for distro **kinetic** . Known supported distros are highlighted in\nthe buttons above.\n\nNo version for distro **melodic** . Known supported distros are highlighted in\nthe buttons above.\n\n[ ros-infrastructure/rosindex  ](https://github.com/ros-\ninfrastructure/rosindex \"Find rosindex in Github\") | _generated on 2024-04-17_\n\na community-maintained index of robotics software | [ privacy ](/privacy.txt)\n\n"
  },
  {
    "id": "navsetplugin/2468.txt",
    "content": "[ Gazebo Community ](/)\n\n#  [ How to use NavSat plugin ](/t/how-to-use-navsat-plugin/2468)\n\n[ Help  ](/c/help/8)\n\n[ ignition ](https://community.gazebosim.org/tag/ignition) , [ fortress\n](https://community.gazebosim.org/tag/fortress)\n\n[ leets0429  ](https://community.gazebosim.org/u/leets0429) January 10, 2024,\n10:29am  1\n\nI\u2019m trying to use the Navsat plugin but I can\u2019t get it working. I\u2019m using ros-\nhumble\n\nI\u2019ve been following the link below, but I am unable to see any navsat topic in\ngazebo  \n[ https://answers.gazebosim.org//question/28643/gps-sensor-plugin-in-ignition/\n](https://answers.gazebosim.org//question/28643/gps-sensor-plugin-in-\nignition/)\n\nIn my robot urdf, I have the following code\n\n    \n    \n        <link name=\"chassis\">\n                ....\n          <plugin filename=\"ignition-gazebo-navsat-system\" name=\"ignition::gazebo::systems::NavSat\"/>\n          <gazebo>\n            <sensor name=\"navsat_sensor\" type=\"navsat\">\n              <always_on>1</always_on>\n              <update_rate>1</update_rate>\n              <topic>navsat</topic>\n            </sensor>\n         </gazebo>\n        </link>\n    \n\nOn my world sdf, I also included\n\n    \n    \n        <world name=\"field\">\n            ...\n          <spherical_coordinates>\n            <surface_model>EARTH_WGS84</surface_model>\n            <world_frame_orientation>ENU</world_frame_orientation>\n            <latitude_deg>-22.986687</latitude_deg>\n            <longitude_deg>-43.202501</longitude_deg>\n            <elevation>0</elevation>\n            <heading_deg>0</heading_deg>\n          </spherical_coordinates>\n        </world>\n    \n\n[ peci1  ](https://community.gazebosim.org/u/peci1) January 10, 2024, 4:39pm\n2\n\nThis type of question seems better suited for [ robotics.stackexchange.com\n](http://robotics.stackexchange.com) .\n\n###  Related Topics\n\nTopic  |  |  Replies  |  Views  |  Activity  \n---|---|---|---|---  \n[ No force_torque topic is published when loading xacro into ignition gazebo\nvia ros2 launch ](https://community.gazebosim.org/t/no-force-torque-topic-is-\npublished-when-loading-xacro-into-ignition-gazebo-via-ros2-launch/1769)\n\n[ Help  ](/c/help/8)\n\n[ ros2 ](https://community.gazebosim.org/tag/ros2) , [ ignition\n](https://community.gazebosim.org/tag/ignition) , [ fortress\n](https://community.gazebosim.org/tag/fortress)\n\n|  2  |  310  |  February 7, 2023  \n[ Updates in Ignition Gazebo Documentation\n](https://community.gazebosim.org/t/updates-in-ignition-gazebo-\ndocumentation/2263)\n\n|  1  |  158  |  September 12, 2023  \n[ Using the skid steer plugin with ign gazebo fortress (or citadel)\n](https://community.gazebosim.org/t/using-the-skid-steer-plugin-with-ign-\ngazebo-fortress-or-citadel/2317)\n\n[ General  ](/c/general/6)\n\n|  0  |  120  |  October 4, 2023  \n[ Ignition-gazebo plugin subscriber\n](https://community.gazebosim.org/t/ignition-gazebo-plugin-subscriber/1764)\n\n[ Help  ](/c/help/8)\n\n[ ignition ](https://community.gazebosim.org/tag/ignition)\n\n|  1  |  398  |  January 30, 2023  \n[ Ignition ros control hardware interface (noetic + ignition edifice)\n](https://community.gazebosim.org/t/ignition-ros-control-hardware-interface-\nnoetic-ignition-edifice/1142)\n\n[ Projects  ](/c/projects/7)\n\n[ ignition ](https://community.gazebosim.org/tag/ignition) , [ ros1\n](https://community.gazebosim.org/tag/ros1)\n\n|  0  |  551  |  October 16, 2021  \n  \n  * [ Home ](/)\n  * [ Categories ](/categories)\n  * [ FAQ/Guidelines ](/guidelines)\n  * [ Terms of Service ](/tos)\n  * [ Privacy Policy ](/privacy)\n\nPowered by [ Discourse ](https://www.discourse.org) , best viewed with\nJavaScript enabled\n\n"
  },
  {
    "id": "additional_argument/629.txt",
    "content": "Skip to content\n\nToggle navigation\n\n[ ](https://github.com/)\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2Fros2%2Frclpy%2Fissues%2F629)\n\n  * Product \n\n    * [ Actions  Automate any workflow  ](/features/actions)\n    * [ Packages  Host and manage packages  ](/features/packages)\n    * [ Security  Find and fix vulnerabilities  ](/features/security)\n    * [ Codespaces  Instant dev environments  ](/features/codespaces)\n    * [ Copilot  Write better code with AI  ](/features/copilot)\n    * [ Code review  Manage code changes  ](/features/code-review)\n    * [ Issues  Plan and track work  ](/features/issues)\n    * [ Discussions  Collaborate outside of code  ](/features/discussions)\n\nExplore\n\n    * [ All features ](/features)\n    * [ Documentation  ](https://docs.github.com)\n    * [ GitHub Skills  ](https://skills.github.com/)\n    * [ Blog  ](https://github.blog)\n\n  * Solutions \n\nFor\n\n    * [ Enterprise ](/enterprise)\n    * [ Teams ](/team)\n    * [ Startups ](/enterprise/startups)\n    * [ Education  ](https://education.github.com)\n\nBy Solution\n\n    * [ CI/CD & Automation ](/solutions/ci-cd/)\n    * [ DevOps ](/solutions/devops/)\n    * [ DevSecOps  ](https://resources.github.com/devops/fundamentals/devsecops/)\n\nResources\n\n    * [ Learning Pathways  ](https://resources.github.com/learn/pathways/)\n    * [ White papers, Ebooks, Webinars  ](https://resources.github.com/)\n    * [ Customer Stories ](/customer-stories)\n    * [ Partners  ](https://partner.github.com/)\n\n  * Open Source \n\n    * [ GitHub Sponsors  Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project  GitHub community articles  ](/readme)\n\nRepositories\n\n    * [ Topics ](/topics)\n    * [ Trending ](/trending)\n    * [ Collections ](/collections)\n\n  * [ Pricing ](/pricing)\n\nSearch or jump to...\n\n#  Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[ Search syntax tips ](https://docs.github.com/search-github/github-code-\nsearch/understanding-github-code-search-syntax)\n\n#  Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n##  Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [ documentation\n](https://docs.github.com/search-github/github-code-search/understanding-\ngithub-code-search-syntax) .\n\nCancel  Create saved search\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2Fros2%2Frclpy%2Fissues%2F629)\n\n[ Sign up\n](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-\nname%3E%2F%3Crepo-\nname%3E%2Fvoltron%2Fissues_fragments%2Fissue_layout&source=header-\nrepo&source_repo=ros2%2Frclpy)\n\nYou signed in with another tab or window. [ Reload ]() to refresh your\nsession.  You signed out in another tab or window. [ Reload ]() to refresh\nyour session.  You switched accounts on another tab or window. [ Reload ]() to\nrefresh your session.  Dismiss alert\n\n{{ message }}\n\n[ ros2 ](/ros2) /  **[ rclpy ](/ros2/rclpy) ** Public\n\n  * [ Notifications ](/login?return_to=%2Fros2%2Frclpy)\n  * [ Fork  213  ](/login?return_to=%2Fros2%2Frclpy)\n  * [ Star  245  ](/login?return_to=%2Fros2%2Frclpy)\n\n  * [ Code  ](/ros2/rclpy)\n  * [ Issues  99  ](/ros2/rclpy/issues)\n  * [ Pull requests  33  ](/ros2/rclpy/pulls)\n  * [ Actions  ](/ros2/rclpy/actions)\n  * [ Security  ](/ros2/rclpy/security)\n  * [ Insights  ](/ros2/rclpy/pulse)\n\nAdditional navigation options\n\n  * [ Code  ](/ros2/rclpy)\n  * [ Issues  ](/ros2/rclpy/issues)\n  * [ Pull requests  ](/ros2/rclpy/pulls)\n  * [ Actions  ](/ros2/rclpy/actions)\n  * [ Security  ](/ros2/rclpy/security)\n  * [ Insights  ](/ros2/rclpy/pulse)\n\nNew issue\n\n**Have a question about this project?** Sign up for a free GitHub account to\nopen an issue and contact its maintainers and the community.\n\nPick a username\n\n    \n\nEmail Address\n\n    \n\nPassword\n\n    \nSign up for GitHub\n\nBy clicking \u201cSign up for GitHub\u201d, you agree to our [ terms of service\n](https://docs.github.com/terms) and [ privacy statement\n](https://docs.github.com/privacy) . We\u2019ll occasionally send you account\nrelated emails.\n\nAlready on GitHub? [ Sign in\n](/login?return_to=%2Fros2%2Frclpy%2Fissues%2Fnew%2Fchoose) to your account\n\nJump to bottom\n\n#  Passing argument to Node.create_subscription method  #629\n\nClosed\n\n[ ramezanifar ](/ramezanifar) opened this issue  Oct 10, 2020  \u00b7 9 comments\n\nClosed\n\n#  Passing argument to Node.create_subscription method  #629\n\n[ ramezanifar ](/ramezanifar) opened this issue  Oct 10, 2020  \u00b7 9 comments\n\nLabels\n\n[ question  ](/ros2/rclpy/labels/question) Further information is requested\n\n##  Comments\n\n[ ![@ramezanifar](https://avatars.githubusercontent.com/u/11685859?s=80&v=4)\n](/ramezanifar)\n\nCopy link\n\n###\n\n**[ ramezanifar ](/ramezanifar) ** commented  Oct 10, 2020\n\n##  Feature request\n\nAbility to pass argument to ` Node.create_subscription ` method.\n\n####  Feature description\n\nIn ROS 1, I was able to pass arguments to the callback function of a\nsubscriber:  \n` rospy.Subscriber(topic_name, type, call_back, call_back_arg) `  \nThis feature was great because I could define a single callback for multiple\ntopics (for example, in a for loop I want to create the subscribers in\nmasses). When the callback was invoked, based on the argument I knew which one\nowned the message.  \nIt looks like this option is missing in ROS2, ` Node.create_subscription `\nfunction.  \nCan we have that?  \n  \n---  \n  \nThe text was updated successfully, but these errors were encountered:\n\n  \n  \nAll reactions\n\n[\n![@ivanpauno](https://avatars.githubusercontent.com/u/26796393?s=40&u=8f754ac57482921ea34e7bc6fa3491a127814a74&v=4)\n](/ivanpauno) [ ivanpauno ](/ivanpauno) added the [ question\n](/ros2/rclpy/labels/question) Further information is requested  label  Oct\n23, 2020\n\n[\n![@ivanpauno](https://avatars.githubusercontent.com/u/26796393?s=80&u=8f754ac57482921ea34e7bc6fa3491a127814a74&v=4)\n](/ivanpauno)\n\nCopy link\n\nMember\n\n###\n\n**[ ivanpauno ](/ivanpauno) ** commented  Oct 23, 2020\n\nYou can easily solve this using a lambda, the extra ` call_back_arg ` argument\nin ros1 ` Subscriber ` doesn't seem to add much value:\n\n    \n    \n    node.create_subscription(std_msgs.msg.String, \"my_topic\", lambda msg: common_callback(msg, other_args), 10)\n\nDo you thing that will work for you?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@ivanpauno](https://avatars.githubusercontent.com/u/26796393?s=80&u=8f754ac57482921ea34e7bc6fa3491a127814a74&v=4)\n](/ivanpauno)\n\nCopy link\n\nMember\n\n###\n\n**[ ivanpauno ](/ivanpauno) ** commented  Nov 3, 2020\n\nI'm closing this, as the extra ` call_back_arg ` doesn't seem to add much\nvalue.\n\n[ @ramezanifar ](https://github.com/ramezanifar) if you think that `\ncall_back_arg ` would still be useful feel free to left a comment here or\nreopen the issue.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@ivanpauno](https://avatars.githubusercontent.com/u/26796393?s=40&u=8f754ac57482921ea34e7bc6fa3491a127814a74&v=4)\n](/ivanpauno) [ ivanpauno ](/ivanpauno) closed this as [ completed\n](/ros2/rclpy/issues?q=is%3Aissue+is%3Aclosed+archived%3Afalse+reason%3Acompleted)\nNov 3, 2020\n\n[ ![@ramezanifar](https://avatars.githubusercontent.com/u/11685859?s=80&v=4)\n](/ramezanifar)\n\nCopy link\n\nAuthor\n\n###\n\n**[ ramezanifar ](/ramezanifar) ** commented  Nov 30, 2020\n\nAwesome!  \nThanks for the hint.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@TheConstructAi](https://avatars.githubusercontent.com/u/80715513?s=80&u=0086e3dca53758236a47b310ef33222ebaa05ad0&v=4)\n](/TheConstructAi)\n\nCopy link\n\n###\n\n**[ TheConstructAi ](/TheConstructAi) ** commented  Sep 28, 2022\n\nHi,\n\nTried this and it stays with the last value of the multiple subscribers done:\n\n    \n    \n    for i in range(self.fleet_robots_number):\n                robot_name = self.fleet_name +\"_\"+str(i+1)\n                docked_status_topic_name = robot_name+\"/docked_status\"\n                \n                qos_profile_subscriber = QoSProfile(depth=1)\n                qos_profile_subscriber.durability = QoSDurabilityPolicy.TRANSIENT_LOCAL\n    \n                # Your own common callback\n                self.get_logger().error(\"INIT Subscriber ==\"+str(docked_status_topic_name))\n                self.create_subscription(   BoolRosMsg, \n                                            docked_status_topic_name,\n                                            lambda msg: self.dock_state_clb(msg, robot_name),\n                                            qos_profile=qos_profile_subscriber)\n                self.get_logger().error(\"INIT Subscriber ==\"+str(docked_status_topic_name)+\"....DONE\")\n    \n        def dock_state_clb(self, msg, in_robot_name):\n            self.get_logger().error(\"Message in_robot_name==\"+str(msg)+\", from robot=\"+str(in_robot_name))\n    \n    \n    Any ideas why? All the callback messages appear with the las `robot_name`used to initialise the subscribers.\n      \n  \n---  \n  \n\ud83d\udc4d  3  DSep, KiloNovemberDelta, and manye31 reacted with thumbs up emoji\n\nAll reactions\n\n  * \ud83d\udc4d  3 reactions \n\nSorry, something went wrong.\n\n[ ![@patrickwasp](https://avatars.githubusercontent.com/u/70671760?s=80&v=4)\n](/patrickwasp)\n\nCopy link\n\n###\n\n**[ patrickwasp ](/patrickwasp) ** commented  Jan 22, 2023\n\n[ @TheConstructAi ](https://github.com/TheConstructAi) did you end up figuring\nthis out?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@apockill](https://avatars.githubusercontent.com/u/1740412?s=80&u=dbb3f1036aadaca3422451823493dbd6f4fdc157&v=4)\n](/apockill)\n\nCopy link\n\n###\n\n**[ apockill ](/apockill) ** commented  Jan 22, 2023  \u2022\n\nedited\n\nHey, this is an odd thing with lambdas. Here's the fix:\n\nChange\n\n    \n    \n                                            lambda msg: self.dock_state_clb(msg, robot_name),\n\nTo:\n\n    \n    \n                                            lambda msg=msg: self.dock_state_clb(msg, robot_name),\n\n(FYI, if you use mypy it'll catch these errors!)\n\n[ More on this topic ](https://stackoverflow.com/questions/19837486/lambda-in-\na-loop)  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@KiloNovemberDelta](https://avatars.githubusercontent.com/u/41945728?s=80&u=9f709bd44a972fa667e8064c427456c10ddfd2de&v=4)\n](/KiloNovemberDelta)\n\nCopy link\n\n###\n\n**[ KiloNovemberDelta ](/KiloNovemberDelta) ** commented  Feb 20, 2023  \u2022\n\nedited\n\nHello, I face the same situation as [ @TheConstructAi\n](https://github.com/TheConstructAi)\n\n> Hey, this is an odd thing with lambdas. Here's the fix:\n>\n> Change\n>  \n>  \n>                                             lambda msg:\n> self.dock_state_clb(msg, robot_name),\n>\n> To:\n>  \n>  \n>                                             lambda msg=msg:\n> self.dock_state_clb(msg, robot_name),\n>\n> (FYI, if you use mypy it'll catch these errors!)\n>\n> [ More on this topic ](https://stackoverflow.com/questions/19837486/lambda-\n> in-a-loop)\n\nThank you for your help, I tried your solution, however I got \"NameError: name\n'msg' is not defined\".\n\nMy solution is to use another function to generate the callback. In your\nexample, it will be sth like:\n\n    \n    \n    def generate_callback(self, robot_name):\n      return lambda msg=self.dock_state_clb(msg, robot_name)\n\nAnd in your subscriber :\n\n    \n    \n    self.create_subscription(   BoolRosMsg, \n                                           docked_status_topic_name,\n                                           self.generate_callback(robot_name),\n                                           qos_profile=qos_profile_subscriber)  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@evan-\npalmer](https://avatars.githubusercontent.com/u/75103118?s=80&u=33c66adb11b022d6d5cae7b7df7411c58bec1c68&v=4)\n](/evan-palmer)\n\nCopy link\n\n###\n\n**[ evan-palmer ](/evan-palmer) ** commented  Mar 14, 2023\n\nAnother solution that may be worth mentioning here is to use [ `\nfunctools.partial ` ](https://docs.python.org/3/library/functools.html#) :\n\n    \n    \n    node.create_subscription(std_msgs.msg.String, \"my_topic\", partial(my_callback, my_extra_args=other_args), 10)  \n  \n---  \n  \n\ud83d\udc4d  2  KiloNovemberDelta and joseantoniobecerrapermuy reacted with thumbs up\nemoji\n\nAll reactions\n\n  * \ud83d\udc4d  2 reactions \n\nSorry, something went wrong.\n\n[\n![@ArjunBalakrishnan](https://avatars.githubusercontent.com/u/15687079?s=80&u=0b8298f132e4daab8b5f5df1de3ba91e3c485695&v=4)\n](/ArjunBalakrishnan)\n\nCopy link\n\n###\n\n**[ ArjunBalakrishnan ](/ArjunBalakrishnan) ** commented  May 10, 2023\n\n> Hi,\n>\n> Tried this and it stays with the last value of the multiple subscribers\n> done:\n>  \n>  \n>     for i in range(self.fleet_robots_number):\n>                 robot_name = self.fleet_name +\"_\"+str(i+1)\n>                 docked_status_topic_name = robot_name+\"/docked_status\"\n>  \n>                 qos_profile_subscriber = QoSProfile(depth=1)\n>                 qos_profile_subscriber.durability =\n> QoSDurabilityPolicy.TRANSIENT_LOCAL\n>  \n>                 # Your own common callback\n>                 self.get_logger().error(\"INIT Subscriber\n> ==\"+str(docked_status_topic_name))\n>                 self.create_subscription(   BoolRosMsg,\n>                                             docked_status_topic_name,\n>                                             lambda msg:\n> self.dock_state_clb(msg, robot_name),\n>\n> qos_profile=qos_profile_subscriber)\n>                 self.get_logger().error(\"INIT Subscriber\n> ==\"+str(docked_status_topic_name)+\"....DONE\")\n>  \n>         def dock_state_clb(self, msg, in_robot_name):\n>             self.get_logger().error(\"Message in_robot_name==\"+str(msg)+\",\n> from robot=\"+str(in_robot_name))\n>  \n>  \n>     Any ideas why? All the callback messages appear with the las\n> `robot_name`used to initialise the subscribers.\n>  \n\nThis seemed to work and not get stuck in the last name\n\n    \n    \n           lambda msg, in_robot_name=robot_name : self.dock_state_clb (msg, in_robot_name)\n      \n  \n---  \n  \n\ud83d\udc4d  1  jeffbfr reacted with thumbs up emoji\n\nAll reactions\n\n  * \ud83d\udc4d  1 reaction \n\nSorry, something went wrong.\n\n[ Sign up for free ](/join?source=comment-repo) **to join this conversation on\nGitHub** . Already have an account? [ Sign in to comment\n](/login?return_to=https%3A%2F%2Fgithub.com%2Fros2%2Frclpy%2Fissues%2F629)\n\nAssignees\n\nNo one assigned\n\nLabels\n\n[ question  ](/ros2/rclpy/labels/question) Further information is requested\n\nProjects\n\nNone yet\n\nMilestone\n\nNo milestone\n\nDevelopment\n\nNo branches or pull requests\n\n8 participants\n\n[ ![@apockill](https://avatars.githubusercontent.com/u/1740412?s=52&v=4)\n](/apockill) [\n![@ramezanifar](https://avatars.githubusercontent.com/u/11685859?s=52&v=4)\n](/ramezanifar) [\n![@ArjunBalakrishnan](https://avatars.githubusercontent.com/u/15687079?s=52&v=4)\n](/ArjunBalakrishnan) [\n![@ivanpauno](https://avatars.githubusercontent.com/u/26796393?s=52&v=4)\n](/ivanpauno) [\n![@KiloNovemberDelta](https://avatars.githubusercontent.com/u/41945728?s=52&v=4)\n](/KiloNovemberDelta) [\n![@patrickwasp](https://avatars.githubusercontent.com/u/70671760?s=52&v=4)\n](/patrickwasp) [ ![@evan-\npalmer](https://avatars.githubusercontent.com/u/75103118?s=52&v=4) ](/evan-\npalmer) [\n![@TheConstructAi](https://avatars.githubusercontent.com/u/80715513?s=52&v=4)\n](/TheConstructAi)\n\n##  Footer\n\n[ ](https://github.com \"GitHub\") \u00a9 2024 GitHub, Inc.\n\n###  Footer navigation\n\n  * [ Terms ](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [ Privacy ](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [ Security ](/security)\n  * [ Status ](https://www.githubstatus.com/)\n  * [ Docs ](https://docs.github.com/)\n  * [ Contact ](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.\n\n"
  },
  {
    "id": "rosdep_install/367.txt",
    "content": "Skip to content\n\nToggle navigation\n\n[ ](https://github.com/)\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fros-\ninfrastructure%2Frosdep%2Fissues%2F367)\n\n  * Product \n\n    * [ Actions  Automate any workflow  ](/features/actions)\n    * [ Packages  Host and manage packages  ](/features/packages)\n    * [ Security  Find and fix vulnerabilities  ](/features/security)\n    * [ Codespaces  Instant dev environments  ](/features/codespaces)\n    * [ Copilot  Write better code with AI  ](/features/copilot)\n    * [ Code review  Manage code changes  ](/features/code-review)\n    * [ Issues  Plan and track work  ](/features/issues)\n    * [ Discussions  Collaborate outside of code  ](/features/discussions)\n\nExplore\n\n    * [ All features ](/features)\n    * [ Documentation  ](https://docs.github.com)\n    * [ GitHub Skills  ](https://skills.github.com/)\n    * [ Blog  ](https://github.blog)\n\n  * Solutions \n\nFor\n\n    * [ Enterprise ](/enterprise)\n    * [ Teams ](/team)\n    * [ Startups ](/enterprise/startups)\n    * [ Education  ](https://education.github.com)\n\nBy Solution\n\n    * [ CI/CD & Automation ](/solutions/ci-cd/)\n    * [ DevOps ](/solutions/devops/)\n    * [ DevSecOps  ](https://resources.github.com/devops/fundamentals/devsecops/)\n\nResources\n\n    * [ Learning Pathways  ](https://resources.github.com/learn/pathways/)\n    * [ White papers, Ebooks, Webinars  ](https://resources.github.com/)\n    * [ Customer Stories ](/customer-stories)\n    * [ Partners  ](https://partner.github.com/)\n\n  * Open Source \n\n    * [ GitHub Sponsors  Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project  GitHub community articles  ](/readme)\n\nRepositories\n\n    * [ Topics ](/topics)\n    * [ Trending ](/trending)\n    * [ Collections ](/collections)\n\n  * [ Pricing ](/pricing)\n\nSearch or jump to...\n\n#  Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[ Search syntax tips ](https://docs.github.com/search-github/github-code-\nsearch/understanding-github-code-search-syntax)\n\n#  Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n##  Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [ documentation\n](https://docs.github.com/search-github/github-code-search/understanding-\ngithub-code-search-syntax) .\n\nCancel  Create saved search\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fros-\ninfrastructure%2Frosdep%2Fissues%2F367)\n\n[ Sign up\n](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-\nname%3E%2F%3Crepo-\nname%3E%2Fvoltron%2Fissues_fragments%2Fissue_layout&source=header-\nrepo&source_repo=ros-infrastructure%2Frosdep)\n\nYou signed in with another tab or window. [ Reload ]() to refresh your\nsession.  You signed out in another tab or window. [ Reload ]() to refresh\nyour session.  You switched accounts on another tab or window. [ Reload ]() to\nrefresh your session.  Dismiss alert\n\n{{ message }}\n\n[ ros-infrastructure ](/ros-infrastructure) /  **[ rosdep ](/ros-\ninfrastructure/rosdep) ** Public\n\n  * [ Notifications ](/login?return_to=%2Fros-infrastructure%2Frosdep)\n  * [ Fork  164  ](/login?return_to=%2Fros-infrastructure%2Frosdep)\n  * [ Star  71  ](/login?return_to=%2Fros-infrastructure%2Frosdep)\n\n  * [ Code  ](/ros-infrastructure/rosdep)\n  * [ Issues  107  ](/ros-infrastructure/rosdep/issues)\n  * [ Pull requests  34  ](/ros-infrastructure/rosdep/pulls)\n  * [ Actions  ](/ros-infrastructure/rosdep/actions)\n  * [ Projects  0  ](/ros-infrastructure/rosdep/projects)\n  * [ Security  ](/ros-infrastructure/rosdep/security)\n  * [ Insights  ](/ros-infrastructure/rosdep/pulse)\n\nAdditional navigation options\n\n  * [ Code  ](/ros-infrastructure/rosdep)\n  * [ Issues  ](/ros-infrastructure/rosdep/issues)\n  * [ Pull requests  ](/ros-infrastructure/rosdep/pulls)\n  * [ Actions  ](/ros-infrastructure/rosdep/actions)\n  * [ Projects  ](/ros-infrastructure/rosdep/projects)\n  * [ Security  ](/ros-infrastructure/rosdep/security)\n  * [ Insights  ](/ros-infrastructure/rosdep/pulse)\n\nNew issue\n\n**Have a question about this project?** Sign up for a free GitHub account to\nopen an issue and contact its maintainers and the community.\n\nPick a username\n\n    \n\nEmail Address\n\n    \n\nPassword\n\n    \nSign up for GitHub\n\nBy clicking \u201cSign up for GitHub\u201d, you agree to our [ terms of service\n](https://docs.github.com/terms) and [ privacy statement\n](https://docs.github.com/privacy) . We\u2019ll occasionally send you account\nrelated emails.\n\nAlready on GitHub? [ Sign in ](/login?return_to=%2Fros-\ninfrastructure%2Frosdep%2Fissues%2Fnew%2Fchoose) to your account\n\nJump to bottom\n\n#  rosdep fails if pip is not installed  #367\n\nClosed\n\n[ mitchellwills ](/mitchellwills) opened this issue  Jan 6, 2015  \u00b7 15\ncomments\n\nClosed\n\n#  rosdep fails if pip is not installed  #367\n\n[ mitchellwills ](/mitchellwills) opened this issue  Jan 6, 2015  \u00b7 15\ncomments\n\n##  Comments\n\n[ ![@mitchellwills](https://avatars.githubusercontent.com/u/427009?s=80&v=4)\n](/mitchellwills)\n\nCopy link\n\n###\n\n**[ mitchellwills ](/mitchellwills) ** commented  Jan 6, 2015\n\nWhen installing the base ros system nothing appears to depend on pip. This\nleads to issues when trying to use rosdep to install dependencies. I have\nexperienced this issue on hydro 12.04 and indigo 13.10. I get the following\nerror message when running rosdep\n\n    \n    \n    ERROR: Rosdep experienced an internal error.\n    Please go to the rosdep page [1] and file a bug report with the message below.\n    [1] : http://www.ros.org/wiki/rosdep\n    \n    rosdep version: 0.11.0\n    \n    Bad installer [pip]: [Errno 2] No such file or directory\n    \n\nIt seems like it may be nice to make pip be installed implicitly on systems\nthat support it when rosdep will attempt to install using pip.  \n  \n---  \n  \nThe text was updated successfully, but these errors were encountered:\n\n  \n  \nAll reactions\n\n[ ![@wjwwood](https://avatars.githubusercontent.com/u/100427?s=80&v=4)\n](/wjwwood)\n\nCopy link\n\nContributor\n\n###\n\n**[ wjwwood ](/wjwwood) ** commented  Jan 6, 2015\n\nCould you provide the command you ran to produce this error?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@mitchellwills](https://avatars.githubusercontent.com/u/427009?s=80&v=4)\n](/mitchellwills)\n\nCopy link\n\nAuthor\n\n###\n\n**[ mitchellwills ](/mitchellwills) ** commented  Jan 6, 2015\n\nWoops, sorry. I ran the following in the root of my catkin workspace\n\n    \n    \n    rosdep install -i --from-paths src\n    \n\nIt happened to be on a system that I think had some base installation of ROS\nand that was it. In the src directory there was a package that depended on a\nrosdep key that resolved to a pip package.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@wjwwood](https://avatars.githubusercontent.com/u/100427?s=80&v=4)\n](/wjwwood)\n\nCopy link\n\nContributor\n\n###\n\n**[ wjwwood ](/wjwwood) ** commented  Jan 6, 2015\n\nOk, well in the case that a ` pip ` key is needed it will assert that ` pip `\nis available, that is intended behavior. If that was the case then I'll close\nthis for now. Feel free to comment further, I can reopen the issue if\nsomething is still left to be resolved.\n\nYou can add ` --simulate ` to get what it would try to install, that shouldn't\nexcept if ` pip ` is not installed.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@wjwwood](https://avatars.githubusercontent.com/u/100427?s=40&v=4)\n](/wjwwood) [ wjwwood ](/wjwwood) closed this as [ completed ](/ros-\ninfrastructure/rosdep/issues?q=is%3Aissue+is%3Aclosed+archived%3Afalse+reason%3Acompleted)\nJan 6, 2015\n\n[ ![@mitchellwills](https://avatars.githubusercontent.com/u/427009?s=80&v=4)\n](/mitchellwills)\n\nCopy link\n\nAuthor\n\n###\n\n**[ mitchellwills ](/mitchellwills) ** commented  Jan 6, 2015\n\nOk it just seemed like it was weird that it raises an internal error. I would\nhave expected it to just print bad installer (without the internal error\nmessage cause it's not really an internal error). Not a huge problem,\nespecially since rosdep will be replaced soon.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@wjwwood](https://avatars.githubusercontent.com/u/100427?s=80&v=4)\n](/wjwwood)\n\nCopy link\n\nContributor\n\n###\n\n**[ wjwwood ](/wjwwood) ** commented  Jan 6, 2015\n\nI guess I was mistaken, it will except if you use ` --simulate ` , but it will\nnot when nothing in your workspace depends on a key which resolves to ` pip `\n. I just tested it by getting ` ros_base ` 's source and uninstall ` pip ` ,\nthen adding the ` python-cpplint ` depend to catkin's ` package.xml ` .  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@wjwwood](https://avatars.githubusercontent.com/u/100427?s=80&v=4)\n](/wjwwood)\n\nCopy link\n\nContributor\n\n###\n\n**[ wjwwood ](/wjwwood) ** commented  Jan 6, 2015\n\nYeah, unfortunately that whole top part is attached to all exceptions. We\nshould probably change the exception handling up a bit to make it more\npalatable.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@bryan-\nbisonai](https://avatars.githubusercontent.com/u/1245675?s=80&u=1ec5f65a8f6f0be41ddbda657008c8dc418c2c90&v=4)\n](/bryan-bisonai)\n\nCopy link\n\n###\n\n**[ bryan-bisonai ](/bryan-bisonai) ** commented  Dec 28, 2017\n\nIs this issue fixed? I am getting the same message as below by typing the\ncommand\n\n` rosdep install --from-paths src --ignore-src --rosdistro kinetic -y `\n\n    \n    \n    ERROR: Rosdep experienced an internal error.\n    Please go to the rosdep page [1] and file a bug report with the message below.\n    [1] : http://www.ros.org/wiki/rosdep\n    \n    rosdep version: 0.11.8\n    \n    Bad installer [pip]: [Errno 2] No such file or directory: 'pip': 'pip'\n      \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@NikolausDemmel](https://avatars.githubusercontent.com/u/479562?s=80&v=4)\n](/NikolausDemmel)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ NikolausDemmel ](/NikolausDemmel) ** commented  Dec 28, 2017\n\n> Is this issue fixed?\n\nNot sure what you mean. Did you read the responses? The issue should be the\nsame as always, i.e. it would be great if the error message read differently.\n\nAs mentioned above there should be an easy workaround: Install pip.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@aniroodh-\nravikumar](https://avatars.githubusercontent.com/u/30080678?s=80&u=04eb43d29f4d17087678782b5cae8bdf2c7b127a&v=4)\n](/aniroodh-ravikumar)\n\nCopy link\n\n###\n\n**[ aniroodh-ravikumar ](/aniroodh-ravikumar) ** commented  Apr 4, 2018\n\n> As mentioned above there should be an easy workaround: Install pip.\n\nI have the same issue as @taegoobot , and the issue seems to persist even\nafter pip is installed.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@NikolausDemmel](https://avatars.githubusercontent.com/u/479562?s=80&v=4)\n](/NikolausDemmel)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ NikolausDemmel ](/NikolausDemmel) ** commented  Apr 4, 2018\n\n[ @aniroodh-ravikumar ](https://github.com/aniroodh-ravikumar) : What happens\nwhen you run ` pip --version ` in the same terminal from which you run `\nrosdep ` ? What OS are you on? Can you paste the output of the rosdep command\nyou run and also the output when you run with the ` -s ` (simmulate) flag?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@aniroodh-\nravikumar](https://avatars.githubusercontent.com/u/30080678?s=80&u=04eb43d29f4d17087678782b5cae8bdf2c7b127a&v=4)\n](/aniroodh-ravikumar)\n\nCopy link\n\n###\n\n**[ aniroodh-ravikumar ](/aniroodh-ravikumar) ** commented  Apr 4, 2018  \u2022\n\nedited\n\n> ERROR: Rosdep experienced an internal error.  \n>  Please go to the rosdep page [1] and file a bug report with the message\n> below.  \n>  [1] : [ http://www.ros.org/wiki/rosdep ](http://www.ros.org/wiki/rosdep)  \n>  rosdep version: 0.12.2  \n>  Bad installer [pip]: [Errno 2] No such file or directory\n\nThat is the output when I run the rosdep command with the -s flag.\n\nHowever, when I try to run pip --version, I get:\n\n> -bash: /usr/local/bin/pip: No such file or directory\n\nthough I do have pip installed, which seems to suggest that the issue might be\nwith the directory that pip is installed in, so I will see if changing that\nfixes the error.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@NikolausDemmel](https://avatars.githubusercontent.com/u/479562?s=80&v=4)\n](/NikolausDemmel)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ NikolausDemmel ](/NikolausDemmel) ** commented  Apr 4, 2018\n\nYes, you need to make sure that ` pip ` is runnable from the shell.\n\nCould you run ` which python ` and ` python --version ` .  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@aniroodh-\nravikumar](https://avatars.githubusercontent.com/u/30080678?s=80&u=04eb43d29f4d17087678782b5cae8bdf2c7b127a&v=4)\n](/aniroodh-ravikumar)\n\nCopy link\n\n###\n\n**[ aniroodh-ravikumar ](/aniroodh-ravikumar) ** commented  Apr 4, 2018\n\n> aniroodhs-mbp:ros_catkin_ws aniroodhravikumar$ which python  \n>  /opt/local/bin/python  \n>  aniroodhs-mbp:ros_catkin_ws aniroodhravikumar$ python --version  \n>  Python 2.7.14  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@NikolausDemmel](https://avatars.githubusercontent.com/u/479562?s=80&v=4)\n](/NikolausDemmel)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ NikolausDemmel ](/NikolausDemmel) ** commented  Apr 4, 2018\n\nWhat kind of setup is this that you have python in ` /opt/local/bin ` on a\nmac? With homebrew it should be in ` /usr/local/bin ` or with system python in\n` /usr/bin/python ` , I guess?\n\nIn any case, you should be able to upgrade / reinstall pip with ` python -m\npip install --force-reinstall -U pip ` , but you need check where the\nexecutables are installed and make sure that directory is on your path...  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@wjwwood](https://avatars.githubusercontent.com/u/100427?s=80&v=4)\n](/wjwwood)\n\nCopy link\n\nContributor\n\n###\n\n**[ wjwwood ](/wjwwood) ** commented  Apr 5, 2018\n\n` /opt/local/bin ` is probably macports, which none of us use regularly.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ Sign up for free ](/join?source=comment-repo) **to join this conversation on\nGitHub** . Already have an account? [ Sign in to comment\n](/login?return_to=https%3A%2F%2Fgithub.com%2Fros-\ninfrastructure%2Frosdep%2Fissues%2F367)\n\nAssignees\n\nNo one assigned\n\nLabels\n\nNone yet\n\nProjects\n\nNone yet\n\nMilestone\n\nNo milestone\n\nDevelopment\n\nNo branches or pull requests\n\n5 participants\n\n[ ![@wjwwood](https://avatars.githubusercontent.com/u/100427?s=52&v=4)\n](/wjwwood) [\n![@mitchellwills](https://avatars.githubusercontent.com/u/427009?s=52&v=4)\n](/mitchellwills) [\n![@NikolausDemmel](https://avatars.githubusercontent.com/u/479562?s=52&v=4)\n](/NikolausDemmel) [ ![@bryan-\nbisonai](https://avatars.githubusercontent.com/u/1245675?s=52&v=4) ](/bryan-\nbisonai) [ ![@aniroodh-\nravikumar](https://avatars.githubusercontent.com/u/30080678?s=52&v=4)\n](/aniroodh-ravikumar)\n\n##  Footer\n\n[ ](https://github.com \"GitHub\") \u00a9 2024 GitHub, Inc.\n\n###  Footer navigation\n\n  * [ Terms ](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [ Privacy ](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [ Security ](/security)\n  * [ Status ](https://www.githubstatus.com/)\n  * [ Docs ](https://docs.github.com/)\n  * [ Contact ](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.\n\n"
  },
  {
    "id": "rclcpp_service_action/clienthpp1.txt",
    "content": "// Copyright 2014 Open Source Robotics Foundation, Inc.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n#ifndef RCLCPP__CLIENT_HPP_\n#define RCLCPP__CLIENT_HPP_\n#include <atomic>\n#include <functional>\n#include <future>\n#include <memory>\n#include <mutex>\n#include <optional>\n#include <sstream>\n#include <string>\n#include <tuple>\n#include <unordered_map>\n#include <utility>\n#include <variant>\n#include <vector>\n#include \"rcl/client.h\"\n#include \"rcl/error_handling.h\"\n#include \"rcl/event_callback.h\"\n#include \"rcl/service_introspection.h\"\n#include \"rcl/wait.h\"\n#include \"rclcpp/clock.hpp\"\n#include \"rclcpp/detail/cpp_callback_trampoline.hpp\"\n#include \"rclcpp/exceptions.hpp\"\n#include \"rclcpp/expand_topic_or_service_name.hpp\"\n#include \"rclcpp/function_traits.hpp\"\n#include \"rclcpp/logging.hpp\"\n#include \"rclcpp/macros.hpp\"\n\n\n\n#include \"rclcpp/node_interfaces/node_graph_interface.hpp\"\n#include \"rclcpp/qos.hpp\"\n#include \"rclcpp/type_support_decl.hpp\"\n#include \"rclcpp/utilities.hpp\"\n#include \"rclcpp/visibility_control.hpp\"\n#include \"rmw/error_handling.h\"\n#include \"rmw/impl/cpp/demangle.hpp\"\n#include \"rmw/rmw.h\"\nnamespace rclcpp\n{\nnamespace detail\n{\ntemplate<typename FutureT>\nstruct FutureAndRequestId\n{\n  FutureT future;\n  int64_t request_id;\n  FutureAndRequestId(FutureT impl, int64_t req_id)\n  : future(std::move(impl)), request_id(req_id)\n  {}\n  /// Allow implicit conversions to `std::future` by reference.\n  operator FutureT &() {return this->future;}\n  /// Deprecated, use the `future` member variable instead.\n  /**\n   * Allow implicit conversions to `std::future` by value.\n   * \\deprecated\n   */\n  [[deprecated(\"FutureAndRequestId: use .future instead of an implicit conversion\")]]\n  operator FutureT() {return this->future;}\n  // delegate future like methods in the std::future impl_\n  /// See std::future::get().\n  auto get() {return this->future.get();}\n  /// See std::future::valid().\n  bool valid() const noexcept {return this->future.valid();}\n  /// See std::future::wait().\n  void wait() const {return this->future.wait();}\n  /// See std::future::wait_for().\n  template<class Rep, class Period>\n  std::future_status wait_for(\n    const std::chrono::duration<Rep, Period> & timeout_duration) const\n\n\n\n  {\n    return this->future.wait_for(timeout_duration);\n  }\n  /// See std::future::wait_until().\n  template<class Clock, class Duration>\n  std::future_status wait_until(\n    const std::chrono::time_point<Clock, Duration> & timeout_time) const\n  {\n    return this->future.wait_until(timeout_time);\n  }\n  // Rule of five, we could use the rule of zero here, but better be explicit as some of the\n  // methods are deleted.\n  /// Move constructor.\n  FutureAndRequestId(FutureAndRequestId && other) noexcept = default;\n  /// Deleted copy constructor, each instance is a unique owner of the future.\n  FutureAndRequestId(const FutureAndRequestId & other) = delete;\n  /// Move assignment.\n  FutureAndRequestId & operator=(FutureAndRequestId && other) noexcept = default;\n  /// Deleted copy assignment, each instance is a unique owner of the future.\n  FutureAndRequestId & operator=(const FutureAndRequestId & other) = delete;\n  /// Destructor.\n  ~FutureAndRequestId() = default;\n};\n}  // namespace detail\nnamespace node_interfaces\n{\nclass NodeBaseInterface;\n}  // namespace node_interfaces\nclass ClientBase\n{\npublic:\n  RCLCPP_SMART_PTR_DEFINITIONS_NOT_COPYABLE(ClientBase)\n  RCLCPP_PUBLIC\n  ClientBase(\n    rclcpp::node_interfaces::NodeBaseInterface * node_base,\n    rclcpp::node_interfaces::NodeGraphInterface::SharedPtr node_graph);\n  RCLCPP_PUBLIC\n  virtual ~ClientBase() = default;\n  /// Take the next response for this client as a type erased pointer.\n  /**\n\n\n\n   * The type erased pointer allows for this method to be used in a type\n   * agnostic way along with ClientBase::create_response(),\n   * ClientBase::create_request_header(), and ClientBase::handle_response().\n   * The typed version of this can be used if the Service type is known,\n   * \\sa Client::take_response().\n   *\n   * \\param[out] response_out The type erased pointer to a Service Response into\n   *   which the middleware will copy the response being taken.\n   * \\param[out] request_header_out The request header to be filled by the\n   *   middleware when taking, and which can be used to associte the response\n   *   to a specific request.\n   * \\returns true if the response was taken, otherwise false.\n   * \\throws rclcpp::exceptions::RCLError based exceptions if the underlying\n   *   rcl function fail.\n   */\n  RCLCPP_PUBLIC\n  bool\n  take_type_erased_response(void * response_out, rmw_request_id_t & request_header_out);\n  /// Return the name of the service.\n  /** \\return The name of the service. */\n  RCLCPP_PUBLIC\n  const char *\n  get_service_name() const;\n  /// Return the rcl_client_t client handle in a std::shared_ptr.\n  /**\n   * This handle remains valid after the Client is destroyed.\n   * The actual rcl client is not finalized until it is out of scope everywhere.\n   */\n  RCLCPP_PUBLIC\n  std::shared_ptr<rcl_client_t>\n  get_client_handle();\n  /// Return the rcl_client_t client handle in a std::shared_ptr.\n  /**\n   * This handle remains valid after the Client is destroyed.\n   * The actual rcl client is not finalized until it is out of scope everywhere.\n   */\n  RCLCPP_PUBLIC\n  std::shared_ptr<const rcl_client_t>\n  get_client_handle() const;\n  /// Return if the service is ready.\n\n\n\n  /**\n   * \\return `true` if the service is ready, `false` otherwise\n   */\n  RCLCPP_PUBLIC\n  bool\n  service_is_ready() const;\n  /// Wait for a service to be ready.\n  /**\n   * \\param timeout maximum time to wait\n   * \\return `true` if the service is ready and the timeout is not over, `false` otherwise\n   */\n  template<typename RepT = int64_t, typename RatioT = std::milli>\n  bool\n  wait_for_service(\n    std::chrono::duration<RepT, RatioT> timeout = std::chrono::duration<RepT, RatioT>(-1))\n  {\n    return wait_for_service_nanoseconds(\n      std::chrono::duration_cast<std::chrono::nanoseconds>(timeout)\n    );\n  }\n  virtual std::shared_ptr<void> create_response() = 0;\n  virtual std::shared_ptr<rmw_request_id_t> create_request_header() = 0;\n  virtual void handle_response(\n    std::shared_ptr<rmw_request_id_t> request_header, std::shared_ptr<void> response) = 0;\n  /// Exchange the \"in use by wait set\" state for this client.\n  /**\n   * This is used to ensure this client is not used by multiple\n   * wait sets at the same time.\n   *\n   * \\param[in] in_use_state the new state to exchange into the state, true\n   *   indicates it is now in use by a wait set, and false is that it is no\n   *   longer in use by a wait set.\n   * \\returns the previous state.\n   */\n  RCLCPP_PUBLIC\n  bool\n  exchange_in_use_by_wait_set_state(bool in_use_state);\n  /// Get the actual request publsher QoS settings, after the defaults have been determined.\n  /**\n   * The actual configuration applied when using RMW_QOS_POLICY_*_SYSTEM_DEFAULT\n\n\n\n   * can only be resolved after the creation of the client, and it\n   * depends on the underlying rmw implementation.\n   * If the underlying setting in use can't be represented in ROS terms,\n   * it will be set to RMW_QOS_POLICY_*_UNKNOWN.\n   * May throw runtime_error when an unexpected error occurs.\n   *\n   * \\return The actual request publsher qos settings.\n   * \\throws std::runtime_error if failed to get qos settings\n   */\n  RCLCPP_PUBLIC\n  rclcpp::QoS\n  get_request_publisher_actual_qos() const;\n  /// Get the actual response subscription QoS settings, after the defaults have been determined.\n  /**\n   * The actual configuration applied when using RMW_QOS_POLICY_*_SYSTEM_DEFAULT\n   * can only be resolved after the creation of the client, and it\n   * depends on the underlying rmw implementation.\n   * If the underlying setting in use can't be represented in ROS terms,\n   * it will be set to RMW_QOS_POLICY_*_UNKNOWN.\n   * May throw runtime_error when an unexpected error occurs.\n   *\n   * \\return The actual response subscription qos settings.\n   * \\throws std::runtime_error if failed to get qos settings\n   */\n  RCLCPP_PUBLIC\n  rclcpp::QoS\n  get_response_subscription_actual_qos() const;\n  /// Set a callback to be called when each new response is received.\n  /**\n   * The callback receives a size_t which is the number of responses received\n   * since the last time this callback was called.\n   * Normally this is 1, but can be > 1 if responses were received before any\n   * callback was set.\n   *\n   * Since this callback is called from the middleware, you should aim to make\n   * it fast and not blocking.\n   * If you need to do a lot of work or wait for some other event, you should\n   * spin it off to another thread, otherwise you risk blocking the middleware.\n   *\n   * Calling it again will clear any previously set callback.\n\n\n\n   *\n   * An exception will be thrown if the callback is not callable.\n   *\n   * This function is thread-safe.\n   *\n   * If you want more information available in the callback, like the client\n   * or other information, you may use a lambda with captures or std::bind.\n   *\n   * \\sa rmw_client_set_on_new_response_callback\n   * \\sa rcl_client_set_on_new_response_callback\n   *\n   * \\param[in] callback functor to be called when a new response is received\n   */\n  void\n  set_on_new_response_callback(std::function<void(size_t)> callback)\n  {\n    if (!callback) {\n      throw std::invalid_argument(\n              \"The callback passed to set_on_new_response_callback \"\n              \"is not callable.\");\n    }\n    auto new_callback =\n      [callback, this](size_t number_of_responses) {\n        try {\n          callback(number_of_responses);\n        } catch (const std::exception & exception) {\n          RCLCPP_ERROR_STREAM(\n            node_logger_,\n            \"rclcpp::ClientBase@\" << this <<\n              \" caught \" << rmw::impl::cpp::demangle(exception) <<\n              \" exception in user-provided callback for the 'on new response' callback: \" <<\n              exception.what());\n        } catch (...) {\n          RCLCPP_ERROR_STREAM(\n            node_logger_,\n            \"rclcpp::ClientBase@\" << this <<\n              \" caught unhandled exception in user-provided callback \" <<\n              \"for the 'on new response' callback\");\n        }\n      };\n\n\n\n    std::lock_guard<std::recursive_mutex> lock(callback_mutex_);\n    // Set it temporarily to the new callback, while we replace the old one.\n    // This two-step setting, prevents a gap where the old std::function has\n    // been replaced but the middleware hasn't been told about the new one yet.\n    set_on_new_response_callback(\n      rclcpp::detail::cpp_callback_trampoline<decltype(new_callback), const void *, size_t>,\n      static_cast<const void *>(&new_callback));\n    // Store the std::function to keep it in scope, also overwrites the existing one.\n    on_new_response_callback_ = new_callback;\n    // Set it again, now using the permanent storage.\n    set_on_new_response_callback(\n      rclcpp::detail::cpp_callback_trampoline<\n        decltype(on_new_response_callback_), const void *, size_t>,\n      static_cast<const void *>(&on_new_response_callback_));\n  }\n  /// Unset the callback registered for new responses, if any.\n  void\n  clear_on_new_response_callback()\n  {\n    std::lock_guard<std::recursive_mutex> lock(callback_mutex_);\n    if (on_new_response_callback_) {\n      set_on_new_response_callback(nullptr, nullptr);\n      on_new_response_callback_ = nullptr;\n    }\n  }\nprotected:\n  RCLCPP_DISABLE_COPY(ClientBase)\n  RCLCPP_PUBLIC\n  bool\n  wait_for_service_nanoseconds(std::chrono::nanoseconds timeout);\n  RCLCPP_PUBLIC\n  rcl_node_t *\n  get_rcl_node_handle();\n  RCLCPP_PUBLIC\n  const rcl_node_t *\n  get_rcl_node_handle() const;\n  RCLCPP_PUBLIC\n  void\n  set_on_new_response_callback(rcl_event_callback_t callback, const void * user_data);\n  rclcpp::node_interfaces::NodeGraphInterface::WeakPtr node_graph_;\n\n\n\n  std::shared_ptr<rcl_node_t> node_handle_;\n  std::shared_ptr<rclcpp::Context> context_;\n  rclcpp::Logger node_logger_;\n  std::recursive_mutex callback_mutex_;\n  // It is important to declare on_new_response_callback_ before\n  // client_handle_, so on destruction the client is\n  // destroyed first. Otherwise, the rmw client callback\n  // would point briefly to a destroyed function.\n  std::function<void(size_t)> on_new_response_callback_{nullptr};\n  // Declare client_handle_ after callback\n  std::shared_ptr<rcl_client_t> client_handle_;\n  std::atomic<bool> in_use_by_wait_set_{false};\n};\ntemplate<typename ServiceT>\nclass Client : public ClientBase\n{\npublic:\n  using Request = typename ServiceT::Request;\n  using Response = typename ServiceT::Response;\n  using SharedRequest = typename ServiceT::Request::SharedPtr;\n  using SharedResponse = typename ServiceT::Response::SharedPtr;\n  using Promise = std::promise<SharedResponse>;\n  using PromiseWithRequest = std::promise<std::pair<SharedRequest, SharedResponse>>;\n  using SharedPromise = std::shared_ptr<Promise>;\n  using SharedPromiseWithRequest = std::shared_ptr<PromiseWithRequest>;\n  using Future = std::future<SharedResponse>;\n  using SharedFuture = std::shared_future<SharedResponse>;\n  using SharedFutureWithRequest = std::shared_future<std::pair<SharedRequest, SharedResponse>>;\n  using CallbackType = std::function<void (SharedFuture)>;\n  using CallbackWithRequestType = std::function<void (SharedFutureWithRequest)>;\n  RCLCPP_SMART_PTR_DEFINITIONS(Client)\n  /// A convenient Client::Future and request id pair.\n  /**\n   * Public members:\n   * - future: a std::future<SharedResponse>.\n   * - request_id: the request id associated with the future.\n   *\n   * All the other methods are equivalent to the ones std::future provides.\n   */\n  struct FutureAndRequestId\n\n\n\n    : detail::FutureAndRequestId<std::future<SharedResponse>>\n  {\n    using detail::FutureAndRequestId<std::future<SharedResponse>>::FutureAndRequestId;\n    /// Deprecated, use `.future.share()` instead.\n    /**\n     * Allow implicit conversions to `std::shared_future` by value.\n     * \\deprecated\n     */\n    [[deprecated(\n      \"FutureAndRequestId: use .future.share() instead of an implicit conversion\")]]\n    operator SharedFuture() {return this->future.share();}\n    // delegate future like methods in the std::future impl_\n    /// See std::future::share().\n    SharedFuture share() noexcept {return this->future.share();}\n  };\n  /// A convenient Client::SharedFuture and request id pair.\n  /**\n   * Public members:\n   * - future: a std::shared_future<SharedResponse>.\n   * - request_id: the request id associated with the future.\n   *\n   * All the other methods are equivalent to the ones std::shared_future provides.\n   */\n  struct SharedFutureAndRequestId\n    : detail::FutureAndRequestId<std::shared_future<SharedResponse>>\n  {\n    using detail::FutureAndRequestId<std::shared_future<SharedResponse>>::FutureAndRequestId;\n  };\n  /// A convenient Client::SharedFutureWithRequest and request id pair.\n  /**\n   * Public members:\n   * - future: a std::shared_future<SharedResponse>.\n   * - request_id: the request id associated with the future.\n   *\n   * All the other methods are equivalent to the ones std::shared_future provides.\n   */\n  struct SharedFutureWithRequestAndRequestId\n    : detail::FutureAndRequestId<std::shared_future<std::pair<SharedRequest, SharedResponse>>>\n  {\n    using detail::FutureAndRequestId<\n\n\n\n      std::shared_future<std::pair<SharedRequest, SharedResponse>>\n    >::FutureAndRequestId;\n  };\n  /// Default constructor.\n  /**\n   * The constructor for a Client is almost never called directly.\n   * Instead, clients should be instantiated through the function\n   * rclcpp::create_client().\n   *\n   * \\param[in] node_base NodeBaseInterface pointer that is used in part of the setup.\n   * \\param[in] node_graph The node graph interface of the corresponding node.\n   * \\param[in] service_name Name of the topic to publish to.\n   * \\param[in] client_options options for the subscription.\n   */\n  Client(\n    rclcpp::node_interfaces::NodeBaseInterface * node_base,\n    rclcpp::node_interfaces::NodeGraphInterface::SharedPtr node_graph,\n    const std::string & service_name,\n    rcl_client_options_t & client_options)\n  : ClientBase(node_base, node_graph),\n    srv_type_support_handle_(rosidl_typesupport_cpp::get_service_type_support_handle<ServiceT>())\n  {\n    rcl_ret_t ret = rcl_client_init(\n      this->get_client_handle().get(),\n      this->get_rcl_node_handle(),\n      srv_type_support_handle_,\n      service_name.c_str(),\n      &client_options);\n    if (ret != RCL_RET_OK) {\n      if (ret == RCL_RET_SERVICE_NAME_INVALID) {\n        auto rcl_node_handle = this->get_rcl_node_handle();\n        // this will throw on any validation problem\n        rcl_reset_error();\n        expand_topic_or_service_name(\n          service_name,\n          rcl_node_get_name(rcl_node_handle),\n          rcl_node_get_namespace(rcl_node_handle),\n          true);\n      }\n      rclcpp::exceptions::throw_from_rcl_error(ret, \"could not create client\");\n\n\n\n    }\n  }\n  virtual ~Client()\n  {\n  }\n  /// Take the next response for this client.\n  /**\n   * \\sa ClientBase::take_type_erased_response().\n   *\n   * \\param[out] response_out The reference to a Service Response into\n   *   which the middleware will copy the response being taken.\n   * \\param[out] request_header_out The request header to be filled by the\n   *   middleware when taking, and which can be used to associte the response\n   *   to a specific request.\n   * \\returns true if the response was taken, otherwise false.\n   * \\throws rclcpp::exceptions::RCLError based exceptions if the underlying\n   *   rcl function fail.\n   */\n  bool\n  take_response(typename ServiceT::Response & response_out, rmw_request_id_t & request_header_out)\n  {\n    return this->take_type_erased_response(&response_out, request_header_out);\n  }\n  /// Create a shared pointer with the response type\n  /**\n   * \\return shared pointer with the response type\n   */\n  std::shared_ptr<void>\n  create_response() override\n  {\n    return std::shared_ptr<void>(new typename ServiceT::Response());\n  }\n  /// Create a shared pointer with a rmw_request_id_t\n  /**\n   * \\return shared pointer with a rmw_request_id_t\n   */\n  std::shared_ptr<rmw_request_id_t>\n  create_request_header() override\n  {\n    // TODO(wjwwood): This should probably use rmw_request_id's allocator.\n\n\n\n    //                (since it is a C type)\n    return std::shared_ptr<rmw_request_id_t>(new rmw_request_id_t);\n  }\n  /// Handle a server response\n  /**\n    * \\param[in] request_header used to check if the secuence number is valid\n    * \\param[in] response message with the server response\n   */\n  void\n  handle_response(\n    std::shared_ptr<rmw_request_id_t> request_header,\n    std::shared_ptr<void> response) override\n  {\n    std::optional<CallbackInfoVariant>\n    optional_pending_request = this->get_and_erase_pending_request(request_header->sequence_number);\n    if (!optional_pending_request) {\n      return;\n    }\n    auto & value = *optional_pending_request;\n    auto typed_response = std::static_pointer_cast<typename ServiceT::Response>(\n      std::move(response));\n    if (std::holds_alternative<Promise>(value)) {\n      auto & promise = std::get<Promise>(value);\n      promise.set_value(std::move(typed_response));\n    } else if (std::holds_alternative<CallbackTypeValueVariant>(value)) {\n      auto & inner = std::get<CallbackTypeValueVariant>(value);\n      const auto & callback = std::get<CallbackType>(inner);\n      auto & promise = std::get<Promise>(inner);\n      auto & future = std::get<SharedFuture>(inner);\n      promise.set_value(std::move(typed_response));\n      callback(std::move(future));\n    } else if (std::holds_alternative<CallbackWithRequestTypeValueVariant>(value)) {\n      auto & inner = std::get<CallbackWithRequestTypeValueVariant>(value);\n      const auto & callback = std::get<CallbackWithRequestType>(inner);\n      auto & promise = std::get<PromiseWithRequest>(inner);\n      auto & future = std::get<SharedFutureWithRequest>(inner);\n      auto & request = std::get<SharedRequest>(inner);\n      promise.set_value(std::make_pair(std::move(request), std::move(typed_response)));\n      callback(std::move(future));\n    }\n\n\n\n  }\n  /// Send a request to the service server.\n  /**\n   * This method returns a `FutureAndRequestId` instance\n   * that can be passed to Executor::spin_until_future_complete() to\n   * wait until it has been completed.\n   *\n   * If the future never completes,\n   * e.g. the call to Executor::spin_until_future_complete() times out,\n   * Client::remove_pending_request() must be called to clean the client internal state.\n   * Not doing so will make the `Client` instance to use more memory each time a response is not\n   * received from the service server.\n   *\n   * ```cpp\n   * auto future = client->async_send_request(my_request);\n   * if (\n   *   rclcpp::FutureReturnCode::TIMEOUT ==\n   *   executor->spin_until_future_complete(future, timeout))\n   * {\n   *   client->remove_pending_request(future);\n   *   // handle timeout\n   * } else {\n   *   handle_response(future.get());\n   * }\n   * ```\n   *\n   * \\param[in] request request to be send.\n   * \\return a FutureAndRequestId instance.\n   */\n  FutureAndRequestId\n  async_send_request(SharedRequest request)\n  {\n    Promise promise;\n    auto future = promise.get_future();\n    auto req_id = async_send_request_impl(\n      *request,\n      std::move(promise));\n    return FutureAndRequestId(std::move(future), req_id);\n  }\n  /// Send a request to the service server and schedule a callback in the executor.\n\n\n\n  /**\n   * Similar to the previous overload, but a callback will automatically be called when a response is received.\n   *\n   * If the callback is never called, because we never got a reply for the service server, remove_pending_request()\n   * has to be called with the returned request id or prune_pending_requests().\n   * Not doing so will make the `Client` instance use more memory each time a response is not\n   * received from the service server.\n   * In this case, it's convenient to setup a timer to cleanup the pending requests.\n   * See for example the `examples_rclcpp_async_client` package in https://github.com/ros2/examples.\n   *\n   * \\param[in] request request to be send.\n   * \\param[in] cb callback that will be called when we get a response for this request.\n   * \\return the request id representing the request just sent.\n   */\n  template<\n    typename CallbackT,\n    typename std::enable_if<\n      rclcpp::function_traits::same_arguments<\n        CallbackT,\n        CallbackType\n      >::value\n    >::type * = nullptr\n  >\n  SharedFutureAndRequestId\n  async_send_request(SharedRequest request, CallbackT && cb)\n  {\n    Promise promise;\n    auto shared_future = promise.get_future().share();\n    auto req_id = async_send_request_impl(\n      *request,\n      std::make_tuple(\n        CallbackType{std::forward<CallbackT>(cb)},\n        shared_future,\n        std::move(promise)));\n    return SharedFutureAndRequestId{std::move(shared_future), req_id};\n  }\n  /// Send a request to the service server and schedule a callback in the executor.\n  /**\n   * Similar to the previous method, but you can get both the request and response in the callback.\n   *\n\n\n\n   * \\param[in] request request to be send.\n   * \\param[in] cb callback that will be called when we get a response for this request.\n   * \\return the request id representing the request just sent.\n   */\n  template<\n    typename CallbackT,\n    typename std::enable_if<\n      rclcpp::function_traits::same_arguments<\n        CallbackT,\n        CallbackWithRequestType\n      >::value\n    >::type * = nullptr\n  >\n  SharedFutureWithRequestAndRequestId\n  async_send_request(SharedRequest request, CallbackT && cb)\n  {\n    PromiseWithRequest promise;\n    auto shared_future = promise.get_future().share();\n    auto req_id = async_send_request_impl(\n      *request,\n      std::make_tuple(\n        CallbackWithRequestType{std::forward<CallbackT>(cb)},\n        request,\n        shared_future,\n        std::move(promise)));\n    return SharedFutureWithRequestAndRequestId{std::move(shared_future), req_id};\n  }\n  /// Cleanup a pending request.\n  /**\n   * This notifies the client that we have waited long enough for a response from the server\n   * to come, we have given up and we are not waiting for a response anymore.\n   *\n   * Not calling this will make the client start using more memory for each request\n   * that never got a reply from the server.\n   *\n   * \\param[in] request_id request id returned by async_send_request().\n   * \\return true when a pending request was removed, false if not (e.g. a response was received).\n   */\n  bool\n  remove_pending_request(int64_t request_id)\n\n\n\n  {\n    std::lock_guard guard(pending_requests_mutex_);\n    return pending_requests_.erase(request_id) != 0u;\n  }\n  /// Cleanup a pending request.\n  /**\n   * Convenient overload, same as:\n   *\n   * `Client::remove_pending_request(this, future.request_id)`.\n   */\n  bool\n  remove_pending_request(const FutureAndRequestId & future)\n  {\n    return this->remove_pending_request(future.request_id);\n  }\n  /// Cleanup a pending request.\n  /**\n   * Convenient overload, same as:\n   *\n   * `Client::remove_pending_request(this, future.request_id)`.\n   */\n  bool\n  remove_pending_request(const SharedFutureAndRequestId & future)\n  {\n    return this->remove_pending_request(future.request_id);\n  }\n  /// Cleanup a pending request.\n  /**\n   * Convenient overload, same as:\n   *\n   * `Client::remove_pending_request(this, future.request_id)`.\n   */\n  bool\n  remove_pending_request(const SharedFutureWithRequestAndRequestId & future)\n  {\n    return this->remove_pending_request(future.request_id);\n  }\n  /// Clean all pending requests.\n  /**\n   * \\return number of pending requests that were removed.\n\n\n\n   */\n  size_t\n  prune_pending_requests()\n  {\n    std::lock_guard guard(pending_requests_mutex_);\n    auto ret = pending_requests_.size();\n    pending_requests_.clear();\n    return ret;\n  }\n  /// Clean all pending requests older than a time_point.\n  /**\n   * \\param[in] time_point Requests that were sent before this point are going to be removed.\n   * \\param[inout] pruned_requests Removed requests id will be pushed to the vector\n   *  if a pointer is provided.\n   * \\return number of pending requests that were removed.\n   */\n  template<typename AllocatorT = std::allocator<int64_t>>\n  size_t\n  prune_requests_older_than(\n    std::chrono::time_point<std::chrono::system_clock> time_point,\n    std::vector<int64_t, AllocatorT> * pruned_requests = nullptr)\n  {\n    std::lock_guard guard(pending_requests_mutex_);\n    auto old_size = pending_requests_.size();\n    for (auto it = pending_requests_.begin(), last = pending_requests_.end(); it != last; ) {\n      if (it->second.first < time_point) {\n        if (pruned_requests) {\n          pruned_requests->push_back(it->first);\n        }\n        it = pending_requests_.erase(it);\n      } else {\n        ++it;\n      }\n    }\n    return old_size - pending_requests_.size();\n  }\n  /// Configure client introspection.\n  /**\n   * \\param[in] clock clock to use to generate introspection timestamps\n   * \\param[in] qos_service_event_pub QoS settings to use when creating the introspection publisher\n\n\n\n   * \\param[in] introspection_state the state to set introspection to\n   */\n  void\n  configure_introspection(\n    Clock::SharedPtr clock, const QoS & qos_service_event_pub,\n    rcl_service_introspection_state_t introspection_state)\n  {\n    rcl_publisher_options_t pub_opts = rcl_publisher_get_default_options();\n    pub_opts.qos = qos_service_event_pub.get_rmw_qos_profile();\n    rcl_ret_t ret = rcl_client_configure_service_introspection(\n      client_handle_.get(),\n      node_handle_.get(),\n      clock->get_clock_handle(),\n      srv_type_support_handle_,\n      pub_opts,\n      introspection_state);\n    if (RCL_RET_OK != ret) {\n      rclcpp::exceptions::throw_from_rcl_error(ret, \"failed to configure client introspection\");\n    }\n  }\nprotected:\n  using CallbackTypeValueVariant = std::tuple<CallbackType, SharedFuture, Promise>;\n  using CallbackWithRequestTypeValueVariant = std::tuple<\n    CallbackWithRequestType, SharedRequest, SharedFutureWithRequest, PromiseWithRequest>;\n  using CallbackInfoVariant = std::variant<\n    std::promise<SharedResponse>,\n    CallbackTypeValueVariant,\n    CallbackWithRequestTypeValueVariant>;\n  int64_t\n  async_send_request_impl(const Request & request, CallbackInfoVariant value)\n  {\n    int64_t sequence_number;\n    std::lock_guard<std::mutex> lock(pending_requests_mutex_);\n    rcl_ret_t ret = rcl_send_request(get_client_handle().get(), &request, &sequence_number);\n    if (RCL_RET_OK != ret) {\n      rclcpp::exceptions::throw_from_rcl_error(ret, \"failed to send request\");\n    }\n    pending_requests_.try_emplace(\n      sequence_number,\n      std::make_pair(std::chrono::system_clock::now(), std::move(value)));\n\n\n\n    return sequence_number;\n  }\n  std::optional<CallbackInfoVariant>\n  get_and_erase_pending_request(int64_t request_number)\n  {\n    std::unique_lock<std::mutex> lock(pending_requests_mutex_);\n    auto it = this->pending_requests_.find(request_number);\n    if (it == this->pending_requests_.end()) {\n      RCUTILS_LOG_DEBUG_NAMED(\n        \"rclcpp\",\n        \"Received invalid sequence number. Ignoring...\");\n      return std::nullopt;\n    }\n    auto value = std::move(it->second.second);\n    this->pending_requests_.erase(request_number);\n    return value;\n  }\n  RCLCPP_DISABLE_COPY(Client)\n  std::unordered_map<\n    int64_t,\n    std::pair<\n      std::chrono::time_point<std::chrono::system_clock>,\n      CallbackInfoVariant>>\n  pending_requests_;\n  std::mutex pending_requests_mutex_;\nprivate:\n  const rosidl_service_type_support_t * srv_type_support_handle_;\n};\n}  // namespace rclcpp\n#endif  // RCLCPP__CLIENT_HPP_\n\n\n"
  },
  {
    "id": "access_urdf/ur5transmissionxacro.txt",
    "content": "<?xml version=\"1.0\"?>\n<robot xmlns:xacro=\"http://www.ros.org/wiki/xacro\">\n\n  <xacro:macro name=\"ur5_arm_transmission\" params=\"prefix\">\n\n    <transmission name=\"${prefix}shoulder_pan_trans\">\n      <type>transmission_interface/SimpleTransmission</type>\n      <joint name=\"${prefix}shoulder_pan_joint\">\n        <hardwareInterface>PositionJointInterface</hardwareInterface>\n      </joint>\n      <actuator name=\"${prefix}shoulder_pan_motor\">\n        <mechanicalReduction>1</mechanicalReduction>\n      </actuator>\n    </transmission>\n  \n    <transmission name=\"${prefix}shoulder_lift_trans\">\n      <type>transmission_interface/SimpleTransmission</type>\n      <joint name=\"${prefix}shoulder_lift_joint\">\n        <hardwareInterface>PositionJointInterface</hardwareInterface>\n      </joint>\n      <actuator name=\"${prefix}shoulder_lift_motor\">\n        <mechanicalReduction>1</mechanicalReduction>\n      </actuator>\n    </transmission>\n  \n    <transmission name=\"${prefix}elbow_trans\">\n      <type>transmission_interface/SimpleTransmission</type>\n      <joint name=\"${prefix}elbow_joint\">\n        <hardwareInterface>PositionJointInterface</hardwareInterface>\n      </joint>\n      <actuator name=\"${prefix}elbow_motor\">\n        <mechanicalReduction>1</mechanicalReduction>\n      </actuator>\n    </transmission>\n  \n    <transmission name=\"${prefix}wrist_1_trans\">\n      <type>transmission_interface/SimpleTransmission</type>\n      <joint name=\"${prefix}wrist_1_joint\">\n        <hardwareInterface>PositionJointInterface</hardwareInterface>\n      </joint>\n      <actuator name=\"${prefix}wrist_1_motor\">\n        <mechanicalReduction>1</mechanicalReduction>\n      </actuator>\n    </transmission>\n  \n    <transmission name=\"${prefix}wrist_2_trans\">\n      <type>transmission_interface/SimpleTransmission</type>\n      <joint name=\"${prefix}wrist_2_joint\">\n        <hardwareInterface>PositionJointInterface</hardwareInterface>\n      </joint>\n      <actuator name=\"${prefix}wrist_2_motor\">\n        <mechanicalReduction>1</mechanicalReduction>\n      </actuator>\n    </transmission>\n  \n    <transmission name=\"${prefix}wrist_3_trans\">\n      <type>transmission_interface/SimpleTransmission</type>\n      <joint name=\"${prefix}wrist_3_joint\">\n        <hardwareInterface>PositionJointInterface</hardwareInterface>\n      </joint>\n      <actuator name=\"${prefix}wrist_3_motor\">\n        <mechanicalReduction>1</mechanicalReduction>\n      </actuator>\n    </transmission>\n\n  </xacro:macro>\n\n</robot>"
  },
  {
    "id": "crazyswarm/230200716pdf.txt",
    "content": "CrazyChoir: Flying Swarms of Crazyflie Quadrotors in ROS 2\nLorenzo Pichierri, Andrea Testa, Giuseppe Notarstefano\n\u00a92023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all\nother uses, in any current or future media, including reprinting/republishing this material for advertising or\npromotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse\nof any copyrighted component of this work in other works.\nAbstract\u2014 This paper introduces CRAZYCHOIR, a modular\nPython framework based on the Robot Operating System (ROS)\n2. The toolbox provides a comprehensive set of functionalities to\nsimulate and run experiments on teams of cooperating Crazyflie\nnano-quadrotors. Specifically, it allows users to perform realistic simulations over robotic simulators as, e.g., Webots\nand includes bindings of the firmware control and planning\nfunctions. The toolbox also provides libraries to perform radio\ncommunication with Crazyflie directly inside ROS 2 scripts.\nThe package can be thus used to design, implement and\ntest planning strategies and control schemes for a Crazyflie\nnano-quadrotor. Moreover, the modular structure of CRAZYCHOIR allows users to easily implement online distributed\noptimization and control schemes over multiple quadrotors.\nThe CRAZYCHOIR package is validated via simulations and\nexperiments on a swarm of Crazyflies for formation control,\npickup-and-delivery vehicle routing and trajectory tracking\ntasks. CRAZYCHOIR is available at https://github.com/\nOPT4SMART/crazychoir.\nIndex Terms\u2014 Distributed Robot Systems; Software Architecture for Robotics and Automation; Cooperating Robots;\nOptimization and Optimal Control\nI. INTRODUCTION\nUAV swarms have gained a great interest in both research\nand industrial applications due to their applicability in a wide\nrange of scenarios. In the last years the Crazyflie platform\n(Figure 1) has gained a lot of attention among researchers.\nCrazyflie is a cheap nano-quadrotor weighting 27 g. It is\nendowed with an ARM Cortex-M4 microcontroller and can\nreceive radio messages through a so-called Crazyradio dongle. In the last years, several efforts have been put into the\ndevelopment of simulation and control toolboxes based on\nthe Robot Operating System (ROS) [1]. Recently, ROS is\nbeing substituted by ROS 2, which is expanding its capabilities with novel functionalities [2]. In this paper, we introduce\nCRAZYCHOIR, a ROS 2 package allowing researchers to run\nrealistic simulations and laboratory experiments on a swarm\nof cooperating Crazyflie nano-quadrotors.\nThis work was supported in part by the Italian Ministry of Foreign Affairs\n\n\n\nand International Cooperation, grant number BR22GR01.\nAuthors are with the Department of Electrical, Electronic and Information Engineering, University of Bologna,\nBologna, Italy. {lorenzo.pichierri, a.testa,\ngiuseppe.notarstefano}@unibo.it.\nFig. 1. Snapshot of a swarm of Crazyflie nano-quadrotors in our testbed.\nA. Related Work\nControl of quadrotors is currently performed with toolboxes based on the first ROS version. As for toolboxes\nspecific for the Crazyflie, the toolboxes in [3], [4] allow user\nto run experiments on multiple Crazyflies. Researchers also\ndeveloped tools to efficiently simulate generic, autonomous\nquadrotors in a realistic environment. An Unreal Engine\nsimulator for unmanned vehicles is proposed in [5]. Authors\nin [6] propose a simulator based on Unreal Engine with\nbridges for RotorS and OpenAI-Gym as to perform Reinforcement Learning tasks. Works in [7], [8] propose two\ntoolboxes to simulate and control multiple UAVs. Finally,\na ROS-Gazebo simulator for the Erle-Copter is provided\nin [9]. As for simulation toolboxes tailored for the Crazyflie,\nauthors in [10] extend the well-known RotorS toolbox [11] to\ntarget the Crazyflie. A Gazebo-ROS-Simulink toolbox for the\nCrazyflie is proposed instead in [12]. However, in the above\ntoolboxes the swarm is handled by few, centralized ROS\nprocesses that interact with all the quadrotors, thus affecting\nthe scalability and robustness of the swarm. Moreover, they\ndo not involve distributed or decentralized design tools\nfor swarm management and control. Recently, the novel\nROS 2 [13] is substituting ROS. Indeed, ROS 2 allows\nmulti-process communication leveraging the popular Data\nDistribution Service (DDS) open standard. The DDS does\nnot require a centralized broker to dispatch messages, and\nnodes can implement self-discovery procedures. Moreover,\nthe DDS allows for the implemention of different Quality of\nService profiles, and provides reliable and secure communiarXiv:2302.00716v2 [cs.RO] 30 May 2023\nFig. 2. CRAZYCHOIR architecture. Crazyflies can exchange information with neighbors to implement distributed feedback and optimization schemes.\nLocal classes handle planning and low-level control. Control inputs can be sent to simulation environments (Webots or RVIZ) or to real robots via radio.\ncation. Also, ROS 2 has been designed for industrial settings,\nthus supporting real-time [14] and embedded systems [15]\ndevelopment. Authors in [16] propose a framework for collaborative industrial manipulators. The work in [17] proposes\na ROS 2-based architecture for self-driving cars. As for\nworks concerning software for multi-robot systems in ROS 2,\npapers [18], [19] address the development of toolboxes\n\n\n\nfor swarm robotics on ground mobile robots. Moreover,\nthese works neglect cooperation among robots or simulate\nit via (computationally demanding) all-to-all communication. None of these frameworks is however tailored for the\nCrazyflie. Recently, Crazyswarm2 [20] has been proposed\nas a ROS 2 extension to Crazyswarm [3]. Still, this package\ndoes not include routines to implement distributed optimization and control schemes on cooperating Crazyflies. Finally,\nthe toolbox in [21] provides distributed optimization and\ncommunication functionalities for teams of generic robots.\nThis package however does not handle Crazyflie swarms and\nradio communication with the quadrotors. Moreover, as we\ndetail next, our package provides simulations by combining\nthe Webots engine [22] and Crazyflie firmware bindings.\nB. Contributions\nIn this paper we introduce CRAZYCHOIR, a ROS 2\nmodular framework to perform realistic simulations and\nexperiments on swarms of cooperating Crazyflie nanoquadrotors. The toolbox provides a comprehensive set of\nPython modules allowing for fast prototyping of (distributed)\ndecision-making and control schemes on Crazyflie swarms.\nSpecifically, CRAZYCHOIR is a scalable package in which\neach Crazyflie is handled by a set of independent ROS 2\nprocesses, thus reducing single points of failure. These nodes\nare executed on a ROS-enabled workstation and can be\nallocated among multiple workstations connected on the\nsame networks. Also, its modular structure allows the user to\neasily switch from simulative scenarios to real experiments\nby changing a few lines of code. The toolbox is integrated\nwith the Webots engine, so that users can perform realistic\nsimulations of multiple Crazyflie. To the best of the authors\u2019\nknowledge, realistic, CAD-based simulation of large-scale\nswarms is often neglected. Moreover, the simulator incorporates the firmware bindings provided by Bitcraze implementing Crazyflie onboard control functions. Thereby, the user\ncan perform parameter tuning in a safe simulation environment. The proposed framework also allows for lightweight\nsimulations by means of an ad-hoc numerical integrator\ncombined with the RVIZ visualizer. Finally, CRAZYCHOIR\nsupports DISROPT [23] and CHOIRBOT [21] toolboxes,\nthus allowing users to implement distributed optimization\nschemes and handle inter-robot communications over ROS 2\naccording to a user-defined graph. The paper unfolds as\nfollows. In Section II, we detail the architecture of CRAZYCHOIR. Section III details libraries for control schemes.\nSection IV discusses swarm decision making strategies, distributed control and distributed optimization functionalities\nof the proposed package. In Section V, we discuss the\n\n\n\ncommunication bridge with the Crazyflie. Section VI shows\nhow to simulate swarms of Crazyflies in Webots and RVIZ.\nIn Section VII, we provide a use-case implementation, while\nother experiments are discussed in Section VIII.\nII. ARCHITECTURE DESCRIPTION\nCRAZYCHOIR is written in Python and is based on the\nnovel ROS 2 framework. In CRAZYCHOIR, each Crazyflie\nis handled by a set of ROS 2 processes (also called nodes).\nThese nodes handle simulation, control, planning and radio\ncommunication for each quadrotor, as well as inter-robot\ncommunication and cooperation. In the proposed package,\nthese functionalities are implemented in a modular fashion\nas a set of Python classes. At runtime, these classes are instantiated in a dedicated ROS 2 node as a standalone process.\nAn illustrative representation of the software architecture\nis in Figure 2. The software architecture of CRAZYCHOIR\nis made of five main blocks: i) control layer, ii) swarm\nplanning layer, iii) cooperative decision making layer, iv)\nradio communication layer, v) realistic simulation layer. We\nnow briefly introduce the main components of the proposed\narchitecture. A detailed description is provided in the following sections. The control layer provides a set of classes that\ncan be extended to implement off-board feedback-control\nschemes. These control classes receive reference trajectories\nfrom the planning module, in which users can also provide\ngraphical inputs to describe complex trajectories. The trajectory planning functionalities are used to generate feasible\ntrajectories, steering the generic quadrotor to fulfill highlevel decisions. These decisions are taken in another module provided by CRAZYCHOIR, in which users can implement cooperative, decision-making and distributed feedback\nschemes on swarms of Crazyflies. This cooperative decision\nmaking layer indeed provides functionalities to implement\ndistributed, online optimization and control schemes. Leveraging this cooperative framework, robots can jointly fulfill\ncomplex tasks by exchanging messages with neighboring\nrobots. The control inputs generated by the control classes,\nor the setpoints provided by the planning module, can\neither be sent to the Crazyflie via radio, or transmitted via\nROS 2 topics to the simulators provided in CRAZYCHOIR.\nIn particular, users can choose between realistic simulations,\ndeveloped in Webots, and lightweight numerical integrations,\nvisualized in RVIZ. Finally, CRAZYCHOIR can be interfaced\nwith motion capture systems as, e.g., Vicon so that users\ncan retrieve quadrotor poses during the experiments. The\nproposed package implements derivative and low-pass filters\nto obtain linear and angular velocities for each robot. Indeed,\n\n\n\nmotion capture systems usually provide only position and\nattitude data. Thanks to this modular design, users can\ncombine classes from the different layers according to their\nneeds. As we detail in the following, this allows for switching\nfrom simulations to experiments with few lines of code.\nUsers can quickly extend the proposed modules with novel\nfunctionalities and, thanks to the ROS 2 capabilities, can also\ndeploy the software on different workstations.\nIII. CRAZYCHOIR CONTROL LIBRARY\nCRAZYCHOIR provides a CrazyflieController\ntemplate class that can be specialized to implement\nthe desired control schemes for the Crazyflie. This\nclass aims at mapping desired trajectory inputs to a\ncontrol setpoint to be sent to the Crazyflie or to the\nsimulators. The CrazyflieController class is\ndesigned according to the Strategy pattern [24] so that the\nspecific control law can be defined at runtime. Specifically,\nthe class owns as attributes a set of classes specifying\nits behavior. That is, it owns TrajectoryHandler\nand CommunicationHandler classes specifying how\ndesired trajectories will be published to the controller\nand which control input must be communicated to the\nCrazyflie. In the proposed package, we already provide\na HierarchicalController class that implements\nclassical flatness-based control schemes [25]. This class\nis suitable to track a desired flat-output trajectory (e.g.,\nposition and yaw profiles with their derivatives), or it\ncan be used to track desired acceleration profiles coming\nfrom, e.g., double-integrator distributed control laws. We\nprovide an example of this setting in Section VII, in\nwhich we use this class to perform a distributed formation\ncontrol task. HierarchicalController extends\nthe CrazyflieController template. To this end,\nit owns two additional classes PositionControl\nand AttitudeControl, implementing position\nand angular control, respectively. The outputs of the\nPositionControl class are the thrust and desired\nattitude profile. The AttitudeControl classes instead\ngenerate an angular velocity profile given desired attitude\nreferences. As an example, we implement the geometric\n\n\n\ncontrol law in [26]. We refer the reader to the next\nsections for a detailed discussion of these modules. A\nsketch of the role of these classes and the related topics is\nprovided in Figure 3. Here, the arrows generated from the\nHierarchicalController class represent the fact that\nTrajectoryHandler and CommunicationHandler\nare attributes of HierarchicalController, that call\ntheir methods. The HierarchicalController class\nreceives trajectory messages on /traj topic and sends\ncontrol messages on /cmd vel topic.\nFig. 3. HierarchicalControl class and involved topics.\nIV. CRAZYCHOIR MODULES FOR COOPERATIVE\nDECISION MAKING AND PLANNING\nCRAZYCHOIR provides modules to perform off-board\nplanning tasks for each quadrotor. Also, the proposed package allows users to implement cooperative decision-making\nand distributed feedback schemes on swarms of Crazyflies.\nA. GUI-based Swarm Trajectory Planning\nCRAZYCHOIR involves a set of functionalities to handle\nplanning tasks. More in detail, CRAZYCHOIR includes a\ngraphical interface to provide trajectories to a set of quadrotors. In fact, one of these functionalities allows users to\nhand-draw trajectories and directly send them to the chosen\nquadrotor(s). The points of these hand-drawn trajectories\nare interpolated, and a polynomial spline is constructed in\norder to ensure the continuity of velocity and acceleration\nprofiles. Then, users can tune the trajectory time in order to\nincrease/decrease its execution and avoid high accelerations.\nAlso, this process can be extended in order to use different\nplanning methods and, e.g., manually impose bounds on\nthe trajectories. A snapshot of the interface is reported in\nFigure 4, where we draw the name of our laboratory (i.e.,\nCasy). Further, in Section VIII we present an example in\nwhich a Crazyflie follows this trajectory.\nThis functionality can be exploited in scenarios in which,\ne.g., there is a subset of leading quadrotors that move in the\nspace and a subset of following quadrotors that run cooperative algorithms to suitably track the leaders. In Section VII,\nwe provide an example of formation control with moving\nleaders to highlight this aspect. The GUI can be also used to\nhelp the final user to manage classical operations needed during simulations/experiments (e.g., hovering, landing, starting\nFig. 4. Snapshot of the proposed GUI.\nthe experiment, etc.). Then, the package provides methods\n\n\n\nto perform point-to-point trajectories and to evaluate polynomial paths passing through multiple, arbitrary points. These\nmodules allow the user to send (e.g., to the controller node)\nposition, velocity, and acceleration setpoints constituting a\nsmooth trajectory at the desired communication rate. These\nclasses also handle dynamic replanning scenarios where\na new trajectory has to be evaluated while the quadrotor\nis already following another path. To interface planning\nclasses with, e.g. controller classes, CRAZYCHOIR provides\na TrajectoryHandler Strategy class. This class details\nthe topic on which the desired trajectory will be published.\nIn this way, ROS 2 nodes dynamically instantiate the proper\nROS 2 publisher and subscribers. The class also specifies the\ntrajectory message type and a callback function to extract the\ntrajectory from the message.\nB. Distributed Optimization and Control\nIn CRAZYCHOIR, the user can implement distributed optimization and control schemes in which teams of quadrotors\nexchange suitable data in order to solve complex tasks. In\nthis cooperative setting, each quadrotor communicates with\nfew, neighboring quadrotors, possibly according to timevarying communication topologies. As a result, the team\nof robots leverages the local knowledge of each quadrotor\n(coming, e.g. from onboard sensors) and exploits interrobot communications to achieve a global goal. CRAZYCHOIR implements a set of functionalities to deploy distributed optimization and control schemes in which users\ncan implement distributed algorithms from the perspective\nof each robot. Embedding DISROPT [23] functionalities,\nusers can model different optimization problems in which\neach robot knowns only a part of the objective function and\nconstraints, eventually including non-convex, mixed-integer\nsets. An example is provided in Section VIII-B. Inter-robot\ncommunication is then handled using the ROS 2 middleware. To this end, it is compatible with CHOIRBOT [21],\na ROS 2 package for cooperative robotics. More in detail,\nit allows users to implement static or time-varying directed\ncommunication networks. This is performed according to\nthe publisher-subscriber protocol. Exploiting the Quality of\nService feature introduced in ROS 2, the package allows\nfor the implementation of synchronous and asynchronous\nschemes, as well as lossy communications. This set of functionalities is provided by two main classes, CFGuidance\nand CFDistributedFeedback, that extend CHOIRBOT\nfunctionalities in order to implement distributed schemes\ntailored for Crazyflie swarms. The two classes expose\nto users a set of pre-defined methods send, receive,\nasynchronous receive, neighbors exchange (to\n\n\n\nsimultaneously perform send/receive) according to some\nuser-defined communication graph. These functions also allow to send different kinds of data to different neighbors. An\ninteresting feature is that the user does not need to define any\nROS message. Indeed, all the data is automatically serialized\nand sent as a std msgs/ByteMultiArray on the sender\nside, while it is de-serialized on the receiver side. Thus,\nusers can extend these classes according to their needs by\nonly implementing the desired algorithmic strategies without\nwarning about inter-robot communications. We remind the\nreader to Section VII and Section VIII for usage examples of\nthese classes for cooperative control and optimization tasks.\nV. RADIO COMMUNICATION\nTo physically control the Crazyflie nano-quadrotor, angular or angular-rate set points can be sent via radio. Position or velocity set-points can be communicated as well,\ntogether with periodical ground-truth information. Crazyflies\nare equipped with an nRF51822 radio controller, used to\ncommunicate with a PC by means of the Crazyradio PA.\nThe Crazyradio PA is a 2.4 GHz USB radio dongle based on\nthe nRF24LU1+. It transmits 32-byte packets with datarate\nup to 2Mbits, spreading in a range of 125 channels. Each\nCrazyflie is able to receive data on one of these channels\nat a certain datarate. The choice of these communication\nparameter is crucial when performing experiments with a\nlarge number of quadrotors. Indeed, a wrong choice may\nresult into a noisy communication channel and poor flight\nperformance. To mitigate this aspect, CRAZYCHOIR provides\na script that identifies the channels that are less subject\nto external interferences. To handle the communication\nwith the quadrotors, CRAZYCHOIR implements a tailored\nRadioHandler class. Each Crazyradio PA is handled by\nan instantiation of this class into an independent ROS 2 node.\nIn particular, this class allows each dongle to communicate\nwith multiple Crazyflies by exploiting the Python methods\nof Crazyflie-lib-python developed by Bitcraze. The\nRadioHandler requires a list of URI address, used\nto set a unique communication link with each Crazyflie\nassociated with the radio. In an initialization procedure, the\nclass updates a set of required parameters of the Crazyflie\nrelated to the onboard controller. After that, each radio\nnode subscribes to the multiple cmd vel topics published\nby the control nodes (cf. Section III) for each Crazyflie\n\n\n\nassociated with the dongle. The subscription callback triggers\nthe cmd sender, which is implemented in subclasses of\nRadioHandler, and it is in charge of elaborating the\ncontrol input and forward it to the nano-quadrotors. A sketch\nof this architecture is provided in Figure 5.\nWe provide a set of subclasses that extend\nRadioHandler, namely RadioHandlerFPQR,\nFig. 5. Examples of nodes and topics involved in the radio communication\nfor a swarm of 5 quadrotors and 2 radio dongles.\nRadioHandlerFRPY and RadioHandlerXYZ. More\nin detail, the first one sends to the nano-quadrotors thrust\nand angular-rate setpoints. The onboard firmware then\nevaluates a suitable control input using a PID controller,\ncomparing the setpoint with gyroscope data. The second\none instead sends thrust and angular setpoints. An onboard\nPID controller tracks these setpoints. The class leverages\nBitcraze logging methods to retrieve onboard log data.\nThese subclasses are tailored for precise control schemes\nand require control inputs to be sent at high communication\nrates. The RadioHandlerXYZ class instead sends\nposition setpoints and ground truth information to\nthe robots. These setpoints are handled onboard by\nthe higher level commander implemented on the\nCrazyflie firmware. The communication of position setpoints\ncan be performed at a low communication rate, in the order\nof a few Hertz. This fact reduces the number of messages\non the communication links. Thus, this class is tailored\nfor experimental scenarios with several quadrotors. Each\nradio node handles a group of Crazyflies and thus requires\na list of radio URIs and a set of numerical identifiers to\nsubscribe to the correct topics.\nVI. SIMULATION TOOLS IN CRAZYCHOIR\nIn this section, we describe how to simulate a swarm\nof Crazyflies in CRAZYCHOIR. First, we detail how to\nperform this task in conjunction with Webots, a realistic\nengine tailored for robot simulations. Then, we detail how\nto run a numerical simulation using a custom integrator and\nRVIZ visualization. Although we focus on Webots, users can\nextend the package to leverage other engines such as Gazebo.\nA. Realistic Simulations via Webots\n\n\n\nCRAZYCHOIR includes a set of functionalities, in the form\nof plugins, to interact with Webots. These plugins receive\ninputs from the higher-level classes (e.g., control inputs or\nwaypoints coordinates) and map them to motor commands.\nThe command mapping is evaluated using Python bindings\nof the Crazyflie firmware functions provided by Bitcraze.\nThis allows the designer to have realistic feedbacks on the\nquadrotor behavior. Also, the designer could use this feature\nto test new firmware functions, e.g., embed control algorithm\ndirectly onboard. To properly simulate a robot in the Webots\nenvironment, also called World, the designer has to specify\n(i) the geometry of the robot, (ii) external features that\nenrich the model (e.g. sensors, cameras, and actuators) and\n(iii) plugins to control the actuators. The first requirement\nis achieved by importing a .stl file (STereo Lithography\ninterface format). External features can be endowed by filling\nup a .urdf file (Unified Robot Description Format). Finally,\nto satisfy the third requirement, CRAZYCHOIR provides a\nclass of plugins to control the Crazyflie actuators. Hence,\nto endow our package with an exhaustive set of Webots\nplugins, we developed a parent class named MotorCtrl.\nAt the beginning, the class sets out the whole Crazyflie\nphysical equipments, making available GPS measurements\nand IMU detections. Moreover, the class initializes ROS 2\npublishers and subscribers in order to interface Webots with\nCRAZYCHOIR planners and controllers. The main class of\nplugins MotorCtrl is extended by two subclasses. The first\nsubclass, MotorCtrlFPQR, takes as input references the\ndesired thrust and angular rates. The computation of these\nquantities is explained in Section III. The mapping to motor\ntorques is then performed using firmware Python bindings,\nthus using the same model implemented on the Crazyflie.\nThe second subclass, MotorCtrlXYZ, leverages the functionalities of the trajectory planner coded in the firmware.\nIndeed, it receives desired position and yaw setpoints that are\nforwarded to the planner methods to evaluate a trajectory. As\na result, the trajectory is elaborated by firmware bindings and\nmotor commands are provided to the simulated Crazyflie.\nB. Lightweight Simulations via Numerical Integration\nTo allow users to perform simulations without additional,\nexternal software, we provide a dynamics simulator for the\n\n\n\nCrazyflie nano-quadrotor running an Explicit Runge-Kutta\nmethod. The integration is performed at 100 Hz, and is based\non the following dynamics\n\u02d9p = v (1)\n\u02d9v = gzW \u2212\nu1\nm\nR(\u03b7)zW \u2212\n1\nm\nR(\u03b7)AR(\u03b7)\n\u22a4v (2)\n\u03b7\u02d9 = [u2 u3 u4]\n\u22a4 (3)\nHere, p \u2208 R\n3\nis the position of the quadrotor in the\nworld frame FW = {xW , yW , zW }, v \u2208 R\n3\nis its linear\nvelocity, and m = 0.027 Kg is the Crazyflie mass. The\nrotation matrix is denoted by R \u2208 SO(3), and the vector\n\u03b7 = [\u03c6, \u03b8, \u03c8]\n\u22a4 stacks the Euler\u2019s angles, namely, roll, pitch\nand yaw. The Crazyflie allows the user to send thrust, roll\nrate, pitch rate and yaw rate as control actions. Thus, the\ncontrol inputs in the considered dynamics are collected by\nthe vector u = [u1 u2 u3 u4]\n\u22a4 \u2208 R\n4\n, with u1 \u2208 R denoting\nthe thrust and u2, u3, u4 \u2208 R the angular rates (according\nto the Z \u2212 Y \u2212 X extrinsic Euler representation). The term\nRAR\u22a4v in (2) refers to the rotor drag effect as modelled\nin [27]. The numerical values of the drag parameters have\nbeen chosen according to the discussion in [28]. Thanks to\nthe modular structure of the package, the user can extend\nor modify the proposed integrator to simulate more complex\ndynamics. To visualize the quadrotor motion, we also provide\na visualization utility based on RVIZ.\n\n\n\nVII. CRAZYCHOIR HANDS-ON EXAMPLE:\nBEARING-BASED FORMATION CONTROL\nThis section aims at introducing the user to our toolbox.\nTo this end, we show how to simulate the bearing-based\ndistributed formation control scheme as in [29] over a swarm\nof Crazyflie. We start by providing the problem set-up and\nthe classes needed for its implementation. Then, we show\nhow to run the simulation both in RVIZ and Webots. Finally,\nwe show how CRAZYCHOIR allows users to easily switch\nfrom simulation to experiment and run the same setting on\na real swarm of Crazyflies.\nA. Problem Set-up\nWe consider a network of N quadrotors, divided into Nl\nleaders and N \u2212Nl followers. The objective is to control the\nfollowers to deploy a desired formation in the space, while\nthe leaders stand still in their positions. In the considered\ndistributed set-up, each quadrotor can communicate with a\nset Ni of neighboring quadrotors. The formation is defined\nby a set of bearings g\n\u22c6\nij for all the couples (i, j) with i \u2208\n{1, . . . , N} and j \u2208 Ni\n. Authors in [29] consider doubleintegrator systems in the form \u00a8p\ndi\ni = u\ndi\ni\n. Leaders apply\nu\ndi\ni = 0, while followers implement\nu\ndi\ni = \u2212\nP\nj\u2208Ni\nPg\n\u22c6\nij\n[kp(pi \u2212 pj ) + kv(vi \u2212 vj )], (4)\n\n\n\nwhere Pg\n\u22c6\nij = I3\u2212g\n\u22c6\nijg\n\u22c6\u22a4\nij and I3 is the 3\u00d73 identity matrix.\nNotice that this input cannot be directly fed to the quadrotors.\nIn our example, we use the control input u\ndi\ni\nas a desired\nacceleration profile for the i-th Crazyflie. This profile is then\ntracked using a flatness-based controller (cf. Section III).\nB. Software Implementation\nTo implement the distributed bearing-based formation control scheme, we need three classes. The first one implements\nthe distributed control law in (4). This is done in a specific\nmethod as follows\nu = np.zeros(3)\nif not self.is_leader:\nfor j, neigh_pose in neigh_data.items():\nerr_pos = self.current.position -\nneigh_pose.position\nerr_vel = self.current_pose.velocity -\nneigh_pose.velocity\nu += - P_i[j] @ (self.kp * err_pos +\nself.kv * err_vel)\nThe rest of the CRAZYCHOIR ecosystem will handle ROS 2\ncommunication among nodes so that the user solely has\nto implement the desired control law. The second required\nclass needs to track the acceleration profile generated by\nthe distributed control scheme. This is developed according\nto Section III. For this example, we need a control law\ntracking the acceleration profile generated by the guidance\nclass. Then, we generate an angular velocity input according\nto a geometric control law. To this end, we have to specify\nthat the controller sends the Crazyflie angular rates and thrust\nas control inputs. This can be implemented as follows\nposition_ctrl = FlatnessAccelerationCtrl()\nattitude_ctrl = GeometryAttitudeCtrl()\n\n\n\nsender = FPQRSender()\ndesired_accel = AccelerationTraj()\ncontroller = HierarchicalController(\npos_strategy=position_ctrl,\nattitude_strategy=attitude_ctrl,\ncommand_sender=sender,\ntraj_handler=desired_accel)\nrclpy.spin(controller)\nThe last class instead simulates the Crazyflie dynamics. In\nFigure 6, we provide a communication diagram highlighting\nthe classes involved in this use-case and their interactions.\nFor the formation control problem, the guidance node of\neach quadrotor sends to its neighbors only two vectors (i.e.,\nposition and velocity) at 100Hz rate.\nFig. 6. Class communication diagram. Rectangles represent different\nclasses, each one handled by a different node. Arrows represent directional\ncommunications, which are performed leveraging ROS 2 topics. On each\narrow, exchanged data is reported.\nC. Running and Visualize the Simulation\nTo easily run the simulation, we leverage\nthe ROS 2 launching system. Specifically, it is\nnecessary to write a Python script specifying which\nnodes have to be run. It is necessary to set-up\ninstances of the DistributedControlGuidance,\nHierarchicalController and CFIntegrator\nclasses for each quadrotor in the network. The launch file\nalso allows the user to specify additional parameters, e.g.,\nrobot initial conditions and the communication graph. As\nan example, let N be the number of Crazyflie in the desired\nsimulation. To instantiate a controller for each quadrotor,\nthe code can be formatted as follows.\ndef generate_launch_description():\n# ... define graph and init. positions\nlaunch_description = [] # list overall nodes\nfor i in range(N): # for each quadrotor add\nneeded nodes\n# ... set-up distributed feedback node\n# ... set-up integrator node\nlaunch_description.append(Node(\npackage=\u2019crazychoir_examples\u2019,\n\n\n\nnode_executable=\u2019crazychoir_controller\u2019,\nnamespace=\u2019agent_{}\u2019.format(i),\nparameters=[{\u2019cf_id\u2019: i}]))\nreturn LaunchDescription(launch_description)\nIn order to visualize the simulation, we included in our\ntoolbox a script to visualize the Crazyflie team in RVIZ. More\nin detail, we provide a class that receives the pose information from the CFIntegrator classes and sends suitable\nmessages to RVIZ for visualization. A set of snapshots for\na simulation with N = 4 robots is provided in Figure 7.\nTo run the same setting in the Webots simulator, it is solely\nt = 0 t = 1 t = 2 t = 3\nFig. 7. Sequence of images from the RVIZ toolbox at different subsequent\ntime instants. Static quadrotors are the leaders, while the moving ones are\nthe followers. As time progresses, quadrotors reach the desired formation.\nnecessary to substitute the CFIntegrator classes with the\nWebots simulation architecture. To emphasize the potential\nof Webots, we simulate 30 quadrotors drawing a grid. In\nthis setting, we leverage the distributed paradigm allowed\nby CRAZYCHOIR employing three workstations to handle\nthe swarm, each of them endowed with Ubuntu 20.04 and\nROS 2 Foxy. One handles the physics engine, while each one\nhandles a subset of the quadrotors. We implemented a keepout zone to ensure that, as soon as a quadrotor flies beyond\na certain limit area, it is immediately shut down. Snapshots\nfrom the Webots simulation are depicted in Figure 8.\nFig. 8. Beginning of the simulation (left) and end of the simulation (right)\nof the bearing formation control problem in Webots.\nD. Running the Experiment\nIn this section, we show how CRAZYCHOIR meets prototyping standards, allowing the user to switch from simulation\nand experiment by changing only a few lines of code.\nIndeed, to run an experiment, it is necessary to include\nin the launch file the Crazyflie URIs and the radio nodes\nas described in Section V. These few lines of code shall\nsubstitute the ones related to Webots or RVIZ. After that,\nit is only required to check that nodes subscribe to the\ntopics transporting Vicon data. To run our experiments, we\nused the ros2-vicon-receiver package 1\nto receive\ndata from our Vicon system. Snapshots from an experiment\nwith 4 quadrotor are provided in Figure 9. Furthermore,\n1https://github.com/OPT4SMART/ros2-vicon-receiver\n\n\n\nt = 0 t = 1 t = 2 t = 3\nFig. 9. Snapshots from an experiment at different time instants. Leaders\nare circled in red, followers in blue.\nwe provide an experiment in which leaders track a handwritten trajectory, leveraging the tools provided by the GUI\n(see Section IV-A). More precisely, we draw a circle with\na radius of 0.4m, and we execute this trajectory for 40s.\nTo realize this scenario, we changed only a few settings in\nthe leader control node. We modified the control strategy\nto FlatnessPositionCtrl(), which also processes\nposition and velocity references, and the trajectory handler to\nFullStateTraj(). In addition, it is necessary to launch\na planner node for the leaders, with the goal of evaluating the\nsplines retrieved by the drawing done in the GUI. A video\nis available as supplementary material2\n.\nVIII. CRAZYCHOIR EXPERIMENTS ON TRAJECTORY\nTRACKING AND PICKUP AND DELIVERY\nWe now provide two additional experiments. First, a\nquadrotor tracks a hand-written trajectory. Then, a swarm\nof Crazyflies executes a pickup-and-delivery task. All the\nneeded nodes are executed on a workstation (Intel i9, Nvidia\nRTX 4000, Ubuntu 20.04, ROS 2 Foxy) equipped with\nmultiple radio transmitters, each handling two quadrotors.\nMoreover, a second workstation (Intel Xeon, Windows 7)\nhandles the Vicon Tracker software.\nA. Tracking of a hand-written trajectory\nWe provide experimental results for a Crazyflie tracking\na hand-drawn trajectory. The path has been implemented\nusing he graphical interface introduced in Section IV-A, see\nalso Figure 4. The chosen trajectory, i.e., the name of our\nlaboratory \u201cCasy\u201d, is interpolated by a set of Python methods\nprovided by the proposed planning module. This trajectory is\ntracked by an off-board controller that elaborates the desired\nreferences and, leveraging the RadioFPQR class, forwards\nthe thrust and angular-rates commands to the Crazyflie. Figure 10 shows a long-exposure snapshot from the experiment.\nA video is available as supplementary material to the paper3\n.\nB. Multi-Robot Pickup and Delivery\nBy exploiting the distributed optimization features detailed\nin Section IV-B, we choose an experimental set-up that deals\n\n\n\nwith a distributed optimization problem.\n2The video is also available at https://youtu.be/mJ1HOquR-vE\n3The video is also available at https://youtu.be/wX2r55WdZ9g\nFig. 10. Long-term exposure snapshot from an experiment in which a\nquadrotor draws a hand-drawn trajectory.\n1) Problem Set-up: We employ CRAZYCHOIR to perform\nexperiments for a cooperative pickup-and-delivery scenario\ninvolving N = 6 Crazyflie. In this setting, quadrotors have\nto pickup goods at given locations and delivery them in\nother locations. As a further constraint, each quadrotor has\na certain load capability and can pick-up only some goods.\nThe goal is to minimize the overall travel distance, while\nguaranteeing that all the goods are successfully delivered.\nThis problem can be formulated as a large-scale mixedinteger linear program, i.e. an optimization problem with a\nlarge number of both binary and continuous variables. We\nrefer the reader to [30] for a description of the problem.\n2) Software Implementation: Similarly to Section VII,\nwe exploit the modularity features of CRAZYCHOIR to\nimplement the considered scenario on a real swarm of\nCrazyflies. Firstly, we take advantage of the CFGuidance\nclass, creating a child subclass named PDVRPGuidance\nwhich computes the optimal pickup-and-delivery locations\nfor each quadrotor. In this subclass, we exploit the functionalities of DISROPT [23] to model and solve the distributed\noptimization problem. As opposed to the simulative example\nprovided in Section VII, in this experiment, we exploit the\nonboard controller, by sending position references to each\nCrazyflie. Thanks to the RadioHandlerXYZ class, the\nposition references given by the solution of the pickup-anddelivery problem are forwarded to the onboard controller\nof the Crazyflie, which is in charge to generate and track\nthe desired trajectory. A snapshot from an experiment is in\nFigure 11. A video is available as supplementary material3\n.\nFig. 11. The left snapshot illustrates the Crazyflies reaching the delivery\nlocations, while the right scheme shows the pickup points (blue arrows) and\nthe delivery points (orange arrows). Dashed lines represent optimal paths.\nIX. CONCLUSIONS\nIn this paper, we introduced CRAZYCHOIR, a ROS 2\ntoolbox specifically tailored for swarms of Crazyflie nanoquadrotors. The package allows the user to perform realistic\nsimulations of Crazyflie swarms using Webots and firmware\nbindings. Also, the toolbox interfaces with radio dongles to\n\n\n\nperform experiments on real nano-quadrotors. We provide\nseveral template classes to perform control, planning, and\ncooperative decision making. Thanks to these functionalities,\nusers can easily extend the package by implementing their\nown algorithms. Illustrative simulations and experiments\nhave been provided to assess the potentiality of the toolbox.\nREFERENCES\n[1] M. Quigley, K. Conley, B. Gerkey, J. Faust, T. Foote, J. Leibs,\nR. Wheeler, A. Y. Ng et al., \u201cRos: an open-source robot operating\nsystem,\u201d in ICRA workshop on open source software, vol. 3, no. 3.2,\n2009, p. 5.\n[2] Y. Maruyama, S. Kato, and T. Azumi, \u201cExploring the performance of\nros2,\u201d in 13th Intern. Conf. on Embedded Software, 2016, pp. 1\u201310.\n[3] J. A. Preiss, W. Honig, G. S. Sukhatme, and N. Ayanian, \u201cCrazyswarm:\nA large nano-quadcopter swarm,\u201d in IEEE International Conference\non Robotics and Automation (ICRA), 2017, pp. 3299\u20133304.\n[4] W. Honig and N. Ayanian, \u201cFlying multiple uavs using ros,\u201d in \u00a8 Robot\nOperating System (ROS). Springer, 2017, pp. 83\u2013118.\n[5] S. Shah, D. Dey, C. Lovett, and A. Kapoor, \u201cAirsim: High-fidelity\nvisual and physical simulation for autonomous vehicles,\u201d in Field and\nservice robotics. Springer, 2018, pp. 621\u2013635.\n[6] Y. Song, S. Naji, E. Kaufmann, A. Loquercio, and D. Scaramuzza,\n\u201cFlightmare: A flexible quadrotor simulator,\u201d arXiv:2009.00563, 2020.\n[7] V. Grabe, M. Riedel, H. H. Bulthoff, P. R. Giordano, and A. Franchi, \u00a8\n\u201cThe telekyb framework for a modular and extendible ros-based\nquadrotor control,\u201d in IEEE ECMR, 2013, pp. 19\u201325.\n[8] J. Meyer, A. Sendobry, S. Kohlbrecher, U. Klingauf, and O. v. Stryk,\n\u201cComprehensive simulation of quadrotor uavs using ros and gazebo,\u201d\nin IEEE SIMPAR. Springer, 2012, pp. 400\u2013411.\n[9] K. Kumar, S. I. Azid, A. Fagiolini, and M. Cirrincione, \u201cErlecopter simulation using ros and gazebo,\u201d in IEEE Mediterranean\nElectrotechnical Conference, 2020, pp. 259\u2013263.\n[10] G. Silano, E. Aucone, and L. Iannelli, \u201cCrazys: a software-in-theloop platform for the crazyflie 2.0 nano-quadcopter,\u201d in IEEE Mediterranean Conference on Control and Automation, 2018, pp. 1\u20136.\n[11] F. Furrer, M. Burri, M. Achtelik, and R. Siegwart, \u201cRotors\u2014a modular\ngazebo mav simulator framework,\u201d in Robot operating system (ROS).\nSpringer, 2016, pp. 595\u2013625.\n[12] M. Nithya and M. Rashmi, \u201cGazebo-ros-simulink framework for hover\ncontrol and trajectory tracking of crazyflie 2.0,\u201d in IEEE Region 10\nConference, 2019, pp. 649\u2013653.\n[13] S. Macenski, T. Foote, B. Gerkey, C. Lalancette, and W. Woodall,\n\u201cRobot operating system 2: Design, architecture, and uses in the wild,\u201d\n\n\n\nScience Robotics, vol. 7, no. 66, p. eabm6074, 2022.\n[14] L. Puck, P. Keller, T. Schnell, C. Plasberg, A. Tanev, G. Heppner,\nA. Roennau, and R. Dillmann, \u201cDistributed and synchronized setup\ntowards real-time robotic control using ros2 on linux,\u201d in IEEE Intern.\nConf. on Automation Science and Engineering, 2020, pp. 1287\u20131293.\n[15] K. Belsare, A. C. Rodriguez, P. G. Sanchez, J. Hierro, T. Ko\u0142con, \u00b4\nR. Lange, I. Lutkebohle, A. Malki, J. M. Losa, F. Melendez \u00a8 et al.,\n\u201cMicro-ros,\u201d in Robot Operating System (ROS) The Complete Reference (Volume 7). Springer, 2023, pp. 3\u201355.\n[16] E. Eros, M. Dahl, K. Bengtsson, A. Hanna, and P. Falkman, \u201cA \u02dd\nROS2 based communication architecture for control in collaborative\nand intelligent automation systems,\u201d Procedia Manufacturing, vol. 38,\npp. 349\u2013357, 2019.\n[17] M. Reke, D. Peter, J. Schulte-Tigges, S. Schiffer, A. Ferrein, T. Walter,\nand D. Matheis, \u201cA self-driving car architecture in ROS2,\u201d in IEEE\nInternational SAUPEC/RobMech/PRASA Conference, 2020, pp. 1\u20136.\n[18] T. K. Kaiser, M. J. Begemann, T. Plattenteich, L. Schilling, G. Schildbach, and H. Hamann, \u201cRos2swarm-a ros 2 package for swarm robot\nbehaviors,\u201d in IEEE ICRA, 2022, pp. 6875\u20136881.\n[19] S. Mai, N. Traichel, and S. Mostaghim, \u201cDriving swarm: A swarm\nrobotics framework for intelligent navigation in a self-organized\nworld,\u201d in IEEE Intern. Conf. on Robot. and Autom., 2022, pp. 01\u201307.\n[20] \u201cCrazyswarm2,\u201d https://github.com/IMRCLab/crazyswarm2/.\n[21] A. Testa, A. Camisa, and G. Notarstefano, \u201cChoiRbot: A ROS 2\ntoolbox for cooperative robotics,\u201d IEEE Robotics and Automation\nLetters, vol. 6, no. 2, pp. 2714\u20132720, 2021.\n[22] O. Michel, \u201cCyberbotics ltd. webots\u2122: professional mobile robot\nsimulation,\u201d Int. Jour. of Adv. Robotic Sys., vol. 1, no. 1, p. 5, 2004.\n[23] F. Farina, A. Camisa, A. Testa, I. Notarnicola, and G. Notarstefano,\n\u201cDisropt: a python framework for distributed optimization,\u201d IFACPapersOnLine, vol. 53, no. 2, pp. 2666\u20132671, 2020.\n[24] E. Gamma, R. Helm, R. Johnson, R. E. Johnson, J. Vlissides et al., Design patterns: elements of reusable object-oriented software. Pearson\nDeutschland GmbH, 1995.\n[25] D. Mellinger and V. Kumar, \u201cMinimum snap trajectory generation and\ncontrol for quadrotors,\u201d in IEEE ICRA, 2011, pp. 2520\u20132525.\n[26] T. Lee, M. Leok, and N. H. McClamroch, \u201cGeometric tracking control\nof a quadrotor uav on se (3),\u201d in IEEE conference on decision and\ncontrol, 2010, pp. 5420\u20135425.\n[27] J.-M. Kai, G. Allibert, M.-D. Hua, and T. Hamel, \u201cNonlinear feedback control of quadrotors exploiting first-order drag effects,\u201d IFACPapersOnLine, vol. 50, no. 1, pp. 8189\u20138195, 2017.\n[28] J. Forster, \u201cSystem identification of the crazyflie 2.0 nano quadro- \u00a8\ncopter,\u201d B.S. thesis, ETH Zurich, 2015.\n[29] S. Zhao and D. Zelazo, \u201cTranslational and scaling formation maneuver\ncontrol via a bearing-based approach,\u201d IEEE Transactions on Control\n\n\n\nof Network Systems, vol. 4, no. 3, pp. 429\u2013438, 2017.\n[30] A. Camisa, A. Testa, and G. Notarstefano, \u201cMulti-robot pickup and\ndelivery via distributed resource allocation,\u201d IEEE Transactions on\nRobotics, vol. 39, no. 2, pp. 1106\u20131118, 2022.\n\n\n"
  },
  {
    "id": "ros_instantiate/pythonapirosbagwrite.txt",
    "content": "First time here? Check out the FAQ!\n\n  \nROS Resources: [ Documentation ](http://wiki.ros.org/) | [ Support\n](http://wiki.ros.org/Support) | [ Discussion Forum\n](http://discourse.ros.org/) | [ Index ](http://index.ros.org/) | [ Service\nStatus ](http://status.ros.org/) | [ ros @ Robotics Stack Exchange\n](https://robotics.stackexchange.com/questions/tagged/ros)  \n---  \n  \n_Attention:_ Answers.ros.org is deprecated as of August the 11th, 2023. Please\nvisit [ robotics.stackexchange.com ](http://robotics.stackexchange.com) to ask\na new question. This site will remain online in read-only mode during the\ntransition and into the foreseeable future. Selected questions and answers\nhave been migrated, and redirects have been put in place to direct users to\nthe corresponding questions on Robotics Stack Exchange. Additional details are\n[ available here ](https://discourse.ros.org/t/ros-and-gazebo-answers-\nmigration-to-robotics-stack-exchange-process/31494) .\n\n[ Hi there! Please sign in ](/account/signin/?next=/question/374115/python-\napi-rosbag-write-custom-message/) [ help ](/help/ \"help\")\n\n[ ![ROS Answers logo](/m/ros/media/images/logoros.png?v=28) ](/questions/)\n\n[ tags ](/tags/) [ users ](/users/) [ badges ](/badges/)\n\nThe site is read-only. Please transition to use Robotics Stack Exchange\n\n[ __ ](/questions/) |\n\n[ ALL ](/questions/scope:all/sort:activity-desc/page:1/) [ UNANSWERED\n](/questions/scope:unanswered/sort:answers-asc/page:1/)\n\n|\n\n|  [ Ask Your Question ](/questions/ask/)  \n---|---|---|---  \n  \n0\n\n#\n\nPython API rosbag write custom message\n\nedit\n\n  * [ melodic ](/questions/scope:all/sort:activity-desc/tags:melodic/page:1/)\n\n  * [ rosbag ](/questions/scope:all/sort:activity-desc/tags:rosbag/page:1/)\n\n  * [ std_msgs ](/questions/scope:all/sort:activity-desc/tags:std_msgs/page:1/)\n\n[ **asked 2021-03-16 15:14:04 -0500  ** ](/questions/374115/revisions/)\n\n[ ![Asdewar gravatar image](/m/default/media/images/nophoto.png?v=28)\n](/users/71807/asdewar/)\n\n[ Asdewar ](/users/71807/asdewar/)  \n11  \u25cf  2  \u25cf  2  \u25cf  3\n\nHi everyone,using the Python API I would like to write a message in a rosbag\nfile.\n\nThe message's format is described in this file [ https://github.com/uzh-\nrpg/rpg_dvs_ro... ](https://github.com/uzh-\nrpg/rpg_dvs_ros/blob/master/dvs_msgs/msg/Event.msg)\n\nSomeone knows how to write it in the bag file?\n\nWith the library std_msgs I can write standar types like str or unint, but i\ndon't know how to do it with a custom message.\n\n[ edit ](/questions/374115/edit/) [ retag ](/s/questions/374115/retag/) flag\noffensive  [ close ](/questions/374115/close/) merge  delete\n\n##  Comments\n\n1\n\nDo you have the custom message installed already?\n\n[ ![tryan gravatar\nimage](//www.gravatar.com/avatar/4cd1a4a3c51b6947acbcfb58c7f1f988?s=16&d=identicon&r=PG)\n](/users/33908/tryan/) [ tryan ](/users/33908/tryan/) (  2021-03-16 20:04:01\n-0500  )  edit\n\nProbably not, what do you mean? I have to install it like a python module? I\nonly have that .msg file but I did not know that it could be installed.\n\n[ ![Asdewar gravatar image](/m/default/media/images/nophoto.png?v=28)\n](/users/71807/asdewar/) [ Asdewar ](/users/71807/asdewar/) (  2021-03-17\n07:11:23 -0500  )  edit\n\nadd a comment\n\n##  1  Answer\n\nSort by \u00bb  [ oldest  ](/question/374115/python-api-rosbag-write-custom-\nmessage/?sort=oldest#sort-top) [ newest  ](/question/374115/python-api-rosbag-\nwrite-custom-message/?sort=latest#sort-top) [ most voted\n](/question/374115/python-api-rosbag-write-custom-message/?sort=votes#sort-\ntop)\n\n0\n\n[ **answered 2021-03-17 08:54:13 -0500  ** ](/answers/374173/revisions/)\n\n[ ![tryan gravatar\nimage](//www.gravatar.com/avatar/4cd1a4a3c51b6947acbcfb58c7f1f988?s=32&d=identicon&r=PG)\n](/users/33908/tryan/)\n\n[ tryan ](/users/33908/tryan/)  \n1421  \u25cf  96  \u25cf  26\n\n[ **updated 2021-03-17 08:55:59 -0500  ** ](/answers/374173/revisions/)\n\nTo use your own custom message, you have to tell ROS about it when you build\nyour package. More specifically, ROS needs to generate the message headers and\nput them in the proper location (depends on build tool). The [ Creating a Msg\nand Srv tutorial\n](http://wiki.ros.org/ROS/Tutorials/CreatingMsgAndSrv#Creating_a_msg) has the\nsteps for doing this, and it's explained in the [ msg wiki\n](http://wiki.ros.org/msg#Building_.msg_Files) .\n\nIf it's a custom message as part of a third-party package, the message\ngeneration should happen automatically when you build/install that package. To\ncheck if it's installed properly and ROS can find it, you can run ` rosmsg\nshow <package_name>/<msg_name> ` in a terminal. In this case, it would be:\n\n    \n    \n    rosmsg show dvs_msgs/Event\n    \n\nThe output should match the message definition:\n\n    \n    \n    uint16 x\n    uint16 y\n    time ts\n    bool polarity\n    \n\nOnce the headers are available, you can use the message just like any other.\nHere's the ` Event ` message added to the [ ` rosbag ` Python API example\n](http://wiki.ros.org/rosbag/Code%20API#Python_API) :\n\n    \n    \n    import rosbag\n    import rospy  # Need this to create a rospy.Time object for Event.ts\n    from std_msgs.msg import Int32, String\n    from dvs_msgs.msg import Event  # Imports the custom message from its package\n    \n    bag = rosbag.Bag('test.bag', 'w')\n    \n    try:\n        s = String()\n        s.data = 'foo'\n    \n        i = Int32()\n        i.data = 42\n    \n        e = Event()\n        e.x = 23\n        e.y = 17\n        e.ts = rospy.Time.now()\n        e.polarity = False\n    \n        bag.write('chatter', s)\n        bag.write('numbers', i)\n        bag.write('events', e)\n    finally:\n        bag.close()\n    \n\nI didn't actually test this code, so let me know if you run into problems.\n\n[ edit ](/s/answers/374173/edit/) flag offensive  delete  [ link\n](/question/374115/python-api-rosbag-write-custom-message/?answer=374173#post-\nid-374173 \"permanent link\") more\n\n  *   * \n\n##  Comments\n\nHi again, I understand what you mean but, I want to do it without installing\nROS in mi computer. There is another way to write a custom message without\nusing ROS? I want to make a program that can write some messages but without\nthe user having to worry about installing ROS But thanks a lot, I will\ncontinue searching but if I do not find a solution, I'll use yours\n\n[ ![Asdewar gravatar image](/m/default/media/images/nophoto.png?v=28)\n](/users/71807/asdewar/) [ Asdewar ](/users/71807/asdewar/) (  2021-03-25\n09:31:28 -0500  )  edit\n\nIf you don't want to use ROS, why not just use the lower-level library for\nyour device (libcaer, I think) instead of ROS messages and bag files, which\nhave inherent dependencies on ROS components?\n\n[ ![tryan gravatar\nimage](//www.gravatar.com/avatar/4cd1a4a3c51b6947acbcfb58c7f1f988?s=16&d=identicon&r=PG)\n](/users/33908/tryan/) [ tryan ](/users/33908/tryan/) (  2021-03-25 09:56:19\n-0500  )  edit\n\nIts because I want to make a bridge beetween a rosbag file and a txt file, and\nthe only way I know to write in the bag file is to use the rosbag API for\npython\n\n[ ![Asdewar gravatar image](/m/default/media/images/nophoto.png?v=28)\n](/users/71807/asdewar/) [ Asdewar ](/users/71807/asdewar/) (  2021-03-25\n10:48:23 -0500  )  edit\n\nYou may have valid reasons, but it's still unclear to me why a bag is involved\nif you don't expect to use ROS. To avoid ROS dependencies, you could\n(de)serialize the data yourself or using some other tool to work with a non-\nbag format. If you want to use a bag without ROS, you can still do so by\n(de)serializeng according to the [ bag format\n](http://wiki.ros.org/Bags/Format/2.0) , though.\n\n[ ![tryan gravatar\nimage](//www.gravatar.com/avatar/4cd1a4a3c51b6947acbcfb58c7f1f988?s=16&d=identicon&r=PG)\n](/users/33908/tryan/) [ tryan ](/users/33908/tryan/) (  2021-03-29 09:47:32\n-0500  )  edit\n\nadd a comment\n\n##  Question Tools\n\nFollow\n\n2 followers\n\n[ subscribe to rss feed ](/feeds/question/374115/ \"subscribe to the rss feed\")\n\n##  Stats\n\nAsked: ** 2021-03-16 15:14:04 -0500  **\n\nSeen: **2,105 times**\n\nLast updated: **Mar 17 '21**\n\n##  Related questions\n\n[ What are rosbag --split and --chunksize useful for? ](/question/363852/what-\nare-rosbag-split-and-chunksize-useful-for/)\n\n[ Dataset that has camera,radar and imu ](/question/394720/dataset-that-has-\ncameraradar-and-imu/)\n\n[ AttributeError's when running Python scripts\n](/question/363102/attributeerrors-when-running-python-scripts/)\n\n[ ROS Melodic OpenCV xfeatures2d ](/question/312669/ros-melodic-opencv-\nxfeatures2d/)\n\n[ Publish to topic from file ](/question/221828/publish-to-topic-from-file/)\n\n[ ROS TCP Connector C# Lost Publishers & Freezing ](/question/417733/ros-tcp-\nconnector-c-lost-publishers-freezing/)\n\n[ Source for downloading rosbag files containing pointclouds\n](/question/282981/source-for-downloading-rosbag-files-containing-\npointclouds/)\n\n[ Controlling a quadcopter in Gazebo ](/question/327096/controlling-a-\nquadcopter-in-gazebo/)\n\n[ URDF model using the a variable parameter ](/question/361766/urdf-model-\nusing-the-a-variable-parameter/)\n\n[ ros::Rate::sleep() equivalent in rosserial ](/question/344793/rosratesleep-\nequivalent-in-rosserial/)\n\n[ ![cc-by-sa](/m/default/media/images/cc-by-sa.png?v=28)\n](http://creativecommons.org/licenses/by-sa/3.0/legalcode) ROS Answers is\nlicensed under Creative Commons Attribution 3.0 Content on this site is\nlicensed under a [ Creative Commons Attribution Share Alike 3.0\n](http://creativecommons.org/licenses/by-sa/3.0/legalcode) license.\n\n[ about ](/about/) |  [ faq ](/faq/) |  [ help ](/help/ \"help\") |  [ privacy\npolicy ](/privacy/) |  [ terms of service ](/terms/)\n\n[ Powered by Askbot version 0.10.2 ](http://askbot.com)\n\nPlease note: ROS Answers requires javascript to work properly, please enable\njavascript in your browser, [ here is how\n](https://www.google.com/support/bin/answer.py?answer=23852)\n\n[ ![ gravatar image]() ]() [ ]() (  2024-04-18 18:36:16 -0500  )  edit\n\n[ none ](/questions/scope:all/sort:activity-desc/tags:none/page:1/) \u00d7\n\n  *[\n              2021-03-16 15:14:04 -0500\n             ]: 2021-03-16 15:14:04 -0500\n  *[\n             2021-03-16 20:04:01 -0500\n            ]: 2021-03-16 20:04:01 -0500\n  *[\n             2021-03-17 07:11:23 -0500\n            ]: 2021-03-17 07:11:23 -0500\n  *[\n              2021-03-17 08:54:13 -0500\n             ]: 2021-03-17 08:54:13 -0500\n  *[\n              2021-03-17 08:55:59 -0500\n             ]: 2021-03-17 08:55:59 -0500\n  *[\n             2021-03-25 09:31:28 -0500\n            ]: 2021-03-25 09:31:28 -0500\n  *[\n             2021-03-25 09:56:19 -0500\n            ]: 2021-03-25 09:56:19 -0500\n  *[\n             2021-03-25 10:48:23 -0500\n            ]: 2021-03-25 10:48:23 -0500\n  *[\n             2021-03-29 09:47:32 -0500\n            ]: 2021-03-29 09:47:32 -0500\n  *[\n        2021-03-16 15:14:04 -0500\n       ]: 2021-03-16 15:14:04 -0500\n  *[\n        2024-04-18 18:36:16 -0500\n       ]: 2024-04-18 18:36:16 -0500\n\n"
  },
  {
    "id": "custom_bt/behaviortreesincforr.txt",
    "content": "[ Open in app\n](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F775ec0e97856&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&source=---two_column_layout_nav----------------------------------)\n\nSign up\n\n[ Sign in\n](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmarkus-x-\nbuchholz.medium.com%2Fbehavior-trees-in-c-for-robotic-applications-\nros2-775ec0e97856&source=post_page---two_column_layout_nav\n-----------------------global_nav-----------)\n\n[\n](https://medium.com/?source=---two_column_layout_nav----------------------------------)\n\n[ Write\n](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-\nstory&source=---two_column_layout_nav-----------------------\nnew_post_topnav-----------)\n\n[\n](https://medium.com/search?source=---two_column_layout_nav----------------------------------)\n\nSign up\n\n[ Sign in\n](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmarkus-x-\nbuchholz.medium.com%2Fbehavior-trees-in-c-for-robotic-applications-\nros2-775ec0e97856&source=post_page---two_column_layout_nav\n-----------------------global_nav-----------)\n\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\n\n#  Behavior Trees for Robotic Applications (ROS2) in C++\n\n[ ![Markus\nBuchholz](https://miro.medium.com/v2/resize:fill:88:88/1*12k3P8bjeeTvt1EoxSTDEg.jpeg)\n](/?source=post_page-----775ec0e97856--------------------------------)\n\n[ Markus Buchholz ](/?source=post_page-----\n775ec0e97856--------------------------------)\n\n\u00b7\n\n[ Follow\n](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc9076eed918c&operation=register&redirect=https%3A%2F%2Fmarkus-\nx-buchholz.medium.com%2Fbehavior-trees-in-c-for-robotic-applications-\nros2-775ec0e97856&user=Markus+Buchholz&userId=c9076eed918c&source=post_page-c9076eed918c\n----775ec0e97856---------------------post_header-----------)\n\n8 min read\n\n\u00b7\n\nJan 20, 2023\n\n[\n](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F775ec0e97856&operation=register&redirect=https%3A%2F%2Fmarkus-\nx-buchholz.medium.com%2Fbehavior-trees-in-c-for-robotic-applications-\nros2-775ec0e97856&user=Markus+Buchholz&userId=c9076eed918c&source=-----775ec0e97856\n---------------------clap_footer-----------)\n\n\\--\n\n[\n](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F775ec0e97856&operation=register&redirect=https%3A%2F%2Fmarkus-\nx-buchholz.medium.com%2Fbehavior-trees-in-c-for-robotic-applications-\nros2-775ec0e97856&source=-----775ec0e97856---------------------\nbookmark_footer-----------)\n\nListen\n\nShare\n\nThe following article provides you with general intuition over the Behaviour\nTrees which are often used in robotic applications or frameworks: [ ROS\n](https://www.ros.org/) , [ Moveit ](https://picknik.ai/moveit/) , and [ NAV2\n](https://navigation.ros.org/behavior_trees/index.html) . Understanding the\nprinciples of the Behavior Tress (BT) framework gives you an excellent\nopportunity to apply knowledge in the [ gaming domain\n](https://www.gamedeveloper.com/programming/behavior-trees-for-ai-how-they-\nwork) . The BT can be integrated with [ Unity\n](https://medium.com/geekculture/how-to-create-a-simple-behaviour-tree-in-\nunity-c-3964c84c060e) or [ Unreal ](https://docs.unrealengine.com/5.1/en-\nUS/behavior-trees-in-unreal-engine/) .\n\nSince BT is the C++ library that provides a framework to create BT (in C++),\nthe article focuses on an overview of BT. Your interest in this area can be\nexpanded by the [ online course ](https://app.theconstructsim.com/Course/131/)\n, and [ hands-on course ](https://www.theconstructsim.com/one-day-\ntraining/behavior-trees-for-ros2/) , which I highly recommend. If you are\ninterested more about learning ROS, robotics, AI, ML, software, and many more\nplease take a look at [ The ConstructSim ](https://www.theconstructsim.com/)\nwebsite and be inspired by [ what you can learn\n](https://www.theconstructsim.com/robotigniteacademy_learnros/ros-courses-\nlibrary/) . They have also a perfectly done Robotics [ Developer Master Class\n](https://www.theconstructsim.com/robotics-developer/) which approaches you to\nland in the dream company.\n\nIn addition, to the online course please download the [ free book\n](https://arxiv.org/abs/1709.00084) and be inspired by this [ YouTube channel\n](https://www.youtube.com/@petterogren7535) .\n\n[ Here ](https://www.youtube.com/watch?v=KO4S0Lsba6I) you will find also the\nbrilliant introduction to BT link to the online environment where you can run\nyour mobile robot.\n\n#  Behavior Trees. Software Architecture\n\n[ **The BT framework is the C++ library** ](https://www.behaviortree.dev/)\n**** that enables you to architect the BT in your robotics or gaming\napplication. BT provides abstract methods (built in C++) to secure logical\nrelationships within your application. For instance, if you develop a game,\nthe behavior tree can be related to the performance of the game or define how\nthe game characters behave in certain game situations, etc. In this regard, we\nstate that the BT framework offers the tools to enable logical/abstract\nrelationships between C++ classes, whose methods are called in accordance with\nthe logical tree (BT) structure of your program.\n\nThe BT can be associated with [ State Machine\n](https://en.wikipedia.org/wiki/Finite-state_machine) (SM) however there are\ncertain differences in which BT outperforms the SM.  \nThe main problem with SM is transitions between states which increase while\nthe number of states grows. States in SM are tightly connected and there is\noften a problem when there is a necessity for reuse. It is true that SM can be\nhandled with ease by a designer (SW engineer), but a person will undoubtedly\nfind it difficult to comprehend and forecast the system\u2019s overall behavior.\nMost of these issues are resolved by **Behavior Trees, which enhance the\nmodular design and can be reused. Behavior Trees are by nature hierarchical.**\n\nThe following figure provides you with a general overview of BT. As you can\nsee the BT framework can be run independently, without ROS (as I mention while\nyou design a game). Later I will give you an example of how to build a simple\nBT and run your first program. Please note the tutorials on the official site\nare outstanding and should be studied accordingly to exhaust all the remaining\nissues.\n\nGeneral overview of SW architecture (by author)\n\nWe can imagine your robot performing the task. In order to guarantee the task\nperformance by a robot (for example robot cleaner) the \u201cmain\u201d task is divided\ninto several subtasks, like path planning, perception, orientation in the\nspace, and power management, etc (in the ROS all these subtasks can be\ndistributed across the nodes). All these subtasks can be considered low-level\ntasks, which are not architected by BT.  \nBT can be considered as the logical flow of your application. One task or\naction can depend on one or several previous actions, and at the same time,\ndifferent conditions have to be true/false in order to affect the\nrobot/application action.\n\nWith regard to robotics specifical, the BT is the sort of abstraction that\nshifts from low-level task control (path planner, power management, etc) to\nhigher\u2014level behaviors.\n\nWhen we design a robot system, we still have to consider how the fundamental\ncomponents (low-level actions/tasks) work and look for optimization (eg. boost\nthe performance of the path algorithm by adding heuristics).\n\nHowever, in order to build the architecture of the whole robot application, we\nneed to move to a **higher level of programming abstraction** , meaning\nevaluating the task like path planner or power management as a simple\ncomponent.\n\n**We use the idea of a high level of abstraction therefore it seems to be\nreasonable to elaborate on the location of this abstraction. The following\nfigure gives you an overview of a stack of abstractions.**\n\nAbstraction stack. (by author)\n\nThe depicted stack can be considered as follows. The engineer/designer takes\nthe requirements for the robot application and architects the logical flow of\nthe application (create the behavior trees).  \nThe structure of BT (logical flow) mimics the behavior of the robot (figure in\nthe game). We can say, the designer logically connects the robot primitives to\nreflect the specification for the robot application.  \nThe BT is modeled as an XML format file. The C++ framework ( [\nBehaviourTree.CP ](https://www.behaviortree.dev/) P) allows the construction\nof BT in your application. The definition of the robot tasks (program function\nin C++) completes the following stack.\n\nWhile discussing the concept of BT, I used the logical flow formulation. In\nthe context of software design, we can evaluate the discussed concept as a\nlogical connection between certain software modules (nodes). The logical\nconnection can be described as the usage of a certain logic operator like AND,\nOR, or NOT wrapped into the BT framework.\n\nThe beauty of the BT framework is the fact that designers receive a full\nimplementation of all the mechanisms and other components to architect complex\nlogical structures. Moreover, the logical flow can be designed as a\nmultithreading application without unnecessary effort. All C++ mechanisms to\nsupport threading are incorporated into the framework.\n\n#  Logical Primitives\n\nSince the idea of the article is the only introduction to the BT I will focus\non the basic logical components, which I will use later in the practical C++\nexample. The ROS2 (Galactic) example you will find [ here\n](https://app.theconstructsim.com/LiveClass/8e39921b-f25e-4bdf-b8af-d71cc0f560c9/)\nor in the [ course ](https://app.theconstructsim.com/Course/131/) .\n\nIn simple principle (only for the purpose of this article), we can distinguish\ntwo logical nodes (BT mechanisms). The **fallback** realizes the logical OR\nand **sequence** node, which realizes the AND logic.\n\nBoth can be depicted as follows,\n\nThe fallback node (OR operator). (by author)\n\nThe sequence node (AND operator). (by author)\n\nThe architecture of the BT is specified in XML file which is read by the\napplication. BehaviourTree.CPP framework manages the logical flow ( **tick the\nBT node** ) according to XML specification (we say invoke a callback). Nodes\n(here tasks) based on the status send the return signal to the \u201croot\u201d \u2014 the\nmain node of the application. The signal can be **SUCCESS, FAILURE, or\nRUNNING** .\n\nThe following example combines the above mechanism and displays how the\nmentioned signals are distributed across the BT.\n\nBT in action. (by author)\n\nWe can describe the above BT as follows,\n\nDeriving this BT philosophy we can describe how following BT works by\nconsidering the following example.\n\n1\\. presented BT consists of 4 tasks, falling to fallback, and sequence nodes.\n\n2\\. the root that sends the tick to that fallback. We follow the left side.\nFallback sends a tick to task 1 which is a failure (of course this is only the\nsimulation ). Normally the decision SUCCESS or FAILURE is taken by the running\nprogram. In our case callback returns Failure.  \n**Please note, now we run the Fallback node (OR) which needs at least one\nSUCCESS to return SUCCESS therefore all the nodes can be checked. For the\nsequence node (AND) the first FAILURE terminates \u201cnode investigation\u201d.**\n\n3\\. Similar to task 1, the task 2 callback returns Failure. Since we still ran\nthe fallback mechanism (OR) we continue.\n\n4\\. Now the tick is sent to the Sequence node (AND). Sequence sends tick to\ntask 3 and receives SUCCESS but the Sequence is logical AND operation so so we\ncontinue to check if all are SUCCESS.  \nTask 4 is SUCCESS therefore the root receives also SUCCESS.\n\nThe XML describing the logic depicted above BT can be formulated:\n\n    \n    \n     <root main_tree_to_execute = \"MainTree\" >  \n      \n         <BehaviorTree ID=\"MainTree\">  \n            <Fallback name=\"root\">  \n                <Task1 name=\"task_1\"/>  \n                <Task2 name=\"task_2\"/>  \n                <Sequence>  \n                    <Task3 name=\"task_3\"/>  \n                    <Task4  name=\"task_4\"/>  \n                </Sequence>  \n            </Fallback>  \n         </BehaviorTree>  \n      \n     </root>  \n     )\";\n\nBelow you will find the code which you can run in the [ ROSject\n](https://app.theconstructsim.com/LiveClass/8e39921b-f25e-4bdf-b8af-d71cc0f560c9/)\n. (ROS2 Galactic)\n\n    \n    \n    #include \"behaviortree_cpp_v3/bt_factory.h\"  \n      \n    using namespace BT;  \n      \n    class Task1 : public BT::SyncActionNode  \n    {  \n      public:  \n        Task1(const std::string& name) : BT::SyncActionNode(name, {})  \n        {  \n        }  \n      \n        // You must override the virtual function tick()  \n        NodeStatus tick() override  \n        {  \n            std::cout << \"Task1: \" << this->name() << std::endl;  \n            return BT::NodeStatus::FAILURE;  \n        }  \n    };  \n      \n    class Task2 : public BT::SyncActionNode  \n    {  \n      public:  \n        Task2(const std::string& name) : BT::SyncActionNode(name, {})  \n        {  \n        }  \n      \n        // You must override the virtual function tick()  \n        NodeStatus tick() override  \n        {  \n            std::cout << \"Task2: \" << this->name() << std::endl;  \n            return BT::NodeStatus::FAILURE;  \n        }  \n    };  \n      \n    class Task3 : public BT::SyncActionNode  \n    {  \n      public:  \n        Task3(const std::string& name) : BT::SyncActionNode(name, {})  \n        {  \n        }  \n      \n        // You must override the virtual function tick()  \n        NodeStatus tick() override  \n        {  \n            std::cout << \"Task3: \" << this->name() << std::endl;  \n            return BT::NodeStatus::SUCCESS;  \n        }  \n    };  \n      \n    class Task4 : public BT::SyncActionNode  \n    {  \n      public:  \n        Task4(const std::string& name) : BT::SyncActionNode(name, {})  \n        {  \n        }  \n      \n        // You must override the virtual function tick()  \n        NodeStatus tick() override  \n        {  \n            std::cout << \"Task4: \" << this->name() << std::endl;  \n            return BT::NodeStatus::SUCCESS;  \n        }  \n    };  \n      \n    static const char* xml_text_medium = R\"(  \n      \n     <root main_tree_to_execute = \"MainTree\" >  \n      \n         <BehaviorTree ID=\"MainTree\">  \n            <Fallback name=\"root\">  \n                <Task1 name=\"task_1\"/>  \n                <Task2 name=\"task_2\"/>  \n                <Sequence>  \n                    <Task3 name=\"task_3\"/>  \n                    <Task4  name=\"task_4\"/>  \n                </Sequence>  \n            </Fallback>  \n         </BehaviorTree>  \n      \n     </root>  \n     )\";  \n      \n    int main()  \n    {  \n        BehaviorTreeFactory factory;  \n      \n        factory.registerNodeType<Task1>(\"Task1\");  \n        factory.registerNodeType<Task2>(\"Task2\");  \n        factory.registerNodeType<Task3>(\"Task3\");  \n        factory.registerNodeType<Task4>(\"Task4\");  \n      \n        std::cout << \"\\n------------ BUILDING A NEW TREE ------------\" << std::endl;  \n      \n        auto tree = factory.createTreeFromText(xml_text_medium);  \n      \n        tree.tickRoot();  \n      \n        std::cout << std::endl;  \n      \n        // }  \n      \n        return 0;  \n    }\n\nIn the ROSject (on a Linux terminal) perform the following actions,\n\n    \n    \n    cd /ros2_ws/src/bt_course_files/BehaviorTree.CPP/course_bt  \n      \n    touch bt_medium.cpp  \n      \n    // go to VSC  to the same folder where you created bt_medium.cpp  \n      \n    // paste above code  \n      \n    // in the same folder modify the CMakeList.txt by adding:  \n    // CompileExample(\"bt_medium\")  \n      \n    cd ros2_ws/src/bt_course_files/BehaviorTree.CPP/build  \n    cmake ..  \n    make  \n      \n    // after building is finish  \n       \n    cd course_bt  \n    ./bt_medium\n\nExpected output\n\nThank you for reading.\n\n[ Robotics  ](https://medium.com/tag/robotics?source=post_page-----\n775ec0e97856---------------robotics-----------------)\n\n[ Programming  ](https://medium.com/tag/programming?source=post_page-----\n775ec0e97856---------------programming-----------------)\n\n[ Artificial Intelligence  ](https://medium.com/tag/artificial-\nintelligence?source=post_page-----775ec0e97856---------------\nartificial_intelligence-----------------)\n\n[ Cpp  ](https://medium.com/tag/cpp?source=post_page-----775ec0e97856\n---------------cpp-----------------)\n\n[\n](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F775ec0e97856&operation=register&redirect=https%3A%2F%2Fmarkus-\nx-buchholz.medium.com%2Fbehavior-trees-in-c-for-robotic-applications-\nros2-775ec0e97856&user=Markus+Buchholz&userId=c9076eed918c&source=-----775ec0e97856\n---------------------clap_footer-----------)\n\n\\--\n\n[\n](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F775ec0e97856&operation=register&redirect=https%3A%2F%2Fmarkus-\nx-buchholz.medium.com%2Fbehavior-trees-in-c-for-robotic-applications-\nros2-775ec0e97856&user=Markus+Buchholz&userId=c9076eed918c&source=-----775ec0e97856\n---------------------clap_footer-----------)\n\n\\--\n\n[\n](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F775ec0e97856&operation=register&redirect=https%3A%2F%2Fmarkus-\nx-buchholz.medium.com%2Fbehavior-trees-in-c-for-robotic-applications-\nros2-775ec0e97856&source=--------------------------bookmark_footer-----------)\n\n[ ![Markus\nBuchholz](https://miro.medium.com/v2/resize:fill:144:144/1*12k3P8bjeeTvt1EoxSTDEg.jpeg)\n](/?source=post_page-----775ec0e97856--------------------------------)\n\nFollow\n\n[\n](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F33b47b657e93&operation=register&redirect=https%3A%2F%2Fmarkus-\nx-buchholz.medium.com%2Fbehavior-trees-in-c-for-robotic-applications-\nros2-775ec0e97856&newsletterV3=c9076eed918c&newsletterV3Id=33b47b657e93&user=Markus+Buchholz&userId=c9076eed918c&source=-----775ec0e97856\n---------------------subscribe_user-----------)\n\n[\n\n##  Written by  Markus Buchholz\n\n](/?source=post_page-----775ec0e97856--------------------------------)\n\n[ 767 Followers ](/followers?source=post_page-----\n775ec0e97856--------------------------------)\n\nResearcher in underwater robotics\n\nFollow\n\n[\n](https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F33b47b657e93&operation=register&redirect=https%3A%2F%2Fmarkus-\nx-buchholz.medium.com%2Fbehavior-trees-in-c-for-robotic-applications-\nros2-775ec0e97856&newsletterV3=c9076eed918c&newsletterV3Id=33b47b657e93&user=Markus+Buchholz&userId=c9076eed918c&source=-----775ec0e97856\n---------------------subscribe_user-----------)\n\n[\n\nHelp\n\n](https://help.medium.com/hc/en-us?source=post_page-----\n775ec0e97856--------------------------------)\n\n[\n\nStatus\n\n](https://medium.statuspage.io/?source=post_page-----\n775ec0e97856--------------------------------)\n\n[\n\nAbout\n\n](https://medium.com/about?autoplay=1&source=post_page-----\n775ec0e97856--------------------------------)\n\n[\n\nCareers\n\n](https://medium.com/jobs-at-medium/work-at-\nmedium-959d1a85284e?source=post_page-----\n775ec0e97856--------------------------------)\n\n[\n\nBlog\n\n](https://blog.medium.com/?source=post_page-----\n775ec0e97856--------------------------------)\n\n[\n\nPrivacy\n\n](https://policy.medium.com/medium-privacy-\npolicy-f03bf92035c9?source=post_page-----\n775ec0e97856--------------------------------)\n\n[\n\nTerms\n\n](https://policy.medium.com/medium-terms-of-\nservice-9db0094a1e0f?source=post_page-----\n775ec0e97856--------------------------------)\n\n[\n\nText to speech\n\n](https://speechify.com/medium?source=post_page-----\n775ec0e97856--------------------------------)\n\n[\n\nTeams\n\n](https://medium.com/business?source=post_page-----\n775ec0e97856--------------------------------)\n\n"
  },
  {
    "id": "robot_euler_angle/97836421953961.txt",
    "content": "J.A. Cetto et al. (Eds.): Informatics in Control, Automation and Robotics, LNEE 89, pp. 3\u201320.\nspringerlink.com \u00a9 Springer-Verlag Berlin Heidelberg 2011\nDynamic Modeling of Robots Using\nNewton-Euler Formulation\nWisama Khalil\nEcole Centrale de Nantes, IRCCyN UMR CNRS 6597, 1 Rue de la No\u00eb, 44321, Nantes, France\nWisama.khalil@irccyn.ec-nantes.fr\nAbstract. This paper presents the use of recursive Newton-Euler formulation to\nmodel different types of robots. The main advantages of this technique are the\nfacility of implementation and obtaining models with reduced number of\noperations. The following structures are treated: rigid tree structure robots,\nclosed loop robots, parallel robots, robots with lumped elasticity, robots with\nmoving base and wheeled robots.\nKeywords: Dynamic modeling, Newton-Euler, Recursive calculation, Tree\nstructure, Parallel robots, Flexible joints, Mobile robots.\n1 Introduction\nThe dynamic modeling of robots is an important topic for the design, simulation, and\ncontrol of robots. Different techniques have been proposed and used by the robotics\ncommunity. In this paper we show that the use of Newton-Euler recursive technique\nis easy to develop and implement. The proposed algorithm can be extended to many\ntypes of structures. In section 2 we recall the method used to describe the kinematics\nof the structure, and then in section 3 we present the inverse and direct dynamic\nmodels of tree structure rigid robots. The following sections present the generalization\nto the other systems.\n2 Description of the Robots\nThe structures of robots will be described using Khalil and Kleinfinger notations [1].\nThis method can take into account tree structures and closed loop robots. Its use\nfacilitates the calculation of minimum number of inertial parameters [2]\u2026[4], which\nreduce the number of operations of the dynamic models and are needed in dynamic\nidentification and adaptive control laws.\n2.1 Geometric Description of Tree Structure Robots\nA tree structure robot is composed of n+1 links and n joints. Link 0 is the base and\nlink n is a terminal link. The joints are revolute or pris-matic, rigid or elastic. The\nlinks are numbered consecutively from the base, to the terminal links. Joint j connects \n4 W. Khalil\nlink j to link a(j), where a(j) denotes the link antecedent to link j. A frame Ri is\nattached to each link i such that (Fig. 1):\n\u2022 zi is along the axis of joint i;\n\u2022 xi is along the common normal between zi and one of the succeeding joint axes.\n\u03b3j\n\u03b8j bj r\nj\ndj\nuj\nxi\nzk\nzi\nxj\nzj\n\u03b1j\n\u03b1k Link j\nLink k Link i\nFig. 1. Geometric parameters for frame j\nThe transformation matrix i\nj h , defining frame Rj with respect to (wrt) frame Ri is\nobtained as a function of six geometric parameters ( j j j j jj \u03b3 \u03b1\u03b8 , b , ,d , ,r )such that:\n = i\nj j j j jj j h Rot( z, ) Tran( z,b ) Rot( x, ) Tran( x,d ) Rot( z, ) Tran( z,r ) \u03b3\u03b1 \u03b8\nAfter developing, this matrix can be written as follows:\n\u23a1 \u23a4\n= \u23a2 \u23a5\n\u23a2 \u23a5 \u23a3 \u23a6\ni i\ni j j\nj\n1x3\nR P\nh\n0 0\n=\nC C -S C S -C S -S C C S S dC rS S\nS C C C S -S S C C C -C S dS - rC S\nS S S C C rC bj\n0 0 01\n\u23a1 \u23a4 \u03b3 \u03b8 \u03b3 \u03b1 \u03b8 \u03b3 \u03b8 \u03b3 \u03b1 \u03b8 \u03b3 \u03b1 \u03b3 + \u03b3 \u03b1\n\u23a2 \u23a5 \u03b3 \u03b8 + \u03b3 \u03b1 \u03b8 \u03b3 \u03b8 + \u03b3 \u03b1 \u03b8 \u03b3 \u03b1 \u03b3 \u03b3 \u03b1 \u23a2 \u23a5\n\u03b1 \u03b8 \u03b1 \u03b8 \u03b1 \u03b1+\n\u23a3 \u23a6\n(1)\nWhere i\nRj defines the (3\u00d73) rotation matrix and i\nPj defines the (3\u00d71) vector defining\nthe position of the origin of frame j with respect to frame i.\nIf xi is along the common normal between zi and zj, both \u03b3j and bj will be zero.\nThe type of the joint is identified by \u03c3 j where \u03c3 j = 0 if j is revolute, \u03c3 j = 1 if j\nis prismatic, and \u03c3 \u03c3 j j = \u22121 . The joint variable, denoted as j q , is \u03b8 j if j is revolute\nand j r if j is prismatic.\nA serial structure is a special case of a tree structure where\n , = == j j a( j ) j - 1 0, b 0 \u03b3 for all j = 1,.., n.\n2.2 Description of Closed Loop Structure\nThe system is composed of L joints and n + 1 links, where link 0 is the fixed base and\nL > n. The number of independent closed loops is equal to B = L \u2013 n. "
  },
  {
    "id": "rosparam/XMLEvaluationorder.txt",
    "content": "[ ![ros.org](/custom/images/ros_org.png) ](/) |  [ About\n](http://www.ros.org/about-ros) | [ Support ](/Support) | [ Discussion Forum\n](http://discourse.ros.org/) | [ Index ](http://index.ros.org/) | [ Service\nStatus ](http://status.ros.org/) | [ ros @ Robotics Stack Exchange\n](https://robotics.stackexchange.com/questions/tagged/ros)  \n---|---  \n![](/custom/images/menu_left.png) [\n![Documentation](/custom/images/menu_documentation.png) ](/)\n![](/custom/images/menu_spacer.png) [ ![Browse\nSoftware](/custom/images/menu_browse_software.png)\n](https://index.ros.org/packages) ![](/custom/images/menu_spacer.png) [\n![News](/custom/images/menu_news.png) ](https://discourse.ros.org/c/general)\n![](/custom/images/menu_spacer.png) [\n![Download](/custom/images/menu_download.png) ](/ROS/Installation)\n![](/custom/images/menu_right.png)  \n  \n  * [ roslaunch ](/roslaunch)\n  * [ XML ](/roslaunch/XML)\n\n####  ROS 2 Documentation\n\nThe ROS Wiki is for ROS 1. Are you using ROS 2 ( [ Humble\n](http://docs.ros.org/en/humble/) , [ Iron ](http://docs.ros.org/en/iron/) ,\nor [ Rolling ](http://docs.ros.org/en/rolling/) )?  \n[ Check out the ROS 2 Project Documentation ](http://docs.ros.org)  \nPackage specific documentation can be found on [ index.ros.org\n](https://index.ros.org)\n\n#  Wiki\n\n  * [ Distributions ](/Distributions)\n  * [ ROS/Installation ](/ROS/Installation)\n  * [ ROS/Tutorials ](/ROS/Tutorials)\n  * [ RecentChanges ](/RecentChanges)\n  * [ roslaunch/XML ](/roslaunch/XML)\n\n#  Page\n\n  * Immutable Page \n  * Comments \n  * [ Info ](/action/info/roslaunch/XML?action=info)\n  * [ Attachments ](/action/AttachFile/roslaunch/XML?action=AttachFile)\n  * More Actions:  Raw Text  Print View  Render as Docbook  Delete Cache  \\------------------------  Check Spelling  Like Pages  Local Site Map  \\------------------------  Rename Page  Copy Page  Delete Page  \\------------------------  My Pages  Subscribe User  \\------------------------  Remove Spam  Revert to this revision  Package Pages  Sync Pages  \\------------------------  CreatePdfDocument  Load  RawFile  Save  SlideShow \n\n#  User\n\n  * [ Login ](/action/login/roslaunch/XML?action=login)\n\nContents\n\n  1. Evaluation order \n  2. substitution args \n  3. if and unless attributes \n    1. Example \n  4. Tag Reference \n  5. Example .launch XML Config Files \n    1. Minimal Example \n    2. A More Complicated Example \n    3. Setting parameters \n\nThis page describes the XML format used for [ roslaunch ](/roslaunch) `\n.launch ` files. For background on [ roslaunch ](/roslaunch) , its\nfunctionality, and related tools, please consult the [ roslaunch ](/roslaunch)\npage first.\n\n##  Evaluation order\n\n` roslaunch ` evaluates the XML file in a single pass. Includes are processed\nin depth-first traversal order. Tags are evaluated serially and the **last\nsetting wins** . Thus, if there are multiple settings of a parameter, the last\nvalue specified for the parameter will be used.\n\nRelying on the override behavior can be brittle. There is no guarantee that an\noverride is specified correctly (e.g. if a parameter name is changed in an\nincluded file). Instead, it is recommended that override behavior be done\nusing ` $(arg) ` / ` <arg> ` settings.\n\n##  substitution args\n\nRoslaunch tag attributes can make use of _substitution args_ , which roslaunch\nwill resolve prior to launching nodes. The currently supported substitution\nargs are:\n\n  * ` $(env ENVIRONMENT_VARIABLE) `\n    * Substitute the value of a variable from the current environment. The launch will fail if environment variable is not set. This value cannot be overridden by ` <env> ` tags. \n\n` $(optenv ENVIRONMENT_VARIABLE) ` ` $(optenv ENVIRONMENT_VARIABLE\ndefault_value) `\n\n    * Substitute the value of an environment variable if it is set. If ` default_value ` is provided, it will be used if the environment variable is not set. If ` default_value ` is not provided, an empty string will be used. ` default_value ` can be multiple words separated by spaces. \n\n  * Examples: \n    *           <param name=\"foo\" value=\"$(optenv NUM_CPUS 1)\" />\n          <param name=\"foo\" value=\"$(optenv CONFIG_PATH /home/marvin/ros_workspace)\" />\n          <param name=\"foo\" value=\"$(optenv VARIABLE ros rocks)\" />\n\n` $(find pkg) `\n\n    * e.g. ` $(find rospy)/manifest.xml ` . Specifies a _package-relative path_ . The filesystem path to the package directory will be substituted inline. Use of package-relative paths is highly encouraged as hard-coded paths inhibit the portability of the launch configuration. Forward and backwards slashes will be resolved to the local filesystem convention. \n\n` $(anon name) `\n\n    * e.g. ` $(anon rviz-1) ` . Generates an anonymous id based on ` name ` . ` name ` itself is a unique identifier: multiple uses of ` $(anon foo) ` will create the same \"anonymized\" [ name ](/Names) . This is used for <node> ` name ` attributes in order to create [ nodes ](/Nodes) with anonymous [ names ](/Names) , as ROS requires nodes to have unique names. For example: \n        \n                  <node name=\"$(anon foo)\" pkg=\"rospy_tutorials\" type=\"talker.py\" />\n          <node name=\"$(anon foo)\" pkg=\"rospy_tutorials\" type=\"talker.py\" />\n\nWill generate an error that there are two <node>s with the same name.\n\n` $(arg foo) `\n\n    * ` $(arg foo) ` evaluates to the value specified by an [ <arg> ](/roslaunch/XML/arg) tag. There must be a corresponding [ <arg> ](/roslaunch/XML/arg) tag _in the same launch file_ that declares the arg. \n\n    * For example: \n        \n                  <param name=\"foo\" value=\"$(arg my_foo)\" />\n\n    * Will assign the _my_foo_ argument to the _foo_ parameter. \n\n    * Another example: \n        \n                <node name=\"add_two_ints_server\" pkg=\"beginner_tutorials\" type=\"add_two_ints_server\" />\n        <node name=\"add_two_ints_client\" pkg=\"beginner_tutorials\" type=\"add_two_ints_client\" args=\"$(arg a) $(arg b)\" />\n\nWill launch both the server and client from the [ <add_two_ints>\n](/ROS/Tutorials/WritingServiceClient%28c%2B%2B%29) example, passing as\nparameters the value _a_ and _b_ . The resulting launch project can be called\nas follows:\n\n        \n                roslaunch beginner_tutorials launch_file.launch a:=1 b:=5\n\n` $(eval <expression>) ` New in Kinetic\n\n    * ` $(eval <expression>) ` allows to evaluate arbitrary complex python expressions. \n\n    * For example: \n        \n                <param name=\"circumference\" value=\"$(eval 2.* 3.1415 * arg('radius'))\"/>\n\n    * Will compute the circumference from the _radius_ argument and assign the result to an appropriate parameter. \n\n    * **Note** : As a limitation, ` $(eval) ` expressions need to span the whole attribute string. A mixture of other substitution args with ` eval ` within a single string is **not** possible: \n        \n                <param name=\"foo\" value=\"$(arg foo)$(eval 6*7)bar\"/>\n\nTo remedy this limitation, all substitution commands are available as\nfunctions _within_ ` eval ` as well:\n\n        \n                \"$(eval arg('foo') + env('PATH') + 'bar' + find('pkg')\"\n\n    * For your convenience, arguments are also implicitly resolved, i.e. the following two expressions are identical: \n        \n                \"$(eval arg('foo'))\"\n        \"$(eval foo)\"\n\n` $(dirname) ` New in Lunar\n\n    * ` $(dirname) ` returns the absolute path to the directory of the launch file in which it appears. This can be used in conjunction with ` eval ` and ` if/unless ` to modify behaviour based on the installation path, or simply as a convenience for referencing ` launch ` or ` yaml ` files relative to the current file rather than relative to a package root (as with ` $(find PKG) ` ). \n\n    * For example: \n        \n                <include file=\"$(dirname)/other.launch\" />\n\n    * Will expect to find ` other.launch ` in the same directory as the launch file which it appears in. \n\n**Substitution args are currently resolved on the local machine.** In other\nwords, environment variables and ROS package paths will be set to their values\nin your current environment, **even for remotely launched processes** .\n\n##  if and unless attributes\n\nAll tags support ` if ` and ` unless ` attributes, which include or exclude a\ntag based on the evaluation of a value. \"1\" and \"true\" are considered true\nvalues. \"0\" and \"false\" are considered false values. Other values will error.\n\n  * ` if=value ` (optional) \n    * If ` value ` evaluates to true, include tag and its contents. \n\n` unless=value ` (optional)\n\n    * Unless ` value ` evaluates to true (which means if ` value ` evaluates to false), include tag and its contents. \n\n###  Example\n\n  *     <group if=\"$(arg foo)\">\n      <!-- stuff that will only be evaluated if foo is true -->\n    </group>\n    \n    <param name=\"foo\" value=\"bar\" unless=\"$(arg foo)\" />  <!-- This param won't be set when \"unless\" condition is met -->\n\n##  Tag Reference\n\n  * [ <launch> ](/roslaunch/XML/launch)\n\n  * [ <node> ](/roslaunch/XML/node)\n\n  * [ <machine> ](/roslaunch/XML/machine)\n\n  * [ <include> ](/roslaunch/XML/include)\n\n  * [ <remap> ](/roslaunch/XML/remap)\n\n  * [ <env> ](/roslaunch/XML/env)\n\n  * [ <param> ](/roslaunch/XML/param)\n\n  * [ <rosparam> ](/roslaunch/XML/rosparam)\n\n  * [ <group> ](/roslaunch/XML/group)\n\n  * [ <test> ](/roslaunch/XML/test)\n\n  * [ <arg> ](/roslaunch/XML/arg)\n\n##  Example .launch XML Config Files\n\nNOTE: by convention, the roslaunch XML files are named with the extension `\n.launch ` , e.g. ` example.launch ` .\n\n###  Minimal Example\n\nThe following example shows a minimal launch configuration script. It launches\na single 'talker' node, which is part of the 'rospy_tutorials' package. This\nnode will launch on the local machine using the currently configured ROS\nenvironment (i.e. ROS_ROOT, etc...).\n\n    \n    \n    <launch>\n      <node name=\"talker\" pkg=\"rospy_tutorials\" type=\"talker\" />\n    </launch>\n\n###  A More Complicated Example\n\n    \n    \n    <launch>\n      <!-- local machine already has a definition by default.\n           This tag overrides the default definition with\n           specific ROS_ROOT and ROS_PACKAGE_PATH values -->\n      <machine name=\"local_alt\" address=\"localhost\" default=\"true\" ros-root=\"/u/user/ros/ros/\" ros-package-path=\"/u/user/ros/ros-pkg\" />\n      <!-- a basic listener node -->\n      <node name=\"listener-1\" pkg=\"rospy_tutorials\" type=\"listener\" />\n      <!-- pass args to the listener node -->\n      <node name=\"listener-2\" pkg=\"rospy_tutorials\" type=\"listener\" args=\"-foo arg2\" />\n      <!-- a respawn-able listener node -->\n      <node name=\"listener-3\" pkg=\"rospy_tutorials\" type=\"listener\" respawn=\"true\" />\n      <!-- start listener node in the 'wg1' namespace -->\n      <node ns=\"wg1\" name=\"listener-wg1\" pkg=\"rospy_tutorials\" type=\"listener\" respawn=\"true\" />\n      <!-- start a group of nodes in the 'wg2' namespace -->\n      <group ns=\"wg2\">\n        <!-- remap applies to all future statements in this scope. -->\n        <remap from=\"chatter\" to=\"hello\"/>\n        <node pkg=\"rospy_tutorials\" type=\"listener\" name=\"listener\" args=\"--test\" respawn=\"true\" />\n        <node pkg=\"rospy_tutorials\" type=\"talker\" name=\"talker\">\n          <!-- set a private parameter for the node -->\n          <param name=\"talker_1_param\" value=\"a value\" />\n          <!-- nodes can have their own remap args -->\n          <remap from=\"chatter\" to=\"hello-1\"/>\n          <!-- you can set environment variables for a node -->\n          <env name=\"ENV_EXAMPLE\" value=\"some value\" />\n        </node>\n      </group>\n    </launch>\n\n###  Setting parameters\n\nYou can also set parameters on the [ Parameter Server ](/Parameter%20Server) .\nThese parameters will be stored on the Parameter Server before any nodes are\nlaunched.\n\nYou can omit the ` type ` attribute if value is unambiguous. Supported types\nare ` str ` , ` int ` , ` double ` , ` bool ` . You can also specify the\ncontents of a file instead using the ` textfile ` or ` binfile ` attributes.\n\nExample:\n\n    \n    \n    <launch>\n      <param name=\"somestring1\" value=\"bar\" />\n      <!-- force to string instead of integer -->\n      <param name=\"somestring2\" value=\"10\" type=\"str\" />\n    \n      <param name=\"someinteger1\" value=\"1\" type=\"int\" />\n      <param name=\"someinteger2\" value=\"2\" />\n    \n      <param name=\"somefloat1\" value=\"3.14159\" type=\"double\" />\n      <param name=\"somefloat2\" value=\"3.0\" />\n    \n      <!-- you can set parameters in child namespaces -->\n      <param name=\"wg/childparam\" value=\"a child namespace parameter\" />\n    \n      <!-- upload the contents of a file to the server -->\n      <param name=\"configfile\" textfile=\"$(find roslaunch)/example.xml\" />\n      <!-- upload the contents of a file as base64 binary to the server -->\n      <param name=\"binaryfile\" binfile=\"$(find roslaunch)/example.xml\" />\n    \n    </launch>\n\nWiki: roslaunch/XML (last edited 2017-07-21 01:19:06 by  [ MikePurvis\n](/MikePurvis \"MikePurvis @ 23-233-6-110.cpe.pppoe.ca\\[23.233.6.110\\]\") )\n\nExcept where otherwise noted, the ROS wiki is licensed under the  \n[ Creative Commons Attribution 3.0\n](http://creativecommons.org/licenses/by/3.0/)\n\n* * *\n\n[ ![](/custom/images/brought_by_horiz.png) ](https://www.openrobotics.org/)\n\n"
  },
  {
    "id": "joint_controller_velocity/hk4vWCUAs5E.txt",
    "content": "[\n![](https://fonts.gstatic.com/s/i/productlogos/groups/v9/web-48dp/logo_groups_color_1x_web_48dp.png)\nGroups  ](./my-groups \"Groups\")\n\nConversations\n\nAll groups and messages\n\nSend feedback to Google\n\nHelp\n\nTraining\n\n[ ](https://www.google.com.hk/intl/en/about/products?tab=gh)\n\n[ Sign in\n](https://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=https://groups.google.com&ec=GAZA0AM)\n\n[ Groups  ](./my-groups \"Groups\")\n\n##  ROS/Orocos Robot Control Special Interest Group\n\n[ Conversations  ](./g/ros-sig-robot-control)\n\n[ About  ](./g/ros-sig-robot-control/about)\n\n[ Privacy ](https://policies.google.com/privacy?hl=en_US) \u2022  [ Terms\n](https://policies.google.com/terms?hl=en_US)\n\n\ue5c4\n\n\ue899\n\n\ue408\n\n\ue409\n\n#  Configuring the controller.yaml file to use a velocity controller\n\n4,776 views\n\nSkip to first unread message\n\n\ue946\n\n![mfr...@vt.edu's profile photo](//lh3.googleusercontent.com/a-/ALV-\nUjXLZw18gFzZHa2C4A0mrLpZ13blWBOpMeCRZ4tYXUaxAYg45w=s40-c)\n\n###  mfr...@vt.edu\n\nunread,\n\nJul 3, 2014, 4:18:02 AM  7/3/14\n\n\ue83a\n\n\ue15f\n\n\ue5d4\n\nReply to author\n\nSign in to reply to author\n\nForward\n\nSign in to forward\n\nDelete\n\nYou do not have permission to delete messages in this group\n\nCopy link\n\nReport message\n\nSign in to report message\n\nShow original message\n\nEither email addresses are anonymous for this group or you need the view\nmember email addresses permission to view the original message\n\nto ros-sig-ro...@googlegroups.com\n\nHey all,  \n  \nSo I am trying to use the effort_controller/JointVelocityController as a\ncontroller to interface with movegroup action service. In my urdf file I made\nsure to set the hardware interface to VelocityJointInterface, and when\ncreating my RobotHW class I made sure to create a private variable\n_hardware_interface::EffortJointInterface jnt_vel_interface;_ in order to\nregister and connect the interface. Here is my controller.yaml file  \n  \natlasarm:  \n  \n# Trajectory Controllers ---------------------------------------  \narm_controller:  \ntype: effort_controllers/JointVelocityController  \njoints:  \n\\- base_to_azimuth  \n\\- azimuth_to_upperArm  \n\\- upperArm_to_lowerArm  \n\\- lowerArm_to_forward_link  \n\\- forward_link_to_wristlink_1  \n\\- wristlink_1_to_wristlink_2  \ngains:  \nbase_to_azimuth: {p: 100.0, i: 0.01, d: 10.0}  \nazimuth_to_upperArm: {p: 100.0, i: 0.01, d: 10.0}  \nupperArm_to_lowerArm: {p: 100.0, i: 0.01, d: 10.0}  \nlowerArm_to_forward_link: {p: 100.0, i: 0.01, d: 10.0}  \nforward_link_to_wristlink_1: {p: 100.0, i: 0.01, d: 10.0}  \nwristlink_1_to_wristlink_2: {p: 100.0, i: 0.01, d: 10.0}  \n  \n  \nWhen I try to run a program using ros_control in order to create/start this\nvelocity controller I get the following error:  \n  \n[ERROR] [1404329741.678130586]: No joint given (namespace:\n/atlasarm/arm_controller)  \n[ERROR] [1404329741.678209566]: Failed to initialize the controller  \n[ERROR] [1404329741.678232210]: Initializing controller\n'/atlasarm/arm_controller' failed  \n  \nWhy is it that when I try to load the controller I get this error saying No\njoint given. But looking at the yaml file I see the list of joints?  \n  \nThanks  \nMike  \n  \n\n![Adolfo Rodr\u00edguez Tsouroukdissian's profile\nphoto](//lh3.googleusercontent.com/a-/ALV-\nUjWUxHT8qByi6OYKbrEfTiu12v2zMkGSVemC9-iV-3dj6so_yIrg=s40-c)\n\n###  Adolfo Rodr\u00edguez Tsouroukdissian\n\nunread,\n\nJul 3, 2014, 2:56:00 PM  7/3/14\n\n\ue83a\n\n\ue15f\n\n\ue5d4\n\nReply to author\n\nSign in to reply to author\n\nForward\n\nSign in to forward\n\nDelete\n\nYou do not have permission to delete messages in this group\n\nCopy link\n\nReport message\n\nSign in to report message\n\nShow original message\n\nEither email addresses are anonymous for this group or you need the view\nmember email addresses permission to view the original message\n\nto Michael Francis, ros-sig-ro...@googlegroups.com\n\nOn Wed, Jul 2, 2014 at 10:18 PM,  < [ mfr...@vt.edu ]() > wrote:  \n\n> Hey all,  \n>  \n>  So I am trying to use the effort_controller/JointVelocityController as a\n> controller to interface with movegroup action service. In my urdf file I\n> made sure to set the hardware interface to VelocityJointInterface, and when\n> creating my RobotHW class I made sure to create a private variable\n> _hardware_interface::EffortJointInterface jnt_vel_interface;_ in order to\n> register and connect the interface. Here is my controller.yaml file  \n>\n\n  \nIf you're using the MoveitSimpleControllerManager (the most common usecase),\nthen a effort_controller/JointVelocityController (from the ros_controllers\nproject) will not do. The expected controller interface should implement a\nfollow_joint_trajectoy action server. See [1] for more details. In\nros_controllers, there's the joint_trajectory_controller that implements this\ninterface. Position and effort interfaces are already supported, and velocity\ninterfaces have an open PR [2], that is pending some validation.  \n  \n[1] [ http://moveit.ros.org/wiki/Executing_Trajectories_with_MoveIt\n](http://moveit.ros.org/wiki/Executing_Trajectories_with_MoveIt) !  \n[2] [ https://github.com/ros-controls/ros_controllers/pull/64\n](https://github.com/ros-controls/ros_controllers/pull/64)  \n\n  \n\n> \ue5d3\n\n> \\--  \n>  You received this message because you are subscribed to the Google Groups\n> \"ROS/Orocos Robot Control Special Interest Group\" group.  \n>  To unsubscribe from this group and stop receiving emails from it, send an\n> email to [ ros-sig-robot-co...@googlegroups.com ]() .  \n>  For more options, visit [ https://groups.google.com/d/optout\n> ](https://groups.google.com/d/optout) .  \n>\n\n  \n\n![Felix Me\u00dfmer's profile photo](//lh3.googleusercontent.com/a-/ALV-UjXo2aXfAk-\ndu0bo7Rk6_qcY5MZE8BRzAtLvSi33j1VJUTXvhQ=s40-c)\n\n###  Felix Me\u00dfmer\n\nunread,\n\nJul 4, 2014, 2:24:40 PM  7/4/14\n\n\ue83a\n\n\ue15f\n\n\ue5d4\n\nReply to author\n\nSign in to reply to author\n\nForward\n\nSign in to forward\n\nDelete\n\nYou do not have permission to delete messages in this group\n\nCopy link\n\nReport message\n\nSign in to report message\n\nShow original message\n\nEither email addresses are anonymous for this group or you need the view\nmember email addresses permission to view the original message\n\nto ros-sig-ro...@googlegroups.com, mfr...@vt.edu\n\nI am also working with the effort_controller/JointVelocityController.  \nWe are currently trying to figure out good PID gains for a 7DoF robot arm. I\nwill post our experiences here, once we are done.  \n  \nI just have a few questions:  \n\\- Isn't the effort_controller/JointVelocityController a single joint\ncontroller? Thus only capable of having one joint being set in the joint tag?  \n\\- What we are currently trying to do is figure out good PIDs for each\nrevolute joint separately (separate controllers with separate yaml files) by\nmaking all but the current joint a fixed joint in the URDF.  \n\\- Another thing that we recognized is that the JointVelocityController only\npublishes state information only every 10th time update() is called ( [\nhttps://github.com/ros-controls/ros_controllers/blob/indigo-\ndevel/effort_controllers/src/joint_velocity_controller.cpp#L140\n](https://github.com/ros-controls/ros_controllers/blob/indigo-\ndevel/effort_controllers/src/joint_velocity_controller.cpp#L140) ). For our\ninitial PIDs the rqt_plots looked quite ok/smooth, but the arm kept dropping\nand was totally unstable. When I then published to the state topic every\nupdate(), I found the controller heavily oscillating changing sign every\nmessage. By only publishing every even message, you did not see this...;-)  \n\\- Now we are trying to find the PIDs using Ziegler-Nichols strategy for each\njoint controller separately and then hope that it still works when me make all\njoints revolute again. Would you say this approach is feasible? Are there any\nother suggestions?\n\n\ue5d3\n\n\ue5d3\n\n\ue5d3\n\n\ue5d3\n\n> > To unsubscribe from this group and stop receiving emails from it, send an\n> email to  ros-sig-robot-control+unsub...@googlegroups.com  .\n\n\ue5d3\n\n![Adolfo Rodr\u00edguez Tsouroukdissian's profile\nphoto](https://lh3.googleusercontent.com/a/default-user=s40-c)\n\n###  Adolfo Rodr\u00edguez Tsouroukdissian\n\nunread,\n\nJul 4, 2014, 2:49:55 PM  7/4/14\n\n\ue83a\n\n\ue15f\n\n\ue5d4\n\nReply to author\n\nSign in to reply to author\n\nForward\n\nSign in to forward\n\nDelete\n\nYou do not have permission to delete messages in this group\n\nCopy link\n\nReport message\n\nSign in to report message\n\nShow original message\n\nEither email addresses are anonymous for this group or you need the view\nmember email addresses permission to view the original message\n\nto Felix Me\u00dfmer, ros-sig-ro...@googlegroups.com, Michael Francis\n\nOn Fri, Jul 4, 2014 at 8:24 AM, Felix Me\u00dfmer  < [ felixm...@gmail.com ]() >\nwrote:  \n\n> I am also working with the effort_controller/JointVelocityController.  \n>  We are currently trying to figure out good PID gains for a 7DoF robot arm.\n> I will post our experiences here, once we are done.  \n>  \n>  I just have a few questions:  \n>  \\- Isn't the effort_controller/JointVelocityController a single joint\n> controller? Thus only capable of having one joint being set in the joint\n> tag?  \n>\n\n  \n\nYes, it's a single-joint controller.  \n  \n\n> \\- What we are currently trying to do is figure out good PIDs for each\n> revolute joint separately (separate controllers with separate yaml files) by\n> making all but the current joint a fixed joint in the URDF.  \n>\n\n  \n\nIf a joint is part of a chain, it's dynamics will be affected by the dynamic\ncoupling with upstream and downsteam links. That is, as the robot changes\nconfiguration, it's mass distribution will also change, as well as the joint\naccelerations. In the absence of a controller that compensates dynamics, as in\npure PID control, these dynamic effects are disturbances the PID must be\neffective at rejecting. If you tune a joint PID in a fixed configuration, you\ncould be underestimating the disturbances it must reject. If your robot does\nnot do very dynamic motions, you can probably get a good starting point by\nusing the most demanding fixed configurations (eg. tune a shoulder joint with\nthe arm stretched, oriented for max gravity load).  \n\n> \\- Another thing that we recognized is that the JointVelocityController only\n> publishes state information only every 10th time update() is called ( [\n> https://github.com/ros-controls/ros_controllers/blob/indigo-\n> devel/effort_controllers/src/joint_velocity_controller.cpp#L140\n> ](https://github.com/ros-controls/ros_controllers/blob/indigo-\n> devel/effort_controllers/src/joint_velocity_controller.cpp#L140) ). For our\n> initial PIDs the rqt_plots looked quite ok/smooth, but the arm kept dropping\n> and was totally unstable. When I then published to the state topic every\n> update(), I found the controller heavily oscillating changing sign every\n> message. By only publishing every even message, you did not see this...;-)  \n>\n\n  \n\nIf you want to make this a configurable parameter, as other controller do, I'd\nbe happy to review a patch.  \n\n> \\- Now we are trying to find the PIDs using Ziegler-Nichols strategy for\n> each joint controller separately and then hope that it still works when me\n> make all joints revolute again. Would you say this approach is feasible? Are\n> there any other suggestions?  \n>\n\n  \n\nWe tune our hardware PIDs using frequency-domain tools. We've so far been more\nheuristic when tuning our simulation gains, definitely something to improve.  \n  \n\nBest,  \n  \nAdolfo.  \n  \n\n  \n\n> \ue5d3\n\n\ue5d3\n\n> To unsubscribe from this group and stop receiving emails from it, send an\n> email to [ ros-sig-robot-co...@googlegroups.com ]() .\n\n>  \n>  For more options, visit [ https://groups.google.com/d/optout\n> ](https://groups.google.com/d/optout) .  \n>\n\n>  \n\n  \n  \n\\--  \nAdolfo Rodr\u00edguez Tsouroukdissian  \nSenior robotics engineer  \n[ adolfo.r...@pal-robotics.com ]()  \n[ http://www.pal-robotics.com ](http://www.pal-robotics.com/)  \n  \nPAL ROBOTICS S.L  \nc/ Pujades 77-79, 4\u00ba4\u00aa  \n08005 Barcelona, Spain.  \nTel. [ +34.93.414.53.47 ](tel:+34%20934%2014%2053%2047)  \nFax. [ +34.93.209.11.09 ](tel:+34%20932%2009%2011%2009)  \nSkype: adolfo.pal-robotics  \n[ Facebook ](http://www.facebook.com/palrobotics1) \\- [ Twitter\n](http://twitter.com/#%21/palrobotics) \\- [ PAL Robotics YouTube Channel\n](http://www.youtube.com/user/PALRobotics)  \n  \nAVISO DE CONFIDENCIALIDAD: Este mensaje y sus documentos adjuntos, pueden\ncontener informaci\u00f3n privilegiada y/o confidencial que est\u00e1 dirigida\nexclusivamente a su destinatario. Si usted recibe este mensaje y no es el\ndestinatario indicado, o el empleado encargado de su entrega a dicha persona,\npor favor, notif\u00edquelo inmediatamente y remita el mensaje original a la\ndirecci\u00f3n de correo electr\u00f3nico indicada. Cualquier copia, uso o distribuci\u00f3n\nno autorizados de esta comunicaci\u00f3n queda estrictamente prohibida.  `  \n  \n` CONFIDENTIALITY NOTICE: This e-mail and the accompanying document(s) may\ncontain confidential information which is privileged and intended only for the\nindividual or entity to whom they are addressed. If you are not the intended\nrecipient, you are hereby notified that any disclosure, copying, distribution\nor use of this e-mail and/or accompanying document(s) is strictly prohibited.\nIf you have received this e-mail in error, please immediately notify the\nsender at the above e-mail address.\n\n![Felix Me\u00dfmer's profile photo](//lh3.googleusercontent.com/a-/ALV-UjXo2aXfAk-\ndu0bo7Rk6_qcY5MZE8BRzAtLvSi33j1VJUTXvhQ=s40-c)\n\n###  Felix Me\u00dfmer\n\nunread,\n\nJul 4, 2014, 8:30:56 PM  7/4/14\n\n\ue83a\n\n\ue15f\n\n\ue5d4\n\nReply to author\n\nSign in to reply to author\n\nForward\n\nSign in to forward\n\nDelete\n\nYou do not have permission to delete messages in this group\n\nCopy link\n\nReport message\n\nSign in to report message\n\nShow original message\n\nEither email addresses are anonymous for this group or you need the view\nmember email addresses permission to view the original message\n\nto ros-sig-ro...@googlegroups.com, felixm...@gmail.com, mfr...@vt.edu,\nadolfo.r...@pal-robotics.com\n\nThanks for the comments,  \n  \nit seems that we are able to find (more or less) good/satisfying PIDs for all\nseparate joint respectively following the approach mentioned above.  \nHowever, as soon as we allow several joints to be revolute again at the same\ntime, The behaviour is bad again - as Adolfo already expected for the obvious\nreasons.  \nWe again see highly oscillating values in the joint controllers changing the\nsign evey update cycle.  \n  \nSome things that we are currently thinking about:  \n\\- As we do not know realistic values for damping, friction and so on, so far,\nwe tried to use default values (or simply remove the respective tags from the\nURDF or the gazebo extension XACRO). In fact, we currently only set the\n<matrial> in the gazebo extension and use damping=0 and friction=0 in the\nURDF. (Friction is not implemented in Gazebo anyway, isn't it?)  \nMaybe setting some of these values would help reduce the oscillation and help\nin the PID tuning. However, I don't know what should be set or how we could\napproximate the respective values for our robot. Any good default values?\nIdeas?  \n  \n\\- We also have had the <safety_controller> tag in our URDF. There were values\nfor k_p and k_v, where I don't know where they come from. When I removed the\ntag, the controller seems to behave (at least a bit) better. Any counter-\narguments against removing this tag from the URDF?  \n  \n\\- Is it possible that a slower update frequency for the\nJointVelocityController might help the problem? Is this update frequency\nparameterizable? Where can I set it? I think the default is the gazebo tick\nrate, isn't it?  \n  \n  \n@Adolfo:  \nCan you elaborate a bit more on what frequency-domain tools you were using? Do\nyou mean Bode-Diagram and stuff like that?  \nSo you have a mathematical model for your hardware, right?  \n  \n  \n  \nBest,  \nFelix\n\n\ue5d3\n\n\ue5d3\n\n\ue5d3\n\n\ue5d3\n\n\ue5d3\n\n\ue5d3\n\n> > > > To unsubscribe from this group and stop receiving emails from it, send\n> an email to  ros-sig-robot-control+ __ unsubscri...@googlegroups.com  .\n\n> > > >  \n>  For more options, visit [ https://groups.google.com/d/ __ optout\n> ](https://groups.google.com/d/optout) .  \n>\n\n> > \\--  \n>  You received this message because you are subscribed to the Google Groups\n> \"ROS/Orocos Robot Control Special Interest Group\" group.  \n>  To unsubscribe from this group and stop receiving emails from it, send an\n> email to  ros-sig-robot-control+unsub...@googlegroups.com  .  \n>  For more options, visit [ https://groups.google.com/d/optout\n> ](https://groups.google.com/d/optout) .  \n>\n\n> >  \n>\n>\n>  \n>  \n>  \\--  \n>\n\n\ue5d3\n\n![Felix Me\u00dfmer's profile photo](//lh3.googleusercontent.com/a-/ALV-UjXo2aXfAk-\ndu0bo7Rk6_qcY5MZE8BRzAtLvSi33j1VJUTXvhQ=s40-c)\n\n###  Felix Me\u00dfmer\n\nunread,\n\nJul 4, 2014, 8:45:04 PM  7/4/14\n\n\ue83a\n\n\ue15f\n\n\ue5d4\n\nReply to author\n\nSign in to reply to author\n\nForward\n\nSign in to forward\n\nDelete\n\nYou do not have permission to delete messages in this group\n\nCopy link\n\nReport message\n\nSign in to report message\n\nShow original message\n\nEither email addresses are anonymous for this group or you need the view\nmember email addresses permission to view the original message\n\nto ros-sig-ro...@googlegroups.com, felixm...@gmail.com, mfr...@vt.edu,\nadolfo.r...@pal-robotics.com\n\nOh, two more things, that I cannot explain at the moment:  \n  \nWhen I have a look at the process_value entry in the JointVelocityController\nstate message, this should be the actual/current joint velocity, right?  \nThis value is retrieved directly from the HardwareInterface/GazeboHandle\njoint_->getVelocity(),right?  \nHow can it be that the process_value sometimes is higher than the velocity\nlimit specified in the URDF? This mainly happens, when in the oscillation\ncase, where it the arm is actually not moving at all (probably because the\nvelocities equalize themselves).  \n  \nSimilar thing with the efforts.  \nWhen looking at the /joint_states/effort[] values, they seem to be correctly\nclamped to the effort limit as specified in the URDF.  \nHowever, using only one revolute joint (the others fixed) this effort\nsometimes is already used up just to keep the joint at velocity 0.  \nWhen we now command a velocity in the same direction as the effort (e.g. send\nnegative velocity in case current effort is -effort_limit), the arm move but\nthe current effort still is equal to the previous effort value (still\n-effort_limit).  \nHow is it possible to move without being allowed to exceed the effort limit?\n(I saw that the command value in the state message of the\nJointVelocityController has values much higher than the effort limit (which\nseems to be ok, as the documentation for SetForce() says that the commanded\neffort is truncated to the effort limit).  \n  \n....Strange things, I cannot explain....\n\n\ue5d3\n\n![Adolfo Rodr\u00edguez Tsouroukdissian's profile\nphoto](https://lh3.googleusercontent.com/a/default-user=s40-c)\n\n###  Adolfo Rodr\u00edguez Tsouroukdissian\n\nunread,\n\nJul 7, 2014, 4:47:35 PM  7/7/14\n\n\ue83a\n\n\ue15f\n\n\ue5d4\n\nReply to author\n\nSign in to reply to author\n\nForward\n\nSign in to forward\n\nDelete\n\nYou do not have permission to delete messages in this group\n\nCopy link\n\nReport message\n\nSign in to report message\n\nShow original message\n\nEither email addresses are anonymous for this group or you need the view\nmember email addresses permission to view the original message\n\nto Felix Me\u00dfmer, ros-sig-ro...@googlegroups.com, Michael Francis\n\nOn Fri, Jul 4, 2014 at 2:30 PM, Felix Me\u00dfmer  < [ felixm...@gmail.com ]() >\nwrote:  \n\n> Thanks for the comments,  \n>  \n>  it seems that we are able to find (more or less) good/satisfying PIDs for\n> all separate joint respectively following the approach mentioned above.  \n>  However, as soon as we allow several joints to be revolute again at the\n> same time, The behaviour is bad again - as Adolfo already expected for the\n> obvious reasons.  \n>  We again see highly oscillating values in the joint controllers changing\n> the sign evey update cycle.  \n>  \n>  Some things that we are currently thinking about:  \n>  \\- As we do not know realistic values for damping, friction and so on, so\n> far, we tried to use default values (or simply remove the respective tags\n> from the URDF or the gazebo extension XACRO). In fact, we currently only set\n> the <matrial> in the gazebo extension and use damping=0 and friction=0 in\n> the URDF. (Friction is not implemented in Gazebo anyway, isn't it?)  \n>\n\n  \n\nI think not, and I couldn't find  \n\n> Maybe setting some of these values would help reduce the oscillation and\n> help in the PID tuning. However, I don't know what should be set or how we\n> could approximate the respective values for our robot. Any good default\n> values? Ideas?  \n>\n\n  \n\nI'm not sure. Gazebo's changelog and roadmap don't make much mention of it.\nSome time ago it was in the roadmap, but not anymore.  \n\n>  \n>  \\- We also have had the <safety_controller> tag in our URDF. There were\n> values for k_p and k_v, where I don't know where they come from.\n\n  \n\nYou can find some doc in the PR2 pages, which has not been migrated to the\nros_control wiki:  \n  \n[ http://wiki.ros.org/pr2_controller_manager/safety_limits\n](http://wiki.ros.org/pr2_controller_manager/safety_limits)  \n\n> When I removed the tag, the controller seems to behave (at least a bit)\n> better.\n\n  \n\nMaybe the gains are not set correctly.  \n  \n\n> Any counter-arguments against removing this tag from the URDF?  \n>\n\n  \n\nUsing the safety controller specification is not mandatory.  \n\n>  \n>  \\- Is it possible that a slower update frequency for the\n> JointVelocityController might help the problem? Is this update frequency\n> parameterizable? Where can I set it? I think the default is the gazebo tick\n> rate, isn't it?  \n>\n\n  \n\nAll controllers will get their update() method called at the same periodic\nfrequency. For the GazeboRosControlPlugin  plugin, you can set it like so from\nthe URDF:  \n  \n\n    \n    \n    <gazebo>\n      <plugin name=\"gazebo_ros_control\" filename=\"libgazebo_ros_control.so\">\n        <controlPeriod>0.001</controlPeriod>\n      </plugin>\n    </gazebo>\n\nThe code that does this is here:  \n\n  \n[ https://github.com/ros-simulation/gazebo_ros_pkgs/blob/hydro-\ndevel/gazebo_ros_control/src/gazebo_ros_control_plugin.cpp#L117\n](https://github.com/ros-simulation/gazebo_ros_pkgs/blob/hydro-\ndevel/gazebo_ros_control/src/gazebo_ros_control_plugin.cpp#L117)  \n  \nYou can additionally decide to skip doing work on a per-controller basis if\nyou want, say to run a controllers computations every n controller_manager\nupdates.  \n\n>  \n>  \n>  @Adolfo:  \n>  Can you elaborate a bit more on what frequency-domain tools you were using?\n> Do you mean Bode-Diagram and stuff like that?  \n>  So you have a mathematical model for your hardware, right?  \n>\n\n  \n\nWe identify the plant by exciting it with signals of varying frequency, and\nthen run some frequency-domain tools from Matlab. There are some building\nblocks for doing a sine sweep in the control_toolbox package.  \n  \n[ https://github.com/ros-controls/control_toolbox/tree/indigo-\ndevel/include/control_toolbox ](https://github.com/ros-\ncontrols/control_toolbox/tree/indigo-devel/include/control_toolbox)  \n  \n\n\ue5d3\n\n\ue5d3\n\n![Adolfo Rodr\u00edguez Tsouroukdissian's profile\nphoto](https://lh3.googleusercontent.com/a/default-user=s40-c)\n\n###  Adolfo Rodr\u00edguez Tsouroukdissian\n\nunread,\n\nJul 7, 2014, 5:04:56 PM  7/7/14\n\n\ue83a\n\n\ue15f\n\n\ue5d4\n\nReply to author\n\nSign in to reply to author\n\nForward\n\nSign in to forward\n\nDelete\n\nYou do not have permission to delete messages in this group\n\nCopy link\n\nReport message\n\nSign in to report message\n\nShow original message\n\nEither email addresses are anonymous for this group or you need the view\nmember email addresses permission to view the original message\n\nto Felix Me\u00dfmer, ros-sig-ro...@googlegroups.com, Michael Francis\n\nOn Fri, Jul 4, 2014 at 2:45 PM, Felix Me\u00dfmer  < [ felixm...@gmail.com ]() >\nwrote:  \n\n> Oh, two more things, that I cannot explain at the moment:  \n>  \n>  When I have a look at the process_value entry in the\n> JointVelocityController state message, this should be the actual/current\n> joint velocity, right?  \n>  This value is retrieved directly from the HardwareInterface/GazeboHandle\n> joint_->getVelocity(),right?  \n>\n\n  \n\nYes  \n[ https://github.com/ros-controls/ros_controllers/blob/indigo-\ndevel/effort_controllers/src/joint_velocity_controller.cpp#L146\n](https://github.com/ros-controls/ros_controllers/blob/indigo-\ndevel/effort_controllers/src/joint_velocity_controller.cpp#L146)  \n  \n\n> How can it be that the process_value sometimes is higher than the velocity\n> limit specified in the URDF? This mainly happens, when in the oscillation\n> case, where it the arm is actually not moving at all (probably because the\n> velocities equalize themselves).  \n>\n\n  \n\nDo you get constant high velocities, isolated peaks or noise?.  \n\n>  \n>  Similar thing with the efforts.  \n>  When looking at the /joint_states/effort[] values, they seem to be\n> correctly clamped to the effort limit as specified in the URDF.  \n>  However, using only one revolute joint (the others fixed) this effort\n> sometimes is already used up just to keep the joint at velocity 0.  \n>\n\n  \n\nIf there's a load to overcome, like gravity, it makes sense to have a nonzero\neffort to keep the joint velocity equal to zero.  \n\n> When we now command a velocity in the same direction as the effort (e.g.\n> send negative velocity in case current effort is -effort_limit), the arm\n> move but the current effort still is equal to the previous effort value\n> (still -effort_limit).  \n>\n\n  \n\nThis sounds unexpected.  \n\n> How is it possible to move without being allowed to exceed the effort limit?\n> (I saw that the command value in the state message of the\n> JointVelocityController has values much higher than the effort limit (which\n> seems to be ok, as the documentation for SetForce() says that the commanded\n> effort is truncated to the effort limit).  \n>\n\n  \n\nI don't know what can be happening here. I suggest using a debugger and follow\nthe trail until the unexpected action happens, which can be on how commands\nare sent to Gazebo, within Gazebo itself, or on how the state is read from\nGazebo.  \n  \n\nHTH,  \n  \n\nAdolfo.  \n  \n\nP.S. This thread has diverged significantly from its subject. Since very\ninteresting discussions are taking place here, it would be nice for others to\neasily find them. I appreciate it if we create a new thread with an\nappropriate title the next time the subject strays from the original post.\nSmaller, focused threads are easier to find.  \n\n\ue5d3\n\n\ue5d3\n\n![mfr...@vt.edu's profile photo](//lh3.googleusercontent.com/a-/ALV-\nUjXLZw18gFzZHa2C4A0mrLpZ13blWBOpMeCRZ4tYXUaxAYg45w=s40-c)\n\n###  mfr...@vt.edu\n\nunread,\n\nJul 9, 2014, 1:53:14 AM  7/9/14\n\n\ue83a\n\n\ue15f\n\n\ue5d4\n\nReply to author\n\nSign in to reply to author\n\nForward\n\nSign in to forward\n\nDelete\n\nYou do not have permission to delete messages in this group\n\nCopy link\n\nReport message\n\nSign in to report message\n\nShow original message\n\nEither email addresses are anonymous for this group or you need the view\nmember email addresses permission to view the original message\n\nto ros-sig-ro...@googlegroups.com, mfr...@vt.edu\n\nSorry for the late response Adolfo,  \n  \nFirst of all thanks for the feedback. I guess what my main concern is how can\nI extract the velocity data being sent through the trajectory msg? I started\ndigging around and came to the conclusion that I dont fully understand the\ndifference between \"effort_controllers/JointTrajectoryController\" and\n\"position_controllers/JointTrajectoryController\".  \n  \nAt first I thought \"effort_controllers/JointTrajectoryController\" was giving\nme the relative position to which my joint should move to. It did this by\nconnecting and registering a \"hardware_interface::EffortJointInterface\njnt_pos_interface\" object to a array named cmd[ ] (This is all from this\ntutorial). The cmd array had only one value for each joint, that being the\nrelative position. Adolfo am I correct in assuming that? Or is the value being\nsent something different?  \n  \nIf I am correct in my assumption from above what is\n\"position_controllers/JointTrajectoryController\" for (I havent tried to use\nthis controller yet)?  \n  \nAlso I was wondering does \"effort_controllers/JointTrajectoryController\" use\njoint_position_controller.cpp located in\nros_controllers/effort_controllers/src directory? If so does the cmd [ ]\n(mentioned above) use the setCommand() function to get its target position\ndata?  \n  \nFinally I just wanted to know if I could use\n\"effort_controllers/JointTrajectoryController\" and some how grab the velocity\nvalues coming from the trajectory msg from moveit using it?  \n  \nMike  \n\n\ue5d3\n\n\ue5d3\n\n\ue5d3\n\n\ue5d3\n\n> > To unsubscribe from this group and stop receiving emails from it, send an\n> email to  ros-sig-robot-control+unsub...@googlegroups.com  .\n\n\ue5d3\n\n![Adolfo Rodr\u00edguez Tsouroukdissian's profile\nphoto](https://lh3.googleusercontent.com/a/default-user=s40-c)\n\n###  Adolfo Rodr\u00edguez Tsouroukdissian\n\nunread,\n\nJul 9, 2014, 2:45:06 PM  7/9/14\n\n\ue83a\n\n\ue15f\n\n\ue5d4\n\nReply to author\n\nSign in to reply to author\n\nForward\n\nSign in to forward\n\nDelete\n\nYou do not have permission to delete messages in this group\n\nCopy link\n\nReport message\n\nSign in to report message\n\nShow original message\n\nEither email addresses are anonymous for this group or you need the view\nmember email addresses permission to view the original message\n\nto Michael Francis, ros-sig-ro...@googlegroups.com\n\nOn Tue, Jul 8, 2014 at 7:53 PM,  < [ mfr...@vt.edu ]() > wrote:  \n\n> Sorry for the late response Adolfo,  \n>  \n>  First of all thanks for the feedback. I guess what my main concern is how\n> can I extract the velocity data being sent through the trajectory msg? I\n> started digging around and came to the conclusion that I dont fully\n> understand the difference between\n> \"effort_controllers/JointTrajectoryController\" and\n> \"position_controllers/JointTrajectoryController\".  \n>\n\n  \n\nThe former produces effort commands that realize the desired trajectory, while\nthe latter produces position commands that do the same thing. You use one or\nthe other depending on whether your hardware exposes effort or position\ncontrolled joints.  \n  \n\nInternally, when the trajectory is sampled, one has access to the desired\nposition, velocity and acceleration. For position controlled joints it\nsuffices to forward the desired position. For effort controlled joints, a PID\naround position is implemented (note that we also have access to the current\nposition and velocity to compute errors).  \n\n>  \n>  At first I thought \"effort_controllers/JointTrajectoryController\" was\n> giving me the relative position to which my joint should move to.\n\n  \n\nNo, it does not produce relative increments.  \n  \n\n> It did this by connecting and registering a\n> \"hardware_interface::EffortJointInterface jnt_pos_interface\" object to a\n> array named cmd[ ] (This is all from this tutorial). The cmd array had only\n> one value for each joint, that being the relative position. Adolfo am I\n> correct in assuming that? Or is the value being sent something different?  \n>  \n>\n\ncmd[] contains the joint effort to apply in this control cycle. It's not a\nrelative value. The same applies for position references, they are not\nrelative.  \n\n  \n\n> If I am correct in my assumption from above what is\n> \"position_controllers/JointTrajectoryController\" for (I havent tried to use\n> this controller yet)?  \n>  \n>  Also I was wondering does \"effort_controllers/JointTrajectoryController\"\n> use joint_position_controller.cpp located in\n> ros_controllers/effort_controllers/src directory? If so does the cmd [ ]\n> (mentioned above) use the setCommand() function to get its target position\n> data?  \n>\n\n  \n\nNo, \"effort_controllers/JointTrajectoryController\" does not depend on the\n\"effort_controllers\" package. What lead you to believe this?. You can verify\ndependencies of a package by using rospack:  \n  \nrospack depends joint_trajectory_controller | grep effort_controllers #\nreturns an empty list  \n  \n\n>  \n>  Finally I just wanted to know if I could use\n> \"effort_controllers/JointTrajectoryController\" and some how grab the\n> velocity values coming from the trajectory msg from moveit using it?  \n>\n\n  \n\nIf you have velocity-controlled joints, keep an eye on [\nhttps://github.com/ros-controls/ros_controllers/issues/43\n](https://github.com/ros-controls/ros_controllers/issues/43)  \n\nThis would be the right way to do it.  \n  \n\nAdolfo.  \n  \n\n> \ue5d3\n\n\ue5d3\n\n> To unsubscribe from this group and stop receiving emails from it, send an\n> email to [ ros-sig-robot-co...@googlegroups.com ]() .\n\n>  \n>  For more options, visit [ https://groups.google.com/d/optout\n> ](https://groups.google.com/d/optout) .  \n>\n\n\ue5d3\n\n![mfr...@vt.edu's profile photo](//lh3.googleusercontent.com/a-/ALV-\nUjXLZw18gFzZHa2C4A0mrLpZ13blWBOpMeCRZ4tYXUaxAYg45w=s40-c)\n\n###  mfr...@vt.edu\n\nunread,\n\nJul 11, 2014, 1:10:18 AM  7/11/14\n\n\ue83a\n\n\ue15f\n\n\ue5d4\n\nReply to author\n\nSign in to reply to author\n\nForward\n\nSign in to forward\n\nDelete\n\nYou do not have permission to delete messages in this group\n\nCopy link\n\nReport message\n\nSign in to report message\n\nShow original message\n\nEither email addresses are anonymous for this group or you need the view\nmember email addresses permission to view the original message\n\nto ros-sig-ro...@googlegroups.com, mfr...@vt.edu, adolfo.r...@pal-robotics.com\n\nHow exactly is the effort value calculated?\n\n\ue5d3\n\n\ue5d3\n\n\ue5d3\n\n\ue5d3\n\n\ue5d3\n\n\ue5d3\n\n> > > > To unsubscribe from this group and stop receiving emails from it, send\n> an email to  ros-sig-robot-control+ __ unsubscri...@googlegroups.com  .\n\n> > > >  \n>  For more options, visit [ https://groups.google.com/d/ __ optout\n> ](https://groups.google.com/d/optout) .  \n>\n\n> > \\--  \n>  You received this message because you are subscribed to the Google Groups\n> \"ROS/Orocos Robot Control Special Interest Group\" group.  \n>  To unsubscribe from this group and stop receiving emails from it, send an\n> email to  ros-sig-robot-control+unsub...@googlegroups.com  .  \n>  For more options, visit [ https://groups.google.com/d/optout\n> ](https://groups.google.com/d/optout) .  \n>\n\n> >  \n>\n>\n>  \n>  \n>  \\--  \n>\n\n\ue5d3\n\n![Adolfo Rodr\u00edguez Tsouroukdissian's profile\nphoto](https://lh3.googleusercontent.com/a/default-user=s40-c)\n\n###  Adolfo Rodr\u00edguez Tsouroukdissian\n\nunread,\n\nJul 11, 2014, 10:38:21 PM  7/11/14\n\n\ue83a\n\n\ue15f\n\n\ue5d4\n\nReply to author\n\nSign in to reply to author\n\nForward\n\nSign in to forward\n\nDelete\n\nYou do not have permission to delete messages in this group\n\nCopy link\n\nReport message\n\nSign in to report message\n\nShow original message\n\nEither email addresses are anonymous for this group or you need the view\nmember email addresses permission to view the original message\n\nto Michael Francis, ros-sig-ro...@googlegroups.com\n\nOn Thu, Jul 10, 2014 at 7:10 PM,  < [ mfr...@vt.edu ]() > wrote:  \n\n> How exactly is the effort value calculated?  \n>\n\n  \nThis file should answer your question,  \n  \n[ https://github.com/ros-controls/ros_controllers/blob/indigo-\ndevel/joint_trajectory_controller/include/joint_trajectory_controller/hardware_interface_adapter.h\n](https://github.com/ros-controls/ros_controllers/blob/indigo-\ndevel/joint_trajectory_controller/include/joint_trajectory_controller/hardware_interface_adapter.h)\n\n\ue5d3\n\n![mfr...@vt.edu's profile photo](//lh3.googleusercontent.com/a-/ALV-\nUjXLZw18gFzZHa2C4A0mrLpZ13blWBOpMeCRZ4tYXUaxAYg45w=s40-c)\n\n###  mfr...@vt.edu\n\nunread,\n\nJul 11, 2014, 10:57:26 PM  7/11/14\n\n\ue83a\n\n\ue15f\n\n\ue5d4\n\nReply to author\n\nSign in to reply to author\n\nForward\n\nSign in to forward\n\nDelete\n\nYou do not have permission to delete messages in this group\n\nCopy link\n\nReport message\n\nSign in to report message\n\nShow original message\n\nEither email addresses are anonymous for this group or you need the view\nmember email addresses permission to view the original message\n\nto ros-sig-ro...@googlegroups.com, mfr...@vt.edu, adolfo.r...@pal-robotics.com\n\nAdolfo  \n  \nThank you soo much for the link, it really helped me break down the confusion\n:). My next question then is if the effort controller is outputing a position\nthat uses the position error, and velocity error, how can I extract the\nvelocity error? If possible I would like to continue using the effort\ncontroller and extract the velocity error from the command , so that I can\ncontrol the arm using the velocity error. This way i can use velocity to\ncontrol the arm and use the position error to determine other factors. Or\nshould I go another route and use the velocity controller created for the\njoint_trajectory_controllers but still not released( [ https://github.com/ros-\ncontrols/ros_controllers/pull/64 ](https://github.com/ros-\ncontrols/ros_controllers/pull/64) )?  \n  \nMike\n\n\ue5d3\n\n![Adolfo Rodr\u00edguez Tsouroukdissian's profile\nphoto](https://lh3.googleusercontent.com/a/default-user=s40-c)\n\n###  Adolfo Rodr\u00edguez Tsouroukdissian\n\nunread,\n\nJul 14, 2014, 4:01:10 PM  7/14/14\n\n\ue83a\n\n\ue15f\n\n\ue5d4\n\nReply to author\n\nSign in to reply to author\n\nForward\n\nSign in to forward\n\nDelete\n\nYou do not have permission to delete messages in this group\n\nCopy link\n\nReport message\n\nSign in to report message\n\nShow original message\n\nEither email addresses are anonymous for this group or you need the view\nmember email addresses permission to view the original message\n\nto Michael Francis, ros-sig-ro...@googlegroups.com\n\nOn Fri, Jul 11, 2014 at 4:57 PM,  < [ mfr...@vt.edu ]() > wrote:  \n\n> Adolfo  \n>  \n>  Thank you soo much for the link, it really helped me break down the\n> confusion :). My next question then is if the effort controller is outputing\n> a position that uses the position error, and velocity error, how can I\n> extract the velocity error? If possible I would like to continue using the\n> effort controller and extract the velocity error from the command , so that\n> I can control the arm using the velocity error. This way i can use velocity\n> to control the arm and use the position error to determine other factors. Or\n> should I go another route and use the velocity controller created for the\n> joint_trajectory_controllers but still not released( [\n> https://github.com/ros- __ controls/ros_controllers/pull/ __ 64\n> ](https://github.com/ros-controls/ros_controllers/pull/64) )?  \n>\n\n  \n\nMike,  \n  \n\nYou already asked this question, the original answer still holds:  \n\n  \n\n> If you have velocity-controlled joints, keep an eye on [\n> https://github.com/ros-controls/ros_controllers/issues/43\n> ](https://github.com/ros-controls/ros_controllers/issues/43)  \n>  This would be the right way to do it.  \n>\n\n> >  \n\nSupporting velocity-controlled joints implies implementing a new\nspecialization for the HardwareInterfaceAdapter class. Only this file needs to\nbe touched:  \n  \n[ https://github.com/ros-controls/ros_controllers/blob/indigo-\ndevel/joint_trajectory_controller/include/joint_trajectory_controller/hardware_interface_adapter.h\n](https://github.com/ros-controls/ros_controllers/blob/indigo-\ndevel/joint_trajectory_controller/include/joint_trajectory_controller/hardware_interface_adapter.h)  \n\n\ue5d3\n\n\ue15f  Reply all\n\n\ue15e  Reply to author\n\n\ue154  Forward\n\n\ue5d5\n\n0 new messages\n\n\ue5cd\n\nSearch\n\nClear search\n\nClose search\n\nGoogle apps\n\nMain menu\n\n"
  },
  {
    "id": "ros_environment_variable/EnvironmentVariables.txt",
    "content": "[ ![ros.org](/custom/images/ros_org.png) ](/) |  [ About\n](http://www.ros.org/about-ros) | [ Support ](/Support) | [ Discussion Forum\n](http://discourse.ros.org/) | [ Index ](http://index.ros.org/) | [ Service\nStatus ](http://status.ros.org/) | [ ros @ Robotics Stack Exchange\n](https://robotics.stackexchange.com/questions/tagged/ros)  \n---|---  \n![](/custom/images/menu_left.png) [\n![Documentation](/custom/images/menu_documentation.png) ](/)\n![](/custom/images/menu_spacer.png) [ ![Browse\nSoftware](/custom/images/menu_browse_software.png)\n](https://index.ros.org/packages) ![](/custom/images/menu_spacer.png) [\n![News](/custom/images/menu_news.png) ](https://discourse.ros.org/c/general)\n![](/custom/images/menu_spacer.png) [\n![Download](/custom/images/menu_download.png) ](/ROS/Installation)\n![](/custom/images/menu_right.png)  \n  \n  * [ ROS ](/ROS)\n  * [ EnvironmentVariables ](/ROS/EnvironmentVariables)\n####  ROS 2 Documentation\nThe ROS Wiki is for ROS 1. Are you using ROS 2 ( [ Humble\n](http://docs.ros.org/en/humble/) , [ Iron ](http://docs.ros.org/en/iron/) ,\nor [ Rolling ](http://docs.ros.org/en/rolling/) )?  \n[ Check out the ROS 2 Project Documentation ](http://docs.ros.org)  \nPackage specific documentation can be found on [ index.ros.org\n](https://index.ros.org)\n#  Wiki\n  * [ Distributions ](/Distributions)\n  * [ ROS/Installation ](/ROS/Installation)\n  * [ ROS/Tutorials ](/ROS/Tutorials)\n  * [ RecentChanges ](/RecentChanges)\n  * [ ROS/EnvironmentVariables ](/ROS/EnvironmentVariables)\n#  Page\n  * Immutable Page \n  * Comments \n  * [ Info ](/action/info/ROS/EnvironmentVariables?action=info)\n  * [ Attachments ](/action/AttachFile/ROS/EnvironmentVariables?action=AttachFile)\n  * More Actions:  Raw Text  Print View  Render as Docbook  Delete Cache  \\------------------------  Check Spelling  Like Pages  Local Site Map  \\------------------------  Rename Page  Copy Page  Delete Page  \\------------------------  My Pages  Subscribe User  \\------------------------  Remove Spam  Revert to this revision  Package Pages  Sync Pages  \\------------------------  CreatePdfDocument  Load  RawFile  Save  SlideShow \n#  User\n  * [ Login ](/action/login/ROS/EnvironmentVariables?action=login)\nContents\n\n\n\n  1. Required ROS Environment Variables \n    1. ROS_ROOT \n    2. ROS_MASTER_URI \n    3. PYTHONPATH \n  2. Additional PATH Environment Variables \n    1. ROS_PACKAGE_PATH \n  3. System Data Environment Variables \n    1. ROS_HOME \n    2. ROS_LOG_DIR \n    3. ROS_TEST_RESULTS_DIR \n    4. ROS_CACHE_TIMEOUT \n  4. Additional Bash Environment Variables \n    1. ROS_LOCATIONS \n    2. ROS_WORKSPACE \n  5. Node Environment Variables \n    1. ROS_IP/ROS_HOSTNAME \n    2. ROS_NAMESPACE \n    3. ROSCONSOLE_CONFIG_FILE \n    4. Console Output Formatting \n    5. ROS_PYTHON_LOG_CONFIG_FILE \n  6. Build System Environment Variables \n    1. ROS_BOOST_ROOT \n    2. ROS_PARALLEL_JOBS \n    3. ROS_LANG_DISABLE \n    4. ROS_OS_OVERRIDE \nThere are many environment variables that you can set to affect the behavior\nof ROS. Of these, the most important to understand are ` ROS_MASTER_URI ` , `\nROS_ROOT ` , and ` ROS_PACKAGE_PATH ` as they are commonly used in the system\nand frequently mentioned in documentation.\nEnvironment variables serve a variety of roles in ROS:\n  * _Finding packages_ : First and foremost, the ` ROS_ROOT ` and ` ROS_PACKAGE_PATH ` enable ROS to locate [ packages ](/Packages) and [ stacks ](/Stacks) in the filesystem. You must also set the ` PYTHONPATH ` so that the Python interpreter can find ROS libraries. \n  * _Effecting a Node runtime_ : There are also several ROS environment variables that effect how a Node runs. The ` ROS_MASTER_URI ` is an important environment variable that tells a Node where the [ Master ](/Master) is. ` ROS_IP ` and ` ROS_HOSTNAME ` affect the network address of a Node and ` ROS_NAMESPACE ` lets you change its namespace. ` ROS_LOG_DIR ` lets you set the directory where log files are written. Many of these can be overridden by [ Remapping Arguments ](/Remapping%20Arguments) as well, which have precedence over environment variables. \n  * _Modifying the build system_ : ` ROS_BINDEPS_PATH ` , ` ROS_BOOST_ROOT ` , ` ROS_PARALLEL_JOBS ` , and ` ROS_LANG_DISABLE ` affect where libraries are found, how they are built, and which ones are built. \nThese environment variables and more are described in greater detail below.\n#  Required ROS Environment Variables\nMost systems will also have ` ROS_PACKAGE_PATH ` set, but the only required\nenvironment variables for ROS are ` ROS_ROOT ` , ` ROS_MASTER_URI ` , and `\nPYTHONPATH ` . By default these are automatically set for you by sourcing\n/opt/ros/ROSDISTRO/setup.bash. (Replace ROSDISTRO with the desired ROS\ndistribution, e.g. indigo.)\n\n\n\n##  ROS_ROOT\n` ROS_ROOT ` sets the location where the ROS core packages are installed.\n    \n    \n    export ROS_ROOT=/home/user/ros/ros\n    export PATH=$ROS_ROOT/bin:$PATH\n##  ROS_MASTER_URI\n` ROS_MASTER_URI ` is a required setting that tells nodes where they can\nlocate the master. It should be set to the XML-RPC URI of the master. Great\ncare should be taken when using ` localhost ` , as that can lead to unintended\nbehaviors with remotely launched nodes.\n    \n    \n    export ROS_MASTER_URI=http://mia:11311/\n##  PYTHONPATH\nROS requires that your ` PYTHONPATH ` be updated, **even if you don't program\nin Python!** Many ROS infrastructure tools rely on Python and need access to\nthe [ roslib ](/roslib) package for bootstrapping.\n    \n    \n    export PYTHONPATH=$PYTHONPATH:$ROS_ROOT/core/roslib/src\n#  Additional PATH Environment Variables\n##  ROS_PACKAGE_PATH\n` ROS_PACKAGE_PATH ` is an optional, but very common environment variable that\nallows you to add more ROS packages from source to your environment. `\nROS_PACKAGE_PATH ` can be composed of one or more paths separated by your\nstandard OS path separator (e.g. ':' on Unix-like systems). These _ordered_\npaths tell the ROS system where to search for more ROS packages. If there are\nmultiple packages of the same name, ROS will choose the one that appears on `\nROS_PACKAGE_PATH ` _first_ .\n    \n    \n    export ROS_PACKAGE_PATH=/home/user/ros/ros-pkg:/another/path\nNote that each entry in ` ROS_PACKAGE_PATH ` is searched recursively--all ROS\npackages below the named path will be found.\nWith the introduction of catkin, the need to manually update `\nROS_PACKAGE_PATH ` becomes obsolete, and is only necessary for backwards\ncompatibility with rosbuild packages.\n#  System Data Environment Variables\n##  ROS_HOME\n\n\n\nBy default, ROS writes data to ` ~/.ros ` . This location can be changed by\nsetting an optional ` ROS_HOME ` . You can also change the location of certain\nindividual directories in ` ~/.ros ` (e.g. ` ROS_TEST_RESULTS_DIR ` , `\nROS_LOG_DIR ` ).\n##  ROS_LOG_DIR\nBy default, ROS writes internal log files to ROS_HOME/log. If this location is\nnot writable to ROS, or if you wish for log files to be written elsewhere, set\nROS_LOG_DIR to that path.\n##  ROS_TEST_RESULTS_DIR\nDirectory that test results should be written to.\n##  ROS_CACHE_TIMEOUT\n(See [ rospack's api doc\n](http://docs.ros.org/independent/api/rospkg/html/rospack.html#efficiency-\nconsiderations) for the detail).\n[ rospack ](/rospack) re-parses the ` package.xml ` files and rebuilds the\ndependency tree on each execution. However, it maintains a cache of package\ndirectories in ` ROS_ROOT/.rospack_cache ` . This cache is updated whenever\nthere is a cache miss, or when the cache is 60 seconds old. You can change\nthis timeout by setting the environment variable ` ROS_CACHE_TIMEOUT ` , in\nseconds. Set it to 0.0 to force a cache rebuild on every invocation of `\nrospack ` .\n#  Additional Bash Environment Variables\n##  ROS_LOCATIONS\n` ROS_LOCATIONS ` is an optional environment variable that provides keyed\nnames for useful locations. It is a ` : ` separated list of key-location\npairs. Each key-location pair is separated by an ` = ` . For example:\n    \n    \n    export ROS_LOCATIONS=\"rospkg=/path/to/rospkg:stairpkg=/path/to/stairpkg\"\nThese keys can then be used in tools such as roscd.\n##  ROS_WORKSPACE\n` ROS_WORKSPACE ` is introduced by the rosinstall / rosws tools, it is set by\nsetup.sh that is generated by these tools when creating a workspace. It points\nto the folder of the workspace and is used by the rosws command as a default\ntarget of the command.\nThe roscd tool in fuerte was also changed to use that variable when called\nwithout arguments. Previously it had defaulted to change to ` ROS_ROOT ` .\n#  Node Environment Variables\n##  ROS_IP/ROS_HOSTNAME\n` ROS_IP ` and ` ROS_HOSTNAME ` are optional environment variable that sets\n\n\n\nthe declared network address of a ROS [ Node ](/Node) or tool. The options are\nmutually exclusive, if both are set ` ROS_HOSTNAME ` will take precedence. Use\n` ROS_IP ` if you are specifying an IP address, and ` ROS_HOSTNAME ` if you\nare specifying a host name. When a ROS component reports a URI to the master\nor other components, this value will be used. This setting is only needed in\nsituations where you have multiple addresses for a computer and need to force\nROS to a particular one.\nWith the exception of 'localhost', it does _not_ affect the actual bound\naddress as ROS components bind to all available network interfaces. If the\nvalue is set to localhost, the ROS component will bind only to the loopback\ninterface. This will prevent remote components from being able to talk to your\nlocal component.\n##  ROS_NAMESPACE\n` ROS_NAMESPACE ` lets you _push down_ a Node into a namespace. All of the\nnames in the Node will be resolved relative to this value, including remapped\nnames.\n##  ROSCONSOLE_CONFIG_FILE\nThis is a [ roscpp ](/roscpp) -specific environment variable. [ rosconsole\n](/rosconsole) lets you define your own configuration file that will be used\nby log4cxx, defined by the ROSCONSOLE_CONFIG_FILE environment variable.\nAnything defined in this config file will override the default config file.\nSee [ http://ros.org/doc/api/rosconsole/html/index.html\n](http://ros.org/doc/api/rosconsole/html/index.html) for more information.\n##  Console Output Formatting\nrosconsole allows you to specify how you'd like its output to show up in the\nconsole output through the ` ROSCONSOLE_FORMAT ` environment variable. The\ndefault is equivalent to:\n    \n    \n    export ROSCONSOLE_FORMAT='[${severity}] [${time}]: ${message}'\nSee [ http://ros.org/doc/api/rosconsole/html/index.html\n](http://ros.org/doc/api/rosconsole/html/index.html) for more information on\nthis package in general. You can see the list of parsed format strings [ in\nthe source code\n](http://docs.ros.org/api/rosconsole/html/namespaceros_1_1console.html#a002c0a7a505520666bc6e9362677fd93)\n.\n##  ROS_PYTHON_LOG_CONFIG_FILE\nThis is specific to [ rospy ](/rospy) , [ rosmaster ](/rosmaster) , [\nroslaunch ](/roslaunch) , and [ rostest ](/rostest) . For these tools, you can\ndefine your own Python ` logging ` configuration file to use instead of the\n\n\n\ndefault config file, which is stored in ` $ROS_ROOT/config/python_logging.conf\n` .\nFor more information, see the Python ` logging ` documentation:\n[ http://docs.python.org/library/logging.html\n](http://docs.python.org/library/logging.html)\n#  Build System Environment Variables\nIn order to understand these environment variables better, please see the\nsection on the [ ROS Build System ](/ROS/BuildSystem) .\n##  ROS_BOOST_ROOT\n` ROS_BOOST_ROOT ` is an optional environment variable that lets you override\nwhere to search for boost. If ` ROS_BOOST_ROOT ` is not set it defaults to\nusing ` ROS_BINDEPS_PATH `\n##  ROS_PARALLEL_JOBS\nThe value of this variable, if set, is passed to ` make ` when building\npackages. The idea is to let you exploit a multi-processor machine. For\nexample, if you have 8 processors / cores and want to run as many parallel\njobs as possible, as long as the system load is less than 8, by limiting the\njobs to 8 you prevent overshoot at startup time:\n    \n    \n    export ROS_PARALLEL_JOBS='-j8 -l8'\nAlternatively, you could use the ` -j ` flag with an argument to run up to 8\njobs in parallel, independent of system load:\n    \n    \n    export ROS_PARALLEL_JOBS=-j8\nWe **strongly** recommend using the ` -l ` flag to set a system load-dependent\nlimit on parallelism. Excessive parallelism in a large build can exhaust\nsystem memory.\nWhat system load is acceptable to you depends on how many cores you have: [\nhttp://blog.scoutapp.com/articles/2009/07/31/understanding-load-averages\n](http://blog.scoutapp.com/articles/2009/07/31/understanding-load-averages)\nSo 8 might be suitable for a machine with 8 cores.\n##  ROS_LANG_DISABLE\nA colon-separated list of package names for message generators / client\nlibraries that should be disabled. Message-generation will not happen for\nlanguages in this list.\nFor packages build with **catkin** you need to list the names of the message\ngenerators which should be ignored, e.g.:\n    \n\n\n\n    \n    export ROS_LANG_DISABLE=genlisp\nFor packages build with **rosbuild** you need to list the names of the message\ngenerators _as well as_ the client libraries which should be ignored, e.g.:\n    \n    \n    export ROS_LANG_DISABLE=genlisp:roslisp\nWhen ignoring message generators with rosbuild the CMake configure step will\nshow a warning that the client library (e.g. ` roslisp ` ) is not a known\nmessage generator. This warning can safely be ignored.\nNote that before disabling a language, you should first be very sure that none\nof the code you're using requires that language's bindings.\n##  ROS_OS_OVERRIDE\nFormat: \"OS_NAME:OS_VERSION_STRING:OS_CODENAME\" This will force it to detect\nUbuntu Bionic:\n    \n    \n    export ROS_OS_OVERRIDE=ubuntu:18.04:bionic\nIf defined, this will override the autodetection of an OS. This can be useful\nwhen debugging rosdep dependencies on alien platforms, when platforms are\nactually very similar and might need be forced, or of course if the\nautodetection is failing.\nWiki: ROS/EnvironmentVariables (last edited 2019-09-13 13:17:31 by  [\nBryceWilley ](/BryceWilley \"BryceWilley @ 104.238.237.109\\[104.238.237.109\\]\")\n)\nExcept where otherwise noted, the ROS wiki is licensed under the  \n[ Creative Commons Attribution 3.0\n](http://creativecommons.org/licenses/by/3.0/)\n* * *\n[ ![](/custom/images/brought_by_horiz.png) ](https://www.openrobotics.org/)\n\n\n"
  },
  {
    "id": "ackermann/userdochtml1.txt",
    "content": "[ ![Logo](../../../../_static/logo_ros-controls.png) ](../../../../index.html)\n  * [ Getting Started ](../../../getting_started/getting_started.html)\n  * [ ros2_control ](../../../ros2_control/doc/index.html)\n  * [ ros2_controllers ](../../doc/controllers_index.html)\n    * [ Guidelines and Best Practices ](../../doc/controllers_index.html#guidelines-and-best-practices)\n    * [ Controllers for Mobile Robots ](../../doc/controllers_index.html#controllers-for-mobile-robots)\n      * [ Ackermann Steering Controller ](../../ackermann_steering_controller/doc/userdoc.html)\n      * [ Bicycle Steering Controller ](../../bicycle_steering_controller/doc/userdoc.html)\n      * [ Differential Drive Controller ](../../diff_drive_controller/doc/userdoc.html)\n      * [ Steering Controllers Library ](../../steering_controllers_library/doc/userdoc.html)\n      * Tricycle Controller \n        * Velocity commands \n        * Other features \n        * Parameters \n      * [ Tricycle Steering Controller ](../../tricycle_steering_controller/doc/userdoc.html)\n    * [ Controllers for Manipulators and Other Robots ](../../doc/controllers_index.html#controllers-for-manipulators-and-other-robots)\n    * [ Broadcasters ](../../doc/controllers_index.html#broadcasters)\n    * [ Common Controller Parameters ](../../doc/controllers_index.html#common-controller-parameters)\n  * [ Demos ](../../../ros2_control_demos/doc/index.html)\n  * [ Command Line Interface ](../../../ros2_control/ros2controlcli/doc/userdoc.html)\n  * [ Simulator Integrations ](../../../simulators/simulators.html)\n  * [ Migration Guides ](../../../migration/migration.html)\n  * [ Supported Robots ](../../../supported_robots/supported_robots.html)\n  * [ Resources ](../../../resources/resources.html)\n  * [ Contributing ](../../../contributing/contributing.html)\n  * [ Project Ideas for GSoC 2024 ](../../../project_ideas.html)\n  * [ Acknowledgements ](../../../acknowledgements/acknowledgements.html)\n__ [ ROS2_Control: Rolling ](../../../../index.html)\n  * [ ](../../../../index.html)\n  * [ ros2_controllers ](../../doc/controllers_index.html)\n  * tricycle_controller \n  * [ Edit on GitHub ](https://github.com/ros-controls/ros2_controllers/blob/master/tricycle_controller/doc/userdoc.rst)\n* * *\n**You're reading the documentation for a development version. For the latest\nreleased version, please have a look at[ Iron\n](../../../../../iron/doc/ros2_controllers/tricycle_controller/doc/userdoc.html)\n. **\n#  tricycle_controller  \uf0c1\nController for mobile robots with a single double-actuated wheel, including\ntraction and steering. An example is a tricycle robot with the actuated wheel\n\n\n\nin the front and two trailing wheels on the rear axle.\nInput for control are robot base_link twist commands which are translated to\ntraction and steering commands for the tricycle drive base. Odometry is\ncomputed from hardware feedback and published.\n##  Velocity commands  \uf0c1\nThe controller works with a velocity twist from which it extracts the x\ncomponent of the linear velocity and the z component of the angular velocity.\nVelocities on other components are ignored.\n##  Other features  \uf0c1\n> Realtime-safe implementation. Odometry publishing Velocity, acceleration and\n> jerk limits Automatic stop after command timeout\n##  Parameters  \uf0c1\nThis controller uses the [ generate_parameter_library\n](https://github.com/PickNikRobotics/generate_parameter_library) to handle its\nparameters.\ntraction_joint_name (string)\n    \nName of the traction joint\nDefault: \u201c\u201d\nConstraints:\n>   * parameter is not empty\n>\n>\nsteering_joint_name (string)\n    \nName of the steering joint\nDefault: \u201c\u201d\nConstraints:\n>   * parameter is not empty\n>\n>\nwheelbase (double)\n    \nShortest distance between the front wheel and the rear axle. If this parameter\nis wrong, the robot will not behave correctly in curves.\nDefault: 0.0\nwheel_radius (double)\n    \nRadius of a wheel, i.e., wheels size, used for transformation of linear\nvelocity into wheel rotations. If this parameter is wrong the robot will move\n\n\n\nfaster or slower then expected.\nDefault: 0.0\nodom_frame_id (string)\n    \nName of the frame for odometry. This frame is parent of ` base_frame_id  `\nwhen controller publishes odometry.\nDefault: \u201codom\u201d\nbase_frame_id (string)\n    \nName of the robot\u2019s base frame that is child of the odometry frame.\nDefault: \u201cbase_link\u201d\npose_covariance_diagonal (double_array)\n    \nOdometry covariance for the encoder output of the robot for the pose. These\nvalues should be tuned to your robot\u2019s sample odometry data, but these values\nare a good place to start: ` [0.001,  0.001,  0.001,  0.001,  0.001,  0.01]  `\n.\nDefault: {0.0, 0.0, 0.0, 0.0, 0.0, 0.0}\ntwist_covariance_diagonal (double_array)\n    \nOdometry covariance for the encoder output of the robot for the speed. These\nvalues should be tuned to your robot\u2019s sample odometry data, but these values\nare a good place to start: ` [0.001,  0.001,  0.001,  0.001,  0.001,  0.01]  `\n.\nDefault: {0.0, 0.0, 0.0, 0.0, 0.0, 0.0}\nopen_loop (bool)\n    \nIf set to true the odometry of the robot will be calculated from the commanded\nvalues and not from feedback.\nDefault: false\nenable_odom_tf (bool)\n    \nPublish transformation between ` odom_frame_id  ` and ` base_frame_id  ` .\nDefault: false\nodom_only_twist (bool)\n    \nfor doing the pose integration in separate node.\nDefault: false\ncmd_vel_timeout (int)\n    \n\n\n\nTimeout in milliseconds, after which input command on ` cmd_vel  ` topic is\nconsidered staled.\nDefault: 500\npublish_ackermann_command (bool)\n    \nPublish limited commands.\nDefault: false\nvelocity_rolling_window_size (int)\n    \nSize of the rolling window for calculation of mean velocity use in odometry.\nDefault: 10\nConstraints:\n>   * greater than 0\n>\n>\nuse_stamped_vel (bool)\n    \nUse stamp from input velocity message to calculate how old the command\nactually is.\nDefault: true\ntraction.max_velocity (double)\n    \nDefault: std::numeric_limits<double>::quiet_NaN()\ntraction.min_velocity (double)\n    \nDefault: std::numeric_limits<double>::quiet_NaN()\ntraction.max_acceleration (double)\n    \nDefault: std::numeric_limits<double>::quiet_NaN()\ntraction.min_acceleration (double)\n    \nDefault: std::numeric_limits<double>::quiet_NaN()\ntraction.max_deceleration (double)\n    \nDefault: std::numeric_limits<double>::quiet_NaN()\ntraction.min_deceleration (double)\n    \nDefault: std::numeric_limits<double>::quiet_NaN()\ntraction.max_jerk (double)\n    \n\n\n\nDefault: std::numeric_limits<double>::quiet_NaN()\ntraction.min_jerk (double)\n    \nDefault: std::numeric_limits<double>::quiet_NaN()\nsteering.max_position (double)\n    \nDefault: std::numeric_limits<double>::quiet_NaN()\nsteering.min_position (double)\n    \nDefault: std::numeric_limits<double>::quiet_NaN()\nsteering.max_velocity (double)\n    \nDefault: std::numeric_limits<double>::quiet_NaN()\nsteering.min_velocity (double)\n    \nDefault: std::numeric_limits<double>::quiet_NaN()\nsteering.max_acceleration (double)\n    \nDefault: std::numeric_limits<double>::quiet_NaN()\nsteering.min_acceleration (double)\n    \nDefault: std::numeric_limits<double>::quiet_NaN()\n[ Previous ](../../steering_controllers_library/doc/userdoc.html\n\"steering_controllers_library\") [ Next\n](../../tricycle_steering_controller/doc/userdoc.html\n\"tricycle_steering_controller\")\n* * *\n\u00a9 Copyright 2024, ros2_control Development Team.\nBuilt with [ Sphinx ](https://www.sphinx-doc.org/) using a [ theme\n](https://github.com/readthedocs/sphinx_rtd_theme) provided by [ Read the Docs\n](https://readthedocs.org) .\nOther Versions  v: master\nReleases\n     [ Iron (latest) ](../../../../../iron/doc/ros2_controllers/tricycle_controller/doc/userdoc.html)\n  \n     [ Humble ](../../../../../humble/doc/ros2_controllers/tricycle_controller/doc/userdoc.html)\n  \n     [ Galactic (EOL) ](../../../../../galactic/index.html)\n  \n     [ Foxy (EOL) ](../../../../../foxy/doc/ros2_controllers/tricycle_controller/doc/userdoc.html)\n\n\n\n  \nIn Development\n     [ Master ](userdoc.html)\n\n\n"
  },
  {
    "id": "realtime_ros2/2816.txt",
    "content": "Skip to content\n\nToggle navigation\n\n[ ](https://github.com/)\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2FIntelRealSense%2Frealsense-\nros%2Fissues%2F2816)\n\n  * Product \n\n    * [ Actions  Automate any workflow  ](/features/actions)\n    * [ Packages  Host and manage packages  ](/features/packages)\n    * [ Security  Find and fix vulnerabilities  ](/features/security)\n    * [ Codespaces  Instant dev environments  ](/features/codespaces)\n    * [ Copilot  Write better code with AI  ](/features/copilot)\n    * [ Code review  Manage code changes  ](/features/code-review)\n    * [ Issues  Plan and track work  ](/features/issues)\n    * [ Discussions  Collaborate outside of code  ](/features/discussions)\n\nExplore\n\n    * [ All features ](/features)\n    * [ Documentation  ](https://docs.github.com)\n    * [ GitHub Skills  ](https://skills.github.com/)\n    * [ Blog  ](https://github.blog)\n\n  * Solutions \n\nFor\n\n    * [ Enterprise ](/enterprise)\n    * [ Teams ](/team)\n    * [ Startups ](/enterprise/startups)\n    * [ Education  ](https://education.github.com)\n\nBy Solution\n\n    * [ CI/CD & Automation ](/solutions/ci-cd/)\n    * [ DevOps ](/solutions/devops/)\n    * [ DevSecOps  ](https://resources.github.com/devops/fundamentals/devsecops/)\n\nResources\n\n    * [ Learning Pathways  ](https://resources.github.com/learn/pathways/)\n    * [ White papers, Ebooks, Webinars  ](https://resources.github.com/)\n    * [ Customer Stories ](/customer-stories)\n    * [ Partners  ](https://partner.github.com/)\n\n  * Open Source \n\n    * [ GitHub Sponsors  Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project  GitHub community articles  ](/readme)\n\nRepositories\n\n    * [ Topics ](/topics)\n    * [ Trending ](/trending)\n    * [ Collections ](/collections)\n\n  * [ Pricing ](/pricing)\n\nSearch or jump to...\n\n#  Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[ Search syntax tips ](https://docs.github.com/search-github/github-code-\nsearch/understanding-github-code-search-syntax)\n\n#  Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n##  Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [ documentation\n](https://docs.github.com/search-github/github-code-search/understanding-\ngithub-code-search-syntax) .\n\nCancel  Create saved search\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2FIntelRealSense%2Frealsense-\nros%2Fissues%2F2816)\n\n[ Sign up\n](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-\nname%3E%2F%3Crepo-\nname%3E%2Fvoltron%2Fissues_fragments%2Fissue_layout&source=header-\nrepo&source_repo=IntelRealSense%2Frealsense-ros)\n\nYou signed in with another tab or window. [ Reload ]() to refresh your\nsession.  You signed out in another tab or window. [ Reload ]() to refresh\nyour session.  You switched accounts on another tab or window. [ Reload ]() to\nrefresh your session.  Dismiss alert\n\n{{ message }}\n\n[ IntelRealSense ](/IntelRealSense) /  **[ realsense-ros\n](/IntelRealSense/realsense-ros) ** Public\n\n  * [ Notifications ](/login?return_to=%2FIntelRealSense%2Frealsense-ros)\n  * [ Fork  1.7k  ](/login?return_to=%2FIntelRealSense%2Frealsense-ros)\n  * [ Star  2.3k  ](/login?return_to=%2FIntelRealSense%2Frealsense-ros)\n\n  * [ Code  ](/IntelRealSense/realsense-ros)\n  * [ Issues  85  ](/IntelRealSense/realsense-ros/issues)\n  * [ Pull requests  6  ](/IntelRealSense/realsense-ros/pulls)\n  * [ Discussions  ](/IntelRealSense/realsense-ros/discussions)\n  * [ Actions  ](/IntelRealSense/realsense-ros/actions)\n  * [ Projects  0  ](/IntelRealSense/realsense-ros/projects)\n  * [ Wiki  ](/IntelRealSense/realsense-ros/wiki)\n  * [ Security  ](/IntelRealSense/realsense-ros/security)\n  * [ Insights  ](/IntelRealSense/realsense-ros/pulse)\n\nAdditional navigation options\n\n  * [ Code  ](/IntelRealSense/realsense-ros)\n  * [ Issues  ](/IntelRealSense/realsense-ros/issues)\n  * [ Pull requests  ](/IntelRealSense/realsense-ros/pulls)\n  * [ Discussions  ](/IntelRealSense/realsense-ros/discussions)\n  * [ Actions  ](/IntelRealSense/realsense-ros/actions)\n  * [ Projects  ](/IntelRealSense/realsense-ros/projects)\n  * [ Wiki  ](/IntelRealSense/realsense-ros/wiki)\n  * [ Security  ](/IntelRealSense/realsense-ros/security)\n  * [ Insights  ](/IntelRealSense/realsense-ros/pulse)\n\nNew issue\n\n**Have a question about this project?** Sign up for a free GitHub account to\nopen an issue and contact its maintainers and the community.\n\nPick a username\n\n    \n\nEmail Address\n\n    \n\nPassword\n\n    \nSign up for GitHub\n\nBy clicking \u201cSign up for GitHub\u201d, you agree to our [ terms of service\n](https://docs.github.com/terms) and [ privacy statement\n](https://docs.github.com/privacy) . We\u2019ll occasionally send you account\nrelated emails.\n\nAlready on GitHub? [ Sign in ](/login?return_to=%2FIntelRealSense%2Frealsense-\nros%2Fissues%2Fnew%2Fchoose) to your account\n\nJump to bottom\n\n#  [ROS2] Realsense Camera Node Error  #2816\n\nClosed\n\n[ jesusramondovale ](/jesusramondovale) opened this issue  Jul 18, 2023  \u00b7 50\ncomments\n\nClosed\n\n#  [ROS2] Realsense Camera Node Error  #2816\n\n[ jesusramondovale ](/jesusramondovale) opened this issue  Jul 18, 2023  \u00b7 50\ncomments\n\nLabels\n\n[ question  ](/IntelRealSense/realsense-ros/labels/question)\n\n##  Comments\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 18, 2023  \u2022\n\nedited\n\nI receive the following error while executing:\n\n` ros2 run realsense2_camera realsense2_camera_node `\n\non my SBC **Debix Model A (2GB RAM** ) with **Ubuntu 22.04 LTS (Kernel:\n5.15.71) and ROS2 Humble Hawksbill** installed on it.\n\n    \n    \n    [INFO] [1689686546.852992327] [camera]: RealSense ROS v4.54.1\n    [INFO] [1689686546.853310713] [camera]: Built with LibRealSense v2.54.1\n    [INFO] [1689686546.853378966] [camera]: Running with LibRealSense v2.54.1\n     18/07 15:22:26,882 WARNING [281472727836896] (d400-factory.cpp:1195) DS5 group_devices is empty.\n     18/07 15:22:27,259 ERROR [281472727836896] (librealsense-exception.h:52) xioctl(VIDIOC_S_EXT_CTRLS) failed Last Error: Invalid argument\n     18/07 15:22:27,283 WARNING [281472727836896] (rs.cpp:312) null pointer passed for argument \"device\"\n    [WARN] [1689686547.284061376] [camera]: Device 1/3 failed with exception: xioctl(VIDIOC_S_EXT_CTRLS) failed Last Error: Invalid argument\n    \n    \n\nI've installed \"succesfully\" (no problems appeared) both the SDK and RealSense\nlibs (and dependencies).\n\nThe camera is correctly plugged via USB, as it shows the **lsusb** command:\n\n` Bus 002 Device 003: ID 8086:0b3a Intel Corp. Intel(R) RealSense(TM) Depth\nCamera 435i `  \n  \n---  \n  \nThe text was updated successfully, but these errors were encountered:\n\n  \n  \n\ud83d\udc4d  1  Achllle reacted with thumbs up emoji\n\nAll reactions\n\n  * \ud83d\udc4d  1 reaction \n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 18, 2023  \u2022\n\nedited\n\nHi [ @jesusramondovale ](https://github.com/jesusramondovale) This type of\nwarning is typically related to a conflict with the kernel. Which method did\nyou use to install the librealsense SDK, please?\n\n  1. Built with packages using apt-get install \n  2. Built from source code with CMake \n  3. Built from source code with CMake and with the build flag **-DFORCE_RSUSB_BACKEND=TRUE** included in the CMake build instruction \n\nIf methods 1 and 3 are used then there is no need to apply a kernel patch\nscript to patch the kernel.\n\nIf method 2 is used then a kernel patch script called **patch-realsense-\nubuntu-lts-hwe.sh** should be run before librealsense is built in order to\npatch kernel 5.15.\n\n* * *\n\nIs the ROS wrapper able to launch without this warning if instead of using\nros2 run, you use ros2 launch?\n\n` ros2 launch realsense2_camera rs_launch.py `\n\n* * *\n\nI note that you have had previous issues with Debix at [ #2694\n](https://github.com/IntelRealSense/realsense-ros/issues/2694)  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=40&v=4)\n](/MartyG-RealSense) [ MartyG-RealSense ](/MartyG-RealSense) added the [\nquestion ](/IntelRealSense/realsense-ros/labels/question) label  Jul 18, 2023\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 19, 2023  \u2022\n\nedited\n\nHi! Thank you for your response!\n\nI've used the method number 1: install with apt-get, but.. the Linux Image\nthat I'm using is not the \"original\" Ubuntu 22.04, it's the DEBIX image they\nprovide at [ https://debix.io/Software/download.html\n](https://debix.io/Software/download.html) (Ubuntu 22.04 - Model A&B) ... soo\nI don't know exactly if I must repatch the kernel ...\n\n* * *\n\n2nd question:  \nThe same occurs if I launch with ros2 launch instead of ros2 run  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 19, 2023  \u2022\n\nedited\n\nlibrealsense installation method **1\\. Built with packages using apt-get\ninstall** does not need to have the kernel patched as the kernel patch is\nalready included in the packages. So if you have previously installed\nlibrealsense from packages and also applied a patch script to the kernel then\nthis could be a potential cause of problems.\n\nIf you are using a non-standard Linux version then building librealsense from\nsource code with the **RSUSB backend** installation method and then building\nthe ROS2 wrapper from source afterwards may work better for you than the apt-\nget package installation. This is because an RSUSB-based build of librealsense\nis not dependent on Linux versions or kernel versions and does not require\nkernel patching, so it should not matter if your Ubuntu version is a special\nDEBIX image.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 20, 2023\n\nHi!\n\nCould you please tell me exactly what must I do to build from source with \"the\nRSUSB backend installation method\", or where can I find some information about\nthat? Thank you so much!  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 20, 2023\n\nInstructions for using the **CMake** tool to build the SDK from source code\nwith the RSUSB backend method can be found at [\nIntelRealSense/librealsense#9931 (comment)\n](https://github.com/IntelRealSense/librealsense/issues/9931#issuecomment-964289692)  \n  \n---  \n  \n\u2764\ufe0f  1  jesusramondovale reacted with heart emoji\n\nAll reactions\n\n  * \u2764\ufe0f  1 reaction \n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 21, 2023  \u2022\n\nedited\n\nHi again! The librealsense was succesfully installed using the method you\nmentioned, but now I can't execute any command, what must I do?\n\nEDIT: I reinstalled the ROS Wrapper and I could use again the commands, but it\ndid exactly the same as mentioned in message 1  \nEDIT 2: trying some commands in /usr/local/bin as rs-enumerate devices:\n\nERROR [281473482933344] (librealsense-exception.h:52)\nxioctl(VIDIOC_S_EXT_CTRLS) failed Last Error: Invalid argument\n\nCould not create device - xioctl(VIDIOC_S_EXT_CTRLS) failed Last Error:\nInvalid argument . Check SDK logs for details  \nSegmentation fault (core dumped)\n\nEDIT 3: executing realsense-viewer does literally nothing (no message, not\neven an error)  \n[ ![image](https://private-user-\nimages.githubusercontent.com/71335809/255090733-f18345c5-4ca3-4eef-a9ed-12ba38d43965.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTM0NTkyMjYsIm5iZiI6MTcxMzQ1ODkyNiwicGF0aCI6Ii83MTMzNTgwOS8yNTUwOTA3MzMtZjE4MzQ1YzUtNGNhMy00ZWVmLWE5ZWQtMTJiYTM4ZDQzOTY1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA0MTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNDE4VDE2NDg0NlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNiYjE0ZWI5ZTVhMDZkYzQyYjE4YzViMjI3Njc4ZGM5ZDIyNmFlOWM0MzEzN2E3Y2E2MDMzMzNiYTE1OTY1NWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.09VNPwuZc7iLUtG1cAaQEMhouyVY1ZyAbFd21OfBaoA)\n](https://private-user-\nimages.githubusercontent.com/71335809/255090733-f18345c5-4ca3-4eef-a9ed-12ba38d43965.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTM0NTkyMjYsIm5iZiI6MTcxMzQ1ODkyNiwicGF0aCI6Ii83MTMzNTgwOS8yNTUwOTA3MzMtZjE4MzQ1YzUtNGNhMy00ZWVmLWE5ZWQtMTJiYTM4ZDQzOTY1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA0MTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNDE4VDE2NDg0NlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNiYjE0ZWI5ZTVhMDZkYzQyYjE4YzViMjI3Njc4ZGM5ZDIyNmFlOWM0MzEzN2E3Y2E2MDMzMzNiYTE1OTY1NWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.09VNPwuZc7iLUtG1cAaQEMhouyVY1ZyAbFd21OfBaoA)  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 21, 2023\n\nIf you earlier installed the SDK from packages then I recommend removing it\nfrom the computer by inputting the uninstall instruction below into the Ubuntu\nterminal.\n\n` dpkg -l | grep \"realsense\" | cut -d \" \" -f 3 | xargs sudo dpkg --purge `\n\nAfter that, use the RSUSB installation method at [\nIntelRealSense/librealsense#9931 (comment)\n](https://github.com/IntelRealSense/librealsense/issues/9931#issuecomment-964289692)\nagain and ensure that you do **not** run a kernel patch script before or after\nperforming the RSUSB installation.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 24, 2023  \u2022\n\nedited\n\nHi! I've made a clean installation from zero, and first I've re-installed the\nRSUSB using method you mention at [ IntelRealSense/librealsense#9931 (comment)\n](https://github.com/IntelRealSense/librealsense/issues/9931#issuecomment-964289692)\n, but when I execute  \n` cmake ../ -DFORCE_RSUSB_BACKEND=true -DCMAKE_BUILD_TYPE=release\n-DBUILD_EXAMPLES=true -DBUILD_GRAPHICAL_EXAMPLES=true `\n\nI'm getting the output error:\n\n    \n    \n    debix@DEBIX26:~/librealsense-2.54.1/build$ cmake ../ -DFORCE_RSUSB_BACKEND=true -DCMAKE_BUILD_TYPE=release -DBUILD_EXAMPLES=true -DBUILD_GRAPHICAL_EXAMPLES=true\n    cmake: /usr/lib/libcurl.so.4: no version information available (required by cmake)\n    -- The CXX compiler identification is unknown\n    -- The C compiler identification is GNU 11.3.0\n    -- Detecting CXX compiler ABI info\n    -- Detecting CXX compiler ABI info - failed\n    -- Detecting C compiler ABI info\n    -- Detecting C compiler ABI info - done\n    -- Check for working C compiler: /usr/bin/cc - skipped\n    -- Detecting C compile features\n    -- Detecting C compile features - done\n    -- Checking internet connection...\n    -- Internet connection identified\n    -- Info: REALSENSE_VERSION_STRING=2.54.1\n    -- Setting Unix configurations\n    -- Building libcurl enabled\n    -- Found OpenSSL: /usr/lib/aarch64-linux-gnu/libcrypto.so (found version \"3.0.2\")  \n    -- Performing Test SUPPORTS_CXX14\n    -- Performing Test SUPPORTS_CXX14 - Failed\n    CMake Error at CMake/lrs_macros.cmake:17 (message):\n      Project 'realsense2' requires C++14 or higher\n    Call Stack (most recent call first):\n      CMakeLists.txt:53 (config_cxx_flags)\n    \n    \n    -- Configuring incomplete, errors occurred!\n    See also \"/home/debix/librealsense-2.54.1/build/CMakeFiles/CMakeOutput.log\".\n    See also \"/home/debix/librealsense-2.54.1/build/CMakeFiles/CMakeError.log\".\n    \n      \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 24, 2023  \u2022\n\nedited\n\nHi [ @jesusramondovale ](https://github.com/jesusramondovale) It appears that\nthe build is failing on the error **Performing Test SUPPORTS_CXX14 - Failed**\n. The current latest version 2.54.1 of librealsense introduced a change that\nrequires C++14 support instead of the C++11 supported in versions before\n2.54.1.\n\nYou could try inputting into the CMake command line interface the instruction\nbelow:\n\n**set(CMAKE_CXX_STANDARD 14)**  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 24, 2023\n\nAdded \"set(CMAKE_CXX_STANDARD 14)\" at line 1 of CMakeLists.txt and\nCMake/lrs_macros.cmake files but nothing changed (same error output)  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 24, 2023\n\nThe Debix Model A has an i.MX 8M Plus quad-core ARM Cortex-A53 processor.\nThere have been past problems with installing librealsense on IMX8 boards. But\nuse of ` -DFORCE_RSUSB_BACKEND = true ` usually fixed them.\n\nWhich version of CMake are you using, please? Version 3.8 or newer is\nrecommended for librealsense.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 24, 2023\n\nI'm using CMake version 3.22.1, I'll try installing a newer one and doing\neverything again. Thank you!  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 24, 2023\n\n3.22 is newer than 3.8, so it should be fine.  \n  \n---  \n  \n\ud83d\ude15  1  jesusramondovale reacted with confused emoji\n\nAll reactions\n\n  * \ud83d\ude15  1 reaction \n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 24, 2023  \u2022\n\nedited\n\nSo, should it compile correctly with CMake 3.22? I don't know what can I try\nnext :(  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 24, 2023  \u2022\n\nedited\n\nThere have not been many past cases on this support forum site of boards with\nIMX8 so there are not many references about it, except that they had problems\nwith installing librealsense and RSUSB usually solved the problem.\n\nYou said that you edited the CMakeLists.txt file to add\n**set(CMAKE_CXX_STANDARD 14)** and it did not make a difference. Have you also\ntried entering it into the CMake command-line interface instead before\ninputting the CMake build instruction?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 24, 2023\n\nI don't know what you mean, if you're asking if I added the SET command before\nexecuting cmake.. yes, I did.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 24, 2023  \u2022\n\nedited\n\nInstead of a source code installation with CMake, let's try installing\nlibrealsense and the RealSense ROS wrapper from packages on Ubuntu 22.04 and\nkernel 5.15 using the wrapper's Humble install instructions.\n\n  1. First, set up the Ubuntu repositories using the instructions at the link below. \n\n[ http://wiki.ros.org/Installation/Ubuntu/Sources\n](http://wiki.ros.org/Installation/Ubuntu/Sources)\n\n  2. Then afterwards install all RealSense and RealSense ROS packages with the command below. \n\n` sudo apt install ros-humble-librealsense2* `\n\nThis installation method does not include librealsense graphical examples and\ntools such as RealSense Viewer but may enable you to get the ROS wrapper for\nHumble up and running.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 24, 2023  \u2022\n\nedited\n\n\u00b7 Succesfully setted the Ubuntu Respositories :\n\n    \n    \n    debix@DEBIX26:~$ sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" > /etc/apt/sources.list.d/ros-latest.list'\n    [sudo] password for debix: \n    debix@DEBIX26:~$ curl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add -\n    curl: /usr/lib/libcurl.so.4: no version information available (required by curl)\n    Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n    OK\n    \n\n\u00b7 Succesfully installed the librealsense2 via apt install:\n\n    \n    \n    debix@DEBIX26:~$ sudo apt install ros-humble-librealsense2*\n    Reading package lists... Done\n    Building dependency tree... Done\n    Reading state information... Done\n    Note, selecting 'ros-humble-librealsense2' for glob 'ros-humble-librealsense2*'\n    Note, selecting 'ros-humble-librealsense2-dbgsym' for glob 'ros-humble-librealsense2*'\n    The following NEW packages will be installed:\n      ros-humble-librealsense2 ros-humble-librealsense2-dbgsym\n    0 upgraded, 2 newly installed, 0 to remove and 2 not upgraded.\n    Need to get 69.1 MB of archives.\n    After this operation, 87.3 MB of additional disk space will be used.\n    Get:1 http://packages.ros.org/ros2/ubuntu jammy/main arm64 ros-humble-librealsense2 arm64 2.54.1-1jammy.20230624.065425 [3307 kB]\n    Get:2 http://packages.ros.org/ros2/ubuntu jammy/main arm64 ros-humble-librealsense2-dbgsym arm64 2.54.1-1jammy.20230624.065425 [65.7 MB]\n    Fetched 69.1 MB in 34s (2011 kB/s)                                                                                                                                                                                \n    Selecting previously unselected package ros-humble-librealsense2.\n    (Reading database ... 158886 files and directories currently installed.)\n    Preparing to unpack .../ros-humble-librealsense2_2.54.1-1jammy.20230624.065425_arm64.deb ...\n    Unpacking ros-humble-librealsense2 (2.54.1-1jammy.20230624.065425) ...\n    Selecting previously unselected package ros-humble-librealsense2-dbgsym.\n    Preparing to unpack .../ros-humble-librealsense2-dbgsym_2.54.1-1jammy.20230624.065425_arm64.deb ...\n    Unpacking ros-humble-librealsense2-dbgsym (2.54.1-1jammy.20230624.065425) ...\n    Setting up ros-humble-librealsense2 (2.54.1-1jammy.20230624.065425) ...\n    Setting up ros-humble-librealsense2-dbgsym (2.54.1-1jammy.20230624.065425) ...\n    Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n    \n\nThe output while trying to execute\n\n    \n    \n    ros2 run realsense2_camera realsense2_camera_node --ros-args -p enable_color:=false -p spatial_filter.enable:=true -p temporal_filter.enable:=true\n    Illegal instruction (core dumped)\n      \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 24, 2023\n\nWhat happens if you launch with **ros2 launch** instead of ros2 run?\n\n` ros2 launch realsense2_camera rs_launch.py enable_color:=false\nspatial_filter.enable:=true temporal_filter.enable:=true `  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 24, 2023  \u2022\n\nedited\n\n> What happens if you launch with **ros2 launch** instead of ros2 run?\n>\n> ` ros2 launch realsense2_camera rs_launch.py enable_color:=false\n> spatial_filter.enable:=true temporal_filter.enable:=true `\n\nExactly the same (Illegal instruction: core dumped)  \nMust I execute it from an exact folder? I removed the librealsense source used\nin the RSUSB installation method.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 24, 2023\n\nNo, you would not need to execute it from an exact folder. ROS commands such\nas this should be input into the ROS terminal window and not an Ubuntu\nterminal window.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 24, 2023\n\n> No, you would not need to execute it from an exact folder. ROS commands such\n> as this should be input into the ROS terminal window and not an Ubuntu\n> terminal window.\n\nWhat is the **ROS terminal** ??  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 24, 2023\n\n  1. Open a new Terminal Window (Ctrl + Alt + T). \n\n  2. In the new terminal, input **roscore** to launch the 'ROS Master'. \n\n[ ![image](https://private-user-\nimages.githubusercontent.com/41145062/255574204-dd6afa68-a002-40f3-b09c-d190b8a9c6cc.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTM0NTkyMjYsIm5iZiI6MTcxMzQ1ODkyNiwicGF0aCI6Ii80MTE0NTA2Mi8yNTU1NzQyMDQtZGQ2YWZhNjgtYTAwMi00MGYzLWIwOWMtZDE5MGI4YTljNmNjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA0MTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNDE4VDE2NDg0NlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFjOTQ2MjVkODY4ZWE0MjE0NjQyMTMyZjllMDYzMDQ0NmMyYTRiMmExYTFjODA0ZDY4MzU0MTQ4YmI2OTQ3MWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.8oybQ_FcWXi3Hqr5stF-\nVW-kpKilnYDFeMtWbzmruIs) ](https://private-user-\nimages.githubusercontent.com/41145062/255574204-dd6afa68-a002-40f3-b09c-d190b8a9c6cc.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTM0NTkyMjYsIm5iZiI6MTcxMzQ1ODkyNiwicGF0aCI6Ii80MTE0NTA2Mi8yNTU1NzQyMDQtZGQ2YWZhNjgtYTAwMi00MGYzLWIwOWMtZDE5MGI4YTljNmNjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA0MTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNDE4VDE2NDg0NlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFjOTQ2MjVkODY4ZWE0MjE0NjQyMTMyZjllMDYzMDQ0NmMyYTRiMmExYTFjODA0ZDY4MzU0MTQ4YmI2OTQ3MWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.8oybQ_FcWXi3Hqr5stF-\nVW-kpKilnYDFeMtWbzmruIs)\n\n  3. Open a second new terminal window with Ctrl - Alt - T. \n\n  4. Input the launch command into this second terminal window. \n\n` ros2 run realsense2_camera realsense2_camera_node --ros-args -p\nenable_color:=false -p spatial_filter.enable:=true -p\ntemporal_filter.enable:=true `  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 24, 2023\n\nROS2 distros don't use the slave/master system so I can't launch the \"ROS\nMaster\" on my ROS2 - humble Hawskbill ROS distro...  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 24, 2023  \u2022\n\nedited\n\nIt seems that you should enter the command below to enable ROS2 Humble.\n\n` source /opt/ros/humble/setup.bash `\n\nThis command needs to be entered every time that you are starting a new ROS2\nsession.\n\nThen try entering the ROS2 launch command.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 24, 2023\n\nI've got the ROS2 distro sourced every time I start a Linux session since I've\nwritten it in the ~./bashrc file, so... nothing changed.\n\nTried it and gave the exact same error (Illegal instruction: core dumped)  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 24, 2023\n\nAs this error has occurred on both source code and package installations, it\ndoes not seem as though it is librealsense or the ROS wrapper causing the\nproblem. It is more likely to be the board's ARM processor.\n\nSome have suggested inputting the command below to see whether it makes a\ndifference.\n\n` export OPENBLAS_CORETYPE=ARMV8 `  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 24, 2023  \u2022\n\nedited\n\nDid the export and nothing changed :(\n\n    \n    \n    debix@DEBIX26:~$ export OPENBLAS_CORETYPE=ARMV8\n    debix@DEBIX26:~$ ros2 launch realsense2_camera rs_launch.py enable_color:=false spatial_filter.enable:=true temporal_filter.enable:=true\n    Illegal instruction (core dumped)\n    \n      \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 24, 2023\n\nDo you have an Ubuntu PC computer that you can test installation on? If it\nworks on that but not on the Debix then it would likely confirm that the\nproblem is with compatibility with Debix.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 24, 2023\n\nObviously it is a Debix SBC-related problem. It worked fine on a Raspberry Pi\n4 with Ubuntu 22 and ROS2-Humble.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 24, 2023  \u2022\n\nedited\n\nHow much memory capacity has your Pi 4 got compared to the 2 GB memory that is\nusually on Debix Model A?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 24, 2023\n\nMine (Raspi Pi) has a 4GB RAM, while Debix has only 2GB.\n\nBut I'm using a 12GB swapfile  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 24, 2023\n\nAs a swapfile is virtual memory created from setting aside drive storage\nspace, it will be slower than real memory and only as fast as the access speed\nof the storage device. Swapfile memory will start being used once the real\nmemory is consumed.\n\nI would rather trust real memory capacity for running an application than\nswapfile memory. But there is not enough information about the use of IMX8\nboards with RealSense to draw a firm conclusion about whether the low amount\nof real memory is responsible for the ROS wrapper error.\n\nWould it be possible for your project to use Pi 4 instead of Debix or is Debix\na compulsory project requirement?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 24, 2023\n\nUsing a Debix SBC is a compulsory project requirement, my friend ...  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 24, 2023\n\nI note that on the Debix official website they list support for Ubuntu 20.04\nbut not 22.04 and the documentation site also does not have 22.04 information,\nsuggesting the possibility that the Model A has not been validated for use\nwith 22.04 yet.\n\n[ http://www.polyhex.net/product/embedded-motherboard/board/nxp.html?id=483\n](http://www.polyhex.net/product/embedded-motherboard/board/nxp.html?id=483)\n\n[ https://debix.io/Document/manual.html\n](https://debix.io/Document/manual.html)  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 24, 2023\n\nThey have been recently working on a Ubuntu 22.04 Image, they have released it\na month ago aproximately, as you can see in their downloads webpage: [\nhttps://debix.io/Software/download.html\n](https://debix.io/Software/download.html)  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 24, 2023  \u2022\n\nedited\n\nEven though installing librealsense and the wrapper from packages does not\ninclude graphical librealsense tools in the installation, are you able to run\ntext-based tools such as **rs-enumerate-devices** and **rs-hello-realsense**\non the Debix?\n\nOn Ubuntu, if they have been installed then they should be located in the\n**usr/local/bin** folder. If librealsense programs can run successfully then\nit would make it more likely that the problem is with ROS2 Humble or the\nRealSense ROS wrapper instead of librealsense.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 25, 2023  \u2022\n\nedited\n\nI'm going to re-isntall the Debix's Ubuntu Image from zero, and then re-do all\nthe steps you mention. I'll keep you updated, thank you so much.\n\nEDIT: this is the new error that is appearing now :\n\n    \n    \n    [100%] Linking C static library libcurl.a\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    [100%] Built target libcurl\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    [ 17%] Performing install step for 'libcurl'\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    Consolidate compiler generated dependencies of target libcurl\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    [100%] Built target libcurl\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    Install the project...\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    -- Install configuration: \"release\"\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/lib/libcurl.a\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/bin/curl-config\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/lib/pkgconfig/libcurl.pc\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/include/curl\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/include/curl/easy.h\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/include/curl/options.h\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/include/curl/typecheck-gcc.h\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/include/curl/system.h\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/include/curl/multi.h\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/include/curl/stdcheaders.h\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/include/curl/urlapi.h\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/include/curl/curlver.h\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/include/curl/curl.h\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/include/curl/mprintf.h\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/lib/cmake/CURL/CURLTargets.cmake\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/lib/cmake/CURL/CURLTargets-release.cmake\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/lib/cmake/CURL/CURLConfigVersion.cmake\n    -- Installing: /home/debix/Desktop/librealsense-2.54.1/build/libcurl/libcurl_install/lib/cmake/CURL/CURLConfig.cmake\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    [ 18%] No test step for 'libcurl'\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    [ 19%] Completed 'libcurl'\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    /usr/bin/cmake: /usr/lib/libcurl.so.4: no version information available (required by /usr/bin/cmake)\n    [ 19%] Built target libcurl\n    make: *** [Makefile:136: all] Error 2\n    \n    \n    \n\nSummarize: I can't build the librealsense from source, neither can I execute a\nsingle command as \"rs-enumerate-devices\" after installing librealsense with\nsudo apt-get... it says \"command not found\" ... this is now becoming\nembarrasing.\n\nDo you know what can I try? If not, you can close the issue if you want..  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 25, 2023\n\nA suggested solution to the **no version information available** error\nregarding libcurl is to input the command below.\n\n` unlink /usr/local/lib/libcurl.so.4 `  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 25, 2023  \u2022\n\nedited\n\nRe-installed all dependencies, Realsense SDK and ROS Wrapper. Everything\nworked fine during installation. No errors\n\nI can use the rs-enumerate-devices command, and much more (rs-*), but the\nerror given is the same as first. Where can I find the SDK logs?\n\n    \n    \n    debix@DEBIX26:~$ rs-enumerate-devices\n     25/07 09:26:26,587 ERROR [281473799996512] (librealsense-exception.h:52) xioctl(VIDIOC_S_EXT_CTRLS) failed Last Error: Invalid argument\n    Could not create device - xioctl(VIDIOC_S_EXT_CTRLS) failed Last Error: Invalid argument . Check SDK logs for details\n    Segmentation fault (core dumped)\n    \n\nI remind you that Intel Realsense Camera is correctly plugged and recognised\nby the Debix board as you can see:\n\n    \n    \n    debix@DEBIX26:~$ lsusb | grep \"Intel\"\n    Bus 002 Device 005: ID 8086:0b5c Intel Corp. Intel(R) RealSense(TM) Depth Camera 455 \n    \n      \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 25, 2023\n\nThe directory that Linux stores logs in is **/var/log**  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 26, 2023\n\nThere's no Realsense Logs in there. Does the Realsense SDK even write to logs?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 26, 2023  \u2022\n\nedited\n\nYes, the SDK can write log files.\n\n[\nhttps://github.com/IntelRealSense/librealsense/wiki/Troubleshooting-Q%26A#q-how-\ndo-i-enable-librealsense-logs\n](https://github.com/IntelRealSense/librealsense/wiki/Troubleshooting-Q%26A#q-how-\ndo-i-enable-librealsense-logs)\n\nThe documentation implies that the SDK's logging is not on by default and has\nto be enabled.\n\n[ IntelRealSense/librealsense#5851 (comment)\n](https://github.com/IntelRealSense/librealsense/issues/5851#issuecomment-586573985)\nexplains how logging can also be enabled in the RealSense Viewer tool and the\npath is displayed, though this method could not be used if you do not have the\nViewer installed on your librealsense build.\n\nAlso, on a RealSense ROS2 wrapper launch log, a log location is provided at\nthe top of the launch log on the line **All log files can be found below** ,\nfollowed by the log path for your particular computer. You would need to use `\nros2 launch ` instead of ros2 run to see this log.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 26, 2023  \u2022\n\nedited\n\nIn regards to libcurl, a CMake flag that depends on it can be set to false.\n\n` cmake ../ -DCHECK_FOR_UPDATES=OFF `  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Jul 27, 2023  \u2022\n\nedited\n\nI achieved to get rs-enumerate-devices work correctly (only doing **sudo rs-\nenumerate-devices** ) : it gives me a large list of video properties (output\nOK) but the same error persists when I try to run ROS2 camera node.......\n\n    \n    \n    debix@DEBIX26:~$ ros2 run realsense2_camera realsense2_camera_node\n    [INFO] [1690469333.859057130] [camera]: RealSense ROS v4.54.1\n    [INFO] [1690469333.859422552] [camera]: Built with LibRealSense v2.54.1\n    [INFO] [1690469333.859521736] [camera]: Running with LibRealSense v2.54.1\n     27/07 16:48:53,888 WARNING [281472518645984] (d400-factory.cpp:1195) DS5 group_devices is empty.\n     27/07 16:48:54,267 ERROR [281472518645984] (librealsense-exception.h:52) xioctl(VIDIOC_S_EXT_CTRLS) failed Last Error: Invalid argument\n     27/07 16:48:54,291 WARNING [281472518645984] (rs.cpp:312) null pointer passed for argument \"device\"\n    [WARN] [1690469334.291689435] [camera]: Device 1/3 failed with exception: xioctl(VIDIOC_S_EXT_CTRLS) failed Last Error: Invalid argument\n    [ros2run]: Segmentation fault\n    \n\nAdded 99-realsense-libsub.rules to /etc/udev/rules.d directory  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Jul 27, 2023\n\nPlease try resetting the camera at launch with **initial_reset** as it has not\nbeen mentioned yet in this case that it has been tried yet.\n\n` ros2 run realsense2_camera realsense2_camera_node --ros-args -p\ninitial_reset:=true `  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=40&v=4)\n](/MartyG-RealSense) [ MartyG-RealSense ](/MartyG-RealSense) mentioned this\nissue  Jul 27, 2023\n\n[ WARNING : (d400-factory.cpp:1195) DS5 group_devices is empty.\nIntelRealSense/librealsense#12047\n](/IntelRealSense/librealsense/issues/12047)\n\nClosed\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Aug 2, 2023\n\nHi [ @jesusramondovale ](https://github.com/jesusramondovale) Do you require\nfurther assistance with this case, please? Thanks!  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Aug 9, 2023\n\nCase closed due to no further comments received.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=40&v=4)\n](/MartyG-RealSense) [ MartyG-RealSense ](/MartyG-RealSense) closed this as [\ncompleted ](/IntelRealSense/realsense-\nros/issues?q=is%3Aissue+is%3Aclosed+archived%3Afalse+reason%3Acompleted) Aug\n9, 2023\n\n[\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=80&u=685a941db48e06cf9755dda201d84325d3088551&v=4)\n](/jesusramondovale)\n\nCopy link\n\nAuthor\n\n###\n\n**[ jesusramondovale ](/jesusramondovale) ** commented  Sep 27, 2023\n\nHey. I've got the exact same problem again...  \nInstalled RealSense SDK succesfully (sudo rs-enumerate-devices works fine)  \nbut when I execute the ROS2 Wrapper with\n\n` debix@DEBIX25:~/librealsense$ ros2 launch realsense2_camera rs_launch.py `\n\nI get this error ouput:\n\n` [INFO] [launch]: All log files can be found below\n/home/debix/.ros/log/2023-09-27-06-45-57-373454-DEBIX25-14668 [INFO] [launch]:\nDefault logging verbosity is set to INFO [INFO] [realsense2_camera_node-1]:\nprocess started with pid [14682] [realsense2_camera_node-1] [INFO]\n[1695797158.404652736] [camera.camera]: RealSense ROS v4.54.1\n[realsense2_camera_node-1] [INFO] [1695797158.404968999] [camera.camera]:\nBuilt with LibRealSense v2.54.1 [realsense2_camera_node-1] [INFO]\n[1695797158.405047252] [camera.camera]: Running with LibRealSense v2.54.1\n[realsense2_camera_node-1] 27/09 06:45:58,435 WARNING [281472476768480]\n(d400-factory.cpp:1195) DS5 group_devices is empty. [realsense2_camera_node-1]\n27/09 06:45:58,830 ERROR [281472476768480] (librealsense-exception.h:52)\nxioctl(VIDIOC_S_EXT_CTRLS) failed Last Error: Invalid argument\n[realsense2_camera_node-1] 27/09 06:45:58,837 WARNING [281472476768480]\n(rs.cpp:312) null pointer passed for argument \"device\"\n[realsense2_camera_node-1] [WARN] [1695797158.837362369] [camera.camera]:\nDevice 1/3 failed with exception: xioctl(VIDIOC_S_EXT_CTRLS) failed Last\nError: Invalid argument [ERROR] [realsense2_camera_node-1]: process has died\n[pid 14682, exit code -11, cmd\n'/home/debix/ros2_ws/install/realsense2_camera/lib/realsense2_camera/realsense2_camera_node\n--ros-args --log-level info --ros-args -r __node:=camera -r __ns:=/camera\n--params-file /tmp/launch_params_j9ko_vrh --params-file\n/tmp/launch_params_w3fbxgpj']. `\n\nI need help as soon as possible, please.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=80&v=4)\n](/MartyG-RealSense)\n\nCopy link\n\nCollaborator\n\n###\n\n**[ MartyG-RealSense ](/MartyG-RealSense) ** commented  Sep 27, 2023  \u2022\n\nedited\n\nHi [ @jesusramondovale ](https://github.com/jesusramondovale) I will reply to\nyour question at the new issue that you have created. Thanks!  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ Sign up for free ](/join?source=comment-repo) **to join this conversation on\nGitHub** . Already have an account? [ Sign in to comment\n](/login?return_to=https%3A%2F%2Fgithub.com%2FIntelRealSense%2Frealsense-\nros%2Fissues%2F2816)\n\nAssignees\n\nNo one assigned\n\nLabels\n\n[ question  ](/IntelRealSense/realsense-ros/labels/question)\n\nProjects\n\nNone yet\n\nMilestone\n\nNo milestone\n\nDevelopment\n\nNo branches or pull requests\n\n2 participants\n\n[ ![@MartyG-\nRealSense](https://avatars.githubusercontent.com/u/41145062?s=52&v=4)\n](/MartyG-RealSense) [\n![@jesusramondovale](https://avatars.githubusercontent.com/u/71335809?s=52&v=4)\n](/jesusramondovale)\n\n##  Footer\n\n[ ](https://github.com \"GitHub\") \u00a9 2024 GitHub, Inc.\n\n###  Footer navigation\n\n  * [ Terms ](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [ Privacy ](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [ Security ](/security)\n  * [ Status ](https://www.githubstatus.com/)\n  * [ Docs ](https://docs.github.com/)\n  * [ Contact ](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.\n\n"
  },
  {
    "id": "srvmsg/19647.txt",
    "content": "[ The Construct ROS Community ](/)\n\n#  [ ROS2 Service Client in C++ with Classes with Node Inheritance\n](/t/ros2-service-client-in-c-with-classes-with-node-inheritance/19647)\n\n[ Course Support  ](/c/course-support/ros2-basics-in-5-days-galactic-c/108) [\nROS2 Basics in 5 Days (C++)  ](/c/course-support/ros2-basics-in-5-days-\ngalactic-c/108)\n\n[ girishkumar.kannan  ](https://get-help.theconstruct.ai/u/girishkumar.kannan)\nOctober 3, 2022, 8:39am  1\n\nHi The Construct Team,\n\nAs I was learning **ROS2 Basics in 5 Days Galactic (C++)** , I found that\neverything except Service Client had been written with code that had Node\nInheritance. It kept bothering me as to why Service Client was not\ndemonstrated with a Node Inheritance code and I tried to come up with my own\ncode, which I got inspired from learning the Action Client code with C++.\n\nI have attached my code below. It works as expected and cleanly exits after\ncalling the service.\n\nI would like to know if this code can be generalized for a \u201cService Client\u201d\nreplacing the code without the Node Inheritance. [As of 03/10/2022], Service\nClient example in this course is demonstrated without Node Inheritance or\nClasses in C++.\n\nService Client Code **[using Node Inheritance]** :\n\n    \n    \n    #include \"rclcpp/logger.hpp\"\n    #include \"rclcpp/rclcpp.hpp\"\n    #include \"rclcpp/timer.hpp\"\n    #include \"std_srvs/srv/detail/empty__struct.hpp\"\n    #include \"std_srvs/srv/detail/set_bool__struct.hpp\"\n    #include \"std_srvs/srv/empty.hpp\"\n    #include \"std_srvs/srv/set_bool.hpp\"\n    \n    #include <chrono>\n    #include <cstdlib>\n    #include <future>\n    #include <memory>\n    \n    using namespace std::chrono_literals;\n    \n    class ServiceClient : public rclcpp::Node {\n    private:\n      rclcpp::Client<std_srvs::srv::SetBool>::SharedPtr client_;\n      rclcpp::TimerBase::SharedPtr timer_;\n      bool service_done_ = false; // inspired from action client c++ code\n    \n      void timer_callback() {\n        while (!client_->wait_for_service(1s)) {\n          if (rclcpp::ok()) {\n            RCLCPP_ERROR(\n                this->get_logger(),\n                \"Client interrupted while waiting for service. Terminating...\");\n            return;\n          }\n          RCLCPP_INFO(this->get_logger(),\n                      \"Service Unavailable. Waiting for Service...\");\n        }\n    \n        auto request = std::make_shared<std_srvs::srv::SetBool::Request>();\n        // set request variables here, if any\n        request->data = true; // comment this line if using Empty() message\n    \n        service_done_ = false; // inspired from action client c++ code\n        auto result_future = client_->async_send_request(\n            request, std::bind(&ServiceClient::response_callback, this,\n                               std::placeholders::_1));\n      }\n    \n      void response_callback(\n          rclcpp::Client<std_srvs::srv::SetBool>::SharedFuture future) {\n        auto status = future.wait_for(1s);\n        if (status == std::future_status::ready) {\n          // uncomment below line if using Empty() message\n          // RCLCPP_INFO(this->get_logger(), \"Result: success\");\n          // comment below line if using Empty() message\n          RCLCPP_INFO(this->get_logger(), \"Result: success: %i, message: %s\",\n                      future.get()->success, future.get()->message.c_str());\n          service_done_ = true;\n        } else {\n          RCLCPP_INFO(this->get_logger(), \"Service In-Progress...\");\n        }\n      }\n    \n    public:\n      ServiceClient() : Node(\"service_client\") {\n        client_ = this->create_client<std_srvs::srv::SetBool>(\"move_right\");\n        timer_ = this->create_wall_timer(\n            1s, std::bind(&ServiceClient::timer_callback, this));\n        // use below line if you do not want to use\n        // \"using namespace std::chrono_literals;\"\n        // timer_ = this->create_wall_timer(\n        //     std::chrono::milliseconds(1000),\n        //     std::bind(&ServiceClient::timer_callback, this));\n      }\n    \n      bool is_service_done() const {\n        // inspired from action client c++ code\n        return this->service_done_;\n      }\n    };\n    \n    int main(int argc, char *argv[]) {\n      rclcpp::init(argc, argv);\n    \n      // inspired from action client c++ code\n      auto service_client = std::make_shared<ServiceClient>();\n      while (!service_client->is_service_done()) {\n        rclcpp::spin_some(service_client);\n      }\n    \n      rclcpp::shutdown();\n      return 0;\n    }\n    \n    // End of Code\n    \n\nService Server Code [for reference only]:\n\n    \n    \n    #include \"geometry_msgs/msg/twist.hpp\"\n    #include \"rclcpp/rclcpp.hpp\"\n    #include \"std_srvs/srv/detail/set_bool__struct.hpp\"\n    #include \"std_srvs/srv/set_bool.hpp\"\n    \n    #include <memory>\n    \n    class ServerNode : public rclcpp::Node {\n    public:\n      ServerNode() : Node(\"service_move_right\") {\n    \n        srv_ = create_service<std_srvs::srv::SetBool>(\n            \"move_right\", std::bind(&ServerNode::moving_callback, this,\n                                    std::placeholders::_1, std::placeholders::_2));\n        publisher_ =\n            this->create_publisher<geometry_msgs::msg::Twist>(\"cmd_vel\", 10);\n      }\n    \n    private:\n      rclcpp::Service<std_srvs::srv::SetBool>::SharedPtr srv_;\n      rclcpp::Publisher<geometry_msgs::msg::Twist>::SharedPtr publisher_;\n    \n      void moving_callback(\n          const std::shared_ptr<std_srvs::srv::SetBool::Request> request,\n          const std::shared_ptr<std_srvs::srv::SetBool::Response> response) {\n        RCLCPP_INFO(this->get_logger(), \"Requested /move_right Service: %d\",\n                    request->data);\n        auto message = geometry_msgs::msg::Twist();\n        if (request->data == true) {\n          message.linear.x = 0.25;\n          message.angular.z = -0.25;\n          response->message = \"Robot Moving\";\n        } else {\n          message.linear.x = 0.0;\n          message.angular.z = 0.0;\n          response->message = \"Robot Stopped\";\n        }\n        publisher_->publish(message);\n        response->success = true;\n        RCLCPP_INFO(this->get_logger(), \"/move_right Service Response: %s\",\n                    response->message.c_str());\n      }\n    };\n    \n    int main(int argc, char *argv[]) {\n      rclcpp::init(argc, argv);\n      rclcpp::spin(std::make_shared<ServerNode>());\n      rclcpp::shutdown();\n      return 0;\n    }\n    \n    // End of Code\n    \n\nFeel free to try it out and let me know if this code is correct and can be\nused.\n\nThanks in advance,  \nGirish\n\n[ Service client node class problem ](https://get-\nhelp.robotigniteacademy.com/t/service-client-node-class-problem/25021/2)\n\n[ amalik  ](https://get-help.theconstruct.ai/u/amalik) October 3, 2022, 8:41am\n2\n\nBrilliant .  \nYour coding is awesome.\n\n1 Like\n\n[ albertoezquerro  ](https://get-help.theconstruct.ai/u/albertoezquerro)\nOctober 4, 2022, 8:03am  3\n\nHello [ @girishkumar.kannan ](/u/girishkumar.kannan) ,\n\nGreat initiative! Initially, it was added like this for simplicity, but I do\nagree it makes more sense to keep the same structure as the other examples and\nuse classes as well.\n\nI\u2019ll try to analyze and test the code today and if everything is correct I\u2019ll\nadd it to the course.\n\n2 Likes\n\n[ system  ](https://get-help.theconstruct.ai/u/system) Closed  October 9,\n2022, 8:04am  4\n\nThis topic was automatically closed 5 days after the last reply. New replies\nare no longer allowed.\n\n  * [ Home ](/)\n  * [ Categories ](/categories)\n  * [ FAQ/Guidelines ](/guidelines)\n  * [ Terms of Service ](http://www.theconstructsim.com/terms_and_conditions/)\n  * [ Privacy Policy ](http://www.theconstructsim.com/privacy_policy/)\n\nPowered by [ Discourse ](https://www.discourse.org) , best viewed with\nJavaScript enabled\n\n"
  },
  {
    "id": "missing_module/openmowerros.txt",
    "content": "Skip to content\n\nToggle navigation\n\n[ ](https://github.com/)\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2FClemensElflein%2Fopen_mower_ros)\n\n  * Product \n\n    * [ Actions  Automate any workflow  ](/features/actions)\n    * [ Packages  Host and manage packages  ](/features/packages)\n    * [ Security  Find and fix vulnerabilities  ](/features/security)\n    * [ Codespaces  Instant dev environments  ](/features/codespaces)\n    * [ Copilot  Write better code with AI  ](/features/copilot)\n    * [ Code review  Manage code changes  ](/features/code-review)\n    * [ Issues  Plan and track work  ](/features/issues)\n    * [ Discussions  Collaborate outside of code  ](/features/discussions)\n\nExplore\n\n    * [ All features ](/features)\n    * [ Documentation  ](https://docs.github.com)\n    * [ GitHub Skills  ](https://skills.github.com/)\n    * [ Blog  ](https://github.blog)\n\n  * Solutions \n\nFor\n\n    * [ Enterprise ](/enterprise)\n    * [ Teams ](/team)\n    * [ Startups ](/enterprise/startups)\n    * [ Education  ](https://education.github.com)\n\nBy Solution\n\n    * [ CI/CD & Automation ](/solutions/ci-cd/)\n    * [ DevOps ](/solutions/devops/)\n    * [ DevSecOps  ](https://resources.github.com/devops/fundamentals/devsecops/)\n\nResources\n\n    * [ Learning Pathways  ](https://resources.github.com/learn/pathways/)\n    * [ White papers, Ebooks, Webinars  ](https://resources.github.com/)\n    * [ Customer Stories ](/customer-stories)\n    * [ Partners  ](https://partner.github.com/)\n\n  * Open Source \n\n    * [ GitHub Sponsors  Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project  GitHub community articles  ](/readme)\n\nRepositories\n\n    * [ Topics ](/topics)\n    * [ Trending ](/trending)\n    * [ Collections ](/collections)\n\n  * [ Pricing ](/pricing)\n\nSearch or jump to...\n\n#  Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[ Search syntax tips ](https://docs.github.com/search-github/github-code-\nsearch/understanding-github-code-search-syntax)\n\n#  Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n##  Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [ documentation\n](https://docs.github.com/search-github/github-code-search/understanding-\ngithub-code-search-syntax) .\n\nCancel  Create saved search\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2FClemensElflein%2Fopen_mower_ros)\n\n[ Sign up\n](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-\nname%3E%2F%3Crepo-name%3E&source=header-\nrepo&source_repo=ClemensElflein%2Fopen_mower_ros)\n\nYou signed in with another tab or window. [ Reload ]() to refresh your\nsession.  You signed out in another tab or window. [ Reload ]() to refresh\nyour session.  You switched accounts on another tab or window. [ Reload ]() to\nrefresh your session.  Dismiss alert\n\n{{ message }}\n\n[ ClemensElflein ](/ClemensElflein) /  **[ open_mower_ros\n](/ClemensElflein/open_mower_ros) ** Public\n\n  * [ Notifications ](/login?return_to=%2FClemensElflein%2Fopen_mower_ros)\n  * [ Fork  103  ](/login?return_to=%2FClemensElflein%2Fopen_mower_ros)\n  * [ Star  410  ](/login?return_to=%2FClemensElflein%2Fopen_mower_ros)\n\n  * \n\n###  License\n\n[ View license ](/ClemensElflein/open_mower_ros/blob/main/LICENSE)\n\n[ 410  stars ](/ClemensElflein/open_mower_ros/stargazers) [ 103  forks\n](/ClemensElflein/open_mower_ros/forks) [ Branches\n](/ClemensElflein/open_mower_ros/branches) [ Tags\n](/ClemensElflein/open_mower_ros/tags) [ Activity\n](/ClemensElflein/open_mower_ros/activity)\n\n[ Star  ](/login?return_to=%2FClemensElflein%2Fopen_mower_ros)\n\n[ Notifications ](/login?return_to=%2FClemensElflein%2Fopen_mower_ros)\n\n  * [ Code  ](/ClemensElflein/open_mower_ros)\n  * [ Issues  13  ](/ClemensElflein/open_mower_ros/issues)\n  * [ Pull requests  9  ](/ClemensElflein/open_mower_ros/pulls)\n  * [ Actions  ](/ClemensElflein/open_mower_ros/actions)\n  * [ Projects  0  ](/ClemensElflein/open_mower_ros/projects)\n  * [ Security  ](/ClemensElflein/open_mower_ros/security)\n  * [ Insights  ](/ClemensElflein/open_mower_ros/pulse)\n\nAdditional navigation options\n\n  * [ Code  ](/ClemensElflein/open_mower_ros)\n  * [ Issues  ](/ClemensElflein/open_mower_ros/issues)\n  * [ Pull requests  ](/ClemensElflein/open_mower_ros/pulls)\n  * [ Actions  ](/ClemensElflein/open_mower_ros/actions)\n  * [ Projects  ](/ClemensElflein/open_mower_ros/projects)\n  * [ Security  ](/ClemensElflein/open_mower_ros/security)\n  * [ Insights  ](/ClemensElflein/open_mower_ros/pulse)\n\n#  ClemensElflein/open_mower_ros\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\nmain\n\n[ Branches  ](/ClemensElflein/open_mower_ros/branches) [ Tags\n](/ClemensElflein/open_mower_ros/tags)\n\n[ ](/ClemensElflein/open_mower_ros/branches) [\n](/ClemensElflein/open_mower_ros/tags)\n\nGo to file\n\nCode\n\n##  Folders and files\n\nName  |  Name  |\n\nLast commit message\n\n|\n\nLast commit date  \n  \n---|---|---|---  \n  \n##  Latest commit\n\n##  History\n\n[ 414 Commits  ](/ClemensElflein/open_mower_ros/commits/main/)\n\n[ ](/ClemensElflein/open_mower_ros/commits/main/)  \n  \n###\n\n[ .github ](/ClemensElflein/open_mower_ros/tree/main/.github \".github\")\n\n|\n\n###\n\n[ .github ](/ClemensElflein/open_mower_ros/tree/main/.github \".github\")\n\n|\n\n|  \n  \n###\n\n[ assets ](/ClemensElflein/open_mower_ros/tree/main/assets \"assets\")\n\n|\n\n###\n\n[ assets ](/ClemensElflein/open_mower_ros/tree/main/assets \"assets\")\n\n|\n\n|  \n  \n###\n\n[ img ](/ClemensElflein/open_mower_ros/tree/main/img \"img\")\n\n|\n\n###\n\n[ img ](/ClemensElflein/open_mower_ros/tree/main/img \"img\")\n\n|\n\n|  \n  \n###\n\n[ src ](/ClemensElflein/open_mower_ros/tree/main/src \"src\")\n\n|\n\n###\n\n[ src ](/ClemensElflein/open_mower_ros/tree/main/src \"src\")\n\n|\n\n|  \n  \n###\n\n[ utils ](/ClemensElflein/open_mower_ros/tree/main/utils \"utils\")\n\n|\n\n###\n\n[ utils ](/ClemensElflein/open_mower_ros/tree/main/utils \"utils\")\n\n|\n\n|  \n  \n###\n\n[ web ](/ClemensElflein/open_mower_ros/tree/main/web \"web\")\n\n|\n\n###\n\n[ web ](/ClemensElflein/open_mower_ros/tree/main/web \"web\")\n\n|\n\n|  \n  \n###\n\n[ .gitignore ](/ClemensElflein/open_mower_ros/blob/main/.gitignore\n\".gitignore\")\n\n|\n\n###\n\n[ .gitignore ](/ClemensElflein/open_mower_ros/blob/main/.gitignore\n\".gitignore\")\n\n|\n\n|  \n  \n###\n\n[ .gitmodules ](/ClemensElflein/open_mower_ros/blob/main/.gitmodules\n\".gitmodules\")\n\n|\n\n###\n\n[ .gitmodules ](/ClemensElflein/open_mower_ros/blob/main/.gitmodules\n\".gitmodules\")\n\n|\n\n|  \n  \n###\n\n[ Dockerfile ](/ClemensElflein/open_mower_ros/blob/main/Dockerfile\n\"Dockerfile\")\n\n|\n\n###\n\n[ Dockerfile ](/ClemensElflein/open_mower_ros/blob/main/Dockerfile\n\"Dockerfile\")\n\n|\n\n|  \n  \n###\n\n[ LICENSE ](/ClemensElflein/open_mower_ros/blob/main/LICENSE \"LICENSE\")\n\n|\n\n###\n\n[ LICENSE ](/ClemensElflein/open_mower_ros/blob/main/LICENSE \"LICENSE\")\n\n|\n\n|  \n  \n###\n\n[ README.md ](/ClemensElflein/open_mower_ros/blob/main/README.md \"README.md\")\n\n|\n\n###\n\n[ README.md ](/ClemensElflein/open_mower_ros/blob/main/README.md \"README.md\")\n\n|\n\n|  \n  \n###\n\n[ VERSION ](/ClemensElflein/open_mower_ros/blob/main/VERSION \"VERSION\")\n\n|\n\n###\n\n[ VERSION ](/ClemensElflein/open_mower_ros/blob/main/VERSION \"VERSION\")\n\n|\n\n|  \n  \nView all files  \n  \n##  Repository files navigation\n\n  * README \n  * License \n\n#  ROS Workspace\n\n[\n![Build](https://github.com/ClemensElflein/open_mower_ros/actions/workflows/build-\nimage.yaml/badge.svg)\n](https://github.com/ClemensElflein/open_mower_ros/actions/workflows/build-\nimage.yaml)\n\nThis folder is the ROS workspace, which should be used to build the OpenMower\nROS software. This repository contains the ROS package for controlling the\nOpenMower.\n\nThere are references to other repositories (libraries) needed to build the\nsoftware. This way, we can track the exact version of the packages used in\neach release to ensure package compatibility. Currently, the following\nrepositories are included:\n\n  * **slic3r_coverage_planner** : A coverage planner based on the Slic3r software for 3d printers. This is used to plan the mowing path. \n  * **teb_local_planner** : The local planner which allows the robot to avoid obstacles and follow the global path using kinematic constraints. \n  * **xesc_ros** : The ROS interface for the xESC motor controllers. \n\n##  Getting started\n\n###  Running on your machine\n\nOpenMower requires ROS Noetic. ( [ installation instruction\n](http://wiki.ros.org/noetic/Installation) ) There is no distributed release\npackage yet, for development and test purpose it's best to build the workspace\non your own.\n\nBy default, OpenMower is supposed to run on an ARM-based Raspberry boards: [\nhttps://x-tech.online/2022/01/installing-ros-noetic-on-a-headless-raspberry-\npi-4-with-ubuntu-20-04/ ](https://x-tech.online/2022/01/installing-ros-noetic-\non-a-headless-raspberry-pi-4-with-ubuntu-20-04/)\n\n####  Fetch Dependencies\n\nBefore building, you need to fetch this project's dependencies. The best way\nto do this is by using rosdep:\n\n    \n    \n    sudo apt install python3-rosdep\n    sudo rosdep init\n\nRun in the repository's root:\n\n    \n    \n    rosdep update\n    rosdep install --from-paths src --ignore-src --default-yes\n\n####  Build workspace\n\nJust build as any other ROS workspace: ` catkin_make ` Once it's done, another\nstep is to source workspace env vars:\n\n    \n    \n    source devel/setup.bash\n\n####  Launch OpenMower\n\nOpenMower ROS package is distributed with [ roslaunch\n](http://wiki.ros.org/roslaunch) launch files. There are few in: `\nsrc/open_mower/open_mower/launch ` , however the ` open_mower.launch ` runs\neverything needed to mow.\n\n    \n    \n    roslaunch open_mower open_mower.launch\n\nBefore you launch ` open_mower ` package, env vars with configuration have to\nbe set.\n\n    \n    \n    cp src/open_mower/config/mower_config.sh.example mower_config.sh\n    source mower_config.sh # it's expected to adjust the file\n\n###  Running in a container\n\nTBD (no automated image build yet)\n\n##  Contribution\n\n###  How to Build Using CLion IDE\n\nFirst, launch CLion in a sourced environment. For this I use the following\nbash file:\n\n    \n    \n    #!/bin/zsh\n    \n    source <your_absolute_path_to_repository>/devel/setup.zsh\n    \n    # You can find this path in the Jetbrains Toolbox\n    nohup <your_absolute_path_to_clion>/clion.sh >/dev/null 2>&1 &\n\nThen, open the ` src ` directory. CLion will prompt with the following screen:\n\n[ ![CLion CMake\nSettings](/ClemensElflein/open_mower_ros/raw/main/img/clion_cmake_settings.png)\n](/ClemensElflein/open_mower_ros/blob/main/img/clion_cmake_settings.png)\n\nCopy the settings for **Build directory** and **CMake options** . Everything\nelse can stay the same. This is all you need!\n\n#  Notes / ToDos\n\n  * For local navigation, I have tried to use the teb_local_planner. Unfortunately, it seems that (at least for me) the noetic version is VERY broken. Therefore I added the current melodic dev version as git submodule to this repo. It seems to work fine with ROS noetic and this setup here. \n  * If the map has no docking point set, planning crashes as soon as we try to approach the docking point. TODO: check, before even starting to mow. \n\n#  License\n\n[ ![Creative Commons\nLicense](https://camo.githubusercontent.com/394c08dc4b8a47e0c6eaecef98132816cccc0bf446259bde1911462f4d6f5a91/68747470733a2f2f692e6372656174697665636f6d6d6f6e732e6f72672f6c2f62792d6e632d73612f342e302f38387833312e706e67)\n](http://creativecommons.org/licenses/by-nc-sa/4.0/)  \nThis work is licensed under a [ Creative Commons Attribution-NonCommercial-\nShareAlike 4.0 International License ](http://creativecommons.org/licenses/by-\nnc-sa/4.0/) .\n\nFeel free to use the design in your private/educational projects, but don't\ntry to sell the design or products based on it without getting my consent\nfirst. The idea here is to share knowledge, not to enable others to simply\nsell my work. Thank you for understanding.\n\n##  About\n\nNo description, website, or topics provided.\n\n###  Resources\n\nReadme\n\n###  License\n\nView license\n\n[ Activity  ](/ClemensElflein/open_mower_ros/activity)\n\n###  Stars\n\n[ **410** stars ](/ClemensElflein/open_mower_ros/stargazers)\n\n###  Watchers\n\n[ **38** watching ](/ClemensElflein/open_mower_ros/watchers)\n\n###  Forks\n\n[ **103** forks ](/ClemensElflein/open_mower_ros/forks)\n\n[ Report repository ](/contact/report-\ncontent?content_url=https%3A%2F%2Fgithub.com%2FClemensElflein%2Fopen_mower_ros&report=ClemensElflein+%28user%29)\n\n##  [ Releases ](/ClemensElflein/open_mower_ros/releases)\n\nNo releases published\n\n##  [ Packages  1  ](/users/ClemensElflein/packages?repo_name=open_mower_ros)\n\n##  [ Contributors  16  ](/ClemensElflein/open_mower_ros/graphs/contributors)\n\n  * [ ![@ClemensElflein](https://avatars.githubusercontent.com/u/2864655?s=64&v=4) ](https://github.com/ClemensElflein)\n  * [ ![@midevil](https://avatars.githubusercontent.com/u/6246065?s=64&v=4) ](https://github.com/midevil)\n  * [ ![@cloudn1ne](https://avatars.githubusercontent.com/u/20051930?s=64&v=4) ](https://github.com/cloudn1ne)\n  * [ ![@jkaflik](https://avatars.githubusercontent.com/u/101614?s=64&v=4) ](https://github.com/jkaflik)\n  * [ ![@NDaub](https://avatars.githubusercontent.com/u/128170906?s=64&v=4) ](https://github.com/NDaub)\n  * [ ![@docgalaxyblock](https://avatars.githubusercontent.com/u/21227087?s=64&v=4) ](https://github.com/docgalaxyblock)\n  * [ ![@mnh-jansson](https://avatars.githubusercontent.com/u/39061161?s=64&v=4) ](https://github.com/mnh-jansson)\n  * [ ![@olliewalsh](https://avatars.githubusercontent.com/u/240140?s=64&v=4) ](https://github.com/olliewalsh)\n  * [ ![@tommarek](https://avatars.githubusercontent.com/u/556427?s=64&v=4) ](https://github.com/tommarek)\n  * [ ![@Apehaenger](https://avatars.githubusercontent.com/u/23478605?s=64&v=4) ](https://github.com/Apehaenger)\n  * [ ![@cedbossneo](https://avatars.githubusercontent.com/u/2912737?s=64&v=4) ](https://github.com/cedbossneo)\n  * [ ![@vermut](https://avatars.githubusercontent.com/u/779376?s=64&v=4) ](https://github.com/vermut)\n  * [ ![@lucasw](https://avatars.githubusercontent.com/u/1334122?s=64&v=4) ](https://github.com/lucasw)\n  * [ ![@DarthBubi](https://avatars.githubusercontent.com/u/5691837?s=64&v=4) ](https://github.com/DarthBubi)\n\n[ \\+ 2 contributors ](/ClemensElflein/open_mower_ros/graphs/contributors)\n\n##  Languages\n\n  * [ JavaScript  88.0%  ](/ClemensElflein/open_mower_ros/search?l=javascript)\n  * [ C++  9.0%  ](/ClemensElflein/open_mower_ros/search?l=c%2B%2B)\n  * [ CMake  2.1%  ](/ClemensElflein/open_mower_ros/search?l=cmake)\n  * [ C  0.2%  ](/ClemensElflein/open_mower_ros/search?l=c)\n  * [ Shell  0.2%  ](/ClemensElflein/open_mower_ros/search?l=shell)\n  * [ Dockerfile  0.2%  ](/ClemensElflein/open_mower_ros/search?l=dockerfile)\n  * Other  0.3% \n\n##  Footer\n\n[ ](https://github.com \"GitHub\") \u00a9 2024 GitHub, Inc.\n\n###  Footer navigation\n\n  * [ Terms ](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [ Privacy ](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [ Security ](/security)\n  * [ Status ](https://www.githubstatus.com/)\n  * [ Docs ](https://docs.github.com/)\n  * [ Contact ](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.\n\n"
  },
  {
    "id": "visual_marker/classignition11rende.txt",
    "content": "[ ![](https://ignitionrobotics.org/assets/doxygen/ignition_logo.svg)\n](index.html)\n\n#  Ignition Rendering\n\n##  API Reference\n\n5.0.0\n\n[ _insert_drive_file_ Tutorials ](tutorials.html) _library_books_ Classes\n_toc_ Namespaces  [ _insert_drive_file_ Files ](files.html) [ _launch_\nIgnition Website ](http://ignitionrobotics.org)\n\n  * [ Index ](classes.html)\n  * [ List ](annotated.html)\n  * [ Hierarchy ](hierarchy.html)\n  * [ Members: All ](functions.html)\n  * [ Members: Functions ](functions_func.html)\n  * [ Members: Variables ](functions_vars.html)\n  * [ Members: Typedefs ](functions_type.html)\n  * [ Members: Enumerations ](functions_enum.html)\n  * [ Members: Enumerator ](functions_eval.html)\n\n  * [ List ](namespaces.html)\n  * [ Members ](namespacemembers.html)\n  * [ Functions ](namespacemembers_func.html)\n  * [ Typedefs ](namespacemembers_type.html)\n  * [ Variables ](namespacemembers_vars.html)\n  * [ Enumerations ](namespacemembers_enum.html)\n  * [ Enumerator ](namespacemembers_eval.html)\n\n  * [ ignition ](namespaceignition.html)\n  * [ rendering ](namespaceignition_1_1rendering.html)\n  * [ Marker ](classignition_1_1rendering_1_1Marker.html)\n\n[ List of all members ](classignition_1_1rendering_1_1Marker-members.html) |\nPublic Member Functions  |  Protected Member Functions\n\nMarker Class Reference  abstract\n\nA marker geometry class. The marker's visual appearance is based on the marker\ntype specified. [ More... ](classignition_1_1rendering_1_1Marker.html#details)\n\n` #include < [ ignition/rendering/Marker ](Marker_8hh_source.html) > `\n\n##  Public Member Functions  \n  \n---  \nvirtual  |  [ ~Marker\n](classignition_1_1rendering_1_1Marker.html#a462b444c50a147538ca59c701d7316ae)\n()  \n|  Destructor.  More...  \n  \nvirtual void  |  [ AddPoint\n](classignition_1_1rendering_1_1Marker.html#a545137f216690c8bd74a579f5e1debcc)\n(double _x, double _y, double _z, const [ ignition::math::Color\n](https://ignitionrobotics.org/api/math/6.8/classignition_1_1math_1_1Color.html)\n&_color)=0  \n|  Add a point with its respective color to the marker.  More...  \n  \nvirtual void  |  [ AddPoint\n](classignition_1_1rendering_1_1Marker.html#abcf5675394e7739ba5cf8bf97fe03f2c)\n(const [ ignition::math::Vector3d\n](https://ignitionrobotics.org/api/math/6.8/namespaceignition_1_1math.html#a1f05093f5ee1a9ecdd54476792e4c206)\n&_pt, const [ ignition::math::Color\n](https://ignitionrobotics.org/api/math/6.8/classignition_1_1math_1_1Color.html)\n&_color)=0  \n|  Add a point with its respective color to the marker.  More...  \n  \nvirtual void  |  [ ClearPoints\n](classignition_1_1rendering_1_1Marker.html#a3bcbd6d459e5218ff756dbf196c2d43d)\n()=0  \n|  Clear the points of the marker, if applicable.  More...  \n  \nvirtual int32_t  |  [ Layer\n](classignition_1_1rendering_1_1Marker.html#aad6f195adf89a46d28a85337e84babd3)\n() const =0  \n|  Get the layer of this [ Marker ](classignition_1_1rendering_1_1Marker.html\n\"A marker geometry class. The marker's visual appearance is based on the\nmarker type specified...\") .  More...  \n  \nvirtual std::chrono::steady_clock::duration  |  [ Lifetime\n](classignition_1_1rendering_1_1Marker.html#ae4925fdc7832b45df96554a191d31f97)\n() const =0  \n|  Get the lifetime of this [ Marker\n](classignition_1_1rendering_1_1Marker.html \"A marker geometry class. The\nmarker's visual appearance is based on the marker type specified...\") .\nMore...  \n  \nvirtual void  |  [ SetLayer\n](classignition_1_1rendering_1_1Marker.html#a6ab41a4f71c62f8d5f14d436a166e089)\n(int32_t _layer)=0  \n|  Set the layer of this [ Marker ](classignition_1_1rendering_1_1Marker.html\n\"A marker geometry class. The marker's visual appearance is based on the\nmarker type specified...\") .  More...  \n  \nvirtual void  |  [ SetLifetime\n](classignition_1_1rendering_1_1Marker.html#acf50acc3346a7651de6c54679723914d)\n(const std::chrono::steady_clock::duration &_lifetime)=0  \n|  Set the lifetime of this [ Marker\n](classignition_1_1rendering_1_1Marker.html \"A marker geometry class. The\nmarker's visual appearance is based on the marker type specified...\") .\nMore...  \n  \nvirtual void  |  [ SetPoint\n](classignition_1_1rendering_1_1Marker.html#a6497fc79fd2f028ca890b4b23038b195)\n(unsigned int _index, const [ ignition::math::Vector3d\n](https://ignitionrobotics.org/api/math/6.8/namespaceignition_1_1math.html#a1f05093f5ee1a9ecdd54476792e4c206)\n&_value)=0  \n|  Set an existing point's vector.  More...  \n  \nvirtual void  |  [ SetType\n](classignition_1_1rendering_1_1Marker.html#a0848a2e5d0939beb566b8473e7fec72d)\n(const [ MarkerType\n](namespaceignition_1_1rendering.html#ade22213fff69cfb37d8238e8fd3073df)\n_markerType)=0  \n|  Set the render type of this [ Marker\n](classignition_1_1rendering_1_1Marker.html \"A marker geometry class. The\nmarker's visual appearance is based on the marker type specified...\") .\nMore...  \n  \nvirtual [ MarkerType\n](namespaceignition_1_1rendering.html#ade22213fff69cfb37d8238e8fd3073df) |  [\nType\n](classignition_1_1rendering_1_1Marker.html#a687d8763c93d1aefd281c4f64d8a97ec)\n() const =0  \n|  Get the render type of this [ Marker\n](classignition_1_1rendering_1_1Marker.html \"A marker geometry class. The\nmarker's visual appearance is based on the marker type specified...\") .\nMore...  \n  \n![-](closed.png) Public Member Functions inherited from [ Geometry\n](classignition_1_1rendering_1_1Geometry.html)  \nvirtual  |  [ ~Geometry\n](classignition_1_1rendering_1_1Geometry.html#af23026f6b196240a471f6e7a33581e4d)\n()  \n|  Destructor. [ More...\n](classignition_1_1rendering_1_1Geometry.html#af23026f6b196240a471f6e7a33581e4d)  \n  \nvirtual bool  |  [ HasParent\n](classignition_1_1rendering_1_1Geometry.html#a678e6abd59399644e7ea9d662e3be598)\n() const =0  \n|  Determine if this [ Geometry ](classignition_1_1rendering_1_1Geometry.html\n\"Represents a geometric shape to be rendered. \") is attached to a [ Visual\n](classignition_1_1rendering_1_1Visual.html \"Represents a visual node in a\nscene graph. A Visual is the only node that can have Geometry and other...\") .\n[ More...\n](classignition_1_1rendering_1_1Geometry.html#a678e6abd59399644e7ea9d662e3be598)  \n  \nvirtual [ MaterialPtr\n](namespaceignition_1_1rendering.html#a0a1c61d9d22ae1ff35852e769030b0e4) |  [\nMaterial\n](classignition_1_1rendering_1_1Geometry.html#ae2ed76cde5778787639fe85041dee5ce)\n() const =0  \n|  Get the material of this geometry. [ More...\n](classignition_1_1rendering_1_1Geometry.html#ae2ed76cde5778787639fe85041dee5ce)  \n  \nvirtual [ VisualPtr\n](namespaceignition_1_1rendering.html#ad78e0f29088d161daa274afdee08ade0) |  [\nParent\n](classignition_1_1rendering_1_1Geometry.html#a66d129c0b38f7dee5d094834ffc8c116)\n() const =0  \n|  Get the parent [ Visual ](classignition_1_1rendering_1_1Visual.html\n\"Represents a visual node in a scene graph. A Visual is the only node that can\nhave Geometry and other...\") . [ More...\n](classignition_1_1rendering_1_1Geometry.html#a66d129c0b38f7dee5d094834ffc8c116)  \n  \nvirtual void  |  [ RemoveParent\n](classignition_1_1rendering_1_1Geometry.html#af5090c35413cf7de0900aee61624dd36)\n()=0  \n|  Detach this [ Geometry ](classignition_1_1rendering_1_1Geometry.html\n\"Represents a geometric shape to be rendered. \") from its parent [ Visual\n](classignition_1_1rendering_1_1Visual.html \"Represents a visual node in a\nscene graph. A Visual is the only node that can have Geometry and other...\") .\nIf this [ Geometry ](classignition_1_1rendering_1_1Geometry.html \"Represents a\ngeometric shape to be rendered. \") does not have a parent, no work will be\ndone. [ More...\n](classignition_1_1rendering_1_1Geometry.html#af5090c35413cf7de0900aee61624dd36)  \n  \nvirtual void  |  [ SetMaterial\n](classignition_1_1rendering_1_1Geometry.html#afd79acea6227187a9da38b3196bd7aef)\n(const [ std::string\n](http://en.cppreference.com/w/cpp/string/basic_string.html) &_name, bool\nunique=true)=0  \n|  Set the materials of this [ Geometry\n](classignition_1_1rendering_1_1Geometry.html \"Represents a geometric shape to\nbe rendered. \") . The specified material will be retrieved from the parent [\nScene ](classignition_1_1rendering_1_1Scene.html \"Manages a single scene-\ngraph. This class updates scene-wide properties and holds the root scene\nnode...\") . If no material is registered by the given name, no work will be\ndone. [ More...\n](classignition_1_1rendering_1_1Geometry.html#afd79acea6227187a9da38b3196bd7aef)  \n  \nvirtual void  |  [ SetMaterial\n](classignition_1_1rendering_1_1Geometry.html#adb4793f0896c89c61a7927bb60ea9955)\n( [ MaterialPtr\n](namespaceignition_1_1rendering.html#a0a1c61d9d22ae1ff35852e769030b0e4)\n_material, bool unique=true)=0  \n|  Set the materials of this [ Geometry\n](classignition_1_1rendering_1_1Geometry.html \"Represents a geometric shape to\nbe rendered. \") . [ More...\n](classignition_1_1rendering_1_1Geometry.html#adb4793f0896c89c61a7927bb60ea9955)  \n  \n![-](closed.png) Public Member Functions inherited from [ Object\n](classignition_1_1rendering_1_1Object.html)  \nvirtual  |  [ ~Object\n](classignition_1_1rendering_1_1Object.html#ab5cc4f9ba1ea5c2f25bc4b1f0dac5dc5)\n()  \n|  Destructor. [ More...\n](classignition_1_1rendering_1_1Object.html#ab5cc4f9ba1ea5c2f25bc4b1f0dac5dc5)  \n  \nvirtual void  |  [ Destroy\n](classignition_1_1rendering_1_1Object.html#a84693792fa8cba90b312c0b1caf53716)\n()=0  \n|  Destroy any resources associated with this object. Invoking any other\nfunctions after destroying an object will result in undefined behavior. [\nMore...\n](classignition_1_1rendering_1_1Object.html#a84693792fa8cba90b312c0b1caf53716)  \n  \nvirtual unsigned int  |  [ Id\n](classignition_1_1rendering_1_1Object.html#af440fd9edb16553775262ac2c5fcd315)\n() const =0  \n|  Get the object ID. This ID will be unique across all objects inside a given\nscene, but necessarily true for objects across different scenes. [ More...\n](classignition_1_1rendering_1_1Object.html#af440fd9edb16553775262ac2c5fcd315)  \n  \nvirtual [ std::string\n](http://en.cppreference.com/w/cpp/string/basic_string.html) |  [ Name\n](classignition_1_1rendering_1_1Object.html#a70ee001ce76c53aebb215a9f51653ab3)\n() const =0  \n|  Get the object name. This name will be unique across all objects inside a\ngiven scene, but necessarily true for objects across different scenes. [\nMore...\n](classignition_1_1rendering_1_1Object.html#a70ee001ce76c53aebb215a9f51653ab3)  \n  \nvirtual void  |  [ PostRender\n](classignition_1_1rendering_1_1Object.html#aee73a4d9fd3bca2a941038e4a5a3879d)\n()=0  \n|  Post process this object and any of its children after rendering. [ More...\n](classignition_1_1rendering_1_1Object.html#aee73a4d9fd3bca2a941038e4a5a3879d)  \n  \nvirtual void  |  [ PreRender\n](classignition_1_1rendering_1_1Object.html#adffb56e0e545fefebf96b36f295396e9)\n()=0  \n|  Prepare this object and any of its children for rendering. This should be\ncalled for each object in a scene just before rendering, which can be achieved\nby a single call to [ Scene::PreRender\n](classignition_1_1rendering_1_1Scene.html#adffb56e0e545fefebf96b36f295396e9\n\"Prepare scene for rendering. The scene will flushing any scene changes by\ntraversing scene-graph...\") . [ More...\n](classignition_1_1rendering_1_1Object.html#adffb56e0e545fefebf96b36f295396e9)  \n  \nvirtual [ ScenePtr\n](namespaceignition_1_1rendering.html#aa53c2652ba6a30e89d915fc8847dcc47) |  [\nScene\n](classignition_1_1rendering_1_1Object.html#a7483c1d44b5981eacd31fe5ac8332e10)\n() const =0  \n|  Get the [ Scene ](classignition_1_1rendering_1_1Scene.html \"Manages a\nsingle scene-graph. This class updates scene-wide properties and holds the\nroot scene node...\") that created this object. [ More...\n](classignition_1_1rendering_1_1Object.html#a7483c1d44b5981eacd31fe5ac8332e10)  \n  \n  \n##  Protected Member Functions  \n  \n---  \n|  [ Marker\n](classignition_1_1rendering_1_1Marker.html#a98e5d6711036ca1c99d0294ecbd2be43)\n()  \n  \n##  Detailed Description\n\nA marker geometry class. The marker's visual appearance is based on the marker\ntype specified.\n\n##  Constructor & Destructor Documentation\n\n##  \u25c6  Marker()\n\n|  [ Marker ](classignition_1_1rendering_1_1Marker.html) |  (  |  |  )  |  \n---|---|---|---|---  \nprotected  \n  \n##  \u25c6  ~Marker()\n\n|  virtual ~ [ Marker ](classignition_1_1rendering_1_1Marker.html) |  (  |  |\n)  |  \n---|---|---|---|---  \nvirtual  \n  \nDestructor.\n\n##  Member Function Documentation\n\n##  \u25c6  AddPoint()  [1/2]\n\n|  virtual void AddPoint  |  (  |  double  |  __x_ ,  \n---|---|---|---  \n|  |  double  |  __y_ ,  \n|  |  double  |  __z_ ,  \n|  |  const [ ignition::math::Color\n](https://ignitionrobotics.org/api/math/6.8/classignition_1_1math_1_1Color.html)\n& |  __color_  \n|  )  |  |  \npure virtual  \n  \nAdd a point with its respective color to the marker.\n\nParameters\n\n     [in]  |  _x  |  X coordinate   \n---|---|---  \n[in]  |  _y  |  Y coordinate  \n[in]  |  _z  |  Z coordinate  \n[in]  |  _color  |  The color the point is set to  \n  \nImplemented in [ BaseMarker< T >\n](classignition_1_1rendering_1_1BaseMarker.html#aaf7f5b19c45fc71ebad36db6afa8c48a)\n, [ BaseMarker< Ogre2Geometry >\n](classignition_1_1rendering_1_1BaseMarker.html#aaf7f5b19c45fc71ebad36db6afa8c48a)\n, and [ BaseMarker< OgreGeometry >\n](classignition_1_1rendering_1_1BaseMarker.html#aaf7f5b19c45fc71ebad36db6afa8c48a)\n.\n\n##  \u25c6  AddPoint()  [2/2]\n\n|  virtual void AddPoint  |  (  |  const [ ignition::math::Vector3d\n](https://ignitionrobotics.org/api/math/6.8/namespaceignition_1_1math.html#a1f05093f5ee1a9ecdd54476792e4c206)\n& |  __pt_ ,  \n---|---|---|---  \n|  |  const [ ignition::math::Color\n](https://ignitionrobotics.org/api/math/6.8/classignition_1_1math_1_1Color.html)\n& |  __color_  \n|  )  |  |  \npure virtual  \n  \nAdd a point with its respective color to the marker.\n\nParameters\n\n     [in]  |  _pt  |  A vector containing the position of the point   \n---|---|---  \n[in]  |  _color  |  The color the point is set to  \n  \nImplemented in [ BaseMarker< T >\n](classignition_1_1rendering_1_1BaseMarker.html#a23ad75a631d7d3e6ad8143b8a346c950)\n, [ BaseMarker< Ogre2Geometry >\n](classignition_1_1rendering_1_1BaseMarker.html#a23ad75a631d7d3e6ad8143b8a346c950)\n, [ BaseMarker< OgreGeometry >\n](classignition_1_1rendering_1_1BaseMarker.html#a23ad75a631d7d3e6ad8143b8a346c950)\n, [ OgreMarker\n](classignition_1_1rendering_1_1OgreMarker.html#a5a70195978056aad793e9da61ce2974a)\n, and [ Ogre2Marker\n](classignition_1_1rendering_1_1Ogre2Marker.html#a5a70195978056aad793e9da61ce2974a)\n.\n\n##  \u25c6  ClearPoints()\n\n|  virtual void ClearPoints  |  (  |  |  )  |  \n---|---|---|---|---  \npure virtual  \n  \nClear the points of the marker, if applicable.\n\nImplemented in [ OgreMarker\n](classignition_1_1rendering_1_1OgreMarker.html#ad3b1567f005c06a0770409dfc3ba203a)\n, [ Ogre2Marker\n](classignition_1_1rendering_1_1Ogre2Marker.html#ad3b1567f005c06a0770409dfc3ba203a)\n, [ BaseMarker< T >\n](classignition_1_1rendering_1_1BaseMarker.html#a75dcfaf0d84ecfd1e001aaf27fd2984b)\n, [ BaseMarker< Ogre2Geometry >\n](classignition_1_1rendering_1_1BaseMarker.html#a75dcfaf0d84ecfd1e001aaf27fd2984b)\n, and [ BaseMarker< OgreGeometry >\n](classignition_1_1rendering_1_1BaseMarker.html#a75dcfaf0d84ecfd1e001aaf27fd2984b)\n.\n\n##  \u25c6  Layer()\n\n|  virtual int32_t Layer  |  (  |  |  )  |  const  \n---|---|---|---|---  \npure virtual  \n  \nGet the layer of this [ Marker ](classignition_1_1rendering_1_1Marker.html \"A\nmarker geometry class. The marker's visual appearance is based on the marker\ntype specified...\") .\n\nReturns\n\n     The layer of the marker \n\nImplemented in [ BaseMarker< T >\n](classignition_1_1rendering_1_1BaseMarker.html#aef350bbc86c74fd1903d570d2270d2a3)\n, [ BaseMarker< Ogre2Geometry >\n](classignition_1_1rendering_1_1BaseMarker.html#aef350bbc86c74fd1903d570d2270d2a3)\n, and [ BaseMarker< OgreGeometry >\n](classignition_1_1rendering_1_1BaseMarker.html#aef350bbc86c74fd1903d570d2270d2a3)\n.\n\n##  \u25c6  Lifetime()\n\n|  virtual std::chrono::steady_clock::duration Lifetime  |  (  |  |  )  |\nconst  \n---|---|---|---|---  \npure virtual  \n  \nGet the lifetime of this [ Marker ](classignition_1_1rendering_1_1Marker.html\n\"A marker geometry class. The marker's visual appearance is based on the\nmarker type specified...\") .\n\nReturns\n\n     The time at which the marker will be removed \n\nImplemented in [ BaseMarker< T >\n](classignition_1_1rendering_1_1BaseMarker.html#ab79616842db1c2c1f3019c4980771eeb)\n, [ BaseMarker< Ogre2Geometry >\n](classignition_1_1rendering_1_1BaseMarker.html#ab79616842db1c2c1f3019c4980771eeb)\n, and [ BaseMarker< OgreGeometry >\n](classignition_1_1rendering_1_1BaseMarker.html#ab79616842db1c2c1f3019c4980771eeb)\n.\n\n##  \u25c6  SetLayer()\n\n|  virtual void SetLayer  |  (  |  int32_t  |  __layer_ |  )  |  \n---|---|---|---|---|---  \npure virtual  \n  \nSet the layer of this [ Marker ](classignition_1_1rendering_1_1Marker.html \"A\nmarker geometry class. The marker's visual appearance is based on the marker\ntype specified...\") .\n\nParameters\n\n     [in]  |  _layer  |  Layer at which the marker will reside   \n---|---|---  \n  \nImplemented in [ BaseMarker< T >\n](classignition_1_1rendering_1_1BaseMarker.html#a8f016341c17389fdcfb0a73804ca8707)\n, [ BaseMarker< Ogre2Geometry >\n](classignition_1_1rendering_1_1BaseMarker.html#a8f016341c17389fdcfb0a73804ca8707)\n, and [ BaseMarker< OgreGeometry >\n](classignition_1_1rendering_1_1BaseMarker.html#a8f016341c17389fdcfb0a73804ca8707)\n.\n\n##  \u25c6  SetLifetime()\n\n|  virtual void SetLifetime  |  (  |  const\nstd::chrono::steady_clock::duration & |  __lifetime_ |  )  |  \n---|---|---|---|---|---  \npure virtual  \n  \nSet the lifetime of this [ Marker ](classignition_1_1rendering_1_1Marker.html\n\"A marker geometry class. The marker's visual appearance is based on the\nmarker type specified...\") .\n\nParameters\n\n     [in]  |  _lifetime  |  The time at which the marker will be removed   \n---|---|---  \n  \nImplemented in [ BaseMarker< T >\n](classignition_1_1rendering_1_1BaseMarker.html#a80f6398e2697a75863596c190090cb4d)\n, [ BaseMarker< Ogre2Geometry >\n](classignition_1_1rendering_1_1BaseMarker.html#a80f6398e2697a75863596c190090cb4d)\n, and [ BaseMarker< OgreGeometry >\n](classignition_1_1rendering_1_1BaseMarker.html#a80f6398e2697a75863596c190090cb4d)\n.\n\n##  \u25c6  SetPoint()\n\n|  virtual void SetPoint  |  (  |  unsigned int  |  __index_ ,  \n---|---|---|---  \n|  |  const [ ignition::math::Vector3d\n](https://ignitionrobotics.org/api/math/6.8/namespaceignition_1_1math.html#a1f05093f5ee1a9ecdd54476792e4c206)\n& |  __value_  \n|  )  |  |  \npure virtual  \n  \nSet an existing point's vector.\n\nParameters\n\n     [in]  |  _index  |  The index of the point   \n---|---|---  \n[in]  |  _value  |  The new positional vector of the point  \n  \nImplemented in [ BaseMarker< T >\n](classignition_1_1rendering_1_1BaseMarker.html#ae1638b8733af1e2bca74028b083b246c)\n, [ BaseMarker< Ogre2Geometry >\n](classignition_1_1rendering_1_1BaseMarker.html#ae1638b8733af1e2bca74028b083b246c)\n, [ BaseMarker< OgreGeometry >\n](classignition_1_1rendering_1_1BaseMarker.html#ae1638b8733af1e2bca74028b083b246c)\n, [ OgreMarker\n](classignition_1_1rendering_1_1OgreMarker.html#a540c2bad49688568489ca361c7fbd485)\n, and [ Ogre2Marker\n](classignition_1_1rendering_1_1Ogre2Marker.html#a540c2bad49688568489ca361c7fbd485)\n.\n\n##  \u25c6  SetType()\n\n|  virtual void SetType  |  (  |  const [ MarkerType\n](namespaceignition_1_1rendering.html#ade22213fff69cfb37d8238e8fd3073df) |\n__markerType_ |  )  |  \n---|---|---|---|---|---  \npure virtual  \n  \nSet the render type of this [ Marker\n](classignition_1_1rendering_1_1Marker.html \"A marker geometry class. The\nmarker's visual appearance is based on the marker type specified...\") .\n\nParameters\n\n     [in]  |  The  |  desired render type   \n---|---|---  \n  \nImplemented in [ OgreMarker\n](classignition_1_1rendering_1_1OgreMarker.html#af8720431f57fcaf3fdc71e5a5f9c9848)\n, [ Ogre2Marker\n](classignition_1_1rendering_1_1Ogre2Marker.html#af8720431f57fcaf3fdc71e5a5f9c9848)\n, [ BaseMarker< T >\n](classignition_1_1rendering_1_1BaseMarker.html#a47ace2ab83de948a828c993cd8d7c5e3)\n, [ BaseMarker< Ogre2Geometry >\n](classignition_1_1rendering_1_1BaseMarker.html#a47ace2ab83de948a828c993cd8d7c5e3)\n, and [ BaseMarker< OgreGeometry >\n](classignition_1_1rendering_1_1BaseMarker.html#a47ace2ab83de948a828c993cd8d7c5e3)\n.\n\n##  \u25c6  Type()\n\n|  virtual [ MarkerType\n](namespaceignition_1_1rendering.html#ade22213fff69cfb37d8238e8fd3073df) Type\n|  (  |  |  )  |  const  \n---|---|---|---|---  \npure virtual  \n  \nGet the render type of this [ Marker\n](classignition_1_1rendering_1_1Marker.html \"A marker geometry class. The\nmarker's visual appearance is based on the marker type specified...\") .\n\nReturns\n\n     The render type of the marker \n\nImplemented in [ OgreMarker\n](classignition_1_1rendering_1_1OgreMarker.html#a3e30032650ac7ec55afbd3e74978ad48)\n, [ Ogre2Marker\n](classignition_1_1rendering_1_1Ogre2Marker.html#a3e30032650ac7ec55afbd3e74978ad48)\n, [ BaseMarker< T >\n](classignition_1_1rendering_1_1BaseMarker.html#adbdf8a4bc5454664ee09c0e21113d97d)\n, [ BaseMarker< Ogre2Geometry >\n](classignition_1_1rendering_1_1BaseMarker.html#adbdf8a4bc5454664ee09c0e21113d97d)\n, and [ BaseMarker< OgreGeometry >\n](classignition_1_1rendering_1_1BaseMarker.html#adbdf8a4bc5454664ee09c0e21113d97d)\n.\n\n* * *\n\nThe documentation for this class was generated from the following file:\n\n  * [ Marker.hh ](Marker_8hh_source.html)\n\n"
  },
  {
    "id": "posepublish/depthcamerahtml.txt",
    "content": "[ ![](https://gazebosim.org/assets/doxygen/gazebo_logo.svg) ](index.html)\n\n#  Gazebo Rendering\n\n##  API Reference\n\n8.1.1\n\n[ _insert_drive_file_ Tutorials ](tutorials.html) _library_books_ Classes\n_toc_ Namespaces  [ _insert_drive_file_ Files ](files.html) [ _launch_ Gazebo\nWebsite ](http://gazebosim.org)\n\n  * [ Index ](classes.html)\n  * [ List ](annotated.html)\n  * [ Hierarchy ](hierarchy.html)\n  * [ Members: All ](functions.html)\n  * [ Members: Functions ](functions_func.html)\n  * [ Members: Variables ](functions_vars.html)\n  * [ Members: Typedefs ](functions_type.html)\n  * [ Members: Enumerations ](functions_enum.html)\n  * [ Members: Enumerator ](functions_eval.html)\n\n  * [ List ](namespaces.html)\n  * [ Members ](namespacemembers.html)\n  * [ Functions ](namespacemembers_func.html)\n  * [ Typedefs ](namespacemembers_type.html)\n  * [ Variables ](namespacemembers_vars.html)\n  * [ Enumerations ](namespacemembers_enum.html)\n  * [ Enumerator ](namespacemembers_eval.html)\n\nDepth camera\n\nThis example shows how to use the depth camera.\n\n##  Compile and run the example\n\nClone the source code, create a build directory and use ` cmake ` and ` make `\nto compile the code:\n\ngit clone https://github.com/gazebosim/gz-rendering\n\ncd gz-rendering/examples/depth_camera\n\nmkdir build\n\ncd build\n\ncmake ..\n\nmake\n\nExecute the example:\n\n./depth_camera ogre\n\nYou'll see:\n\n[Msg] Loading plugin [gz-rendering-ogre]\n\n===============================\n\nESC - Exit\n\n===============================\n\n![](depth_camera_ogre.png)\n\n##  Code\n\nMost of the code is adapted from [ Simple demo ](simple_demo.html) , here we\noutline the key differences.\n\nThe function ` buildScene() ` is responsible for creating and configuring the\ndepth camera. The main points to note are:\n\n  * The image format is set to ` PixelFormat::PF_FLOAT32_RGBA ` , \n  * Anti-alising is enabled, \n  * The depth texture is created after configuration is modified from defaults. \n\n// create camera\n\n[ DepthCameraPtr\n](namespacegz_1_1rendering.html#a7b7291d7f5d3bc1ee846763b2e7429a5 \"Shared\npointer to DepthCamera.\") camera = _scene->CreateDepthCamera(  \"camera\"  );\n\ncamera->SetLocalPosition(0.0, 0.0, 0.5);\n\ncamera->SetLocalRotation(0.0, 0.0, 0.0);\n\ncamera->SetImageWidth(800);\n\ncamera->SetImageHeight(600);\n\ncamera->SetAspectRatio(1.333);\n\ncamera->SetHFOV(GZ_PI / 2);\n\ncamera->SetImageFormat( [ PixelFormat::PF_FLOAT32_RGBA\n](namespacegz_1_1rendering.html#a60883d4958a60b91661e97027a85072aad19f2defd1732717fd1a248955f41a7f)\n);\n\ncamera->SetNearClipPlane(0.15);\n\ncamera->SetFarClipPlane(10.0);\n\ncamera->SetAntiAliasing(2);\n\ncamera->CreateDepthTexture();\n\nroot->AddChild(camera);\n\nThe window updating code is in ` GlutWindow.cc ` . The function ` initCamera()\n` registers a callback with the camera that captures a copy of the depth image\neach frame. This will later be drawn to the window in the main update loop.\n\nvoid  initCamera( [ ir::CameraPtr\n](namespacegz_1_1rendering.html#afc9577975b8c7e847de55c43bd5798c0 \"Shared\npointer to Camera.\") _camera)\n\n{\n\ng_camera = _camera;\n\nimgw = g_camera->ImageWidth();\n\nimgh = g_camera->ImageHeight();\n\nir::Image image = g_camera->CreateImage();\n\ng_image = std::make_shared<ir::Image>(image);\n\n[ ir::DepthCameraPtr\n](namespacegz_1_1rendering.html#a7b7291d7f5d3bc1ee846763b2e7429a5 \"Shared\npointer to DepthCamera.\") depthCamera =\nstd::dynamic_pointer_cast<ir::DepthCamera>(\n\ng_camera);\n\ng_connection = depthCamera->ConnectNewDepthFrame(\n\n[ std::bind ](http://en.cppreference.com/w/cpp/utility/functional/bind.html)\n(OnNewDepthFrame,\n\nstd::placeholders::_1, std::placeholders::_2, std::placeholders::_3,\n\nstd::placeholders::_4, std::placeholders::_5));\n\ng_camera->Update();\n\n}\n\nThe depth camera is capable of generating both color and depth data. This\nexample shows how to connect and receive depth data in the ` OnNewDepthFrame()\n` callback function.\n\nvoid  OnNewDepthFrame(  const  float  *_scan,\n\nunsigned  int  _width,  unsigned  int  _height,\n\nunsigned  int  /*_channels*/  ,\n\nconst  [ std::string\n](http://en.cppreference.com/w/cpp/string/basic_string.html) & /*_format*/  )\n\n{\n\nunsigned  char  *data = g_image->Data< unsigned  char  >();\n\nConvertDepthToImage(_scan, data, _width, _height);\n\n}\n\nIt converts the depth image to a RGB grayscale format and copies it from the\ndepth camera to a memory reserved in a globally scoped ` Image ` .\n\nvoid  ConvertDepthToImage(\n\nconst  float  *_data,\n\nunsigned  char  *_imageBuffer,\n\nunsigned  int  _width,  unsigned  int  _height)\n\n{\n\nfloat  maxDepth = 0;\n\nfor  (  unsigned  int  i = 0; i < _height * _width; ++i)\n\n{\n\nif  (_data[i] > maxDepth && ! [ std::isinf\n](http://en.cppreference.com/w/cpp/numeric/math/isinf.html) (_data[i]))\n\n{\n\nmaxDepth = _data[i];\n\n}\n\n}\n\ndouble  factor = 255 / maxDepth;\n\nfor  (  unsigned  int  j = 0; j < _height * _width; ++j)\n\n{\n\nunsigned  char  d =  static_cast< unsigned  char  > (255 - (_data[j] *\nfactor));\n\n_imageBuffer[j * 3] = d;\n\n_imageBuffer[j * 3 + 1] = d;\n\n_imageBuffer[j * 3 + 2] = d;\n\n}\n\n}\n\nThe other option is the [ ConnectNewRgbPointCloud\n](https://github.com/gazebosim/gz-\nrendering/blob/main/include/gz/rendering/DepthCamera.hh#L58) call that\nreceives colored point cloud data on callback.\n\nThe reason for setting the camera image format to `\nPixelFormat::PF_FLOAT32_RGBA ` is to ensure that when the ` Image ` is created\nit reserves a buffer of the correct size so that it is able to pack both color\nand depth data.\n\n"
  },
  {
    "id": "coordinate_frame/allp27html.txt",
    "content": "[ ](//www.rssing.com/index.php \"Home\")\n\n  * [ Login  ](//www.rssing.com/account.php?a=lgi&t=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Fall_p27.html)\n    * [ Account ](//www.rssing.com/account.php)\n    * [ Sign Up ](//www.rssing.com/account.php?a=reg&t=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Fall_p27.html)\n\n  * [ Home  ](//www.rssing.com/index.php)\n    * [ About Us ](//www.rssing.com/about.php)\n    * [ Catalog ](//www.rssing.com/catalog.php)\n  * [ Search  ](//www.rssing.com/search.php)\n  * [ Register RSS  ](//www.rssing.com/register.php)\n  * [ Embed RSS  ](//www.rssing.com/embed.php)\n    * [ FAQ ](//www.rssing.com/embed.php?a=whe)\n    * [ Get Embed Code ](//www.rssing.com/embed.php)\n    * [ Example: Default CSS ](//www.rssing.com/embed.php?a=ex1)\n    * [ Example: Custom CSS ](//www.rssing.com/embed.php?a=ex2)\n    * [ Example: Custom CSS per Embedding ](//www.rssing.com/embed.php?a=ex3)\n  * [ Super RSS  ](//www.rssing.com/super.php)\n    * [ Usage ](//www.rssing.com/super.php)\n    * [ View Latest ](//www.rssing.com/super.php?a=l)\n    * [ Create ](//www.rssing.com/super.php?a=crt)\n\n  * [ Contact Us  ](//www.rssing.com/contact.php)\n    * [ Technical Support ](//www.rssing.com/contact.php)\n    * [ Guest Posts/Articles ](//www.rssing.com/contact.php?r=o9)\n    * [ Report Violations ](//www.rssing.com/contact.php)\n    * [ Google Warnings ](//www.rssing.com/contact.php?r=o4)\n    * [ Article Removal Requests ](//www.rssing.com/contact.php?r=o5_0)\n    * [ Channel Removal Requests ](//www.rssing.com/contact.php?r=o5_0)\n    * [ General Questions ](//www.rssing.com/contact.php?r=o8)\n    * [ DMCA Takedown Notice ](//www.rssing.com/contact.php)\n\n[ ](//www.rssing.com/index.php)\n\n  * [ RSSing>> ](//www.rssing.com/index.php)\n    * Collections: \n    * [ RSSing ](//www.rssing.com/index.php)\n    * [ EDA ](//www.rssing.com/d/eda/index.php)\n    * [ Intel ](//www.rssing.com/d/intel/index.php)\n    * [ Mesothelioma ](//www.rssing.com/d/mesothelioma/index.php)\n    * [ SAP ](//www.rssing.com/d/sap/index.php)\n    * [ SEO ](//www.rssing.com/d/seo/index.php)\n  * [ Latest  ](//www.rssing.com/index.php?l=l)\n    * [ Articles ](//www.rssing.com/index.php?l=la)\n    * [ Channels ](//www.rssing.com/index.php?l=lc)\n    * [ Super Channels ](//www.rssing.com/index.php?l=ls)\n  * [ Popular  ](//www.rssing.com/index.php?l=p)\n    * [ Articles ](//www.rssing.com/index.php?l=pa)\n    * [ Pages ](//www.rssing.com/index.php?l=pp)\n    * [ Channels ](//www.rssing.com/index.php?l=pc)\n    * [ Super Channels ](//www.rssing.com/index.php?l=ps)\n  * [ Top Rated  ](//www.rssing.com/index.php?l=r)\n    * [ Articles ](//www.rssing.com/index.php?l=ra)\n    * [ Pages ](//www.rssing.com/index.php?l=rp)\n    * [ Channels ](//www.rssing.com/index.php?l=rc)\n    * [ Super Channels ](//www.rssing.com/index.php?l=rs)\n  * [ Trending  ](//www.rssing.com/index.php?l=t)\n    * [ Articles ](//www.rssing.com/index.php?l=ta)\n    * [ Pages ](//www.rssing.com/index.php?l=tp)\n    * [ Channels ](//www.rssing.com/index.php?l=tc)\n    * [ Super Channels ](//www.rssing.com/index.php?l=ts)\n\n[ ](javascript:;)\n\n[ ](javascript:;) Switch Editions?  \n[ Cancel ](javascript:;)\n\n[ ](javascript:;)\n\n[ ](javascript:;)\n\nSharing:\n\nTitle:\n\nURL:\n\n[ Copy Share URL ](javascript:;)\n\n[ ](javascript:; \"Share Page\")\n\n[ English  ](javascript:; \"English\")\n\nRSSing.com\n\n[ RSSing>> ](//www.rssing.com/index.php) [ Latest\n](//www.rssing.com/index.php?l=l) [ Popular ](//www.rssing.com/index.php?l=p)\n[ Top Rated ](//www.rssing.com/index.php?l=r) [ Trending\n](//www.rssing.com/index.php?l=t)\n\nChannel: ROS Answers: Open Source Q&A Forum - RSS feed  \n\n[ NSFW?  ](javascript:; \"Mark channel Not-Safe-For-Work\")\n\n[ Claim  ](javascript:; \"Claim Chan\")\n\n[ ](javascript:; \"Share Chan\")\n\n[ 0  ](javascript:; \"Show Rating\")\n\n  \n  \n\n[ X ](javascript:;) Mark channel Not-Safe-For-Work?  [ cancel ](javascript:;)\n[ confirm ](javascript:;) NSFW Votes:  (  0  votes)\n\n[ X ](javascript:;) Are you the publisher? [ Claim\n](//www.rssing.com/account.php?a=mmc&r=36149602) or [ contact us\n](//www.rssing.com/contact.php?a=ssm&r=o5&u=//question2177.rssing.com/chan-36149602/all_p27.html)\nabout this channel.\n\n[ X ](javascript:;) 0\n\nShowing article 521 to 540 of 844 in channel 36149602  \nChannel Details:\n\n  * Title: ROS Answers: Open Source Q&A Forum - RSS feed \n  * Channel Number: 36149602 \n  * Language: English \n  * Registered On: November 3, 2014, 11:44 am \n  * Number of Articles: 844 \n  * Latest Snapshot: July 5, 2019, 5:22 am \n  * RSS URL: [ http://answers.ros.org/feeds/rss/?tags=tf ](javascript:;)\n  * Publisher: [ http://answers.ros.org/questions/ ](javascript:;)\n  * Description: Open source question and answer forum written in Python and Django \n  * Catalog: [ //question2177.rssing.com/catalog.php?indx=36149602 ](//question2177.rssing.com/catalog.php?indx=36149602)\n\n[ Remove ADS ](//www.rssing.com/account.php?r=27)\n\nViewing all 844 articles\n\n[ ](//question2177.rssing.com/chan-36149602/all_p26.html \"older\") First Page\n...  Page 25  Page 26  Page 27  Page 28  Page 29  ...  Last Page  [\n](//question2177.rssing.com/chan-36149602/all_p28.html \"newer\")\n\n[ Browse latest ](//question2177.rssing.com/chan-36149602/index-latest.php) [\nView live ](//question2177.rssing.com/chan-36149602/article521-live.html)\n\n#  [ Can tf/tf2 resolve \"hidden transforms\" ?\n](//question2177.rssing.com/chan-36149602/article521-live.html)\n\nAugust 6, 2017, 8:46 am\n\n[ _\u226b_ Next: TransformListener has unconnected trees\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a522 \"Next\nArticle\")\n\n[ _\u226a_ Previous: ros::moveit adding rotation to xyz-coordinates\n](//question2177.rssing.com/chan-36149602/all_p26.html#c36149602a520 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle521-live.html\n\"Article Support\")\n\nHowdy folks, I have question relating to the following transform tree:\n**[/nav_frame]->[/base_link]->[/sensor_platform] -> [/IMU_AHRS]** The sensor\nplatform is literally a platform that has sensors mounted on it (GPS antenna,\nIMU-AHRS, etc.) and is attached to the robotic platform (/base_link). The\nnav_frame is a local ENU frame in which I do my navigation computations: it's\nplaced on the WGS84 ellipsoid at the same location as the base_link, and it\nalways points north. I got an IMU-AHRS system (with magnetometer and world\nmagnetic map) mounted on the sensor_platform that I will use to resolve the\ntransformation between nav_frame and base_link. So, I have the following\nsituation: [/nav_frame]->[/base_link] UNKNOWN, this is what I need to resolve\n[/base_link] ->[/sensor_platform] is a known and fixed transform\n[/sensor_platform] -> [/IMU_AHRS] is a known and fixed transform **My\nQuestion: Can tf (or tf2) somehow automatically (internally) resolve the\nhidden transform [/nav_frame]->[base_link] when it's given the measured\ntransform [/nav_frame] -> [/IMU_AHRS] as produced by the IMU-AHRS system, or\ndo I (as the programmer) have to explicitly compute this transform (which is\neasy enough using the IMU-AHRS measurements and the fixed transforms relating\nthe IMU_AHRS frame w.r.t. the base_link) and explicitly publish this as the\n[/nave_frame] -> [/base_link] transform?** if tf/tf2 can do this \"internally\",\nthen how? Thanks in advance Best regards, Galto\n\n\u21a7\n\n[ Search ](javascript:;)\n\nRSSing.com\n\n* * *\n\n\u21a7\n\n#  [ TransformListener has unconnected trees\n](//question2177.rssing.com/chan-36149602/article522-live.html)\n\nAugust 8, 2017, 7:07 am\n\n[ _\u226b_ Next: what are quaternions and how can I use them?\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a523 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Can tf/tf2 resolve \"hidden transforms\" ?\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a521 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle522-live.html\n\"Article Support\")\n\nI have multiple tf frames which some of are dynamically published by the\nrobot_state_publisher and some are static transformations. When using the\ntf.TransformListener i get the error message that there are two or more\nunconnected trees. Running rosrun tf view_frames also shows the unconnected\ntrees. However, rosrun rqt_tf_tree rqt_tf_tree shows the correct tf tree, rviz\ncan show the correct tf tree and even rosrun tf tf_echo source_frame\ndestination_frame returns the transformation values. What am I doing wrong?\nEDIT1: rosrun tf tf_monitor source_frame target_frame returns the correct\nchain, however every frame is published by \"unknown publisher\" and the only\nbroadcaster node is called \"unknown\". Could this be the reason why view_frames\nor the TransformListener are failing? EDIT2: TF2 can do the transformation\nwith the following piece of code: tf_buffer = tf2_ros.Buffer() tf2_listener =\ntf2_ros.TransformListener(tf_buffer) tf_buffer.lookup_transform('world',\n'halcon_camera', rospy.Time())\n\n\u21a7\n\n#  [ what are quaternions and how can I use them?\n](//question2177.rssing.com/chan-36149602/article523-live.html)\n\nMay 17, 2011, 7:59 am\n\n[ _\u226b_ Next: tf time out error : hector slam\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a524 \"Next\nArticle\")\n\n[ _\u226a_ Previous: TransformListener has unconnected trees\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a522 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle523-live.html\n\"Article Support\")\n\nI have seen quaternions in tf and bullet but I don't know what they are or how\nto use them.\n\n\u21a7\n\n#  [ tf time out error : hector slam\n](//question2177.rssing.com/chan-36149602/article524-live.html)\n\nAugust 9, 2017, 1:30 pm\n\n[ _\u226b_ Next: how to Transform Pointcloud2 with tf\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a525 \"Next\nArticle\")\n\n[ _\u226a_ Previous: what are quaternions and how can I use them?\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a523 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle524-live.html\n\"Article Support\")\n\nI'm suffering tf time out error. I want to use hector slam on a UAV(quad\ncopter) with a Lidar First, the error output on the terminal looks like the\nbelow [ INFO] [1502340821.590928774]: lookupTransform base_stabilized to laser\ntimed out. Could not transform laser scan into base_frame. [ INFO]\n[1502340822.096555365]: lookupTransform base_stabilized to laser timed out.\nCould not transform laser scan into base_frame. [ WARN]\n[1502340822.584208719]: No transform between frames /map and scanmatcher_frame\navailable after 20.002080 seconds of waiting. This warning only prints once. [\nINFO] [1502340822.601611575]: lookupTransform base_stabilized to laser timed\nout. Could not transform laser scan into base_frame. I set tf setting as\nfollows. map -> (scanmatcher_frame , static) -> base_stabilized (odom)\nbase_stabilized -> base_link (imu_attitude node in order to describe\nroll,pitch motion) base_link -> laser (static tf publisher) I think I've got\ncorrect at the tf setting. and all topics have proper time stamps. I'll let\nyou see the **launch file** that I use and **tf tree**.  the tf tree is given\n.. [here](https://drive.google.com/open?id=0B1HgCksxRA2ldnR3YXAzR19uYWM)\nthanks in advance!\n\n\u21a7\n\n#  [ how to Transform Pointcloud2 with tf\n](//question2177.rssing.com/chan-36149602/article525-live.html)\n\nAugust 12, 2017, 5:33 am\n\n[ _\u226b_ Next: Two 6 DOF robots on scene\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a526 \"Next\nArticle\")\n\n[ _\u226a_ Previous: tf time out error : hector slam\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a524 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle525-live.html\n\"Article Support\")\n\nHi, I tried to run the python code on this link\nhttp://answers.ros.org/question/9103/how-to-transform-pointcloud2-with-tf/ and\ngot such an error below : Traceback(most recent call last): File\n\"/home/ahmet/catkin_ws/src/laserTF/src/laserTransform.py\", line 26 in module>\nlistener.waitForTransform(\"/base_link\", \"/odom\" ,\nrospy.Time(0),rospy.Duration(1.0)) tf.Exception: . canTransform returned after\n1.00039 timeout was 1. How to solve this problem ? Please help me this time .\n@jayess\n\n\u21a7\n\n\u21a7\n\n#  [ Two 6 DOF robots on scene\n](//question2177.rssing.com/chan-36149602/article526-live.html)\n\nAugust 12, 2017, 6:09 am\n\n[ _\u226b_ Next: Best practices for tf in kinetic?\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a527 \"Next\nArticle\")\n\n[ _\u226a_ Previous: how to Transform Pointcloud2 with tf\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a525 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle526-live.html\n\"Article Support\")\n\nHello everybody/ I'm new in ros and possible my question is very stupid. But\ni've read huge amount of tutotials and posts on forum and still have\nquestions. I'm really stack with my task to setup 2 6dof robot on scene, I\ncant figure out how to publush transform between robot base and world when\neach robot has it own namespace and tf_prefix. So what I have: I have two 6dof\nrobot setup on table, camera and the box. I whant to detect box from camera\nand publish box's coordinates in table/world coordinate system. Each robot\nlisten there coordinates topic and transform coordinates of the box in there\nown frame, then robot touch a box. What I did. I can get the position of box\nin camera frame and tranform it robot frame. But it transform likes robot base\nin the [0,0,0] world frame. So I cant publish in TF static transformation from\nrobot base to the zero point, I run static_tranform_publisher node for that\nbut in tf tree I can't see the root node. So my questions is: \\- if there some\nrecommended way to use namespases with MoveIt and Rviz? \\- how could I build\nand set the \"world\" for scene from several frames. Thanks a lot in advance and\nsorry if it common question. Any information about topic would be very\nappripricate.\n\n\u21a7\n\n#  [ Best practices for tf in kinetic?\n](//question2177.rssing.com/chan-36149602/article527-live.html)\n\nAugust 15, 2017, 10:54 am\n\n[ _\u226b_ Next: Best practices for tf?\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a528 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Two 6 DOF robots on scene\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a526 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle527-live.html\n\"Article Support\")\n\nI see other similar questions here, but nothing that answered my specific\ninquiries about tf: 1\\. Is it recommended to use a separate tf server (as in\nits own node)? 1\\. Should URDF be used for statically-linked robots like\nquadcopters with a few attached sensors? 1\\. When is a tf_state_publisher used\n(from a launch file, say), as opposed to a tf broadcaster in code?\n\n\u21a7\n\n#  [ Best practices for tf?\n](//question2177.rssing.com/chan-36149602/article528-live.html)\n\nAugust 15, 2017, 10:52 am\n\n[ _\u226b_ Next: How to transform the whole /tf frame?\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a529 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Best practices for tf in kinetic?\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a527 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle528-live.html\n\"Article Support\")\n\nI see other similar questions here, but nothing that answered my specific\ninquiries about tf: 1\\. Is it recommended to use a separate tf server (as in\nits own node)? 1\\. Should URDF be used for statically-linked robots like\nquadcopters with a few attached sensors? 1\\. When is a tf_state_publisher used\n(from a launch file, say), as opposed to a tf broadcaster in code?\n\n\u21a7\n\n[ Search ](javascript:;)\n\nRSSing.com\n\n* * *\n\n#  [ How to transform the whole /tf frame?\n](//question2177.rssing.com/chan-36149602/article529-live.html)\n\nMay 21, 2014, 1:49 am\n\n[ _\u226b_ Next: Unable to lookup tf transform\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a530 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Best practices for tf?\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a528 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle529-live.html\n\"Article Support\")\n\nGiven I have an occupancy grid map which I would want to transform with a\ncertain [tx,ty,theta] transformation. How do I do it? The tf tree is posted\nbelow and also the rviz which contains the grid map. My ultimate goal is that\nI would have two occupancy grid maps which I would have to apply a\ntransformation to either one of them so that they can be overlapped -- Map\nMerging. I'm looking for the mechanism in ROS where I can transform the map,\nparticularly the whole /tf frame so that even the robot's pose will be\ntransformed into a new coordinate frame. http://postimg.org/image/d4xd3d39p/\nhttp://postimg.org/image/vrdqce6x9/\n\n\u21a7\n\n\u21a7\n\n#  [ Unable to lookup tf transform\n](//question2177.rssing.com/chan-36149602/article530-live.html)\n\nAugust 23, 2017, 7:39 am\n\n[ _\u226b_ Next: nav_msgs/Odometry to tf2_msgs/TFMessage\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a531 \"Next\nArticle\")\n\n[ _\u226a_ Previous: How to transform the whole /tf frame?\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a529 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle530-live.html\n\"Article Support\")\n\nHi, I'm unable to lookup tf transforms in my C++ node for some reason, unless\nthe parent and child are the same. I have done this many times before and\nchecked with the tutorials and wikis but am not having any luck. The tf tree\ndisplays fine in RVIZ as well as command line with the tf_echo. I've tried\nmultiple different rosbags that worked fine in other ROS nodes but nothing is\nworking with this node. What is different is that this time I am working with\na ROS package where there are no classes, everything is in functions but I\ndon't think that should matter because that is how the tutorial is done. Here\nis a code snippet: void laserCloudHandler(const\nsensor_msgs::PointCloud2ConstPtr &laserCloudMsg) { tf::TransformListener\ntf_listener; if (tf_listener.waitForTransform(\"world\", \"velodyne_frame\",\nlaserCloudMsg->header.stamp, ros::Duration(0.2))) { // Get the tf transform.\ntf::StampedTransform tf_transform; tf_listener.lookupTransform(world_frame,\nvelo_frame, laserCloudMsg->header.stamp, tf_transform); } else {\nROS_FATAL(\"UNABLE TO LOOKUP INITIAL TRANSFORM!\"); } } Does anyone have any\nidea what may be wrong? Thanks!\n\n\u21a7\n\n#  [ nav_msgs/Odometry to tf2_msgs/TFMessage\n](//question2177.rssing.com/chan-36149602/article531-live.html)\n\nAugust 28, 2017, 5:14 am\n\n[ _\u226b_ Next: Sample rosbag file for laser scanner data\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a532 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Unable to lookup tf transform\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a530 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle531-live.html\n\"Article Support\")\n\nI am following this tutorial\n[here](http://wiki.ros.org/laser_pipeline/Tutorials/IntroductionToWorkingWithLaserScannerData)\nfor understanding how to use laserscanner data. There is a bag file which\npublishes laser scan data alongside odometry data. So it doesn't publish\nanything on /tf topic but gives out Odometry message. Is there a way to\nconvert that Odometry info to TF ? I have rosbag file which Is there a way to\nconvert that odometry data to tf?\n\n\u21a7\n\n#  [ Sample rosbag file for laser scanner data\n](//question2177.rssing.com/chan-36149602/article532-live.html)\n\nAugust 29, 2017, 2:46 am\n\n[ _\u226b_ Next: tf cannot find boost thread library\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a533 \"Next\nArticle\")\n\n[ _\u226a_ Previous: nav_msgs/Odometry to tf2_msgs/TFMessage\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a531 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle532-live.html\n\"Article Support\")\n\nI need a bag file for laser scanner data. The bag file should have a node\npublishing tf2_msgs/TFMessage and sensor_msgs/LaserScan type messages to\ntopics. I started out with this tutorial - [Introduction to Working With Laser\nScanner\nData](http://wiki.ros.org/laser_pipeline/Tutorials/IntroductionToWorkingWithLaserScannerData#Converting_a_Laser_Scan_to_a_Point_Cloud)\nbut the bag file provided here has odometry data (nav_msgs/Odometry type\nmessage). I just don't understand how to transform odometry data to tf data.\nEither help is appreciated.\n\n\u21a7\n\n#  [ tf cannot find boost thread library\n](//question2177.rssing.com/chan-36149602/article533-live.html)\n\nDecember 20, 2014, 9:43 am\n\n[ _\u226b_ Next: robot_localization IMU TF\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a534 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Sample rosbag file for laser scanner data\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a532 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle533-live.html\n\"Article Support\")\n\nI am trying to build ros hydro from source on ubuntu 12.04 it requires boost\n1.46.1 but the version of boost installed on my machine is 1.48 so I\ndownloaded boost 1.46.1 and installed it in a local folder. I also added skip-\nkeys flag in rosdep to stop it from installing boost (because it would remove\nthe newer version). After installing these dependencies I did\n./src/catkin/bin/catkin_make_isolated --install -DCMAKE_BUILD_TYPE=Release as\nmentioned here : http://wiki.ros.org/hydro/Installation/Source this started\nbuilding plain cmake and catkin packages but gave an error while building tf:\nCMakeFiles/tf_monitor.dir/src/tf_monitor.cpp.o: In function `main':\ntf_monitor.cpp:(.text.startup+0x3cf): undefined reference to\n`boost::thread::start_thread_noexcept()' tf_monitor.cpp:(.text.startup+0x46f):\nundefined reference to `boost::thread::join_noexcept()' I specified the boost\nlibrary path using CMAKE_LIBRARY_PATH variable cmake is able to find the local\nboost installation using this. I also tried changing the CMakeCahe.txt file in\ntf package by specifying the location of libboost_thread.so but still no luck\ncan someone please help .\n\n\u21a7\n\n\u21a7\n\n#  [ robot_localization IMU TF\n](//question2177.rssing.com/chan-36149602/article534-live.html)\n\nSeptember 7, 2017, 2:11 am\n\n[ _\u226b_ Next: what is tf\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a535 \"Next\nArticle\")\n\n[ _\u226a_ Previous: tf cannot find boost thread library\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a533 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle534-live.html\n\"Article Support\")\n\nDear all, If I use robot_localization with [9 Degrees of Freedom - Razor\nIMU](https://www.sparkfun.com/products/retired/10736), do I need to provide TF\nbetween base link and imu link? Is TF between base_link and imu_link important\nfor robot_localization internal processing? Since this IMU uses three\ndifferent chips for an accelerometer, gyroscope and magnetometer, which\nsensor's location will determine the TF value? Based on this [Q\n&A](https://answers.ros.org/question/9957/what-frame_id-to-put-in-a-\nsensor_msgsimu-message/), we may need to mount IMU to be aligned with\nbase_link. In that case, how should I align this IMU due to three separate\nchips locations in the PCB?\n\n\u21a7\n\n#  [ what is tf\n](//question2177.rssing.com/chan-36149602/article535-live.html)\n\nSeptember 7, 2017, 4:47 am\n\n[ _\u226b_ Next: robot_state_publisher design: multiple publishers on /joint_states\nok? ](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a536 \"Next\nArticle\")\n\n[ _\u226a_ Previous: robot_localization IMU TF\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a534 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle535-live.html\n\"Article Support\")\n\nHey guys, I am all in all pretty new to computer science in general and\nlearning ROS now. came across some tutorials on tf after completing the\nbeginner tutorials. I want to use rososc but that's another story since it is\nnot updated for kinetic and catkin and I'm still trying to work out how to\nmake that work for me... anyway, -explain what tf is used for as if I am a 5\nyear old. -why would I use it in developing robots? -what type of applications\nis it useful for?\n\n\u21a7\n\n[ Search ](javascript:;)\n\nRSSing.com\n\n* * *\n\n#  [ robot_state_publisher design: multiple publishers on /joint_states ok?\n](//question2177.rssing.com/chan-36149602/article536-live.html)\n\nSeptember 10, 2017, 5:16 pm\n\n[ _\u226b_ Next: tf tree details\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a537 \"Next\nArticle\")\n\n[ _\u226a_ Previous: what is tf\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a535 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle536-live.html\n\"Article Support\")\n\nIs robot_state_publisher designed to handle multiple sources of /joint_state\ninformation? For example, let's say I have the R2D2-like robot from this\n[tutorial](http://wiki.ros.org/urdf/Tutorials/Using%20urdf%20with%20robot_state_publisher).\nIf I have one node publishing the state of the 'periscope' on `/joint_states`,\nand another node publishing the rest of the joints, also on `/joint_states`,\nwill `robot_state_publisher` do the right thing? (i.e., 'merge' the\n`/joint_state` messages?). I'm currently studying the source code to\ndefinitively figure this out, but I see that others have asked this in the\npast, so I figured I'd raise the issue again.\n\n\u21a7\n\n#  [ tf tree details\n](//question2177.rssing.com/chan-36149602/article537-live.html)\n\nNovember 22, 2016, 10:52 pm\n\n[ _\u226b_ Next: how to change the transform according to a transform tree\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a538 \"Next\nArticle\")\n\n[ _\u226a_ Previous: robot_state_publisher design: multiple publishers on\n/joint_states ok?\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a536 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle537-live.html\n\"Article Support\")\n\nAfter running gmapping from intel.bag, while generating the map, if I run\nrosrun tf view_frames, it gives me the frames.pdf. In this case, the transform\nis map->odom->base_link and odom->laser,the broadcasting node for map->odom is\n/slam_gmapping, the broadcasting node for odom->laser is\n/play_1479118047019813325 node, the broadcasting node for odom->base_link is\n/static_transform_publisher_1479118028670611586 node Please explain the tree.\n\n\u21a7\n\n\u21a7\n\n#  [ how to change the transform according to a transform tree\n](//question2177.rssing.com/chan-36149602/article538-live.html)\n\nSeptember 11, 2017, 10:43 pm\n\n[ _\u226b_ Next: Extract robot position from rosbag\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a539 \"Next\nArticle\")\n\n[ _\u226a_ Previous: tf tree details\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a537 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle538-live.html\n\"Article Support\")\n\ni have a bag file containing a transform tree and want to make a map from\ngmapping and hector slam. i want to know what all changes i have to make in\nthe transforms in order to get the result..\n\n\u21a7\n\n#  [ Extract robot position from rosbag\n](//question2177.rssing.com/chan-36149602/article539-live.html)\n\nMay 21, 2013, 7:47 pm\n\n[ _\u226b_ Next: using tf data from bag files\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a540 \"Next\nArticle\")\n\n[ _\u226a_ Previous: how to change the transform according to a transform tree\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a538 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle539-live.html\n\"Article Support\")\n\nI recorded tf-messages (while driving the robot) into a bagfile and wrote a\nros node that should extract the positions (base_link-frame) from that bag\nfile. My idea was to use a tf::Transformer and feed it with all the transforms\nstored in the tf-messages: rosbag::Bag bag; bag.open(\"tf.bag\",\nrosbag::bagmode::Read); std::vector<:string> topics; topics.push_back(\"/tf\");\nrosbag::View view(bag, rosbag::TopicQuery(topics)); tf::Transformer\ntransformer; BOOST_FOREACH(rosbag::MessageInstance const m, view) {\n//instantiate bag message tf::tfMessage::ConstPtr tfPtr =\nm.instantiate<:tfmessage>(); BOOST_FOREACH(geometry_msgs::TransformStamped\nconst tfs, tfPtr->transforms) { tf::StampedTransform stampedTf;\ntf::transformStampedMsgToTF(tfs, stampedTf); //setTransform returns true!\ntransformer.setTransform(stampedTf); ... } } The method setTransform(...)\nalways returns true, so I thought that it works... Each time I get a transform\nwith child_frame == /robot_1/base_link I want to get the map-base_link-\ntransform at the time of this last transform. But the transformer returns\nfalse: if(transformer.canTransform(baseLink, mapFrame,\nstampedTf.stamp_)==true){ //lookup transform\ntransformer.lookupTransform(baseLink, mapFrame, stampedTf.stamp_, temp); } A\nfew additional facts: The transformer's latest common time is always = 0:\ntransformer.getLatestCommonTime(baseLink, mapFrame, time, NULL) And printing\nall tf-messages of the bag shows that the tf-tree should be consistent (I'm\nusing stage and used view_frames): /map -> /robot_1/odom ->\n/robot_1/base_footprint -> /robot_1/base_link -> /robot_1/base_laser_link Is\nsomething wrong with my code or idea? Any suggestions for a better solution?\nThanks in advance!\n\n\u21a7\n\n#  [ using tf data from bag files\n](//question2177.rssing.com/chan-36149602/article540-live.html)\n\nOctober 8, 2011, 10:58 am\n\n[ _\u226b_ Next: How to remove a TF from a ROS bag?\n](//question2177.rssing.com/chan-36149602/all_p28.html#c36149602a541 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Extract robot position from rosbag\n](//question2177.rssing.com/chan-36149602/all_p27.html#c36149602a539 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2177.rssing.com%2Fchan-36149602%2Farticle540-live.html\n\"Article Support\")\n\nI'm wondering if there is a good way to get transforms (rotation and\ntranslation) from tf data recorded in bag files. I'm working in python and I\ndon't want to replay the bag file as part of the solution. Instead I want to\nbe able to get other messages from the bag file and use tf to find the\neuclidean distance between two frames on the robot at the same time instant as\nmy message of interest. Any thoughts? I could look at parent-child\nrelationships in a single tf message and string the transforms together, but\nthen I'd be recreating the functionality of tf. Is there a utility or tool for\ngetting a transformation from a single tf message (i.e. not using ROS to wait\nfor transform or having to replay the bag file). Thanks a lot for any ideas.\n\n\u21a7\n\n[ Remove ADS ](//www.rssing.com/account.php?r=27)\n\nViewing all 844 articles\n\n[ ](//question2177.rssing.com/chan-36149602/all_p26.html \"older\") First Page\n...  Page 25  Page 26  Page 27  Page 28  Page 29  ...  Last Page  [\n](//question2177.rssing.com/chan-36149602/all_p28.html \"newer\")\n\n[ Browse latest ](//question2177.rssing.com/chan-36149602/index-latest.php) [\nView live ](//question2177.rssing.com/chan-36149602/article521-live.html)\n\n* * *\n\n[ Search ](javascript:;)\n\nRSSing.com\n\n* * *\n\n##  Top-Rated Images\n\n[ \u2182\n](////lists288.rssing.com/chan-11077187/article374.html#c11077187a374i164684108\n\"Top 20 Hot and Sexy Dragon Ball Z Girls \\(Characters\\)\")\n\n![Top 20 Hot and Sexy Dragon Ball Z Girls\n\\(Characters\\)](//1.bp.blogspot.com/-OqJPaiXp4As/U1r7dNW2ElI/AAAAAAAAk_I/J7YbqMD1OJk/s1600/pan-\nof-dragon-ball-z.jpg)\n\n###  [ Top 20 Hot and Sexy Dragon Ball Z Girls (Characters)\n](////lists288.rssing.com/chan-11077187/article374.html#c11077187a374i164684108)\n\n[ \u2182\n](////roadsnacks62.rssing.com/chan-75361660/article129.html#c75361660a129i1920752423\n\"The 10 West Virginia Cities With The Largest Black Population For 2021\")\n\n![The 10 West Virginia Cities With The Largest Black Population For\n2021](//www.homesnacks.com/images/wv/huntington-wv-1.jpg)\n\n###  [ The 10 West Virginia Cities With The Largest Black Population For 2021\n](////roadsnacks62.rssing.com/chan-75361660/article129.html#c75361660a129i1920752423)\n\n[ \u2182\n](////ngemu1.rssing.com/chan-25253293/article13362.html#c25253293a13362i1209846253\n\"Epsxe On-screen Gamepad skins \\(For Android\\)\")\n\n![Epsxe On-screen Gamepad skins \\(For Android\\)](//i.imgur.com/Oc5rtZR.jpg)\n\n###  [ Epsxe On-screen Gamepad skins (For Android)\n](////ngemu1.rssing.com/chan-25253293/article13362.html#c25253293a13362i1209846253)\n\n[ \u2182\n](////barbados171.rssing.com/chan-13839764/article16821.html#c13839764a16821i186843027\n\"Woman is 21st murder victim\")\n\n![Woman is 21st murder victim](//barbadostoday.bb/wp-\ncontent/uploads/2019/04/MG_3723.jpg)\n\n###  [ Woman is 21st murder victim\n](////barbados171.rssing.com/chan-13839764/article16821.html#c13839764a16821i186843027)\n\n[ \u2182\n](////morion34.rssing.com/chan-6716153/article201.html#c6716153a201i1852207283\n\"Zamboanga del Sur | The Simply Majestic Pulacan Falls of Labangan\")\n\n![Zamboanga del Sur | The Simply Majestic Pulacan Falls of\nLabangan](//farm6.staticflickr.com/5790/23330797891_84b6542fa0_o.jpg)\n\n###  [ Zamboanga del Sur | The Simply Majestic Pulacan Falls of Labangan\n](////morion34.rssing.com/chan-6716153/article201.html#c6716153a201i1852207283)\n\n[ \u2182\n](////guangzhou99.rssing.com/chan-7000757/article34.html#c7000757a34i619299452\n\"A Trail Through Guangzhou Sex Toys Market\")\n\n![A Trail Through Guangzhou Sex Toys Market](//www.business-in-\nguangzhou.com/wp-content/uploads/2017/08/Guangzhou-Sex-Toy-Market-3.jpg)\n\n###  [ A Trail Through Guangzhou Sex Toys Market\n](////guangzhou99.rssing.com/chan-7000757/article34.html#c7000757a34i619299452)\n\n[ \u2182\n](////salina38.rssing.com/chan-7227570/article346.html#c7227570a346i969163884\n\"Saline County Jail Booking Activity \u2013 Saturday\")\n\n![Saline County Jail Booking Activity \u2013\nSaturday](//thepost.s3.amazonaws.com/wp-\ncontent/uploads/2014/05/0CA0E0F2-150x150.jpg)\n\n###  [ Saline County Jail Booking Activity \u2013 Saturday\n](////salina38.rssing.com/chan-7227570/article346.html#c7227570a346i969163884)\n\n[ \u2182\n](////publications1361.rssing.com/chan-8114218/article11524.html#c8114218a11524i1058703038\n\"Tayler Holder\")\n\n![Tayler\nHolder](//s3.amazonaws.com/storage1.magcloud.com/image/03840701e70adf4fb8076c13bff36829.jpg)\n\n###  [ Tayler Holder\n](////publications1361.rssing.com/chan-8114218/article11524.html#c8114218a11524i1058703038)\n\n[ \u2182\n](////mynavi14.rssing.com/chan-9278202/article344.html#c9278202a344i1767525073\n\"City Navigator Europe NTU 2020.20\")\n\n![City Navigator Europe NTU 2020.20](//i.imgur.com/Msatrfa.jpg)\n\n###  [ City Navigator Europe NTU 2020.20\n](////mynavi14.rssing.com/chan-9278202/article344.html#c9278202a344i1767525073)\n\n[ \u2182\n](////lanka464.rssing.com/chan-9574025/article523.html#c9574025a523i98402367\n\"\u0d87\u0dc4\u0dd0\u0dc5\u0dda\u0db4\u0ddc\u0dc5 \u0d9a\u0dd4\u0db8\u0dcf\u0dbb\u0dd2\u0dc4\u0dcf\u0db8\u0dd2 \u2013 Ahelepolakumarihami\")\n\n![\u0d87\u0dc4\u0dd0\u0dc5\u0dda\u0db4\u0ddc\u0dc5 \u0d9a\u0dd4\u0db8\u0dcf\u0dbb\u0dd2\u0dc4\u0dcf\u0db8\u0dd2 \u2013 Ahelepolakumarihami](//cinema.lk/wp-\ncontent/uploads/2014/09/3.png)\n\n###  [ \u0d87\u0dc4\u0dd0\u0dc5\u0dda\u0db4\u0ddc\u0dc5 \u0d9a\u0dd4\u0db8\u0dcf\u0dbb\u0dd2\u0dc4\u0dcf\u0db8\u0dd2 \u2013 Ahelepolakumarihami\n](////lanka464.rssing.com/chan-9574025/article523.html#c9574025a523i98402367)\n\n[ \u2182\n](////crayon54.rssing.com/chan-11954040/article21.html#c11954040a21i2029720422\n\"Rare and Not Rare:  A Visual look at Crayola crayon color names you probably\nhaven't seen\")\n\n![Rare and Not Rare:  A Visual look at Crayola crayon color names you probably\nhaven't\nseen](//3.bp.blogspot.com/-mwvaqULbKsU/UhTjnpw4NyI/AAAAAAAAAVw/MFjG6SynFMs/s400/Chili+Colors.jpg)\n\n###  [ Rare and Not Rare: A Visual look at Crayola crayon color names you\nprobably haven't seen\n](////crayon54.rssing.com/chan-11954040/article21.html#c11954040a21i2029720422)\n\n[ \u2182\n](////nickalive1.rssing.com/chan-12111484/article19428.html#c12111484a19428i709189718\n\"Wicked Cool Toys Announces 'The Loud House' Plush Toy Line | NYTF 2018\n\\[Updated\\]\")\n\n![Wicked Cool Toys Announces 'The Loud House' Plush Toy Line | NYTF 2018\n\\[Updated\\]](//3.bp.blogspot.com/-nOI76eg4gOE/W5arvkqxY5I/AAAAAAAA-\nbs/dk80jyd1o5ICOU25r8SLjyKQySQQUb0lACLcBGAs/s400/The-Loud-House-Wicked-Cool-\nToys-Booth-Toy-Nickelodeon-Nick-TFNY-NYTF_1.jpg)\n\n###  [ Wicked Cool Toys Announces 'The Loud House' Plush Toy Line | NYTF 2018\n[Updated]\n](////nickalive1.rssing.com/chan-12111484/article19428.html#c12111484a19428i709189718)\n\n[ \u2182\n](////shayaris11.rssing.com/chan-65042695/article318.html#c65042695a318i30152888\n\"Happy Marriage Anniversary Wishes in Hindi for Husband & Wife \")\n\n![Happy Marriage Anniversary Wishes in Hindi for Husband & Wife\n](//1.bp.blogspot.com/-xTxRJ14dB4k/XqmIOws3A_I/AAAAAAAACzg/siiux_kSOsEggMrxHeLa2tjyA8UkWMcKwCLcBGAsYHQ/s320/happy-\nmarriage-anniversary-wishes-in-hindi-Lovesove.jpg)\n\n###  [ Happy Marriage Anniversary Wishes in Hindi for Husband & Wife\n](////shayaris11.rssing.com/chan-65042695/article318.html#c65042695a318i30152888)\n\n[ \u2182 ](////long-\nago6.rssing.com/chan-1715054/article75001.html#c1715054a75001i54785627 \"Robert\nM. Mills, 76, Elyria, Ohio\")\n\n![Robert M. Mills, 76, Elyria,\nOhio](//d3trabu2dfbdfb.cloudfront.net/1/1/11173204_220w_1.jpeg)\n\n###  [ Robert M. Mills, 76, Elyria, Ohio ](////long-\nago6.rssing.com/chan-1715054/article75001.html#c1715054a75001i54785627)\n\n[ \u2182\n](////busyteacher96.rssing.com/chan-4234831/article296.html#c4234831a296i495218235\n\"Movie Worksheet: The Short Life of Anne Frank\")\n\n![Movie Worksheet: The Short Life of Anne\nFrank](//busyteacher.org/uploads/posts/2015-04/thumbs/1430406847_the-short-\nlife-of-anne-frank-0.png)\n\n###  [ Movie Worksheet: The Short Life of Anne Frank\n](////busyteacher96.rssing.com/chan-4234831/article296.html#c4234831a296i495218235)\n\n[ \u2182\n](////globetrotting260.rssing.com/chan-5576664/article587.html#c5576664a587i1181168371\n\"Drug kingpin Frank Lucas' House \\(former\\)\")\n\n![Drug kingpin Frank Lucas' House\n\\(former\\)](//c2.vgtstatic.com/thumbll/1/9/191021-v1/drug-kingpin-frank-lucas-\nhouse-former.jpg)\n\n###  [ Drug kingpin Frank Lucas' House (former)\n](////globetrotting260.rssing.com/chan-5576664/article587.html#c5576664a587i1181168371)\n\n[ \u2182\n](////fonts1404.rssing.com/chan-57741102/article197.html#c57741102a197i1172405349\n\"Bayern Munchen 23-24 Font \\(OTF & Vector\\)\")\n\n![Bayern Munchen 23-24 Font \\(OTF &\nVector\\)](//footballfonts.com/u/img/bayern-munchen-23-24-otf-font-\ninstallation.jpg)\n\n###  [ Bayern Munchen 23-24 Font (OTF & Vector)\n](////fonts1404.rssing.com/chan-57741102/article197.html#c57741102a197i1172405349)\n\n[ \u2182\n](////ourhappyschool15.rssing.com/chan-59119707/article22.html#c59119707a22i1030558410\n\"Consuelo Ortiga y Rey: The \")\n\n![Consuelo Ortiga y Rey: The\n](//ourhappyschool.com/sites/default/files/LoveRizalJensen_0.jpg)\n\n###  [ Consuelo Ortiga y Rey: The \"Crush ng Bayan\" in Rizal's Time\n](////ourhappyschool15.rssing.com/chan-59119707/article22.html#c59119707a22i1030558410)\n\n[ \u2182\n](////prasar9.rssing.com/chan-61257419/article6109.html#c61257419a6109i818610802\n\"Padmasree for Sri K G Jayan ,a senior musician of AIR Thrissur\")\n\n![Padmasree for Sri K G Jayan ,a senior musician of AIR\nThrissur](//2.bp.blogspot.com/-tLgIZZjIOWI/XEwatKG_qzI/AAAAAAAANYA/Irjv1Z-4URUW5-GlyA-\n_D4bLyIe8lbJhgCLcBGAs/s400/1.jpg)\n\n###  [ Padmasree for Sri K G Jayan ,a senior musician of AIR Thrissur\n](////prasar9.rssing.com/chan-61257419/article6109.html#c61257419a6109i818610802)\n\n[ \u2182\n](////augustacrime16.rssing.com/chan-36733858/article181.html#c36733858a181i777026533\n\"HAFSA ROBINSON\")\n\n![HAFSA ROBINSON](//augustacrime.com/wp-content/uploads/2016/12/Hafsa-\nRobinson-23-Theft-by-taking-240x300.jpg)\n\n###  [ HAFSA ROBINSON\n](////augustacrime16.rssing.com/chan-36733858/article181.html#c36733858a181i777026533)\n\n\u02c2\n\n\u02c3\n\n####  Latest Images\n\n[ ![New $4.5 million East Bay trail path will connect bicyclists, pedestrians\nto...](//i0.wp.com/www.mercurynews.com/wp-content/uploads/2024/04/EBT-L-\nBIKEPATH.jpg?fit=620%2C9999px&ssl=1)\n](////highways565.rssing.com/chan-72305408/article7527.html#c72305408a7527i675934014)\n\n###  [ New $4.5 million East Bay trail path will connect bicyclists,\npedestrians to...\n](////highways565.rssing.com/chan-72305408/article7527.html#c72305408a7527i675934014)\n\nApril 18, 2024, 11:05 am\n\n[ ![Photographer Gifts for Clients / Print Packaging / 4x6 Photo Box\nby...](//i.etsystatic.com/24045442/r/il/ec549c/3983631708/il_570xN.3983631708_ah99.jpg)\n](////photografica1.rssing.com/chan-21171088/article22266.html#c21171088a22266i1623189003)\n\n###  [ Photographer Gifts for Clients / Print Packaging / 4x6 Photo Box by...\n](////photografica1.rssing.com/chan-21171088/article22266.html#c21171088a22266i1623189003)\n\nApril 17, 2024, 6:48 pm\n\n[ ![Deepfake Video of Aamir Khan circulates Online](//www.desiblitz.com/wp-\ncontent/uploads/2024/04/Deepfake-Video-of-Aamir-Khan-circulates-Online-f.jpg)\n](////desiblitz102.rssing.com/chan-14666875/article8744.html#c14666875a8744i305008331)\n\n###  [ Deepfake Video of Aamir Khan circulates Online\n](////desiblitz102.rssing.com/chan-14666875/article8744.html#c14666875a8744i305008331)\n\nApril 17, 2024, 3:07 am\n\n[ ![Very Hungry Caterpillar\u2122 Shirt: World of Eric Carle\u2122+ Little Goodall\nby...](//i.etsystatic.com/6018612/r/il/7591e4/3868173454/il_570xN.3868173454_gxfr.jpg)\n](////cryptomnesia.rssing.com/chan-1183730/article16627.html#c1183730a16627i1139077293)\n\n###  [ Very Hungry Caterpillar\u2122 Shirt: World of Eric Carle\u2122+ Little Goodall\nby...\n](////cryptomnesia.rssing.com/chan-1183730/article16627.html#c1183730a16627i1139077293)\n\nApril 14, 2024, 8:14 am\n\n[ ![Have you seen Michael Wines? Burien man has been missing since\nSaturday,...](//b-townblog.com/wp-\ncontent/uploads/2024/04/michael-3shoe.jpg?_t=1712879471)\n](////normandy480.rssing.com/chan-74604448/article56.html#c74604448a56i1857302427)\n\n###  [ Have you seen Michael Wines? Burien man has been missing since\nSaturday,...\n](////normandy480.rssing.com/chan-74604448/article56.html#c74604448a56i1857302427)\n\nApril 12, 2024, 3:59 pm\n\n[ ![Stay Salty POTS Awareness Stretchy Stacking Bracelets | Set of\nThree|...](//i.etsystatic.com/28677176/r/il/b2413c/4350795851/il_570xN.4350795851_fflz.jpg)\n](////pomaces4.rssing.com/chan-3795444/article11960.html#c3795444a11960i1086411135)\n\n###  [ Stay Salty POTS Awareness Stretchy Stacking Bracelets | Set of\nThree|...\n](////pomaces4.rssing.com/chan-3795444/article11960.html#c3795444a11960i1086411135)\n\nApril 11, 2024, 5:27 pm\n\n[ ![19 Reader-Favourite March Purchases \u2014 From Steals To\nSplurges](//www.refinery29.com/images/11700602.png?auto=webp&width=750&height=938&quality=85&crop=375:469)\n](////refinery1042.rssing.com/chan-72297680/article18978.html#c72297680a18978i1490871663)\n\n###  [ 19 Reader-Favourite March Purchases \u2014 From Steals To Splurges\n](////refinery1042.rssing.com/chan-72297680/article18978.html#c72297680a18978i1490871663)\n\nApril 11, 2024, 5:07 am\n\n[ ![Fake lip ring, silver lip ring, simple lip ring, unisex lip ring by\nAIRlab](//i.etsystatic.com/10798216/r/il/3a91cc/761285074/il_570xN.761285074_fu8j.jpg)\n](////kuteriot1.rssing.com/chan-5865851/article17035.html#c5865851a17035i913072506)\n\n###  [ Fake lip ring, silver lip ring, simple lip ring, unisex lip ring by\nAIRlab\n](////kuteriot1.rssing.com/chan-5865851/article17035.html#c5865851a17035i913072506)\n\nApril 9, 2024, 4:00 pm\n\n[ ![People's Blog \u2022 First Pictures of the Eclipse ! !\n!](//thepeoplescube.com/red/download/file.php?id=57243&sid=d61d4527be50ef499d8f3761aad83688)\n](////satire6144.rssing.com/chan-78334822/article122.html#c78334822a122i1295535114)\n\n###  [ People's Blog \u2022 First Pictures of the Eclipse ! ! !\n](////satire6144.rssing.com/chan-78334822/article122.html#c78334822a122i1295535114)\n\nApril 8, 2024, 1:08 pm\n\n[ ![People's Blog \u2022 First Pictures of the Eclipse ! !\n!](//thepeoplescube.com/red/download/file.php?id=57243&sid=3721c68912ad1a7b63f4cf1eafba9b41)\n](////satire3490.rssing.com/chan-77006292/article253.html#c77006292a253i838655542)\n\n###  [ People's Blog \u2022 First Pictures of the Eclipse ! ! !\n](////satire3490.rssing.com/chan-77006292/article253.html#c77006292a253i838655542)\n\nApril 8, 2024, 1:08 pm\n\n  * [ RSSing>> ](//www.rssing.com/index.php)\n  * [ Latest ](//www.rssing.com/index.php?l=l)\n  * [ Popular ](//www.rssing.com/index.php?l=p)\n  * [ Top Rated ](//www.rssing.com/index.php?l=r)\n  * [ Trending ](//www.rssing.com/index.php?l=t)\n\n\u00a9 2024 //www.rssing.com\n\n"
  },
  {
    "id": "gz_sim/migrationfromgazeboc.txt",
    "content": "[ ![](https://assets-global.website-\nfiles.com/5e7b3ab65e9f113eadf770b4/5eba355ac3a6603c1730472c_nav%20bar%20BCR%20Logo.png)\n](/)\n\n[ BLOG ](/blog) CONTACT US\n\n#  Migration from Gazebo Classic to Ignition with ROS\u00c2 2\n\n[ Gaurav Gupta  ](https://www.linkedin.com/in/ggupta9777)\n\nJuly 17, 2023\n\nRead time 4 mins\n\n![LinkedIn Share](https://assets-global.website-\nfiles.com/5e7b3ab65e9f113eadf770b4/63fee6764dc16b62ab28a7c2_linkedinshare.png)\n![Twitter share icon](https://assets-global.website-\nfiles.com/5e7b3ab65e9f113eadf770b4/63fee44ee101659b03501b2c_twittershareicon.png)\n\n[ Gazebo Ignition ](https://gazebosim.org/home) is a long-term support release\nand a successor to [ Gazebo Classic ](https://classic.gazebosim.org/) , with\nGazebo 11 being the last classic release. Over the last 8 years, Open Robotics\nhas been working on a successor, which was earlier referred to as\n\u00e2\u0080\u009cIgnition\u00e2\u0080\u009d but has since been [ renamed to Gazebo\n](https://community.gazebosim.org/t/a-new-era-for-gazebo/1356) , while the\nprevious version is now called Gazebo Classic. At Black Coffee Robotics we\nhave been working extensively with gz-classic to develop a wide spectrum of\nautonomous robot applications. (We will refer to Ignition and Classic variants\nof Gazebo as gz-sim and gz-classic respectively)\n\nOver time, we have faced some problems with gz-classic, particularly\nconcerning rendering, stability, and computation. A switch to gz-sim seemed\npromising, as well as mandatory, very much in the mold of migrating from ROS1\nto ROS2. In this article, we will cover -\n\n  1. Using Gazebo Sim with ROS2 \n  2. Modeling robots and worlds with Gazebo Ignition \n  3. Conclude our findings \n\n###  Using Gazebo Sim with ROS2\n\nA large developer base working with Gazebo uses it in conjunction with ROS2.\n\n####  Gazebo\u00e2\u0080\u008a\u00e2\u0080\u0094\u00e2\u0080\u008aROS2 distro compatibility\n\nThe image below by Open Robotics provides recommended distros across ROS2 and\nGazebo. At the time of writing, ROS2 Humble running on Ubuntu 22.04 is the\nmost stable and widespread distro, so using it in conjunction with Gazebo\nFortress makes the most sense. Interestingly, the [ official documentation\n](https://gazebosim.org/docs/garden/getstarted) recommends the usage of Gazebo\nGarden on Ubuntu 22.04. To make it a little more complicated, there are some\nsyntactical and command-line differences between Fortress and Garden. All\nthings considered, if you are looking to start development, I\u00e2\u0080\u0099d recommend\nusing Ubuntu 22.04 + ROS2 Humble + Gazebo Fortress stack.  \n\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/649d6a0b2e2ca9bf62e038a3_0*gxZsPHd7GaPIOGz8.png)\n\nRecommended Gazebo-ROS2 combinations ( [ source\n](https://www.reddit.com/r/ROS/comments/11rbwwc/ros_gazebo_compatibility_guide/)\n)\n\n####  ROS2 plugins for sensors and control\n\nGazebo Classic depended on [ gazebo_ros_pkgs\n](http://wiki.ros.org/gazebo_ros_pkgs) to relay sensor data from the simulated\nworld to ROS/ROS2 world. Writing a custom sensor, actuator or model plugin\nwould typically involve utilizing Gazebo\u00e2\u0080\u0099s C++ APIs in conjunction with\nstandard ROS pub/sub or service mechanisms. Gazebo Sim however uses [\nros_gz_bridge ](https://github.com/gazebosim/ros_gz/tree/ros2/ros_gz_bridge) ,\nthis allows a convenient way to bridge topics across Gazebo and ROS2, very\nsimilar to [ bridging topics across ROS1 and ROS2\n](https://blackcoffeerobotics.com/blog/ros1-robots-in-a-ros2-world) . This\nmeans that developers can utilize Gazebo APIs to model a relevant\nsensor/model, publish it as a Gazebo topic and just bridge the topic across to\nROS2!\n\n###  Open Source Release of a Gazebo Robot\n\nThe [ official docs ](https://gazebosim.org/docs/fortress/building_robot)\nprovide a guide to developing a robot with gz-sim. These docs combined with a\n[ migration guide ](https://gazebosim.org/api/gazebo/6/migrationsdf.html)\nprovide **most** of the necessary information to model a robot with gz-sim.\nThe documentation itself could provide more complete and consolidated\ninformation, however. Additionally, open-source examples providing a working\nrobot model in gz-sim are sparse.\n\nTo bridge the information gap concerning model design, sensor modeling, and\nROS2 integration, we are announcing the release of [ **bcr_bot**\n](https://github.com/blackcoffeerobotics/bcr_bot) , an open-source robot\nsimulator for an industrial Autonomous Mobile Robot (AMR). Our primary\nobjectives for this development and release are\u00e2\u0080\u008a\u00e2\u0080\u0094\u00e2\u0080\u008a\n\n  1. A standard platform with all necessary sensor models for an AMR. \n  2. Support multiple ROS and Gazebo distros (Noetic + Classic, Humble + Classic, Humble + Fortress) \n  3. Detailed documentation and run instructions. \n\nOur goal over time is to keep adding hardware and sensor interfaces.\n\n###  Conclusion\n\nGazebo Ignition provides a solution for modeling robots and environments. In\naddition to a modular architecture and customizations, gz-sim provides\nfeatures such as distributed computing, the concept of levels, and cloud\nintegration to model complicated and large-scale worlds. At the same time, I\nfound that the documentation and examples do not match up to the pace of\ndevelopment and list of features.\n\nOur goal with [ **bcr_bot** ](https://github.com/blackcoffeerobotics/bcr_bot)\nis to provide a goto reference with regards to mobile robot simulation with\nignition, and we welcome all contributions to it! If you\u00e2\u0080\u0098re looking to\ncreate advanced and large simulations for your robotic applications with gz-\nsim, reach out to us!\n\n**Read more**\n\n[ ROS MoveIt Servo with Kinova Arm  Read time 5 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/65cc9efae3f6ef644b5e32a3_kinova_sim.jpg)\n](/blog/ros-moveit-servo-with-kinova-arm)\n\n[ Unit Tests for Robotics Software: Quality over Quantity  Read time: 5 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/6571c648f6a21b27d239fb73_path_follower%20\\(1\\).jpg)\n](/blog/unit-tests-for-robotics-software-quality-over-quantity)\n\n[ 5 Ways to Speedup Gazebo Simulations  Read time: 7 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/64b52af1de8dcc67e648ed8f_sim_speed_thumb.jpg)\n](/blog/5-ways-to-speedup-gazebo-simulations)\n\n[ Migration from Gazebo Classic to Ignition with ROS\u00c2 2  Read time 4 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/649d7e725c2b81b728090ea3_image.png)\n](/blog/migration-from-gazebo-classic-to-ignition-with-ros-2)\n\n[ Webots with ROS: Simulation Overview  Read time 4 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/6481d2dec9c02d08e0b8454f_webots_mapping.png)\n](/blog/webots-with-ros-simulation-overview)\n\n[ ROS plugin to control Actors in Gazebo Simulation  Read time 4 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/642ead64f8ce14006b1b18ae_actor_gazebo_ros.jpg)\n](/blog/ros-plugin-to-control-actors-in-gazebo-simulation)\n\n[ How to become a robotics software engineer  Read time 5 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/641982ff80f7ef2c61002d68_zubin_arm_robot.jpeg)\n](/blog/how-to-become-a-robotics-software-engineer)\n\n[ 4 challenges in robotics product development  Read time 4 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/640c35aa3ecaf8c09c320117_rpd_cover_2.jpg)\n](/blog/4-challenges-in-robotics-product-development)\n\n[ Localization for Warehouse Autonomous Robots  Read time 6 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/6403a4a2a2b653579951dab3_warehouse_cov.gif)\n](/blog/localization-for-warehouse-autonomous-robots)\n\n[ Unity and ROS: Keeping it real  Read time 4 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/6403a2147ad4e057dfba6e2f_unityorch-0.png)\n](/blog/unity-and-ros-keeping-it-real)\n\n[ ROS1 robots in a ROS2 world  Read time 3 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/6403989d7d01f7212c247a19_ros12bridge.png)\n](/blog/ros1-robots-in-a-ros2-world)\n\n[ Our DevOps pipeline for a heterogeneous fleet of robots  Read time 4 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/640377df8a898d9b070ce13a_devopsmedium2.png)\n](/blog/our-devops-pipeline-for-a-heterogeneous-fleet-of-robots)\n\n[ Robot software: Beyond algorithms  Read time 5 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/640375087d01f73442215172_devops.png)\n](/blog/robot-software-beyond-algorithms)\n\n[ Gazebo: Projection of Occupancy Maps  Read time 5 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/64036b3f6fa970bc6e2d51e7_gzcover.png)\n](/blog/gazebo-projection-of-occupancy-maps)\n\n[ Simulations for mobile robots  Read time 5 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/64035b16422e3a2855bb5668_anim-opt.gif)\n](/blog/simulations-for-mobile-robots)\n\n[ GPS based Localization for Self-Driving Robots  Read time 6 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/64033f2c5361e52d693b7c6f_gps_localization.png)\n](/blog/gps-based-localization-for-self-driving-robots)\n\n[ ROS and ROS2 Navigation Stacks: A performance review  Read time 7 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/63f90f613fc93f95c74a965a_ros1ros2nav.png)\n](/blog/ros-and-ros2-navigation-stacks-a-performance-review)\n\n[ ROS: Why What and How.  Read time 5 mins  ![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/63f633f92da6c307d732a5db_ros1logo.png)\n](/blog/ros-why-what-and-how)\n\n[ ROS: Core\u00c2 concepts  Read time 7 mins  ![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/63f633f92da6c307d732a5db_ros1logo.png)\n](/blog/ros-core-concepts)\n\n[ Robotics Product Development: Pitfalls you need to know  Read time 5 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/63f90c056e2483866c71b685_rpdp.png)\n](/blog/robotics-product-development-learning)\n\n##  Contact Us\n\n##  Get in touch. Let us know how we can help.\n\n![contact@blackcoffeerobotics.com](https://assets-global.website-\nfiles.com/5e7b3ab65e9f113eadf770b4/5e7b549cf803a25889973e2d_email.png)\n\n[ contact@blackcoffeerobotics.com ](mailto:contact@blackcoffeerobotics.com)\n\n[ ![Twitter Link](https://assets-global.website-\nfiles.com/5e7b3ab65e9f113eadf770b4/60a00125f9cc8f85844407ba_Twitter%20social%20icons%20-%20rounded%20square%20-%20blue.png)\n](https://twitter.com/bcrllp) [ ![LinkendIn Link](https://assets-\nglobal.website-\nfiles.com/5e7b3ab65e9f113eadf770b4/640975263d2118947636e711_linkedinicon.png)\n](http://www.linkedin.com/company/blackcoffeerobotics)\n\n![location pin](https://assets-global.website-\nfiles.com/5e7b3ab65e9f113eadf770b4/5e7b549e46049e7283219cfe_location-pin.png)\n\n14, Raghava Enclave, Transport Road, Secunderabad, Hyderabad (500009)\n\n[ Careers ](/careers)\n\n| Copyright \u00c2\u00a9 2023 Black Coffee Robotics\n\n"
  },
  {
    "id": "source_install/interpretationofforc.txt",
    "content": "First time here? Check out the FAQ!\n\n  \nROS Resources: [ Documentation ](http://wiki.ros.org/) | [ Support\n](http://wiki.ros.org/Support) | [ Discussion Forum\n](http://discourse.ros.org/) | [ Index ](http://index.ros.org/) | [ Service\nStatus ](http://status.ros.org/) | [ ros @ Robotics Stack Exchange\n](https://robotics.stackexchange.com/questions/tagged/ros)  \n---  \n  \n_Attention:_ Answers.ros.org is deprecated as of August the 11th, 2023. Please\nvisit [ robotics.stackexchange.com ](http://robotics.stackexchange.com) to ask\na new question. This site will remain online in read-only mode during the\ntransition and into the foreseeable future. Selected questions and answers\nhave been migrated, and redirects have been put in place to direct users to\nthe corresponding questions on Robotics Stack Exchange. Additional details are\n[ available here ](https://discourse.ros.org/t/ros-and-gazebo-answers-\nmigration-to-robotics-stack-exchange-process/31494) .\n\n[ Hi there! Please sign in\n](/account/signin/?next=/question/243173/interpretation-of-forcetorque-sensor-\nusing-gazebo_ros_ft_sensor-plugin/) [ help ](/help/ \"help\")\n\n[ ![ROS Answers logo](/m/ros/media/images/logoros.png?v=28) ](/questions/)\n\n[ tags ](/tags/) [ users ](/users/) [ badges ](/badges/)\n\nThe site is read-only. Please transition to use Robotics Stack Exchange\n\n[ __ ](/questions/) |\n\n[ ALL ](/questions/scope:all/sort:activity-desc/page:1/) [ UNANSWERED\n](/questions/scope:unanswered/sort:answers-asc/page:1/)\n\n|\n\n|  [ Ask Your Question ](/questions/ask/)  \n---|---|---|---  \n  \n0\n\n#\n\nInterpretation of Force/Torque Sensor using gazebo_ros_ft_sensor plugin\n\nedit\n\n  * [ force ](/questions/scope:all/sort:activity-desc/tags:force/page:1/)\n\n  * [ torque ](/questions/scope:all/sort:activity-desc/tags:torque/page:1/)\n\n  * [ Sensor ](/questions/scope:all/sort:activity-desc/tags:Sensor/page:1/)\n\n  * [ noise ](/questions/scope:all/sort:activity-desc/tags:noise/page:1/)\n\n[ **asked 2016-09-06 03:24:09 -0500  ** ](/questions/243173/revisions/)\n\n[ ![Masoud gravatar image](/upfiles/avatars/Masoud/resized/32/Shiraz.png)\n](/users/26841/masoud/)\n\n[ Masoud ](/users/26841/masoud/)  \n39  \u25cf  14  \u25cf  15  \u25cf  18\n\n[ **updated 2016-09-06 03:30:16 -0500  ** ](/questions/243173/revisions/)\n\n[ ![gvdhoorn gravatar image](/upfiles/avatars/gvdhoorn/resized/32/4550046.png)\n](/users/5184/gvdhoorn/)\n\n[ gvdhoorn ](/users/5184/gvdhoorn/)  \n86574  \u25cf  283  \u25cf  1432  \u25cf  1054  [ http://cor.tudelft.nl/\n](http://cor.tudelft.nl/ \"gvdhoorn's website is http://cor.tudelft.nl/\")\n\nI've successfully added a force torque/sensor to my model by adding following\ncodes in my urdf file:\n\n    \n    \n    <gazebo reference=\"shoulder_pan_joint\">\n        <provideFeedback>true</provideFeedback>\n    </gazebo>\n    \n    \n    <gazebo>\n        <plugin name=\"ft_sensor\" filename=\"libgazebo_ros_ft_sensor.so\">\n            <updateRate>10.0</updateRate>\n            <topicName>ft_sensor_topic</topicName>\n            <jointName>shoulder_pan_joint</jointName>\n        </plugin>\n    </gazebo>\n    \n\nAlthough the model is static and nothing is moving in gazebo gui, the outputs\nof force/torque sensor published by \"ft_sensor_topic\" is fluctuating. For\nexample the force value that I expect to be -100 is fluctuating between -55 N\nand -143N. Other 5 components of torque and force values are also fluctuating\nin a similar range.\n\nI also tried to reduce Gaussian Noise of the sensor by adding `\n<gaussianNoise>0.0</gaussianNoise> ` to the plugin tag. but this didn't solve\nthe problem.\n\nI'm using gazebo 2.2.3 + Ros indigo running in ubuntu 14.04.\n\n[ edit ](/questions/243173/edit/) [ retag ](/s/questions/243173/retag/) flag\noffensive  [ close ](/questions/243173/close/) merge  delete\n\nadd a comment\n\n##  1  Answer\n\nSort by \u00bb  [ oldest  ](/question/243173/interpretation-of-forcetorque-sensor-\nusing-gazebo_ros_ft_sensor-plugin/?sort=oldest#sort-top) [ newest\n](/question/243173/interpretation-of-forcetorque-sensor-using-\ngazebo_ros_ft_sensor-plugin/?sort=latest#sort-top) [ most voted\n](/question/243173/interpretation-of-forcetorque-sensor-using-\ngazebo_ros_ft_sensor-plugin/?sort=votes#sort-top)\n\n1\n\n[ **answered 2018-08-09 15:38:36 -0500  ** ](/answers/300191/revisions/)\n\n[ ![KurtR gravatar\nimage](//www.gravatar.com/avatar/e3a59c43e9571cc13c91da2c148f3940?s=32&d=identicon&r=PG)\n](/users/36914/kurtr/)\n\n[ KurtR ](/users/36914/kurtr/)  \n16  \u25cf  1\n\nI realize this is an old post, however I found that the torque/force plugin\nfor gazebo was giving very large values even when my model was stationary.\nGenerating better inertial values made the reported values much better ( [\nhttp://answers.gazebosim.org/question...\n](http://answers.gazebosim.org/question/4372/the-inertia-matrix-explained) )\n\n[ edit ](/s/answers/300191/edit/) flag offensive  delete  [ link\n](/question/243173/interpretation-of-forcetorque-sensor-using-\ngazebo_ros_ft_sensor-plugin/?answer=300191#post-id-300191 \"permanent link\")\nmore\n\n  *   * \n\nadd a comment\n\n##  Question Tools\n\nFollow\n\n1 follower\n\n[ subscribe to rss feed ](/feeds/question/243173/ \"subscribe to the rss feed\")\n\n##  Stats\n\nAsked: ** 2016-09-06 03:24:09 -0500  **\n\nSeen: **1,798 times**\n\nLast updated: **Sep 06 '16**\n\n##  Related questions\n\n[ Has anyone ever used ATI wireless F/T sensor ? ](/question/262641/has-\nanyone-ever-used-ati-wireless-ft-sensor/)\n\n[ how to control a 6 dof manipulator to write words on a wall through moveit\nsimulation ](/question/257026/how-to-control-a-6-dof-manipulator-to-write-\nwords-on-a-wall-through-moveit-simulation/)\n\n[ Distance measurements and tf ](/question/10603/distance-measurements-and-\ntf/)\n\n[ Issue subscribing to topic that is populated from\nlibgazebo_ros_ray_sensor.so ](/question/377045/issue-subscribing-to-topic-\nthat-is-populated-from-libgazebo_ros_ray_sensorso/)\n\n[ Where effort joint values come from ](/question/306958/where-effort-joint-\nvalues-come-from/)\n\n[ ros2 gazebo camera not publishing data ](/question/371730/ros2-gazebo-\ncamera-not-publishing-data/)\n\n[ Change rviz opengl version on Qt app, python ](/question/370940/change-rviz-\nopengl-version-on-qt-app-python/)\n\n[ PCL - coordinates from PointCloud2 message ](/question/265379/pcl-\ncoordinates-from-pointcloud2-message/)\n\n[ Has anyone connected more than 3 sensors to ROS? If so, how can we manage\nit? Is it advisable to use a usb splitter? ](/question/172621/has-anyone-\nconnected-more-than-3-sensors-to-ros-if-so-how-can-we-manage-it-is-it-\nadvisable-to-use-a-usb-splitter/)\n\n[ How to subscribe to a topic whom type is gazebo_msg/ContactState\n](/question/244380/how-to-subscribe-to-a-topic-whom-type-is-\ngazebo_msgcontactstate/)\n\n[ ![cc-by-sa](/m/default/media/images/cc-by-sa.png?v=28)\n](http://creativecommons.org/licenses/by-sa/3.0/legalcode) ROS Answers is\nlicensed under Creative Commons Attribution 3.0 Content on this site is\nlicensed under a [ Creative Commons Attribution Share Alike 3.0\n](http://creativecommons.org/licenses/by-sa/3.0/legalcode) license.\n\n[ about ](/about/) |  [ faq ](/faq/) |  [ help ](/help/ \"help\") |  [ privacy\npolicy ](/privacy/) |  [ terms of service ](/terms/)\n\n[ Powered by Askbot version 0.10.2 ](http://askbot.com)\n\nPlease note: ROS Answers requires javascript to work properly, please enable\njavascript in your browser, [ here is how\n](https://www.google.com/support/bin/answer.py?answer=23852)\n\n[ ![ gravatar image]() ]() [ ]() (  2024-04-18 18:57:03 -0500  )  edit\n\n[ none ](/questions/scope:all/sort:activity-desc/tags:none/page:1/) \u00d7\n\n  *[\n              2016-09-06 03:24:09 -0500\n             ]: 2016-09-06 03:24:09 -0500\n  *[\n              2016-09-06 03:30:16 -0500\n             ]: 2016-09-06 03:30:16 -0500\n  *[\n              2018-08-09 15:38:36 -0500\n             ]: 2018-08-09 15:38:36 -0500\n  *[\n        2016-09-06 03:24:09 -0500\n       ]: 2016-09-06 03:24:09 -0500\n  *[\n        2024-04-18 18:57:03 -0500\n       ]: 2024-04-18 18:57:03 -0500\n\n"
  },
  {
    "id": "hardware_communicate/hardwarerequiredform.txt",
    "content": "First time here? Check out the FAQ!\n\n  \nROS Resources: [ Documentation ](http://wiki.ros.org/) | [ Support\n](http://wiki.ros.org/Support) | [ Discussion Forum\n](http://discourse.ros.org/) | [ Index ](http://index.ros.org/) | [ Service\nStatus ](http://status.ros.org/) | [ ros @ Robotics Stack Exchange\n](https://robotics.stackexchange.com/questions/tagged/ros)  \n---  \n  \n_Attention:_ Answers.ros.org is deprecated as of August the 11th, 2023. Please\nvisit [ robotics.stackexchange.com ](http://robotics.stackexchange.com) to ask\na new question. This site will remain online in read-only mode during the\ntransition and into the foreseeable future. Selected questions and answers\nhave been migrated, and redirects have been put in place to direct users to\nthe corresponding questions on Robotics Stack Exchange. Additional details are\n[ available here ](https://discourse.ros.org/t/ros-and-gazebo-answers-\nmigration-to-robotics-stack-exchange-process/31494) .\n\n[ Hi there! Please sign in ](/account/signin/?next=/question/417318/hardware-\nrequired-for-making-real-industrial-robot-arm-through-ethercat/) [ help\n](/help/ \"help\")\n\n[ ![ROS Answers logo](/m/ros/media/images/logoros.png?v=28) ](/questions/)\n\n[ tags ](/tags/) [ users ](/users/) [ badges ](/badges/)\n\nThe site is read-only. Please transition to use Robotics Stack Exchange\n\n[ __ ](/questions/) |\n\n[ ALL ](/questions/scope:all/sort:activity-desc/page:1/) [ UNANSWERED\n](/questions/scope:unanswered/sort:answers-asc/page:1/)\n\n|\n\n|  [ Ask Your Question ](/questions/ask/)  \n---|---|---|---  \n  \n0\n\n#\n\nHardware required for making Real Industrial Robot Arm through EtherCAT\n\nedit\n\n  * [ ros2 ](/questions/scope:all/sort:activity-desc/tags:ros2/page:1/)\n\n  * [ humble ](/questions/scope:all/sort:activity-desc/tags:humble/page:1/)\n\n  * [ ros2-humble ](/questions/scope:all/sort:activity-desc/tags:ros2-humble/page:1/)\n\n  * [ industrial ](/questions/scope:all/sort:activity-desc/tags:industrial/page:1/)\n\n  * [ robot_arm ](/questions/scope:all/sort:activity-desc/tags:robot_arm/page:1/)\n\n  * [ ethercat ](/questions/scope:all/sort:activity-desc/tags:ethercat/page:1/)\n\n  * [ ros_control ](/questions/scope:all/sort:activity-desc/tags:ros_control/page:1/)\n\n  * [ soem ](/questions/scope:all/sort:activity-desc/tags:soem/page:1/)\n\n[ **asked 2023-07-10 02:15:17 -0500  ** ](/questions/417318/revisions/)\n\n[ ![Omar_Alkassas gravatar image](/m/default/media/images/nophoto.png?v=28)\n](/users/117542/omar_alkassas/)\n\n[ Omar_Alkassas ](/users/117542/omar_alkassas/)  \n1  \u25cf  3  \u25cf  4\n\n[ **updated 2023-07-10 03:16:31 -0500  ** ](/questions/417318/revisions/)\n\nHello,\n\nI want to make an articulated robot using ROS 2 humble. It will be used in\nindustry, so the motors are more industrial. the motor is connected to a\ndriver to control it and the driver will be connected to my laptop which runs\nROS 2 humble through EtherCAT communication using EtherCAT cable. I want to\nask how to connect to this driver and send commands with ROS. Is there a\npackage to help me? And Will I need a controller or a hardware device to\nconnect the laptop to the drivers?\n\nThanks in advance,\n\n[ edit ](/questions/417318/edit/) [ retag ](/s/questions/417318/retag/) flag\noffensive  [ close ](/questions/417318/close/) merge  delete\n\n##  Comments\n\nIsn't this a duplicate of [ #q416701\n](http://answers.ros.org/question/416701/) ?\n\n[ ![gvdhoorn gravatar image](/upfiles/avatars/gvdhoorn/resized/16/4550046.png)\n](/users/5184/gvdhoorn/) [ gvdhoorn ](/users/5184/gvdhoorn/) (  2023-07-10\n04:47:33 -0500  )  edit\n\nadd a comment\n\n##  Question Tools\n\nFollow\n\n1 follower\n\n[ subscribe to rss feed ](/feeds/question/417318/ \"subscribe to the rss feed\")\n\n##  Stats\n\nAsked: ** 2023-07-10 02:15:17 -0500  **\n\nSeen: **158 times**\n\nLast updated: **Jul 10 '23**\n\n##  Related questions\n\n[ Send an array or a list between nodes? ](/question/411851/send-an-array-or-\na-list-between-nodes/)\n\n[ ROS2 nav2_turorial on win10 ERROR! ](/question/418092/ros2-nav2_turorial-on-\nwin10-error/)\n\n[ What is the cause of ROS2 XML launch substitution error \"Unknown\nsubstitution: arg\"? ](/question/411977/what-is-the-cause-of-ros2-xml-launch-\nsubstitution-error-unknown-substitution-arg/)\n\n[ Where does message \"Message Filter dropping message\" comes from\n](/question/409132/where-does-message-message-filter-dropping-message-comes-\nfrom/)\n\n[ map_server Caught exception in callback for transition 10\n](/question/413968/map_server-caught-exception-in-callback-for-transition-10/)\n\n[ Using Nav2 with external localization source ](/question/409260/using-\nnav2-with-external-localization-source/)\n\n[ rviz2 unable to create glx context ](/question/408252/rviz2-unable-to-\ncreate-glx-context/)\n\n[ MoveIt2 Tutorials Getting Stuck ](/question/404996/moveit2-tutorials-\ngetting-stuck/)\n\n[ ros2 run - symbol not found on custom msg ](/question/326008/ros2-run-\nsymbol-not-found-on-custom-msg/)\n\n[ rosbag2 doesn't write meta data file ](/question/397687/rosbag2-doesnt-\nwrite-meta-data-file/)\n\n[ ![cc-by-sa](/m/default/media/images/cc-by-sa.png?v=28)\n](http://creativecommons.org/licenses/by-sa/3.0/legalcode) ROS Answers is\nlicensed under Creative Commons Attribution 3.0 Content on this site is\nlicensed under a [ Creative Commons Attribution Share Alike 3.0\n](http://creativecommons.org/licenses/by-sa/3.0/legalcode) license.\n\n[ about ](/about/) |  [ faq ](/faq/) |  [ help ](/help/ \"help\") |  [ privacy\npolicy ](/privacy/) |  [ terms of service ](/terms/)\n\n[ Powered by Askbot version 0.10.2 ](http://askbot.com)\n\nPlease note: ROS Answers requires javascript to work properly, please enable\njavascript in your browser, [ here is how\n](https://www.google.com/support/bin/answer.py?answer=23852)\n\n[ ![ gravatar image]() ]() [ ]() (  2024-04-14 20:00:14 -0500  )  edit\n\n[ none ](/questions/scope:all/sort:activity-desc/tags:none/page:1/) \u00d7\n\n  *[\n              2023-07-10 02:15:17 -0500\n             ]: 2023-07-10 02:15:17 -0500\n  *[\n              2023-07-10 03:16:31 -0500\n             ]: 2023-07-10 03:16:31 -0500\n  *[\n             2023-07-10 04:47:33 -0500\n            ]: 2023-07-10 04:47:33 -0500\n  *[\n        2023-07-10 02:15:17 -0500\n       ]: 2023-07-10 02:15:17 -0500\n  *[\n        2024-04-14 20:00:14 -0500\n       ]: 2024-04-14 20:00:14 -0500\n\n"
  },
  {
    "id": "ros_convert/deserializingmultipl.txt",
    "content": "First time here? Check out the FAQ!\n\n  \nROS Resources: [ Documentation ](http://wiki.ros.org/) | [ Support\n](http://wiki.ros.org/Support) | [ Discussion Forum\n](http://discourse.ros.org/) | [ Index ](http://index.ros.org/) | [ Service\nStatus ](http://status.ros.org/) | [ ros @ Robotics Stack Exchange\n](https://robotics.stackexchange.com/questions/tagged/ros)  \n---  \n  \n_Attention:_ Answers.ros.org is deprecated as of August the 11th, 2023. Please\nvisit [ robotics.stackexchange.com ](http://robotics.stackexchange.com) to ask\na new question. This site will remain online in read-only mode during the\ntransition and into the foreseeable future. Selected questions and answers\nhave been migrated, and redirects have been put in place to direct users to\nthe corresponding questions on Robotics Stack Exchange. Additional details are\n[ available here ](https://discourse.ros.org/t/ros-and-gazebo-answers-\nmigration-to-robotics-stack-exchange-process/31494) .\n\n[ Hi there! Please sign in\n](/account/signin/?next=/question/369573/deserializing-multiple-topics-from-a-\nros2-bag-sqlite3/) [ help ](/help/ \"help\")\n\n[ ![ROS Answers logo](/m/ros/media/images/logoros.png?v=28) ](/questions/)\n\n[ tags ](/tags/) [ users ](/users/) [ badges ](/badges/)\n\nThe site is read-only. Please transition to use Robotics Stack Exchange\n\n[ __ ](/questions/) |\n\n[ ALL ](/questions/scope:all/sort:activity-desc/page:1/) [ UNANSWERED\n](/questions/scope:unanswered/sort:answers-asc/page:1/)\n\n|\n\n|  [ Ask Your Question ](/questions/ask/)  \n---|---|---|---  \n  \n1\n\n#\n\nDeserializing multiple topics from a ROS2 Bag (SQLite3)\n\nedit\n\n  * [ ros2 ](/questions/scope:all/sort:activity-desc/tags:ros2/page:1/)\n\n  * [ dashing ](/questions/scope:all/sort:activity-desc/tags:dashing/page:1/)\n\n  * [ bag ](/questions/scope:all/sort:activity-desc/tags:bag/page:1/)\n\n  * [ ros2bag ](/questions/scope:all/sort:activity-desc/tags:ros2bag/page:1/)\n\n  * [ serialization ](/questions/scope:all/sort:activity-desc/tags:serialization/page:1/)\n\n  * [ deserialization ](/questions/scope:all/sort:activity-desc/tags:deserialization/page:1/)\n\n  * [ ros_serialization ](/questions/scope:all/sort:activity-desc/tags:ros_serialization/page:1/)\n\n  * [ turtlesim ](/questions/scope:all/sort:activity-desc/tags:turtlesim/page:1/)\n\n  * [ csv ](/questions/scope:all/sort:activity-desc/tags:csv/page:1/)\n\n[ **asked 2021-01-14 10:47:48 -0500  ** ](/questions/369573/revisions/)\n\n[ ![Aghiad Haloul gravatar image](/m/default/media/images/nophoto.png?v=28)\n](/users/67878/aghiad-haloul/)\n\n[ Aghiad Haloul ](/users/67878/aghiad-haloul/) ![flag of\nGermany](/m/default/media/images/flags/de.gif?v=28)  \n11  \u25cf  1  \u25cf  1  \u25cf  2\n\nI'm using ROS 2 Dashing, Ubuntu 18.04.\n\nI've recorded data with ` ros2 bag ` as explained in [ the ROS2 tutorial\n](https://index.ros.org/doc/ros2/Tutorials/Ros2bag/Recording-And-Playing-Back-\nData/) from the ` turtlesim ` package.\n\nFirst, I started the node:\n\n    \n    \n    ros2 run turtlesim turtlesim_node\n    ros2 run turtlesim turtle_teleop_key\n    \n\nthen I recorded all three topics with\n\n    \n    \n    ros2 bag record -a\n    \n\nnamely, the topics are:\n\n  * ` /turtle1/cmd_vel ` of type ` geometry_msgs/msg/Twist `\n  * ` /turtle1/color_sensor ` of type ` turtlesim/msg/Color `\n  * ` /turtle1/pose ` of type ` turtlesim/msg/Pose `\n\nI am interested in viewing the data recorded as text files, but the .db3\nSQLite3 file inside the bag shows the data as BLOB (binary large object),\nstating: ` Binary data cannot be viewed with the text editor ` .\n\nI am able to deserialize data from the bag if there is one topic **only** ,\nbut I'm not sure how to deserialize multiple topics.\n\nThe approach I'm trying ( [ found here ](https://kyungpyo-\nkim.github.io/study/ros2-bag-file-parsing/) ) is to use `\nrosbag2::converter_interfaces::SerializationFormatConverter ` :\n\n    \n    \n    void deserialize(const std::string datatype_name){\n      //Opening part:\n      rosbag2::SequentialReader reader;\n      rosbag2::ConverterOptions converter_options{};\n      converter_options.input_serialization_format = \"cdr\";\n      converter_options.output_serialization_format = \"cdr\";\n      reader.open(storage_options, converter_options);\n    \n      // Load the topics\n      auto topics = reader.get_all_topics_and_types();\n      rosbag2::SerializationFormatConverterFactory factory;\n      std::unique_ptr<rosbag2::converter_interfaces::SerializationFormatDeserializer> cdr_deserializer_;\n      cdr_deserializer_ = factory.load_deserializer(\"cdr\");\n    \n      // Iterate through the file\n      while(reader.has_next()){\n        auto serialized_message = reader.read_next();\n    \n        auto ros_message = std::make_shared<rosbag2_introspection_message_t>();\n        ros_message->time_stamp = 0;\n        ros_message->message = nullptr;\n        ros_message->allocator = rcutils_get_default_allocator();\n        auto type_support = rosbag2::get_typesupport(datatype_name, \"rosidl_typesupport_cpp\");\n    \n        if(datatype_name == \"geometry_msgs/msg/Twist\"){\n          ros_message->message = new geometry_msgs::msg::Twist();\n        }\n        else if(datatype_name == \"turtlesim/msg/Pose\"){\n          ros_message->message = new turtlesim::msg::Pose();\n        }\n        else if(datatype_name == \"turtlesim/msg/Color\"){\n          ros_message->message = new turtlesim::msg::Color();\n        }\n        else{\n          std::cout << \"not supported\" << std::endl;\n        }\n        if(ros_message->message){\n          cdr_deserializer_->deserialize(serialized_message, type_support, ros_message);\n          // optionally, print:\n          // std::cout << (int)msgColor.r << \" \" << (int)msgColor.g << \" \" <<  (int)msgColor.b <<  std::endl;\n        }\n      }\n    }\n    \n\nBut the data does not deserialize correctly except for the first type, I\nassume it is because it should receive an offset of some sort before\ndeserialitazion starts.\n\n    \n    \n    [INFO] [rosbag2_storage]: Opened database '../rosbag2_test_data_multi'.\n    0x96d480    turtlesim/msg/Pose  Pose\n    0x96d480    turtlesim/msg/Pose  Pose\n    terminate called after throwing an instance of 'eprosima::fastcdr::exception::NotEnoughMemoryException'\n      what():  Not enough memory in the buffer stream\n    \n\nIs there a way to set a combination of ` datatype_name ` in the type_support?\n\n    \n    \n    auto type_support = rosbag2::get_typesupport(datatype_name, \"rosidl_typesupport_cpp\");\n    \n\nIs there a simpler way to convert ROS2 Bag files into csv/text without\nchanging the current version of Dashing?\n\nI'm not limited to C++, I found some cool python libraries that could help but\nthey do not support Dashing unfortunately.\n\nThank you for your help.\n\n[ edit ](/questions/369573/edit/) [ retag ](/s/questions/369573/retag/) flag\noffensive  [ close ](/questions/369573/close/) merge  delete\n\nadd a comment\n\n##  1  Answer\n\nSort by \u00bb  [ oldest  ](/question/369573/deserializing-multiple-topics-from-a-\nros2-bag-sqlite3/?sort=oldest#sort-top) [ newest\n](/question/369573/deserializing-multiple-topics-from-a-ros2-bag-\nsqlite3/?sort=latest#sort-top) [ most voted  ](/question/369573/deserializing-\nmultiple-topics-from-a-ros2-bag-sqlite3/?sort=votes#sort-top)\n\n0\n\n[ **answered 2021-04-01 08:26:37 -0500  ** ](/answers/375199/revisions/)\n\n[ ![Gerbert gravatar image](/m/default/media/images/nophoto.png?v=28)\n](/users/72796/gerbert/)\n\n[ Gerbert ](/users/72796/gerbert/)  \n1\n\n[ **updated 2021-04-02 06:36:49 -0500  ** ](/answers/375199/revisions/)\n\nI think the main problem is that the code does not check which message is\nactually read out of the ros2bag. You can do this by reading the ros topic:\n\nserialized_message->topic_name\n\nbefore deserializing.\n\nThen make sure to map the topic name to the type by initially retrieving the\ntopic and types from the ros2bag by\n\nauto topics = reader.get_all_topics_and_types();\n\nThe error message is common if one tries to deserialize with the wrong message\ntype.\n\nYou can find an expample at [ https://github.com/orascheg/ROS2BagFi...\n](https://github.com/orascheg/ROS2BagFileParsing.git)\n\n[ edit ](/s/answers/375199/edit/) flag offensive  delete  [ link\n](/question/369573/deserializing-multiple-topics-from-a-ros2-bag-\nsqlite3/?answer=375199#post-id-375199 \"permanent link\") more\n\n  *   * \n\nadd a comment\n\n##  Question Tools\n\nFollow\n\n1 follower\n\n[ subscribe to rss feed ](/feeds/question/369573/ \"subscribe to the rss feed\")\n\n##  Stats\n\nAsked: ** 2021-01-14 10:47:48 -0500  **\n\nSeen: **2,269 times**\n\nLast updated: **Apr 02 '21**\n\n##  Related questions\n\n[ [Ros2] Package Binaries ](/question/331971/ros2-package-binaries/)\n\n[ ROS2 Run __params not affecting node ](/question/335016/ros2-run-__params-\nnot-affecting-node/)\n\n[ ROS1 vs ROS2 serialization ](/question/371866/ros1-vs-ros2-serialization/)\n\n[ [ROS2] publishing UInt16 ](/question/349003/ros2-publishing-uint16/)\n\n[ State of ROS2 on embedded MCUs ](/question/326687/state-of-ros2-on-embedded-\nmcus/)\n\n[ subscription callback types ROS1 vs. ROS2 ](/question/333462/subscription-\ncallback-types-ros1-vs-ros2/)\n\n[ Get all key/value pairs from custom ROS2 message ](/question/370820/get-all-\nkeyvalue-pairs-from-custom-ros2-message/)\n\n[ [ROS2] Navigation2 only planning short local plan\n](/question/364379/ros2-navigation2-only-planning-short-local-plan/)\n\n[ How to get ROS2 parameter hosted by another Node ](/question/340600/how-to-\nget-ros2-parameter-hosted-by-another-node/)\n\n[ rclpy fails to run on arm64 after cross-compilation\n](/question/329161/rclpy-fails-to-run-on-arm64-after-cross-compilation/)\n\n[ ![cc-by-sa](/m/default/media/images/cc-by-sa.png?v=28)\n](http://creativecommons.org/licenses/by-sa/3.0/legalcode) ROS Answers is\nlicensed under Creative Commons Attribution 3.0 Content on this site is\nlicensed under a [ Creative Commons Attribution Share Alike 3.0\n](http://creativecommons.org/licenses/by-sa/3.0/legalcode) license.\n\n[ about ](/about/) |  [ faq ](/faq/) |  [ help ](/help/ \"help\") |  [ privacy\npolicy ](/privacy/) |  [ terms of service ](/terms/)\n\n[ Powered by Askbot version 0.10.2 ](http://askbot.com)\n\nPlease note: ROS Answers requires javascript to work properly, please enable\njavascript in your browser, [ here is how\n](https://www.google.com/support/bin/answer.py?answer=23852)\n\n[ ![ gravatar image]() ]() [ ]() (  2024-04-17 19:33:13 -0500  )  edit\n\n[ none ](/questions/scope:all/sort:activity-desc/tags:none/page:1/) \u00d7\n\n  *[\n              2021-01-14 10:47:48 -0500\n             ]: 2021-01-14 10:47:48 -0500\n  *[\n              2021-04-01 08:26:37 -0500\n             ]: 2021-04-01 08:26:37 -0500\n  *[\n              2021-04-02 06:36:49 -0500\n             ]: 2021-04-02 06:36:49 -0500\n  *[\n        2021-01-14 10:47:48 -0500\n       ]: 2021-01-14 10:47:48 -0500\n  *[\n        2024-04-17 19:33:13 -0500\n       ]: 2024-04-17 19:33:13 -0500\n\n"
  },
  {
    "id": "gazebo_tag/surfacematerialcolor.txt",
    "content": "First time here? Check out the FAQ!\n\n[ Gazebo ](http://gazebosim.org) | [ Ignition ](https://ignitionrobotics.org)\n| [ Community ](https://community.gazebosim.org/)\n\n_Attention:_ answers.gazebosim.org is deprecated as of August the 11th, 2023.\nPlease visit [ robotics.stackexchange.com ](http://robotics.stackexchange.com)\nto ask a new question. This site will remain online in read-only mode during\nthe transition and into the foreseeable future. Selected questions and answers\nhave been migrated, and redirects have been put in place to direct users to\nthe corresponding questions on Robotics Stack Exchange. Additional details are\n[ available here ](https://community.gazebosim.org/t/important-final-ros-\ngazebo-answers-migration-schedule/2185) .\n\n[ Hi there! Please sign in ](/account/signin/?next=/question/582/surface-\nmaterial-colors-from-urdf-and-collada/) [ help ](/help/ \"help\")\n\n[ ![Gazebo logo](/upfiles/gazebo_logo_1.png) ](/questions/)\n\n[ __ tags ](/tags/) [ __ users ](/users/) [ __ badges ](/badges/)\n\nThe site is read-only. Please transition to use Robotics Stack Exchange\n\n[ __ ](/questions/) |\n\n[ ALL ](/questions/scope:all/sort:activity-desc/page:1/) [ UNANSWERED\n](/questions/scope:unanswered/sort:answers-asc/page:1/)\n\n|\n\n|  [ Ask Your Question ](/questions/ask/)  \n---|---|---|---  \n  \n1\n\n#\n\nsurface material colors from URDF and COLLADA\n\nedit\n\n  * [ gazebo-1.2.5 ](/questions/scope:all/sort:activity-desc/tags:gazebo-1.2.5/page:1/)\n\n  * [ URDF ](/questions/scope:all/sort:activity-desc/tags:URDF/page:1/)\n\n  * [ color ](/questions/scope:all/sort:activity-desc/tags:color/page:1/)\n\n[ **asked 2013-01-01 04:19:54 -0500  ** ](/questions/582/revisions/)\n\n[ ![piyushk gravatar\nimage](//www.gravatar.com/avatar/4c0a1652789850a7953553e6d883eb06?s=32&d=identicon&r=PG)\n](/users/131/piyushk/)\n\n[ piyushk ](/users/131/piyushk/)  \n138  \u25cf  8  \u25cf  9  \u25cf  16\n\n[ **updated 2013-01-10 00:57:52 -0500  ** ](/questions/582/revisions/)\n\nGazebo 1.2.5 no longer seems to be picking up the ` material ` tag from the\nURDF file. This can be seen through the following commands (from [ this\ntutorial\n](http://www.ros.org/wiki/simulator_gazebo/Tutorials/SpawningObjectInSimulation)\non the ROS wiki).\n\n    \n    \n    roslaunch gazebo_worlds empty_world.launch\n    roslaunch gazebo_worlds table.launch\n    \n\nA screenshot can be seen [ here ](http://cs.utexas.edu/~piyushk/share/no-urdf-\ncolor.png) . I am facing the same problem in my robot models.\n\nOn a similar note, I have seen weird behavior in Gazebo from my COLLADA mesh\nmodels (this behavior was also similarly weird in Gazebo 1.0 + ROS Fuerte). I\nwould like to use the colors as specified in the mesh file (rviz + RobotModel\nhandle this correctly).\n\nGazebo seems to start with all the meshes painted grey. If any of the joints\nmove, then the corresponding links seem to alternate between grey and the\ncolor as specified by the mesh. A video of this can be seen [ here\n](http://cs.utexas.edu/~piyushk/share/weird-mesh-color.ogv) .\n\nI am not sure what information will be required to debug this, but I can place\nit online.\n\n**Edit #1:**\n\nReplacing the material tag as suggested by the SDF documentation and Nate's\nanswer does not work. I've replace the material tag of all my urdf links with\nthis line from my world file which I know works:\n\n    \n    \n    <material>\n      <script>\n        <uri>file://media/materials/scripts/gazebo.material</uri>\n        <name>Gazebo/Green</name>\n      </script>\n    </material>\n    \n\n  * Here is the generated urdf after running through xacro: [ test.urdf ](http://cs.utexas.edu/~piyushk/share/test.urdf)\n  * Here is the world file I get from gazebo gui (after using save world as): [ test.world ](http://cs.utexas.edu/~piyushk/share/test.world) . \n    * Notice all the material tags from URDF are empty (Search for \"material/\") \n    * All the tags from my world SDF file are fine and rendered correctly. \n\nThanks!!\n\n[ edit ](/questions/582/edit/) [ retag ](/s/questions/582/retag/) flag\noffensive  [ close ](/questions/582/close/) merge  delete\n\n##  Comments\n\ni'm having this same issue and would like to have the material color from the\nURDF to be used\n\n[ ![davetcoleman gravatar\nimage](//www.gravatar.com/avatar/9ca6e6fe619a51425fcb84fbde6ace8a?s=16&d=identicon&r=PG)\n](/users/134/davetcoleman/) [ davetcoleman ](/users/134/davetcoleman/) (\n2013-01-02 14:48:38 -0500  )  edit\n\nDitto! I had to go back from ROS Groovy to ROS fuerte for this reason.\n\n[ ![Ben B gravatar\nimage](//www.gravatar.com/avatar/e8232b91ef7a1bc30f2b5f865d8d5ab8?s=16&d=identicon&r=PG)\n](/users/136/ben-b/) [ Ben B ](/users/136/ben-b/) (  2013-01-07 19:18:01 -0500\n)  edit\n\nadd a comment\n\n##  3  Answers\n\nSort by \u00bb  [ oldest  ](/question/582/surface-material-colors-from-urdf-and-\ncollada/?sort=oldest#sort-top) [ newest  ](/question/582/surface-material-\ncolors-from-urdf-and-collada/?sort=latest#sort-top) [ most voted\n](/question/582/surface-material-colors-from-urdf-and-\ncollada/?sort=votes#sort-top)\n\n1\n\n[ **answered 2013-01-10 02:56:25 -0500  ** ](/answers/654/revisions/)\n\n[ ![hsu gravatar\nimage](//www.gravatar.com/avatar/b097f55d6872f4a2cb040e90bdd92872?s=32&d=identicon&r=PG)\n](/users/6/hsu/)\n\n[ hsu ](/users/6/hsu/)  \n1873  \u25cf  14  \u25cf  19\n\n[ **updated 2013-01-22 10:30:37 -0500  ** ](/answers/654/revisions/)\n\nfixed in trunk per [ commit\n](https://bitbucket.org/osrf/gazebo/commits/d9edb000a87db61d30b85c7f14885be451dda876)\n, will make a groovy release soon.\n\n**Update 2012-01-22** [ simulator_gazebo 1.7.8\n](http://ros.org/wiki/simulator_gazebo/ChangeList/1.7#A1.7.8_.282013-01-17.29)\nwith a fix for the materials issue in [ tutorial\n](http://www.ros.org/wiki/simulator_gazebo/Tutorials/SpawningObjectInSimulation)\nis in [ shadow fixed ](http://packages.ros.org/ros-shadow-\nfixed/ubuntu/pool/main/r/ros-groovy-simulator-gazebo/) , should make it out to\nthe [ public repo ](http://packages.ros.org/ros/ubuntu/pool/main/r/ros-groovy-\nsimulator-gazebo/) soon.\n\n[ edit ](/s/answers/654/edit/) flag offensive  delete  [ link\n](/question/582/surface-material-colors-from-urdf-and-\ncollada/?answer=654#post-id-654 \"permanent link\") more\n\n  *   * \n\nadd a comment\n\n1\n\n[ **answered 2013-01-09 15:53:28 -0500  ** ](/answers/634/revisions/)\n\n[ ![nkoenig gravatar\nimage](//www.gravatar.com/avatar/7d7b669912eaa47178b36acdee3c72ad?s=32&d=identicon&r=PG)\n](/users/5/nkoenig/)\n\n[ nkoenig ](/users/5/nkoenig/)  \n7676  \u25cf  8  \u25cf  44  \u25cf  71  [ http://gazebosim.org/ ](http://gazebosim.org/\n\"nkoenig's website is http://gazebosim.org/\")\n\nThe URDF in that tutorial is incorrect. It should be:\n\n    \n    \n    <material>\n      <script>\n        <uri>URI of the .material file</uri>\n        <name>Name of the material</name>\n      </script>\n    </material>\n    \n\nLook for the SDF documentation for information: [ ](http://gazebosim.org/sdf)\n[ http://gazebosim.org/sdf ](http://gazebosim.org/sdf)\n\n[ edit ](/s/answers/634/edit/) flag offensive  delete  [ link\n](/question/582/surface-material-colors-from-urdf-and-\ncollada/?answer=634#post-id-634 \"permanent link\") more\n\n  *   * \n\n##  Comments\n\n[ @nkoenig ](/users/5/nkoenig/) : I just tried this and it does not work. See\nupdated question. I can't see why it should not work if I take a look at\nurdf_parser.cc, but I am having trouble compiling the simulator_gazebo stack\nfrom source to figure it out.\n\n[ ![piyushk gravatar\nimage](//www.gravatar.com/avatar/4c0a1652789850a7953553e6d883eb06?s=16&d=identicon&r=PG)\n](/users/131/piyushk/) [ piyushk ](/users/131/piyushk/) (  2013-01-10 00:59:44\n-0500  )  edit\n\nadd a comment\n\n0\n\n[ **answered 2013-01-10 02:56:46 -0500  ** ](/answers/655/revisions/)\n\n[ ![hsu gravatar\nimage](//www.gravatar.com/avatar/b097f55d6872f4a2cb040e90bdd92872?s=32&d=identicon&r=PG)\n](/users/6/hsu/)\n\n[ hsu ](/users/6/hsu/)  \n1873  \u25cf  14  \u25cf  19\n\nfixed in trunk per [ commit\n](https://bitbucket.org/osrf/gazebo/commits/d9edb000a87db61d30b85c7f14885be451dda876)\n, will make a groovy release soon.\n\n[ edit ](/s/answers/655/edit/) flag offensive  delete  [ link\n](/question/582/surface-material-colors-from-urdf-and-\ncollada/?answer=655#post-id-655 \"permanent link\") more\n\n  *   * \n\nadd a comment\n\n##  Question Tools\n\nFollow\n\n1 follower\n\n[ subscribe to rss feed ](/feeds/question/582/ \"subscribe to the rss feed\")\n\n##  Stats\n\nAsked: ** 2013-01-01 04:19:54 -0500  **\n\nSeen: **3,875 times**\n\nLast updated: **Jan 22 '13**\n\n##  Related questions\n\n[ How to change color of my sdf/urdf models from script ?\n](/question/25405/how-to-change-color-of-my-sdfurdf-models-from-script/)\n\n[ Color of a link is not taken into account ](/question/23766/color-of-a-link-\nis-not-taken-into-account/)\n\n[ Ackermann robot URDF or SDF ](/question/24439/ackermann-robot-urdf-or-sdf/)\n\n[ Problem adding gazebo_ros_control plugin in sdf model and running in gazebo\n](/question/5599/problem-adding-gazebo_ros_control-plugin-in-sdf-model-and-\nrunning-in-gazebo/)\n\n[ Xacro model spawn issues ](/question/13323/xacro-model-spawn-issues/)\n\n[ Empty cylinder geometry for gazebo ](/question/26098/empty-cylinder-\ngeometry-for-gazebo/)\n\n[ Is it possible to define the joint frame? ](/question/24427/is-it-possible-\nto-define-the-joint-frame/)\n\n[ How to set a right revolute joint coordinate? ](/question/23560/how-to-set-\na-right-revolute-joint-coordinate/)\n\n[ Colors not shown in Gazebo 5 ](/question/12418/colors-not-shown-in-\ngazebo-5/)\n\n[ Friction Not Working Between URDF and Database Model\n](/question/16928/friction-not-working-between-urdf-and-database-model/)\n\n[ ![cc-by-sa](/m/default/media/images/cc-by-sa.png?v=2)\n](http://creativecommons.org/licenses/by-sa/3.0/legalcode) Copyright Askbot,\n2010-2011. Content on this site is licensed under a [ Creative Commons\nAttribution Share Alike 3.0 ](http://creativecommons.org/licenses/by-\nsa/3.0/legalcode) license.\n\n[ about ](/about/) |  [ faq ](/faq/) |  [ help ](/help/ \"help\") |  [ privacy\npolicy ](/privacy/) |  [ terms of service ](/terms/)\n\n[ Powered by Askbot version 0.7.58 ](http://askbot.com)\n\nPlease note: Gazebo requires javascript to work properly, please enable\njavascript in your browser, [ here is how\n](https://www.google.com/support/bin/answer.py?answer=23852)\n\n[ ![ gravatar image]() ]() [ ]() (  2024-04-16 18:08:46 -0500  )  edit\n\n[ none ](/questions/scope:all/sort:activity-desc/tags:none/page:1/) \u00d7\n\n  *[\n              2013-01-01 04:19:54 -0500\n             ]: 2013-01-01 04:19:54 -0500\n  *[\n              2013-01-10 00:57:52 -0500\n             ]: 2013-01-10 00:57:52 -0500\n  *[\n             2013-01-02 14:48:38 -0500\n            ]: 2013-01-02 14:48:38 -0500\n  *[\n             2013-01-07 19:18:01 -0500\n            ]: 2013-01-07 19:18:01 -0500\n  *[\n              2013-01-10 02:56:25 -0500\n             ]: 2013-01-10 02:56:25 -0500\n  *[\n              2013-01-22 10:30:37 -0500\n             ]: 2013-01-22 10:30:37 -0500\n  *[\n              2013-01-09 15:53:28 -0500\n             ]: 2013-01-09 15:53:28 -0500\n  *[\n             2013-01-10 00:59:44 -0500\n            ]: 2013-01-10 00:59:44 -0500\n  *[\n              2013-01-10 02:56:46 -0500\n             ]: 2013-01-10 02:56:46 -0500\n  *[\n        2013-01-01 04:19:54 -0500\n       ]: 2013-01-01 04:19:54 -0500\n  *[\n        2024-04-16 18:08:46 -0500\n       ]: 2024-04-16 18:08:46 -0500\n\n"
  },
  {
    "id": "rclcpp_service_action/clienthpp.txt",
    "content": "// Copyright 2018 Open Source Robotics Foundation, Inc.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n#ifndef RCLCPP_ACTION__CLIENT_HPP_\n#define RCLCPP_ACTION__CLIENT_HPP_\n#include <algorithm>\n#include <chrono>\n#include <functional>\n#include <future>\n#include <map>\n#include <memory>\n#include <mutex>\n#include <string>\n#include <unordered_map>\n#include <utility>\n#include \"rcl/event_callback.h\"\n#include \"rclcpp/exceptions.hpp\"\n#include \"rclcpp/macros.hpp\"\n#include \"rclcpp/node_interfaces/node_base_interface.hpp\"\n#include \"rclcpp/node_interfaces/node_logging_interface.hpp\"\n#include \"rclcpp/node_interfaces/node_graph_interface.hpp\"\n#include \"rclcpp/logger.hpp\"\n#include \"rclcpp/time.hpp\"\n#include \"rclcpp/waitable.hpp\"\n#include \"rosidl_runtime_c/action_type_support_struct.h\"\n#include \"rosidl_typesupport_cpp/action_type_support.hpp\"\n#include \"rclcpp_action/client_goal_handle.hpp\"\n#include \"rclcpp_action/exceptions.hpp\"\n#include \"rclcpp_action/types.hpp\"\n#include \"rclcpp_action/visibility_control.hpp\"\n\n\n\nnamespace rclcpp_action\n{\n// Forward declaration\nclass ClientBaseImpl;\n/// Base Action Client implementation\n/// \\internal\n/**\n * This class should not be used directly by users wanting to create an aciton client.\n * Instead users should use `rclcpp_action::Client<>`.\n *\n * Internally, this class is responsible for interfacing with the `rcl_action` API.\n */\nclass ClientBase : public rclcpp::Waitable\n{\npublic:\n  RCLCPP_ACTION_PUBLIC\n  virtual ~ClientBase();\n  /// Enum to identify entities belonging to the action client\n  enum class EntityType : std::size_t\n  {\n    GoalClient,\n    ResultClient,\n    CancelClient,\n    FeedbackSubscription,\n    StatusSubscription,\n  };\n  /// Return true if there is an action server that is ready to take goal requests.\n  RCLCPP_ACTION_PUBLIC\n  bool\n  action_server_is_ready() const;\n  /// Wait for action_server_is_ready() to become true, or until the given timeout is reached.\n  template<typename RepT = int64_t, typename RatioT = std::milli>\n  bool\n  wait_for_action_server(\n    std::chrono::duration<RepT, RatioT> timeout = std::chrono::duration<RepT, RatioT>(-1))\n  {\n    return wait_for_action_server_nanoseconds(\n      std::chrono::duration_cast<std::chrono::nanoseconds>(timeout)\n    );\n  }\n\n\n\n  // -------------\n  // Waitables API\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  size_t\n  get_number_of_ready_subscriptions() override;\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  size_t\n  get_number_of_ready_timers() override;\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  size_t\n  get_number_of_ready_clients() override;\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  size_t\n  get_number_of_ready_services() override;\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  size_t\n  get_number_of_ready_guard_conditions() override;\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  void\n  add_to_wait_set(rcl_wait_set_t * wait_set) override;\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  bool\n  is_ready(rcl_wait_set_t * wait_set) override;\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  std::shared_ptr<void>\n  take_data() override;\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  std::shared_ptr<void>\n  take_data_by_entity_id(size_t id) override;\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n\n\n\n  void\n  execute(std::shared_ptr<void> & data) override;\n  /// \\internal\n  /// Set a callback to be called when action client entities have an event\n  /**\n   * The callback receives a size_t which is the number of messages received\n   * since the last time this callback was called.\n   * Normally this is 1, but can be > 1 if messages were received before any\n   * callback was set.\n   *\n   * The callback also receives an int identifier argument, which identifies\n   * the action client entity which is ready.\n   * This implies that the provided callback can use the identifier to behave\n   * differently depending on which entity triggered the waitable to become ready.\n   *\n   * Calling it again will clear any previously set callback.\n   *\n   * An exception will be thrown if the callback is not callable.\n   *\n   * This function is thread-safe.\n   *\n   * If you want more information available in the callback, like the subscription\n   * or other information, you may use a lambda with captures or std::bind.\n   *\n   * \\param[in] callback functor to be called when a new message is received.\n   */\n  RCLCPP_ACTION_PUBLIC\n  void\n  set_on_ready_callback(std::function<void(size_t, int)> callback) override;\n  /// Unset the callback registered for new events, if any.\n  RCLCPP_ACTION_PUBLIC\n  void\n  clear_on_ready_callback() override;\n  // End Waitables API\n  // -----------------\nprotected:\n  RCLCPP_ACTION_PUBLIC\n  ClientBase(\n    rclcpp::node_interfaces::NodeBaseInterface::SharedPtr node_base,\n    rclcpp::node_interfaces::NodeGraphInterface::SharedPtr node_graph,\n\n\n\n    rclcpp::node_interfaces::NodeLoggingInterface::SharedPtr node_logging,\n    const std::string & action_name,\n    const rosidl_action_type_support_t * type_support,\n    const rcl_action_client_options_t & options);\n  /// Wait for action_server_is_ready() to become true, or until the given timeout is reached.\n  RCLCPP_ACTION_PUBLIC\n  bool\n  wait_for_action_server_nanoseconds(std::chrono::nanoseconds timeout);\n  // -----------------------------------------------------\n  // API for communication between ClientBase and Client<>\n  using ResponseCallback = std::function<void (std::shared_ptr<void> response)>;\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  rclcpp::Logger get_logger();\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  virtual\n  GoalUUID\n  generate_goal_id();\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  virtual\n  void\n  send_goal_request(\n    std::shared_ptr<void> request,\n    ResponseCallback callback);\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  virtual\n  void\n  send_result_request(\n    std::shared_ptr<void> request,\n    ResponseCallback callback);\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  virtual\n  void\n  send_cancel_request(\n    std::shared_ptr<void> request,\n    ResponseCallback callback);\n\n\n\n  /// \\internal\n  virtual\n  std::shared_ptr<void>\n  create_goal_response() const = 0;\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  virtual\n  void\n  handle_goal_response(\n    const rmw_request_id_t & response_header,\n    std::shared_ptr<void> goal_response);\n  /// \\internal\n  virtual\n  std::shared_ptr<void>\n  create_result_response() const = 0;\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  virtual\n  void\n  handle_result_response(\n    const rmw_request_id_t & response_header,\n    std::shared_ptr<void> result_response);\n  /// \\internal\n  virtual\n  std::shared_ptr<void>\n  create_cancel_response() const = 0;\n  /// \\internal\n  RCLCPP_ACTION_PUBLIC\n  virtual\n  void\n  handle_cancel_response(\n    const rmw_request_id_t & response_header,\n    std::shared_ptr<void> cancel_response);\n  /// \\internal\n  virtual\n  std::shared_ptr<void>\n  create_feedback_message() const = 0;\n  /// \\internal\n  virtual\n  void\n\n\n\n  handle_feedback_message(std::shared_ptr<void> message) = 0;\n  /// \\internal\n  virtual\n  std::shared_ptr<void>\n  create_status_message() const = 0;\n  /// \\internal\n  virtual\n  void\n  handle_status_message(std::shared_ptr<void> message) = 0;\n  // End API for communication between ClientBase and Client<>\n  // ---------------------------------------------------------\n  /// \\internal\n  /// Set a callback to be called when the specified entity is ready\n  RCLCPP_ACTION_PUBLIC\n  void\n  set_on_ready_callback(\n    EntityType entity_type,\n    rcl_event_callback_t callback,\n    const void * user_data);\n  // Mutex to protect the callbacks storage.\n  std::recursive_mutex listener_mutex_;\n  // Storage for std::function callbacks to keep them in scope\n  std::unordered_map<EntityType, std::function<void(size_t)>> entity_type_to_on_ready_callback_;\nprivate:\n  std::unique_ptr<ClientBaseImpl> pimpl_;\n  /// Set a std::function callback to be called when the specified entity is ready\n  RCLCPP_ACTION_PUBLIC\n  void\n  set_callback_to_entity(\n    EntityType entity_type,\n    std::function<void(size_t, int)> callback);\n  bool on_ready_callback_set_{false};\n};\n/// Action Client\n/**\n * This class creates an action client.\n *\n * To create an instance of an action client use `rclcpp_action::create_client()`.\n *\n * Internally, this class is responsible for:\n\n\n\n *  - coverting between the C++ action type and generic types for `rclcpp_action::ClientBase`, and\n *  - calling user callbacks.\n */\ntemplate<typename ActionT>\nclass Client : public ClientBase\n{\npublic:\n  RCLCPP_SMART_PTR_DEFINITIONS_NOT_COPYABLE(Client<ActionT>)\n  using Goal = typename ActionT::Goal;\n  using Feedback = typename ActionT::Feedback;\n  using GoalHandle = ClientGoalHandle<ActionT>;\n  using WrappedResult = typename GoalHandle::WrappedResult;\n  using GoalResponseCallback = std::function<void (typename GoalHandle::SharedPtr)>;\n  using FeedbackCallback = typename GoalHandle::FeedbackCallback;\n  using ResultCallback = typename GoalHandle::ResultCallback;\n  using CancelRequest = typename ActionT::Impl::CancelGoalService::Request;\n  using CancelResponse = typename ActionT::Impl::CancelGoalService::Response;\n  using CancelCallback = std::function<void (typename CancelResponse::SharedPtr)>;\n  /// Options for sending a goal.\n  /**\n   * This struct is used to pass parameters to the function `async_send_goal`.\n   */\n  struct SendGoalOptions\n  {\n    SendGoalOptions()\n    : goal_response_callback(nullptr),\n      feedback_callback(nullptr),\n      result_callback(nullptr)\n    {\n    }\n    /// Function called when the goal is accepted or rejected.\n    /**\n     * Takes a single argument that is a goal handle shared pointer.\n     * If the goal is accepted, then the pointer points to a valid goal handle.\n     * If the goal is rejected, then pointer has the value `nullptr`.\n     */\n    GoalResponseCallback goal_response_callback;\n    /// Function called whenever feedback is received for the goal.\n    FeedbackCallback feedback_callback;\n    /// Function called when the result for the goal is received.\n\n\n\n    ResultCallback result_callback;\n  };\n  /// Construct an action client.\n  /**\n   * This constructs an action client, but it will not work until it has been added to a node.\n   * Use `rclcpp_action::create_client()` to both construct and add to a node.\n   *\n   * \\param[in] node_base A pointer to the base interface of a node.\n   * \\param[in] node_graph A pointer to an interface that allows getting graph information about\n   *   a node.\n   * \\param[in] node_logging A pointer to an interface that allows getting a node's logger.\n   * \\param[in] action_name The action name.\n   * \\param[in] client_options Options to pass to the underlying `rcl_action::rcl_action_client_t`.\n   */\n  Client(\n    rclcpp::node_interfaces::NodeBaseInterface::SharedPtr node_base,\n    rclcpp::node_interfaces::NodeGraphInterface::SharedPtr node_graph,\n    rclcpp::node_interfaces::NodeLoggingInterface::SharedPtr node_logging,\n    const std::string & action_name,\n    const rcl_action_client_options_t & client_options = rcl_action_client_get_default_options()\n  )\n  : ClientBase(\n      node_base, node_graph, node_logging, action_name,\n      rosidl_typesupport_cpp::get_action_type_support_handle<ActionT>(),\n      client_options)\n  {\n  }\n  /// Send an action goal and asynchronously get the result.\n  /**\n   * If the goal is accepted by an action server, the returned future is set to a `ClientGoalHandle`.\n   * If the goal is rejected by an action server, then the future is set to a `nullptr`.\n   *\n   * The returned goal handle is used to monitor the status of the goal and get the final result.\n   * It is valid as long as you hold a reference to the shared pointer or until the\n   * rclcpp_action::Client is destroyed at which point the goal status will become UNKNOWN.\n   *\n   * \\param[in] goal The goal request.\n   * \\param[in] options Options for sending the goal request. Contains references to callbacks for\n   *   the goal response (accepted/rejected), feedback, and the final result.\n   * \\return A future that completes when the goal has been accepted or rejected.\n\n\n\n   *   If the goal is rejected, then the result will be a `nullptr`.\n   */\n  std::shared_future<typename GoalHandle::SharedPtr>\n  async_send_goal(const Goal & goal, const SendGoalOptions & options = SendGoalOptions())\n  {\n    // Put promise in the heap to move it around.\n    auto promise = std::make_shared<std::promise<typename GoalHandle::SharedPtr>>();\n    std::shared_future<typename GoalHandle::SharedPtr> future(promise->get_future());\n    using GoalRequest = typename ActionT::Impl::SendGoalService::Request;\n    auto goal_request = std::make_shared<GoalRequest>();\n    goal_request->goal_id.uuid = this->generate_goal_id();\n    goal_request->goal = goal;\n    this->send_goal_request(\n      std::static_pointer_cast<void>(goal_request),\n      [this, goal_request, options, promise](std::shared_ptr<void> response) mutable\n      {\n        using GoalResponse = typename ActionT::Impl::SendGoalService::Response;\n        auto goal_response = std::static_pointer_cast<GoalResponse>(response);\n        if (!goal_response->accepted) {\n          promise->set_value(nullptr);\n          if (options.goal_response_callback) {\n            options.goal_response_callback(nullptr);\n          }\n          return;\n        }\n        GoalInfo goal_info;\n        goal_info.goal_id.uuid = goal_request->goal_id.uuid;\n        goal_info.stamp = goal_response->stamp;\n        // Do not use std::make_shared as friendship cannot be forwarded.\n        std::shared_ptr<GoalHandle> goal_handle(\n          new GoalHandle(goal_info, options.feedback_callback, options.result_callback));\n        {\n          std::lock_guard<std::mutex> guard(goal_handles_mutex_);\n          goal_handles_[goal_handle->get_goal_id()] = goal_handle;\n        }\n        promise->set_value(goal_handle);\n        if (options.goal_response_callback) {\n          options.goal_response_callback(goal_handle);\n        }\n        if (options.result_callback) {\n\n\n\n          this->make_result_aware(goal_handle);\n        }\n      });\n    // TODO(jacobperron): Encapsulate into it's own function and\n    //                    consider exposing an option to disable this cleanup\n    // To prevent the list from growing out of control, forget about any goals\n    // with no more user references\n    {\n      std::lock_guard<std::mutex> guard(goal_handles_mutex_);\n      auto goal_handle_it = goal_handles_.begin();\n      while (goal_handle_it != goal_handles_.end()) {\n        if (!goal_handle_it->second.lock()) {\n          RCLCPP_DEBUG(\n            this->get_logger(),\n            \"Dropping weak reference to goal handle during send_goal()\");\n          goal_handle_it = goal_handles_.erase(goal_handle_it);\n        } else {\n          ++goal_handle_it;\n        }\n      }\n    }\n    return future;\n  }\n  /// Asynchronously get the result for an active goal.\n  /**\n   * \\throws exceptions::UnknownGoalHandleError If the goal unknown or already reached a terminal\n   *   state, or if there was an error requesting the result.\n   * \\param[in] goal_handle The goal handle for which to get the result.\n   * \\param[in] result_callback Optional callback that is called when the result is received.\n   * \\return A future that is set to the goal result when the goal is finished.\n   */\n  std::shared_future<WrappedResult>\n  async_get_result(\n    typename GoalHandle::SharedPtr goal_handle,\n    ResultCallback result_callback = nullptr)\n  {\n    std::lock_guard<std::mutex> lock(goal_handles_mutex_);\n    if (goal_handles_.count(goal_handle->get_goal_id()) == 0) {\n      throw exceptions::UnknownGoalHandleError();\n    }\n\n\n\n    if (goal_handle->is_invalidated()) {\n      // This case can happen if there was a failure to send the result request\n      // during the goal response callback\n      throw goal_handle->invalidate_exception_;\n    }\n    if (result_callback) {\n      // This will override any previously registered callback\n      goal_handle->set_result_callback(result_callback);\n    }\n    this->make_result_aware(goal_handle);\n    return goal_handle->async_get_result();\n  }\n  /// Asynchronously request a goal be canceled.\n  /**\n   * \\throws exceptions::UnknownGoalHandleError If the goal is unknown or already reached a\n   *   terminal state.\n   * \\param[in] goal_handle The goal handle requesting to be canceled.\n   * \\param[in] cancel_callback Optional callback that is called when the response is received.\n   *   The callback takes one parameter: a shared pointer to the CancelResponse message.\n   * \\return A future to a CancelResponse message that is set when the request has been\n   * acknowledged by an action server.\n   * See\n   * <a href=\"https://github.com/ros2/rcl_interfaces/blob/master/action_msgs/srv/CancelGoal.srv\">\n   * action_msgs/CancelGoal.srv</a>.\n   */\n  std::shared_future<typename CancelResponse::SharedPtr>\n  async_cancel_goal(\n    typename GoalHandle::SharedPtr goal_handle,\n    CancelCallback cancel_callback = nullptr)\n  {\n    std::lock_guard<std::mutex> lock(goal_handles_mutex_);\n    if (goal_handles_.count(goal_handle->get_goal_id()) == 0) {\n      throw exceptions::UnknownGoalHandleError();\n    }\n    auto cancel_request = std::make_shared<CancelRequest>();\n    // cancel_request->goal_info.goal_id = goal_handle->get_goal_id();\n    cancel_request->goal_info.goal_id.uuid = goal_handle->get_goal_id();\n    return async_cancel(cancel_request, cancel_callback);\n  }\n  /// Asynchronously request for all goals to be canceled.\n\n\n\n  /**\n   * \\param[in] cancel_callback Optional callback that is called when the response is received.\n   *   The callback takes one parameter: a shared pointer to the CancelResponse message.\n   * \\return A future to a CancelResponse message that is set when the request has been\n   * acknowledged by an action server.\n   * See\n   * <a href=\"https://github.com/ros2/rcl_interfaces/blob/master/action_msgs/srv/CancelGoal.srv\">\n   * action_msgs/CancelGoal.srv</a>.\n   */\n  std::shared_future<typename CancelResponse::SharedPtr>\n  async_cancel_all_goals(CancelCallback cancel_callback = nullptr)\n  {\n    auto cancel_request = std::make_shared<CancelRequest>();\n    // std::fill(cancel_request->goal_info.goal_id.uuid, 0u);\n    std::fill(\n      cancel_request->goal_info.goal_id.uuid.begin(),\n      cancel_request->goal_info.goal_id.uuid.end(), 0u);\n    return async_cancel(cancel_request, cancel_callback);\n  }\n  /// Asynchronously request all goals at or before a specified time be canceled.\n  /**\n   * \\param[in] stamp The timestamp for the cancel goal request.\n   * \\param[in] cancel_callback Optional callback that is called when the response is received.\n   *   The callback takes one parameter: a shared pointer to the CancelResponse message.\n   * \\return A future to a CancelResponse message that is set when the request has been\n   * acknowledged by an action server.\n   * See\n   * <a href=\"https://github.com/ros2/rcl_interfaces/blob/master/action_msgs/srv/CancelGoal.srv\">\n   * action_msgs/CancelGoal.srv</a>.\n   */\n  std::shared_future<typename CancelResponse::SharedPtr>\n  async_cancel_goals_before(\n    const rclcpp::Time & stamp,\n    CancelCallback cancel_callback = nullptr)\n  {\n    auto cancel_request = std::make_shared<CancelRequest>();\n    // std::fill(cancel_request->goal_info.goal_id.uuid, 0u);\n    std::fill(\n      cancel_request->goal_info.goal_id.uuid.begin(),\n      cancel_request->goal_info.goal_id.uuid.end(), 0u);\n\n\n\n    cancel_request->goal_info.stamp = stamp;\n    return async_cancel(cancel_request, cancel_callback);\n  }\n  virtual\n  ~Client()\n  {\n    std::lock_guard<std::mutex> guard(goal_handles_mutex_);\n    auto it = goal_handles_.begin();\n    while (it != goal_handles_.end()) {\n      typename GoalHandle::SharedPtr goal_handle = it->second.lock();\n      if (goal_handle) {\n        goal_handle->invalidate(exceptions::UnawareGoalHandleError());\n      }\n      it = goal_handles_.erase(it);\n    }\n  }\nprivate:\n  /// \\internal\n  std::shared_ptr<void>\n  create_goal_response() const override\n  {\n    using GoalResponse = typename ActionT::Impl::SendGoalService::Response;\n    return std::shared_ptr<void>(new GoalResponse());\n  }\n  /// \\internal\n  std::shared_ptr<void>\n  create_result_response() const override\n  {\n    using GoalResultResponse = typename ActionT::Impl::GetResultService::Response;\n    return std::shared_ptr<void>(new GoalResultResponse());\n  }\n  /// \\internal\n  std::shared_ptr<void>\n  create_cancel_response() const override\n  {\n    return std::shared_ptr<void>(new CancelResponse());\n  }\n  /// \\internal\n  std::shared_ptr<void>\n  create_feedback_message() const override\n\n\n\n  {\n    using FeedbackMessage = typename ActionT::Impl::FeedbackMessage;\n    return std::shared_ptr<void>(new FeedbackMessage());\n  }\n  /// \\internal\n  void\n  handle_feedback_message(std::shared_ptr<void> message) override\n  {\n    std::lock_guard<std::mutex> guard(goal_handles_mutex_);\n    using FeedbackMessage = typename ActionT::Impl::FeedbackMessage;\n    typename FeedbackMessage::SharedPtr feedback_message =\n      std::static_pointer_cast<FeedbackMessage>(message);\n    const GoalUUID & goal_id = feedback_message->goal_id.uuid;\n    if (goal_handles_.count(goal_id) == 0) {\n      RCLCPP_DEBUG(\n        this->get_logger(),\n        \"Received feedback for unknown goal. Ignoring...\");\n      return;\n    }\n    typename GoalHandle::SharedPtr goal_handle = goal_handles_[goal_id].lock();\n    // Forget about the goal if there are no more user references\n    if (!goal_handle) {\n      RCLCPP_DEBUG(\n        this->get_logger(),\n        \"Dropping weak reference to goal handle during feedback callback\");\n      goal_handles_.erase(goal_id);\n      return;\n    }\n    auto feedback = std::make_shared<Feedback>();\n    *feedback = feedback_message->feedback;\n    goal_handle->call_feedback_callback(goal_handle, feedback);\n  }\n  /// \\internal\n  std::shared_ptr<void>\n  create_status_message() const override\n  {\n    using GoalStatusMessage = typename ActionT::Impl::GoalStatusMessage;\n    return std::shared_ptr<void>(new GoalStatusMessage());\n  }\n  /// \\internal\n\n\n\n  void\n  handle_status_message(std::shared_ptr<void> message) override\n  {\n    std::lock_guard<std::mutex> guard(goal_handles_mutex_);\n    using GoalStatusMessage = typename ActionT::Impl::GoalStatusMessage;\n    auto status_message = std::static_pointer_cast<GoalStatusMessage>(message);\n    for (const GoalStatus & status : status_message->status_list) {\n      const GoalUUID & goal_id = status.goal_info.goal_id.uuid;\n      if (goal_handles_.count(goal_id) == 0) {\n        RCLCPP_DEBUG(\n          this->get_logger(),\n          \"Received status for unknown goal. Ignoring...\");\n        continue;\n      }\n      typename GoalHandle::SharedPtr goal_handle = goal_handles_[goal_id].lock();\n      // Forget about the goal if there are no more user references\n      if (!goal_handle) {\n        RCLCPP_DEBUG(\n          this->get_logger(),\n          \"Dropping weak reference to goal handle during status callback\");\n        goal_handles_.erase(goal_id);\n        continue;\n      }\n      goal_handle->set_status(status.status);\n    }\n  }\n  /// \\internal\n  void\n  make_result_aware(typename GoalHandle::SharedPtr goal_handle)\n  {\n    // Avoid making more than one request\n    if (goal_handle->set_result_awareness(true)) {\n      return;\n    }\n    using GoalResultRequest = typename ActionT::Impl::GetResultService::Request;\n    auto goal_result_request = std::make_shared<GoalResultRequest>();\n    goal_result_request->goal_id.uuid = goal_handle->get_goal_id();\n    try {\n      this->send_result_request(\n        std::static_pointer_cast<void>(goal_result_request),\n\n\n\n        [goal_handle, this](std::shared_ptr<void> response) mutable\n        {\n          // Wrap the response in a struct with the fields a user cares about\n          WrappedResult wrapped_result;\n          using GoalResultResponse = typename ActionT::Impl::GetResultService::Response;\n          auto result_response = std::static_pointer_cast<GoalResultResponse>(response);\n          wrapped_result.result = std::make_shared<typename ActionT::Result>();\n          *wrapped_result.result = result_response->result;\n          wrapped_result.goal_id = goal_handle->get_goal_id();\n          wrapped_result.code = static_cast<ResultCode>(result_response->status);\n          goal_handle->set_result(wrapped_result);\n          std::lock_guard<std::mutex> lock(goal_handles_mutex_);\n          goal_handles_.erase(goal_handle->get_goal_id());\n        });\n    } catch (rclcpp::exceptions::RCLError & ex) {\n      // This will cause an exception when the user tries to access the result\n      goal_handle->invalidate(exceptions::UnawareGoalHandleError(ex.message));\n    }\n  }\n  /// \\internal\n  std::shared_future<typename CancelResponse::SharedPtr>\n  async_cancel(\n    typename CancelRequest::SharedPtr cancel_request,\n    CancelCallback cancel_callback = nullptr)\n  {\n    // Put promise in the heap to move it around.\n    auto promise = std::make_shared<std::promise<typename CancelResponse::SharedPtr>>();\n    std::shared_future<typename CancelResponse::SharedPtr> future(promise->get_future());\n    this->send_cancel_request(\n      std::static_pointer_cast<void>(cancel_request),\n      [cancel_callback, promise](std::shared_ptr<void> response) mutable\n      {\n        auto cancel_response = std::static_pointer_cast<CancelResponse>(response);\n        promise->set_value(cancel_response);\n        if (cancel_callback) {\n          cancel_callback(cancel_response);\n        }\n      });\n    return future;\n  }\n\n\n\n  std::map<GoalUUID, typename GoalHandle::WeakPtr> goal_handles_;\n  std::mutex goal_handles_mutex_;\n};\n}  // namespace rclcpp_action\n#endif  // RCLCPP_ACTION__CLIENT_HPP_\n\n\n"
  },
  {
    "id": "vscode_gazebo/29760.txt",
    "content": "[ ![](https://github.com/Dronecode/dronecode-wordpress-\ntheme/raw/master/dronecode-salient-\nchild/images/dronecode_top_bar_logo_full.png) ](https://www.dronecode.org/)\n\n[ ![](https://github.com/Dronecode/dronecode-wordpress-\ntheme/raw/master/dronecode-salient-\nchild/images/dronecode_top_bar_logo_small.png) ](https://www.dronecode.org/)\n\n[ Dronecode ](https://www.dronecode.org/)\n\n[ PX4 ](http://px4.io/)\n\n[ QGroundControl ](http://qgroundcontrol.com/)\n\n[ QGC ](http://qgroundcontrol.com/)\n\n[ MAVSDK ](http://mavsdk.mavlink.io)\n\n[ MAVLink ](https://mavlink.io/en/)\n\n[ Documentation ](https://www.dronecode.org/documentation/)\n\n[ Docs ](https://www.dronecode.org/documentation/)\n\n[ Support ](http://discuss.px4.io/)\n\n[ Help ](http://discuss.px4.io/)\n\n[ Discussion Forum for PX4, Pixhawk, QGroundControl, MAVSDK, MAVLink ](/)\n\n#  [ Should VSCode LAUNCH Gazebo? ](/t/should-vscode-launch-gazebo/29760)\n\n[ rdehart  ](https://discuss.px4.io/u/rdehart) November 15, 2022, 1:11am  1\n\n[ Visual Studio Code IDE (VSCode) | PX4 User Guide\n](https://docs.px4.io/main/en/dev_setup/vscode.html#debugging) as seen here.\nIt does not seem to launch a Gazebo Window for me.\n\n[ hamishwillee  ](https://discuss.px4.io/u/hamishwillee) November 16, 2022,\n1:38am  2\n\nIt should. What PX4 version are you running on what platform? Is \u201canything\u201d\nhappening?\n\n[ rdehart  ](https://discuss.px4.io/u/rdehart) November 21, 2022, 3:41pm  3\n\n1.13.1. Ill send you screenshot. PX4 boots, but Gazebo never comes up.\n\n[ hamishwillee  ](https://discuss.px4.io/u/hamishwillee) November 21, 2022,\n10:06pm  4\n\nAttach screenshot here. I probably can\u2019t help you - what you want to do is\nprovide enough information that someone can.\n\n[ rdehart  ](https://discuss.px4.io/u/rdehart) November 22, 2022, 1:26am  5\n\nUnderstood.\n\nI was following the debugging/VSCode instructions here:\n\n[ docs.px4.io ](https://docs.px4.io/main/en/dev_setup/vscode.html)\n\n###  [ Visual Studio Code IDE (VSCode) | PX4 User Guide\n](https://docs.px4.io/main/en/dev_setup/vscode.html)\n\nPX4 is the Professional Autopilot. Developed by world-class developers from\nindustry and academia, and supported by an active world wide community, it\npowers all kinds of vehicles from racing and cargo drones through to ground\nvehicles and...\n\n[ docs.px4.io ](https://docs.px4.io/main/en/simulation/gazebo.html)\n\n###  [ Gazebo Simulation | PX4 User Guide\n](https://docs.px4.io/main/en/simulation/gazebo.html)\n\nPX4 is the Professional Autopilot. Developed by world-class developers from\nindustry and academia, and supported by an active world wide community, it\npowers all kinds of vehicles from racing and cargo drones through to ground\nvehicles and...\n\nNode that my screenshots differ slightly than the documentation in that I dont\nhave a px4_sitl (debug) option nor a SITL (Gazebo iris) option exactly. I am\nunsure if that matters. Additionally, it is clear (see screenshots) that PX4\nstarts and gazebo seems to start in the terminal, but the Gazebo UI never\nlaunches.  \n\n[ ![Screenshot from 2022-11-21\n20-16-08](https://discuss.px4.io/uploads/default/optimized/2X/5/5b7ae61ae60a03991e6ca71a686e152e5ebf7ed0_2_690x414.png)\nScreenshot from 2022-11-21 20-16-08  1078\u00d7648 55.8 KB\n](https://discuss.px4.io/uploads/default/original/2X/5/5b7ae61ae60a03991e6ca71a686e152e5ebf7ed0.png\n\"Screenshot from 2022-11-21 20-16-08\")\n\n  \n\n[ ![Screenshot from 2022-11-21\n20-17-37](https://discuss.px4.io/uploads/default/optimized/2X/8/882425138af61c2017db964a0a16e4f4b17325bb_2_690x418.png)\nScreenshot from 2022-11-21 20-17-37  1140\u00d7692 72.8 KB\n](https://discuss.px4.io/uploads/default/original/2X/8/882425138af61c2017db964a0a16e4f4b17325bb.png\n\"Screenshot from 2022-11-21 20-17-37\")\n\n[ rdehart  ](https://discuss.px4.io/u/rdehart) November 22, 2022, 1:27am  6\n\n[ ![Screenshot from 2022-11-21\n20-18-45](https://discuss.px4.io/uploads/default/optimized/2X/f/f22f66ca5ae774ff5ba8e29e349766cf69ce2e85_2_690x464.png)\nScreenshot from 2022-11-21 20-18-45  1187\u00d7799 101 KB\n](https://discuss.px4.io/uploads/default/original/2X/f/f22f66ca5ae774ff5ba8e29e349766cf69ce2e85.png\n\"Screenshot from 2022-11-21 20-18-45\")\n\n  \n\n[ ![Screenshot from 2022-11-21\n20-19-27](https://discuss.px4.io/uploads/default/optimized/2X/2/2ddab06917a54a670c3962ea0b332375c859a3a2_2_690x376.png)\nScreenshot from 2022-11-21 20-19-27  1462\u00d7797 132 KB\n](https://discuss.px4.io/uploads/default/original/2X/2/2ddab06917a54a670c3962ea0b332375c859a3a2.png\n\"Screenshot from 2022-11-21 20-19-27\")\n\n[ rdehart  ](https://discuss.px4.io/u/rdehart) November 22, 2022, 1:32am  7\n\nAdditionally it says empty world and it must be loading some generic vehicle.\nHow do I specify a specific one I want to use?\n\n[ hamishwillee  ](https://discuss.px4.io/u/hamishwillee) November 22, 2022,\n10:16pm  8\n\nHonestly I don\u2019t know - I always run stuff from command line. [ @MaEtUgR\n](/u/maetugr) or [ @Jaeyoung-Lim ](/u/jaeyoung-lim) Is this something you can\nadvise on?\n\n[ MaEtUgR  ](https://discuss.px4.io/u/MaEtUgR) December 6, 2022, 9:07am  9\n\n[ @rdehart ](/u/rdehart) Thanks for the insightful screenshots. I quickly gave\nit a spin myself on ` main ` from today and like you described I do not get a\ngazebo visualization window. I\u2019m pretty sure that worked before since [ @dagar\n](/u/dagar) showed me and I did not have any issue then. Maybe it broke when\nquite some things changed when enabling new gazebo in [ merge px4_sitl_ign\ninto px4_sitl_default by dagar \u00b7 Pull Request #20188 \u00b7 PX4/PX4-Autopilot \u00b7\nGitHub ](https://github.com/PX4/PX4-Autopilot/pull/20188) maybe somewhere\nclose to here where the commands changed: [ merge px4_sitl_ign into\npx4_sitl_default (#20188) \u00b7 PX4/PX4-Autopilot@b8fb5df \u00b7 GitHub\n](https://github.com/PX4/PX4-Autopilot/commit/b8fb5dfa517874e193db847854c021bc98381707#diff-092213d353755a488f6abf87bb0993d1b1100857e370b397f1c3fdf1fafdd6f7R94-R154)  \nI honestly (still) run the simulation by executing the commands e.g. ` make\npx4_sitl gazebo ` from the embedded terminal in VS code which works like\nexpected but of course doesn\u2019t give you all the nice debug tools\n![:grimacing:](https://discuss.px4.io/images/emoji/apple/grimacing.png?v=12)\n\nWe need to have a look why the visualization is suddenly missing. Did you try\ndifferent versions? That might just give a hint. I just saw that on 1.13 the\nlaunch structure was still different: [ PX4-Autopilot/launch_sim.json.in at\nrelease/1.13 \u00b7 PX4/PX4-Autopilot \u00b7 GitHub\n](https://github.com/PX4/PX4-Autopilot/blob/release/1.13/platforms/posix/Debug/launch_sim.json.in#L10-L19)\n\n1 Like\n\n[ ecuashungo  ](https://discuss.px4.io/u/ecuashungo) July 19, 2023, 11:19am\n10\n\n[ @rdehart ](/u/rdehart) and [ @MaEtUgR ](/u/maetugr)  \nNot sure if this is still relevant, but I think the problem is that the [\ngazebo client task\n](https://github.com/PX4/PX4-Autopilot/blob/1c8ab2a0d7db2d14a6f320ebd8766b5ffaea28fa/.vscode/tasks.json#L219-L257)\nis never executed.\n\nIf you run the ` gazebo client ` task afterwards it works for me.\n\nHere is how to do it:\n\n  1. Run everything just like you did in your screenshots \n  2. hit ` ctrl-p ` in vs code to access the quick open command line \n  3. type ` task gazebo client ` and hit enter. This will open the gzclient graphical interface which is connected to your running simulation \n\n[\n![image](https://discuss.px4.io/uploads/default/optimized/2X/7/7414aa6ba7397baf47279082a08415d976c87746_2_556x500.png)\nimage  626\u00d7562 22.7 KB\n](https://discuss.px4.io/uploads/default/original/2X/7/7414aa6ba7397baf47279082a08415d976c87746.png\n\"image\")\n\n  * [ Home ](/)\n  * [ Categories ](/categories)\n  * [ FAQ/Guidelines ](/guidelines)\n  * [ Terms of Service ](/tos)\n  * [ Privacy Policy ](/privacy)\n\nPowered by [ Discourse ](https://www.discourse.org) , best viewed with\nJavaScript enabled\n\n"
  },
  {
    "id": "ros2_camera/231024.txt",
    "content": "[ NVIDIA Developer Forums ](/)\n\n#  [ ROS2 Camera topic publish Hz control (Camera FPS Fix problem using ros2)\n](/t/ros2-camera-topic-publish-hz-control-camera-fps-fix-problem-using-\nros2/231024)\n\n[ Omniverse  ](/c/omniverse/simulation/69) [ Isaac Sim\n](/c/omniverse/simulation/69)\n\n[ camera ](https://forums.developer.nvidia.com/tag/camera) , [ ros\n](https://forums.developer.nvidia.com/tag/ros) , [ isaacsim\n](https://forums.developer.nvidia.com/tag/isaacsim) , [ isaac-sdk\n](https://forums.developer.nvidia.com/tag/isaac-sdk) , [ custom-robot\n](https://forums.developer.nvidia.com/tag/custom-robot)\n\n[ phr0201  ](https://forums.developer.nvidia.com/u/phr0201) October 17, 2022,\n2:20pm  1\n\nI want to **get the camera topic of fixed fps ( 30 ) when i publish** the\ncamera topic(/carter1/rgb_left, /carter1/rgb_right) using ros2.\n\n  1. At first, I set the **\u201cFPS Limit\u201d** ( =10 _ just test ) But like below figure, It does not apply.   \n( In figure, FPS Limit is 10, but camera fps published is 22.34 )  \n\n[ ![image](https://global.discourse-\ncdn.com/nvidia/optimized/3X/9/4/946f1fd798db9e1eb49d9d55da4668787e1c02a4_2_500x500.jpeg)\nimage  1262\u00d71262 109 KB  ](https://global.discourse-\ncdn.com/nvidia/original/3X/9/4/946f1fd798db9e1eb49d9d55da4668787e1c02a4.jpeg\n\"image\")\n\nAnd then, **What should i do if i want to get the fixed fps of camera topic\nusing ros2 in isaac sim?**  \nNow I am using the **omnigraph** for getting the ros topics ( camera, imu,\nlidar etc ).  \nAnd also **when the scene is more complicated or I open multiple viewport, FPS\ndecreased.**\n\n  2. Second, I found the RTX Option(real time & interactive & accurate ), **What is differences between them?** When i choose \u201cInteractive option\u201d like below, scene looks like blurry and dark. ( But real-time looks good )   \n\n[ ![image](https://global.discourse-\ncdn.com/nvidia/optimized/3X/7/1/71b9a70eeb28d37ce139c911c289a3731bd93171_2_690x291.jpeg)\nimage  1920\u00d7810 48.1 KB  ](https://global.discourse-\ncdn.com/nvidia/original/3X/7/1/71b9a70eeb28d37ce139c911c289a3731bd93171.jpeg\n\"image\")\n\n  3. Is it possible to get the topic of fixed fps if i use the **Enterprise version** ? \n\n  4. Lastly, I want to publish various sensor topic ( imu, camera, lidar ). In this case, **Can i get it at a fixed fps for each topic? ( like camera = 30 fps, IMU = 110hz )**\n\nThank you so much for reading. If anyone knows, Please reply me\u2026 !!\n\nThank you\n\n1 Like\n\n[ How to publish the camera topic at a fixed FPS?\n](https://forums.developer.nvidia.com/t/how-to-publish-the-camera-topic-at-a-\nfixed-fps/231509/2)\n\n[ ROS2 Camera Topic Publish Hz Problem\n](https://forums.developer.nvidia.com/t/ros2-camera-topic-publish-hz-\nproblem/231683/2)\n\n[ smoon  ](https://forums.developer.nvidia.com/u/smoon) November 7, 2022,\n2:52am  3\n\n[ @Hammad_M ](/u/hammad_m) Can you help to respond this thread? [ @phr0201\n](/u/phr0201) can elaborate more on the question if this is not clear to you.\nShe is looking for a way to set FPS Limit forthe camera topic. Thank you!\n\n1 Like\n\n[ Hammad_M  ](https://forums.developer.nvidia.com/u/Hammad_M) November 8,\n2022, 3:30am  4\n\n[ @phr0201 ](/u/phr0201) Are you using isaac-sim.sh or python.sh +\nSImulationApp?  \nThere are different ways of fixing the rendering FPS based on the simulation\nmethod.\n\nThere are also additional options mentioned here if you want to reduce the\npublishing rate by a fixed multiple.\n\n[\nhttps://docs.omniverse.nvidia.com/app_isaacsim/app_isaacsim/tutorial_ros_migration.html#periodic-\nimage-publishing\n](https://docs.omniverse.nvidia.com/app_isaacsim/app_isaacsim/tutorial_ros_migration.html#periodic-\nimage-publishing)\n\nIf you want to Publish at an increased rate that is possible in certain\ncircumstances. For example to publish a simulation clock message every physics\nstep you can take a look at  \nstandalone_examples/api/omni.isaac.quadruped/go1_ros1_standalone.py\n\nWhere a specific graph like\n\n    \n    \n     try:\n                keys = og.Controller.Keys\n                (self._clock_graph, _, _, _) = og.Controller.edit(\n                    {\n                        \"graph_path\": \"/ROS_Clock\",\n                        \"evaluator_name\": \"push\",\n                        \"pipeline_stage\": og.GraphPipelineStage.GRAPH_PIPELINE_STAGE_ONDEMAND,\n                    },\n                    {\n                        keys.CREATE_NODES: [\n                            (\"OnTick\", \"omni.graph.action.OnTick\"),\n                            (\"readSimTime\", \"omni.isaac.core_nodes.IsaacReadSimulationTime\"),\n                            (\"publishClock\", \"omni.isaac.ros_bridge.ROS1PublishClock\"),\n                        ],\n                        keys.CONNECT: [\n                            (\"OnTick.outputs:tick\", \"publishClock.inputs:execIn\"),\n                            (\"readSimTime.outputs:simulationTime\", \"publishClock.inputs:timeStamp\"),\n                        ],\n                    },\n                )\n            except Exception as e:\n                print(e)\n                simulation_app.close()\n                exit()\n    \n\nis then manually run each physics step:\n\n    \n    \n    og.Controller.evaluate_sync(self._clock_graph)\n    \n\nAlso take a look at ` standalone_examples/api/omni.isaac.core/time_stepping.py\n`\n\nFor various options on stepping time forward at specific frequencies/step\nsizes.\n\n[ phr0201  ](https://forums.developer.nvidia.com/u/phr0201) November 8, 2022,\n4:48am  5\n\nThank you for replying me!\n\nBy the way, Your examples are all based on **ros1** , but i want to use\n**ros2.**  \nBecause i want to get the **30 fps camera topics** (e.g /carter1/rgb_left) in\n**isaac** **sim (2022.1.1 release version)** based on ros2.  \nIs it possible applying above examples in ros2 environment?\n\nThank you!\n\n[ Hammad_M  ](https://forums.developer.nvidia.com/u/Hammad_M) November 8,\n2022, 6:31pm  6\n\nYes the same applies to ROS2 Omnigraph nodes as well.  \nNote that if your current FPS is lower than 30, there is no way to increase\nthis because its GPU/CPU limited performance wise.\n\nYou can however run slower than realtime and use the sim_time clock message\nfrom isaac sim to keep things in sync.\n\n  * [ Home ](/)\n  * [ Categories ](/categories)\n  * [ FAQ/Guidelines ](/guidelines)\n  * [ Terms of Service ](https://www.nvidia.com/en-us/about-nvidia/legal-info/)\n  * [ Privacy Policy ](https://www.nvidia.com/en-us/about-nvidia/privacy-policy/)\n\nPowered by [ Discourse ](https://www.discourse.org) , best viewed with\nJavaScript enabled\n\nCopyright \u00a9 2024 NVIDIA Corporation\n\n  * [ Legal Information ](https://www.nvidia.com/en-us/about-nvidia/legal-info/)\n  * [ Terms of Use ](https://developer.nvidia.com/legal/terms)\n  * [ Privacy Policy ](https://www.nvidia.com/en-us/about-nvidia/privacy-policy/)\n  * [ Contact ](https://developer.nvidia.com/contact)\n  * [ Cookie Policy ](https://www.nvidia.com/en-us/about-nvidia/cookie-policy/ \"NVIDIA websites use cookies to deliver and improve the website experience. See our cookie policy for further details on how we use cookies and how to change your cookie settings.\")\n\n"
  },
  {
    "id": "arduino/wire.txt",
    "content": "[ ](https://docs.arduino.cc/)\n\n/\n\n[ ](https://app.arduino.cc/) [ ARDUINO.CC  ](https://www.arduino.cc/)\n\n[ Go Back  ](/learn/)\n\nLearn\n\n#####  Arduino Ecosystem\n\n#####  Microcontrollers\n\n#####  Programming\n\n#####  Electronics\n\n#####  Communication\n\n[ Inter-Integrated Circuit (I2C) Protocol ](/learn/communication/wire) [\nArduino & Serial Peripheral Interface (SPI) ](/learn/communication/spi) [\nLPWAN (Low-Power Wide-Area Networks) 101 ](/learn/communication/low-power-\nwide-area-networks-101) [ GPS NMEA 0183 Messaging Protocol 101\n](/learn/communication/gps-nmea-data-101) [ The Arduino Guide to LoRa\u00c2\u00ae and\nLoRaWAN\u00c2\u00ae ](/learn/communication/lorawan-101) [ 1-Wire Protocol\n](/learn/communication/one-wire) [ Arduino\u00c2\u00ae & Modbus Protocol\n](/learn/communication/modbus) [ Bluetooth\u00c2\u00ae Low Energy\n](/learn/communication/bluetooth) [ Universal Asynchronous Receiver-\nTransmitter (UART) ](/learn/communication/uart)\n\n#####  Hardware Design\n\n#####  Built-in Libraries\n\n#####  Contributions\n\n[ Home  /  ](/) [ Learn  /  ](/learn/) Inter-Integrated Circuit (I2C) Protocol\n\n#  Inter-Integrated Circuit (I2C) Protocol\n\nAllows the communication between devices or sensors connected via Two Wire\nInterface Bus.\n\nAuthor  Nicholas Zambetti, Karl S\u00c3\u00b6derby, Jacob Hyl\u00c3\u00a9n\n\nLast revision  01/16/2024\n\n##  Introduction\n\nA good way of adding complexity of features to your projects without adding\ncomplexity of wiring, is to make use of the Inter-integrated circuit (I2C)\nprotocol. The I2C protocol is supported on all Arduino boards. It allows you\nto connect several peripheral devices, such as sensors, displays, motor\ndrivers, and so on, with only a few wires. Giving you lots of flexibility and\nspeeding up your prototyping, without an abundancy of wires. Keep reading to\nlearn about how it works, how it is implemented into different standards, as\nwell as how to use the  Wire Library  to build your own I2C devices.\n\n##  Overview\n\nThis section provides an overview of the topics covered in the article.\n\n  * What Is I2C? \n  * Arduino I2C Pins \n  * I2C Wiring \n  * Wire Library \n  * Examples \n\n##  What Is I2C?\n\nThe I2C protocol involves using two lines to send and receive data: a serial\nclock pin **(SCL)** that the Arduino Controller board pulses at a regular\ninterval, and a serial data pin **(SDA)** over which data is sent between the\ntwo devices.\n\nIn I2C, there is one controller device, with one or more peripheral devices\nconnected to the controllers SCL and SDA lines.\n\nAs the clock line changes from low to high (known as the rising edge of the\nclock pulse), a single bit of information is transferred from the board to the\nI2C device over the SDA line. As the clock line keeps pulsing, more and more\nbits are sent until a sequence of a 7 or 8 bit address, and a command or data\nis formed. When this information is sent - bit after bit -, the called upon\ndevice executes the request and transmits it's data back - if required - to\nthe board over the same line using the clock signal still generated by the\nController on SCL as timing.\n\nEach device in the I2C bus is functionally independent from the controller,\nbut will respond with information when prompted by the controller.\n\nBecause the I2C protocol allows for each enabled device to have it's own\nunique address, and as both controller and peripheral devices to take turns\ncommunicating over a single line, it is possible for your Arduino board to\ncommunicate (in turn) with many devices, or other boards, while using just two\npins of your microcontroller.\n\nAn I2C message on a lower bit-level looks something like this:\n\n![An I2C Message](/static/9d32a6e488d79f211470b15f06644a31/a6d36/I2C.png) An\nI2C Message\n\n  * The controller sends out instructions through the I2C bus on the data pin (SDA), and the instructions are prefaced with the address, so that only the correct device listens. \n  * Then there is a bit signifying whether the controller wants to read or write. \n  * Every message needs to be acknowledged, to combat unexpected results, once the receiver has acknowledged the previous information it lets the controller know, so it can move on to the next set of bits. \n  * 8 bits of data \n  * Another acknowledgement bit \n  * 8 bits of data \n  * Another acknowledgement bit \n\nBut how does the controller and peripherals know where the address, messages,\nand so on starts and ends? That's what the SCL wire is for. It synchronises\nthe clock of the controller with the devices, ensuring that they all move to\nthe next instruction at the same time.\n\nHowever, you are nearly never going to _actually_ need to consider any of\nthis, in the Arduino ecosystem we have the [ Wire library\n](https://www.arduino.cc/reference/en/language/functions/communication/wire/)\nthat handles everything for you.\n\n##  Arduino I2C Pins\n\nBelow is a table that lists the different board form factors and what pins are\nfor I2C.\n\nForm factor  |  SDA  |  SCL  |  SDA1  |  SCL1  |  SDA2  |  SCL2  \n---|---|---|---|---|---|---  \nUNO  |  SDA/A4  |  SCL/A5  |  |  |  |  \nNano  |  A4  |  A5  |  |  |  |  \nMKR  |  D11  |  D12  |  |  |  |  \nGIGA  |  D20  |  D21  |  D102  |  D101  |  D9  |  D8  \nMega & Due  |  D20  |  D21  |  |  |  |  \n  \n##  I2C Wiring\n\nBelow you'll find a couple ways to wire I2C breakout modules. Which way is\nbest depends on each module, and your needs.\n\n###  Breakout Boards\n\nSome brekout board modules let you wire them directly, with bare wires on a\nbreadboard. To connect a module like this to your Arduino board, connect it as\nfollows:\n\n  * VCC* - 5V/3V3 pin (depending on breakout module) \n  * GND* - GND \n  * SDA - SDA \n  * SCL - SCL \n\n*Pin name might vary depending on what module, VCC might be named \"VIN\", \"+\", etc. GND might be named \"-\". \n\nHere's an example of how you might connect a sensor to an UNO R4 WiFi:  ![Bare\nI2C Wiring on UNO R4 WiFi\n](/static/5f90596512320d9577cfa9638fdb6115/a6d36/wiring.png) Bare I2C Wiring\non UNO R4 WiFi\n\n###  Qwiic & STEMMA QT\n\nWhen delving into the market of breakout modules and sensors, you'll find that\nthere are entire ecosystems, where standards are built around the I2C\nprotocol. Examples of such standards are Qwiic, developed by Sparkfun, and\nSTEMMA QT, developed by Adafruit. Both Qwiic and STEMMA QT use a 4-pin JST SH\nconnector for I2C devices, making it easier for third parties to design\nhardware with vast compatibility. By having a standardized connector, you'll\nknow that if you see the word Qwiic or STEMMA QT in association with an item,\nthat it will work together with an Arduino board with a Qwiic or STEMMA QT\nconnector, such as the UNO R4 WiFi.\n\nBoth Qwiic and STEMMA QT bundle together wires for power, ground, as well as\nthe SDA and SCL wires for I2C, making it a complete kit, one cable that\nbundles everything together.\n\n![I2C on a Qwiic/STEMMA QT connector with UNO R4\nWiFi](/static/be0b2311735da10182411aebe8e56acd/a6d36/Qwiic.png) I2C on a\nQwiic/STEMMA QT connector with UNO R4 WiFi\n\n**But what's the difference between the two?**\n\nBoth Qwiic and STEMMA QT use I2C, and even when inspecting modules using the\ntwo standards up close, it may be difficult to tell what makes them unique\nfrom each other. But there is a difference! And it has some implications on\nhow and for what you may use them.\n\nQwiic has level shifting and voltage regulation on the controller (but not on\nthe peripherals). What this means is that Qwiic is 3.3 V logic **only** . This\nmakes it easier to use, as for the end user, there is one less thing that can\ngo wrong when designing and assembling your circuit.\n\nSTEMMA QT, on the other hand, doesn't have this. This lets you use both 3.3 V\nand 5 V logic for modules. This also means that there is one more thing you\nmay need to consider when creating your circuit, but it also grants some more\nflexibility in power and logic requirements.\n\nThe pin order for STEMMA QT is designed to match the pin order for Qwiic,\nenabling cross-compatibility between the two standards.\n\n###  Grove\n\nGrove is another connector standard, this one developed by seeed studio. You\ncan find a plethora of modules with a Grove connector, however only some of\nthem use I2C. There are no Arduino boards that have a built in Grove\nconnector, however you can use products such as the [ MKR connector carrier\n](https://store.arduino.cc/products/arduino-mkr-connector-carrier-grove-\ncompatible) , [ Nano Grove Shield ](https://store.arduino.cc/products/grove-\nshield-for-arduino-nano) , or the Base Shield from the [ Arduino Sensor Kit\n](https://store.arduino.cc/products/arduino-sensor-kit-base) to connect Grove\nsensors to your Arduino board.\n\n##  Wire Library\n\nThe Wire library is what Arduino uses to communicate with I2C devices. It is\nincluded in all board packages, so you don't need to install it manually in\norder to use it.\n\nTo see the full API for the Wire library, visit its [ documentation page\n](https://www.arduino.cc/reference/en/language/functions/communication/wire) .\n\n  *     begin()\n\n\\- Initialise the I2C bus\n\n  *     end()\n\n\\- Close the I2C bus\n\n  *     requestFrom()\n\n\\- Request bytes from a peripheral device\n\n  *     beginTransmission()\n\n\\- Begins queueing up a transmission\n\n  *     endTransmission()\n\n\\- Transmit the bytes that have been queued and end the transmission\n\n  *     write()\n\n\\- Writes data from peripheral to controller or vice versa\n\n  *     available()\n\n\\- returns the number of bytes available for retrieval\n\n  *     read()\n\n\\- Reads a byte that was transmitted from a peripheral to a controller.\n\n  *     setClock()\n\n\\- Modify the clock frequency\n\n  *     onReceive()\n\n\\- Register a function to be called when a peripheral receives a transmission\n\n  *     onRequest()\n\n\\- Register a function to be called when a controller requests data\n\n  *     setWireTimeout()\n\n\\- Sets the timeout for transmissions in controller mode\n\n  *     clearWireTimeoutFlag()\n\n\\- Clears the timeout flag\n\n  *     getWireTimeoutFlag()\n\n\\- Checks whether a timeout has occurred since the last time the flag was\ncleared.\n\n###  Derived libraries\n\nWhen you buy basically any breakout module that makes use of the I2C protocol,\nthey will come with some library that helps you use the sensor. This library\nis more often than not built on top of the Wire library, and uses it under the\nhood. Adding functionality in order to make, for example, reading temperature\neasier.\n\nAn example of this is if you want to use Adafruits MCP9808 sensor module, you\ndownload the Adafruit_MCP9808 Library from the IDEs library manager, which\nenables you to use functions such as\n\n    \n    \n    tempsensor.readTempC()\n\nin order to read the sensors temperature data by requesting from the right\naddress, and read the information returned with just a single line instead of\nwriting the Wire code yourself.\n\nTo learn how to install libraries, check out our [ guide to installing\nlibraries ](/software/ide-v2/tutorials/ide-v2-installing-a-library) .\n\n##  Examples\n\nThe remainder of this article is a collection of examples that can get you off\nthe ground with I2C.\n\n###  Controller Reader\n\n![Arduino Boards connected via\nI2C](/static/069030eceac90efce7d31e05109464ad/a6d36/I2Cb2b.png) Arduino Boards\nconnected via I2C\n\nIn some situations, it can be helpful to set up two (or more!) Arduino boards\nto share information with each other. In this example, two boards are\nprogrammed to communicate with one another in a Controller Reader/Peripheral\nSender configuration via the [ I2C synchronous serial protocol\n](http://en.wikipedia.org/wiki/I2C) . Several functions of Arduino's [ Wire\nLibrary ](https://www.arduino.cc/en/Reference/Wire) are used to accomplish\nthis. Arduino 1, the Controller, is programmed to request, and then read, 6\nbytes of data sent from the uniquely addressed Peripheral Arduino. Once that\nmessage is received, it can then be viewed in the Arduino Software (IDE)\nserial monitor window.\n\n**Controller Reader Sketch**\n\n    \n    \n    Copy\n    \n    1// Wire Controller Reader\n    \n    2// by Nicholas Zambetti [http://www.zambetti.com](http://www.zambetti.com)\n    \n    3\n    \n    \n    4// Demonstrates use of the Wire library\n    \n    5// Reads data from an I2C/TWI peripheral device\n    \n    6// Refer to the \"Wire Peripheral Sender\" example for use with this\n    \n    7\n    \n    \n    8// Created 29 March 2006\n    \n    9\n    \n    \n    10// This example code is in the public domain.\n    \n    11\n    \n    \n    12\n    \n    \n    13#include <Wire.h>\n    \n    14\n    \n    \n    15void setup() {\n    \n    16  Wire.begin();        // join i2c bus (address optional for master)\n    \n    17  Serial.begin(9600);  // start serial for output\n    \n    18}\n    \n    19\n    \n    \n    20void loop() {\n    \n    21  Wire.requestFrom(8, 6);    // request 6 bytes from peripheral device #8\n    \n    22\n    \n    \n    23  while (Wire.available()) { // peripheral may send less than requested\n    \n    24    char c = Wire.read(); // receive a byte as character\n    \n    25    Serial.print(c);         // print the character\n    \n    26  }\n    \n    27\n    \n    \n    28  delay(500);\n    \n    29}\n\n**Peripheral Sender Sketch**\n\n    \n    \n    Copy\n    \n    1// Wire Peripheral Sender\n    \n    2// by Nicholas Zambetti [http://www.zambetti.com](http://www.zambetti.com)\n    \n    3\n    \n    \n    4// Demonstrates use of the Wire library\n    \n    5// Sends data as an I2C/TWI peripheral device\n    \n    6// Refer to the \"Wire Master Reader\" example for use with this\n    \n    7\n    \n    \n    8// Created 29 March 2006\n    \n    9\n    \n    \n    10// This example code is in the public domain.\n    \n    11\n    \n    \n    12\n    \n    \n    13#include <Wire.h>\n    \n    14\n    \n    \n    15void setup() {\n    \n    16  Wire.begin(8);                // join i2c bus with address #8\n    \n    17  Wire.onRequest(requestEvent); // register event\n    \n    18}\n    \n    19\n    \n    \n    20void loop() {\n    \n    21  delay(100);\n    \n    22}\n    \n    23\n    \n    \n    24// function that executes whenever data is requested by master\n    \n    25// this function is registered as an event, see setup()\n    \n    26void requestEvent() {\n    \n    27  Wire.write(\"hello \"); // respond with message of 6 bytes\n    \n    28  // as expected by master\n    \n    29}\n\n###  Controller Writer\n\n![Arduino Boards connected via\nI2C](/static/069030eceac90efce7d31e05109464ad/a6d36/I2Cb2b.png) Arduino Boards\nconnected via I2C\n\nIn some situations, it can be helpful to set up two (or more!) Arduino boards\nto share information with each other. In this example, two boards are\nprogrammed to communicate with one another in a Controller Writer/Peripheral\nReceiver configuration via the [ I2C synchronous serial protocol\n](http://en.wikipedia.org/wiki/I2C) . Several functions of Arduino's [ Wire\nLibrary ](https://www.arduino.cc/en/Reference/Wire) are used to accomplish\nthis. Arduino 1, the Controller, is programmed to send 6 bytes of data every\nhalf second to a uniquely addressed Peripheral. Once that message is received,\nit can then be viewed in the Peripheral board's serial monitor window opened\non the USB connected computer running the Arduino Software (IDE).\n\n**Controller Writer Sketch**\n\n    \n    \n    Copy\n    \n    1// Wire Master Writer\n    \n    2// by Nicholas Zambetti [http://www.zambetti.com](http://www.zambetti.com)\n    \n    3\n    \n    \n    4// Demonstrates use of the Wire library\n    \n    5// Writes data to an I2C/TWI Peripheral device\n    \n    6// Refer to the \"Wire Peripheral Receiver\" example for use with this\n    \n    7\n    \n    \n    8// Created 29 March 2006\n    \n    9\n    \n    \n    10// This example code is in the public domain.\n    \n    11\n    \n    \n    12\n    \n    \n    13#include <Wire.h>\n    \n    14\n    \n    \n    15void setup()\n    \n    16{\n    \n    17  Wire.begin(); // join i2c bus (address optional for master)\n    \n    18}\n    \n    19\n    \n    \n    20byte x = 0;\n    \n    21\n    \n    \n    22void loop()\n    \n    23{\n    \n    24  Wire.beginTransmission(4); // transmit to device #4\n    \n    25  Wire.write(\"x is \");        // sends five bytes\n    \n    26  Wire.write(x);              // sends one byte\n    \n    27  Wire.endTransmission();    // stop transmitting\n    \n    28\n    \n    \n    29  x++;\n    \n    30  delay(500);\n    \n    31}\n\n**Peripheral Receiver Sketch**\n\n    \n    \n    Copy\n    \n    1// Wire Peripheral Receiver\n    \n    2// by Nicholas Zambetti [http://www.zambetti.com](http://www.zambetti.com)\n    \n    3\n    \n    \n    4// Demonstrates use of the Wire library\n    \n    5// Receives data as an I2C/TWI Peripheral device\n    \n    6// Refer to the \"Wire Master Writer\" example for use with this\n    \n    7\n    \n    \n    8// Created 29 March 2006\n    \n    9\n    \n    \n    10// This example code is in the public domain.\n    \n    11\n    \n    \n    12\n    \n    \n    13#include <Wire.h>\n    \n    14\n    \n    \n    15void setup()\n    \n    16{\n    \n    17  Wire.begin(4);                // join i2c bus with address #4\n    \n    18  Wire.onReceive(receiveEvent); // register event\n    \n    19  Serial.begin(9600);           // start serial for output\n    \n    20}\n    \n    21\n    \n    \n    22void loop()\n    \n    23{\n    \n    24  delay(100);\n    \n    25}\n    \n    26\n    \n    \n    27// function that executes whenever data is received from master\n    \n    28// this function is registered as an event, see setup()\n    \n    29void receiveEvent(int howMany)\n    \n    30{\n    \n    31  while(1 < Wire.available()) // loop through all but the last\n    \n    32  {\n    \n    33    char c = Wire.read(); // receive byte as a character\n    \n    34    Serial.print(c);         // print the character\n    \n    35  }\n    \n    36  int x = Wire.read();    // receive byte as an integer\n    \n    37  Serial.println(x);         // print the integer\n    \n    38}\n\n###  Accelerometer\n\n![Grove IMU over\nI2C](/static/fbb611fd4ec7e9c20096b14f7ebb26af/a6d36/GroveIMU.png) Grove IMU\nover I2C\n\nThis code lets you read accelerometer data from a [ Grove 6-Axis Accelerometer\nmodule ](https://store.arduino.cc/collections/sensors/products/grove-6-axis-\naccelerometer-gyroscope) using the [ seeed arduino LSM6DS3 library\n](https://www.arduino.cc/reference/en/libraries/seeed-arduino-lsm6ds3/) .\n\n    \n    \n    Copy\n    \n    1#include \"LSM6DS3.h\"\n    \n    2#include \"Wire.h\"\n    \n    3\n    \n    \n    4//Create instance of Accelerometer class\n    \n    5LSM6DS3 accelerometer(I2C_MODE, 0x6A);\n    \n    6\n    \n    \n    7void setup() {\n    \n    8    // put your setup code here, to run once:\n    \n    9    Serial.begin(9600);\n    \n    10    while (!Serial);\n    \n    11\n    \n    \n    12    if (accelerometer.begin() != 0) {\n    \n    13        Serial.println(\"LSM6DS3 not found, check your wiring.\");\n    \n    14    } else {\n    \n    15        Serial.println(\"LSM6DS3 found!\");\n    \n    16    }\n    \n    17}\n    \n    18\n    \n    \n    19void loop() {\n    \n    20    //Gyroscope\n    \n    21    Serial.print(\"\\nGyroscope:\\n\");\n    \n    22    Serial.print(\" X1 = \");\n    \n    23    Serial.println(accelerometer.readFloatGyroX(), 4);\n    \n    24    Serial.print(\" Y1 = \");\n    \n    25    Serial.println(accelerometer.readFloatGyroY(), 4);\n    \n    26    Serial.print(\" Z1 = \");\n    \n    27    Serial.println(accelerometer.readFloatGyroZ(), 4);\n    \n    28\n    \n    \n    29    //Accelerometer\n    \n    30    Serial.print(\"\\nAccelerometer:\\n\");\n    \n    31    Serial.print(\" X1 = \");\n    \n    32    Serial.println(accelerometer.readFloatAccelX(), 4);\n    \n    33    Serial.print(\" Y1 = \");\n    \n    34    Serial.println(accelerometer.readFloatAccelY(), 4);\n    \n    35    Serial.print(\" Z1 = \");\n    \n    36    Serial.println(accelerometer.readFloatAccelZ(), 4);\n    \n    37\n    \n    \n    38    delay(1000);\n    \n    39}\n\n###  I2C BMP280\n\n![Qwiic BMP280 module](/static/a59bff38e9dff46ea46bfbe0f96fef00/a6d36/Qwiic-\nbmp280.png) Qwiic BMP280 module\n\nThis code example lets you read the temperature over I2C from a BMP280\nbreakout module from Adafruit:\n\n    \n    \n    Copy\n    \n    1#include <Wire.h>\n    \n    2#include <Adafruit_BMP280.h>\n    \n    3\n    \n    \n    4//Create an instance of the BMP280 sensor\n    \n    5Adafruit_BMP280 bmp;\n    \n    6\n    \n    \n    7void setup() {\n    \n    8  Serial.begin(9600);\n    \n    9\n    \n    \n    10  // Start the sensor, and verify that it was found\n    \n    11  if (!bmp.begin()) {\n    \n    12    Serial.println(\"Sensor not found\");\n    \n    13    while (1){}\n    \n    14  }\n    \n    15\n    \n    \n    16}\n    \n    17\n    \n    \n    18void loop() {\n    \n    19  // Read the values\n    \n    20  float temperature = bmp.readTemperature();\n    \n    21\n    \n    \n    22  // Print to the Serial Monitor\n    \n    23  Serial.print(\"Temperature: \");\n    \n    24  Serial.print(temperature);\n    \n    25  Serial.println(\" C\");\n    \n    26\n    \n    \n    27  Serial.println();\n    \n    28  delay(2000);\n    \n    29}\n\n###  I2C OLED\n\n![Grove OLED over\nI2C](/static/a130a959bf0be18815ba45cca32a12c1/a6d36/GroveOLED.png) Grove OLED\nover I2C  This code example draws a version of the Arduino logo on a 128x64\nI2C Grove OLED:\n\n    \n    \n    Copy\n    \n    1#include <Wire.h>\n    \n    2#include <Adafruit_GFX.h>\n    \n    3#include <Adafruit_SSD1306.h>\n    \n    4\n    \n    \n    5Adafruit_SSD1306 display(128, 64, &Wire, -1);\n    \n    6\n    \n    \n    7// The Arduino Logo in a bitmap format\n    \n    8const uint8_t arduinoLogo[] = {\n    \n    9  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    \n    10  0x00, 0x00, 0x00, 0x00, 0x07, 0xf8, 0x00, 0x00, 0x00, 0x00, 0x1f, 0xe0, 0x00, 0x30, 0x00, 0x00,\n    \n    11  0x00, 0x00, 0x00, 0x00, 0x3f, 0xff, 0x00, 0x00, 0x00, 0x00, 0xff, 0xfc, 0x00, 0x70, 0x00, 0x00,\n    \n    12  0x00, 0x00, 0x00, 0x01, 0xff, 0xff, 0xe0, 0x00, 0x00, 0x07, 0xff, 0xff, 0x80, 0x50, 0x00, 0x00,\n    \n    13  0x00, 0x00, 0x00, 0x07, 0xff, 0xff, 0xf8, 0x00, 0x00, 0x1f, 0xff, 0xff, 0xe0, 0x40, 0x00, 0x00,\n    \n    14  0x00, 0x00, 0x00, 0x0f, 0xff, 0xff, 0xfe, 0x00, 0x00, 0x3f, 0xff, 0xff, 0xf0, 0x20, 0x00, 0x00,\n    \n    15  0x00, 0x00, 0x00, 0x3f, 0xff, 0xff, 0xff, 0x00, 0x00, 0xff, 0xff, 0xff, 0xfc, 0x00, 0x00, 0x00,\n    \n    16  0x00, 0x00, 0x00, 0x7f, 0xff, 0xff, 0xff, 0x80, 0x01, 0xff, 0xff, 0xff, 0xfe, 0x00, 0x00, 0x00,\n    \n    17  0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0xc0, 0x03, 0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00,\n    \n    18  0x00, 0x00, 0x01, 0xff, 0xfc, 0x0f, 0xff, 0xe0, 0x07, 0xff, 0xf0, 0x3f, 0xff, 0x80, 0x00, 0x00,\n    \n    19  0x00, 0x00, 0x01, 0xff, 0xc0, 0x00, 0xff, 0xf0, 0x0f, 0xff, 0x00, 0x07, 0xff, 0x80, 0x00, 0x00,\n    \n    20  0x00, 0x00, 0x03, 0xff, 0x80, 0x00, 0x7f, 0xf8, 0x1f, 0xfc, 0x00, 0x01, 0xff, 0xc0, 0x00, 0x00,\n    \n    21  0x00, 0x00, 0x07, 0xfe, 0x00, 0x00, 0x1f, 0xfc, 0x3f, 0xf8, 0x00, 0x00, 0x7f, 0xe0, 0x00, 0x00,\n    \n    22  0x00, 0x00, 0x07, 0xfc, 0x00, 0x00, 0x0f, 0xfe, 0x7f, 0xf0, 0x00, 0x00, 0x3f, 0xe0, 0x00, 0x00,\n    \n    23  0x00, 0x00, 0x0f, 0xf8, 0x00, 0x00, 0x07, 0xff, 0x7f, 0xe0, 0x00, 0x00, 0x1f, 0xf0, 0x00, 0x00,\n    \n    24  0x00, 0x00, 0x0f, 0xf0, 0x00, 0x00, 0x03, 0xff, 0xff, 0xc0, 0x00, 0x00, 0x0f, 0xf0, 0x00, 0x00,\n    \n    25  0x00, 0x00, 0x0f, 0xf0, 0x00, 0x00, 0x01, 0xff, 0xff, 0x80, 0x0f, 0x00, 0x0f, 0xf8, 0x00, 0x00,\n    \n    26  0x00, 0x00, 0x1f, 0xe0, 0x00, 0x00, 0x00, 0xff, 0xff, 0x00, 0x0f, 0x80, 0x07, 0xf8, 0x00, 0x00,\n    \n    27  0x00, 0x00, 0x1f, 0xe0, 0x00, 0x00, 0x00, 0x7f, 0xfe, 0x00, 0x0f, 0x80, 0x07, 0xf8, 0x00, 0x00,\n    \n    28  0x00, 0x00, 0x1f, 0xe0, 0x00, 0x00, 0x00, 0x3f, 0xfc, 0x00, 0x0f, 0x80, 0x07, 0xf8, 0x00, 0x00,\n    \n    29  0x00, 0x00, 0x1f, 0xc0, 0x00, 0x00, 0x00, 0x3f, 0xfc, 0x00, 0x0f, 0x80, 0x03, 0xf8, 0x00, 0x00,\n    \n    30  0x00, 0x00, 0x1f, 0xc0, 0x1f, 0xff, 0x00, 0x1f, 0xf8, 0x00, 0xff, 0xf8, 0x03, 0xfc, 0x00, 0x00,\n    \n    31  0x00, 0x00, 0x1f, 0xc0, 0x3f, 0xff, 0x00, 0x1f, 0xf8, 0x00, 0xff, 0xf8, 0x03, 0xfc, 0x00, 0x00,\n    \n    32  0x00, 0x00, 0x1f, 0xc0, 0x3f, 0xff, 0x00, 0x1f, 0xf0, 0x00, 0xff, 0xf8, 0x03, 0xfc, 0x00, 0x00,\n    \n    33  0x00, 0x00, 0x1f, 0xc0, 0x1f, 0xff, 0x00, 0x1f, 0xf8, 0x00, 0xff, 0xf8, 0x03, 0xfc, 0x00, 0x00,\n    \n    34  0x00, 0x00, 0x1f, 0xc0, 0x00, 0x00, 0x00, 0x3f, 0xfc, 0x00, 0x0f, 0x80, 0x03, 0xf8, 0x00, 0x00,\n    \n    35  0x00, 0x00, 0x1f, 0xc0, 0x00, 0x00, 0x00, 0x3f, 0xfc, 0x00, 0x0f, 0x80, 0x07, 0xf8, 0x00, 0x00,\n    \n    36  0x00, 0x00, 0x1f, 0xe0, 0x00, 0x00, 0x00, 0x7f, 0xfe, 0x00, 0x0f, 0x80, 0x07, 0xf8, 0x00, 0x00,\n    \n    37  0x00, 0x00, 0x1f, 0xe0, 0x00, 0x00, 0x00, 0xff, 0xff, 0x00, 0x0f, 0x80, 0x07, 0xf8, 0x00, 0x00,\n    \n    38  0x00, 0x00, 0x1f, 0xf0, 0x00, 0x00, 0x01, 0xff, 0xff, 0x80, 0x0f, 0x00, 0x0f, 0xf8, 0x00, 0x00,\n    \n    39  0x00, 0x00, 0x0f, 0xf0, 0x00, 0x00, 0x03, 0xff, 0xff, 0x80, 0x00, 0x00, 0x0f, 0xf0, 0x00, 0x00,\n    \n    40  0x00, 0x00, 0x0f, 0xf8, 0x00, 0x00, 0x07, 0xff, 0xff, 0xc0, 0x00, 0x00, 0x1f, 0xf0, 0x00, 0x00,\n    \n    41  0x00, 0x00, 0x07, 0xfc, 0x00, 0x00, 0x0f, 0xfe, 0x7f, 0xf0, 0x00, 0x00, 0x3f, 0xe0, 0x00, 0x00,\n    \n    42  0x00, 0x00, 0x07, 0xfe, 0x00, 0x00, 0x1f, 0xfc, 0x3f, 0xf8, 0x00, 0x00, 0x7f, 0xe0, 0x00, 0x00,\n    \n    43  0x00, 0x00, 0x03, 0xff, 0x00, 0x00, 0x7f, 0xf8, 0x1f, 0xfc, 0x00, 0x00, 0xff, 0xc0, 0x00, 0x00,\n    \n    44  0x00, 0x00, 0x01, 0xff, 0xc0, 0x01, 0xff, 0xf0, 0x0f, 0xff, 0x00, 0x03, 0xff, 0x80, 0x00, 0x00,\n    \n    45  0x00, 0x00, 0x01, 0xff, 0xf8, 0x07, 0xff, 0xf0, 0x07, 0xff, 0xe0, 0x1f, 0xff, 0x80, 0x00, 0x00,\n    \n    46  0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0xe0, 0x03, 0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00,\n    \n    47  0x00, 0x00, 0x00, 0x7f, 0xff, 0xff, 0xff, 0x80, 0x01, 0xff, 0xff, 0xff, 0xfe, 0x00, 0x00, 0x00,\n    \n    48  0x00, 0x00, 0x00, 0x3f, 0xff, 0xff, 0xff, 0x00, 0x00, 0xff, 0xff, 0xff, 0xfc, 0x00, 0x00, 0x00,\n    \n    49  0x00, 0x00, 0x00, 0x0f, 0xff, 0xff, 0xfe, 0x00, 0x00, 0x7f, 0xff, 0xff, 0xf0, 0x00, 0x00, 0x00,\n    \n    50  0x00, 0x00, 0x00, 0x07, 0xff, 0xff, 0xf8, 0x00, 0x00, 0x1f, 0xff, 0xff, 0xe0, 0x00, 0x00, 0x00,\n    \n    51  0x00, 0x00, 0x00, 0x01, 0xff, 0xff, 0xe0, 0x00, 0x00, 0x07, 0xff, 0xff, 0x80, 0x00, 0x00, 0x00,\n    \n    52  0x00, 0x00, 0x00, 0x00, 0x7f, 0xff, 0x80, 0x00, 0x00, 0x01, 0xff, 0xfc, 0x00, 0x00, 0x00, 0x00,\n    \n    53  0x00, 0x00, 0x00, 0x00, 0x07, 0xf8, 0x00, 0x00, 0x00, 0x00, 0x1f, 0xc0, 0x00, 0x00, 0x00, 0x00,\n    \n    54  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    \n    55  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    \n    56  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    \n    57  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    \n    58  0x00, 0x00, 0x00, 0x0c, 0x07, 0x80, 0xf0, 0x04, 0x18, 0xff, 0x88, 0x18, 0x1c, 0x00, 0x00, 0x00,\n    \n    59  0x00, 0x00, 0x00, 0x1e, 0x0f, 0xf8, 0xff, 0x1e, 0x1c, 0xff, 0x9e, 0x1c, 0x7f, 0x00, 0x00, 0x00,\n    \n    60  0x00, 0x00, 0x00, 0x1f, 0x0f, 0xfc, 0xff, 0x9e, 0x1c, 0xff, 0x9f, 0x1c, 0xff, 0x80, 0x00, 0x00,\n    \n    61  0x00, 0x00, 0x00, 0x3f, 0x0e, 0x3c, 0xe3, 0xce, 0x1c, 0x1c, 0x1f, 0x1d, 0xe3, 0x80, 0x00, 0x00,\n    \n    62  0x00, 0x00, 0x00, 0x3f, 0x0e, 0x1c, 0xe1, 0xce, 0x1c, 0x1c, 0x1f, 0x99, 0xc3, 0x80, 0x00, 0x00,\n    \n    63  0x00, 0x00, 0x00, 0x33, 0x8e, 0x1c, 0xe1, 0xce, 0x1c, 0x1c, 0x1f, 0x99, 0xc3, 0xc0, 0x00, 0x00,\n    \n    64  0x00, 0x00, 0x00, 0x73, 0x8f, 0x3c, 0xe1, 0xce, 0x1c, 0x1c, 0x1d, 0xd9, 0xc3, 0xc0, 0x00, 0x00,\n    \n    65  0x00, 0x00, 0x00, 0x73, 0x8f, 0xf8, 0xe1, 0xce, 0x1c, 0x1c, 0x1d, 0xf9, 0xc3, 0xc0, 0x00, 0x00,\n    \n    66  0x00, 0x00, 0x00, 0x7f, 0x8f, 0xf0, 0xe1, 0xce, 0x1c, 0x1c, 0x1c, 0xf9, 0xc3, 0x80, 0x00, 0x00,\n    \n    67  0x00, 0x00, 0x00, 0xff, 0xce, 0x70, 0xe3, 0xce, 0x1c, 0x1c, 0x1c, 0xf9, 0xc3, 0x80, 0x00, 0x00,\n    \n    68  0x00, 0x00, 0x00, 0xff, 0xce, 0x78, 0xe7, 0x8e, 0x3c, 0x3c, 0x1c, 0x7d, 0xe7, 0x80, 0x00, 0x00,\n    \n    69  0x00, 0x00, 0x00, 0xe1, 0xce, 0x3c, 0xff, 0x8f, 0xf8, 0xff, 0x9c, 0x7c, 0xff, 0x00, 0x00, 0x00,\n    \n    70  0x00, 0x00, 0x01, 0xe1, 0xee, 0x3c, 0xff, 0x07, 0xf0, 0xff, 0x9c, 0x3c, 0x7e, 0x00, 0x00, 0x00,\n    \n    71  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0xc0, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n    \n    72  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    \n    73};\n    \n    74\n    \n    \n    75void setup() {\n    \n    76  Serial.begin(9600);\n    \n    77\n    \n    \n    78  if(!display.begin(SSD1306_SWITCHCAPVCC, 0x3C)) {\n    \n    79    Serial.println(F(\"SSD1306 not found\"));\n    \n    80    while(1){}\n    \n    81  }\n    \n    82\n    \n    \n    83  display.clearDisplay();\n    \n    84\n    \n    \n    85  display.drawBitmap(0, 0, arduinoLogo, 128, 64, SSD1306_WHITE);\n    \n    86  display.display();\n    \n    87\n    \n    \n    88}\n    \n    89\n    \n    \n    90void loop() {\n    \n    91}\n\n####  Suggest changes\n\nThe content on [ docs.arduino.cc ](https://docs.arduino.cc/) is facilitated\nthrough a public  [ GitHub repository ](https://github.com/arduino/docs-\ncontent) . If you see anything wrong, you can edit this page  [ here\n](https://github.com/arduino/docs-\ncontent/edit/main/content/learn/05.communication/01.wire/wire.md) .\n\n####  Need support?\n\n[ Help Center ](https://support.arduino.cc/) [ Ask the Arduino Forum\n](https://forum.arduino.cc/) [ Discover Arduino Discord\n](https://discord.gg/jQJFwW7)\n\n####  License\n\nThe Arduino documentation is licensed under the  [ Creative Commons\nAttribution-Share Alike 4.0 ](https://creativecommons.org/licenses/by-sa/4.0/)\nlicense.\n\n#####  ON THIS PAGE\n\n  * Introduction \n\n  * Overview \n\n  * What Is I2C? \n\n  * Arduino I2C Pins \n\n  * I2C Wiring \n\n  * Wire Library \n\n  * Examples \n\n[ \u00c2\u00a9  2024  Arduino ](https://www.arduino.cc/)\n\n[ Terms Of Service ](https://www.arduino.cc/en/terms-conditions) [ Privacy\nPolicy ](https://www.arduino.cc/en/privacy-policy) [ Security\n](https://www.arduino.cc/en/security) [ Cookie Settings\n](https://www.arduino.cc/en/cookie-policy)\n\n"
  },
  {
    "id": "rosgzbridge/389481.txt",
    "content": "[ OpenEmbedded Layer Index ](/layerindex/)\n\n[ Log in ](/accounts/login/?next=/layerindex/recipe/389481/)\n\n  * \n\n[ Submit layer ](/layerindex/submit/)\n\n  * [ master ](/layerindex/branch/master/layers/)\n  * [ meta-ros2-humble ](/layerindex/branch/master/layer/meta-ros2-humble/)\n  * ros-gz-bridge \n\n#  ros-gz-bridge 0.244.12-1\n\nName  |  ros-gz-bridge  \n---|---  \nVersion  |  0.244.12-1 (d8541d76d004037833f2f93dbb090aa9c83f615e)  \nSummary  |  \nDescription  |  Bridge communication between ROS and Gazebo Transport  \nSection  |  devel  \nLicense  |  Apache-2.0  \nHomepage  |  [ https://wiki.ros.org ](https://wiki.ros.org)  \nRecipe file  |  generated-recipes/ros-gz/ros-gz-bridge_0.244.12-1.bb  \nLayer  |  [ meta-ros2-humble ](/layerindex/branch/master/layer/meta-\nros2-humble/) (master branch)  \nInherits  |\n\n  * cmake \n  * python3-dir \n  * python3native \n  * ros2_distro \n  * ros_ament_cmake \n  * ros_component \n  * ros_distro \n  * ros_distro_humble \n  * ros_faulty_solibs \n  * ros_superflore_generated \n\n  \nDependencies __ |\n\n  * actuator-msgs \n  * ament-cmake-native \n  * cmake-native \n  * geometry-msgs \n  * ignition-msgs8 \n  * ignition-transport11 \n  * nav-msgs \n  * ninja-native \n  * pkgconfig-native \n  * python3-native \n  * rclcpp \n  * rclcpp-components \n  * ros-gz-interfaces \n  * rosgraph-msgs \n  * sensor-msgs \n  * std-msgs \n  * tf2-msgs \n  * trajectory-msgs \n  * virtual/i686-oe-linux-compilerlibs \n  * virtual/i686-oe-linux-gcc \n  * virtual/libc \n  * vision-msgs \n  * yaml-cpp-vendor \n\n  \nPACKAGECONFIG options  |  \n  \n##  Sources\n\n[ git://github.com/ros2-gbp/ros_ign-release\n](https://github.com/ros2-gbp/ros_ign-release)  \n---  \n  \n##  Patches\n\nNone\n\n##  Other branches\n\nThis recipe in other branches of meta-ros2-humble:\n\nBranch  |  Recipe  \n---|---  \nmaster  |  ros-gz-bridge 0.244.12-1 (this recipe)  \nnanbield (Yocto Project 4.3)  |  [ ros-gz-bridge 0.244.12-1\n](/layerindex/recipe/390836/)  \nmickledore (Yocto Project 4.2)  |  [ ros-gz-bridge\n](/layerindex/recipe/392191/)  \nlangdale (Yocto Project 4.1)  |  [ ros-gz-bridge ](/layerindex/recipe/393546/)  \nkirkstone (Yocto Project 4.0)  |  [ ros-gz-bridge 0.244.13-1\n](/layerindex/recipe/394901/)  \n  \n* * *\n\n[ change history ](/layerindex/history/) \u2022 [ about this site\n](/layerindex/about/) \u2022 [ FAQ ](http://www.openembedded.org/Layers_FAQ)\n\n"
  },
  {
    "id": "lifecycle_deactivate/hardwarecomponentsus.txt",
    "content": "[ ![Logo](../../../../_static/logo_ros-controls.png) ](../../../../index.html)\n\n  * [ Getting Started ](../../../getting_started/getting_started.html)\n  * [ ros2_control ](../../doc/index.html)\n    * [ API Documentation ](../../doc/index.html#api-documentation)\n    * [ Features ](../../doc/index.html#features)\n    * [ Concepts ](../../doc/index.html#concepts)\n      * [ Controller Manager ](../../controller_manager/doc/userdoc.html)\n      * [ Controller Chaining / Cascade Control ](../../controller_manager/doc/controller_chaining.html)\n      * Hardware Components \n        * Guidelines and Best Practices \n          * [ Hardware Interface Types ](hardware_interface_types_userdoc.html)\n          * [ Writing a Hardware Component ](writing_new_hardware_component.html)\n          * [ Different Update Rates ](different_update_rates_userdoc.html)\n          * Handling of errors that happen during read() and write() calls \n          * Migration from Foxy to newer versions \n      * [ Mock Components ](mock_components_userdoc.html)\n  * [ ros2_controllers ](../../../ros2_controllers/doc/controllers_index.html)\n  * [ Demos ](../../../ros2_control_demos/doc/index.html)\n  * [ Command Line Interface ](../../ros2controlcli/doc/userdoc.html)\n  * [ Simulator Integrations ](../../../simulators/simulators.html)\n  * [ Differences to ros_control (ROS1) ](../../../differences_to_ros1/differences_to_ros1.html)\n  * [ Migration Guide to ros2_control ](../../../differences_to_ros1/differences_to_ros1.html#migration-guide-to-ros2-control)\n  * [ API Documentation ](../../../api/api.html)\n  * [ Supported Robots ](../../../supported_robots/supported_robots.html)\n  * [ Resources ](../../../resources/resources.html)\n  * [ Contributing ](../../../contributing/contributing.html)\n  * [ Project Ideas for GSoC 2024 ](../../../project_ideas.html)\n  * [ Acknowledgements ](../../../acknowledgements/acknowledgements.html)\n\n__ [ ROS2_Control: Iron ](../../../../index.html)\n\n  * [ ](../../../../index.html)\n  * [ ros2_control ](../../doc/index.html)\n  * Hardware Components \n  * [ Edit on GitHub ](https://github.com/ros-controls/ros2_control/blob/iron/hardware_interface/doc/hardware_components_userdoc.rst)\n\n* * *\n\n#  Hardware Components  \uf0c1\n\nHardware components represent abstraction of physical hardware in ros2_control\nframework. There are three types of hardware Actuator, Sensor and System. For\ndetails on each type check [ Hardware Components\n](../../../getting_started/getting_started.html#overview-hardware-components)\ndescription.\n\n##  Guidelines and Best Practices  \uf0c1\n\n  * [ Hardware Interface Types ](hardware_interface_types_userdoc.html)\n  * [ Writing a Hardware Component ](writing_new_hardware_component.html)\n  * [ Different Update Rates ](different_update_rates_userdoc.html)\n\n###  Handling of errors that happen during read() and write() calls  \uf0c1\n\nIf ` hardware_interface::return_type::ERROR  ` is returned from ` read()  ` or\n` write()  ` methods of a hardware_interface class, ` on_error(previous_state)\n` method will be called to handle any error that happened.\n\nError handling follows the [ node lifecycle\n](https://design.ros2.org/articles/node_lifecycle.html) . If successful `\nCallbackReturn::SUCCESS  ` is returned and hardware is again in ` UNCONFIGURED\n` state, if any ` ERROR  ` or ` FAILURE  ` happens the hardware ends in `\nFINALIZED  ` state and can not be recovered. The only option is to reload the\ncomplete plugin, but there is currently no service for this in the Controller\nManager.\n\n###  Migration from Foxy to newer versions  \uf0c1\n\nBetween Foxy and Galactic we made substantial changes to the interface of\nhardware components to enable management of their lifecycle. The following\nlist shows a set of quick changes to port existing hardware components to\nGalactic:\n\n  1. Rename ` configure  ` to ` on_init  ` and change return type to ` CallbackReturn  `\n\n  2. If using BaseInterface as base class then you should remove it. Specifically, change: \n\n>\n>\n> hardware_interface::BaseInterface<hardware_interface::[Actuator|Sensor|System]Interface>\n>  \n>\n> to\n>  \n>  \n>     hardware_interface::[Actuator|Sensor|System]Interface\n>  \n\n  3. Remove include of headers ` base_interface.hpp  ` and ` hardware_interface_status_values.hpp  `\n\n  4. Add include of header ` rclcpp_lifecycle/state.hpp  ` although this may not be strictly necessary \n\n  5. replace first three lines in ` on_init  ` to \n\n>\n>     if (hardware_interface::[Actuator|Sensor|System]Interface::on_init(info)\n> != CallbackReturn::SUCCESS)\n>     {\n>       return CallbackReturn::ERROR;\n>     }\n>  \n\n  6. Change last return of ` on_init  ` to ` return  CallbackReturn::SUCCESS;  `\n\n  7. Remove all lines with ` status_  =  ...  ` or ` status::...  `\n\n  8. Rename ` start()  ` to ` on_activate(const  rclcpp_lifecycle::State  & previous_state)  ` and ` stop()  ` to ` on_deactivate(const  rclcpp_lifecycle::State  & previous_state)  `\n\n  9. Change return type of ` on_activate  ` and ` on_deactivate  ` to ` CallbackReturn  `\n\n  10. Change last return of ` on_activate  ` and ` on_deactivate  ` to ` return  CallbackReturn::SUCCESS;  `\n\n  11. If you have any ` return_type::ERROR  ` in ` on_init  ` , ` on_activate  ` , or ` in_deactivate  ` change to ` CallbackReturn::ERROR  `\n\n  12. If you get link errors with undefined refernences to symbols in ` rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface  ` , then add ` rclcpp_lifecyle  ` package dependency to ` CMakeLists.txt  ` and ` package.xml  `\n\n[ Previous ](../../controller_manager/doc/controller_chaining.html \"Controller\nChaining / Cascade Control\") [ Next  ](hardware_interface_types_userdoc.html\n\"ros2_control hardware interface types\")\n\n* * *\n\n\u00a9 Copyright 2024, ros2_control Development Team.\n\nBuilt with [ Sphinx ](https://www.sphinx-doc.org/) using a [ theme\n](https://github.com/readthedocs/sphinx_rtd_theme) provided by [ Read the Docs\n](https://readthedocs.org) .\n\nOther Versions  v: iron\n\nReleases\n\n     [ Iron (latest) ](hardware_components_userdoc.html)\n  \n     [ Humble ](../../../../../humble/doc/ros2_control/hardware_interface/doc/hardware_components_userdoc.html)\n  \n     [ Galactic (EOL) ](../../../../../galactic/doc/ros2_control/hardware_interface/doc/hardware_components_userdoc.html)\n  \n     [ Foxy (EOL) ](../../../../../foxy/index.html)\n  \n\nIn Development\n\n     [ Master ](../../../../../master/doc/ros2_control/hardware_interface/doc/hardware_components_userdoc.html)\n\n"
  },
  {
    "id": "spawn_entity/spawnmodelwithros2ga.txt",
    "content": "First time here? Check out the FAQ!\n\n  \nROS Resources: [ Documentation ](http://wiki.ros.org/) | [ Support\n](http://wiki.ros.org/Support) | [ Discussion Forum\n](http://discourse.ros.org/) | [ Index ](http://index.ros.org/) | [ Service\nStatus ](http://status.ros.org/) | [ ros @ Robotics Stack Exchange\n](https://robotics.stackexchange.com/questions/tagged/ros)  \n---  \n  \n_Attention:_ Answers.ros.org is deprecated as of August the 11th, 2023. Please\nvisit [ robotics.stackexchange.com ](http://robotics.stackexchange.com) to ask\na new question. This site will remain online in read-only mode during the\ntransition and into the foreseeable future. Selected questions and answers\nhave been migrated, and redirects have been put in place to direct users to\nthe corresponding questions on Robotics Stack Exchange. Additional details are\n[ available here ](https://discourse.ros.org/t/ros-and-gazebo-answers-\nmigration-to-robotics-stack-exchange-process/31494) .\n\n[ Hi there! Please sign in ](/account/signin/?next=/question/314607/spawn-\nmodel-with-ros2-gazebo/) [ help ](/help/ \"help\")\n\n[ ![ROS Answers logo](/m/ros/media/images/logoros.png?v=28) ](/questions/)\n\n[ tags ](/tags/) [ users ](/users/) [ badges ](/badges/)\n\nThe site is read-only. Please transition to use Robotics Stack Exchange\n\n[ __ ](/questions/) |\n\n[ ALL ](/questions/scope:all/sort:activity-desc/page:1/) [ UNANSWERED\n](/questions/scope:unanswered/sort:answers-asc/page:1/)\n\n|\n\n|  [ Ask Your Question ](/questions/ask/)  \n---|---|---|---  \n  \n2\n\n#\n\nspawn model with ROS2 gazebo\n\nedit\n\n  * [ ros2 ](/questions/scope:all/sort:activity-desc/tags:ros2/page:1/)\n\n  * [ crystal ](/questions/scope:all/sort:activity-desc/tags:crystal/page:1/)\n\n  * [ gazebo ](/questions/scope:all/sort:activity-desc/tags:gazebo/page:1/)\n\n[ **asked 2019-02-04 03:42:55 -0500  ** ](/questions/314607/revisions/)\n\n[ ![poonam1120 gravatar\nimage](//www.gravatar.com/avatar/bf885637e4856f27e8510e2b2a4fbaa3?s=32&d=identicon&r=PG)\n](/users/38719/poonam1120/)\n\n[ poonam1120 ](/users/38719/poonam1120/)  \n77  \u25cf  9  \u25cf  12  \u25cf  14\n\nHi,\n\nI followed this link and able to spawn the sdf model in gazebo.\n\n[ https://github.com/ros-simulation/gaz... ](https://github.com/ros-\nsimulation/gazebo_ros_pkgs/wiki/ROS-2-Migration:-Spawn-and-delete)\n\nBut instead of sending sdf model code from command line, can we send just\nsdf/urdf file ? I tried that but it failed.\n\nWhen i send complete sdf modem from cmnd lien with spawn_entity, it launched\nin gazebo. I am trying it on crystal.\n\nPlease let me know if anybody is having any clue.\n\nThanks.\n\n[ edit ](/questions/314607/edit/) [ retag ](/s/questions/314607/retag/) flag\noffensive  [ close ](/questions/314607/close/) merge  delete\n\nadd a comment\n\n##  4  Answers\n\nSort by \u00bb  [ oldest  ](/question/314607/spawn-model-with-\nros2-gazebo/?sort=oldest#sort-top) [ newest  ](/question/314607/spawn-model-\nwith-ros2-gazebo/?sort=latest#sort-top) [ most voted\n](/question/314607/spawn-model-with-ros2-gazebo/?sort=votes#sort-top)\n\n3\n\n[ **answered 2022-02-15 03:48:38 -0500  ** ](/answers/396189/revisions/)\n\n[ ![Reka gravatar\nimage](//www.gravatar.com/avatar/13192370985ec221a13aaf0971f4de0a?s=32&d=identicon&r=PG)\n](/users/41393/reka/)\n\n[ Reka ](/users/41393/reka/)  \n31  \u25cf  1  \u25cf  5  \u25cf  4\n\n[ **updated 2022-02-15 03:53:54 -0500  ** ](/answers/396189/revisions/)\n\nBased on the ROS2 tutorial: 'Writing a simple service and client (python)' and\nthe work of clyde, I've created a complete ROS2 python client to spawn an\nentity:\n\n    \n    \n    import sys\n    import rclpy\n    from gazebo_msgs.srv import SpawnEntity\n    \n    from rclpy.node import Node\n    \n    \n    class MinimalClientAsync(Node):\n    \n        def __init__(self):\n            super().__init__('spawn_entity')\n            self.client = self.create_client(SpawnEntity, 'spawn_entity')\n            while not self.client.wait_for_service(timeout_sec=1.0):\n                self.get_logger().info('service not available, waiting again...')\n            self.req = SpawnEntity.Request()\n    \n        def send_request(self):\n            self.req.name = str(sys.argv[1])\n            self.req.xml = str(sys.argv[2])\n            self.future = self.client.call_async(self.req)\n    \n    \n    def main(args=None):\n        rclpy.init(args=args)\n    \n        minimal_client = MinimalClientAsync()\n        minimal_client.send_request()\n    \n        while rclpy.ok():\n            rclpy.spin_once(minimal_client)\n            if minimal_client.future.done():\n                try:\n                    response = minimal_client.future.result()\n                except Exception as e:\n                    minimal_client.get_logger().info(\n                        'Service call failed %r' % (e,))\n                else:\n                    minimal_client.get_logger().info(\n                        'Test {}'.format(minimal_client.req.xml))\n                break\n    \n        minimal_client.destroy_node()\n        rclpy.shutdown()\n    \n    \n    if __name__ == '__main__':\n        main()\n    \n\nTo spawn a sphere in Gazebo:\n\n  1. Start gazebo: \n    \n          gazebo --verbose -s libgazebo_ros_factory.so\n    \n\n  2. Run the client node: \n    \n          ros2 run my_package my_client_name entity_name xml_description\n    \n\nExample usage :\n\n    \n          ros2 run my_package my_client my_model \"<?xml version=\\\"1.0\\\" ?><sdf version=\\\"1.5\\\"><model name=\\\"will_be_ignored\\\"><static>true</static><link name=\\\"link\\\"><visual name=\\\"visual\\\"><geometry><sphere><radius>1.0</radius></sphere></geometry></visual></link></model></sdf>\"\n    \n\n[ edit ](/s/answers/396189/edit/) flag offensive  delete  [ link\n](/question/314607/spawn-model-with-ros2-gazebo/?answer=396189#post-id-396189\n\"permanent link\") more\n\n  *   * \n\nadd a comment\n\n3\n\n[ **answered 2021-03-29 19:22:19 -0500  ** ](/answers/374963/revisions/)\n\n[ ![808brick gravatar image](/m/default/media/images/nophoto.png?v=28)\n](/users/51297/808brick/)\n\n[ 808brick ](/users/51297/808brick/)  \n153  \u25cf  2  \u25cf  9  \u25cf  11\n\nI'd like to update this answer for some people, as ROS2 functionality has\nimproved but the documentation has not yet caught up. (To be clear it is March\n2021 and I am running ROS 2 Foxy)\n\nIf you have a URDF file (note that the syntax for URDF in ROS 2 is slightly\ndifferent than ROS 1) in your package that you want to spawn into Gazebo, you\nhave to do the following:\n\n1) Launch gazebo (not the standard way, I will elaborate below)  \n2) Launch the robot state publisher with your URDF file  \n3) Run the ` spawn_entity ` node to spawn your robot into gazebo\n\nHere is how you go about doing it (as individual steps)\n\n1) Create a Launch File for for your robot state publisher, here is an\nexample:\n\n    \n    \n    import os\n    from ament_index_python.packages import get_package_share_directory\n    from launch import LaunchDescription\n    from launch.actions import DeclareLaunchArgument\n    from launch.substitutions import LaunchConfiguration\n    from launch_ros.actions import Node\n    \n    def generate_launch_description():\n    \n      use_sim_time = LaunchConfiguration('use_sim_time', default='false')\n      urdf_file_name = 'urdf/camera_bot.xacro'\n    \n      print(\"urdf_file_name : {}\".format(urdf_file_name))\n    \n      urdf = os.path.join(\n          get_package_share_directory('ros2_sim_pkg'),\n          urdf_file_name)\n    \n      return LaunchDescription([\n    \n            DeclareLaunchArgument(\n                'use_sim_time',\n                default_value='false',\n                description='Use simulation (Gazebo) clock if true'),\n            Node(\n                package='robot_state_publisher',\n                executable='robot_state_publisher',\n                name='robot_state_publisher',\n                output='screen',\n                parameters=[{'use_sim_time': use_sim_time}],\n                arguments=[urdf])\n      ])\n    \n\nIn this example I am launching the robot state publisher with a URDF file\ncalled ` camera_bot.xacro ` (I am using .xacro because I want to reference\nother XML files, but a standard ` .urdf ` or ` .xml ` will work all the same)\nfrom a package called ` ros2_sim_pkg ` . Change the URDF and package names to\nfit your project.\n\n2) Build your workspace ( ` colcon build ` )\n\n3) Source your workspace in the terminals you open ( ` source\ninstall/setup.bash ` )\n\n4) Launch gazebo with ` ros2 launch gazebo_ros gazebo.launch.py `\n\n5) Launch the launch file you just created to configure your\nrobot_state_publisher: ` ros2 launch ros2_sim_pkg cam_bot_world.launch ` .\nMake sure to change the package name and launch file name to match yours.\n\n6) Run the URDF spawner node: ` ros2 run gazebo_ros spawn_entity.py ` -topic\n/robot_description -entity my_cam_bot`\n\nThe entity name will be the name of your model within gazebo, so feel free to\nchange \"my_cam_bot\" to whatever you want. It will automatically spawn at the\norigin, so if you do not want this, you can check out the other parameters\nhere: [ https://github.com/ros-\nsimulation/gazebo_ros_pkgs/blob/foxy/gazebo_ros/scripts/spawn_entity.py#L51\n](https://github.com/ros-\nsimulation/gazebo_ros_pkgs/blob/foxy/gazebo_ros/scripts/spawn_entity.py#L51)\n\nAnd with that you should have gazebo running with your URDF spawned in at the\norigin. I do not have Karma points so I can not show you a picture of it\nworking unfortunately.\n\nYou can feel free to combine all these steps into one big launch file for\nconvenience, but I just wanted to illustrate the process order so it was more\nunderstandable.\n\nHope this helps.\n\n[ edit ](/s/answers/374963/edit/) flag offensive  delete  [ link\n](/question/314607/spawn-model-with-ros2-gazebo/?answer=374963#post-id-374963\n\"permanent link\") more\n\n  *   * \n\n##  Comments\n\nFor those this works, but model tree is created in gazebo but robot not\nvisible. Try adding absolute path for mesh in urdf file.\n\n[ ![Jeffin Johny gravatar image](/m/default/media/images/nophoto.png?v=28)\n](/users/115928/jeffin-johny/) [ Jeffin Johny ](/users/115928/jeffin-johny/) (\n2022-08-30 21:55:20 -0500  )  edit\n\nadd a comment\n\n2\n\n[ **answered 2019-03-13 13:21:02 -0500  ** ](/answers/318494/revisions/)\n\n[ ![clyde gravatar image](/upfiles/avatars/clyde/resized/32/headshot.jpg)\n](/users/28405/clyde/)\n\n[ clyde ](/users/28405/clyde/)  \n1247  \u25cf  27  \u25cf  54  \u25cf  51\n\nFollowing tfoote's advice, here is an example:\n\n    \n    \n    import sys\n    import rclpy\n    from gazebo_msgs.srv import SpawnEntity\n    \n    \n    def request_spawn(xml: str):\n        rclpy.init()\n        node = rclpy.create_node('spawn_entity')\n        client = node.create_client(SpawnEntity, 'spawn_entity')\n        if not client.service_is_ready():\n            client.wait_for_service()\n        request = SpawnEntity.Request()\n        request.xml = xml\n        future = client.call_async(request)\n        rclpy.spin_until_future_complete(node, future)\n        if future.result() is not None:\n            print('response: %r' % future.result())\n        else:\n            raise RuntimeError('exception while calling service: %r' % future.exception())\n        node.destroy_node()\n        rclpy.shutdown()\n    \n    \n    if len(sys.argv) < 2:\n        print('usage: ros2 run my_package my_node.py -- example.urdf')\n        sys.exit(1)\n    \n    f = open(sys.argv[1], 'r')\n    request_spawn(f.read())\n    \n\n[ edit ](/s/answers/318494/edit/) flag offensive  delete  [ link\n](/question/314607/spawn-model-with-ros2-gazebo/?answer=318494#post-id-318494\n\"permanent link\") more\n\n  *   * \n\nadd a comment\n\n1\n\n[ **answered 2019-02-04 11:30:17 -0500  ** ](/answers/314681/revisions/)\n\n[ ![tfoote gravatar\nimage](//www.gravatar.com/avatar/3bc6528f8fe1fef6b6ecc7312ee0cf04?s=32&d=identicon&r=PG)\n](/users/3/tfoote/)\n\n[ tfoote ](/users/3/tfoote/) ![flag of United States of\nAmerica](/m/default/media/images/flags/us.gif?v=28)  \n58457  \u25cf  128  \u25cf  550  \u25cf  526  [ http://www.ros.org/ ](http://www.ros.org/\n\"tfoote's website is http://www.ros.org/\")\n\n[ **updated 2019-03-13 15:50:06 -0500  ** ](/answers/314681/revisions/)\n\nThe examples are using generic command line tools. If you want to send from a\nfile you can probably set it up to pipe the arguments into the rosservice call\nusing xargs. But more likely I'd recommend writing the few line rclpy script\nto load the file and call the service call. If you'd like to contribute a\ngeneric version of that helper script to the gazebo_ros_pkgs that would be\neven better.\n\n[ edit ](/s/answers/314681/edit/) flag offensive  delete  [ link\n](/question/314607/spawn-model-with-ros2-gazebo/?answer=314681#post-id-314681\n\"permanent link\") more\n\n  *   * \n\nadd a comment\n\n##  Question Tools\n\nFollow\n\n5 followers\n\n[ subscribe to rss feed ](/feeds/question/314607/ \"subscribe to the rss feed\")\n\n##  Stats\n\nAsked: ** 2019-02-04 03:42:55 -0500  **\n\nSeen: **8,496 times**\n\nLast updated: **Feb 15 '22**\n\n##  Related questions\n\n[ [ROS2 Crystal] Minimalistic built from sources\n](/question/319587/ros2-crystal-minimalistic-built-from-sources/)\n\n[ [Ros2] load a .yaml file in cpp program ](/question/313927/ros2-load-a-yaml-\nfile-in-cpp-program/)\n\n[ [robot_state_publisher-3] process has died\n](/question/370661/robot_state_publisher-3-process-has-died/)\n\n[ ROS2 crystal - QoS publisher failure routine\n](/question/314765/ros2-crystal-qos-publisher-failure-routine/)\n\n[ ros2 run - symbol not found on custom msg ](/question/326008/ros2-run-\nsymbol-not-found-on-custom-msg/)\n\n[ Gazebo in the hardware loop ](/question/44457/gazebo-in-the-hardware-loop/)\n\n[ rosbag2 doesn't write meta data file ](/question/397687/rosbag2-doesnt-\nwrite-meta-data-file/)\n\n[ cannot import interpreter ](/question/316468/cannot-import-interpreter/)\n\n[ Selecting log level in ROS2 launch file ](/question/311471/selecting-log-\nlevel-in-ros2-launch-file/)\n\n[ How can I run ROS2 nodes in a debugger (e.g. gdb)? ](/question/267261/how-\ncan-i-run-ros2-nodes-in-a-debugger-eg-gdb/)\n\n[ ![cc-by-sa](/m/default/media/images/cc-by-sa.png?v=28)\n](http://creativecommons.org/licenses/by-sa/3.0/legalcode) ROS Answers is\nlicensed under Creative Commons Attribution 3.0 Content on this site is\nlicensed under a [ Creative Commons Attribution Share Alike 3.0\n](http://creativecommons.org/licenses/by-sa/3.0/legalcode) license.\n\n[ about ](/about/) |  [ faq ](/faq/) |  [ help ](/help/ \"help\") |  [ privacy\npolicy ](/privacy/) |  [ terms of service ](/terms/)\n\n[ Powered by Askbot version 0.10.2 ](http://askbot.com)\n\nPlease note: ROS Answers requires javascript to work properly, please enable\njavascript in your browser, [ here is how\n](https://www.google.com/support/bin/answer.py?answer=23852)\n\n[ ![ gravatar image]() ]() [ ]() (  2024-04-14 18:33:55 -0500  )  edit\n\n[ none ](/questions/scope:all/sort:activity-desc/tags:none/page:1/) \u00d7\n\n  *[\n              2019-02-04 03:42:55 -0500\n             ]: 2019-02-04 03:42:55 -0500\n  *[\n              2022-02-15 03:48:38 -0500\n             ]: 2022-02-15 03:48:38 -0500\n  *[\n              2022-02-15 03:53:54 -0500\n             ]: 2022-02-15 03:53:54 -0500\n  *[\n              2021-03-29 19:22:19 -0500\n             ]: 2021-03-29 19:22:19 -0500\n  *[\n             2022-08-30 21:55:20 -0500\n            ]: 2022-08-30 21:55:20 -0500\n  *[\n              2019-03-13 13:21:02 -0500\n             ]: 2019-03-13 13:21:02 -0500\n  *[\n              2019-02-04 11:30:17 -0500\n             ]: 2019-02-04 11:30:17 -0500\n  *[\n              2019-03-13 15:50:06 -0500\n             ]: 2019-03-13 15:50:06 -0500\n  *[\n        2019-02-04 03:42:55 -0500\n       ]: 2019-02-04 03:42:55 -0500\n  *[\n        2024-04-14 18:33:55 -0500\n       ]: 2024-04-14 18:33:55 -0500\n\n"
  },
  {
    "id": "ros_launch/roslaunchxmlhtml.txt",
    "content": "articles/151_roslaunch_xml.md\n\nToggle navigation  [ ROS 2 Design ](/)\n\n  * [ Contribute ](/contribute.html)\n\n[ Login disabled for now ]()\n\n  * ROS 2 Launch XML Format \n  * ROS 2 Launch XML Format v0.1.0 \n    * Rationale \n    * Static Description \n      * Schema Definition \n      * Tags Semantics \n        * All Tags \n        * ` <launch> ` Tag \n        * ` <include> ` Tag \n          * Description \n          * Examples \n        * ` <group> ` Tag \n          * Description \n          * Examples \n        * ` <let> ` Tag \n          * Description \n          * Examples \n        * ` <arg> ` Tag \n          * Description \n          * Examples \n        * ` <executable> ` Tag \n          * Description \n          * Examples \n        * ` <node> ` Tag \n          * Description \n          * Examples \n        * ` <param> ` Tag \n          * Description \n          * Examples \n        * ` <remap> ` Tag \n          * Description \n          * Examples \n        * ` <env> ` Tag \n          * Description \n          * Examples \n        * ` <set_env> ` Tag \n          * Description \n          * Examples \n        * ` <unset_env> ` Tag \n          * Description \n          * Examples \n    * Dynamic Configuration \n      * Substitution Syntax \n      * Built-in Substitutions \n        * User-defined Substitutions \n\n#  ROS 2 Launch XML Format\n\nThe XML format for declarative launch descriptions in the ROS 2 launch system.\n\nAuthors: [ Michel Hidalgo ](https://github.com/hidmic)\n\nDate Written: 2019-09\n\nLast Modified: 2021-06\n\n#  ROS 2 Launch XML Format v0.1.0\n\n##  Rationale\n\nAs an alternative to a programmatic approach to the ROS 2 launch system\u2019s API,\na declarative description features a WYSIWYG approach, easier to read, audit\nand maintain. This is the preferred approach for ROS 1 ` roslaunch ` launch\nfiles, thus some degree of familiarity is expected (and relied upon).\n\nThe body of such a description is mainly comprised of statically declared\nlaunch actions with a prescribed configuration. To that, runtime value\nsubstitution is added in order to fullfill common dynamic (re)configuration\nneeds like conditional execution, resource lookups, etc. It is intended for\nthese entities to map to those of the underlying implementation, reducing\nsupport to file parsing.\n\nThis article describes XML aiming to ease the bridge between ROS and ROS 2\nlaunch files. YAML is currently supported too, and other markup languages\ncould be added.\n\n##  Static Description\n\n###  Schema Definition\n\n    \n    \n    <?xml version=\"1.0\"?>\n    <xs:schema xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"\n      xmlns:vc=\"http://www.w3.org/2007/XMLSchema-versioning\"\n      vc:minVersion=\"1.1\">\n      <xs:annotation>\n        <xs:documentation xml:lang=\"en\">\n          ROS 2 launch XML schema v0.1.0\n        </xs:documentation>\n      </xs:annotation>\n    \n      <xs:element name=\"launch\">\n        <xs:annotation>\n          <xs:documentation xml:lang=\"en\">\n            The root element of a launch file.\n          </xs:documentation>\n        </xs:annotation>\n    \n        <xs:complexType>\n          <xs:choice maxOccurs=\"unbounded\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A collection of actions to be launched in order of appearance, plus\n                launch arguments for callers to provide, either through a tool or\n                by inclusion.\n              </xs:documentation>\n            </xs:annotation>\n    \n            <xs:element name=\"arg\">\n              <xs:annotation>\n                <xs:documentation xml:lang=\"en\">\n                  Declares a launch file argument.\n                </xs:documentation>\n              </xs:annotation>\n    \n              <xs:complexType>\n                <xs:attribute name=\"name\" type=\"xs:string\" use=\"required\">\n                  <xs:annotation>\n                    <xs:documentation xml:lang=\"en\">\n                      Name of the launch argument.\n                    </xs:documentation>\n                  </xs:annotation>\n                </xs:attribute>\n                <xs:attribute name=\"value\" type=\"xs:string\" use=\"optional\">\n                  <xs:annotation>\n                    <xs:documentation xml:lang=\"en\">\n                      Fixed value for the launch argument, disables overrides.\n                    </xs:documentation>\n                  </xs:annotation>\n                </xs:attribute>\n                <xs:attribute name=\"default\" type=\"xs:string\" use=\"optional\">\n                  <xs:annotation>\n                    <xs:documentation xml:lang=\"en\">\n                      Default value for the launch argument, used if non is provided.\n                    </xs:documentation>\n                  </xs:annotation>\n                </xs:attribute>\n                <xs:attribute name=\"description\" type=\"xs:string\" use=\"optional\">\n                  <xs:annotation>\n                    <xs:documentation xml:lang=\"en\">\n                      Brief description of the launch argument.\n                    </xs:documentation>\n                  </xs:annotation>\n                </xs:attribute>\n              </xs:complexType>\n            </xs:element>\n            <xs:element ref=\"let\"/>\n            <xs:element ref=\"node\"/>\n            <xs:element ref=\"executable\"/>\n            <xs:element ref=\"include\"/>\n            <xs:element ref=\"group\"/>\n            <xs:element ref=\"set_env\"/>\n            <xs:element ref=\"unset_env\"/>\n          </xs:choice>\n          <xs:attribute name=\"version\" use=\"required\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Launch XML schema version in use.\n              </xs:documentation>\n            </xs:annotation>\n            <xs:simpleType>\n              <xs:restriction base=\"xs:string\">\n                <xs:pattern value=\"[0-9]+\\.[0-9]+\\.[0-9]+\"/>\n              </xs:restriction>\n            </xs:simpleType>\n          </xs:attribute>\n        </xs:complexType>\n      </xs:element>\n    \n      <xs:element name=\"let\">\n        <xs:annotation>\n          <xs:documentation xml:lang=\"en\">\n            Defines a launch configuration variable.\n          </xs:documentation>\n        </xs:annotation>\n    \n        <xs:complexType>\n          <xs:attribute name=\"name\" type=\"xs:string\" use=\"required\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Name of the launch configuration variable.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"value\" type=\"xs:string\" use=\"required\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Value for the launch configuration variable.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n        </xs:complexType>\n      </xs:element>\n    \n      <xs:element name=\"include\">\n        <xs:annotation>\n          <xs:documentation xml:lang=\"en\">\n            Includes another launch file, either descriptive or programmatic.\n          </xs:documentation>\n        </xs:annotation>\n    \n        <xs:complexType>\n          <xs:sequence minOccurs=\"0\" maxOccurs=\"unbounded\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Arguments for the included launch file, if any.\n              </xs:documentation>\n            </xs:annotation>\n    \n            <xs:element name=\"arg\">\n              <xs:annotation>\n                <xs:documentation xml:lang=\"en\">\n                  An included launch file argument provision.\n                </xs:documentation>\n              </xs:annotation>\n    \n              <xs:complexType>\n                <xs:attribute name=\"name\" type=\"xs:string\" use=\"required\">\n                  <xs:annotation>\n                    <xs:documentation xml:lang=\"en\">\n                      Name of the launch argument.\n                    </xs:documentation>\n                  </xs:annotation>\n                </xs:attribute>\n                <xs:attribute name=\"value\" type=\"xs:string\" use=\"required\">\n                  <xs:annotation>\n                    <xs:documentation xml:lang=\"en\">\n                      Value for the launch argument.\n                    </xs:documentation>\n                  </xs:annotation>\n                </xs:attribute>\n              </xs:complexType>\n            </xs:element>\n          </xs:sequence>\n          <xs:attribute name=\"file\" type=\"xs:string\" use=\"required\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Path to the launch file to be included.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"if\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A predicate to condition launch inclusion i.e. only do\n                so if the predicate evaluates to a truthy value.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"unless\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A predicate to condition launch inclusion i.e. do\n                so unless the predicate evaluates to a truthy value.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n        </xs:complexType>\n      </xs:element>\n    \n      <xs:element name=\"group\">\n        <xs:annotation>\n          <xs:documentation xml:lang=\"en\">\n            Groups and optionally scopes a set of actions.\n          </xs:documentation>\n        </xs:annotation>\n    \n        <xs:complexType>\n          <xs:choice minOccurs=\"1\" maxOccurs=\"unbounded\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                The actions that make up the group.\n              </xs:documentation>\n            </xs:annotation>\n            <xs:element ref=\"executable\"/>\n            <xs:element ref=\"node\"/>\n            <xs:element ref=\"group\"/>\n            <xs:element ref=\"include\"/>\n            <xs:element ref=\"let\"/>\n            <xs:element ref=\"set_env\"/>\n            <xs:element ref=\"unset_env\"/>\n          </xs:choice>\n          <xs:attribute name=\"scoped\" type=\"xs:boolean\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Whether the group is a scoping one launch configuration-wise or not.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"if\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A predicate to condition group launch i.e. only do\n                so if the predicate evaluates to a truthy value.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"unless\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A predicate to condition group launch i.e. do\n                so unless the predicate evaluates to a truthy value.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n        </xs:complexType>\n      </xs:element>\n    \n      <xs:element name=\"env\">\n        <xs:annotation>\n          <xs:documentation xml:lang=\"en\">\n            Modifies an executable process environment.\n          </xs:documentation>\n        </xs:annotation>\n    \n        <xs:complexType>\n          <xs:attribute name=\"name\" type=\"xs:string\" use=\"required\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Name of the environment variable to be set.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"value\" type=\"xs:string\" use=\"required\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Value to be set for the environment variable.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n        </xs:complexType>\n      </xs:element>\n    \n      <xs:element name=\"set_env\">\n        <xs:annotation>\n          <xs:documentation xml:lang=\"en\">\n            Modifies an executable process environment.\n          </xs:documentation>\n        </xs:annotation>\n    \n        <xs:complexType>\n          <xs:attribute name=\"name\" type=\"xs:string\" use=\"required\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Name of the environment variable to be set.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"value\" type=\"xs:string\" use=\"required\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Value to be set for the environment variable.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"if\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A predicate to condition executable launch i.e. only do\n                so if the predicate evaluates to a truthy value.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"unless\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A predicate to condition executable launch i.e. do so unless\n                the predicate evaluates to a truthy value.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n        </xs:complexType>\n      </xs:element>\n    \n      <xs:element name=\"unset_env\">\n        <xs:annotation>\n          <xs:documentation xml:lang=\"en\">\n            Modifies an executable process environment.\n          </xs:documentation>\n        </xs:annotation>\n    \n        <xs:complexType>\n          <xs:attribute name=\"name\" type=\"xs:string\" use=\"required\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Name of the environment variable to be set.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"if\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A predicate to condition executable launch i.e. only do\n                so if the predicate evaluates to a truthy value.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"unless\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A predicate to condition executable launch i.e. do so unless\n                the predicate evaluates to a truthy value.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n        </xs:complexType>\n      </xs:element>\n    \n      <xs:element name=\"executable\">\n        <xs:annotation>\n          <xs:documentation xml:lang=\"en\">\n            Executes an executable as a local OS process.\n          </xs:documentation>\n        </xs:annotation>\n        <xs:complexType>\n          <xs:choice minOccurs=\"0\" maxOccurs=\"unbounded\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A collection of environment variable settings for the\n                launched executable.\n              </xs:documentation>\n            </xs:annotation>\n    \n            <xs:element ref=\"env\"/>\n          </xs:choice>\n          <xs:attribute name=\"cmd\" type=\"xs:string\" use=\"required\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Path to the executable or a command-line if a\n                shell is used to launch.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"cwd\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                The working directory for the launched process.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"name\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A name or label for the launched executable.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"args\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Additional 'command-line' arguments for the executable.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"shell\" type=\"xs:boolean\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Whether to use a shell to launch or not.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"launch-prefix\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A prefix for the executable command-line if a shell is used to launch.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"output\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Output type for the launched executable.\n              </xs:documentation>\n            </xs:annotation>\n            <xs:simpleType>\n              <xs:restriction base=\"xs:string\">\n                <xs:enumeration value=\"log\">\n                  <xs:annotation>\n                    <xs:documentation xml:lang=\"en\">\n                      Executable output goes to a log file.\n                    </xs:documentation>\n                  </xs:annotation>\n                </xs:enumeration>\n                <xs:enumeration value=\"screen\">\n                  <xs:annotation>\n                    <xs:documentation xml:lang=\"en\">\n                      Executable output goes to stdout.\n                    </xs:documentation>\n                  </xs:annotation>\n                </xs:enumeration>\n              </xs:restriction>\n            </xs:simpleType>\n          </xs:attribute>\n          <xs:attribute name=\"if\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A predicate to condition executable launch i.e. only do\n                so if the predicate evaluates to a truthy value.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"unless\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A predicate to condition executable launch i.e. do so unless\n                the predicate evaluates to a truthy value.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n        </xs:complexType>\n      </xs:element>\n    \n      <xs:element name=\"param\">\n        <xs:annotation>\n          <xs:documentation xml:lang=\"en\">\n            Sets a ROS parameter for the enclosing node to a scalar\n            value, a sequence of scalar values delimited by a known\n            separator or a sequence of nested named parameters, either\n            defined in place or in a file to be loaded.\n          </xs:documentation>\n        </xs:annotation>\n    \n        <xs:complexType>\n          <xs:choice minOccurs=\"0\" maxOccurs=\"unbounded\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A collection of nested ROS parameters to be set.\n              </xs:documentation>\n            </xs:annotation>\n    \n            <xs:element ref=\"param\"/>\n          </xs:choice>\n          <xs:attribute name=\"name\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Name of the ROS parameter to be set.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"value\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Value or list of values to set the the ROS parameter with.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"sep\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Value separator when dealing with list of values.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"from\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Path to the parameters file to be loaded.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:assert test=\"(@name and not(@from)) or (not(@name) and @from)\"/>\n        </xs:complexType>\n      </xs:element>\n    \n      <xs:element name=\"remap\">\n        <xs:annotation>\n          <xs:documentation xml:lang=\"en\">\n            Remaps ROS names for a node.\n          </xs:documentation>\n        </xs:annotation>\n    \n        <xs:complexType>\n          <xs:attribute name=\"from\" type=\"xs:string\" use=\"required\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Name matching expression to look for replacement candidates.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"to\" type=\"xs:string\" use=\"required\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Name replacement expression to replace candidates found.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n        </xs:complexType>\n      </xs:element>\n    \n      <xs:element name=\"node\">\n        <xs:annotation>\n          <xs:documentation xml:lang=\"en\">\n            Executes a ROS node executable in a local OS process.\n          </xs:documentation>\n        </xs:annotation>\n    \n        <xs:complexType>\n          <xs:choice minOccurs=\"0\" maxOccurs=\"unbounded\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A collection of ROS parameters, ROS remappings and/or\n                environment variable settings for the launched ROS node.\n              </xs:documentation>\n            </xs:annotation>\n            <xs:element ref=\"env\"/>\n            <xs:element ref=\"param\"/>\n            <xs:element ref=\"remap\"/>\n          </xs:choice>\n          <xs:attribute name=\"pkg\" type=\"xs:string\" use=\"required\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Name of the package where the node is to be found.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"exec\" type=\"xs:string\" use=\"required\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Name of the node executable.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"name\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A name for the launched ROS node.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"ros_args\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                ROS-specific 'command-line' arguments for the ROS node.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"args\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Additional 'command-line' arguments for the ROS node.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"namespace\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A ROS namespace to scope the launched ROS node.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"launch-prefix\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A prefix for the ROS node command-line used for launch.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"output\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                Output type for the launched ROS node.\n              </xs:documentation>\n            </xs:annotation>\n            <xs:simpleType>\n              <xs:restriction base=\"xs:string\">\n                <xs:enumeration value=\"log\">\n                  <xs:annotation>\n                    <xs:documentation xml:lang=\"en\">\n                      ROS node output goes to a log file.\n                    </xs:documentation>\n                  </xs:annotation>\n                </xs:enumeration>\n                <xs:enumeration value=\"screen\">\n                  <xs:annotation>\n                    <xs:documentation xml:lang=\"en\">\n                      ROS node output goes to stdout.\n                    </xs:documentation>\n                  </xs:annotation>\n                </xs:enumeration>\n              </xs:restriction>\n            </xs:simpleType>\n          </xs:attribute>\n          <xs:attribute name=\"if\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A predicate to condition ROS node launch i.e. only do\n                so if the predicate evaluates to a truthy value.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n          <xs:attribute name=\"unless\" type=\"xs:string\" use=\"optional\">\n            <xs:annotation>\n              <xs:documentation xml:lang=\"en\">\n                A predicate to condition ROS node launch i.e. do so unless\n                the predicate evaluates to a truthy value.\n              </xs:documentation>\n            </xs:annotation>\n          </xs:attribute>\n        </xs:complexType>\n      </xs:element>\n    </xs:schema>\n    \n    \n\n###  Tags Semantics\n\n####  All Tags\n\nEvery tag\u2019s execution can be conditioned on a boolean predicate via ` if ` or\n` unless ` attributes.\n\n####  ` <launch> ` Tag\n\nRoot tag of any launch file. There must only be one ` <launch> ` tag on a\ngiven launch file.\n\n####  ` <include> ` Tag\n\n#####  Description\n\nThe ` <include> ` tag allows for bringing a launch file description into\nanother, enabling re-use of hierarchical launch layouts. The included launch\nfile description has its own scope for launch configurations. The included\nlaunch file description is not necessarily written in this format nor a\ndeclarative one (i.e. a programmatic description).\n\n#####  Examples\n\n    \n    \n    <include file=\"/opt/my_launch_file.py\"/>\n    <include file=\"$(find-pkg-share my_pkg)/launch/some_launch_file.xml\"/>\n    <include file=\"/opt/my_other_launch_file.xml\">\n      <arg name=\"some_argument\" value=\"dummy_value\"/>\n    </include>\n    \n\n####  ` <group> ` Tag\n\n#####  Description\n\nThe ` <group> ` tag allows for launch actions\u2019 grouping as well as optional\nlaunch file configuration scoping.\n\n#####  Examples\n\n    \n    \n    <group scoped=\"true\">\n      <node pkg=\"a_ros_package\" name=\"dummy0\" namespace=\"my_ns\" exec=\"dummy_node\"/>\n      <node pkg=\"a_ros_package\" name=\"dummy1\" exec=\"dummy_node\"/>\n    </group>\n    \n\n####  ` <let> ` Tag\n\n#####  Description\n\nThe ` <let> ` tags allows for definition of scoped launch file configuration\nvariables.\n\n#####  Examples\n\n    \n    \n    <let name=\"foo\" value=\"$(env BAR)\"/>\n    <let name=\"baz\" value=\"false\"/>\n    \n\n####  ` <arg> ` Tag\n\n#####  Description\n\nThe ` <arg> ` tag allows for launch file configuration via the command-line or\nwhen including it via an ` <include> ` tag. Arguments are launch configuration\nvariables just like the ones defined by ` <let> ` tags. Arguments are limited\nto the scope of their definition and thus have to be explictly passed to\nincluded files if any.\n\n#####  Examples\n\n    \n    \n    <arg name=\"publish_frequency\" default=\"10\"/>\n    <arg name=\"output_path\" description=\"Output path for some processing pipeline\"/>\n    \n\n####  ` <executable> ` Tag\n\n#####  Description\n\nThe ` <executable> ` tag allows for executing any executable as a local OS\nprocess.\n\n#####  Examples\n\n    \n    \n    <executable cmd=\"ls -las\" cwd=\"/home\" launch-prefix=\"time\" output=\"screen\"/>\n    \n\n####  ` <node> ` Tag\n\n#####  Description\n\nThe ` <node> ` tag allows for executing a ROS node as a local OS process.\n\n#####  Examples\n\n    \n    \n    <node pkg=\"ros_demos\" exec=\"publisher\">\n      <param name=\"publish_frequency\" value=\"10\"/>\n      <remap from=\"generic_topic_name\" to=\"my_topic\"/>\n    </node>\n    \n\n####  ` <param> ` Tag\n\n#####  Description\n\nThe ` <param> ` tag allows for setting ROS parameters of a ROS node. These can\nbe scalar values or sequences of scalar values, defined directly or either\nnested or brought from a YAML file to make a map.\n\n#####  Examples\n\n    \n    \n    <node pkg=\"my_pkg\" exec=\"my_node\">\n      <param name=\"some_numeric_param\" value=\"100.2\"/>\n      <param name=\"some_list_of_bools\" value=\"[true, false, true, false]\"/>\n      <param name=\"some_list_of_strings\" value=\"Some phrase,'100.0','true'\" value-sep=\",\"/>\n      <param name=\"some_list_of_ints\" value=\"5, 3, 2\" value-sep=\", \"/>\n      <param name=\"some_list_of_floats\" value=\"5.0, 3.0, 2.0\" value-sep=\", \"/>\n      <param name=\"some_param_group\">\n        <param name=\"some_integer_param\" value=\"10\"/>\n      </param>\n      <param from=\"path/to/param/file.yml\"/>\n    </node>\n    \n\n####  ` <remap> ` Tag\n\n#####  Description\n\nThe ` <remap> ` tag allows for ROS name remapping of a ` <node> ` instance.\n\n#####  Examples\n\n    \n    \n    <node pkg=\"my_pkg\" exec=\"my_node\">\n      <remap from=\"chatter\" to=\"/my_chatter\"/>\n      <remap from=\"*/stuff\" to=\"private_\\1/stuff\"/>\n    </node>\n    \n\n####  ` <env> ` Tag\n\n#####  Description\n\nThe ` <env> ` tag allows for modifying an OS process environment. It can be\nused nested in ` node ` or ` executable ` tags. It doesn\u2019t allow conditional\nexecution.\n\n#####  Examples\n\n    \n    \n    <node pkg=\"my_pkg\" exec=\"my_node\">\n      <env name=\"RMW_IMPLEMENTATION\" value=\"rmw_fastrtps_cpp\"/>\n    </node>\n    \n    <executable cmd=\"ls\" cwd=\"/var/log\">\n      <env name=\"LD_LIBRARY\" value=\"/lib/some.so\"/>\n    </executable>\n    \n\n####  ` <set_env> ` Tag\n\n#####  Description\n\nThe ` <set_env> ` tag allows for modifying an OS process environment. It can\nbe used nested in ` launch ` or ` group ` tags. It allows conditional\nexecution.\n\n#####  Examples\n\n    \n    \n    <group>\n      <set_env name=\"RMW_IMPLEMENTATION\" value=\"rmw_fastrtps_cpp\"/>\n    </group>\n    \n\n####  ` <unset_env> ` Tag\n\n#####  Description\n\nThe ` <unset_env> ` tag allows for deleting an OS process environment\nvariable. It can be used nested in ` launch ` or ` group ` tags. It allows\nconditional execution.\n\n#####  Examples\n\n    \n    \n    <group>\n      <unset_env name=\"MY_ENV_VAR\"/>\n    </group>\n    \n\n##  Dynamic Configuration\n\n###  Substitution Syntax\n\nAll substitutions are enclosed by ` $(...) ` .\n\n###  Built-in Substitutions\n\n` $(find-pkg-prefix <pkg-name>) `\n\n     Substituted by the install prefix path of the given package. Forward and backwards slashes will be resolved to the local filesystem convention. Substitution will fail if the package cannot be found. \n` $(find-pkg-share <pkg-name>) `\n\n     Substituted by the share directory path of the given package. The share directory includes the package\u2019s name, e.g. ` <prefix>/share/<pkg-name> ` . Forward and backwards slashes will be resolved to the local filesystem convention. Substitution will fail if the package cannot be found. \n` $(find-exec <exec-name>) `\n\n     Substituted by the path to the executable in the local filesystem. Executables are looked up in the PATH environment variable. Forward and backwards slashes will be resolved to the local filesystem convention. Substitution will fail if the executable cannot be found. \n` $(exec-in-package <exec-name> <package-name>) `\n\n     Substituted by the path to the executable in the local filesystem. Executables are looked up in the ` lib ` directory of the package. Substitution will fail if the executable cannot be found. \n` $(var <name>) `\n\n     Substituted by the value of the launch configuration variable. Substitution will fail if the named argument does not exist. \n` $(env <env-var> [default-value]) `\n\n     Substituted by the value of the given environment variable Substitution will fail if the variable is not set, unless a default value is provided. \n` $(eval <python-expression>) `\n\n     Substituted by the evaluated python expression. Substitution will fail if python fails to evaluate the expression. \n` $(dirname) `\n\n     Substituted by the current launch file directory name. Substitution will always succeed. \n\n####  User-defined Substitutions\n\nTBD\n\n[ View Source ](https://github.com/ros2/design/blob/gh-\npages/articles/151_roslaunch_xml.md) [ Edit in Github\n](https://github.com/ros2/design/edit/gh-pages/articles/151_roslaunch_xml.md)\n\nPull Requests\n\n  * Open \n  * Closed \n\n[ Please Login to View Pull Requests\n](https://github.com/login/oauth/authorize?client_id=efa6dd8eae9106381720)\n\n[ Please Login to View Pull Requests\n](https://github.com/login/oauth/authorize?client_id=efa6dd8eae9106381720)\n\nContributors\n\n[ Please Login to View Contributors\n](https://github.com/login/oauth/authorize?client_id=efa6dd8eae9106381720)\n\n* * *\n\n\u00a9 Open Source Robotics Foundation, Inc.\n\nExcept where otherwise noted, these design documents are licensed under [\nCreative Commons Attribution 3.0\n](http://creativecommons.org/licenses/by/3.0/) .\n\n"
  },
  {
    "id": "ros2cpp/23841.txt",
    "content": "[ The Construct ROS Community ](/)\n\n#  [ Unit 5 - Exercise 5.22.1: Cannot build after setup all the exercises\n](/t/unit-5-exercise-5-22-1-cannot-build-after-setup-all-the-exercises/23841)\n\n[ Course Support  ](/c/course-support/ros2-control/69) [ ROS2 Control\nFramework  ](/c/course-support/ros2-control/69)\n\n[ error ](https://get-help.theconstruct.ai/tag/error) , [ howto ](https://get-\nhelp.theconstruct.ai/tag/howto)\n\n[ PhongNguyen  ](https://get-help.theconstruct.ai/u/PhongNguyen) April 17,\n2023, 11:17pm  1\n\nI have gone through and set up all the Exercises as guidance:  \nHere is my **dynamixel_hardware_interface.cpp** after all the exercises:\n\n    \n    \n    #include <algorithm>\n    #include <array>\n    #include <string>\n    #include <limits>\n    #include <vector>\n    \n    #include \"dynamixel_hardware_interface/dynamixel_hardware_interface.hpp\"\n    #include \"hardware_interface/types/hardware_interface_return_values.hpp\"\n    #include \"hardware_interface/types/hardware_interface_type_values.hpp\"\n    #include \"rclcpp/rclcpp.hpp\"\n    \n    namespace dynamixel_hardware\n    {\n    constexpr const char * kDynamixelHardware = \"DynamixelHardware\";\n    constexpr uint8_t kGoalPositionIndex = 0;\n    constexpr uint8_t kGoalVelocityIndex = 1;\n    constexpr uint8_t kPresentPositionVelocityCurrentIndex = 0;\n    constexpr const char * kGoalPositionItem = \"Goal_Position\";\n    constexpr const char * kGoalVelocityItem = \"Goal_Velocity\";\n    constexpr const char * kMovingSpeedItem = \"Moving_Speed\";\n    constexpr const char * kPresentPositionItem = \"Present_Position\";\n    constexpr const char * kPresentVelocityItem = \"Present_Velocity\";\n    constexpr const char * kPresentSpeedItem = \"Present_Speed\";\n    constexpr const char * kPresentCurrentItem = \"Present_Current\";\n    constexpr const char * kPresentLoadItem = \"Present_Load\";\n    \n    CallbackReturn DynamixelHardware::on_init(const hardware_interface::HardwareInfo & info)\n    {\n      RCLCPP_DEBUG(rclcpp::get_logger(kDynamixelHardware), \"configure\");\n      if (hardware_interface::SystemInterface::on_init(info) != CallbackReturn::SUCCESS)\n      {\n        return CallbackReturn::ERROR;\n      }\n    \n      joints_.resize(info_.joints.size(), Joint());\n      joint_ids_.resize(info_.joints.size(), 0);\n    \n      for (uint i = 0; i < info_.joints.size(); i++) {\n        joint_ids_[i] = std::stoi(info_.joints[i].parameters.at(\"id\"));\n        joints_[i].state.position = std::numeric_limits<double>::quiet_NaN();\n        joints_[i].state.velocity = std::numeric_limits<double>::quiet_NaN();\n        joints_[i].state.effort = std::numeric_limits<double>::quiet_NaN();\n        joints_[i].command.position = std::numeric_limits<double>::quiet_NaN();\n        joints_[i].command.velocity = std::numeric_limits<double>::quiet_NaN();\n        joints_[i].command.effort = std::numeric_limits<double>::quiet_NaN();\n        RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"joint_id %d: %d\", i, joint_ids_[i]);\n      }\n    \n      if (\n        info_.hardware_parameters.find(\"use_dummy\") != info_.hardware_parameters.end() &&\n        info_.hardware_parameters.at(\"use_dummy\") == \"true\") {\n        use_dummy_ = true;\n        RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"dummy mode\");\n        return CallbackReturn::SUCCESS;\n      }\n    \n      auto usb_port = info_.hardware_parameters.at(\"usb_port\");\n      auto baud_rate = std::stoi(info_.hardware_parameters.at(\"baud_rate\"));\n      const char * log = nullptr;\n    \n      RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"usb_port: %s\", usb_port.c_str());\n      RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"baud_rate: %d\", baud_rate);\n    \n      if (!dynamixel_workbench_.init(usb_port.c_str(), baud_rate, &log)) {\n        RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n        return CallbackReturn::ERROR;\n      }\n    \n      for (uint i = 0; i < info_.joints.size(); ++i) {\n        uint16_t model_number = 0;\n        if (!dynamixel_workbench_.ping(joint_ids_[i], &model_number, &log)) {\n          RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n          return CallbackReturn::ERROR;\n        }\n      }\n    \n      enable_torque(false);\n      set_control_mode(ControlMode::Position, true);\n      enable_torque(true);\n    \n      const ControlItem * goal_position =\n        dynamixel_workbench_.getItemInfo(joint_ids_[0], kGoalPositionItem);\n      if (goal_position == nullptr) {\n        return CallbackReturn::ERROR;\n      }\n    \n      const ControlItem * goal_velocity =\n        dynamixel_workbench_.getItemInfo(joint_ids_[0], kGoalVelocityItem);\n      if (goal_velocity == nullptr) {\n        goal_velocity = dynamixel_workbench_.getItemInfo(joint_ids_[0], kMovingSpeedItem);\n      }\n      if (goal_velocity == nullptr) {\n        return CallbackReturn::ERROR;\n      }\n    \n      const ControlItem * present_position =\n        dynamixel_workbench_.getItemInfo(joint_ids_[0], kPresentPositionItem);\n      if (present_position == nullptr) {\n        return CallbackReturn::ERROR;\n      }\n    \n      const ControlItem * present_velocity =\n        dynamixel_workbench_.getItemInfo(joint_ids_[0], kPresentVelocityItem);\n      if (present_velocity == nullptr) {\n        present_velocity = dynamixel_workbench_.getItemInfo(joint_ids_[0], kPresentSpeedItem);\n      }\n      if (present_velocity == nullptr) {\n        return CallbackReturn::ERROR;\n      }\n    \n      const ControlItem * present_current =\n        dynamixel_workbench_.getItemInfo(joint_ids_[0], kPresentCurrentItem);\n      if (present_current == nullptr) {\n        present_current = dynamixel_workbench_.getItemInfo(joint_ids_[0], kPresentLoadItem);\n      }\n      if (present_current == nullptr) {\n        return CallbackReturn::ERROR;\n      }\n    \n      control_items_[kGoalPositionItem] = goal_position;\n      control_items_[kGoalVelocityItem] = goal_velocity;\n      control_items_[kPresentPositionItem] = present_position;\n      control_items_[kPresentVelocityItem] = present_velocity;\n      control_items_[kPresentCurrentItem] = present_current;\n    \n      if (!dynamixel_workbench_.addSyncWriteHandler(\n            control_items_[kGoalPositionItem]->address, control_items_[kGoalPositionItem]->data_length,\n            &log)) {\n        RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n        return CallbackReturn::ERROR;\n      }\n    \n      if (!dynamixel_workbench_.addSyncWriteHandler(\n            control_items_[kGoalVelocityItem]->address, control_items_[kGoalVelocityItem]->data_length,\n            &log)) {\n        RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n        return CallbackReturn::ERROR;\n      }\n    \n      uint16_t start_address = std::min(\n        control_items_[kPresentPositionItem]->address, control_items_[kPresentCurrentItem]->address);\n      uint16_t read_length = control_items_[kPresentPositionItem]->data_length +\n                             control_items_[kPresentVelocityItem]->data_length +\n                             control_items_[kPresentCurrentItem]->data_length + 2;\n      if (!dynamixel_workbench_.addSyncReadHandler(start_address, read_length, &log)) {\n        RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n        return CallbackReturn::ERROR;\n      }\n    \n      return CallbackReturn::SUCCESS;\n    }\n    \n    std::vector<hardware_interface::StateInterface> DynamixelHardware::export_state_interfaces()\n    {\n      RCLCPP_DEBUG(rclcpp::get_logger(kDynamixelHardware), \"export_state_interfaces\");\n      std::vector<hardware_interface::StateInterface> state_interfaces;\n      for (uint i = 0; i < info_.joints.size(); i++) {\n        state_interfaces.emplace_back(hardware_interface::StateInterface(\n          info_.joints[i].name, hardware_interface::HW_IF_POSITION, &joints_[i].state.position));\n        state_interfaces.emplace_back(hardware_interface::StateInterface(\n          info_.joints[i].name, hardware_interface::HW_IF_VELOCITY, &joints_[i].state.velocity));\n        state_interfaces.emplace_back(hardware_interface::StateInterface(\n          info_.joints[i].name, hardware_interface::HW_IF_EFFORT, &joints_[i].state.effort));\n      }\n    \n      return state_interfaces;\n    }\n    \n    std::vector<hardware_interface::CommandInterface> DynamixelHardware::export_command_interfaces()\n    {\n      RCLCPP_DEBUG(rclcpp::get_logger(kDynamixelHardware), \"export_command_interfaces\");\n      std::vector<hardware_interface::CommandInterface> command_interfaces;\n      for (uint i = 0; i < info_.joints.size(); i++) {\n        command_interfaces.emplace_back(hardware_interface::CommandInterface(\n          info_.joints[i].name, hardware_interface::HW_IF_POSITION, &joints_[i].command.position));\n        command_interfaces.emplace_back(hardware_interface::CommandInterface(\n          info_.joints[i].name, hardware_interface::HW_IF_VELOCITY, &joints_[i].command.velocity));\n      }\n    \n      return command_interfaces;\n    }\n    \n    CallbackReturn DynamixelHardware::on_activate(const rclcpp_lifecycle::State & previous_state)\n    {\n      RCLCPP_DEBUG(rclcpp::get_logger(kDynamixelHardware), \"start\");\n      for (uint i = 0; i < joints_.size(); i++) {\n        if (use_dummy_ && std::isnan(joints_[i].state.position)) {\n          joints_[i].state.position = 0.0;\n          joints_[i].state.velocity = 0.0;\n          joints_[i].state.effort = 0.0;\n        }\n      }\n      read();\n      reset_command();\n      write();\n    \n      return CallbackReturn::SUCCESS;\n    }\n    \n    CallbackReturn DynamixelHardware::on_deactivate(const rclcpp_lifecycle::State & previous_state)\n    {\n      RCLCPP_DEBUG(rclcpp::get_logger(kDynamixelHardware), \"stop\");\n      return CallbackReturn::SUCCESS;\n    }\n    \n    return_type DynamixelHardware::read()\n    {\n      if (use_dummy_) {\n        return return_type::OK;\n      }\n    \n      std::vector<uint8_t> ids(info_.joints.size(), 0);\n      std::vector<int32_t> positions(info_.joints.size(), 0);\n      std::vector<int32_t> velocities(info_.joints.size(), 0);\n      std::vector<int32_t> currents(info_.joints.size(), 0);\n    \n      std::copy(joint_ids_.begin(), joint_ids_.end(), ids.begin());\n      const char * log = nullptr;\n    \n      if (!dynamixel_workbench_.syncRead(\n            kPresentPositionVelocityCurrentIndex, ids.data(), ids.size(), &log)) {\n        RCLCPP_ERROR(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n      }\n    \n      if (!dynamixel_workbench_.getSyncReadData(\n            kPresentPositionVelocityCurrentIndex, ids.data(), ids.size(),\n            control_items_[kPresentCurrentItem]->address,\n            control_items_[kPresentCurrentItem]->data_length, currents.data(), &log)) {\n        RCLCPP_ERROR(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n      }\n    \n      if (!dynamixel_workbench_.getSyncReadData(\n            kPresentPositionVelocityCurrentIndex, ids.data(), ids.size(),\n            control_items_[kPresentVelocityItem]->address,\n            control_items_[kPresentVelocityItem]->data_length, velocities.data(), &log)) {\n        RCLCPP_ERROR(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n      }\n    \n      if (!dynamixel_workbench_.getSyncReadData(\n            kPresentPositionVelocityCurrentIndex, ids.data(), ids.size(),\n            control_items_[kPresentPositionItem]->address,\n            control_items_[kPresentPositionItem]->data_length, positions.data(), &log)) {\n        RCLCPP_ERROR(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n      }\n    \n      for (uint i = 0; i < ids.size(); i++) {\n        joints_[i].state.position = dynamixel_workbench_.convertValue2Radian(ids[i], positions[i]);\n        joints_[i].state.velocity = dynamixel_workbench_.convertValue2Velocity(ids[i], velocities[i]);\n        joints_[i].state.effort = dynamixel_workbench_.convertValue2Current(currents[i]);\n      }\n    \n      return return_type::OK;\n    }\n    \n    return_type DynamixelHardware::write()\n    {\n      if (use_dummy_) {\n        for (auto & joint : joints_) {\n          joint.state.position = joint.command.position;\n        }\n    \n        return return_type::OK;\n      }\n    \n      std::vector<uint8_t> ids(info_.joints.size(), 0);\n      std::vector<int32_t> commands(info_.joints.size(), 0);\n    \n      std::copy(joint_ids_.begin(), joint_ids_.end(), ids.begin());\n      const char * log = nullptr;\n    \n      if (std::any_of(\n            joints_.cbegin(), joints_.cend(), [](auto j) { return j.command.velocity != 0.0; })) {\n        // Velocity control\n        set_control_mode(ControlMode::Velocity);\n        for (uint i = 0; i < ids.size(); i++) {\n          commands[i] = dynamixel_workbench_.convertVelocity2Value(\n            ids[i], static_cast<float>(joints_[i].command.velocity));\n        }\n        if (!dynamixel_workbench_.syncWrite(\n              kGoalVelocityIndex, ids.data(), ids.size(), commands.data(), 1, &log)) {\n          RCLCPP_ERROR(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n        }\n        return return_type::OK;\n      } else if (std::any_of(\n                   joints_.cbegin(), joints_.cend(), [](auto j) { return j.command.effort != 0.0; })) {\n        // Effort control\n        RCLCPP_ERROR(rclcpp::get_logger(kDynamixelHardware), \"Effort control is not implemented\");\n        return return_type::ERROR;\n      }\n    \n      // Position control\n      set_control_mode(ControlMode::Position);\n      for (uint i = 0; i < ids.size(); i++) {\n        commands[i] = dynamixel_workbench_.convertRadian2Value(\n          ids[i], static_cast<float>(joints_[i].command.position));\n      }\n      if (!dynamixel_workbench_.syncWrite(\n            kGoalPositionIndex, ids.data(), ids.size(), commands.data(), 1, &log)) {\n        RCLCPP_ERROR(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n      }\n    \n      return return_type::OK;\n    }\n    \n    return_type DynamixelHardware::enable_torque(const bool enabled)\n    {\n      const char * log = nullptr;\n    \n      if (enabled && !torque_enabled_) {\n        for (uint i = 0; i < info_.joints.size(); ++i) {\n          if (!dynamixel_workbench_.torqueOn(joint_ids_[i], &log)) {\n            RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n            return return_type::ERROR;\n          }\n        }\n        reset_command();\n        RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"Torque enabled\");\n      } else if (!enabled && torque_enabled_) {\n        for (uint i = 0; i < info_.joints.size(); ++i) {\n          if (!dynamixel_workbench_.torqueOff(joint_ids_[i], &log)) {\n            RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n            return return_type::ERROR;\n          }\n        }\n        RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"Torque disabled\");\n      }\n    \n      torque_enabled_ = enabled;\n      return return_type::OK;\n    }\n    \n    return_type DynamixelHardware::set_control_mode(const ControlMode & mode, const bool force_set)\n    {\n      const char * log = nullptr;\n    \n      if (mode == ControlMode::Velocity && (force_set || control_mode_ != ControlMode::Velocity)) {\n        bool torque_enabled = torque_enabled_;\n        if (torque_enabled) {\n          enable_torque(false);\n        }\n    \n        for (uint i = 0; i < joint_ids_.size(); ++i) {\n          if (!dynamixel_workbench_.setVelocityControlMode(joint_ids_[i], &log)) {\n            RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n            return return_type::ERROR;\n          }\n        }\n        RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"Velocity control\");\n        control_mode_ = ControlMode::Velocity;\n    \n        if (torque_enabled) {\n          enable_torque(true);\n        }\n      } else if (\n        mode == ControlMode::Position && (force_set || control_mode_ != ControlMode::Position)) {\n        bool torque_enabled = torque_enabled_;\n        if (torque_enabled) {\n          enable_torque(false);\n        }\n    \n        for (uint i = 0; i < joint_ids_.size(); ++i) {\n          if (!dynamixel_workbench_.setPositionControlMode(joint_ids_[i], &log)) {\n            RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n            return return_type::ERROR;\n          }\n        }\n        RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"Position control\");\n        control_mode_ = ControlMode::Position;\n    \n        if (torque_enabled) {\n          enable_torque(true);\n        }\n      } else if (control_mode_ != ControlMode::Velocity && control_mode_ != ControlMode::Position) {\n        RCLCPP_FATAL(\n          rclcpp::get_logger(kDynamixelHardware), \"Only position/velocity control are implemented\");\n        return return_type::ERROR;\n      }\n    \n      return return_type::OK;\n    }\n    \n    return_type DynamixelHardware::reset_command()\n    {\n      for (uint i = 0; i < joints_.size(); i++) {\n        joints_[i].command.position = joints_[i].state.position;\n        joints_[i].command.velocity = 0.0;\n        joints_[i].command.effort = 0.0;\n      }\n    \n      return return_type::OK;\n    }\n    \n    }  // namespace dynamixel_hardware\n    \n    #include \"pluginlib/class_list_macros.hpp\"\n    \n    PLUGINLIB_EXPORT_CLASS(dynamixel_hardware::DynamixelHardware, hardware_interface::SystemInterface)\n    \n    \n\nAnd below is the error from the terminal which make the package compiled\nunsuccessfully:\n\n    \n    \n    user:~/ros2_ws$ colcon build --symlink-install\n    [0.339s] WARNING:colcon.colcon_core.package_identification:Failed to parse ROS package manifest in 'src/dynamixel_hardware_interface': Error(s) in package 'src/dynamixel_hardware_interface/package.xml':\n    Invalid email \"to-do\" for person \"user\"\n    [0.469s] WARNING:colcon.colcon_core.verb:Some selected packages are already built in one or more underlay workspaces:\n            'diffbot_description' is in: /home/user/ros2_ws/install/diffbot_description\n            'diffbot_sim' is in: /home/user/ros2_ws/install/diffbot_sim\n            'dynamixel_sdk' is in: /home/user/ros2_ws/install/dynamixel_sdk\n            'dynamixel_sdk_custom_interfaces' is in: /home/user/ros2_ws/install/dynamixel_sdk_custom_interfaces\n            'joint_trajectory_publisher' is in: /home/user/ros2_ws/install/joint_trajectory_publisher\n            'my_robot_bringup' is in: /home/user/ros2_ws/install/my_robot_bringup\n            'my_robot_hardware_interface' is in: /home/user/ros2_ws/install/my_robot_hardware_interface\n            'rrbot_unit2' is in: /home/user/ros2_ws/install/rrbot_unit2\n            'rrbot_unit3' is in: /home/user/ros2_ws/install/rrbot_unit3\n            'rrbot_unit4' is in: /home/user/ros2_ws/install/rrbot_unit4\n            'rrbot_unit5' is in: /home/user/ros2_ws/install/rrbot_unit5\n            'solo_description' is in: /home/user/ros2_ws/install/solo_description\n            'spawn_robot' is in: /home/user/ros2_ws/install/spawn_robot\n            'spawn_solo' is in: /home/user/ros2_ws/install/spawn_solo\n            'dynamixel_sdk_examples' is in: /home/user/ros2_ws/install/dynamixel_sdk_examples\n            'dynamixel_workbench_toolbox' is in: /home/user/ros2_ws/install/dynamixel_workbench_toolbox\n            'dynamixel_hardware_interface' is in: /home/user/ros2_ws/install/dynamixel_hardware_interface\n            'dynamixel_workbench' is in: /home/user/ros2_ws/install/dynamixel_workbench\n    If a package in a merged underlay workspace is overridden and it installs headers, then all packages in the overlay must sort their include directories by workspace order. Failure to do so may result in build failures or undefined behavior at run time.\n    If the overridden package is used by another package in any underlay, then the overriding package in the overlay must be API and ABI compatible or undefined behavior at run time may occur.\n    \n    If you understand the risks and want to override a package anyways, add the following to the command line:\n            --allow-overriding diffbot_description diffbot_sim dynamixel_hardware_interface dynamixel_sdk dynamixel_sdk_custom_interfaces dynamixel_sdk_examples dynamixel_workbench dynamixel_workbench_toolbox joint_trajectory_publisher my_robot_bringup my_robot_hardware_interface rrbot_unit2 rrbot_unit3 rrbot_unit4 rrbot_unit5 solo_description spawn_robot spawn_solo\n    \n    This may be promoted to an error in a future release of colcon-core.\n    Starting >>> dynamixel_sdk\n    Starting >>> dynamixel_sdk_custom_interfaces\n    Starting >>> diffbot_description\n    Starting >>> diffbot_sim\n    Starting >>> joint_trajectory_publisher\n    Starting >>> my_robot_bringup\n    Starting >>> my_robot_hardware_interface\n    Starting >>> rrbot_unit2\n    Finished <<< diffbot_description [1.70s]\n    Starting >>> rrbot_unit3\n    Finished <<< my_robot_bringup [1.82s]\n    Finished <<< diffbot_sim [1.87s]\n    Starting >>> rrbot_unit4\n    Starting >>> rrbot_unit5\n    Finished <<< rrbot_unit2 [1.92s]\n    Starting >>> solo_description\n    Finished <<< dynamixel_sdk [2.30s]\n    Finished <<< my_robot_hardware_interface [2.20s]\n    Starting >>> dynamixel_workbench_toolbox\n    Starting >>> spawn_robot\n    Finished <<< rrbot_unit3 [1.50s]\n    Starting >>> spawn_solo\n    Finished <<< rrbot_unit5 [1.45s]\n    Finished <<< spawn_robot [1.13s]\n    Finished <<< solo_description [1.42s]\n    Finished <<< rrbot_unit4 [1.61s]\n    Finished <<< dynamixel_workbench_toolbox [1.52s]\n    Starting >>> dynamixel_hardware_interface\n    Starting >>> dynamixel_workbench\n    Finished <<< spawn_solo [0.89s]\n    Finished <<< dynamixel_sdk_custom_interfaces [4.33s]\n    Starting >>> dynamixel_sdk_examples\n    Finished <<< dynamixel_workbench [0.66s]\n    Finished <<< joint_trajectory_publisher [4.78s]\n    Finished <<< dynamixel_sdk_examples [0.71s]\n    --- stderr: dynamixel_hardware_interface\n    Error parsing '/home/user/ros2_ws/src/dynamixel_hardware_interface/package.xml':\n    Traceback (most recent call last):\n      File \"/opt/ros/galactic/share/ament_cmake_core/cmake/core/package_xml_2_cmake.py\", line 151, in <module>\n        main()\n      File \"/opt/ros/galactic/share/ament_cmake_core/cmake/core/package_xml_2_cmake.py\", line 54, in main\n        raise e\n      File \"/opt/ros/galactic/share/ament_cmake_core/cmake/core/package_xml_2_cmake.py\", line 50, in main\n        package = parse_package_string(\n      File \"/usr/lib/python3/dist-packages/catkin_pkg/package.py\", line 774, in parse_package_string\n        pkg.validate(warnings=warnings)\n      File \"/usr/lib/python3/dist-packages/catkin_pkg/package.py\", line 317, in validate\n        raise InvalidPackage('\\n'.join(errors), self.filename)\n    catkin_pkg.package.InvalidPackage: Error(s) in package '/home/user/ros2_ws/src/dynamixel_hardware_interface/package.xml':\n    Invalid email \"to-do\" for person \"user\"\n    CMake Error at /opt/ros/galactic/share/ament_cmake_core/cmake/core/ament_package_xml.cmake:94 (message):\n      execute_process(/usr/bin/python3\n      /opt/ros/galactic/share/ament_cmake_core/cmake/core/package_xml_2_cmake.py\n      /home/user/ros2_ws/src/dynamixel_hardware_interface/package.xml\n      /home/user/ros2_ws/build/dynamixel_hardware_interface/ament_cmake_core/package.cmake)\n      returned error code 1\n    Call Stack (most recent call first):\n      /opt/ros/galactic/share/ament_cmake_core/cmake/core/ament_package_xml.cmake:49 (_ament_package_xml)\n      /opt/ros/galactic/share/ament_lint_auto/cmake/ament_lint_auto_find_test_dependencies.cmake:31 (ament_package_xml)\n      CMakeLists.txt:71 (ament_lint_auto_find_test_dependencies)\n    \n    \n    make: *** [Makefile:222: cmake_check_build_system] Error 1\n    ---\n    Failed   <<< dynamixel_hardware_interface [2.53s, exited with code 2]\n    \n    Summary: 17 packages finished [6.67s]\n      1 package failed: dynamixel_hardware_interface\n      1 package had stderr output: dynamixel_hardware_interface\n    user:~/ros2_ws$\n    \n\n[ girishkumar.kannan  ](https://get-help.theconstruct.ai/u/girishkumar.kannan)\nApril 18, 2023, 5:30am  2\n\nHi [ @PhongNguyen ](/u/phongnguyen) ,\n\nI guess there is an issue with your ` package.xml ` file.  \nCould you please post the file contents of both ` package.xml ` and `\nCMakeLists.txt ` files as a code block?\n\nRegards,  \nGirish\n\n[ PhongNguyen  ](https://get-help.theconstruct.ai/u/PhongNguyen) April 18,\n2023, 2:50pm  3\n\nHi [ @girishkumar.kannan ](/u/girishkumar.kannan)\n\nBelow is my ` package.xml ` code:\n\n    \n    \n    <?xml version=\"1.0\"?>\n    <?xml-model href=\"http://download.ros.org/schema/package_format3.xsd\" schematypens=\"http://www.w3.org/2001/XMLSchema\"?>\n    <package format=\"3\">\n      <name>dynamixel_hardware_interface</name>\n      <version>0.0.0</version>\n      <description>TODO: Package description</description>\n      <maintainer email=\"to-do\">user</maintainer>\n      <license>TODO: License declaration</license>\n    \n      <buildtool_depend>ament_cmake</buildtool_depend>\n    \n      <depend>rclcpp</depend>\n      <depend>hardware_interface</depend>\n      <depend>pluginlib</depend>\n      <depend>dynamixel_workbench_toolbox</depend>\n    \n      <test_depend>ament_lint_auto</test_depend>\n      <test_depend>ament_lint_common</test_depend>\n    \n      <export>\n        <build_type>ament_cmake</build_type>\n      </export>\n    </package>\n    \n    \n\nBelow is my ` CMakeList.txt ` code\n\n    \n    \n    cmake_minimum_required(VERSION 3.5)\n    project(dynamixel_hardware_interface)\n    \n    # Default to C99\n    if(NOT CMAKE_C_STANDARD)\n      set(CMAKE_C_STANDARD 99)\n    endif()\n    \n    # Default to C++14\n    if(NOT CMAKE_CXX_STANDARD)\n      set(CMAKE_CXX_STANDARD 14)\n    endif()\n    \n    if(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\n      add_compile_options(-Wall -Wextra -Wpedantic)\n    endif()\n    \n    # find dependencies\n    find_package(ament_cmake REQUIRED)\n    find_package(rclcpp REQUIRED)\n    find_package(hardware_interface REQUIRED)\n    find_package(pluginlib REQUIRED)\n    find_package(dynamixel_workbench_toolbox REQUIRED)\n    \n    add_library(\n      ${PROJECT_NAME}\n      SHARED\n      src/dynamixel_hardware_interface.cpp\n    )\n    target_include_directories(\n      ${PROJECT_NAME}\n      PRIVATE\n      include\n    )\n    ament_target_dependencies(\n      ${PROJECT_NAME}\n      rclcpp\n      hardware_interface\n      pluginlib\n      dynamixel_workbench_toolbox\n      )\n    \n    pluginlib_export_plugin_description_file(hardware_interface dynamixel_hardware.xml)\n    \n    # INSTALL\n    install(\n      TARGETS ${PROJECT_NAME}\n      DESTINATION lib\n    )\n    install(\n      DIRECTORY include/\n      DESTINATION include\n    )\n    \n    install(\n      DIRECTORY\n        launch\n        config\n      DESTINATION\n        share/${PROJECT_NAME}/\n    )\n    \n    if(BUILD_TESTING)\n      find_package(ament_lint_auto REQUIRED)\n      # the following line skips the linter which checks for copyrights\n      # uncomment the line when a copyright and license is not present in all source files\n      #set(ament_cmake_copyright_FOUND TRUE)\n      # the following line skips cpplint (only works in a git repo)\n      # uncomment the line when this package is not in a git repo\n      #set(ament_cmake_cpplint_FOUND TRUE)\n      ament_lint_auto_find_test_dependencies()\n    endif()\n    \n    ## EXPORTS\n    ament_export_include_directories(\n      include\n    )\n    ament_export_libraries(\n      ${PROJECT_NAME}\n    )\n    ament_export_dependencies(\n      rclcpp\n      hardware_interface\n      pluginlib\n      dynamixel_workbench_toolbox\n    )\n    \n    ament_package()\n    \n    \n\nI tried to update the ` package.xml ` content from ` email=\"to-do\" ` to `\nemail=\"user@todo.todo\" ` similar to this thread: [ Unit 4\nmy_robot_hardware_interface.hpp error - Course Support / ROS2 Control\nFramework - The Construct ROS Community (robotigniteacademy.com)\n](https://get-help.robotigniteacademy.com/t/unit-4-my-robot-hardware-\ninterface-hpp-error/23787)  \nAnd it worked with warnings.  \nMany thanks to [ @zach ](/u/zach)\n\nI don\u2019t know if this ` email ` thing is the case and what is the root cause of\nthis?\n\n[ girishkumar.kannan  ](https://get-help.theconstruct.ai/u/girishkumar.kannan)\nApril 18, 2023, 3:26pm  4\n\nHi [ @PhongNguyen ](/u/phongnguyen) ,\n\nChange the following line indicated below in ` package.xml ` :\n\n![](https://get-\nhelp.robotigniteacademy.com/letter_avatar_proxy/v4/letter/p/3e96dc/48.png)\nPhongNguyen:\n\n> ` <maintainer email=\"to-do\">user</maintainer> `\n\nMust be changed to:  \n` <maintainer email=\"user@todo.todo\">user</maintainer> ` .\n\nThat is the only change that you need.\n\n![](https://get-\nhelp.robotigniteacademy.com/letter_avatar_proxy/v4/letter/p/3e96dc/48.png)\nPhongNguyen:\n\n> I don\u2019t know if this ` email ` thing is the case and what is the root cause\n> of this?\n\nYes, this is the cause of the problem. Whoever made the package made it long\nback.  \nThere must have been recent updates to ` package.xml ` reading code that\nchecks for email to be a valid format like ` <...>@<...>.<...> ` .\n\nThis should fix your problem.\n\nRegards,  \nGirish\n\n1 Like\n\n[ PhongNguyen  ](https://get-help.theconstruct.ai/u/PhongNguyen) April 18,\n2023, 8:19pm  5\n\nThank you so much [ @girishkumar.kannan ](/u/girishkumar.kannan)\n\n[ system  ](https://get-help.theconstruct.ai/u/system) Closed  April 25, 2023,\n8:19pm  6\n\nThis topic was automatically closed 7 days after the last reply. New replies\nare no longer allowed.\n\n  * [ Home ](/)\n  * [ Categories ](/categories)\n  * [ FAQ/Guidelines ](/guidelines)\n  * [ Terms of Service ](http://www.theconstructsim.com/terms_and_conditions/)\n  * [ Privacy Policy ](http://www.theconstructsim.com/privacy_policy/)\n\nPowered by [ Discourse ](https://www.discourse.org) , best viewed with\nJavaScript enabled\n\n"
  },
  {
    "id": "ros_file_convert/ros1vsros2whatarethe.txt",
    "content": "[ ![](https://assets-global.website-\nfiles.com/6374d6bce94f940eedba934e/65fda299604c5ad64c01b131_model-prime-\nlogo.svg) ](/)\n\nProduct\n\nProduct\n\n![](https://assets-global.website-\nfiles.com/6374d6bce94f940eedba934e/65fe6bf941e900427da7d723_grey%20arrow.svg)\n\n[ Core Services  Search, Metadata, Ingest.  ](https://model-\nprime.webflow.io/services#core-services) [ Analytics & BI  Performance and\nBusiness Analytics.  ](https://model-prime.webflow.io/services#analytics-bi) [\n**Event Autotagging** Understand your logs at scale.  ](https://model-\nprime.webflow.io/services#auto-event-tagging-actions) [ API  Build custom\napplications.  ](https://model-prime.webflow.io/services#api) Data Retention\nKeep the data that matters.  COMING SOON\n\nDocumentation\n\nProduct\n\n![](https://assets-global.website-\nfiles.com/6374d6bce94f940eedba934e/65fe6bf941e900427da7d723_grey%20arrow.svg)\n\nWhitepaper  Lorem ipsum dolor amet.  [ Case Studies  Lorem ipsum dolor amet.\n](/case-study)\n\n[ Blog ](/blog) [ Careers ](/careers) Schedule a demo\n\n[ Schedule a demo ]()\n\nSchedule a demo\n\n[ ](https://twitter.com/ModelDashPrime) [\n](https://www.linkedin.com/company/modelprime/about/)\n\n[ Schedule a demo ]()\n\nSchedule a demo\n\n![](https://assets-global.website-\nfiles.com/6374d6bde94f94030dba937c/65f93fd7ace7cccc85700018_ros-1-vs-\nros-2-what-are-the-biggest-differences.jpg)\n\nArun Venkatadri\n\nMarch 28, 2023\n\n.\n\n4 minutes\n\nread\n\n#  ROS 1 vs ROS 2 What are the Biggest Differences?\n\nIf you're a robotics org today and are thinking of migrating, or a startup\ntaking your first steps, we have a roundup of the biggest differences between\nROS 1 and ROS 2.\n\n![](https://assets-global.website-\nfiles.com/6374d6bde94f94030dba937c/642340726de059d158005f4f_DALL%C2%B7E%202023-02-22%2018.48.10%20-%20an%20older%20robot%20fighting%20a%20younger%20robot%20.png)\n\n##  ROS 1 vs ROS 2 The Major Differences\n\nMany robotics organizations face a decision regarding if or when they should\ntransition to ROS 2 from ROS 1. There isn\u00e2\u0080\u0099t a lot of content that discusses\nthe major differences between the two versions. You can reference the official\n[ ROS 2 design page on the topic;\n](http://design.ros2.org/articles/changes.html#:~:text=In%20ROS%201%20the%20developer,haven't%20been%20implemented%20yet.)\n\u00c2 however, we work to frame some of these differences in the context of what\nthey mean for you and your robotics organization below.\u00c2\n\n###  The ROS 1 vs ROS 2 Decision Horizon\n\nFor organizations deciding between ROS 1 and ROS 2 today, we recommend using\nROS 2. ROS 1 Noetic, the final ROS 1 distro\u00c2 is only officially supported\nthrough 2025 unless you\u00e2\u0080\u0099re willing to only rely on community support. The\nmigration process typically involves using both versions of ROS until you\u00e2\u0080\u0099ve\ncompletely migrated to ROS 2.\u00c2\n\n\u00e2\u0080\u008d **The differences between ROS 1 and ROS 2 fall into three main\ncategories:**\n\n  * Architecture \n  * Features\u00c2 \n  * Tooling/Ecosystem \n\n###  Architecture\n\n**Changes to the Middleware\u00c2 \u00c2**\n\nROS 1 uses the ROS Master-Slave Architecture and the XML-RPC middleware. ROS 2\nuses Data Distribution Service (DDS), which is designed to provide higher\nefficiency and reliability, low latency, and scalability, as well as\nconfigurable quality of service (QoS) parameters. XML-RPC is better for simple\nremote procedure calls, while DDS\u00e2\u0080\u0099s added complexity allows it to better\nsupport real-time systems. Because of its distributed nature, DDS also helps\nremove communications single-points-of-failure from ROS 2 systems.\u00c2\n\n\u00e2\u0080\u008d\n\n**Changes to the ROS API**\n\nROS 1 has two separate libraries - roscpp for C++ and rospy for Python - that\nare not at feature parity with each other. In contrast, ROS 2 has a base\nlibrary written in C - rcl (ROS client library) - with libraries built on top\nof it. This ensures that core functionality is available in different APIs\nsooner. This is one of the key reasons that ROS 2 is able to offer more\nlanguage support than just Python and C++, such as Java and C#.\u00c2\n\n\u00e2\u0080\u008d\n\n**Changes to the Data Format\u00c2**\n\nROS2 rosbags allow for more flexibility with regard to serialization as\ncompared to ROS 1, which uses its own serialization format. The biggest impact\nof changes to the rosbag format from ROS 1 to ROS 2 is potential\nincompatibility of ROS 1 bag tooling with ROS 2 rosbags and subsequent impacts\nto developer workflows.\n\n###  Features\n\n\u00e2\u0080\u008d\n\n**QoS**\n\nROS 2 allows for data flow configuration, affecting how data is sent and\nreceived. This includes settings for message reliability, deadline, and\npriority, which can ensure that critical messages are delivered on time.\u00c2\n\n\u00e2\u0080\u008d\n\n**Multi-Threaded Execution**\n\nROS 2 supports multiple nodes truly running in parallel, allowing it to\nleverage modern multi-core processors far better than ROS 1.\u00c2\n\n\u00e2\u0080\u008d **\u00e2\u0080\u008d**\n\n**Real-Time Processing**\n\nThe summation of the features above, along with the use of DDS, allows ROS 2\nto be superior at real-time processing, especially when deterministic, low-\nlatency communication is needed.\n\n###  Tooling/Ecosystem\n\n\u00e2\u0080\u008d\n\n**Tooling**\n\nThere are a couple notable changes to tooling between ROS 1 and ROS 2:\n\n  * [ Catkin ](http://wiki.ros.org/catkin) is gone, replaced with [ Ament ](https://docs.ros.org/en/foxy/Concepts/About-Build-System.html) as a build system \n  * [ Overlays ](https://docs.ros.org/en/foxy/Tutorials/Beginner-Client-Libraries/Creating-A-Workspace/Creating-A-Workspace.html) allow you to have a secondary workspace that doesn\u00e2\u0080\u0099t affect your primary workspace \u00e2\u0080\u0093 this is helpful when you want to experiment with new packages without affecting your base configuration (called an \u00e2\u0080\u009cunderlay\u00e2\u0080\u009d). \n\n\u00e2\u0080\u008d\n\n\u00e2\u0080\u008d **Ecosystem** \u00c2\n\nROS 2 is not backward compatible with ROS 1. Consequently, ROS 1 packages will\nlikely not work with ROS 2 and would require rework, and other software\nyou\u00e2\u0080\u0099re accustomed to using with ROS 1 may no longer work. While currently a\nmajor limitation, tools like [ ROSbridge\n](http://wiki.ros.org/rosbridge_suite) are enabling improvements.\n\nROS 1 was primarily built for Ubuntu. [ ROS 2 runs on MacOS, Windows, Ubuntu\n](https://www.ros.org/reps/rep-2000.html#targeted-platforms) , and other\noperating systems.\u00c2\n\n###  Recommendations\n\nTeams building from the ground up should start using ROS 2.\n\nFor organizations using ROS 1, it will not be feasible to stay on ROS 1\nindefinitely because official support ends in 2025. However, every\norganization using ROS 1 today has different considerations when determining\nwhen or how to migrate to ROS 2. Teams should work to understand the effort\nand staffing it would take to transition, and work out a timing to execute the\nplan in a manner that aligns with the organizational goals and product\ndevelopment cycle.\n\n\u00e2\u0080\u008d\n\n**Sources/Further Reading:** [ **\u00e2\u0080\u008d** ](https://wiki.ros.org/noetic)\n\n[ ROS 1 Wiki ](https://wiki.ros.org/noetic) (Noetic)\u00c2\n\n[ ROS 2 Wiki\u00c2 ](https://docs.ros.org/en/rolling/index.html) [ \u00e2\u0080\u008d\n](https://roboticsbackend.com/ros1-vs-ros2-practical-overview/)\n\n[ Robotics Back-End Article.\u00c2 ](https://roboticsbackend.com/ros1-vs-\nros2-practical-overview/) [ \u00e2\u0080\u008d ](https://medium.com/@oelmofty/ros2-how-is-it-\nbetter-than-ros1-881632e1979a)\n\n[ Omar Elmofty\u00e2\u0080\u0099s medium article\u00c2 ](https://medium.com/@oelmofty/ros2-how-is-\nit-better-than-ros1-881632e1979a)\n\n\u00e2\u0080\u008d\n\n##  Build your robots now.\n\n##  Never worry about your infra again.\n\nWe thought about robotics cloud infra - so you never have to.\n\nSchedule a demo\n\n[ ![](https://assets-global.website-\nfiles.com/6374d6bce94f940eedba934e/65fda299604c5ad64c01b131_model-prime-\nlogo.svg) ](/)\n\n#####  Reach us\n\n[ support@model-prime.com ](mailto:support@model-prime.com )\n\n[ ![](https://assets-global.website-\nfiles.com/6374d6bce94f940eedba934e/660a37354810c2bdac1bc267_x-logo.svg)\n](https://twitter.com/ModelDashPrime) [ ![](https://assets-global.website-\nfiles.com/6374d6bce94f940eedba934e/660a360e318bdc118b3d3645_linkedin-icon.svg)\n](https://www.linkedin.com/company/modelprime/)\n\n[ Product  ](/services) Docs  [ Careers  ](/careers) [ Blog  ](/blog)\n\n###  Accelerate your Robotics Development\n\nLearn more about Robotics Infra, and what we\u00e2\u0080\u0099re up to at Model-Prime.\n\nThank you! Your submission has been received!\n\nOops! Something went wrong while submitting the form.\n\n\u00c2\u00a9 2024 Model-Prime\n\n[ Privacy policy ](/privacy-policy)\n\n[ Cookie policy ](/cookies-policy)\n\n"
  },
  {
    "id": "ackermann/264.txt",
    "content": "Skip to content\n\nToggle navigation\n\n[ ](https://github.com/)\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fros-\ncontrols%2Fros2_controllers%2Fissues%2F264)\n\n  * Product \n\n    * [ Actions  Automate any workflow  ](/features/actions)\n    * [ Packages  Host and manage packages  ](/features/packages)\n    * [ Security  Find and fix vulnerabilities  ](/features/security)\n    * [ Codespaces  Instant dev environments  ](/features/codespaces)\n    * [ Copilot  Write better code with AI  ](/features/copilot)\n    * [ Code review  Manage code changes  ](/features/code-review)\n    * [ Issues  Plan and track work  ](/features/issues)\n    * [ Discussions  Collaborate outside of code  ](/features/discussions)\n\nExplore\n\n    * [ All features ](/features)\n    * [ Documentation  ](https://docs.github.com)\n    * [ GitHub Skills  ](https://skills.github.com/)\n    * [ Blog  ](https://github.blog)\n\n  * Solutions \n\nFor\n\n    * [ Enterprise ](/enterprise)\n    * [ Teams ](/team)\n    * [ Startups ](/enterprise/startups)\n    * [ Education  ](https://education.github.com)\n\nBy Solution\n\n    * [ CI/CD & Automation ](/solutions/ci-cd/)\n    * [ DevOps ](/solutions/devops/)\n    * [ DevSecOps  ](https://resources.github.com/devops/fundamentals/devsecops/)\n\nResources\n\n    * [ Learning Pathways  ](https://resources.github.com/learn/pathways/)\n    * [ White papers, Ebooks, Webinars  ](https://resources.github.com/)\n    * [ Customer Stories ](/customer-stories)\n    * [ Partners  ](https://partner.github.com/)\n\n  * Open Source \n\n    * [ GitHub Sponsors  Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project  GitHub community articles  ](/readme)\n\nRepositories\n\n    * [ Topics ](/topics)\n    * [ Trending ](/trending)\n    * [ Collections ](/collections)\n\n  * [ Pricing ](/pricing)\n\nSearch or jump to...\n\n#  Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[ Search syntax tips ](https://docs.github.com/search-github/github-code-\nsearch/understanding-github-code-search-syntax)\n\n#  Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n##  Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [ documentation\n](https://docs.github.com/search-github/github-code-search/understanding-\ngithub-code-search-syntax) .\n\nCancel  Create saved search\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fros-\ncontrols%2Fros2_controllers%2Fissues%2F264)\n\n[ Sign up\n](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-\nname%3E%2F%3Crepo-\nname%3E%2Fvoltron%2Fissues_fragments%2Fissue_layout&source=header-\nrepo&source_repo=ros-controls%2Fros2_controllers)\n\nYou signed in with another tab or window. [ Reload ]() to refresh your\nsession.  You signed out in another tab or window. [ Reload ]() to refresh\nyour session.  You switched accounts on another tab or window. [ Reload ]() to\nrefresh your session.  Dismiss alert\n\n{{ message }}\n\n[ ros-controls ](/ros-controls) /  **[ ros2_controllers ](/ros-\ncontrols/ros2_controllers) ** Public\n\n  * [ Notifications ](/login?return_to=%2Fros-controls%2Fros2_controllers)\n  * [ Fork  269  ](/login?return_to=%2Fros-controls%2Fros2_controllers)\n  * [ Star  285  ](/login?return_to=%2Fros-controls%2Fros2_controllers)\n\n  * [ Code  ](/ros-controls/ros2_controllers)\n  * [ Issues  120  ](/ros-controls/ros2_controllers/issues)\n  * [ Pull requests  30  ](/ros-controls/ros2_controllers/pulls)\n  * [ Actions  ](/ros-controls/ros2_controllers/actions)\n  * [ Projects  0  ](/ros-controls/ros2_controllers/projects)\n  * [ Security  ](/ros-controls/ros2_controllers/security)\n  * [ Insights  ](/ros-controls/ros2_controllers/pulse)\n\nAdditional navigation options\n\n  * [ Code  ](/ros-controls/ros2_controllers)\n  * [ Issues  ](/ros-controls/ros2_controllers/issues)\n  * [ Pull requests  ](/ros-controls/ros2_controllers/pulls)\n  * [ Actions  ](/ros-controls/ros2_controllers/actions)\n  * [ Projects  ](/ros-controls/ros2_controllers/projects)\n  * [ Security  ](/ros-controls/ros2_controllers/security)\n  * [ Insights  ](/ros-controls/ros2_controllers/pulse)\n\nNew issue\n\n**Have a question about this project?** Sign up for a free GitHub account to\nopen an issue and contact its maintainers and the community.\n\nPick a username\n\n    \n\nEmail Address\n\n    \n\nPassword\n\n    \nSign up for GitHub\n\nBy clicking \u201cSign up for GitHub\u201d, you agree to our [ terms of service\n](https://docs.github.com/terms) and [ privacy statement\n](https://docs.github.com/privacy) . We\u2019ll occasionally send you account\nrelated emails.\n\nAlready on GitHub? [ Sign in ](/login?return_to=%2Fros-\ncontrols%2Fros2_controllers%2Fissues%2Fnew%2Fchoose) to your account\n\nJump to bottom\n\n#  Mobile Robotics Controllers (Ackermann, four_wheels, swerve, ...)  #264\n\nOpen\n\n[ tomlogan501 ](/tomlogan501) opened this issue  Nov 8, 2021  \u00b7 10 comments\n\nOpen\n\n#  Mobile Robotics Controllers (Ackermann, four_wheels, swerve, ...)  #264\n\n[ tomlogan501 ](/tomlogan501) opened this issue  Nov 8, 2021  \u00b7 10 comments\n\nLabels\n\n[ enhancement  ](/ros-controls/ros2_controllers/labels/enhancement)\n\n##  Comments\n\n[\n![@tomlogan501](https://avatars.githubusercontent.com/u/56969577?s=80&u=d6c511541218546edacd2375c5495ab413dad6ba&v=4)\n](/tomlogan501)\n\nCopy link\n\n###\n\n**[ tomlogan501 ](/tomlogan501) ** commented  Nov 8, 2021\n\nHi,  \nI create just this topic to keep track of the transfert of those controllers\nfrom ROS1 to ROS2.  \nWe can discuss the main changes and the benefit to do so (new architecture,\ncyclic, ...)  \n  \n---  \n  \nThe text was updated successfully, but these errors were encountered:\n\n  \n  \n\ud83d\udc4d  3  destogl, ingjae, and roncapat reacted with thumbs up emoji\n\nAll reactions\n\n  * \ud83d\udc4d  3 reactions \n\n[\n![@tomlogan501](https://avatars.githubusercontent.com/u/56969577?s=40&u=d6c511541218546edacd2375c5495ab413dad6ba&v=4)\n](/tomlogan501) [ tomlogan501 ](/tomlogan501) added the [ enhancement ](/ros-\ncontrols/ros2_controllers/labels/enhancement) label  Nov 8, 2021\n\n[\n![@harderthan](https://avatars.githubusercontent.com/u/13160765?s=80&u=a3722e6edd43afdbdf038cdaa32aa26c406d4b5f&v=4)\n](/harderthan)\n\nCopy link\n\n###\n\n**[ harderthan ](/harderthan) ** commented  Dec 14, 2021\n\nHello.\n\nI create [ ackermann-steering-controller-ros2 repository\n](https://github.com/harderthan/ackermann-steering-controller-ros2) and\nimplement a migration for ros1 [ ackermann_steering_controller\n](https://github.com/ros-controls/ros_controllers/tree/noetic-\ndevel/ackermann_steering_controller)\n\nI finished only to build the migrated code. I have a todo list below.\n\n####  TODO\n\n  * Trouble shooting to build \n  * Add the Odometry/Velocity Calculation on ackermann_steering_controller.cpp \n  * Add test codes for ackermann_steering_controller.cpp \n  * Update Odometry.hpp and .cpp \n  * Update documents (remarks, descriptions, etc.) \n  * Add Test Code \n  * PR \n\nAdvice and questions are welcome. thank you.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@Timple](https://avatars.githubusercontent.com/u/5036851?s=80&u=a08e5b898649b0aab524aa5ce32a07b95b466333&v=4)\n](/Timple)\n\nCopy link\n\nContributor\n\n###\n\n**[ Timple ](/Timple) ** commented  Dec 14, 2021\n\nBe carefull with 'just' porting from ROS1.  \nFor ROS1 ackermann, the implementation seemed [ off ](https://github.com/ros-\ncontrols/ros_controllers/issues/412) .\n\nAlso support for front-wheel drive seems to be missing, but that might be a\nnew feature request.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@harderthan](https://avatars.githubusercontent.com/u/13160765?s=80&u=a3722e6edd43afdbdf038cdaa32aa26c406d4b5f&v=4)\n](/harderthan)\n\nCopy link\n\n###\n\n**[ harderthan ](/harderthan) ** commented  Dec 14, 2021\n\n> For ROS1 ackermann, the implementation seemed off.\n\n[ @Timple ](https://github.com/Timple) Reallly thank you for the feedback! I\ndidn't know it.\n\nDo you know if there was any discussion about adding an Ackermann controller?\nI'm not sure how I should contribute. Does it make sense to read and implement\nall [ this design_drafts ](https://github.com/ros-\ncontrols/roadmap/tree/master/design_drafts) ?\n\nAnd, I couldn't find the information about 'front-wheel drive'.  \nDo you mean ` four_wheel_steering_controller ` ?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@bmagyar](https://avatars.githubusercontent.com/u/3524577?s=80&u=8f938d2dcacdcbb54f3977d6356cef945a6eb6ed&v=4)\n](/bmagyar)\n\nCopy link\n\nMember\n\n###\n\n**[ bmagyar ](/bmagyar) ** commented  Dec 17, 2021  \u2022\n\nedited\n\n[ @harderthan ](https://github.com/harderthan) please don't create a separate\nrepository with code copied.  \nThe way to contribute changes and get feedback is to first fork this repo and\nadd a new package.\n\nFor porting of controllers you don't need a design draft. I agree with [\n@Timple ](https://github.com/Timple) _however_ I think the first step should\nbe to do the porting of that controller as-is, then you can go and improve it.\nDoing too many things at once will only get you into a situation where it's\nimpossible to trace your steps back and impossible to review as well.\n\nHere's my suggestion for a chain of PRs once you have most things working\n(applicable to any of the controllers above):\n\n  * Basic package structure implementing a controller that does nothing in particular, should have plugin, main header file, main cpp file, cmake properly set up, a load-controller test (see other controllers), no parameters, no subscriber or publisher \n  * Add all basic subscribers and publishers, doing the least amount of activity, add basic controller documentation (see other controllers) \n  * Add the implementation of the controller, subscriber callbacks and publishing to topics, add basic functional tests \n  * Expose parameters and add tests that rely on setting parameters \n  * Add any more tests that were not added yet \n  * Add any new features by implementing the new functionality, adding parameter(s) for it and appropriate tests without changing the default behaviour _unless_ you have a very good reason to do so \n\nWhen in doubt, check the diff_drive_controller although it's not in a great\nshape so if you have better ideas for some things, feel free to be smarter.  \nAlso take a look at our contribution guidelines: [\nhttp://control.ros.org/contributing.html\n](http://control.ros.org/contributing.html)  \n  \n---  \n  \n\ud83d\udc4d  4  harderthan, samehmohamed88, jlblancoc, and aarjan222 reacted with thumbs\nup emoji\n\nAll reactions\n\n  * \ud83d\udc4d  4 reactions \n\nSorry, something went wrong.\n\n[ ![@samehmohamed88](https://avatars.githubusercontent.com/u/2354387?s=40&v=4)\n](/samehmohamed88) [ samehmohamed88 ](/samehmohamed88) mentioned this issue\nJan 26, 2022\n\n[ Ackermann Steering Controller  #288  ](/ros-\ncontrols/ros2_controllers/issues/288)\n\nClosed\n\n[ ![@samehmohamed88](https://avatars.githubusercontent.com/u/2354387?s=80&v=4)\n](/samehmohamed88)\n\nCopy link\n\n###\n\n**[ samehmohamed88 ](/samehmohamed88) ** commented  Jan 29, 2022\n\nHas any further work been done on this issue? I also need to implement a car-\nlike steering controller for my current project.  \n  \n---  \n  \n\ud83d\udc4d  2  samuk and romzn reacted with thumbs up emoji\n\nAll reactions\n\n  * \ud83d\udc4d  2 reactions \n\nSorry, something went wrong.\n\n[\n![@tonynajjar](https://avatars.githubusercontent.com/u/14879660?s=80&u=e29d50db1bac036eae32b30fec612615ccd3791a&v=4)\n](/tonynajjar)\n\nCopy link\n\nContributor\n\n###\n\n**[ tonynajjar ](/tonynajjar) ** commented  Jul 15, 2022\n\n[ @bmagyar ](https://github.com/bmagyar) are you getting the notifications on\nthis PR? Could you advise on how to proceed?\n\n[ #345 ](https://github.com/ros-controls/ros2_controllers/pull/345)  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@bmagyar](https://avatars.githubusercontent.com/u/3524577?s=80&u=8f938d2dcacdcbb54f3977d6356cef945a6eb6ed&v=4)\n](/bmagyar)\n\nCopy link\n\nMember\n\n###\n\n**[ bmagyar ](/bmagyar) ** commented  Jul 17, 2022\n\nAs far as I'm concerned [ @tonynajjar ](https://github.com/tonynajjar) your PR\nis the way to go. Sorry for the delay on reviewing, we've been really busy\nwith framework features and controllers received a little less attention. We\nhave the reviewer lottery to help with that but sometimes you get unlucky with\nthe draw  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@DiuLaMaX](https://avatars.githubusercontent.com/u/53355440?s=80&v=4)\n](/DiuLaMaX)\n\nCopy link\n\n###\n\n**[ DiuLaMaX ](/DiuLaMaX) ** commented  Dec 8, 2022\n\n[ @bmagyar ](https://github.com/bmagyar) What is the current status of\nmigrating Ackermann_steering_controller from ROS1 to ROS2?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@hishambaharom](https://avatars.githubusercontent.com/u/113874406?s=80&v=4)\n](/hishambaharom)\n\nCopy link\n\n###\n\n**[ hishambaharom ](/hishambaharom) ** commented  Dec 12, 2022\n\n[ @bmagyar ](https://github.com/bmagyar) when the\nackermann_steering_controller support on ros2 humble  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@bmagyar](https://avatars.githubusercontent.com/u/3524577?s=80&u=8f938d2dcacdcbb54f3977d6356cef945a6eb6ed&v=4)\n](/bmagyar)\n\nCopy link\n\nMember\n\n###\n\n**[ bmagyar ](/bmagyar) ** commented  Dec 13, 2022\n\n[ @DiuLaMaX ](https://github.com/DiuLaMaX) [ @hishambaharom\n](https://github.com/hishambaharom) it's waiting for you guys to put the work\nin ;)  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ gwalck ](/gwalck) pushed a commit to StoglRobotics-forks/ros2_controllers\nthat referenced this issue  Jun 7, 2023\n\n[\n![@v-lopez](https://avatars.githubusercontent.com/u/3469405?s=40&u=23f4ab0ad3756c281f86b2ecfa4d2702db9b10e4&v=4)\n](/v-lopez)\n\n` [ Remove resource checking not ported ros1 code ( ](/StoglRobotics-\nforks/ros2_controllers/commit/2491482e8f814e63a0511a124effa6fb726b54f1 \"Remove\nresource checking not ported ros1 code \\(#264\\)\") [ ros-controls#264\n](https://github.com/ros-controls/ros2_controllers/issues/264) [ )\n](/StoglRobotics-\nforks/ros2_controllers/commit/2491482e8f814e63a0511a124effa6fb726b54f1 \"Remove\nresource checking not ported ros1 code \\(#264\\)\") `\n\n` [ 2491482 ](/StoglRobotics-\nforks/ros2_controllers/commit/2491482e8f814e63a0511a124effa6fb726b54f1) `\n\n[ Sign up for free ](/join?source=comment-repo) **to join this conversation on\nGitHub** . Already have an account? [ Sign in to comment\n](/login?return_to=https%3A%2F%2Fgithub.com%2Fros-\ncontrols%2Fros2_controllers%2Fissues%2F264)\n\nAssignees\n\nNo one assigned\n\nLabels\n\n[ enhancement  ](/ros-controls/ros2_controllers/labels/enhancement)\n\nProjects\n\nNone yet\n\nMilestone\n\nNo milestone\n\nDevelopment\n\nNo branches or pull requests\n\n8 participants\n\n[ ![@samehmohamed88](https://avatars.githubusercontent.com/u/2354387?s=52&v=4)\n](/samehmohamed88) [\n![@bmagyar](https://avatars.githubusercontent.com/u/3524577?s=52&v=4)\n](/bmagyar) [\n![@Timple](https://avatars.githubusercontent.com/u/5036851?s=52&v=4)\n](/Timple) [\n![@harderthan](https://avatars.githubusercontent.com/u/13160765?s=52&v=4)\n](/harderthan) [\n![@tonynajjar](https://avatars.githubusercontent.com/u/14879660?s=52&v=4)\n](/tonynajjar) [\n![@DiuLaMaX](https://avatars.githubusercontent.com/u/53355440?s=52&v=4)\n](/DiuLaMaX) [\n![@tomlogan501](https://avatars.githubusercontent.com/u/56969577?s=52&v=4)\n](/tomlogan501) [\n![@hishambaharom](https://avatars.githubusercontent.com/u/113874406?s=52&v=4)\n](/hishambaharom)\n\n##  Footer\n\n[ ](https://github.com \"GitHub\") \u00a9 2024 GitHub, Inc.\n\n###  Footer navigation\n\n  * [ Terms ](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [ Privacy ](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [ Security ](/security)\n  * [ Status ](https://www.githubstatus.com/)\n  * [ Docs ](https://docs.github.com/)\n  * [ Contact ](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.\n\n"
  },
  {
    "id": "ros_regular/roscon2022workshop.txt",
    "content": "Skip to content\n\nToggle navigation\n\n[ ](https://github.com/)\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fros-\ncontrols%2Froscon2022_workshop)\n\n  * Product \n\n    * [ Actions  Automate any workflow  ](/features/actions)\n    * [ Packages  Host and manage packages  ](/features/packages)\n    * [ Security  Find and fix vulnerabilities  ](/features/security)\n    * [ Codespaces  Instant dev environments  ](/features/codespaces)\n    * [ Copilot  Write better code with AI  ](/features/copilot)\n    * [ Code review  Manage code changes  ](/features/code-review)\n    * [ Issues  Plan and track work  ](/features/issues)\n    * [ Discussions  Collaborate outside of code  ](/features/discussions)\n\nExplore\n\n    * [ All features ](/features)\n    * [ Documentation  ](https://docs.github.com)\n    * [ GitHub Skills  ](https://skills.github.com/)\n    * [ Blog  ](https://github.blog)\n\n  * Solutions \n\nFor\n\n    * [ Enterprise ](/enterprise)\n    * [ Teams ](/team)\n    * [ Startups ](/enterprise/startups)\n    * [ Education  ](https://education.github.com)\n\nBy Solution\n\n    * [ CI/CD & Automation ](/solutions/ci-cd/)\n    * [ DevOps ](/solutions/devops/)\n    * [ DevSecOps  ](https://resources.github.com/devops/fundamentals/devsecops/)\n\nResources\n\n    * [ Learning Pathways  ](https://resources.github.com/learn/pathways/)\n    * [ White papers, Ebooks, Webinars  ](https://resources.github.com/)\n    * [ Customer Stories ](/customer-stories)\n    * [ Partners  ](https://partner.github.com/)\n\n  * Open Source \n\n    * [ GitHub Sponsors  Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project  GitHub community articles  ](/readme)\n\nRepositories\n\n    * [ Topics ](/topics)\n    * [ Trending ](/trending)\n    * [ Collections ](/collections)\n\n  * [ Pricing ](/pricing)\n\nSearch or jump to...\n\n#  Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[ Search syntax tips ](https://docs.github.com/search-github/github-code-\nsearch/understanding-github-code-search-syntax)\n\n#  Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n##  Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [ documentation\n](https://docs.github.com/search-github/github-code-search/understanding-\ngithub-code-search-syntax) .\n\nCancel  Create saved search\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fros-\ncontrols%2Froscon2022_workshop)\n\n[ Sign up\n](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-\nname%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=ros-\ncontrols%2Froscon2022_workshop)\n\nYou signed in with another tab or window. [ Reload ]() to refresh your\nsession.  You signed out in another tab or window. [ Reload ]() to refresh\nyour session.  You switched accounts on another tab or window. [ Reload ]() to\nrefresh your session.  Dismiss alert\n\n{{ message }}\n\n[ ros-controls ](/ros-controls) /  **[ roscon2022_workshop ](/ros-\ncontrols/roscon2022_workshop) ** Public\n\n  * [ Notifications ](/login?return_to=%2Fros-controls%2Froscon2022_workshop)\n  * [ Fork  23  ](/login?return_to=%2Fros-controls%2Froscon2022_workshop)\n  * [ Star  91  ](/login?return_to=%2Fros-controls%2Froscon2022_workshop)\n\n  * \n\n###  License\n\n[ Apache-2.0 license ](/ros-controls/roscon2022_workshop/blob/master/LICENSE)\n\n[ 91  stars ](/ros-controls/roscon2022_workshop/stargazers) [ 23  forks\n](/ros-controls/roscon2022_workshop/forks) [ Branches  ](/ros-\ncontrols/roscon2022_workshop/branches) [ Tags  ](/ros-\ncontrols/roscon2022_workshop/tags) [ Activity  ](/ros-\ncontrols/roscon2022_workshop/activity)\n\n[ Star  ](/login?return_to=%2Fros-controls%2Froscon2022_workshop)\n\n[ Notifications ](/login?return_to=%2Fros-controls%2Froscon2022_workshop)\n\n  * [ Code  ](/ros-controls/roscon2022_workshop)\n  * [ Issues  2  ](/ros-controls/roscon2022_workshop/issues)\n  * [ Pull requests  0  ](/ros-controls/roscon2022_workshop/pulls)\n  * [ Actions  ](/ros-controls/roscon2022_workshop/actions)\n  * [ Projects  0  ](/ros-controls/roscon2022_workshop/projects)\n  * [ Security  ](/ros-controls/roscon2022_workshop/security)\n  * [ Insights  ](/ros-controls/roscon2022_workshop/pulse)\n\nAdditional navigation options\n\n  * [ Code  ](/ros-controls/roscon2022_workshop)\n  * [ Issues  ](/ros-controls/roscon2022_workshop/issues)\n  * [ Pull requests  ](/ros-controls/roscon2022_workshop/pulls)\n  * [ Actions  ](/ros-controls/roscon2022_workshop/actions)\n  * [ Projects  ](/ros-controls/roscon2022_workshop/projects)\n  * [ Security  ](/ros-controls/roscon2022_workshop/security)\n  * [ Insights  ](/ros-controls/roscon2022_workshop/pulse)\n\n#  ros-controls/roscon2022_workshop\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\nmaster\n\n[ Branches  ](/ros-controls/roscon2022_workshop/branches) [ Tags  ](/ros-\ncontrols/roscon2022_workshop/tags)\n\n[ ](/ros-controls/roscon2022_workshop/branches) [ ](/ros-\ncontrols/roscon2022_workshop/tags)\n\nGo to file\n\nCode\n\n##  Folders and files\n\nName  |  Name  |\n\nLast commit message\n\n|\n\nLast commit date  \n  \n---|---|---|---  \n  \n##  Latest commit\n\n##  History\n\n[ 18 Commits  ](/ros-controls/roscon2022_workshop/commits/master/)\n\n[ ](/ros-controls/roscon2022_workshop/commits/master/)  \n  \n###\n\n[ controlko_bringup ](/ros-\ncontrols/roscon2022_workshop/tree/master/controlko_bringup\n\"controlko_bringup\")\n\n|\n\n###\n\n[ controlko_bringup ](/ros-\ncontrols/roscon2022_workshop/tree/master/controlko_bringup\n\"controlko_bringup\")\n\n|\n\n|  \n  \n###\n\n[ controlko_controllers ](/ros-\ncontrols/roscon2022_workshop/tree/master/controlko_controllers\n\"controlko_controllers\")\n\n|\n\n###\n\n[ controlko_controllers ](/ros-\ncontrols/roscon2022_workshop/tree/master/controlko_controllers\n\"controlko_controllers\")\n\n|\n\n|  \n  \n###\n\n[ controlko_description ](/ros-\ncontrols/roscon2022_workshop/tree/master/controlko_description\n\"controlko_description\")\n\n|\n\n###\n\n[ controlko_description ](/ros-\ncontrols/roscon2022_workshop/tree/master/controlko_description\n\"controlko_description\")\n\n|\n\n|  \n  \n###\n\n[ controlko_hardware_interface ](/ros-\ncontrols/roscon2022_workshop/tree/master/controlko_hardware_interface\n\"controlko_hardware_interface\")\n\n|\n\n###\n\n[ controlko_hardware_interface ](/ros-\ncontrols/roscon2022_workshop/tree/master/controlko_hardware_interface\n\"controlko_hardware_interface\")\n\n|\n\n|  \n  \n###\n\n[ roscon2022_control_workshop ](/ros-\ncontrols/roscon2022_workshop/tree/master/roscon2022_control_workshop\n\"roscon2022_control_workshop\")\n\n|\n\n###\n\n[ roscon2022_control_workshop ](/ros-\ncontrols/roscon2022_workshop/tree/master/roscon2022_control_workshop\n\"roscon2022_control_workshop\")\n\n|\n\n|  \n  \n###\n\n[ .clang-format ](/ros-controls/roscon2022_workshop/blob/master/.clang-format\n\".clang-format\")\n\n|\n\n###\n\n[ .clang-format ](/ros-controls/roscon2022_workshop/blob/master/.clang-format\n\".clang-format\")\n\n|\n\n|  \n  \n###\n\n[ LICENSE ](/ros-controls/roscon2022_workshop/blob/master/LICENSE \"LICENSE\")\n\n|\n\n###\n\n[ LICENSE ](/ros-controls/roscon2022_workshop/blob/master/LICENSE \"LICENSE\")\n\n|\n\n|  \n  \n###\n\n[ README.md ](/ros-controls/roscon2022_workshop/blob/master/README.md\n\"README.md\")\n\n|\n\n###\n\n[ README.md ](/ros-controls/roscon2022_workshop/blob/master/README.md\n\"README.md\")\n\n|\n\n|  \n  \n###\n\n[ TODOs.md ](/ros-controls/roscon2022_workshop/blob/master/TODOs.md\n\"TODOs.md\")\n\n|\n\n###\n\n[ TODOs.md ](/ros-controls/roscon2022_workshop/blob/master/TODOs.md\n\"TODOs.md\")\n\n|\n\n|  \n  \n###\n\n[ roscon2022_workshop.humble.repos ](/ros-\ncontrols/roscon2022_workshop/blob/master/roscon2022_workshop.humble.repos\n\"roscon2022_workshop.humble.repos\")\n\n|\n\n###\n\n[ roscon2022_workshop.humble.repos ](/ros-\ncontrols/roscon2022_workshop/blob/master/roscon2022_workshop.humble.repos\n\"roscon2022_workshop.humble.repos\")\n\n|\n\n|  \n  \n###\n\n[ roscon2022_workshop.repos ](/ros-\ncontrols/roscon2022_workshop/blob/master/roscon2022_workshop.repos\n\"roscon2022_workshop.repos\")\n\n|\n\n###\n\n[ roscon2022_workshop.repos ](/ros-\ncontrols/roscon2022_workshop/blob/master/roscon2022_workshop.repos\n\"roscon2022_workshop.repos\")\n\n|\n\n|  \n  \nView all files  \n  \n##  Repository files navigation\n\n  * README \n  * Apache-2.0 license \n\n#  ROSCon 2022 workshop on ros2_control\n\nThank you for your interest in ros2_control. This repository was developed\nwith the purpose of supporting the workshop on _ros2_control_ @ ROSCon2022 in\nKyoto, Japan. Whether you participated or not, the repository will provide you\nwith detailed instructions on how to use the _ros2_control_ framework and\nexplain functionality and purpose of its individual parts.\n\n###  Installing this repository\n\nAfter cloning the repository, go to your source workspace and execute the\nfollowing commands to import the necessary repositories and to install all\ndependencies:\n\n    \n    \n    vcs import --input roscon2022_workshop/roscon2022_workshop.repos .\n    rosdep update\n    rosdep install -y -i --from-paths .\n    \n\n##  What is _ros2_control_\n\nIn short, ros2_control is a control framework for ROS2. But actually, it is\nmuch more, it is the kernel of the ROS2 system that controls robots:\n\n  * it abstracts hardware and low-level control for other frameworks such as MoveIt2 and Nav2; \n  * it provides resource access management, \n  * controls their lifecycle and so on. \n\nFor more details check [ this presentation\n](https://control.ros.org/master/doc/resources/resources.html#ros-world-2021)\n\n##  Structure of this repository (and workshop)\n\nThe structure of the repository follows the flow of integrating robots with\nROS2 and these are the following steps:\n\n  1. \ud83d\udcd1 Setting up the hardware description for _ros2_control_\n\n    1. \ud83d\uddd2 Setting up the robot's URDF using XACRO \n    2. \ud83d\udcdd Extending the robot's URDF with the ` <ros2_control> ` tag \n  2. \ud83d\udda5 Using the _Mock Hardware_ plugin for easy and generic testing of the setup (and how it can save you ton of time and nerves) \n\n    1. \ud83d\udee0 How to setup _Mock Hardware_ for a robot? \n    2. \ud83d\udd29 How to test it with an off-the-shelf controller? \n  3. \u2699 Getting to know the roles of the main components of the _ros2_control_ framework: _Controller Manager_ , _Controllers_ , _Resource Manager_ and _Hardware Interface_\n\n  4. \ud83d\udd2c Introspection of the _ros2_control_ system \n\n  5. \ud83d\udcbb Simulating your hardware using Gazebo Classic and Gazebo \n\n  6. \ud83d\udd03 Become familiar with the lifecycle of controllers and hardware. Learn how to use them. \n\n  7. \ud83e\udd16 How to write a hardware interface for a robot \n\n  8. \ud83d\udec2 How to write a controller \n\n##  Details about the workshop\n\n###  1\\. \ud83d\udcd1 Setting up the hardware description for _ros2_control_\n\n#####  GOAL\n\n  * learn how to setup the URDF of a robot using XACRO macros \n  * learn what URDF changes are needed to integrate a robot with ` ros2_control `\n\n#####  \ud83d\uddd2 Setting up URDF using XACRO for a robot\n\nFor any robot that is used with ROS/ROS2 an URDF description is needed. This\ndescription holds information about kinematics, visualization (e.g., for\nRviz2) and collision data. This description is also used by popular ROS2 high-\nlevel libraries like, MoveIt2, Nav2 and Simulators.\n\nIn this excercise we will focus on setting up the description using the XACRO\nformat which is highly configurable and parameterizable and generally better\nto use than the static URDF format.\n\n#####  Task\n\nBranch: ` 1-robot-description/task `\n\nTask is to setup the XACRO for RRbot in a package called `\ncontrolko_description ` .\n\nKinematics:\n\n  * 2 DoF \n  * 1st joint is on a pedestal (box 30x30x30 cm) 30 cm above the ground and rotates around the axis orthogonal to the ground \n  * 1st link is 50cm long (cylinder with 20cm diameter) \n  * 2nd joint is rotation orthogonal to the first link's height \n  * 2nd link is 60cm long (10x10cm cross-section 5x5cm) \n\nHardware:\n\n  * Force Torque Sensor at TCP (6D) \n  * 2 digital inputs and output (outputs can be measured) \n\nReferences:\n\n  * [ https://wiki.ros.org/urdf ](https://wiki.ros.org/urdf)\n  * [ https://wiki.ros.org/urdf/XML ](https://wiki.ros.org/urdf/XML)\n\nFiles to create or adjust:\n\n  * ` rrbot_macro.xacro ` \\- macro with kinematics and geometries for the ` rrbot `\n  * ` rrbot.urdf.xacro ` \\- main xacro file for the robot where macro is instantiated \n  * ` view_robot.launch.py ` \\- loading and showing robot in ` rviz2 `\n\n**TIPP** : ` RosTeamWS ` tool has some scripts that can help you to solve this\ntask faster (on the branch is this already implemented). Resources:\n\n  * [ Commonly used robot-package structure ](https://stoglrobotics.github.io/ros_team_workspace/master/guidelines/robot_package_structure.html)\n  * [ Creating a new package ](https://stoglrobotics.github.io/ros_team_workspace/master/use-cases/ros_packages/create_package.html)\n  * [ Setting up robot description ](https://stoglrobotics.github.io/ros_team_workspace/master/use-cases/ros_packages/setup_robot_description_package.html)\n\n#####  Solution:\n\nBranch: ` 1-robot-description/solution `\n\nCheck the files listed above and execute:\n\n    \n    \n    ros2 launch controlko_description view_rrbot.launch.py\n    \n\nto view the robot and move its joints using the ` Joint State Publisher ` GUI.\n\n###  2\\. \ud83d\udda5 Using _Mock Hardware_ plugin for simple and generic testing of the\nsetup\n\n#####  GOAL\n\n  * learn what is _Mock Hardware_ and how to use it \n  * learn how you can fast and easily test you controller's setup and parameters before you deal with simulation or real hardware \n\n_Mock Hardware_ is mocking ros2_control ` Hardware Interface ` based on the\nrobot's description from the ` ros2_control ` tag. Its purpose is to simplify\nand boost the development process when creating a new controller or setting up\ntheir configuration. The advantage of using it, over simulation or real\nhardware, is a very fast start-up and lean functionality. It is a well tested\nmodule helping you focus on other components in your setup knowing that your\n\"hardware\" behaves ideally. _NOTE:_ the functionality of _Mock Hardware_ is\nintentionally limited and it only enables you to reflect commanded values on\nthe state interfaces with the same name. Nevertheless, this is sufficient for\nmost tasks.\n\n**TIPP** :\n\n  * Dr. Denis recommends you to always start to develop things first with the Mock Hardware and then start switching to simulation or real hardware. This way you save time dealing with a broken setup with simulation or hardware in the loop. \n\n#####  \ud83d\udee0 How to setup _Mock Hardware_ for a robot?\n\n  1. Add ` hardware ` tag under the ` ros2_control ` tag with plugin ` mock_components/GenericSystem ` and set ` mock_sensor_commands ` parameter. The parameter create fake command interface for sensor values than enables you to simulate the values on the sensor. \n\n  2. Create a launch file named ` rrbot.launch.py ` that starts the ros2_control node with the correct robot description. \n\n**NOTE** : Currently, there is only ` GenericSystem ` mock component, which\ncan mock also sensor or actuator components (because they just have a reduced\nfeature set compared to a system).\n\n#####  \ud83d\udd29 How to test it with an off-the-shelf controller?\n\n  1. Setup the following controllers for the ` RRBot ` : \n\n  * ` Joint State Broadcaster ` \\- always needed to get ` /joint_states ` topic from a hardware. \n  * ` Forward Command Controller ` \\- sending position commands for the joints. \n  * ` Joint Trajectory Controller ` \\- interpolating trajectory between the position commands for the joint. \n\n  2. Add to launch file spawning (loading and activating) of controllers. \n\n  3. Test forward command controller by sending a reference to it using ` ros2 topic pub ` command. \n\n  4. Create a launch file that starts ` ros2_controllers_test_nodes/publisher_joint_trajectory_controller ` to publish goals for the JTC. \n\n**TIPP** : ` RosTeamWS ` tool has some scripts that can help you to solve this\ntask faster. Resources:\n\n  * [ Commonly used robot-package structure ](https://stoglrobotics.github.io/ros_team_workspace/master/guidelines/robot_package_structure.html)\n  * [ Creating a new package ](https://stoglrobotics.github.io/ros_team_workspace/master/use-cases/ros_packages/create_package.html)\n  * [ Setting up robot bringup ](https://stoglrobotics.github.io/ros_team_workspace/master/use-cases/ros_packages/setup_robot_bringup_package.html)\n\n#####  Solution:\n\nBranch: ` 2-robot-mock-hardware `\n\nCheck the files listed above and execute:\n\n    \n    \n    ros2 launch controlko_bringup rrbot.launch.py\n    \n\nthen publish a command to the forward command controller:\n\n    \n    \n    ros2 topic pub /forward_position_controller/commands std_msgs/msg/Float64MultiArray \"\n    layout:\n     dim: []\n     data_offset: 0\n    data:\n     - 0.7\n     - 0.7\"\n    \n\nTo start ` RRBot ` with JTC execute:\n\n    \n    \n    ros2 launch controlko_bringup rrbot.launch.py robot_controller:=joint_trajectory_controller\n    \n\nand open a new terminal and execute:\n\n    \n    \n    ros2 launch controlko_bringup test_joint_trajectory_controller.launch.py\n    \n\n**NOTE** : delay between spawning controllers is usually not necessary, but\nuseful when starting a complex setup. Adjust this specifically for the\nspecific use-case.\n\n###  3\\. \u2699 Getting know the roles of the main components of _ros2_control_\nframework\n\nStart the previous example one more time and try to answer the following\nquestions:\n\n  1. What and where is _Controller Manager_ ? \n  2. What are _Controllers_ ? How they can be seen in ROS2? \n  3. What is _Resource Manager_ ? Where can you see it? How to access it? \n  4. What is _Hardware Interface_ ? Where is this stored? How to interact with it? \n\n#####  Solution:\n\n[ ![ros2_control Overview](https://github.com/ros-\ncontrols/control.ros.org/raw/master/doc/resources/images/ros2_control_overview.png)\n](https://github.com/ros-\ncontrols/control.ros.org/blob/master/doc/resources/images/ros2_control_overview.png)\n\n###  4\\. \ud83d\udd2c Introspection of _ros2_control_ system\n\nThere are two options to interact with the ros2_control, first, using the CLI\ninterface with commands like ` ros2 control <command> ` (package `\nros2controlcli ` ), and second, using services from the controller manager\ndirectly.\n\nTry to figure out how to answer the following questions using those tools:\n\n  1. What controllers are loaded in the system? \n  2. What is the state of the controllers? \n  3. What hardware interfaces are there and in which state? \n  4. Which interfaces are available? \n  5. How can we switch between ` forward_position_controller ` and ` joint_trajectory_controller ` ? \n  6. What happens when you try to run all controllers in parallel? \n  7. What interfaces are controllers using? \n\nAlso there are few graphical tools available for ` ros2_control ` : `\nrqt_controller_manager ` and ` rqt_joint_trajectory_controller ` . Try to use\nthose tools.\n\n#####  Solution:\n\nAnswers to the questions:\n\n  1. ` ros2 control list_controllers `\n  2. ` ros2 control list_controllers `\n  3. ` ros2 service call /controller_manager/list_hardware_components controller_manager_msgs/srv/ListHardwareComponents {} `\n  4. ` ros2 control list_hardware_interfaces `\n  5. ` ros2 run controller_manager spawner forward_position_controller --inactive ` ` ros2 control switch_controllers --deactivate joint_trajectory_controller --activate forward_position_controller `\n  6. See output in the terminal where ` ros2_control_node ` is running: ` ros2 control switch_controllers --activate joint_trajectory_controller `\n  7. ` ros2 control list_controllers -v `\n\n###  5\\. \ud83d\udcbb Simulating your hardware using Gazebo Classic and Gazebo\n\nros2_control is integrated with simulators using simulator-specific plugins.\nThose plugins extend controller manager with simulator-related functionalities\nand enables loading hardware interfaces that are created specifically for the\nsimulator. Simulators are using description under ` <ros2_control> ` to setup\nthe interfaces. They are searched for interfaces with standard names, `\nposition ` , ` velocity ` and ` effort ` , to wire them with the internal\nsimulator-states.\n\nThe plugins and interfaces for the simulators are the following:\n\n**Gazebo Classic**\n\n  * Package: ` gazebo_ros2_control `\n  * Simulator plugin: ` libgazebo_ros2_control.so `\n  * HW interface plugin: ` gazebo_ros2_control/GazeboSystem `\n\n**Gazebo**\n\n  * Package: ` gz_ros2_control `\n  * Simulator plugin: ` libign_ros2_control-system.so `\n  * HW interface plugin: ` ign_ros2_control/IgnitionSystem ` **NOTE** ` ign ` will be switched to ` gz ` very soon! \n\nLet's define those plugins for ` RRBot ` :\n\n  1. Extend ` rrbot.urdf.xacro ` with ` <gazebo> ` tags defining simulator plugins and parameters. \n  2. Add hardware interface plugins under ` <ros2_control> ` tag in the file ` rrbot_macro.ros2_control.xacro ` . \n  3. Add new launch file ` rrbot_sim_gazebo_class.launch.py ` for starting Gazebo Classic simulation. \n  4. Add new launch file ` rrobt_sim_gazebo.launch.py ` for starting Gazebo simulation. \n\n#####  Solution:\n\nBranch: ` 5-simulation `\n\nCheck updated files from the above list. To start the Gazebo Classic\nsimulation use:\n\n    \n    \n    ros2 launch controlko_bringup rrbot_sim_gazebo_classic.launch.py\n    \n\nTo start the Gazebo simulation use:\n\n    \n    \n    ros2 launch controlko_bringup rrbot_sim_gazebo.launch.py\n    \n\nNow execute the test script for joint trajectory controller to move the robot.\n\n    \n    \n    ros2 launch controlko_bringup test_joint_trajectory_controller.launch.py\n    \n\n**NOTE** : When running simulation be sure to set the joint limits defined in\nthe macro file.\n\n###  6\\. \ud83d\udd03 Getting familiar with the lifecycle of controllers and hardware and\nhow to use it\n\n_ros2_control_ enables you to control the lifecycle of controllers and\nhardware components. The states and transitions are the same as for the `\nLifecycle Nodes ` . Check the diagram below for more details:\n\n[ ![Lifecycle of Hardware\nInterfaces](https://camo.githubusercontent.com/dafe15b6ee5d31f8d8b27bb58cf64d764b84346c24f7bb36d67360d22109dead/68747470733a2f2f636f6e74726f6c2e726f732e6f72672f6d61737465722f5f696d616765732f68617264776172655f696e746572666163655f6c6966656379636c652e706e67)\n](https://camo.githubusercontent.com/dafe15b6ee5d31f8d8b27bb58cf64d764b84346c24f7bb36d67360d22109dead/68747470733a2f2f636f6e74726f6c2e726f732e6f72672f6d61737465722f5f696d616765732f68617264776172655f696e746572666163655f6c6966656379636c652e706e67)\n\n#####  Task\n\n  1. Start the ` RRbot ` with ` Mock System `\n  2. Check the lifecycle state of controllers and hardware interfaces \n  3. Activate the ` joint_trajectory_controller ` controller. What else do you have to do to achieve that? \n  4. Set hardware to ` inactive ` state. What is now the internal state of the _ros2_control_ instance? \n  5. Have you heard of the ` RQT Controller Manager ` plugin? Try it! \n\n#####  Solution:\n\nBranch: ` 6-getting-know-lifecycle `\n\nExecute the following commands to get the answers from the task:\n\n  1. ` ros2 launch controlko_bringup rrbot.launch.py `\n\n  2. Execute in another terminal: \n    \n        ros2 control list_controllers\n    ros2 service call /controller_manager/list_hardware_components controller_manager_msgs/srv/ListHardwareComponents {}\n    \n\n  3. Execute the following commands (this is one of multiple valid ways) \n    \n        ros2 control load_controller joint_trajectory_controller\n    ros2 control set_controller_state joint_trajectory_controller inactive\n    ros2 control switch_controllers --deactivate forward_position_controller --activate joint_trajectory_controller\n    \n\n  4. Execute the following commands (this is one of multiple valid ways) \n    \n        # stop controller\n    ros2 control switch_controllers --deactivate joint_trajectory_controller\n    # get component name\n    ros2 service call /controller_manager/list_hardware_components controller_manager_msgs/srv/ListHardwareComponents {}\n    # set component state\n    ros2 service call /controller_manager/set_hardware_component_state controller_manager_msgs/srv/SetHardwareComponentState \"\n    name: rrbot\n    target_state:\n     id: 0 \n     label: inactive\"\n    # check internals of ros2_control\n    ros2 control list_controllers\n    ros2 control list_hardware_interfaces\n    \n\n###  7\\. \ud83e\udd16 How to write a hardware interface for a robot\n\nHardware interface is the lowest layer towards hardware in _ros2_control_ . A\nhardware interface is a driver for a specific robot that exports interfaces to\nthe framework for controllers to use them. Overview of _ros2_control_ shows\nthis graphically:\n\n[ ![Overview of\nros2_control](https://camo.githubusercontent.com/44338401d929f48a49bb091228514f5df1a55f1677fe90f651a600a747cbabb1/68747470733a2f2f636f6e74726f6c2e726f732e6f72672f6d61737465722f5f696d616765732f726f73325f636f6e74726f6c5f6f766572766965772e706e67)\n](https://camo.githubusercontent.com/44338401d929f48a49bb091228514f5df1a55f1677fe90f651a600a747cbabb1/68747470733a2f2f636f6e74726f6c2e726f732e6f72672f6d61737465722f5f696d616765732f726f73325f636f6e74726f6c5f6f766572766965772e706e67)\n\nLifecycle diagrams from the [ Task 6 ](/ros-\ncontrols/roscon2022_workshop/blob/master) explains in detail when which method\nis used.\n\n#####  Task\n\nBranch: ` 7-robot-hardware-interface/task `\n\nWrite a hardware interface for the _RRBot_ .\n\n  1. Create or adjust a package named ` controlko_hardware_interface ` with hardware interface files. \n\n  2. Write a hardware interface that uses a header-only library for the communication with _RRBot_ : \n\n    * check the file ` controlko_hardware_interface/include/controlko_hardware_interface/dr_denis_rrbot_comms.hpp `\n    * use [ Writing a new hardware interface manual ](https://control.ros.org/master/doc/ros2_control/hardware_interface/doc/writing_new_hardware_interface.html) to implement everything needed. \n    * extend the URDF file to use hardware interface \n  3. During the implementation of the hardware interface take care about the following details: \n\n    * Which control modes are supported? \n    * What happens if an incompatible controller is activated? \n  4. What are the capabilities? \n\n**TIPP** : ` RosTeamWS ` tool has some scripts that can help you to solve this\ntask faster. Resources:\n\n  * [ Commonly used robot-package structure ](https://stoglrobotics.github.io/ros_team_workspace/master/guidelines/robot_package_structure.html)\n  * [ Creating a new package ](https://stoglrobotics.github.io/ros_team_workspace/master/use-cases/ros_packages/create_package.html)\n  * [ Setup robot\u2019s hardware package ](https://stoglrobotics.github.io/ros_team_workspace/master/use-cases/ros2_control/setup_robot_hardware_interface.html)\n\n#####  Solution\n\nBranch: ` 7-robot-hardware-interface/solution `\n\nExecute the following commands to get the answers from the task:\n\n  1. ` ros2 launch controlko_bringup rrbot.launch.py use_mock_hardware:=false `\n\n  2. Test execution with ` forward_position_controller ` and ` joint_trajectory_controller `\n\n  3. Test activation of an incompatible controller using: \n    \n        ros2 control load_controller incompatible_joint_trajectory_controller\n    ros2 control set_controller_state incompatible_joint_trajectory_controller inactive\n    ros2 control switch_controllers --deactivate forward_position_controller --activate incompatible_joint_trajectory_controller\n    \n\n###  8\\. \ud83d\udec2 How to write a controller\n\nControllers in _ros2_control_ are serving on the one hand as \"interfaces\"\ntowards the ROS-world and on the other hand implement algorithms to control\nthe hardware. A controller, when activated, gets loaned access to the exported\nhardware interface to read and write values directly from/to memory locations\nthat the hardware interface is using. Although somewhat limited, this concept\nenables deterministic and reliable data flow between controllers and hardware\ninterfaces (drivers).\n\n[ ![Overview of\nros2_control](https://camo.githubusercontent.com/44338401d929f48a49bb091228514f5df1a55f1677fe90f651a600a747cbabb1/68747470733a2f2f636f6e74726f6c2e726f732e6f72672f6d61737465722f5f696d616765732f726f73325f636f6e74726f6c5f6f766572766965772e706e67)\n](https://camo.githubusercontent.com/44338401d929f48a49bb091228514f5df1a55f1677fe90f651a600a747cbabb1/68747470733a2f2f636f6e74726f6c2e726f732e6f72672f6d61737465722f5f696d616765732f726f73325f636f6e74726f6c5f6f766572766965772e706e67)\n\n#####  Task\n\nBranch: ` 8-write-controller/task `\n\nWrite a controller for _RRBot_ robot that takes joint displacements as input\nand updates new joint positions for it.\n\n  1. Add controller files into the ` controlko_controllers ` package. \n\n  2. During the implementation take care about the following details: \n\n    * How is data exchanged between the controller's callbacks and the ` update ` method? \n\n    * How are statuses from controller published to ROS topics? \n\n    * Controller should have a _slow mode_ where displacements are reduced to half. \n\n    * Controller accepts a command only once. \n\n  3. Write a controller that uses ` control_msgs/msg/JointJog ` message for the input. \n\n    * Check the definition of [ ` JointJog ` message ](https://github.com/ros-controls/control_msgs/blob/galactic-devel/control_msgs/msg/JointJog.msg)\n    * Alternatively use the CLI command: ` ros2 interface show control_msgs/msg/JointJog `\n    * Use [ Writing a new controller manual ](https://control.ros.org/master/doc/ros2_controllers/doc/writing_new_controller.html) to implement the controller \n\n**TIPP** : ` RosTeamWS ` tool has some scripts that can help you solve this\ntask faster. Resources:\n\n  * [ Creating a new package ](https://stoglrobotics.github.io/ros_team_workspace/master/use-cases/ros_packages/create_package.html)\n  * [ Setup controller package ](https://stoglrobotics.github.io/ros_team_workspace/master/use-cases/ros2_control/setup_controller.html) \\- choose setup of \"normal\" controller \n\n#####  Solution\n\nBranch: ` 8-write-controller/solution `\n\nFirst check the code:\n\n  * _ros2_control_ is now using PickNik's [ generate_parameter_library ](https://github.com/PickNikRobotics/generate_parameter_library) so simpler and cleaner parameters usage and definition. \n    * parameters are defined in [./src/displacement_controller.yaml] file \n    * example controller setup is in: \n      * [./test/displacement_controller_params.yaml] - when controller is used directly with the hardware \n      * [./test/displacement_controller_preceeding_params.yaml] - when controller is used at the beginning of the chain (see the next task for details!) \n\nExecute the following commands to see the new controller running:\n\n  1. ` ros2 launch controlko_bringup rrbot.launch.py `\n\n##  About\n\nNo description, website, or topics provided.\n\n###  Resources\n\nReadme\n\n###  License\n\nApache-2.0 license\n\n[ Activity  ](/ros-controls/roscon2022_workshop/activity)\n\n[ Custom properties  ](/ros-controls/roscon2022_workshop/custom-properties)\n\n###  Stars\n\n[ **91** stars ](/ros-controls/roscon2022_workshop/stargazers)\n\n###  Watchers\n\n[ **9** watching ](/ros-controls/roscon2022_workshop/watchers)\n\n###  Forks\n\n[ **23** forks ](/ros-controls/roscon2022_workshop/forks)\n\n[ Report repository ](/contact/report-\ncontent?content_url=https%3A%2F%2Fgithub.com%2Fros-\ncontrols%2Froscon2022_workshop&report=ros-controls+%28user%29)\n\n##  [ Releases ](/ros-controls/roscon2022_workshop/releases)\n\nNo releases published\n\n##  [ Packages  0  ](/orgs/ros-\ncontrols/packages?repo_name=roscon2022_workshop)\n\nNo packages published  \n\n##  [ Contributors  4  ](/ros-\ncontrols/roscon2022_workshop/graphs/contributors)\n\n  *   *   *   * \n\n##  Languages\n\n  * [ C++  55.9%  ](/ros-controls/roscon2022_workshop/search?l=c%2B%2B)\n  * [ Python  31.7%  ](/ros-controls/roscon2022_workshop/search?l=python)\n  * [ CMake  7.9%  ](/ros-controls/roscon2022_workshop/search?l=cmake)\n  * [ C  4.5%  ](/ros-controls/roscon2022_workshop/search?l=c)\n\n##  Footer\n\n[ ](https://github.com \"GitHub\") \u00a9 2024 GitHub, Inc.\n\n###  Footer navigation\n\n  * [ Terms ](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [ Privacy ](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [ Security ](/security)\n  * [ Status ](https://www.githubstatus.com/)\n  * [ Docs ](https://docs.github.com/)\n  * [ Contact ](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.\n\n"
  },
  {
    "id": "gazebo/humble.txt",
    "content": "Skip to content\n\nToggle navigation\n\n[ ](https://github.com/)\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2FUniversalRobots%2FUniversal_Robots_ROS2_Gazebo_Simulation%2Ftree%2Fhumble)\n\n  * Product \n\n    * [ Actions  Automate any workflow  ](/features/actions)\n    * [ Packages  Host and manage packages  ](/features/packages)\n    * [ Security  Find and fix vulnerabilities  ](/features/security)\n    * [ Codespaces  Instant dev environments  ](/features/codespaces)\n    * [ Copilot  Write better code with AI  ](/features/copilot)\n    * [ Code review  Manage code changes  ](/features/code-review)\n    * [ Issues  Plan and track work  ](/features/issues)\n    * [ Discussions  Collaborate outside of code  ](/features/discussions)\n\nExplore\n\n    * [ All features ](/features)\n    * [ Documentation  ](https://docs.github.com)\n    * [ GitHub Skills  ](https://skills.github.com/)\n    * [ Blog  ](https://github.blog)\n\n  * Solutions \n\nFor\n\n    * [ Enterprise ](/enterprise)\n    * [ Teams ](/team)\n    * [ Startups ](/enterprise/startups)\n    * [ Education  ](https://education.github.com)\n\nBy Solution\n\n    * [ CI/CD & Automation ](/solutions/ci-cd/)\n    * [ DevOps ](/solutions/devops/)\n    * [ DevSecOps  ](https://resources.github.com/devops/fundamentals/devsecops/)\n\nResources\n\n    * [ Learning Pathways  ](https://resources.github.com/learn/pathways/)\n    * [ White papers, Ebooks, Webinars  ](https://resources.github.com/)\n    * [ Customer Stories ](/customer-stories)\n    * [ Partners  ](https://partner.github.com/)\n\n  * Open Source \n\n    * [ GitHub Sponsors  Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project  GitHub community articles  ](/readme)\n\nRepositories\n\n    * [ Topics ](/topics)\n    * [ Trending ](/trending)\n    * [ Collections ](/collections)\n\n  * [ Pricing ](/pricing)\n\nSearch or jump to...\n\n#  Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[ Search syntax tips ](https://docs.github.com/search-github/github-code-\nsearch/understanding-github-code-search-syntax)\n\n#  Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n##  Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [ documentation\n](https://docs.github.com/search-github/github-code-search/understanding-\ngithub-code-search-syntax) .\n\nCancel  Create saved search\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2FUniversalRobots%2FUniversal_Robots_ROS2_Gazebo_Simulation%2Ftree%2Fhumble)\n\n[ Sign up\n](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-\nname%3E%2F%3Crepo-name%3E%2Ffiles%2Fdisambiguate&source=header-\nrepo&source_repo=UniversalRobots%2FUniversal_Robots_ROS2_Gazebo_Simulation)\n\nYou signed in with another tab or window. [ Reload ]() to refresh your\nsession.  You signed out in another tab or window. [ Reload ]() to refresh\nyour session.  You switched accounts on another tab or window. [ Reload ]() to\nrefresh your session.  Dismiss alert\n\n{{ message }}\n\n[ UniversalRobots ](/UniversalRobots) /  **[\nUniversal_Robots_ROS2_Gazebo_Simulation\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation) ** Public\n\n  * [ Notifications ](/login?return_to=%2FUniversalRobots%2FUniversal_Robots_ROS2_Gazebo_Simulation)\n  * [ Fork  21  ](/login?return_to=%2FUniversalRobots%2FUniversal_Robots_ROS2_Gazebo_Simulation)\n  * [ Star  41  ](/login?return_to=%2FUniversalRobots%2FUniversal_Robots_ROS2_Gazebo_Simulation)\n\n  * \n\n###  License\n\n[ BSD-3-Clause license\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/ros2/LICENSE)\n\n[ 41  stars\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/stargazers) [ 21\nforks ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/forks) [\nBranches  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/branches)\n[ Tags  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/tags) [\nActivity  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/activity)\n\n[ Star\n](/login?return_to=%2FUniversalRobots%2FUniversal_Robots_ROS2_Gazebo_Simulation)\n\n[ Notifications\n](/login?return_to=%2FUniversalRobots%2FUniversal_Robots_ROS2_Gazebo_Simulation)\n\n  * [ Code  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/tree/humble)\n  * [ Issues  7  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/issues)\n  * [ Pull requests  7  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/pulls)\n  * [ Actions  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/actions)\n  * [ Projects  0  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/projects)\n  * [ Security  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/security)\n  * [ Insights  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/pulse)\n\nAdditional navigation options\n\n  * [ Code  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/tree/humble)\n  * [ Issues  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/issues)\n  * [ Pull requests  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/pulls)\n  * [ Actions  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/actions)\n  * [ Projects  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/projects)\n  * [ Security  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/security)\n  * [ Insights  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/pulse)\n\n#  UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\nhumble\n\n[ Branches\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/branches) [ Tags\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/tags)\n\n[ ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/branches) [\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/tags)\n\nGo to file\n\nCode\n\n##  Folders and files\n\nName  |  Name  |\n\nLast commit message\n\n|\n\nLast commit date  \n  \n---|---|---|---  \n  \n##  Latest commit\n\n##  History\n\n[ 29 Commits\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/commits/humble/)\n\n[ ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/commits/humble/)  \n  \n###\n\n[ .github/  workflows\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/tree/humble/.github/workflows\n\"This path skips through empty directories\")\n\n|\n\n###\n\n[ .github/  workflows\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/tree/humble/.github/workflows\n\"This path skips through empty directories\")\n\n|\n\n|  \n  \n###\n\n[ ur_simulation_gazebo\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/tree/humble/ur_simulation_gazebo\n\"ur_simulation_gazebo\")\n\n|\n\n###\n\n[ ur_simulation_gazebo\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/tree/humble/ur_simulation_gazebo\n\"ur_simulation_gazebo\")\n\n|\n\n|  \n  \n###\n\n[ .clang-format\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/humble/.clang-\nformat \".clang-format\")\n\n|\n\n###\n\n[ .clang-format\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/humble/.clang-\nformat \".clang-format\")\n\n|\n\n|  \n  \n###\n\n[ .pre-commit-config.yaml\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/humble/.pre-\ncommit-config.yaml \".pre-commit-config.yaml\")\n\n|\n\n###\n\n[ .pre-commit-config.yaml\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/humble/.pre-\ncommit-config.yaml \".pre-commit-config.yaml\")\n\n|\n\n|  \n  \n###\n\n[ CONTRIBUTING.md\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/humble/CONTRIBUTING.md\n\"CONTRIBUTING.md\")\n\n|\n\n###\n\n[ CONTRIBUTING.md\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/humble/CONTRIBUTING.md\n\"CONTRIBUTING.md\")\n\n|\n\n|  \n  \n###\n\n[ LICENSE\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/humble/LICENSE\n\"LICENSE\")\n\n|\n\n###\n\n[ LICENSE\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/humble/LICENSE\n\"LICENSE\")\n\n|\n\n|  \n  \n###\n\n[ README.md\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/humble/README.md\n\"README.md\")\n\n|\n\n###\n\n[ README.md\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/humble/README.md\n\"README.md\")\n\n|\n\n|  \n  \n###\n\n[ Universal_Robots_ROS2_Gazebo_Simulation.humble.repos\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/humble/Universal_Robots_ROS2_Gazebo_Simulation.humble.repos\n\"Universal_Robots_ROS2_Gazebo_Simulation.humble.repos\")\n\n|\n\n###\n\n[ Universal_Robots_ROS2_Gazebo_Simulation.humble.repos\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/humble/Universal_Robots_ROS2_Gazebo_Simulation.humble.repos\n\"Universal_Robots_ROS2_Gazebo_Simulation.humble.repos\")\n\n|\n\n|  \n  \n###\n\n[ ci_status.md\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/humble/ci_status.md\n\"ci_status.md\")\n\n|\n\n###\n\n[ ci_status.md\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/humble/ci_status.md\n\"ci_status.md\")\n\n|\n\n|  \n  \nView all files  \n  \n##  Repository files navigation\n\n  * README \n  * License \n\n#  Universal_Robots_ROS2_Gazebo_Simulation\n\nExample files and configurations for Gazebo Classic simulation of Universal\nRobots' manipulators.\n\n##  Build status\n\n|  Humble  |  Iron  |  Rolling  \n---|---|---|---  \nBranch  |  [ humble\n](https://github.com/UniversalRobots/Universal_Robots_ROS2_Description/tree/humble)\n|  [ ros2\n](https://github.com/UniversalRobots/Universal_Robots_ROS2_Description/tree/ros2)\n|  [ ros2\n](https://github.com/UniversalRobots/Universal_Robots_ROS2_Description/tree/ros2)  \nBuild status  |  [ ![Humble Binary\nMain](https://github.com/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/actions/workflows/humble-\nbinary-main.yml/badge.svg?event=schedule)\n](https://github.com/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/actions/workflows/humble-\nbinary-main.yml?query=event%3Aschedule++)  \n|  [ ![Iron Binary\nMain](https://github.com/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/actions/workflows/iron-\nbinary-main.yml/badge.svg?event=schedule)\n](https://github.com/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/actions/workflows/iron-\nbinary-main.yml?query=event%3Aschedule++)  \n|  [ ![Rolling Binary\nMain](https://github.com/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/actions/workflows/rolling-\nbinary-main.yml/badge.svg?event=schedule)\n](https://github.com/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/actions/workflows/rolling-\nbinary-main.yml?query=event%3Aschedule++)  \n  \n  \nA more [ detailed build status\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/humble/ci_status.md)\nshows the state of all CI workflows inside this repo. Please note that the\ndetailed view is intended for developers, while the one here should give end\nusers an overview of the current released state.\n\n##  Known issues\n\n\u26a0\ufe0f  The UR5 (non-e-series) model seems to be broken at the moment. Please see\n[ #34\n](https://github.com/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/issues/34)\n\u26a0\ufe0f\n\nAll other models should be working correctly.\n\n##  Using the repository\n\nSkip any of below steps is not applicable.\n\n###  Setup ROS Workspace\n\n  1. Create a colcon workspace: \n    \n        export COLCON_WS=~/workspaces/ur_gazebo\n    mkdir -p $COLCON_WS/src\n    \n\n> **NOTE:** Feel free to change ` ~/workspaces/ur_gazebo ` to whatever\n> absolute path you want.\n\n> **NOTE:** Over time you will probably have multiple ROS workspaces, so it\n> makes sense to them all in a subfolder. Also, it is good practice to put the\n> ROS version in the name of the workspace, for different tests you could just\n> add a suffix to the base name ` ur_gazebo ` .\n\n  2. Download the required repositories and install package dependencies: \n    \n        cd $COLCON_WS\n    git clone git@github.com:UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation.git src/Universal_Robots_ROS2_Gazebo_Simulation\n    vcs import src --input src/Universal_Robots_ROS2_Gazebo_Simulation/Universal_Robots_ROS2_Gazebo_Simulation.<ros-distro>.repos\n    rosdep install --ignore-src --from-paths src -y\n    cd ..\n    \n\n###  Configure and Build Workspace:\n\nTo configure and build workspace execute following commands:\n\n    \n    \n    cd $COLCON_WS\n    colcon build --symlink-install --mixin rel-with-deb-info compile-commands ccache\n    \n\n##  Running Simulation\n\n    \n    \n    ros2 launch ur_simulation_gazebo ur_sim_control.launch.py\n    \n\nMove robot using test script from ` ur_robot_driver ` package (if you've\ninstalled that one):\n\n    \n    \n    ros2 launch ur_robot_driver test_joint_trajectory_controller.launch.py\n    \n\nExample using MoveIt with simulated robot:\n\n    \n    \n    ros2 launch ur_simulation_gazebo ur_sim_moveit.launch.py\n    \n\n##  About\n\nNo description, website, or topics provided.\n\n###  Resources\n\nReadme\n\n###  License\n\n[ BSD-3-Clause license\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/blob/ros2/LICENSE)\n\n[ Activity\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/activity)\n\n[ Custom properties\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/custom-properties)\n\n###  Stars\n\n[ **41** stars\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/stargazers)\n\n###  Watchers\n\n[ **13** watching\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/watchers)\n\n###  Forks\n\n[ **21** forks\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/forks)\n\n[ Report repository ](/contact/report-\ncontent?content_url=https%3A%2F%2Fgithub.com%2FUniversalRobots%2FUniversal_Robots_ROS2_Gazebo_Simulation&report=UniversalRobots+%28user%29)\n\n##  [ Releases\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/releases)\n\nNo releases published\n\n##  [ Packages  0\n](/orgs/UniversalRobots/packages?repo_name=Universal_Robots_ROS2_Gazebo_Simulation)\n\nNo packages published  \n\n##  [ Contributors  3\n](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/graphs/contributors)\n\n  * [ ![@fmauch](https://avatars.githubusercontent.com/u/491645?s=64&v=4) ](https://github.com/fmauch) [ **fmauch** Felix Exner (fexner)  ](https://github.com/fmauch)\n  * [ ![@destogl](https://avatars.githubusercontent.com/u/1918204?s=64&v=4) ](https://github.com/destogl) [ **destogl** Dr. Denis  ](https://github.com/destogl)\n  * [ ![@urrsk](https://avatars.githubusercontent.com/u/41109954?s=64&v=4) ](https://github.com/urrsk) [ **urrsk** Rune S\u00f8e-Knudsen  ](https://github.com/urrsk)\n\n##  Languages\n\n  * [ Python  98.4%  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/search?l=python)\n  * [ CMake  1.6%  ](/UniversalRobots/Universal_Robots_ROS2_Gazebo_Simulation/search?l=cmake)\n\n##  Footer\n\n[ ](https://github.com \"GitHub\") \u00a9 2024 GitHub, Inc.\n\n###  Footer navigation\n\n  * [ Terms ](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [ Privacy ](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [ Security ](/security)\n  * [ Status ](https://www.githubstatus.com/)\n  * [ Docs ](https://docs.github.com/)\n  * [ Contact ](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.\n\n"
  },
  {
    "id": "crazy_file_add_variable/Report2020Undergradu.txt",
    "content": "Research Report\nQuadrotor Visual Servoing\nFor Moving Target Tracking\nMECN4006 - Research Project\nEdward Rycroft\nStudent Number: 1478715\nSupervisor: Ms. C. Kuchwa-Dube\nA project report submitted to the Faculty of Engineering and the Built Environment, University of the\nWitwatersrand, Johannesburg, in partial fulfilment of the requirements for the degree of Bachelor of\nScience in Engineering (Mechanical).\nJohannesburg, October 2019\nABSTRACT\nAn investigation into position-based visual servoing through end-point open-loop control was conducted for estimation of the three-dimensional position and yaw orientation of a moving target using\na single camera, where a Bitcraze Crazyflie 2.1 quadrotor then tracked this position and yaw orientation autonomously. Moreover, inexpensive and low-end hardware with marginal computational effort\nwas used in the form of a Raspberry Pi Zero W 1.1 and Raspberry Pi Camera Module 2.1 for image\nprocessing with OpenCV to utilise computer vision techniques. Comparing grayscale and colour processing for initial target detection, it was evident that grayscale processing allowed for an increased\nframe rate compared to colour processing by an average percentage difference of 23.2% while also\neliminating more background noise for a better interpretation of the target. During the implementation, it was found that the most satisfactory resolution was 160px by 120px for lightweight processing,\nwhere the capability to generate setpoints for the quadrotor was at a frequency of 30.1Hz. The pinhole\ncamera model was also validated and successfully implemented at a resolution of 160px by 120px\nwhich resulted in a focal length of 113.5px found through experimental calibration. This allowed for\nthe pinhole camera model to be used to develop a control script to reconstruct the state of the target\nrelative to the camera with the centroid of the target providing latitude and longitude coordinates, area\nof the target providing the altitude of the camera, and rotation providing the yaw orientation when\nusing a disproportioned marker. With this information, the quadrotor was able to successfully mirror the translational and rotational motion of the target while maintaining the altitude of the camera.\nOver eight independent tests, the real-time effectiveness was captured by a Qualisys motion capture\nsystem and exhibited an average lag of 0.732s, average position deviations of 83.4mm, minimum yaw\norientation deviation of 9.54o\n, and maximum yaw orientation deviation of 9.87o\n. However, if the\naverage lag is compensated in each test, the average position deviation reduces to only 54.0mm, while\nthe minimum and maximum yaw orientation deviations reduce to only 4.76o\nand 4.46o\nrespectively.\nAn altitude could also be maintained effectively, where the quadrotor only drifted by an average of\n3.75% downwards or 3.98% upwards before returning to the correct altitude.\nii\nLIST OF CONTENTS\nIndividual Declaration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . i\nAbstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ii\nList of Contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iii\nList of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vi\nList of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . viii\nList of Symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ix\nList of Acronyms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xii\n1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.2 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n1.3 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n2 Literature Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n2.1 Visual Servoing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n2.2 Quadrotor Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.3 Raster Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.4 Pinhole Camera Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.5 Computer Vision . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.6 Location Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n2.7 Control Principles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3 Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4 Apparatus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n4.1 Quadrotor Parts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n4.2 Visual Servoing Parts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n4.3 Moving Target Parts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n4.4 Motion Capture Facilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\niii\n4.5 Ground Control Laptop . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n4.6 Software . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n4.6.1 Crazyflie . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n4.6.2 OpenCV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n4.6.3 Raspbain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n4.6.4 Arduino . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n5 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.1 Initial Camera Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n5.2 Initial Quadrotor Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n5.3 Target Detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n5.4 Target Tracking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n5.5 Control And Communication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.6 Target Motion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n5.7 Data Monitoring . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n6 Data Analysis And Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n6.1 Camera Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n6.2 Image Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n6.3 Camera Calibration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n6.4 Quadrotor Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n6.5 Visual Servoing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n6.5.1 Primitive Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n6.5.2 Results Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n7 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n7.1 Camera And Processing Factors . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n7.2 Visual Servoing Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n7.3 Other Findings And Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\niv\n8 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n9 Recommendations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\nA Additional Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\nB Control Scripts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\nC Ethics Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\nD Risk Assessment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\nE BigQuad Development . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\nE.1 End-Point Closed-Loop Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\nE.2 BigQuad Apparatus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\nv\nLIST OF FIGURES\n1 Examples of the common multirotor layouts with a general layout of a front view . . . . 1\n2 Examples of end-point closed-loop control and end-point open-loop control . . . . . . . 2\n3 Comparison between the methods of position-based and image-based visual servoing . . 4\n4 Coordinate system relative to the quadrotor showing translation and rotation . . . . . . . 5\n5 Plus-mode (+) rotor arrangement to enable translation and rotation . . . . . . . . . . . . 6\n6 Cross-mode (\u00d7) rotor arrangement to enable translation and rotation . . . . . . . . . . . 7\n7 Conversion between two reference frames with translation and rotation . . . . . . . . . . 8\n8 Rasterisation of a real object with high and low resolutions . . . . . . . . . . . . . . . . 9\n9 Simplification of a model for a pinhole camera with a lens and imaging sensor . . . . . . 9\n10 Geometric relationships resulting from the pinhole camera model . . . . . . . . . . . . . 10\n11 Fish-eye distortion model in a field of view and example of fish-eye distortion . . . . . . 11\n12 Example of an image from a camera in original colour and with processing . . . . . . . 13\n13 Arrangement for end-point open-loop control through target detection and tracking . . . 15\n14 General schematic of an open-loop control system without feedback . . . . . . . . . . . 16\n15 General schematic of a closed-loop control system with feedback . . . . . . . . . . . . . 16\n16 Outline and interactions of the apparatus from a broad overview. . . . . . . . . . . . . . 18\n17 Photographs showing the assembled Bitcraze Crazyflie 2.1 quadrotor . . . . . . . . . . . 19\n18 Schematics and photographs showing the Bitcraze Crazyflie 2.1 control board . . . . . . 20\n19 Interactions of the microcontrollers and sensors on the Bitcraze Crazyflie 2.1 . . . . . . 21\n20 Photographs showing the Bitcraze Flow V2 expansion deck . . . . . . . . . . . . . . . . 21\n21 Schematics and photographs showing the Raspberry Pi Zero and Camera Module . . . . 23\n22 Photographs showing the Bitcraze Crazyradio PA . . . . . . . . . . . . . . . . . . . . . 24\n23 Photographs showing the Dagu S4A EDU, Dagu DG02S Motor, and target assembly . . 24\n24 Photographs showing the SG90 Micro Servo motor and yawing target assembly . . . . . 25\n25 Photographs showing a Qualisys Miqus M1 and layout of the motion capture facilities . 26\n26 Open-source software used for visual servoing, quadrotor control, and target control . . . 27\n27 Method of calibrating the camera and determining the focal length . . . . . . . . . . . . 32\nvi\n28 Tracking of the target with the corresponding movement of the Crazyflie . . . . . . . . . 35\n29 Coordinate system transformation to convert the initial system into the desired system . . 35\n30 Explanation of the initial yaw orientation and desired coordinate system . . . . . . . . . 36\n31 High-level flow diagram of the control flow for the target detection and tracking . . . . . 37\n32 Paths on which the target will aim to move to test various motions . . . . . . . . . . . . 38\n33 Photograph and evaluation of the fish-eye distortion in the Pi Camera . . . . . . . . . . . 40\n34 Example frames captured at 160px by 120px, 320px by 240px, and 640px by 480px . . . 42\n35 Rasterisation at 160px by 120px for the disk and rectangle targets . . . . . . . . . . . . 43\n36 Example frames captured at 160px by 120px for the camera calibration . . . . . . . . . 44\n37 Altitude calibration using a disk as the target with a radius of 95mm . . . . . . . . . . . 44\n38 Altitude calibration using a rectangle as the target with edges of 140mm by 95mm . . . . 45\n39 Position of the markers in the first (top) and second (bottom) trials of the rectilinear test . 46\n40 Position of the markers in the first and second trials of the circular test . . . . . . . . . . 47\n41 Position of the markers in the first (top) and second (bottom) trials of the combined test . 47\n42 Relevant results against time throughout the first trial of the rectilinear motion test . . . . 48\n43 Relevant results against time throughout the second trial of the rectilinear motion test . . 49\n44 Relevant results against time throughout the first trial of the circular motion test . . . . . 49\n45 Relevant results against time throughout the second trial of the circular motion test . . . 50\n46 Relevant results against time throughout the first trial of the combined motion test . . . . 50\n47 Relevant results against time throughout the second trial of the combined motion test . . 51\n48 Relevant results against time throughout the first trial of the yaw orientation test . . . . . 53\n49 Relevant results against time throughout the second trial of the yaw orientation test . . . 53\n50 Deviations with adjustments for average lag in the translation and rotation tests . . . . . 54\n51 Standard operating procedure in the motion capture facilities . . . . . . . . . . . . . . . 84\n52 Arrangement for end-point closed-loop control through detection and tracking of a target. 85\n53 Comparison between the field of view during rolling or pitching . . . . . . . . . . . . . 85\n54 Schematic and photographs showing the Bitcraze BigQuad expansion deck . . . . . . . 86\n55 Photographs showing the assembled larger quadrotor . . . . . . . . . . . . . . . . . . . 86\nvii\nLIST OF TABLES\n1 Quantity and mass of the components used to assemble the moving target . . . . . . . . 25\n2 Evaluation of the most suitable resolution for acceptable real-time performance . . . . . 41\n3 Outline of the lag and position deviation of the Crazyflie for the translation tests . . . . . 52\n4 Outline of the lag and angular deviation of the Crazyflie for rotation tests . . . . . . . . . 52\n5 Outline of the altitude of the Crazyflie for each of the translation and rotation tests . . . . 55\n6 Evaluation of the potential risks involved in the experiment . . . . . . . . . . . . . . . . 83\nviii\nLIST OF SYMBOLS\nThe general symbols used, with a description and relevant units, are as follows:\na first arbitrary variable -\nAuv virtual image area px2\nAxy actual area m2\nb second arbitrary variable -\nb(t) feedback signal -\nd+ plus-mode moment arm m\nd\u00d7 cross-mode moment arm m\nDxy latitude and longitude position deviation m\nD\u03c8 yaw orientation deviation rad or o\ne(t) error signal -\nf focal length px\nf(t) control signal -\nF resultant thrust N\nFM1 motor one thrust N\nFM2 motor two thrust N\nFM3 motor three thrust N\nFM4 motor four thrust N\ng gravitational acceleration; or grayscale value 9.807m/s2\n; or -\ngnew new grayscale value -\ngthr grayscale threshold value -\nh hue value -\nhmax maximum hue value -\nhmin minimum hue value -\nH height px\nIx mass moment of inertia about x-axis kg.m2\nIy mass moment of inertia about y-axis kg.m2\nIz mass moment of inertia about z-axis kg.m2\nk camera correlation coefficient m.px\nKD derivative gain -\nKI\nintegral gain -\nKP proportional gain -\nl lightness value -\nlmax maximum lightness value -\nlmin minimum lightness value -\nm mass; or arbitrary virtual image distance kg; or px\nix\nm\u02d9 arbitrary virtual image velocity px/s\n\u00b5 air molar mass 0.02896kg/mol\nn arbitrary actual distance m\nn\u02d9 arbitrary, actual velocity m/s\np pressure; or pixel colour value Pa; or -\np0 pressure at the lower troposphere limit 101350Pa\n%pa actual percentage difference %\n%pm magnitude percentage difference %\n\u03c6 roll rotation rad or o\n\u03c6\u00a8 roll angular acceleration rad/s2\n\u03c8 yaw rotation or orientation rad or o\n\u03c8i\ninitial yaw orientation rad or o\n\u03c8q quadrotor yaw angle rad or o\n\u03c8t\ntarget yaw angle rad or o\n\u03c8\u00a8 yaw angular acceleration rad/s2\nrH longitude resolution px\nrW latitude resolution px\nr(t) reference signal -\nR universal gas constant 8.315kg.m2\n/(s2\n.mol.K)\ns saturation value -\nsmax maximum saturation value -\nsmin minimum saturation value -\nt time s\nT temperature K\nT0 temperature at the lower troposphere limit 288.15K\nTM1 motor one torque N.m\nTM2 motor two torque N.m\nTM3 motor three torque N.m\nTM4 motor four torque N.m\nT\u03c6,+ plus-mode roll torque N.m\nT\u03c6,\u00d7 cross-mode roll torque N.m\nT\u03c8,+ plus-mode yaw torque N.m\nT\u03c8,\u00d7 cross-mode yaw torque N.m\nT\u03b8,+ plus-mode pitch torque N.m\nT\u03b8,\u00d7 cross-mode pitch torque N.m\n\u03c4 incremental time placeholder s\n\u03c40 temperature gradient within the lower troposphere 0.0065K/m\n\u03b8 pitch rotation rad or o\nx\n\u03b8\u00a8 pitch angular acceleration rad/s2\nu virtual image latitude coordinate or distance px\nui\ninitial latitude coordinate px\nv virtual image longitude coordinate or distance px\nvi\ninitial longitude coordinate px\nW width px\nx actual latitude coordinate or distance m\nxq quadrotor latitude position m\nxt\ntarget latitude position m\ny actual longitude coordinate or distance m\nyq quadrotor longitude position m\nyt\ntarget longitude position m\nz altitude m\nzsea altitude relative to sea level m\nz\u00a8 acceleration along z-axis m/s2\nThroughout the report, the relevant description and units are displayed with the symbols presented in\nequations. If there is a discrepancy or confusion between the displayed information and this listed\ninformation, the displayed information should be assumed to supersede this listed information.\nxi\nLIST OF ACRONYMS\nThe general acronyms used, with a corresponding description, are as follows:\n3D Three-Dimensional\nAMD Advanced Micro Devices\nAPI Application Programming Interface\nBGR Blue, Green, and Red\nBLE Bluetooth Low Energy\nCCD Charge-Coupled Device\nCPPM Chaotic Pulse Position Modulation\nCPU Central Processing Unit\nCMOS Complementary Metal-Oxide Semiconductor\nCSI Camera Serial Interface\nD Derivative\nDC Direct Current\nDOF Degrees Of Freedom\nEEPROM Electrically Erasable Programmable Read Only Memory\nESC Electronic Speed Controller\nFAST Feature from Accelerated Segment Test\nFPS Frames Per Second\nGPIO General Purpose Input/Output\nGPS Global Positioning System\nGUI Graphical User Interface\nHDMI High-Definition Multimedia Interface\nHLS Hue, Lightness, and Saturation\nHP Hewlett-Packard\nHSI Human System Interactions\nHVS Hue, Value, and Saturation\nI Integral\nIBVS Image-Based Visual Servoing\nICUAS International Conference on Unmanned Aircraft Systems\nIDE Integrated Development Environment\nIEEE Institute of Electrical and Electronics Engineers\nIMU Inertial Measurement Unit\nI2C inter-Integrated Circuit\nLAN Local Area Network\nLED Light Emitting Diode\nLiPo Lithium-Polymer\nxii\nMIMO Multiple-Input Multiple-Output\nMOCAP Motion Capture\nNIR Near Infra-Red\nNoIR No Infra-Red\nP Proportional\nPCM Pinhole Camera Model\nPI Proportional-Integral\nPD Proportional-Derivative\nPID Proportional-Integral-Derivative\nPBVS Position-Based Visual Servoing\nPPE Personal Protective Equipment\nPRX Primary Receiver Mode\nPTX Primary Transmitter Mode\nPWM Pulse Width Modulation\nQTM Qualisys Track Manager\nRAM Random Access Memory\nRDP Remote Desktop Protocol\nRGB Red, Green, and Blue\nRTOS Real-Time Operating System\nSD Secure Digital\nSIFT Scale-Invariant Feature Transform\nSPF Seconds Per Frame\nSPI Serial Peripheral Interface\nSRAM Static Random Access Memory\nSSH Secure Shell\nSURF Speeded-Up Robust Features\nToF Time-of-Flight\nUART Universal Asynchronous Receiver/Transmitter\nUAV Unmanned Aerial Vehicle\nUSB Universal Serial Bus\nWiFi Wireless Fidelity\nThroughout the report, the relevant description is displayed with the first appearance of uncommon\nacronyms. If the acronym is commonly known or may be better known by the acronym itself, the\nacronym is used directly with the first appearance, such is the case for USB and HDMI as examples.\nxiii\n1 INTRODUCTION\nIn industries requiring dynamic surveillance, inspection, or exploration, it is often useful to accurately\ntrack moving targets with an unmanned aerial vehicle (UAV) using visual servoing. These industries\ninclude activities involving photography, cinematography, traffic and transportation, surveying, mapping, search and rescue, navigation, and agriculture, with increasing presence in the evolution of the\nfourth industrial revolution [1]. So, it is necessary to establish an initial basis for visual servoing using\nan UAV and infer if there are reasons for further investigation into moving target tracking.\n1.1 BACKGROUND\nA multirotor is generally regarded as an unmanned rotorcraft or rotary-wing aircraft which generates\nthrust and motion using two or more fixed-pitch rotors as actuators and allows for simpler rotor mechanics required for flight control using sensors, as compared to other types of aircraft [2]. A quadrotor\nis a multirotor with four rotors and propellers, where the size may typically vary with propeller diameters from 45mm for small aircraft to 480mm for large aircraft and the cost may relatively vary from\neconomical for hobbies to extravagant for specialised activities [2]. A variety of multirotor layouts,\nincluding a quadrotor, are seen in Figure 1. (Occasionally, the terms \u201cmulticopter\u201d and \u201cquadcopter\u201d\nare used to refer to a multirotor or quadrotor respectively, but from linguistic perspectives and origins,\nit is actually more accurate to use the terms \u201cmultirotor\u201d and \u201cquadrotor\u201d respectively [3]).\nPropellers\nStands\nFront View\nFrame\nTrirotor Quadrotor Hexarotor Octarotor\nFigure 1: Examples of the common multirotor layouts for three (left), four (left-middle), six (middle),\nand eight (right-middle) rotors with a general layout of a front view (right).\nWith regards to a quadrotor, visual servoing for moving target tracking is essentially the technique in\nwhich the motion of the quadrotor is controlled by commands generated based on a passive visionbased sensor. This visual servoing may be in the form of end-point closed-loop or eye-in-hand control\nwith a camera mounted on-board the quadrotor to observe the relative position and motion of a target. An alternative method of visual servoing is end-point open-loop or eye-to-hand control, where\nmultiple external cameras are fixed in the surroundings and form a motion capture system observing\nthe absolute position and motion of a target. These methods are demonstrated in Figure 2.\nTo distinguish within visual servoing, target detection is concerned with using a captured image to\nidentify a designated target, while target tracking is concerned with recognising the movements of the\n1\nEnd-Point Closed-Loop Control End-Point Open-Loop Control\nQuadrotor\nTarget Camera\nViews\nCamera\nQuadrotor\nTarget Camera\nView\nCamera\nFigure 2: Examples of end-point closed-loop control (left) and end-point open-loop control (right).\ndesignated target. Particularly, the target is identified through image processing with computer vision\ntechniques based on distinct features such as colours, areas, edges, corners, and centroids. However,\nthis becomes more difficult with a moving target where variable factors become apparent, which can\npossibly include changes in the target movement, colour pattern, and structure or geometry, with\nconcurrent changes in the background environment and camera tilting orientations.\n1.2 MOTIVATION\nDue to their growing importance and utility, quadrotors are an important part of the robotics and engineering fields of research with the incorporation of knowledge from mechanics, aviation, electronics, and computer science [4]. Additionally, the incorporation of visual servoing with quadrotors has\nbecome highlighted when signals from global positioning systems (GPS) are unreliable or unavailable in indoor environments [5, 6]. The various methods of implementing visual servoing through\ncomputer vision have been extensively developed and show promising results with regards to target\ndetection - this is especially evident in systems with end-point closed-loop control, as successfully\ndemonstrated by Rabah et al. [1], Dunkley [2], Karlsson [6], and Kendall et al. [7] for examples.\nHowever, there are still challenges with regards to implementing visual servoing through end-point\nopen-loop control with only a single camera, such that a quadrotor is able to achieve optimal moving\ntarget tracking in three-dimensions while maintaining fully autonomous flight without manual inputs\nfrom a user. This is a difficult challenge as it requires the extraction of three-dimensional information from a two-dimensional vantage point. Moreover, a significant focus of published research into\ncomputer vision is only involved with isolating or segmenting targets for detection, while the more\nspecific research into end-point open-loop control has been to integrate flight control and indirect\ncomputer vision techniques using motion capture systems with multiple cameras triangulating position, which can be expensive and difficult to access, and utilises systems with excess computational\neffort for image processing without taking into account the possibility of substantial limits on the\navailable computational effort [1, 8, 9]. This is discussed by Mahony et al. [3] using a Vicon motion\ncapture system requiring considerable resources for state estimation of an Ascending Technologies\n2\nquadrotor; and Dunkley [2] and Mack et al. [10] utilised a Microsoft Kinect as an economic alternative to detect and control a Bitcraze Crazyflie quadrotor, but this features two cameras and a depth\nsensor while still accessing excess computational effort on their ground control laptops - unlike most\nof the end-point closed-loop control studies, these studies do not consider tracking moving targets.\nFurthermore, a critical disadvantage of end-point open-loop control is the requirement for the external\ncameras to already be set up, where this would present an obstacle if operating in an unfamiliar\nenvironment since the setting up of multiple cameras may be tedious or inapplicable, but the use of\na single camera would be much more efficient. Thus, there is a need to investigate the detection and\ntracking of a moving target using end-point open-loop control with only a single camera, which will\nreinforce the success of published research with fundamental similarities as a consequence.\n1.3 PROBLEM STATEMENT\nIt is necessary to develop and assess the effectiveness of a control system using end-point open-loop\nvisual servoing with a single camera to autonomously perform real-time moving target tracking. The\ncamera is to be fixed in the surroundings and the tests should be initially performed in a controlled\nindoor environment. The detection of the target will be carried out using computer vision through\nvarious techniques, but this needs to be processed using hardware with limited or marginal computational effort which will likely require a self-derived algorithm utilising lightweight image processing.\nThe tracking of the target will be performed such that a quadrotor effectively follows or mirrors the\nmovement of the target in a manner where the position of the target can be seen to be mapped directly\nby the position of the quadrotor. This tracking should focus on the three degrees of translational freedom, but it may be possible to also track the orientation of the target with regards to yaw or rotation in\nthe horizontal plane, depending on the arrangement. The relative distance error between the position\nof the target and position of the quadrotor should be minimised within an acceptable range for successful implementation. The effectiveness can then be measured based on the lag time, robustness,\nrelative distance fluctuations, and ability to track the target at varying speeds. For supplement, this\nshould be achieved using mostly inexpensive and open-source hardware and software.\nThus, a research question is proposed: is it possible to implement end-point open-loop visual servoing\nin a three-dimensional space using a fixed single camera for moving target tracking with limited\ncomputational effort for image processing and a quadrotor following the movements of the target?\n2 LITERATURE REVIEW\nTo establish a basis from which to progress, existing research and resources for quadrotors and computer vision with regards to visual servoing for target tracking needs to be reviewed and documented.\nIt is also essential to understand certain theory and ideas behind the apparatus and methodology which\nwill be used, such that these concepts can be identified if they do arise even though they are not expected to be direct factors during the tests and in the results. Although many of the concepts discussed\n3\nare generally applicable to visual servoing through other means as well, it should be noted that the\ninformation will be presented primarily in relation to quadrotors and target tracking.\n2.1 VISUAL SERVOING\nDue to the aim of the research, there will be a focus on visual servoing through end-point open-loop\ncontrol, rather than end-point closed-loop control. This may employ position-based visual servoing\nor image-based visual servoing. For position-based visual servoing, information is extracted from an\nimage based on features in the image and used to reconstruct the current three-dimensional position of\nthe target, where this can then be combined with the knowledge about the three-dimensional position\nof the quadrotor to generate control and actuation corrections such that the quadrotor moves to the\ndesired position to follow the target [5]. For image-based visual servoing, an error signal is computed\ndirectly from the features in an image, without performing a three-dimensional reconstruction, where\nthis error signal is then used to generate control and actuation corrections to match the current image\nfeatures with a desired arrangement [5]. It is also possible to use a mixed scheme with a combination\nof aspects from both position-based visual servoing and image-based visual servoing [5].\nConsidering position-based visual servoing, the primary advantage is the convenience of generating\na setpoint as an absolute coordinate in three-dimensional space, but the primary disadvantage is the\nuncertainty in the results of the three-dimensional reconstruction since there is a dependence on the\noptical parameters, calibration of the vision system, and requisite knowledge about the dimensions of\nthe target prior to implementation. Considering image-based visual servoing, the primary advantage\nis the insensitivity of the results to camera calibration, but the primary disadvantage is the necessity to\nrelate the features in the image to actions through non-linear or empirical relationships. The methods\nof position-based visual servoing and image-based visual servoing are illustrated in Figure 3 for an\nimage, where these processes can then be repeated for each frame in a sequence.\nMotion Track\nController\nImage / Video\nProcessing\nError\nCurrent Image\nDetect\nDesired Image\nCompare\nSetpoint\nMotion Track\nController\n3D Position\nReconstruction\nExtract Compare Current Image\nError\nDesired 3D\nPosition Setpoint\nPosition-Based\nVisual Serviong\nImage-Based\nVisual Serviong\nFigure 3: Comparison between the basic methods of position-based visual servoing (top) and imagebased visual servoing for an image - this process is then repeated for each frame in a sequence.\n4\n2.2 QUADROTOR DYNAMICS\nAs briefly mentioned, a quadrotor is a rotorcraft with four rotors which have fixed pitches and are\nused to create motion by varying the thrust generated at each rotor [2]. The rotors usually consist of\npropellers or blades in the form of aerofoils which are mounted on high-speed direct current (DC) motors, while the other parts of a typical quadrotor include a battery as the power source, various sensors\nto estimate real-time position or velocity, cross frame holding the parts, and flight controller for stabilisation [2]. The very basic sensors include an inertial measurement unit, where a gyroscope stabilises\nrotational motion and an accelerometer detects the current orientation - although these sensors alone\nmay lead to cumulative errors over time which will result in drifting with an ever-increasing difference between the estimated state and actual state [2]. More advanced and accurate sensors include\non-board ultrasonic or laser range finders to measure distances, GPS for precise location, barometers\nto measure air pressure changes with altitude, magnetometers to determine which direction is north,\nand monocular or stereo camera for measurements relative to the environment being observed [2].\nWith these parts, a quadrotor is able to vertically take-off and land with exceptional abilities to hover\nat a fixed position and simultaneously manoeuvre vertically, latitudinally, and longitudinally.\nWith regards to the motion of the quadrotor, there are three degrees of freedom for translational displacement, which include forward or backward, left or right, and up or down; and three degrees of\nfreedom for rotational displacement, which include roll, pitch, and yaw. These motions can be illustrated on a conventional coordinate system relative to the quadrotor, as shown in Figure 4, where\ntranslation along the x-axis, y-axis, and z-axis correspond to the translation displacements respectively\nand rotation about the x-axis, y-axis, and z-axis correspond to the rotational displacements respectively. Thus, there is a total of six degrees of freedom for the quadrotor.\nYaw Rotation\nUp / Down\nRoll Rotation\nForward /\nBackward\nPitch Rotation\nLeft / Right\nx\nz\ny\nYaw Rotation\nUp / Down\nRoll Rotation\nForward /\nBackward\nPitch Rotation\nLeft / Right\nx\nz\ny\nM1 M2\nM4 M3\nM1\nM2\nM3\nM4\nFigure 4: Coordinate system relative to the quadrotor showing the three translational and three rotational displacements. The quadrotor may operate in a plus-mode (+) (left) or cross-mode (\u00d7) (right).\n5\nThe quadrotor is then able to generate these degrees of freedom by varying the thrust generated by\neach of the four rotors, as seen in Figure 5 and Figure 6, such that a simple mechanical design can be\nused with a complex controller design. With regards to forces, each rotor produces an upwards thrust,\ntorque about the centre of rotation, and drag opposite to the motion of the quadrotor. To move up or\ndown along the z-axis, the thrust simply needs to be increased or decreased respectively. To move\nforward or backward along the x-axis, the thrust needs to be maintained while pitching clockwise\nor counter-clockwise about the y-axis respectively. To move left or right along the y-axis, the thrust\nneeds to be maintained while rolling counter-clockwise or clockwise about the x-axis respectively.\nThe roll and pitch control will depend on whether the quadrotor is using a plus-mode (+) or crossmode (\u00d7), but the manner of operation is identical where a resultant torque is produced to induce\nrolling or pitching. Considering a plus-mode, the roll with rotation about the x-axis is controlled by\nthe left and right rotors, where the left rotor thrust needs to be greater than the right rotor thrust to\nroll clockwise and the right rotor thrust needs to be greater than the left rotor thrust to roll counterclockwise; and the pitch with rotation about the y-axis is controlled by the front and rear rotors, where\nthe rear rotor thrust needs to be greater than the front rotor thrust to pitch clockwise and the front rotor\nthrust needs to be greater than the rear rotor thrust to pitch counter-clockwise (clockwise and counterclockwise directions are taken relative to the perspective of the quadrotor along the x-axis for rolling\nand y-axis for pitching). For the cross-mode, the side selection of rotors for rolling and pitching is\nidentical, but the rotors will be used in pairs without intermediate rotors.\nFinally, yawing with rotation about the z-axis is created using the resulting torque produced from the\nrotors spinning against the air, where the direction of this torque is in the opposite direction to the\ndirection of the combined angular velocity from the rotors - for flight without yawing, this effect is\nMedium Speed\nStationary Hover Move Up Move Down\nPitch Forward Pitch Backward Roll Left Roll Right Yaw Left\nYaw Right\nLow Speed\nForward Direction\nLeft Direction\nHigh Speed\nM1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nFigure 5: Plus-mode (+) rotor arrangement to enable the translational and rotational displacements.\n6\ncancelled by letting the two diagonally-opposite rotors spin clockwise while the other two diagonallyopposite rotors spin counter-clockwise [2, 8]. So, when yawing is desired in a certain direction, the\nangular velocities of the two rotors spinning in the opposite direction are decreased and the angular\nvelocities of the two rotors spinning in the same direction are increased, which will create rotation\nabout the z-axis such that the total thrust remains constant without rolling or pitching [2, 8].\nStationary Hover Move Up Move Down\nPitch Forward Pitch Backward Roll Left Roll Right Yaw Left\nYaw Right\nMedium Speed\nLow Speed\nForward Direction\nLeft Direction\nHigh Speed M1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nM1\nM2\nM3\nM4\nFigure 6: Cross-mode (\u00d7) rotor arrangement to enable the translational and rotational displacements.\nFor further understanding, a simplified analytical model of a quadrotor is given by Equation 1, which\ndescribes the resultant thrust acting on the quadrotor from the thrust of each rotor, and Equation 2 to\nEquation 4 for plus-mode or Equation 5 to Equation 7 for cross-mode, which respectively describe the\nresultant torque acting on the quadrotor while rolling, pitching, and yawing. These relationships are\nfairly basic and present an ideal model, which can be implemented using the inherent relationships\nbetween thrust, torque, and supplied voltage for each rotor determined experimentally [11].\nF = FM1 + FM2 + FM3 + FM4 \u2212\u2192 F \u2212 mg = mz\u00a8 (1)\nT\u03c6,+ = d+(FM4 \u2212 FM2) = Ix\u03c6\u00a8 (2)\nT\u03b8,+ = d+(FM3 \u2212 FM1) = Iy\u03b8\u00a8 (3)\nT\u03c8,+ = TM1 + TM3 \u2212 TM2 \u2212 TM4 = Iz\u03c8\u00a8 (4)\nT\u03c6,\u00d7 = d\u00d7((FM3 + FM4) \u2212 (FM1 + FM2)) = Ix\u03c6\u00a8 (5)\nT\u03b8,\u00d7 = d\u00d7((FM2 + FM3) \u2212 (FM1 + FM4)) = Iy\u03b8\u00a8 (6)\nT\u03c8,\u00d7 = TM1 + TM3 \u2212 TM2 \u2212 TM4 = Iz\u03c8\u00a8 (7)\nWhere F, resultant thrust, N; FM1, motor one thrust, N; FM2, motor two thrust, N; FM3, motor\nthree thrust, N; FM4, motor four thrust, N; m, mass, kg; g, gravitational acceleration, 9.807m/s2\n; z\u00a8,\nacceleration along z-axis, m/s2\n; T\u03c6,+, plus-mode roll torque, N.m; d+, plus-mode moment arm, m;\nIx, mass moment of inertia about x-axis, kg.m2\n; \u03c6\u00a8, roll angular acceleration, rad/s2\n; T\u03b8,+, plus-mode\npitch torque, N.m; Iy, mass moment of inertia about y-axis, kg.m2\n; \u03b8\u00a8, pitch angular acceleration,\n7\nrad/s2\n; T\u03c8,+, plus-mode yaw torque, N.m; TM1, motor one torque, N.m; TM2, motor two torque, N.m;\nTM3, motor three torque, N.m; TM4, motor four torque, N.m; Iz\n, mass moment of inertia about zaxis, kg.m2\n; \u03c8\u00a8, yaw angular acceleration, rad/s2\n; T\u03c6,\u00d7, cross-mode roll torque, N.m; d\u00d7, cross-mode\nmoment arm, m; T\u03b8,\u00d7, cross-mode pitch torque, N.m; and T\u03c8,\u00d7, cross-mode yaw torque, N.m.\nWhen considering the representation of a quadrotor or another body with six degrees of freedom in\nthree-dimensional space, it is possible to use a reference frame with a coordinate system either fixed\nto an observer or fixed to the quadrotor [2, 6, 11]. For an observer-fixed reference frame, it is assumed\nthat the observer as the origin is arbitrarily on the surface of the Earth, which is seen to be flat and\nstationary. For a body-fixed reference frame, the centre of gravity of the quadrotor is conditioned as\nthe origin, which is convenient when accounting for inertial properties. Followingly, the conversion\nbetween the observer-fixed and quadrotor-fixed reference frame can be seen as a relative transformation which is divided into the difference in distance along each axis and then the change in rotational\nangles described by Figure 7 to produce a rotation matrix in Equation 8 [2, 6, 11].\nD =\n\uf8ee\n\uf8ef\n\uf8ef\n\uf8f0\ncos(\u03b8) cos(\u03c8) cos(\u03b8) sin(\u03c8) \u2212 sin(\u03b8)\nsin(\u03c6) sin(\u03b8) cos(\u03c8) \u2212 cos(\u03b8) sin(\u03c8) sin(\u03c6) sin(\u03b8) sin(\u03c8) + cos(\u03c6) cos(\u03c8) sin(\u03c6) cos(\u03b8)\ncos(\u03c6) sin(\u03b8) cos(\u03c6) + sin(\u03c6) sin(\u03c8) cos(\u03c6) sin(\u03b8) sin(\u03c8) \u2212 sin(\u03c6) cos(\u03c8) cos(\u03c6) cos(\u03b8)\n\uf8f9\n\uf8fa\n\uf8fa\n\uf8fb\n(8)\nWhere \u03b8, pitch rotation, rad or o\n; \u03c8, yaw rotation, rad or o\n; and \u03c6, roll rotation, rad or o\n.\nx1\ny1\nz Translational 1\nTransformation\nRotational\nTransformation\nz\ny\nx y\nz\nx1\ny1\nz1\nx2\ny2\nz2\nx2\ny2\nz2\nx\nx, y, z\nFigure 7: Demonstration of the conversion between two reference frames with translation (left) and\nrotation (right). (In this context, the rotational angles can also be referred to as Euler angles).\n2.3 RASTER IMAGES\nA raster image or bitmap is composed of multiple pixels with the amount of pixels in the horizontal\nand vertical direction forming a rectangular grid and resolution. The process of rasterisation involves\nrepresenting a real object or vector image in the form of a raster image, where the continuous data\ndescribing the real object or vector image is converted into discrete data for representation through\n8\nthe raster image. However, there will always be information lost during rasterisation due to the\ndiscretization error arising from a limit in the ability to completely render the continuous data. The\ndegree to which information is lost is dependent on the construction and resolution of the raster\nimage, which is a principal concern for lower resolutions when features reduce in quality and cannot\nbe resolved. The process of rasterisation and rendering a raster image is demonstrated in Figure 8.\nReal Object\n(Vector Image)\nHigh Resolution\nRasterisation\nLow Resolution\nRasterisation\nFigure 8: Demonstration of the rasterisation of a real object with high and low resolutions. (Although\nthe original image of the real object is actually a raster image, its resolution is sufficiently large to\navoid raster artefacts and it serves as a view from an observer for this demonstration).\n2.4 PINHOLE CAMERA MODEL\nIn fundamental terms, digital cameras capture raster images by measuring the amount and wavelength\nor colour of light projected onto an imaging sensor with pixels (analogue cameras will not be considered) [2]. This imaging sensor is usually a charge-coupled device (CCD) or a complementary\nmetal-oxide semiconductor (CMOS) array [2, 6, 12]. As abridged in Figure 9, there will be rays of\nlight emitted from each point on the target. This light will spread and be incident on the lens of the\ncamera which will then focus the light to the corresponding points on the imaging sensor. So, it is\nessential for the lens to be located at the exact focal length to ensure the light is focussed to a singular\npoint, rather than distorted or blurred discs which create an unclear image [2].\nLens\nOptical\nCentre\nTarget\nSurface\nImage\nSensor\nVirtual\nImage\nPlane\nFocal Length Focal Length\nPinhole Camera Model Light\nRays Through Optical Centre\nAperture\n=\nFigure 9: Simplification of a model for a pinhole camera with a lens and imaging sensor.\nFor simplification while maintaining reasonable accuracy, a pinhole model can be considered for the\ncamera, where it is assumed that the rays of light only pass through the optical centre of the lens or, in\n9\nother words, the rays of light not passing through the optical centre of the lens are neglected - this is\nequivalent to an infinitesimal point as the aperture [2]. With this model, each ray of light can be seen\nto travel in a straight line from the target to the imaging sensor and, for final simplification, the virtual\nimage plane can be considered with the uninverted projection [2]. Thus, these assumption allow for\nthe image to be regarded as a graphically equivalent description of the observed environment without\ndistortions or blurring, which is fairly valid as long as the lens is accurately located at the focal length.\nUsing the pinhole model and considering the virtual image plane, the associated relationship between\ndistances in the image can be related to actual distances in three-dimensional space. This is essentially\nbased on geometrically similar triangles formed by the rays of light between the actual point, projection on the virtual image plane, and optical centre of the lens, as explained in Figure 10 to produce\nEquation 9 [2, 6]. As a result, Equation 10 describes the latitude relationships and Equation 11 describes the longitude relationship, where the focal length is a parameter of the camera and the virtual\nimage coordinates can be found from the image. Thus, the pinhole model can be seen as a first-order\napproximation for the mapping of the observed environment. (If the real image plane is considered,\nit is either necessary to redefine the directions or use a negative sign with the relationships).\nf\nz\n=\nu\nx\n=\nv\ny\n(9)\n(u, v)\n(x, y)\nu\nv\ny\nx\nPrincipal\nPoint\nz\nLens With\nInfinitesimal\nPoint Apeture\nOptical\nCentre\nVirtual\nImage\nPlane\nTarget\nPoint\nPlane\nf = Focal Length\nz = Altitude\nFigure 10: Geometric relationships resulting from the pinhole camera model.\n10\nu = f\nx\nz\n(10)\nv = f\ny\nz\n(11)\nWhere f , focal length, px; z, altitude, m; u, virtual image latitude coordinate, px; x, actual latitude\ncoordinate, m; v, virtual image longitude coordinate, px; and y, actual longitude coordinate, m.\nIf the pinhole model is valid, straight lines in reality are projected as straight lines on the imaging\nsensor - rectilinearity is preserved [2]. If the pinhole model is not valid due to excessive distortions,\nthese distortions will create radial and tangential inaccuracies in the image. The radial inaccuracies\nresult in straight lines appearing curved, while the tangential inaccuracies occur because the lens is\nnot aligned perfectly parallel to the imaging plane so some areas in the image appear nearer than\nexpected. It is most common for fish-eye distortion with large radial exaggerations towards the edges\nof the field of view, as described by Figure 11, where this distortion is usually more pronounced on\nwide angle lenses with large fields of view which capture a greater portion of the environment [2].\nThe distortion present in the actual images will need to be tested with the camera and deemed to be\ninsignificant without the need for compensation or significant with the need for compensation.\nra = Realistic Radial Distance From Principal Point\nrd = Distorted Radial Distance From Principal Point\nSignificant Fish-Eye Distortion\nFocal\nLength\nProjection\nSphere\nLight Ray\nz\nLight Rays\nOptical Centre\nrd\nra\nx or y\nPrincipal Point\nImage\nPlane\nFigure 11: Fish-eye distortion model representing projections of rays of light in a wide field of view\n(left). Example of an image from a camera with very significant fish-eye distortion (right) [2].\nSimilarly, for the common type of camera, a rolling shutter mechanism is used and the image is not\nactually captured at a single instant, but rather the imaging sensor sequentially scans through the\nfield of view either horizontally or vertically over a very short time period [2, 12]. As a result, there\nis an opportunity for distortions to arise due to a target moving during the scanning process, which\nwould result in an inaccurate representation of the target in the captured image through shearing,\nsmearing, or deforming - although it should be emphasised that the speed of the target needs to be\nexceptionally high for a significant effect [2, 12]. These effects are avoided with a global shutter\nmechanism which captures the entire field of view in a single instant, but this is usually only available\non high-performance cameras. There are in-depth methods to compensate for rolling shutter, but for\n11\nthe operating speeds in this research, it can confidently be assumed that there will be no distortions\nfrom rolling shutter and the camera essentially performs as though it has a global shutter.\n2.5 COMPUTER VISION\nComputer vision focusses on gaining high-level understanding from images and basically uses a sequence of consecutive images, where each frame is processed and relevant information is extracted.\nThe camera used for target detection and tracking may be monocular with a single lens for monoscopic vision or binocular with two lenses for stereoscopic vision. The advantage of a binocular\ncamera is that three-dimensional information can be extracted more accurately since the environment\ncan be compared from two vantage points, but this comes at a much higher cost. However, only a\nmonocular camera is available and, so, only monoscopic vision from a single vantage point will be\nconsidered. Notably, other sensors could actually be used to achieve a similar overall result of target\ndetection and tracking, with methods based on sound, lasers, optics, or tactile interaction [2].\nThe image from the camera will require processing in order to detect the target in the image, with\nexamples of this processing seen in Figure 12. A colour image is described by an array of red,\ngreen, and blue (RGB) 8-bit integers for each pixel between 0 for each minimum and 255 for each\nmaximum (alternative colour modes are available which offer advantages in different situations, such\nas hue, value, and saturation (HVS)). The image can be converted to grayscale where each pixel is\ndescribed by a single scalar as an 8-bit integer for each pixel between 0 for black and 255 for white,\nwhich is usually performed to reduce the required computational effort when processing an image\n[13]. Blurring can also be performed through convolving the image with a low-pass filter, which is\nusually employed to aid in noise reduction [13]. Thresholding aims to provide a simple method of\nsegmenting a grayscale image, where a binary image is created using only 0 as black, which is applied\nwhen the value of a pixel is below a threshold value, and 1 as white, which is applied when the value\nof a pixel is above a threshold value [13]. After applying a threshold, a morphology transformation\ncan be performed to further noise reduction - this uses an erosion transformation to remove noise of\nwhite value or dilation transformation to connect regions of white value [13].\nTo develop basic target detection and shape analysis, there are existing algorithms for detecting edges\nusing high-pass or gradient filters, such as the Canny edge detection which is a multi-stage algorithm\nwith noise reduction, gradient intensity finding, non-maximum suppression, and hysteresis thresholding [13]. Alternatively, it is possible to implement contour finding to locate curves joining the continuous points which have the same colour or intensity along a boundary - these curves can then be\nused to analyse the centroid, area, orientation, and other characteristics of the target [13]. The level\nof image processing can vary depending on the situation, where minimal processing will reduce the\ndelay before the response commands can be executed, but excessive processing will be more reliable\nwith more computational effort and heavier algorithms for more accurate results [14].\n12\nOriginal Colour Grayscale Smooth Blur Binary Threshold\nMorphology Transform Edge Detection Contour Finding\nR: 73, G: 62, B: 128\nR: 190\nG: 182\nB: 145\nR: 96\nG: 153\nB: 172\nR: 191\nG: 136\nB: 142\nR: 184\nG: 137\nB: 173\nFigure 12: Example of an image from a camera in original colour and with processing through grayscaling, blurring, thresholding, morphology transforming, edge detecting, and contour finding.\nFor more specific target detection, target recognition is considered to be concerned with recognising the designated target based on learnt features. There are common algorithms which include\ncolour-based matching, template matching, meanshift, camshift (continuously adaptive meanshift),\nand corner detection. The overall techniques and methods of these algorithms are briefly explored:\n\u2022 The colour-based matching algorithm simply compares the colour in patches of an image against\na specific colour range for the target in an attempt to find a match within the range [13, 14]. This\nalgorithm usually requires for the target to be a single colour and may produce false-positives\nwhen there are other objects of similar colours within the image [13, 14].\n\u2022 The template matching algorithm compares patches of an image against a specific template for\nthe target in an attempt to find a match based on a flexible threshold for success [13, 14]. For\nimproved performance, multiple scaled and rotated templates of the target may be considered\n[13, 14]. However, this is likely to be ineffective when the orientation and size of the target\nconstantly changes since many templates and increased computational effort will be required.\n\u2022 The meanshift and camshift algorithms use an initial region of interest of the target separated\nfrom the background in colour mode and then this region is shifted in subsequent frames based on\na local maximum of a probability distribution for the changes in the target location, orientation,\nand size [13, 14]. The camshift algorithm essentially builds on the meanshift algorithm with the\nuse of an adaptive probability distribution to better account for changes in the orientation and\nsize of the target (the meanshift algorithm uses a static probability distribution) [13, 14].\n13\n\u2022 A corner detection algorithm basically considers the change in gradient intensity where corner\nor blob points can be uniquely identified [2, 13]. There are various flavours of corner detection\nalgorithms, such as the Harris, Shi-Tomasi, scale-invariant feature transform (SIFT), speeded-up\nrobust features (SURF), or feature from accelerated segment test (FAST) [2, 13].\nHowever, besides the colour-based matching algorithm, these algorithms generally require a large\namount of computational effort and iterations with multiple frames for success and it is usually not\npossible to perform this processing on low-end hardware while achieving real-time performance [14].\nRegardless of the detection or recognition algorithm, it is essential for the detection algorithm to\nhave repeatability, where the same features of the target should be consistently detected in consecutive frames; distinctiveness, where the features of the target can easily be distinguished using their\nappearance; robustness, where detection is still possible in the presence of distortion or noise; low\ncomputational effort, where the processing must be as fast as possible for real-time operation; scale\ninvariance, where the size of the target does not affect detection (with regards to a reasonable limit);\nillumination invariance, where the lighting or photometry from the environment does not affect detection; and orientation invariance, where the rotation of the target does not affect detection [2].\nAn additional computer vision technique which should be acknowledged is the use of optical flow.\nInstead of directly detecting a specific target, optical flow is concerned with motion detection and\nthe changes in the patterns of features in the environment due to apparent motion caused by relative\nmotion between the camera and environment [13]. Although it may not be useful in target detection,\nan optical flow sensor can be utilised to stabilise a quadrotor by discerning necessary adjustments.\n2.6 LOCATION ESTIMATION\nThe attitude of the quadrotor refers to the angular orientation in three-dimensions and, along with\nthe location in three-dimensions, the state of the quadrotor can then be described by the vertical\naltitude, position in the horizontal plane, and angular arrangement for movement. With regards to\ntarget tracking, the primary concerns are the three translational degrees of freedom, such that the\ndesired altitude and position of the quadrotor relative to the altitude and position of the target can be\ndetermined through position-based visual servoing by processing the captured frame.\nSo, the captured and subsequent frames can be processed to detect the target and find the approximate\narea and centroid of the target as measured in terms of pixels in the frames. Thus, through a pinhole\ncamera model, a reconstruction of the three-dimensional locations can be applied as a method to\nestimate the desired altitude for the quadrotor and current position of the target in terms of distances.\nThis can be pursued with an arrangement similar to that displayed in Figure 13 - although the method\nof estimating the altitude is uncommon and does not directly appear in literature.\nAs mentioned, a complete motion capture system could be used to estimate the absolute position of\nthe target and quadrotor, where multiple external cameras detect reflective infra-red markers attached\n14\nGround\nCamera View\nCamera DOFs\nTarget DOFs\nGround\nQuadrotor mirrors\nthe motion of the\ntarget and altitude\nof the camera.\nCommand Setpoints\nz Quadrotor\nTranslational\nDOFs\nz\nx y\nx y\nMap / Mirror\nPosition From\nTarget Centroid\nFigure 13: Arrangement for end-point open-loop control through detection and tracking of a target.\nto the target and quadrotor, and use triangulation to estimate the position of each marker in threedimensions. To capture three translational degrees of freedom, it is only necessary for at least one\nmarker to be used on a rigid body, but to capture three translational degrees of freedom and three\nrotational degrees of freedom, it is necessary for three or more markers to be used on a rigid body,\npreferably in a non-ambiguous asymmetric arrangement [2]. However, since the aim of the research is\nfocussed on using a single inexpensive camera with a lightweight algorithm, a motion capture system\nwill not be considered for target detection or tracking purposes - although a motion capture system is\navailable and may be used to quantify and validate the effectiveness of the developed system.\n2.7 CONTROL PRINCIPLES\nThe general goal in control theory is to generate a desired setpoint or reference state to achieve a\nmatching output. The control may operate through an open-loop or closed-loop. For open-loop\ncontrol, a desired setpoint is input to a controller as a reference state which generates a corresponding\nsignal for actuators to manipulate the system appropriately, where it is then assumed that the desired\nsetpoint is satisfied in the final output state - in other words, there is no sensor to decide whether the\ndesired setpoint has actually been satisfied [15]. This process is seen in Figure 14. To attain successful\nopen-loop control, the actuation must be repeatable and reliable with the ability to mitigate effects\nfrom disturbances and noise, such that these effects are predictable or become negligible [15]. If the\nopen-loop control is not successful, the error will accumulate over time and rapidly diverge. It is also\nnecessary to discuss closed-loop control for understanding of the flight controller on a quadrotor.\nFor closed-loop control, the current state of the system is accurately estimated through measurements\nfrom the sensors and this state is compared against the desired setpoint to find an error which needs\nto be reduced. The controller then uses this error as an input and outputs the necessary commands\nto correct the state of the system and bring it closer to the reference state. The error should be\nminimised to converge to zero as quickly as possible while the system remains stable, preferably\n15\ns(t) = Setpoint Input\nr(t) = Reference Signal\nf(t) = Control Signal\nm(t) = Manipulated Signal\nn(t) = Resultant Signal\nd(t) = Disturbance Input\nc(t) = Plant Output\nInput\nElement\nControl\nElement\nActuation\nElement\nPlant\nElement\nDisturbance\nElement\n+\ns(t) r(t) f(t) m(t) n(t) c(t)\nd(t)\nForward Direction\nOpen-Loop Control\nFigure 14: General schematic of an open-loop control system without feedback.\nwithout oscillations - although it is unlikely for the error to be completely eliminated due to unknown\nexternal disturbances. This continuous closed-loop is represented in the control system shown in\nFigure 15, where a signal opposite to the forward direction is referred to as feedback.\nInput\nElement\nControl\nElement\nActuation\nElement\nPlant\nElement\nSensing / Feedback\nElement\nDisturbance\nElement\n+ +\ns(t) r(t) e(t) f(t) m(t) n(t) c(t)\nd(t)\nb(t)\nForward Direction\ns(t) = Setpoint Input\nr(t) = Reference Signal\ne(t) = Error Signal\nf(t) = Control Signal\nm(t) = Manipulated Signal\nn(t) = Resultant Signal\nd(t) = Disturbance Input\nc(t) = Plant Output\nb(t) = Feedback Signal\nFeedback\nClosed-Loop Control\nFigure 15: General schematic of a closed-loop control system with feedback.\nFor a quadrotor, the controller will output a velocity command to the rotors in an attempt to correct\nthe state of the system. To obtain satisfactory results, the controller will usually operate based on\na proportional-integral-derivative (PID) control method. The proportional (P) component reacts directly to the magnitude of the current error, where an increased gain will allow for faster response but\nmay exhibit unwanted oscillations [2, 6, 15]. The integral (I) component reacts relative to the accumulation of past errors over time, where there is an increasing effect over time to reach a steady-state\n[2, 6, 15]. The derivative (D) component reacts relative to the rate of change of the error signal with\ntime for a prediction of future errors, where there is a reduction of oscillations by regulating the speed\nof the response and increasing stability [6, 15]. These components utilise Equation 12 for the error\nbetween the setpoint and actual signals with the implementation of PID control in the analytical form\n16\nof Equation 13 or numerical form of Equation 14, where constant parameters or gains are used to\ndistribute the effects of the respective components. There are alternate methods of control, such as\nnon-linear sliding mode control or adaptive backstepping control, but PID control has been proven to\nbe robust and reliable when knowledge of the underlying processes are not known [1, 2, 5]. (It should\nbe noted that, in other situations, it may only be necessary for a subset of the control components,\nsuch as only P, PD, or PI controllers - for 90% of these cases, a PI controller will be sufficient [15]).\ne(t) = r(t) \u2212 b(t) (12)\nf(t) = KPe(t) + KI\nZ t\n0\ne(t) dt + KD\nde(t)\ndt\n(13)\nf(t) \u2248 KPe(t) + KI\nXt\n\u03c4=0\ne(\u03c4) + KD\ne(t) \u2212 e(t \u2212 \u2206t)\n\u2206t\n(14)\nWhere e(t), error signal; r(t), reference signal; b(t), feedback signal; f(t), control signal; t, time, s;\nKP, proportional gain; KI\n, integral gain; KD, derivative gain; and \u03c4, incremental time placeholder, s.\nA quadrotor is a multiple-input multiple-output (MIMO) non-linear system with a high degree of\ncoupling between the input and output variables, multiple aerodynamic effects which are difficult to\nmeasure or model precisely, and a time-varying nature as the battery is discharged and the voltage\ndecreases [11]. Also, from the perspective of control systems, quadrotors are relatively complex to\nstabilise due to noise in sensors, model uncertainty, and other external disturbances [11]. Thus, it is a\nchallenge to design a flight controller for a quadrotor and it is usually required for cascading or nested\nloops of multiple PID controllers directly monitoring and calculating the roll, pitch, yaw, and thrust\nwith required operation at frequencies above 100Hz as a minimum criteria.\nWithout external sensors, it has also been shown that it is practically impossible to obtain stable\ncontrol of a quadrotor, outside of simulations [11]. For unreliable control, the very basic sensors\nthrough an inertial measurement unit, including a gyroscope and accelerometer, are sufficient but\nthe measurements from these sensors are usually noisy and inaccurate with large fluctuations and\nuncertainties. As a result, these basic sensors will not be able to completely compensate for drift\nfrom factors interfering with stability like wind and unbalanced weight distribution [2, 11]. For\nreliable control, it is required for a more advanced sensor which will be able to provide more accurate\nmeasurements of the state of the quadrotor, such as the mentioned sensors in the form of an external\nmotion capture system, optical flow sensor, ultrasonic or laser range finder, GPS, or on-board camera.\n3 OBJECTIVES\nThe primary objectives are defined as follows, with relation to the available apparatus in Section 4:\n\u2022 Validate the accuracy of the pinhole camera model, with compensation for major distortions if\nrequired by the camera. (This will be done with a Raspberry Pi Camera Module 2.1).\n17\n\u2022 Compare target detection through grayscale and colour processing on low-end hardware with\nmarginal computational effort. (A Raspberry Pi Zero W 1.1 will be used as a prime example).\n\u2022 Develop and implement target detection and tracking through end-point open-loop visual servoing using the pinhole camera model and computer vision techniques for image processing on\nlow-end hardware with marginal computational effort, where a quadrotor must remotely track\nthe position of the target in a mirroring fashion while varying its altitude to match the camera.\nThe tracking will be performed for three degrees of translational freedom and one degree of rotational freedom as yaw orientation. (The Raspberry Pi Camera Module 2.1 and Raspberry Pi\nZero W 1.1 will be used along with OpenCV and a Bitcraze Crazyflie 2.1 quadrotor).\n\u2022 Test the effectiveness of the target detection and tracking using an external motion capture system\nwith multiple cameras, where the relative deviation between the desired position from the target\nand actual position of the quadrotor is measured throughout the experimentation. (The motion\ncapture system will comprise of four Qualisys Miqus M1 cameras).\n4 APPARATUS\nThe available apparatus consists of various parts for different systems, as broadly outlined in Figure 16. In these interactions, the quadrotor receives control setpoints from the central processing\nbased on the visual servoing from the camera, while the motion of the target and quadrotor are tracked\nby the motion capture system (to be used only as validation for the effectiveness of the actual target\ntracking of the target by the quadrotor) and information about the current state is reported to a ground\ncontrol laptop for monitoring. Moreover, the basic details of the utilised software need to be briefly\nexplained, because it will form an intrinsic part in implementing the methodology presented in Section 5. Further resources from the manufacturers of the parts are included in Appendix A.\nCamera Processing Quadrotor\nGround Laptop\nMoving Target\nMotion Capture\nArduino Python\nDirect Connection\nIndirect Dependence\nFigure 16: Outline and interactions of the apparatus from a broad overview.\n4.1 QUADROTOR PARTS\nFor the quadrotor, the open-source Bitcraze Crazyflie 2.1 (subsequently referred to as Crazyflie) will\nbe used. This quadrotor consists of a central control board with various on-board sensors (also acting\nas a lightweight frame), four rotor motors, four propellers, four stands, and battery - these components\nare seen in Figure 17 showing the complete assembly. Additionally, expansion decks can be connected\n18\nto the control board for further on-board functionality and sensing, and a 3D printed propeller guard\nmay be mounted with three 12mm motion capture markers - this leads to an additional payload of 7g\nwhich is below the supported additional payload of 14g. (Unfortunately, the motion capture markers\ncould not be placed asymmetrically elsewhere as instability arose with unpredictable drift, but the\nchosen placement is acceptable since the yaw measurements will be accurate and are more important\nthan the roll and pitch measurements which may be adversely affected).\nTop Isometric View Bottom Isommetric View\nFlow\nDeck\nContorl\nBoard\n(Frame)\nBattery\nConnection\nForward\nIndicator\nRotors\nLanding Stands\nStand\nRotor\nContorl\nBoard\nBattery\nForward\nLanding Stands\nRotors\nRotor\nStand\n29mm\nStand\n92mm\n92mm\nPropeller Guard\nSingle MOCAP Marker\nHolder\nFigure 17: Photographs showing various isometric views of the assembled Bitcraze Crazyflie 2.1\nquadrotor, including the Bitcraze Flow V2 expansion deck mounted at the bottom viewing the ground.\nThe control board, seen in Figure 18 with the basic schematics and photographs, executes the control setpoints for the motion of the quadrotor with the flashable firmware and on-board sensors. The\nfirmware for the real-time operating system is based on the FreeRTOS kernel, which handles the\nscheduling of processes and calculations for the flight control - FreeRTOS is also open-source [4, 16].\nThis board has diagonals of 80mm and a mass of approximately 7g using a symmetric form factor\nand is equipped with a STM32F405 microcontroller as the main processor (Cortex-M4, 168MHz,\n192kB SRAM, and 1MB flash), nRF51822 microcontroller for radio interfacing and power management (Cortex-M0, 32Mhz, 16kB SRAM, and 128kB flash), 2.4GHz ISM band radio with 20dBm\nor 100mW low-noise amplifier, 8kB EEPROM, Bluetooth low energy (BLE) module for interfacing\nthrough a smartphone application client, micro-USB Type-B for charging or interfacing over a wired\nconnection, BMP388 pressure barometer, BMI088 inertial measurement unit containing a three-axis\ngyroscope and three-axis accelerometer, and JST-DS connector for connection to the battery [4, 6,\n16, 17]. The processor and radio chips exchange data over an internal link protocol using UART as\na physical interface, while the processor and sensors exchange data over I2C, PWM, and SPI - these\ninteractions are illustrated in Figure 19 [4, 6, 16]. There is also an integrated attitude and heading\nreference system with an extended Kalman filter to provide a fairly reliable estimation of the current\nstate of the quadrotor with regards to position, velocity, angular arrangement, and stability [4, 16].\n19\nTop View Bottom View\n56.56mm 56.56mm\n56.56mm\nMotor Port\nMotor Port\nMotor Port Coordinate\nSystems\nMotor Port\nBattery\nWires\nLED M4 LED M1\nLED M3 LED M2\nForward\nIndicator Switch\nPin Holes Pin Holes\nRadio Controller\nProcessor\nController\nForward\nIndicator\nPin Holes\nPin Holes\nBattery\nWires\nFigure 18: Schematics (top) and photographs (bottom) showing the top and bottom views of the\nBitcraze Crazyflie 2.1 control board with the arrangement of the various sensors [18].\nThe Crazyflie is capable of a maximum speed up to 1.41m/s, although oscillations may be introduced\nif the Crazyflie needs to stop suddenly at a specific location. To achieve steady flight control and\nmaintain its orientation, the control board implements internal cascading PID controllers for attitude\ncontrol of position and velocity. In the cascade, there is an inner loop operating at 500Hz to control\nthe thrust and angular velocity of roll, pitch, and yaw, and there is an outer loop operating at 250Hz\nto control the roll, pitch, and yaw angles for altitude and position control with stabilisation [2, 6, 16].\nThese controllers are conventionally described by Equation 13 and Equation 14, and have been tuned\nwith default values based on the common construction of the Crazyflie for stable and agile flight.\nThe on-board sensors are sufficient to stabilise the orientation of the Crazyflie, but there will be a\nlarge uncertainty in position - in other words, it is possible for the on-board gyroscope and accelerometer to maintain the orientation and the on-board barometer could be used to estimate the altitude\nrelative to sea level with Equation 15 based on pressure and temperature measurements, but this is\nextremely noisy and will be inaccurate [2, 11]. To accurately stabilise the position of the Crazyflie, it\nis required for additional sensors to perform measurements relative to the external environment [16].\n20\nMotor Drivers\nProcess Microcontroller\nPower Management\nProtection Circuit Mod.\nMicro-USB Charging\nLiPo Battery\nRadio Microcontroller\nPower Push Button\nBarometer\nGyroscope\nAccelerometer\nPWM\nI2C SPI\nBrushed Motors\nBluetooth Module\nEEPROM\nUART\nFigure 19: Interactions of the on-board microcontrollers and sensors of the Bitcraze Crazyflie 2.1.\nSo, the Bitcraze Flow V2 expansion deck (subsequently referred to as Flow deck) in Figure 20 will\nbe mounted at the bottom on the control board to provide steady flight by detecting motion in any\ndirection, which can then compensate for unwanted motion or measure desired motion [19]. The\nFlow deck uses a VL53L1x ToF sensor for laser-ranging and measuring the altitude to the ground up\nto 4m with a field of view of 25o\nand an accuracy on the order of millimetres, and a PMW3901 sensor\nto employ optical flow and measure movements of the ground with a field of view of 42o\n[19].\nzsea =\n\u0012\nT\n\u03c40\n\u0013\n1 \u2212\n\u0012\np\np0\n\u0013\u2212R\u03c40/(\u00b5g)\n!\n=\n\u0012\nT\n0.0065K/m\u0013 \u00121 \u2212\n\u0010 p\n101325Pa\n\u00110.19026\u0013\n(15)\nWhere zsea, altitude relative to sea level, m; T, temperature, K (if this cannot be measured, T0 as the\ntemperature at the lower troposphere limit may be used, 288.15K); \u03c40, temperature gradient within\nthe lower troposphere, 0.0065K/m; p, pressure, Pa; p0, pressure at the lower troposphere limit, 21mm Top View Bottom View\nLaser Ranger\nOptical Flow\n28mm 28mm\nPin Holes\nForward\nFigure 20: Photographs showing the top and bottom views of the Bitcraze Flow V2 expansion deck.\n21\n101350Pa; R, universal gas constant, 8.315kg.m2\n/(s2\n.mol.K); \u00b5, air molar mass, 0.02896kg/mol; and\ng, gravitational acceleration, 9.807m/s2\n. This is an approximation of the hypsometric formula [2].\nThe rotor motors, propellers, and battery are briefly mentioned, although there is only minimal information available. The rotor motors are generic brushed DC motors, which are coreless and provide\nfast accelerations and angular velocities up to approximately 21000rev/min [4, 16]. The propellers\nhave a length of 45mm and are made from plastic to mitigate the possibility of damages occurring\nduring a collision or crash. The battery is lithium-polymer (LiPo), supplies 3.7V, and has a capacity of\n250mA.hr with a discharge rate of approximately 15C for a continuous flight time of approximately\n7min, depending on the manoeuvres performed - there is also an internal protection circuit module to\npreserve the cycle life and prevent over-charging, under-charging, and shorting [4, 16, 17].\n4.2 VISUAL SERVOING PARTS\nTo perform visual servoing and image processing, the mentioned Raspberry Pi Zero W 1.1 (subsequently referred to as Raspberry Pi) and Raspberry Pi Camera Module 2.1 (subsequently referred\nto as Pi Camera) will be used. The Raspberry Pi is a single-board computer with a mass of 8g, wireless LAN 802.11n, and Bluetooth 4.1, and features a 1.0GHz BCM2835 single-core CPU, 512MB of\nRAM, 40-pin GPIO header, micro-SD card slot for flash memory (a SanDisk 16GB micro-SD card\nwill be used), mini-HDMI port for display, micro-USB port for power at 0.140A and 5.1V (with the\nPi Camera, the required current may increase so a supply capable of 2.1A will be used), micro-USB\nport for peripherals, and CSI camera connector for communication with the Pi Camera [20].\nThe Pi Camera is designed to detect frequencies of light over the visible light range and has a mass\nof 3g, focal length of 3.04mm, focal ratio of 2.0, latitudinal field of view of 62.2o\n, and longitudinal\nfield of view of 48.8o\n[21]. For the imaging sensor, the Pi Camera uses an 8Mpx Sony IMX219 with\nsquare pixels of 1.12\u00b5m and support for photograph resolutions up to 3280px by 2464px and video\nresolutions up to 1920px by 1080px with 30fr/s, 1280px by 720px at 60fr/s, or 640px by 480px at\n90fr/s (or a lower resolution can be chosen, but the maximum frames rate is 90fr/s) [21]. The basic\nschematics and photographs of the Raspberry Pi and Pi Camera are seen in Figure 21.\nFortunately, the Pi Camera aims to have little to no noticeable fish-eye distortion. However, the Pi\nCamera does use a rolling shutter where frames are rapidly scanned vertically and, as a result, the\nframes may be somewhat susceptible to various distortion effects, which are especially pronounced\nwhen the relative speed of the target is very high and related to the magnitude of the seconds per frame\ncaptured by the camera. As mentioned, there are methods to model and compensate for distortions\nfrom rolling shutter, but these are expected to be unnecessary since it is not crucial for exceptional\ndetail and the discrepancies are expected to be very minimal at the operating speeds.\nThe communication between the Raspberry Pi and Crazyflie will be facilitated by a Bitcraze Crazyradio PA (subsequently referred to as Crazyradio), which is a USB Type-A radio dongle, has a mass\n22\nBottom View\n65mm 23.9mm\n30mm\n25mm\nRaspberry Pi Camera Module 2.1\nTop View Bottom View\nStandard Connection\nLens, Image Sensor\nThe 150mm camera\ncable converts the\nstandard connection at\nthe Pi Camera to the\nmini-connection at the\nRaspberry Pi Zero.\nRaspberry Pi Zero W 1.1\nMicro-USB Power\nMicro-USB Input\nMini-HDMI Output\nMicro-SD Card Slot\nCam. Mini-Connect\nSingle-Core CPU\n40 GPIO Header\nTop View\n150mm\n30mm\n25mm\nTop View\nFigure 21: Schematics (bottom) and photographs (top) showing the top and bottom views of the\nRaspberry Pi Zero W 1.1 (left) and Raspberry Pi Camera Module 2.1 (right) [22, 23].\nof 6g, and features a nRF24LU1+ radio microcontroller (16MHz, 2kB SRAM, and 32kB flash) with\na 20dBm or 100mW low-noise amplifier for communication through the 2.4GHz ISM band radio at\nfrequencies from 2.400GHz to 2.525GHz for 125 channels [16, 24]. The communication data rates\ncan be set at 250kB/s, 1MB/s, or 2MB/s and the data sizes can be up to packets of 32B for low latency,\nwhile the ideal range can exceed 1km under normal conditions with a direct line-of-sight and without\ninterference or obstacles [16, 24]. The minimum latency to send a packet is estimated to be about\n2ms with 1ms for the USB serial communication and 1ms measured latency for the radio at 2MB/s\nwithout any retries [25]. Photographs of the Crazyradio are seen in Figure 22.\nBy default, the Crazyradio operates in primary transmitter mode (PTX), while the Crazyflie operates\nin primary receiver mode (PRX), where the Crazyradio sends data over the communication signal to\nthe Crazyflie and the Crazyflie returns an acknowledgement packet which may also contain additional\ndata for logging and monitoring [16]. So, for the control and communication, the high-level control\nsetpoints will be generated on the Raspberry Pi and then wirelessly transmitted to the Crazyflie using\nthe Crazyradio, where the firmware on the Crazyflie will interpret these setpoints and implement the\ncorresponding low-level commands to control the rotors and overall flight.\n23\n18mm\n160mm\nView\nTop Bottom\nView\n18mm\nUSB Microcontroller Adjustable Hinge Antenna\nFigure 22: Photographs showing the top and bottom views of the Bitcraze Crazyradio PA.\n4.3 MOVING TARGET PARTS\nThe moving target will be a simple two-wheeled design with a Dagu S4E EDU Controller (subsequently referred to as the Dagu Controller) as the motor driver and microcontroller which is compatible with the Arduino integrated development environment (IDE) with an Arduino Pro Mini 328\n5V 16MHz bootloader [26]. This controller has an ATmega328P processor at 16MHz with 2kB of\nSRAM, 32kB of flash, 1kB of EEPROM, and will receive power from a battery pack with five Duracell 1.5V AA batteries with a maximum distribution of 2.5A to each motor pin [26].\nISP Header\nAnalog Input Pins\nRight Motor Connection\nA5\nA4\nA3\nA2\nA1\nA0\nD2\nD3\nD4\nD7\nD8\nD9\nD12\nD13\nDigital Input Pins\nReset Button\nLeft Motor Connection\nBattery Input 6V-9V Mini-USB\nPower Switch\nD5 = Left Speed\nD10 = Left Direction\nD6 = Right Speed\nD11 = Right Direction\nA6 = Rear Solder Tab\nA7 = Battery Monitor\nDagu S4A EDU Controller Dagu DG02S 48:1\nGeared DC Motor\nDC Motor\n48:1 Gearbox\nShaft\nS4A\n153mm\n148mm\nBottom\nIsometric\nView Omni\nWheel\n65mm\nTop Isometric View\nBattery Pack\nDriven\nWheel\nDriven\nWheel Chassis\nMotors,\nController\nMounted Target\nInternals\nFigure 23: Photographs showing the Dagu S4A EDU Controller (top-left), Dagu DG02S 48:1 Geared\nDC Motor (top-right), and various isometric views of the target assembly (bottom).\n24\nConnecting to the two driven wheels of 65mm in diameter, there are two Dagu DO02S 48:1 Geared\nDC Motors (subsequently referred to as the Dagu Motors) requiring an input voltage between 3V and\n6V with a no load current of 200mA, stall current of 1.5A at 3V or 3A at 6V, and maximum allowable\ntorque of approximately 0.078N.m [27]. The built-in gearbox reduces the motor speed based on a\nratio of 48:1, where the output angular speed can vary from 65rev/min at 3V unloaded to 190rev/min\nat 6V unloaded [27]. A generic omni-wheel will also be positioned centrally for stability.\nFor target detection with grayscale processing, a white disk of 93mm in diameter will be used as the\nmarker, since it contrasts with the colour of the target and background for reliable detection and will\nnot change shape as the orientation of the target changes. For target detection with colour processing,\na red rectangle of 95mm by 74mm will be used as the marker, since it is unique in the environment.\nThe Dagu Controller and Dagu Motors are shown in Figure 23 with the complete assembly, which is\nable to accomplish a suitable range of translational motion. The mass and quantity of each component\nare summarised in Table 1 for a total mass of approximately 528g.\nTable 1: Quantity and mass of the components used to assemble the moving target.\nQuantity [unit] Unit Mass [g]\nDagu S4A EDU Controller 1 14\nDagu DG02S 48:1 Geared DC Motor 2 32\nDagu 65mm Wheels With Rubber Tyres 2 40\nGeneric Metal Omni-Wheel 1 36\nDagu DG0-12 Metal Chassis 1 218\nDuracell 1.5V AA Battery 5 25\nOther Parts (Cables, Nuts, Bolts, Target, etc) - 39\nTotal Assembly - 576\nTo separately evaluate the yaw orientation tracking, a SG90 Micro Servo Motor will be used to set the\ndesired orientation with a white rectangle of 140mm by 95mm as the marker, as seen in Figure 24.\nThis servo motor can rotate between 0o\nand 180o with a torque up to 0.245N.m and mass of 14.7g,\nwhere control is issued through a PWM signal and a voltage between 4.8V and 6V is supplied.\nSG90\nController,\nBattery Pack\nTarget\nMotion Capture Marker SG90 Micro Servo\nShaft\n5V Input PWM Signal\nGround\nChassis\n95mm\n140mm\nFigure 24: Photographs showing the SG90 Micro Servo motor and yawing target assembly.\n25\n4.4 MOTION CAPTURE FACILITIES\nThe motion capture system utilises four Qualisys Miqus M1 cameras. These cameras feature a 1Mpx\nimage sensor with a resolution of 1216px by 800px, high-speed frame rate up to 250fr/s, latitudinal\nfield of view of 58o\n, longitudinal field of view of 40o\n, maximum range of 10m using 16mm markers,\nand low latency for real-time applications with a camera latency of 2.9ms and system latency of 5ms\n(there is also an alternate mode for a latitudinal field of view of 41o\nand longitudinal field of view\nof 27o\n) [28]. The body of the camera has dimensions of 140mm by 84mm by 84mm with 102 NIR\nLEDs and infra-red strobe at 850nm [28]. Overall, the system allows for an accuracy anticipated to\nbe on the order of millimetres. The setup in the motion capture facilities is shown in Figure 25, where\nthe operating area for the quadrotor to use is approximately 2420mm by 2420mm with a height up to\nabout 1500mm and black mats have been placed on the floor to cover this area.\nAdjustable Tripod Cantilevered Level\nGround Control Laptop Target Mats Crazyflie\nVisual Servoing Parts\n7200mm\nQuadrotor\nArea\n2420mm\n2420mm\n7200mm\n= Miqus Camera\nMotion Capture\nFacilities Layout\nQualisys Miqus M1\n84mm\n140mm\n84mm\nWall\nMount\nCarbon\nFibre\nCalibration\nKit With\nMotion\nCapture\nMarkers\nWand-Tool\nL-Tool\n300.8mm\nFigure 25: Photographs showing a Qualisys Miqus M1 (top-left), basic layout of the motion capture\nfacilities (top-middle), carbon fibre calibration kit for the initial calibration of the motion capture\nvolume (top-right), and arrangement of the apparatus within the motion capture facilities (bottom).\n26\n4.5 GROUND CONTROL LAPTOP\nA laptop will be used to act as a ground control station for remotely accessing the Raspberry Pi, monitoring the target detection and tracking, and running the Qualisys Track Manager (QTM) software\nfor the motion capture system. To facilitate connection to the Raspbian operating system on the Raspberry Pi, a local wireless LAN network will be created by the ground control laptop. In this case, an\nHP Notebook 14-an013nr will be used with an AMD E3-7110 processor incorporating four threads\nand four cores running at 1.8GHz, but any modern laptop would likely be a sufficient substitute.\n4.6 SOFTWARE\nThe software to be used for visual servoing, controlling the quadrotor, and controlling the target is\nopen-source with free availability and primarily includes Python, OpenCV, Raspbian, and Arduino.\nThe logos associated with these software packages are illustrated in Figure 26 for visual distinction.\nFigure 26: Open-source software used for visual servoing, quadrotor control, and target control.\n4.6.1 CRAZYFLIE\nThe low-level firmware of the Crazyflie is written in C and C++, but there is a Crazyflie Python application programming interface (API) library cflib with high-level bindings which can send setpoints.\nWith access through Python 3.7.3, the following classes and functions will be used:\n\u2022 Crazyflie: Contains the intrinsic commands and callbacks used by the higher-level functions\nin other classes, where the same design as in the firmware is used for a one-to-one mapping.\n\u2022 SyncCrazyflie: Wrapper around the Crazyflie class to handle its asynchronous nature and\nconvert it for use as blocking functions in scripts performing tasks as sequences of events.\n\u2022 SyncLogger: Provide synchronous access to log current variables. The variables which can be\nlogged include estimated position, velocity, acceleration, angular orientation, and other information associated with the current state of the quadrotor as measured from the on-board sensors.\n\u2022 LogConfig: Create a configuration in which to log variables.\n\u2013 add_variable: Add a variable to be logged with its group and name.\n\u2013 start: Begin the logging of the added variables.\n\u2013 stop: End the logging of the added variables.\n27\n\u2022 Commander: Send control setpoints to the Crazyflie. The setpoints need to be sent as often as\npossible, where the Crazyflie has a continuous backend or watchdog timer which will reset the\nroll and pitch after 0.5s and stop the motors after 1s if no setpoint is received. A minimum limit\nat which setpoints can be generated and sent is recommended at 10Hz.\n\u2013 send_setpoint: Send a setpoint in terms of roll, pitch, and yaw angles and thrust.\n\u2013 send_velocity_world_setpoint: Send a setpoint in terms of the desired absolute velocities in the x, y, and z directions with a specific yaw rate.\n\u2013 send_hover_setpoint: Send a setpoint in terms of desired absolute velocities in the x\nand y directions with a specific yaw rate, while a constant altitude is maintained.\n\u2013 send_position_setpoint: Send a setpoint in terms of the desired absolute position with\nx, y, and z coordinates and a specific yaw angle. This actually uses a velocity setpoint over\na time period since there is no direct sense of absolute position, so the error in the estimated\nposition may accumulate over time. The Crazyflie attempts to execute this as fast as possible\nwith a maximum velocity up to 1m/s as limited by default - this can easily be changed by\nsetting the posCtlPid.xyVelMax and posCtlPid.zVelMax parameters.\n\u2022 Extpos: Send the current position of the Crazyflie measured using external sensors, which will\nbe directly forwarded to the position estimator of the Crazyflie.\n\u2013 send_extpos: Send the current position of the Crazyflie in terms of x, y, and z coordinates.\n\u2022 MotionCommander: Send control setpoints to the Crazyflie. This class is more orientated towards blocking functions, where a command is executed and the script waits until the motion is\ncomplete before continuing, rather than just sending a setpoint and continuing immediately. So,\nit is not an applicable option for real-time operations requiring variable adjustments.\nIf desired, further information can be found from the Bitcraze GitHub repository: https://github.\ncom/bitcraze/crazyflie-lib-python. A graphical client is also available which allows for\nflashing firmware and interfacing with the Crazyflie using a remote controller for manual control.\n4.6.2 OPENCV\nOpenCV is a library of programming functions aimed at real-time computer vision. The Python implementation of OpenCV will be used through the OpenCV Python 3.2 library, which is an API with\nbindings for interfacing with the actual functions written in C++ (the complete version of OpenCV is\nactually written in C++, but this will be difficult to integrate with the Crazyflie Python API library and\nthe extra functions are not really required for appropriate target detection and tracking). The library\nincludes various functions for image processing as basically summarised:\n\u2022 line, rectangle, circle, polylines, and putText: Draw shapes or text on the image.\n\u2022 cvtColor: Convert between two colour modes. This will typically be used to convert from the\ndefault blue, green, and red (BGR) mode to grayscale with the argument COLOR_BGR2GRAY or to\n28\na hue, lightness, and saturation (HLS) mode with the argument COLOR_BGR2HLS. (It should be\nemphasised that BGR is the default colour mode - not the common RGB mode).\n\u2022 blur, GaussianBlur, medianBlur, or bilatitudinalFilter: Apply a blur distortion to the\nimage. This will typically be used to provide smoothing and remove noise.\n\u2022 threshold: Apply a threshold or mask to the image. This is typically used to generate a binary\nimage using the argument THRESHOLD_BINARY or THRESHOLD_BINARY_INV.\n\u2022 adaptiveThreshold: Apply an adaptive threshold or mask. This is typically used to consider\nillumination factors from the local neighbourhood of a pixel before applying the threshold.\n\u2022 inRange: Apply a threshold or mask to the image based on the colours within minimum and\nmaximum bounds (usually with HLS or HVS). This is typically used to generate a binary image.\n\u2022 erode, dilation, or morphologyEx: Apply a morphology transformation. This is typically\nused to further reduce noise, where the latter will either apply an erosion transformation (remove\nwhite noise) followed by a dilation transformation (restore the original areas without noise) with\nMORPH_OPEN or apply a dilation transformation (connect white regions) followed by an erosion\ntransformation (restore the original areas without disconnections) with MORPH_CLOSE.\n\u2022 Laplacian, Sobel, or Scharr: Find the gradient or derivative intensities in a direction. This is\ntypically used to highlight edges using a high-pass filter based on feature changes.\n\u2022 Canny: Perform edge detection. This is an existing algorithm with multiple stages including\nnoise reduction with a Gaussian filter, gradient intensity finding with the Sobel method in both\nlatitudinal and longitudinal directions, non-maximum suppression with the removal of pixels\nwhich are not of the maximum value in the local neighbourhood in the gradient directions, and\nhysteresis thresholding to classify pixels as edges to be kept or non-edges to be discarded. Since\na self-derived algorithm is required, this function will not be used, but it provides an initial guide.\n\u2022 findContours: Find the contours (as mentioned, a contour is a continuous curve joining the\npoints which have the same colour or intensity along a boundary). This is typically used for basic\nshape analysis and target detection with RETR_TREE to retrieve all contours and reconstruct a full\nhierarchy of nested contours and CHAIN_APROX_SIMPLE to only store the end points of straight\nlines for decreased processing. (The contours can be drawn with findContours).\n\u2022 boundingRect: Find the top-left coordinate for a bounding rectangle and the width and height\nof this bounding rectangle applied to a contour. This is typically used for monitoring by drawing\nthe found bounding rectangle around a contour. (There is no consideration for rotation).\n\u2022 minAreaRect: Find the centroid, dimensions (height and width), and orientation between 900\nand 0o\nfor a contour. This is typically used when the orientation of a contour is needed.\n\u2022 matchTemplate: Search for and find the location of a provided template image in a larger\nimage. This is typically used when an almost identical match is possible, where there is no\nscaling, colour, or distortion changes of the template image within the larger image.\n29\nBy default, OpenCV uses the connected camera to capture an image at a resolution of 640px by\n480px, but this can be changed along with other default parameters using set, such as the frame rate,\ncodec, file format, brightness, contrast, saturation, hue, gain, exposure, and white balance - it should\nbe noted that the camera must inherently support changing these parameters. There are also more\nadvanced functions available which allow for camera calibration, optical flow, augmented reality,\nepipolar geometry, and various machine learning techniques, but these are mostly only applicable for\nspecialised applications where greater computational effort is available [13].\n(It should be noted that the OpenCV Python API library requires Numpy for backend processing,\nwhich is an open-source Python library for performing advanced calculations and matrix operations).\n4.6.3 RASPBIAN\nRaspbian Buster July 2019 is an operating system based on Debian 10 with the Linux Kernel 4.19.\nThe operating system has been optimised for best performance on the Raspberry Pi and will be used\nto run the control script for visual servoing while issuing setpoints to control the Crazyflie through the\ninstallation of Python 3.7.3 and the required libraries. It also allows for interfacing with the ground\ncontrol laptop using the wireless LAN 802.11n of the Raspberry Pi and local network created by the\nground control laptop, where a remote desktop protocol (RDP) or secure shell (SSH) session is used\nfor remote login through a graphical user interface (GUI) or the command line respectively.\n4.6.4 ARDUINO\nThe Arduino IDE offers a means to program the target using C++ with special rules of code structuring, and it compiles the script when uploading to the controller (any programming language with\na compiler to produce binary machine code could actually be used, but it will be most convenient to\nuse the Arduino IDE). Since the Dagu Controller is compatible with the Arduino IDE, the motors\ncan then be controlled using PWM signals to produce voltages between 0V and 5V corresponding to\nduty cycles linearly represented by values between 0 (0%) and 255 (100%). The following Arduino\ncommands will primarily be used to control the motors and corresponding motion of the target:\n\u2022 pinMode: Configure a pin to behave as either an INPUT (high-impedance state) or OUTPUT (lowimpedance state). This is used to initially set the direction pin of each motor as an output.\n\u2022 digitalWrite: Write a HIGH (5V) or LOW (0V) value to a digital pin. This is applied on the\ndirection pin for the respective motor and used to set the direction in which the motor must turn.\n\u2022 analogWrite: Write an analog value to a pin for a duty cycle represented between 0 (0%) and\n255 (100%). This is applied to the signal pin for the respective motor and used to set the speed\nin terms of a PWM value at which the motor must turn based on a voltage between 0V and 5V.\n\u2022 servo.write: Instruct the servo motor to rotate to the passed angle between 0o\nand 180o\n(servo\nis the name assigned to the pin on which the servo motor is attached).\n30\n5 METHODOLOGY\nAfter preparatory development with the apparatus to gain an improved understanding, the proposed\nmethodology can be divided into parts including camera compensation and calibration; initial Crazyflie considerations; target detection through processing the images from the camera; target tracking\nthrough issuing command setpoints to autonomously move the Crazyflie based on the location of the\ntarget; overall communication between the Raspberry Pi, Crazyflie, ground control laptop, and motion capture system; and motions of the target with different paths. Importantly, it is also required to\nmonitor and store the position of the target and Crazyflie in real-time during execution using the motion capture system which will be examined to validate success or failure. A complete risk assessment\nfor the operators, supervisors, and nearby bystanders has also been included in Appendix D.\n5.1 INITIAL CAMERA CONSIDERATIONS\nFirstly, it is necessary to confirm there is no significant fish-eye distortion, blurring, or effects from\nrolling shutter. This will be done by taking a series of sample images of a chessboard template and\nmeasuring whether the straight lines in the template appear straight in the images, where the measurement will be conducted by digitally overlaying straight lines over the captured image to observe\nany deviations. This also serves as a means to ensure the camera is not faulty.\nBefore the Raspberry Pi and Pi Camera can be used for target detection and tracking, it is necessary\nto evaluate the real-time performance for the image processing. This will be assessed by recording\na short clip of approximately 15s to 30s with resolutions of 160px by 120px, 320px by 240px, and\n640px by 480px to determine which resolutions provide a sufficiently high frames rate with less\nthan 100ms between frames, so at least 10 setpoints can be generated per second. For a realistic\nresult, practical cases will be considered to represent realistic use where there is no image processing,\na minimal amount of image processing with only primary information for basic monitoring, and a\nhigh level of image processing with the additional extraction of secondary information for complete\nmonitoring. Both grayscale and colour processing will be compared to evaluate the most effective and\nefficient method. For an accurate result, the average of three tests for each case with each resolution\nwill be compared. The developed control script is available in Appendix B, where only OpenCV was\nemployed which is valid since the tests are being compared directly against each other.\nWarranting a lack of distortion and successful real-time performance, the pinhole camera model needs\nto be validated for the purpose of determining the desired position for the Crazyflie. So, the camera\nneeds to be calibrated which will be based on a relationship for the current altitude in terms of the\nfocal length of the camera, actual target area, and virtual target area, as found through manipulating\nthe pinhole camera model relationships in Equation 16 for the disk target. Because the focal length of\nthe camera and actual target area will be constant, this reveals an experimental correlation coefficient\nunique to the camera which can then be used in calculations with only the virtual target area.\n31\nThus, a calibration will be performed where the camera is moved between an altitude of approximately 300mm to 800mm in increments of 20mm while the virtual target area is detected and recorded,\nas demonstrated in Figure 27. At each altitude increment, the target will be positioned in the field\nof view at the centre, top-left, top-right, bottom-left, and bottom-right regions to obtain an average\nvalue of the virtual target area and a gauge of the likely error and uncertainty in the measurements.\nThis allows for a trend to be extracted from the recorded data, which can also be used to estimate the\naltitude of the camera. Considering the rectangle target, the same relationship can be derived from the\npinhole camera model, as demonstrated in Equation 17, which presents the option for confirmation\nwith reiteration of the calibration. The proportional relationships are also simplified in Equation 18.\nz = f\nx\nu\n= f\ny\nv\n\u2212\u2192 z = f\ns\n\u03c0x\n2/4\n\u03c0u\n2/4\n= f\ns\n\u03c0y\n2/4\n\u03c0v\n2/4\n= f\nr\nAxy\nAuv\n\u2261 kA\u22120.5\nuv where k = f\np\nAxy (16)\nz = f\nx\nu\n= f\ny\nv\n\u2212\u2192 z = f\nr\nxy\nuv\n= f\nr\nAxy\nAuv\n\u2261 kA\u22120.5\nuv where k = f\np\nAxy (17)\n\u2234 z \u221d\n1\nu\nand z \u221d\n1\nv\nand z\n2 \u221d\n1\nAuv\nor z \u221d\n1\n\u221a\nAuv\n(18)\nWhere z, altitude, m; f , focal length, px; x, actual latitude distance, m; u, virtual image latitude\ndistance, px; y, actual longitude distance, m; v, virtual image longitude distance, px; Axy, actual area,\nm2\n; Auv, virtual image area, px2\n; and k, camera correlation coefficient, m.px.\nCamera Altitude\n800mm 780mm 420mm 400mm 0mm\nTarget\nThe apparent one-dimensional length/width of the target is\nexpected to be inversely proportional to the altitude. Thus,\nthe apparent two-dimensional area of the target is expected\nto be inversely proportional to the square of the altitude.\nApparent One-Dimensional Size Change\nTarget (Half)\nField Of View (Half)\nFigure 27: Method of calibrating the camera and determining the focal length.\n5.2 INITIAL QUADROTOR CONSIDERATIONS\nBy default, the Crazyflie is set to operate in cross-mode which is acceptable given that there are\nno obvious reasons to change to plus-mode. To avoid effects from flying too near the ground, the\nCrazyflie should maintain an altitude above 300mm while also remaining within the range of the\nmotion capture facilities. The natural behaviour of the Crazyflie while attempting to hover also needs\n32\nto be analysed with observations into the drift experienced without any trimming being performed, so\nthis can then be corrected with appropriate trimming to establish balanced behaviour if necessary.\n5.3 TARGET DETECTION\nA direct form of position-based visual servoing will be used, where both the current altitude of the\ncamera and position of the target will be estimated through a reconstruction of the three-dimensional\nlocations. Unfortunately, this technique will slightly suffer from the camera calibration errors.\nSo, the necessary information for visual servoing through target detection and tracking can be found\nfrom the Pi Camera viewing the target. The target detection can be performed through either grayscale\nor colour processing, where various filters are applied to the captured image to isolate the target - as\nmentioned, the most effective and efficient method will be initial evaluated and then used in the final\ntests for the best real-time performance. After considering and testing with the available techniques in\nOpenCV through trials, the following developed algorithm will be performed on each captured frame\nwith the aim of reliable target detection while maintaining minimal computational effort:\nA. Fundamental concept for grayscale processing (either A or B is performed):\n1. Once the BGR original colour image has been captured, it will be converted to a grayscale image\nto reduce the values for each pixel and computational effort required during processing.\n2. Using Equation 19, a binary threshold will be applied to the grayscale image with a threshold\nvalue, where a pixel above this value will become white and a pixel below this value will become\nblack. The value will be tuned to remove the background while maintaining the target as white.\np (g) =\n\uf8f1\n\uf8f2\n\uf8f3\ngnew if g > gthr\n0 otherwise\n(19)\nWhere p, pixel; g, grayscale value; gnew, new grayscale value, 255; gthr, grayscale threshold value.\nB. Fundamental concept for colour processing (either A or B is performed):\n1. Once the original BGR colour image has been captured, it will be converted to a HLS colour\nimage to provide easier isolation of the range for the distinct colour of the target.\n2. Using Equation 20, a binary threshold will be applied to the HLS colour image with minimum\nand maximum bounds of HLS values to create the isolation range, where a pixel within this\nrange will become white and a pixel outside of this range will become black. The bounds act as\na tolerance since there may be distortions in the captured colours due to environment lighting,\nand the values will be tuned to remove the background while maintaining the target as white.\np (h, l, s) =\n\uf8f1\n\uf8f2\n\uf8f3\ngnew if hmin < h < hmax, lmin < l < lmax, smin < s < smax\n0 otherwise\n(20)\nWhere p, pixel; h, hue value; l, lightness value; s, saturation value; gnew, new grayscale value, 255;\n33\nhmin, minimum hue value; hmax, maximum hue value; lmin, minimum lightness value; lmax, maximum\nlightness value; and smin, minimum saturation value; smax, maximum saturation value.\nC. Common target detection strategy (performed after either A or B is completed):\n3. The noise in the threshold image will be reduced to a satisfactory level using a morphology\ntransformation with a kernel size tuned for an open transformation with an erosion transformation followed by a dilation transformation. This will ensure the target is the largest white region\nin the image (unless there is a remarkably rare exception, but this will be accounted for and\nmitigated by checking whether the corresponding pixel area is within the expected range).\n4. The largest contour in the image will then be found based on the maximum pixel area in terms of\npixels. Assuming this contour is the target as is practically assured, the location of the centroid\nof the target can be found in terms of pixels to complete the target detection (a box can also be\ndrawn around the contour to identify the target for monitoring confirmation).\n5. If yaw orientation tracking is also desired, the angle of the target relative to the forward direction\nneeds to be distinguished by fitting a rectangle with the minimum area in which the contour of\nthe target can be enclosed. The respective angle of this rectangle can then be found from the\ncorners of the rectangle, where this angle will provide the orientation of the target.\nImplementing a blur before applying the threshold was initially considered, however preparatory\ntests indicated that this was unnecessary as long as a morphology transformation was performed, as\nis preferred for better noise reduction - in other words, a blur offered no perceivable advantages and\nwill only result in greater computational effort. It was also possible to apply an adaptive threshold,\nbut this is expected to be unnecessary given the stark contrast between the background and target.\n5.4 TARGET TRACKING\nSince the features of the white disk on the target will be constant for every orientation, the current\naltitude of the camera can be estimated based on the area of the target in terms of pixels in the captured\nframe, due to the target remaining at a constant altitude on the ground and relative altitude changes\ncoming from the altitude of the camera. Thus, once the area of the target is known from the target\ndetection, the desired altitude for the Crazyflie can be related with the found relationship from the\ncamera calibration in the form of Equation 16 (instead of being used for calibration with a known\naltitude, the relationship will be known and the associated altitude will be calculated).\nUsing the pinhole camera model, the actual position of the target (which is the desired position of the\nCrazyflie) can also be estimated based on the location of the centroid of the target in terms of pixels\nrelative to a chosen coordinate system within the captured frame. Thus, once the centroid of the target\nis known from the target detection, the desired position of the Crazyflie can be estimated based on\nEquation 21 for the latitude coordinate and Equation 22 for the longitude coordinate (the previously\nfound altitude and experimentally calibrated focal length will actually be used instead of the ratio of\nthe areas from the expanded theoretical model). These methods are illustrated in Figure 28.\n34\nx = u\nz\nf\n= u\nk\nf\n\u221a\nAuv\n= u\nr\nAxy\nAuv\n(21)\ny = v\nz\nf\n= v\nk\nf\n\u221a\nAuv\n= v\nr\nAxy\nAuv\n(22)\nWhere x, actual latitude coordinate, m; u, virtual image latitude coordinate, px; z, altitude, m; f , focal\nlength, px; y, actual longitude coordinate, m; and v, virtual image longitude coordinate, px.\nPinhole Camera Model\nPosition Estimation\nCamera View (Target)\nPosition\nMapping\nu\nv\nMirroring Target\nMovements\n(x,y)\nQuadrotor (View)\nx\ny\nQuadrotor Cross-Mode\nCoordinate System\nx\ny\n(u,v)\nFigure 28: Tracking of the target with the corresponding movement of the Crazyflie, where the desired\naltitude will also be varied by manually changing the relative altitude of the camera.\nTo achieve successful results, the Crazyflie needs to know its starting location. So, for a coordinate\nsystem with the origin chosen to be at the centre of the image (coordinates of (u, v) = (0, 0) are\nassigned to the centre pixel, which corresponds to position coordinates of (x, y) = (0, 0)), it will be\nrequired a conversion of the initial coordinate system through manipulation with Equation 23 and\nEquation 24, such that the coordinate system is moved and rotated from the default location in the\ntop-left corner. This coordinate system conversion is detailed in Figure 29.\nu = \u2212vi +\nrW\n2\n(23)\nv = \u2212ui +\nrH\n2\n(24)\nWhere u, new latitude coordinate, px; ui\n, initial latitude coordinate, px; rW, latitude resolution, px; v,\nnew longitude coordinate, px; vi\n, initial longitude coordinate, px; and rH, longitude resolution, px.\n( rW , rH )\nDesired System\nInitial System\n(0,rH) (rW,rH)\n(0, 0) (rW, 0) ( rW ,rH )\nu\nv\nu\nv\nCoordinate System\nTransformation\n(rW ,rH )\n(rW , rH )\n(rW ,rH )\nFigure 29: Coordinate system transformation to convert the initial system into the desired system.\nA coordinate system also needs to be established for the yaw orientation tracking. As seen in Figure 30, the direct output from OpenCV is uncertain and it is not possible to establish the orientation\n35\nsince the target could be aligned in either of the two forward quadrants. So, relative to the rectangle\ntarget, it is devised that the returned output will be the angle measured between 0o\nand 90o\nfrom a\nhorizontal projected at the lowest corner to the first edge. The orientation relative to the two forward\nquadrants can then be evaluated based on the labelling of the corners and which of the edges are\nlabelled as the width and height. Thus, the yaw orientation can be found between 90o\nand 90o using\nthe conditions of Equation 25 where the forward direction has a yaw orientation of 0o\n.\n\u03c8 =\n\uf8f1\n\uf8f2\n\uf8f3\n\u2212\u03c8i\nif W < H\n\u2212\u03c8i \u2212 90o otherwise\n(25)\nWhere \u03c8, yaw orientation, o\n; \u03c8i\n, initial yaw orientation, o\n; W, width, px; and H, height, px.\n90o 90o\n0o 90o\n0o 90o x\ny\n0\n1\n2\n3\nW\nH\nThe side between 1 and 2\nor 0 and 3 is labelled W.\nThe side between 2 and 3\nor 0 and 1 is labelled H.\nOrientation\n0o 90o\n0o 90o x\ny\n0\n1\n2\n3\nW\nH\nOrientation\nThe lowest corner is always labelled as 0 with the other\ncorners labelled in a clockwise pattern. The angle is always\nmeasured at this lowest corner to the first edge (negatively). 0o x\ny\n0\n1\n2\n3\nW H\nOrientation\nDesired Coordinate System\n0o\n = Starting Direction\n90o\n = Clockwise\n90o\n = Counter-Clockwise\nFigure 30: Explanation of the initial yaw orientation (left) and desired coordinate system (right). (It\nshould be emphasised that this is only the coordinate system for the Crazyflie, and the target will use\na conventional coordinate system between 0o\nand 180o\nas presented in Figure 32).\nSubsequently, the sequence in which setpoints will be generated for target tracking is summarised:\n1. Following the target detection, the found centroid of the target contour will be transformed into\nthe desired coordinate system with the centre of the camera view as the origin.\n2. The pinhole camera model will be used to convert the found area and transformed centroid of\nthe target contour into position coordinates for the desired altitude and position of the Crazyflie.\n3. The desired altitude and position of the Crazyflie will then be sent to the Crazyflie as a setpoint\nfor the Crazyflie to move to this location, relative to its initial location as the origin.\n4. This process repeats with each frame captured by the camera for as long as the target is moving.\n5.5 CONTROL AND COMMUNICATION\nTo clearly describe the overall processes of target tracking, the flow diagram in Figure 31 is developed.\nIn this diagram, the general idea for performing target tracking and open-loop control of the Crazyflie\nis depicted which is fully implemented in the final control script presented in Appendix B.\n36\nImport the necessary\nCrazyflie and\nOpenCV libraries.\nAssign the resolution\nfor use in OpenCV.\nInit. the parameters\nfor the Crazyradio\nand Crazyflie.\nMust the\ncaptured output be\nrecorded?\nSet up the recording\nparameters including\nthe video codec.\nYes\nNo\nMust the\ncamera operation\nbe checked?\nYes\nNo\nSet the initial position\nof the Crazyflie as its\norigin point (0,0,0).\nReset the extended\nKalman filter session\non the Crazyflie.\nCalibrate the extended\nKalman filter for the\nstate of the Crazyflie.\nRead a frame from the\ncamera to initialise\nthe image processing.\nSend the setpoint\nfunction for the\nCrazyflie to take off.\nMust the\nCrazyflie keep\nflying?\nRead the live frame\nfrom the camera.\nYes\nApply the PCM to\nfind the altitude and\nposition of the target.\nGet the area, centroid,\nand orientation of the\ntarget in pixels.\nSend a hover setpoint\nto the Crazyflie with\nthe desired location.\nWait for 1ms to check\nif the termination \"Q\"\nkey was pressed.\nSend the setpoint\nfunction for the\nCrazyflie to land.\nStart\nEnd\nBasic post-processing\nof the overall test and\nrecorded video.\nConvert the BGR\ncolour frame into a\ngrayscale frame.\nDo a binary threshold\nwith a threshold of\n200 and new of 255.\nApply a morphology\ntransformation with a\nkernel matrix of 5x5.\nDisplay the processed\nframe to the user for\nlive monitoring.\nFind the contour with\nmaximum area to be\nassumed as the target.\nIs target\narea over 100px2\nto 1000px2\n?\nYes\nFind the centroid of\nthe target in the new\ncoordinate system.\nFind orientation of\nthe target in the new\ncoordinate system.\nReport an issues if\nany errors occurred.\nCheck the camera is\nopen and display a\nframe to the user.\nNo\nNo\nConvert the BGR\ncolour frame into a\nHLS colour frame.\nDo a binary threshold\nwith lower and upper\nbounds for the colour.\n*1\n*2\n*1Processing Grayscale\n*2Processing Grayscale\nColour\nProcessing\nColour\nProcessing\nAlt. Image Processing Figure 31: High-level flow diagram of the control flow for the moving target detection and tracking\nwith regards to three degrees of translational freedom and a degree of rotational freedom as yaw\norientation. (The suitable HLS colour bounds for the dark red are (150, 40, 40) and (210, 250, 250)).\nFor communication between the Crazyflie and Raspberry Pi with the Crazyradio, a radio frequency of\n2.480GHz will be used with a data rate of 2MB/s and radio address of 0xE7E7E7E7E8 (change from\nthe default radio address of 0xE7E7E7E7E7 to avoid interference from other Crazyflies). Because the\ncontrol scripts will be running on the Raspberry Pi, a RDP is used to control the Raspberry Pi from\nthe ground control laptop, such that the control scripts can be executed and terminated when desired.\n5.6 TARGET MOTION\nThroughout the tracking, the target will remain on the ground and can move in any direction on this\nplane at any moment. The target can also be seen to move from a starting point to reach a destination\npoint along a path which mimics movement according to independent intentions without influence\nfrom the camera or Crazyflie - in other words, the target is unaware of the tracking and will not\nCamera Altitude\nIncreased Manually\nCamera View\n480mm 780mm\n~660mm\n~500mm\nCamera View\n~1050mm\n~800mm\nRectilinear Path\nStart\nEnd\nStart\nEnd\nCamera Altitude\nDecreased Manually\nCamera View\n780mm 480mm\n~1050mm\n~800mm\nCamera View\n~660mm\n~500mm\nCircular Path\nCombined Path\nCamera View\n~800mm\n~600mm\nCamera Altitude\nConstant At 580mm\nEnd\nStart\nEnd Start\nYaw Rotation\nCamera View\n~520mm\n~390mm\nCamera Altitude\nConstant At 380mm\nStart\nEnd\nEnd\nStart\n0o 180o\nFigure 32: Paths on which the target will aim to move to test rectilinear (top), circular (middle),\ncombined (bottom-left), and yaw rotation (bottom-right) motions. (The actual movement may differ).\n38\nintentionally try to assist or avoid the tracking. Furthermore, it is also assumed that the environment\nis clear from static and dynamic obstacles for both the target and Crazyflie.\nInitially, the strength of the PWM signals for each motor will be calibrated in preparatory development. To evaluate different motion characteristics, three tests will be performed and aimed at validating rectilinear motion with primary movements along latitudinal and longitudinal lines, circular\nmotion with primary movements across latitudinal and longitudinal lines, and a combination of rectilinear and circular motions in a seemingly random manner. Throughout the motions, the target will\nmove at various speeds up to 0.20m/s as well as being stationary for sporadic periods of time, where\nthe Crazyflie will be required to hover at a fixed position above the target. Moreover, an additional\ntest will be performed for the yaw orientation, where the target is rotated both clockwise and counterclockwise between 90o\nand 90o\nat about 10o\n/s. The planned path for these tests are annotated in\nFigure 32 - although the actual paths may slightly differ due to inconsistencies between the motors of\nthe target, which is not an issue as these paths are essentially arbitrary and the Crazyflie must track\nthe target regardless of the path. Each test will be performed two times to ensure repeatable results.\nThe altitude of the camera will also be altered for each of the tests and, for the rectilinear and circular motion tests, the target will actually stop at a midpoint and the altitude of the camera will be\nincreased or decreased manually with the tripod. Over all of the tests, the variety of altitudes to be\nexamined specifically include 380mm, 480mm, 580mm, and 780mm with the corresponding tests\nrelated in Figure 32. The respective fields of view from the camera at each altitude are measured to be\napproximately 520mm by 390mm, 660mm by 500mm, 800mm by 600mm, and 1050mm by 800mm.\n5.7 DATA MONITORING\nAs mentioned in Figure 31, the current view from the camera will be displayed by the Raspberry Pi\nwhich is then streamed to the ground control laptop for live monitoring during the tests. It is also\npossible to immediately terminate the execution of the control script and land the Crazyflie, which is\nincluded for safety so a test can be cancelled if unexpected or unsafe behaviour is observed.\nTo validate the tests as successes or failures, the motion capture system will store the position of the\ntarget and Crazyflie in real-time at 100fr/s, such that any relative deviation between the current position of the target (which is the desired position of the Crazyflie) and actual position of the Crazyflie\ncan be exactly quantified. Using the motion capture system is also more accurate than logging variables measured on-board the Crazyflie. The QTM will mostly handle running of the motion capture\nsystem, apart from starting the capture and defining which markers form rigid bodies for the target\nand Crazyflie, but it is necessary to initially calibrate the cameras with the following procedure:\n1. Ensure there are no markers or reflective surfaces in view of the cameras. If there are reflective\nsurfaces outside of the operating area which cannot be moved or covered, apply an auto-mask to\ndigitally block these areas in the views of the camera.\n39\n2. Position the calibration L-tool in the centre of the operating area, where the corner will define\nthe origin, the long axis will form the x-axis, and the short axis will form the y-axis.\n3. Select the 300mm carbon fibre calibration kit under Project Options with a wand-tool length of\n300.8mm and begin the calibration in QTM for a time of about 20s to 30s.\n4. While the calibration is running, proceed to wave the wand-tool completely around the perimeter,\ninside of the operating area, and through different orientations until the calibration is complete.\n5. Ensure the results of the calibration are successful, the resulting residuals for each camera are\nsimilar, and the standard deviation for the markers on the calibration tools is low.\n6 DATA ANALYSIS AND RESULTS\nBy implementing the methodology, the appropriate data is to be obtained in a primitive form. This\ndata can then be processed with an analysis for meaningful results. Ultimately, this allows for the\nexperimental application to be judged against the objectives to form conclusions. There are also\nminor justifications submitted for certain decisions, but these are further discussed in Section 7.\n6.1 CAMERA OBSERVATIONS\nFirstly, the fish-eye distortion is evaluated using the template similar to that on a chessboard. From\na photograph of this pattern shown in Figure 33, it is seen that the distortion present in the image\nfrom the Pi Camera is inconsequential with insignificant distortion towards the edges. Thus, it can\nbe initially assumed that the pinhole camera model is valid, especially near the central region of the\nimage, and it is not necessary to implement compensation for distortion.\nFrom Figure 33 and monitoring while the target was moving, it was evident that there was occasionally slight blurring of the captured image with the Pi Camera being unable to auto-focus. However,\ndue to the methods for image processing, this is not concerning as the effects have no meaningful\nimpact on the target detection since adequate noise reduction is applied.\nFish-Eye Test Template\nNegligible Fish-Eye Distortion\nFigure 33: Photograph and evaluation of the fish-eye distortion in the Pi Camera. (The image was\naligned with the pattern as best as manually possible but this may not be absolutely perfect).\n40\n6.2 IMAGE PROCESSING\nUsing the Raspberry Pi and Pi Camera, the collected data from the preliminary image processing\nto determine the most suitable resolution for acceptable real-time performance is shown in Table 2,\nand example frames illustrating the available detail at each resolution with grayscale and colour processing are seen in Figure 34. Based on the desired criteria, it is clear that a resolution of 160px\nby 120px and grayscale processing attains the best performance with an average frame rate around\n30.1fr/s and time of 33ms between frames, although colour processing would still be sufficient if\ndesired. The higher resolutions result in unacceptable frame rates and a noticeable lag was also\nobserved between the displayed frame and real-time arrangement. This enables setpoints to be generated at about 30.1Hz which should allow for smooth flight without instability - although this may\nbe slightly decreased due to the lightweight but noteworthy processing to control the Crazyflie.\nTable 2: Evaluation of the most suitable resolution for acceptable real-time performance, comparing\nvarious levels of no image processing, grayscale processing, and colour processing with resolutions\nof 160px by 120px (left), 320px by 240px (middle), and 640px by 480px (right).\n1. 160px By 120px\nRecord Time [s]\nTotal Frames [fr]\nAverage FPS [fr/s]\nAverage SPF [s/fr]\nA\n18.9 588 31.1 0.032\n22.9 707 30.9 0.032\n24.7 772 31.2 0.032\nB\n27.3 823 30.1 0.033\n25.0 753 30.1 0.033\n25.5 766 30.0 0.033\nC\n22.3 280 12.6 0.080\n17.5 217 12.4 0.081\n28.1 355 12.6 0.079\nD\n21.6 542 25.1 0.040\n22.6 561 24.8 0.040\n23.8 585 24.6 0.041\nE\n22.0 249 11.3 0.088\n23.5 267 11.4 0.088\n24.7 275 11.1 0.090\n2. 320px By 240px\nRecord Time [s]\nTotal Frames [fr]\nAverage FPS [fr/s]\nAverage SPF [s/fr]\nA\n20.3 217 10.7 0.094\n21.2 233 11.0 0.091\n23.6 261 11.1 0.090\nB\n17.9 149 8.33 0.120\n22.4 191 8.53 0.117\n25.3 214 8.46 0.118\nC\n17.8 60 3.37 0.296\n18.5 65 3.52 0.284\n27.7 96 3.47 0.288\nD\n17.5 116 6.63 0.151\n14.5 94 6.49 0.154\n27.2 181 6.66 0.150\nE\n28.5 92 3.23 0.310\n22.2 72 3.25 0.308\n28.4 93 3.28 0.305\n3. 640px By 480px\nRecord Time [s]\nTotal Frames [fr]\nAverage FPS [fr/s]\nAverage SPF [s/fr]\nA\n18.7 72 3.85 0.260\n19.3 73 3.78 0.264\n15.5 59 3.81 0.263\nB\n27.6 107 3.88 0.258\n21.8 81 3.72 0.269\n24.3 93 3.83 0.261\nC\n38.3 41 1.07 0.934\n34.9 39 1.12 0.894\n30.1 33 1.10 0.912\nD\n26.8 81 3.02 0.331\n35.4 105 2.97 0.337\n23.2 67 2.89 0.346\nE\n14.2 14 0.99 1.013\n29.4 28 0.95 1.049\n22.7 21 0.93 1.080\nA = None, B = Min. Gray Process, C = Max. Gray Process, D = Min. Colour Process, E = Max. Colour Process.\n41\nOriginal With Overlay Grayscale Conversion\nBinary Threshold Morph. With Contour\nOriginal With Overlay Grayscale Conversion\nBinary Threshold Morph. With Contour\nOriginal With Overlay Grayscale Conversion\nBinary Threshold Morph. With Contour\nOriginal With Overlay Colour Mask\nColour Threshold Morph. With Contour\nOriginal With Overlay Colour Mask\nColour Threshold Morph. With Contour\nOriginal With Overlay Colour Mask\nColour Threshold Morph. With Contour\nFigure 34: Example frames and processing captured at 160px by 120px (top), 320px by 240px\n(middle), and 640px by 480px (bottom), with an overlay of the target detection (as a graphical convenience for monitoring) found through grayscale processing (left) and colour processing (right).\nWhile the camera calibration was being completed, the current area of the target in the captured frame\nwas printed to the shell. Unexpectedly, it was gathered from this that the execution drastically slowed\ndown with a sharply dropped frame rate and lag of approximately 2s to 3s between the displayed\nframe and real-time arrangement, even though the resolution remained the same. By removing the\n42\ncommands to print to the shell for confirmation, it was concluded that printing to the shell indeed\ncaused these issues and is not a viable option for real-time monitoring of the camera view.\nThe rasterisation of the target was also considered for the disk and rectangle targets. The comparison\nfor a resolution of 160px by 120px is seen in Figure 35, where it was observed that the pixelated\nappearance of the rectangle target was greatly altered depending upon the orientation, but there was\nalmost no change in the pixelated appearance of the disk target for any orientation.\nDisk Target\nArbirary Orientation\nRectangle Target\nDiagonal Edges\nRectangle Target\nStraight Edges\nFigure 35: Rasterisation at 160px by 120px for the disk (left) and rectangle (middle and right) targets.\n(These images have been cropped from the appearance of the targets during the altitude calibration).\n6.3 CAMERA CALIBRATION\nFor the camera calibration, the altitude of the camera was increased between 300mm and 780mm\ncorresponding to a decrease in the area of the target, with example frames captured during the process\nshown in Figure 36. The recorded data is plotted in Figure 37 which allows for the trend relationship\nto be evaluated and used for the Crazyflie to maintain an altitude. By manipulating Equation 16\nto form Equation 26, the focal length in terms of pixels can be determined using the actual area of\n7088.2mm2\nfor the disk target. To achieve confirmation, the rectangle target of 13300mm2 was also\nused for the same calibration methodology with the recorded data plotted in Figure 38.\nf =\nk\np\nAxy\n(26)\nWhere f , focal length, px; k, camera correlation coefficient, m.px; and Axy, actual area, m2\n.\nFrom Equation 16 and Equation 17, it is evident that it is theoretically expected for a power relationship with a correlation coefficient and exponent of 0.5. From the recorded data, the disk calibration\nresulted in a trend relationship given by Equation 27 with an exponent of 0.484. and the rectangle\ncalibration resulted in a trend relationship given by Equation 28 with an exponent of 0.492. With the\ncorrelation coefficient and Equation 26, the focal length in terms of pixels is then found to be 111px\nfor the disk calibration and 116px for the rectangle calibration, which is an actual percentage difference of 4.41% and magnitude percentage difference of 0.931% using Equation 29 and Equation 30.\n43\nAltitude: 460mm\nArea: 470px2\nAltitude: 530mm\nArea: 358px2\nAltitude: 600mm\nArea: 277px2\nAltitude: 660mm\nArea: 227px2\nAltitude: 750mm\nArea: 175px2\nFigure 36: Example frames captured at 160px by 120px using grayscale processing at altitudes\nbetween 460mm and 750mm for the camera calibration using a disk as the target with a radius of\n95mm, with an overlay of the target detection (as a graphical convenience for monitoring).\nz = 9.128A\n\u22120.484\nuv (27)\nz = 13.47A\n\u22120.492\nuv (28)\n%pa =\n\f\n\f\n\f\n\f\na \u2212 b\n(a + b)/2\n\f\n\f\n\f\n\f\n\u00d7 100% (29)\n%pm =\n\f\n\f\n\f\n\f\nlog(a) \u2212 log(b)\n(log(a) + log(b))/2\n\f\n\f\n\f\n\f\n\u00d7 100% =\n\f\n\f\n\f\n\f\nlog(a/b)\nlog(ab)/2\n\f\n\f\n\f\n\f\n\u00d7 100% (30)\nWhere z, altitude, m; Auv, virtual image area, px2\n; %pa, actual percentage difference; a, first arbitrary\nvariable; b, second arbitrary variable; and %pm, magnitude percentage difference.\n0.10\n0.20\n0.30\n0.40\n0.50\n0.60\n0.70\n0.80\n0.90\n0 200 400 600 800 1000 1200 1400 1600 1800 2000\nAuv Area [px2\n]\n0\nz Altitude [m]\nData Point\nTrend Line\nTrend:\nFigure 37: Altitude calibration using a disk as the target with a radius of 95mm. (The uncertainty in\neach altitude measurement was about \u00b15mm which is not distinguishable on the plot).\n44\n0.10\n0.20\n0.30\n0.40\n0.50\n0.60\n0.70\n0.80\n0.90\n0 200 400 600 800 1000 1200 1400 1600 1800 2000\nz Altitude [m]\n0\nAuv Area [px2\n]\nData Point\nTrend Line\nTrend:\nFigure 38: Altitude calibration using a rectangle as the target with edges of 140mm by 95mm. (The\nuncertainty in each altitude measurement was about \u00b15mm which is not distinguishable on the plot).\n6.4 QUADROTOR OBSERVATIONS\nConsidering ground effects as the increased lift and decreased drag experienced when flying close to\na fixed surface, there were no noticeable ground effects once the Crazyflie had taken off and reached\nthe desired altitudes above 300mm. For an aircraft not designed to normally operate with ground\neffects, these ground effects can be identified by abnormal flight control when flying near the ground,\nbut this was not present in a perceivable form as the Crazyflie was tracking the target.\nThe Flow deck was able to successfully stabilise the Crazyflie and hover at a fixed position without the\nneed for roll or pitch trimming. However, during take off, there were instabilities where the behaviour\nof the Crazyflie was partially uncontrolled and erratic, and this had to be corrected by accounting for\nthe slightly altered origin after take off. There were also indications of very slow and minor drift in\nthe yaw orientation over extended periods of time, but this was seen to be almost undetectable for\nshort flight times and did not affect the performance of the Crazyflie.\n6.5 VISUAL SERVOING\nWhile the tests were being performed, the primitive data was collected in the form of the threedimensional position and three-dimensional rotation of both the target and Crazyflie. To extract\nmeaning from these data, it is necessary to analyse it with regards to lag time in position, target\ndetection robustness, relative deviation fluctuations, and ability to track the target at varying speeds.\n45\n6.5.1 PRIMITIVE DATA\nFrom the motion capture system, the basic three-dimensional position of the target and Crazyflie was\nrecorded and is shown in Figure 39 to Figure 41 for each trial in each of the rectilinear, circular, and\ncombined tests respectively. The position of the target is directly presented relative to its starting\nposition, while the position of the Crazyflie is re-evaluated relative to its initial position after taking\noff due to the mentioned irregularities. Unfortunately, there was a slight delay in the first trial of the\nrectilinear test when manually raising the tripod which contributed to an extended total time, but there\nwas no meaningful impact on the results. (As mentioned, the exact uncertainty of the motion capture\nis not precisely known but it is anticipated to be on the order of millimetres).\nFigure 39: Position of the markers in the first (top) and second (bottom) trials of the rectilinear test.\nThe trials for the yaw orientation tests were also completed fairly successfully. The primary results\nare given in Section 6.5.2 with the analysis, since the three-dimensional position of the target and\nCrazyflie is mostly irrelevant when considering the yaw orientation, but it was observed that the\nCrazyflie would slightly tremor with periods of minor instability as it tried to maintain a fixed position\nwhile only yawing (as expected, the target simply rotated without translational motion).\n46\nFigure 40: Position of the markers in the first (top) and second (bottom) trials of the circular test.\nFigure 41: Position of the markers in the first (top) and second (bottom) trials of the combined test.\n6.5.2 RESULTS ANALYSIS\nFor the translation tests, the relevant results for each trial are divided into the latitude and longitude\nposition of the target and Crazyflie, magnitude of the deviation between the relative position of the\ntarget and Crazyflie as determined with Equation 31, and altitude of the Crazyflie. These factors are\nplotted against time and analysed in Figure 42 to Figure 47 for each of the translation tests.\nDxy =\nq\n(xt \u2212 xq)\n2 + (yt \u2212 yq)\n2\n(31)\nWhere Dxy, latitude and longitude position deviation, m; xt\n, target latitude position, m; xq, quadrotor\nlatitude position, m; yt\n, target longitude position, m; and yq, quadrotor longitude position, m.\nOvershoot\nFirst\nAverage\nSecond\nAverage\nAverage\nMin.\nMax.\nAltitude\nChange\nJitter\nAltitude\nChange\nJitter\nDeviation\nFigure 42: Relevant results against time throughout the first trial of the rectilinear motion test.\nWhen the altitude was being changed in the rectilinear and circular motion tests, the Crazyflie jittered\nirregularly in the latitude and longitude positions due to the manual adjustment of the camera, where\nthe camera could not be kept at a constant position during this adjustment. However, once the succeeding altitude was reached, the Crazyflie was able to continue to operate without a distinct overshoot or\nany perceivable repercussions. There was also a slight lag throughout the tests between the actions\n48\nDeviation\nOvershoot\nFirst\nAverage\nSecond\nAverage\nAverage\nMin.\nMax.\nAltitude\nChange\nJitter\nAltitude\nChange\nJitter\nFigure 43: Relevant results against time throughout the second trial of the rectilinear motion test.\nMax. Overshoot\nMin.\nFirst\nAverage\nSecond\nAverage\nAverage\nAltitude\nChange\nJitter\nAltitude\nChange\nJitter\nDeviation\nFigure 44: Relevant results against time throughout the first trial of the circular motion test.\nMax.\nFirst\nAverage\nSecond\nAverage Average\nAltitude\nChange\nJitter\nAltitude\nChange\nJitter\nMin.\nOvershoot\nDeviation\nFigure 45: Relevant results against time throughout the second trial of the circular motion test.\nOvershoot\nAverage Average\nMax.\nMin.\nDeviation\nFigure 46: Relevant results against time throughout the first trial of the combined motion test.\nMax.\nMin.\nAverage\nOvershoot\nAverage\nDeviation\nFigure 47: Relevant results against time throughout the second trial of the combined motion test.\nof the target and response from the Crazyflie, especially when the target moved at higher speeds - the\nspeed of the target ranged from stationary up to approximately 0.215m/s, which can be represented in\nterms of pixels using the pinhole camera model with Equation 32. This lag, along with the resulting\nposition deviation between the relative position of the target and Crazyflie, are outlined in Table 3\nwith a comparison of the position deviation if the average lag is compensated (for discussion, the\naverage values are more relevant since the magnitude of the deviation is being considered).\nm = f\nn\nz\n\u2212\u2192 m\u02d9 = f\nn\u02d9\nz\n(32)\nWhere m, arbitrary virtual image distance, px; f , focal length, px; n, arbitrary actual distance, m; z,\naltitude, m; m\u02d9 , arbitrary virtual image velocity, px/s; and n\u02d9, arbitrary, actual velocity, m/s.\nFor the yaw orientation test, the relevant results for each trial are divided into the angle of the yaw\norientation for the target and Crazyflie, deviation between the relative angle of the yaw orientation for\nthe target and Crazyflie as determined with Equation 33, and altitude of the Crazyflie. These factors\nare plotted against time and analysed in Figure 48 and Figure 49. A lag between the Crazyflie and\ntarget was still observed, although the average values were particularly less prominent. As outlined\n51\nTable 3: Outline of the lag and position deviation of the Crazyflie in the x-y-plane for the translation\ntests, with comparison for the deviation after adjustment accounting for the average lag.\nLag Time [s] Original Dxy [mm] Adjusted Dxy [mm]\nTotal Time [s]\nMinimum\nAverage\nMaximum\nMinimum\nAverage\nMaximum\nMinimum\nAverage\nMaximum\nRectilinear\nTrial 1 116.1 0.18 0.96 1.60 3.82 81.2 194 9.50 58.9 132\nTrial 2 80.60 0.46 1.02 1.79 2.24 95.9 269 2.94 56.0 136\nCircular\nTrial 1 95.15 0.39 0.78 1.23 2.06 94.6 194 8.77 67.2 138\nTrial 2 91.88 0.22 0.86 1.80 0.659 80.2 241 0.482 63.8 135\nCombined\nTrial 1 64.65 0.19 0.74 2.18 8.02 73.3 133 1.15 39.0 129\nTrial 2 62.29 0.31 0.67 2.61 10.2 75.1 145 2.14 39.3 117\nOverall Averages - 0.292 0.838 1.87 4.50 83.4 196 4.16 54.0 131\nin Table 4, this lag results in an angular deviation between the yaw orientation of the target and\nCrazyflie (for discussion, the minimum and maximum values are more relevant since the direction\nof the deviation is included). The position deviation in the translation tests and angular deviation in\nthese yaw orientation tests while compensating for the average lag are seen in Figure 50.\nD\u03c8 = \u03c8t \u2212 \u03c8q (33)\nWhere D\u03c8, yaw orientation deviation, o\n; \u03c8t\n, target yaw angle, o\n; and \u03c8q, quadrotor yaw angle, o\n.\nTable 4: Outline of the lag and angular deviation of the Crazyflie for the yaw orientation in the rotation\ntests, with comparison for the deviation after adjustment accounting for the average lag.\nLag Time [s] Original D\u03c8 [\no\n] Adjusted D\u03c8 [\no\n]\nTotal Time [s]\nMinimum\nAverage\nMaximum\nMinimum\nAverage\nMaximum\nMinimum\nAverage\nMaximum\nYaw\nTrail 1 69.36 0.34 0.45 0.88 -9.54 0.185 9.87 -4.51 0.136 4.46\nTrail 2 67.06 0.12 0.38 0.64 -8.32 -1.08 8.95 -4.76 -1.04 3.96\nOverall Averages - 0.23 0.415 0.76 -8.94 -0.45 9.42 -4.64 -0.45 4.21\nIn each of the tests, there may be partial effects on the minimum and maximum values from the target\nsuddenly doubling-back which artificially fluctuates the lag and position deviation. This should be\nminimal during the rotation tests due to the low average lag, but it may be noticeable on the translation\ntests although the stationary periods before doubling-back should reduce these effect.\n52\nOvershoot\nAverage\nMax.\nMin.\nAverage\nDeviation\nFigure 48: Relevant results against time throughout the first trial of the yaw orientation test.\nAverage Overshoot\nMax.\nAverage\nMin.\nDeviation\nFigure 49: Relevant results against time throughout the second trial of the yaw orientation test.\nYaw Orientation - Trial 1\nYaw Orientation - Trial 2\nCombined Motion - Trial 1\nCombined Motion - Trial 2\nCircular Motion - Trial 1\nCircular Motion - Trial 2\nRectilinear Motion - Trial 1\nRectilinear Motion - Trial 2\nAverage\nMax.\nMin.\nAverage\nMax.\nMin.\nMax.\nMin.\nAverage\nMax.\nMin.\nAverage\nMax.\nMin.\nMax.\nMin.\nAverage Average\nMax.\nMin.\nAverage\nMax.\nMin.\nAverage\nFigure 50: Deviations with adjustments for average lag in the translation and rotation tests.\nTo isolate the altitude behaviour, the average altitude at each part of the flight was shown on the\naltitude plots for each trial. As mentioned, the initial behaviour during take off is partially unstable\nwith repeated overshooting, where the actual and magnitude percentage differences in the overshoot\ncan be compared, with Equation 29 and Equation 30 respectively, using the average altitude over the\nfollowing part of the flight. The compiled altitude results are included in Table 5.\nTable 5: Outline of the altitude of the Crazyflie for each of the translation and rotation tests. Initial Overshoot [mm] First Minimum [mm] First Average [mm] First Maximum [mm] Second Minimum [mm] Second Average [mm] Second Maximum [mm] Actual Overshoot [%] Mag. Overshoot [%]\nRectilinear\nTrial 1 574 477 495 551 772 799 824 14.7 2.38\nTrial 2 583 473 490 511 767 793 820 17.2 2.79\nCircular\nTrial 1 947 778 794 814 470 484 497 17.6 2.64\nTrial 2 833 780 793 808 471 510 539 4.98 0.75\nCombined\nTrial 1 663 552 576 593 - - - 14.1 2.22\nTrial 2 664 564 574 596 - - - 14.5 2.29\nYaw\nTrail 1 467 375 393 404 - - - 17.3 2.90\nTrail 2 468 370 393 411 - - - 17.3 2.91\nOverall Averages - - - - - - - 14.7 2.36\n7 DISCUSSION\nUsing inexpensive and low-end hardware in the form of a Raspberry Pi and Pi Camera for target\ndetection with computer vision techniques in OpenCV, it was possible to implement position-based\nvisual servoing through end-point open-loop control, where a Crazyflie effectively tracked the relative\nposition of a target in a mirrored fashion. Specifically, as is required for the aim of the research,\nthe Raspberry Pi is definitely considered to have marginal computational effort capabilities, since\nit only utilises a basic 1.0GHz single-core processor and 512MB of RAM, as compared to modern\nhardware where common consumer devices have multiple threads and cores with processing speeds\nover 1.8GHz and access to over 2GB of RAM - this is further highlighted by the cost of a Raspberry\nPi which is only around R200 [29]. The results are discussed for direct relation to the objectives.\n7.1 CAMERA AND PROCESSING FACTORS\nExamining the first significant finding in Table 2, the image processing tests at different resolutions are\nclear and, in a sense, restrictive when considering the apparatus and computationally limited hardware\n55\nin general. As a consequence, it would be absolutely infeasible to use computer vision techniques to\ncontrol the Crazyflie in real-time with the default resolution of 640px by 480px in OpenCV, since a\nsetpoint is only generated every 263ms (frequency of only 3.80Hz) on average with minimum grayscale processing; and, with a resolution of 320px by 240px, a setpoint can be generated every 118ms\n(frequency of 8.47Hz) on average with minimum grayscale processing, but this may be impractical as\nit is below the recommendation for setpoints to be generated at 10Hz as a minimum limit. By reducing the resolution to 160px by 120px, it was possible to achieve a generation of setpoints every 33ms\n(frequency of 30.1Hz) on average with minimum grayscale processing, while colour processing and\nmaximum processing were also satisfactory if desired. The relationship between the resolution and\ntime for each setpoint to be generated appears to be non-linear which is expected since the number\nof pixels in the image is decreasing by a factor of four as the resolution is halved in each dimension, but additional in-between resolutions should be investigated to find a reliable relationship, if\nthis relationship is desired to be found (which was unnecessary for the aim of this research).\nTo compare the grayscale and colour processing, it is evident that the minimum grayscale processing\nobtains a higher frame rate over the minimum colour processing with actual percentage differences\nof 19.3%, 24.7%, and 25.6% (magnitude percentage differences of 2.93%, 6.17%, and 10.6%) for\nresolutions of 160px by 120px, 320px by 240px, and 640px by 480px respectively. Similar results\nare evident for the maximum processing with actual percentage differences of 10.1%, 6.55%, and\n15.4% (magnitude percentage differences of 2.22%, 2.70%, and 5.26%) for resolutions of 160px by\n120px, 320px by 240px, and 640px by 480px respectively. Furthermore, there was severely more\nnoise observed around the target in the frames captured with colour processing, which results in a\nless accurate interpretation of the target in colour processing compared to grayscale processing.\nThe Pi Camera experienced no detrimental fish-eye distortion or effects from rolling shutter, and it\nwas calibrated to find the relationship between the virtual target area and current altitude of the camera\nwith the experimental trend relationships for the disk and rectangle targets expressed in Equation 27\nand Equation 28 respectively. By averaging the 111px and 116px experimental focal lengths from the\ndisk and rectangle targets respectively, the focal length in terms of pixels is estimated to be 113.5px.\nIn addition, these remarkable correlations between the experimental trend relationships and with the\ntheoretical predictions further reinforce and validate the legitimacy of the pinhole camera model. (It\nshould be noted that this calibration is unique to the tested resolution of 160px by 120px, where\nhigher resolutions will have a greater virtual target area due to the increased number of pixels).\nUnfortunately, the calibration for the rectangle target suffered greater uncertainty than the calibration\nfor the disk target, where the variation for the rectangle target increased from 16px to 58px for the\nminimum bound and from 27px to 75px for the maximum bound, and the variation for the disk target\nincreased from 8px to 32px for the minimum bound and from 8px to 46px for the maximum bound\n(and this was over a larger range of altitudes). The power nature of this increase (observed in Figure 37\nand Figure 38) is also expected as it mimics the power nature of the calibration. The reason for the\n56\ngreater uncertainty with the rectangle target is proposed to be due to the possibility for the orientation\nto change, which, with pronounced effects from the low resolution, results in poor rasterisation along\nthe edges when they are diagonal compared to when they are vertical or horizontal. Conversely,\nthe disk target appears almost identical for all orientations, since it is continuously symmetric and\nproportional and, thus, its uncertainty will be mostly independent from orientation.\n7.2 VISUAL SERVOING PERFORMANCE\nWith the grayscale processing and calibration of the Pi Camera to use the pinhole camera model, the\nreal-time target detection and tracking was implemented with the Crazyflie mirroring the motion of\nthe target while maintaining the altitude of the Pi Camera. The take off of the Crazyflie was occasionally erratic with large variations in the latitude and longitude positions as it ascended. There was\nalso initial overshooting before reaching the desired altitude, where the actual percentage difference\nin the overshoot averaged at 14.70% over all of the tests with a fairly consistent trend among the tests,\nwhich is expected since this is an independent event only associated with the take off before the target\nbegins any motion. Nevertheless, this behaviour did not affect the operation once it had reached the\ndesired altitude and, accordingly, the main substance of the results were not affected.\nDuring the target detection and tracking, the Crazyflie lagged slightly behind the target in terms of\nposition with an average of 0.838s for the translation tests and 0.415s for the rotation tests. A lag is\nexpected since each frame is being processed for 0.33s on average and then the generated setpoint\nneeds to be sent wirelessly over the Crazyradio to the Crazyflie which then needs to be processed\ninternally. The reason for the difference in lag between the translation tests and rotation tests is due to\nthe slower speed of the target in terms of pixels in the rotation tests compared to the translation tests.\nElaborating, the maximum speed of the target was 0.215m/s in the translation tests which converts to\n50.8px/s at an altitude of 480mm or 31.3px/s at an altitude of 780mm; and the maximum speed of\nthe target was 10o\n/s in the rotation tests which converts to 24.8px/s at an altitude of 380mm. Notably,\nthe speed of the target in both cases is appropriately less than the 1.41m/s maximum speed of the\nCrazyflie, so the lag was not influenced by the target moving faster than the Crazyflie is capable.\nDue to the lag between the Crazyflie and target, there were substantial deviations in position or yaw\norientation experienced. The maximum position deviation reached 269mm with an average deviation of 83.4mm considering the translation tests, and the minimum and maximum yaw orientation\ndeviations reached 9.54o\nand 9.87o\nrespectively considering the rotation tests. However, for a fair\nconclusion, the deviations in position and yaw orientation should be compared after the lag has been\ncompensated. As a result, the maximum position deviation is reduced to 138mm with an average deviation of 54.0mm, and the minimum and maximum yaw orientation deviations are also diminished\nconsiderably to 4.76o\nand 4.46o\nrespectively. While viewing the plots of the position of the target\nand Crazyflie in Figure 42 to Figure 49 for subsequent trials, it is also evident that there is repeatable\nperformance from the control script with consistent performance across each of the tests.\n57\nWith regards to altitude, the Crazyflie maintained average altitudes of 373mm, 496mm, 558mm, and\n787mm, for the expected altitudes of 380mm, 480mm, 580mm, and 780mm respectively (although\nthe expected altitudes were not measured during operation). During each of the tests, the Crazyflie\nperformed well in sustaining these average altitude with minor variances, where the typical minimum\nbound was only as low as 3.75% below the average value and the typical maximum bound was only\nas high as 3.98% above the average value based on an average of actual percentage differences.\n7.3 OTHER FINDINGS AND REMARKS\nThere are multiple sources causing minor uncertainty in the results, such as the slight inaccuracy\nin measuring the target dimensions at \u00b11mm, discretization error and noise from the low resolution\nof the captured frames, altitude measurement error in calibrating the Pi Camera at \u00b15mm, use of\nunderlying velocity setpoints by the Crazyflie to accomplish position setpoints, and reconstruction\nof the target position which consisted of error accumulation from its interdependent sources. The\nprimary contributor to uncertainty is the measurement accuracy of the motion capture system, where\nthe exact uncertainty is not precisely known but it is on the order of millimetres. For consolation, the\nimportant results are several orders of magnitude above this scale and can reasonably be assumed to\nbe mostly insensitive to discrepancies presented by the motion capture system.\nAlthough there were many sources of uncertainty, the control script was found to be reasonably\nrobust, as long as the target is the largest contour within the captured frame for grayscale processing\nor no similar colours appeared within the captured frame for colour processing. With very minimal\nmodification to its current form, the control script can also be suitable for an implementation of\nautonomous landing, where the desired location for landing is marked by the target and detected\nthrough target detection with the Crazyflie then moving to this location to land - in essence, this is\nalready being performed since the Crazyflie is landing at the final location of the target.\nThus, this overall implementation serves as a fairly successful proof of concept for target detection and\ntracking in three-dimensions using a single camera and hardware with marginal computational effort.\nWith expansion, the possible uses include indoor sports arenas, storage warehouses, manufacturing\nor assembly workshops, and other applications in buildings requiring target tracking, surveillance, or\nmonitoring - although it is recommended for the quadrotor to frequently return to the initial origin\nto recalibrate and account for any accumulation of error in position. Finally, despite a one-to-one\nmapping being pursued where the Crazyflie directly mirrored the target, it is also easily adaptable\nto use a different mapping, such as one-to-two, where the Crazyflie moves twice the distance of the\ntarget, or inverse mapping, where the Crazyflie moves in the opposite direction to the target.\n8 CONCLUSIONS\nAn investigation into position-based visual servoing through end-point open-loop control was conducted for estimation of the three-dimensional position and yaw orientation of a moving target using\n58\na single camera, where a Crazyflie then tracked this position and yaw orientation autonomously. Additionally, inexpensive and low-end hardware with marginal computational effort was used in the\nform of a Raspberry Pi and Pi Camera for lightweight image processing with OpenCV. From the\nimplementation, the following conclusions can be summarised in relation to the objectives:\n\u2022 The pinhole camera model is valid and can be successfully implemented using the Pi Camera at\na resolution of 160px by 120px which results in a focal length of approximately 113.5px. There\nwere no major distortions experienced and compensation was not required.\n\u2022 Comparing the resolutions of 160px by 120px, 320px by 240px, and 640px by 480px, it was\nfound that the most satisfactory resolution was 160px by 120px with the capability to generate\nsetpoints at a frequency of 30.1Hz. Moreover, when considering the minimum processing required, it is evident that the grayscale processing allows for an increased frame rate compared to\ncolour processing by an average actual percentage difference of 23.2% across the resolutions of\n160px by 120px, 320px by 240px, and 640px by 480px (this equivalently corresponds with an\naverage actual percentage difference of 23.2% in the number of setpoints generated), while also\neliminating more background noise for a more accurate interpretation of the target.\n\u2022 Through calibrating the Pi Camera based on the pinhole camera model, the three-dimensional\nposition of the target relative to the camera can be successfully described through computer vision techniques for target detection with the centroid of the target providing latitude and longitude\ncoordinates and the area of the target providing the altitude of the camera. The yaw orientation\ncan also be estimated based on the area of the target when using a disproportioned target. Endpoint open-loop visual servoing can then be executed, such that the Crazyflie is controlled to\nremotely mirror the translational and rotational motion of the target and maintain the altitude of\nthe camera by generating setpoints on the Raspberry Pi with transmission over the Crazyradio.\n\u2022 The real-time effectiveness of the end-point open-loop visual servoing exhibited an average lag\nof 0.732s, average position deviations of 83.4mm, minimum yaw orientation deviation of 9.54o\n,\nand maximum yaw orientation deviation of 9.87o\n. However, if the average lag is compensated in\neach test, the average position deviation reduces to only 54.0mm, while the minimum and maximum yaw orientation deviations reduce to only 4.76o\nand 4.46o\nrespectively. An altitude could\nalso be maintained fairly successfully, where the Crazyflie only drifted by 3.75% downwards or\n3.98% upwards on average before returning to the correct altitude.\n9 RECOMMENDATIONS\nThe following points are recommended for further research and development:\n\u2022 Although it did not affect the results and conclusions, it may be helpful to revise the take off\nfunction in the control script for smoother behaviour if further testing is to be performed.\n\u2022 The tests should be repeated in a larger environment to gauge the capability for expansion. This\nwill involve calibrating the camera for different altitudes and possibly using a larger target.\n59\n\u2022 Additional tests should also be performed in a variety of uncontrolled environments which contain minor obstacles, such as outdoors with effects on the flight control from inconsistent wind\nand effects on the target detection from a greater variation in background colours and textures.\n\u2022 The control script can be adapted to function with multiple targets and quadrotors, where each\ntarget is uniquely identified and assigned to a specific quadrotor to follow the motion.\n\u2022 The target could move at higher speeds to highlight the effect this will have on the lag and\nwhether the computational effort of the Raspberry Pi has a direct influence in this situation.\n\u2022 For faster execution, the commands for the Crazyflie and image processing in OpenCV could be\nrewritten and performed natively in C and C++, which are generally considered to require less\ncomputational time than Python since C and C++ are compiled while Python is interpreted.\n\u2022 An infra-red camera, as is traditional for motion capture systems, can be investigated for use\nin darker environments or when there is noise from changing lighting. The Raspberry Pi NoIR\nCamera Module 2.1 is a suitable infra-red camera and is compatible with the current setup.\n\u2022 Using a larger quadrotor, the camera can be mounted and end-point closed-loop could be performed with the quadrotor directly tracking the target. This was partially developed to complement the completed research, as documented in Appendix E, but it was not possible to get the\nquadrotor to fly safely after several attempts and a reasonable amount of effort.\n\u2022 Finally, there is an opportunity to research artificial intelligence and deep learning algorithms,\nsuch as a convolutional neural network, for more controlled and accurate results compared to the\npinhole camera model, although this will likely require greater computational effort.\n60\nREFERENCES\n[1] M. Rabah et al. \u2018Autonomous Moving Target-Tracking For A UAV Quadcopter Based On\nFuzzy-PI\u2019. In: Institute of Electrical and Electronics Engineers (IEEE) Access Vol. 7 (Apr.\n2019), pp. 38407\u201338419. ISSN: 2169-3536. DOI: 10.1109/ACCESS.2019.2906345. URL:\nhttps://ieeexplore.ieee.org/document/8672092.\n[2] O. Dunkley. Visual Inertial Control Of A Nano-Quadrotor. Technical University Munich, Sept.\n2014. URL: https://vision.in.tum.de/_media/spezial/bib/dunkley14msc.pdf.\n[3] R. Mahony, V. Kumar and P. Corke. \u2018Multirotor Aerial Vehicles: Modelling, Estimation, And\nControl\u2019. In: Robotics And Automation Magazine, Institute of Electrical and Electronics Engineers (IEEE) Vol. 19. (3) (Sept. 2012), pp. 20\u201332. ISSN: 1070-9932. DOI: 10.1109/MRA.2\n012.2206474. URL: https://ieeexplore.ieee.org/document/6289431.\n[4] F. Poirier et al. Control Of Crazyflie Quadcopter. University of Manchester, Manchester, Sept.\n2018. URL: https://www.ensta-bretagne.fr/jaulin/rapport2018_poirier.pdf.\n[5] M. G. Popova. Visual Servoing For A Quadrotor UAV In Target Tracking. University of Toronto,\nNov. 2015. URL: https://tspace.library.utoronto.ca/handle/1807/70520.\n[6] C. Karlsson. Vision Based Control And Landing Of Micro Aerial Vehicles. Karlstad University,\nJune 2019. URL: http://urn.kb.se/resolve?urn=urn:nbn:se:kau:diva-73225.\n[7] A. Kendall, N. Salvapantula and K. Stol. \u2018On-Board Object Tracking Control Of A Quadcopter With Monocular Vision\u2019. In: International Conference on Unmanned Aircraft Systems\n(ICUAS), Institute of Electrical and Electronics Engineers (IEEE) (Apr. 2014), pp. 404\u2013411.\nDOI: 10.1109/ICUAS.2014.6842280. URL: https://ieeexplore.ieee.org/document\n/6842280 or https://alexgkendall.com/media/papers/ICUAS_Kendall_2014.pdf.\n[8] J. Forster. \u00a8 System Identification Of The Crazyflie 2.0 Nano Quadrocopter. Swiss Federal Institute Of Technology, Zurich, Aug. 2015. DOI: 10.3929/ethz-b-000214143. URL: https\n://www.research-collection.ethz.ch/handle/20.500.11850/214143.\n[9] L. Adrjanowicz, M. Kubanek and J. Bobulski. \u2018Single Camera Based Location Estimation\nWith Dissimilarity Measurement\u2019. In: 2013 6th International Conference On Human System\nInteractions (HSI) (June 2013), pp. 241\u2013246. DOI: 10 . 1109 / HSI . 2013 . 6577830. URL:\nhttps://ieeexplore.ieee.org/document/6577830.\n[10] B. Mack, C. Noe and T. Rice. Formation Control Of Crazyflies. Bradley University, Peoria,\nMay 2018. URL: http://cegt201.bradley.edu/projects/proj2018/crazy/resourc\nes/bu_crazyflie_final_report.pdf and http://cegt201.bradley.edu/projects\n/proj2018/crazy/deliverables/deliverables.html.\n[11] L. O. G. Lobo E Silva. Attitude Control Of A Quadrotor. Ministerio Da Defesa Instituto Militar\nDe Engenharia (IME), Rio de Janeiro, Sept. 2016. URL: http://mecatrime.org/wp-cont\nent/uploads/2017/05/Luis_mestrado_dissertacao_final.pdf.\n61\n[12] C.-K. Liang, L.-W. Chang and H. H. Chen. \u2018Analysis And Compensation Of Rolling Shutter\nEffect\u2019. In: Institute of Electrical and Electronics Engineers (IEEE) Transactions On Image\nProcessing Vol. 17. (8) (Aug. 2008), pp. 1323\u20131330. DOI: 10.1109/TIP.2008.925384.\nURL: https://ieeexplore.ieee.org/document/4549748.\n[13] OpenCV and Doxygen. OpenCV 4.1.1 Documentation Modules - Python Tutorials. Open\nSource Computer Vision. Online. 26th July 2019. URL: https : / / docs . opencv . org / 4\n.1.1/d6/d00/tutorial_py_root.html (visited 18th Sept. 2019).\n[14] K. V. Patil. Object Tracking Using A Quadcopter. Indian Institude of Technology (IIT), Bombay, July 2015. URL: https://www.ee.iitb.ac.in/student/~kalpesh.patil/mater\nial/navstik_report.pdf.\n[15] J. Pedro. MECN4029 - Mechatronics II - Lecture Series And Notes. University of The Witwatersrand, Johannesburg, 2019.\n[16] W. Honig and N. Ayanian. \u2018Flying Multiple UAVs Using ROS\u2019. In: \u00a8 Robot Operating System\n(ROS): The Complete Reference. Ed. by A. Koubaa. Vol. 2. Springer International Publishing,\nCham, May 2017, pp. 83\u2013118. ISBN: 978-3-319-54927-9. DOI: 10.1007/978-3-319-5492\n7-9_3. URL: https://link.springer.com/chapter/10.1007%2F978-3-319-54927-\n9_3 or http://act.usc.edu/publications/Hoenig_Springer_ROS2017.pdf.\n[17] K. Richardsson et al. Crazyflie 2.1. Bitcraze. Online. 2019. URL: https://store.bitcraz\ne.io/products/crazyflie-2-1 (visited 16th Sept. 2019).\n[18] T. Antonsson, M. Eliasson and A. Taffanel. Crazyflie 2.1 Control Board Schematic. Bitcraze,\nDec. 2018. URL: https://wiki.bitcraze.io/_media/projects:crazyflie2:hardwa\nre:cf2.1_component_placement.pdf.\n[19] K. Richardsson et al. Flow Deck V2. Bitcraze. Online. 2019. URL: https://store.bitcra\nze.io/collections/decks/products/flow-deck-v2 (visited 12 Oct. 2019).\n[20] Raspberry Pi Foundation. Raspberry Pi Zero W. Raspberry Pi. Online. 2019. URL: https:\n//www.raspberrypi.org/products/raspberry-pi-zero-w/ (visited 16th Sept. 2019).\n[21] J. Hughes, L. Lynch, B. Nuttall, and Raspberry Pi Foundation. Documentation - Hardware -\nCamera Module. Raspberry Pi. Online. 24th April 2018. URL: https://www.raspberrypi\n.org/documentation/hardware/camera/ (visited 16th Sept. 2019).\n[22] R. Thornton. Raspberry Pi Zero W V1.3 - Mechanical Drawings. Raspberry Pi Foundation,\nJuly 2019. URL: https://www.raspberrypi.org/documentation/hardware/raspber\nrypi/mechanical/rpi_MECH_Zero_1p3.pdf.\n[23] M. Stimson and J. Adams. Raspberry Pi Camera Module V2.1 - Mechanical Drawings. Raspberry Pi Foundation, Nov. 2015. URL: https://www.raspberrypi.org/documentation\n/hardware/camera/mechanical/rpi_MECH_Camera2_2p1.pdf.\n62\n[24] K. Richardsson et al. Crazyradio PA USB. Bitcraze. Online. 2019. URL: https://store.bi\ntcraze.io/collections/kits/products/crazyradio-pa (visited 16th Sept. 2019).\n[25] A. Taffanel. Crazyflie Communication. Bitcraze. Online. Jan. 2015. URL: https://www.bit\ncraze.io/2015/01/crazyflie-2-0-radio-communication/ (visited 22nd Oct. 2019).\n[26] DaguRobot Electronics. S4A EDU Controller (Scratch For Arduino) ROHS. Online. 2019.\nURL: http://www.dagurobot.com/S4A_EDU_controller (visited 28th Sept. 2019).\n[27] DaguRobot Electronics. DAGU Off Set Gear Motor Accessories 1:48 (1 Pair) 9mm Long Output Axis ROHS. Online. 2019. URL: http://www.dagurobot.com/motor_acessorios_1\n:48_9MM_long_output_axis (visited 28th Sept. 2019).\n[28] Qualisys. Miqus Specifications, Capture More With Less. Qualisys, Motion Capture Systems,\nOct. 2018. URL: https://cdn-content.qualisys.com/2018/10/PI_Miqus.pdf.\n[29] PiShop. Raspberry Pi Zero W 1.1. Online. 2019. URL: https://www.pishop.co.za/stor\ne/raspberry-pi/raspberry-pi-zero-wireless (visited 23rd Oct. 2019).\n[30] T. Antonsson, M. Eliasson and A. Taffanel. BigQuad Expansion Deck. Bitcraze Wiki. Online.\n11th December 2018. URL: https://wiki.bitcraze.io/projects:crazyflie2:expa\nnsionboards:bigquad (visited 14th Sept. 2019).\n[31] T. Antonsson, M. Eliasson and A. Taffanel. BigQuad Expansion Deck Schematic. Bitcraze,\nDec. 2018. URL: https://wiki.bitcraze.io/_media/projects:crazyflie2:expans\nionboards:bigquad-revc-top.png.\n63\nA ADDITIONAL RESOURCES\nFor supplement to the presented data, online resources containing additional data which are not of an\nappropriate form for presentation in a report are available at: https://drive.google.com/open?\nid=1wsVvasJ_MfNI8SphguZh88tsmAFaG_MC (access is limited to accounts linked to the University\nof the Witwatersrand unless permission is requested). Since the Bitcraze Crazyflie 2.1, Bitcraze Flow\nV2 expansion deck, Bitcraze Crazyradio PA, Raspberry Pi Zero W 1.1, and Raspberry Pi Camera\nModule 2.1 are open-source, the electronic schematics for the hardware are freely available and have\nbeen compiled with these other online resources if reference is desired.\nB CONTROL SCRIPTS\nFirstly, the installation of the required packages is as follows for Raspbian (and other similar Debianbased linux distributions with the Apt 1.8.2 package manager) before utilising the Crazyflie Python\nAPI library, Crazyflie graphical client, and OpenCV Python API library. (The Raspberry Pi must be\nbooted with the Crazyradio inserted otherwise it will not be detected correctly).\nsudo apt install python3\nsudo apt install python3-pip\nsudo apt install python3-libusb1\nsudo apt install python3-pyqt5\npip3 install numpy # sudo apt install python3-numpy\npip3 install opencv-python # sudo apt install python3-opencv\npip3 install cflib\npip3 install PyUSB\npip3 install appdirs\npip3 install PyYAML\nThe subsequent Python script with OpenCV was used to evaluate the real-time performance for image\nprocessing by comparing resolutions of 160px by 120px, 320px by 240px, and 640px by 480px with\nboth grayscale and colour processing. The presented form of the code is for the maximum grayscale\nprocessing - for the other processing tests, the relevant lines marked with ## must be uncommented.\nAs discussed, a resolution around 160px by 120px was only suitable with the Raspberry Pi.\n1 # **********************************************************************************\n2 # Date: 2019-09-30. Author: Edward Rycroft. Description: This program is used to\n> evaluate the grayscale and colour image processing at different resolutions.\n3 # **********************************************************************************\n4\n5 # ----------------------------------------------------------------------------------\n6 # Import Files\n64\n7 # ----------------------------------------------------------------------------------\n8\n9 # Import the necessary libraries (note the changes of names).\n10 import time\n11 import numpy as np\n12 import cv2 as cv\n13\n14 # ----------------------------------------------------------------------------------\n15 # Target Detection Functions\n16 # ----------------------------------------------------------------------------------\n17\n18 # Function to perform grayscale image processing.\n19 def processing_gray (frame):\n20\n21 # Convert the frame to grayscale, apply a threshold or mask with the limit\n> tuned for the target, and apply an open morphology transformation.\n22 mode = cv.cvtColor (frame, cv.COLOR_BGR2GRAY)\n23 #mode = cv.blur (mode, (5, 5))\n24 ret, threshold = cv.threshold (mode, 150, 255, cv.THRESH_BINARY)\n25 kernel = np.ones ((5, 5), np.uint8)\n26 morphology = cv.morphologyEx (threshold, cv.MORPH_OPEN, kernel)\n27\n28 # Return the relevant variables to store.\n29 return frame, mode, threshold, morphology\n30\n31 # Function to perform colour image processing.\n32 def processing_colour (frame):\n33\n34 # Convert the frame to hue-lightness-saturation, apply a threshold or mask with\n> the limits tuned for the target, and apply an open morphology transformation.\n35 mode = cv.cvtColor (frame, cv.COLOR_BGR2HLS)\n36 #mode = cv.blur (mode, (5, 5))\n37 lower_colour = np.array ([150, 40, 40])\n38 upper_colour = np.array ([210, 250, 250])\n39 threshold = cv.inRange (mode, lower_colour, upper_colour)\n40 kernel = np.ones ((5, 5), np.uint8)\n41 morphology = cv.morphologyEx (threshold, cv.MORPH_OPEN, kernel)\n42\n43 # Return the relevant variables to store.\n44 return frame, mode, threshold, morphology\n45\n46 # Function to detect the centroid of the target.\n47 def target_detection (frame, processed):\n48\n65\n49 # Find and identify the contours within the current frame.\n50 image, contours, hierarchy = cv.findContours (threshold, cv.RETR_TREE,\n> cv.CHAIN_APPROX_SIMPLE) # This line should be used for OpenCV Python 3.X.\n51 #contours, hierarchy = cv.findContours (processed, cv.RETR_TREE,\n> cv.CHAIN_APPROX_SIMPLE) # This line should be used for OpenCV Python 4.X.\n52 #temporary = cv2.findContours (des, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE) #\n> With the line below, this line could be used for OpenCV Python 3.X or 4.X.\n53 #contours = temporary [0] if len (temporary) == 2 else temporary [1]\n54\n55 # Locate the largest contour and find the corresponding properties. Note that\n> the image moments are simply weighted averages based on the pixel intensities.\n56 if len (contours) != 0:\n57 maximum = max (contours, key = cv.contourArea)\n58 moment = cv.moments (maximum)\n59 centroid_x = int (moment [\"m10\"] / moment [\"m00\"])\n60 centroid_y = int (moment [\"m01\"] / moment [\"m00\"])\n61 x, y, w, h = cv.boundingRect (maximum)\n62 angled = cv.minAreaRect (maximum)\n63 box = np.int0 (cv.boxPoints (angled))\n64 cv.rectangle (frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n65 cv.drawContours (frame, [box], 0, (0, 0, 255), 2)\n66 cv.circle (frame, (centroid_x, centroid_y), 3, (255, 0, 0), 5)\n67 else:\n68 centroid_x = 0\n69 centroid_y = 0\n70\n71 # Draw a coordinate system and timestamp to the current frame.\n72 time = str (np.around (time.time () - time_start, decimals = 1))\n73 cv.putText (frame, time, (10, 30), cv.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n74 cv.circle (frame, (int (res_x / 2), int (res_y / 2)), 5, (255, 255, 255), 5)\n75\n76 # Return the relevant variables to store.\n77 return frame, contours, centroid_x, centroid_y\n78\n79 # Function to record and display the basic output as a video.\n80 def record_minimum (frame, record):\n81\n82 # Record (optional) and display the basic output.\n83 if record == \"Y\":\n84 video.write (frame)\n85 cv.imshow (\"Original Output\", frame)\n86\n87 # Function to record and display the complete output as a video.\n88 def record_maximum (frame, mode, threshold, morphology, record, contours):\n66\n89\n90 # Combine the processed frames into a single frame.\n91 if np.size (mode) == res_x * res_y:\n92 mode = cv.merge ([mode, mode, mode])\n93 elif np.size (mode) == res_x * res_y * 3:\n94 mode = cv.cvtColor (mode, cv.COLOR_HLS2BGR)\n95 mode = cv.bitwise_and (mode, mode, mask = morphology)\n96 threshold = cv.merge ([threshold, threshold, threshold])\n97 morphology = cv.merge ([morphology, morphology, morphology])\n98 if len (contours) != 0:\n99 cv.drawContours (morphology, contours, -1, (255, 0, 0), 2)\n100 output = np.zeros ((res_y * 2, res_x * 2, 3), dtype = \"uint8\")\n101 output [0:res_y, 0:res_x] = frame\n102 output [0:res_y, res_x:(res_x * 2)] = mode\n103 output [res_y:(res_y * 2), 0:res_x] = threshold\n104 output [res_y:(res_y * 2), res_x:(res_x * 2)] = morphology\n105\n106 # Record (optional) and display the combined output.\n107 if record == \"Y\":\n108 video.write (output)\n109 cv.imshow (\"Combined Output\", output)\n110\n111 # ----------------------------------------------------------------------------------\n112 # Define Variables\n113 # ----------------------------------------------------------------------------------\n114\n115 # Set the variables for target detections.\n116 print (\"Setting the variables to be used.\")\n117 res_x = 160 # 320 # 640\n118 res_y = 120 # 240 # 480\n119 fps = 30\n120\n121 # Find basic requirements from the user.\n122 record = input (\"Must the source be recorded as a video? [Y/N] \")\n123 if record == \"Y\":\n124 version = input (\"Must basic [B] or combined [C] output be recorded? [B/C] \")\n125 if version != \"B\" and version != \"C\":\n126 print (\"! The input for the version is invalid. Quitting the program.\")\n127 raise SystemExit\n128 elif record != \"N\":\n129 print (\"! The input to record the source is invalid. Quitting the program.\")\n130 raise SystemExit\n131\n132 # ----------------------------------------------------------------------------------\n67\n133 # Perform Checks\n134 # ----------------------------------------------------------------------------------\n135\n136 # Identify the source for use and recording if desired.\n137 print (\"Identifying the source for use and recording if desired.\")\n138 source = cv.VideoCapture (0)\n139 source.set (cv.CAP_PROP_FRAME_WIDTH, res_x) # Alternate identifier: 3.\n140 source.set (cv.CAP_PROP_FRAME_HEIGHT, res_y) # Alternate identifier: 4.\n141 if record == \"Y\":\n142 codec = cv.VideoWriter_fourcc (*\"XVID\")\n143 if version == \"B\":\n144 video = cv.VideoWriter (\"Out.avi\", codec, fps, (res_x, res_y), True)\n145 elif version == \"C\":\n146 video = cv.VideoWriter (\"Out.avi\", codec, fps, (res_x * 2, res_y * 2), True)\n147\n148 # Ensure the source is open and available.\n149 active = True\n150 strikes = 0\n151 if source.isOpened == False:\n152 print (\"! The source is not open. Trying to open the source.\")\n153 source.Open ()\n154 if source.isOpened == False:\n155 print (\"The source is not open.\")\n156 active == False\n157 elif source.isOpened == True:\n158 print (\"The source is open and available.\")\n159\n160 # Check that the source is operating correctly.\n161 print (\"Checking that the source is operating correctly.\")\n162 check = input (\"Should the source be checked to be capturing correctly? [Y/N] \")\n163 if check == \"Y\":\n164 correct, frame = source.read ()\n165 if correct == False:\n166 print (\"A frame could not be read correctly.\")\n167 correct = \"N\"\n168 elif correct == True:\n169 cv.imshow (\"Image Test\", frame)\n170 cv.waitKey (1)\n171 correct = input (\"Is the capture displayed correctly? [Y/N] \")\n172 if correct == \"N\":\n173 print (\"! The capture is not operating correctly.\")\n174 active = False\n175 cv.destroyAllWindows ()\n176\n68\n177 # ----------------------------------------------------------------------------------\n178 # Main Project Loop\n179 # ----------------------------------------------------------------------------------\n180\n181 # Begin capture of the video frames and image processing.\n182 print (\"Beginning capture of the video frames and image processing.\")\n183 print (\"To terminate the capture, press [Q] in the video window.\")\n184 time_start = time.time ()\n185 while active == True:\n186\n187 # Load the current frame from the source.\n188 correct, frame = source.read ()\n189\n190 # A: No processing with only basic video capture.\n191 ##record_minimum (frame, record)\n192\n193 # B: Minimum grayscale processing with results video capture.\n194 ##frame, mode, threshold, morphology = processing_gray (frame)\n195 ##frame, contours, centroid_x, centroid_y = target_detection (frame, morphology)\n196 ##record_minimum (frame, record)\n197\n198 # C: Maximum grayscale processing with complete video capture.\n199 frame, mode, threshold, morphology = processing_gray (frame)\n200 frame, contours, centroid_x, centroid_y = target_detection (frame, morphology)\n201 record_maximum (frame, mode, threshold, morphology, record, contours)\n202\n203 # D: Minimum colour processing with results video capture.\n204 ##frame, mode, threshold, morphology = processing_colour (frame)\n205 ##frame, contours, centroid_x, centroid_y = target_detection (frame, morphology)\n206 ##record_minimum (frame, record)\n207\n208 # E: Maximum colour processing with complete video capture.\n209 ##frame, mode, threshold, morphology = processing_colour (frame)\n210 ##frame, contours, centroid_x, centroid_y = target_detection (frame, morphology)\n211 ##record_maximum (frame, mode, threshold, morphology, record, contours)\n212\n213 # Look for the designated key to terminate the capture.\n214 key = cv.waitKey (1)\n215 if key == ord (\"Q\"):\n216 active = False\n217\n218 time_end = time.time ()\n219\n220 # ----------------------------------------------------------------------------------\n69\n221 # Finishing Commands\n222 # ----------------------------------------------------------------------------------\n223\n224 # Terminate the capture and release the source.\n225 print (\"Terminating the capture and releasing the source.\")\n226 source.release ()\n227 if record == \"Y\":\n228 print (\"The output video is \u2019Out.avi\u2019 in the current directory.\")\n229 video.release ()\n230 cv.destroyAllWindows ()\n231\n232 # Review the details of the captured output.\n233 if record == \"Y\":\n234 print (\"Review of the details of the capturing process:\")\n235 video = cv.VideoCapture (\"Out.avi\")\n236 time_record = (time_end - time_start)\n237 total_frames = int (video.get (cv.CAP_PROP_FRAME_COUNT))\n238 print (\" Horizontal Resolution:\", res_x, \"pixels.\")\n239 print (\" Vertical Resolution:\", res_y, \"pixels.\")\n240 print (\" Total Recording Time:\", \"{0:.2f}\".format (time_record), \"seconds.\")\n241 print (\" Total Frames:\", total_frames, \"frames.\")\n242 try:\n243 fps_avg = total_frames / time_record\n244 spf_avg = 1 / fps_avg\n245 print (\" Average FPS: \", \"{0:.2f}\".format (fps_avg), \"frames per second.\")\n246 print (\" Average SPF:\", \"{0:.4f}\".format (spf_avg), \"seconds per frame.\")\n247 except ZeroDivisionError:\n248 print (\" ! The resolution passed for capture does not match the output.\")\n249 print (\" ! The average frame rate values could not be determined.\")\n250 fps_avg = 0\n251 spf_avg = 0\n252\n253 # ----------------------------------------------------------------------------------\n254 # End\n255 # ----------------------------------------------------------------------------------\nFor altitude calibration, the above script was modified with print(cv.contourArea(maximum))\nwithin the target_detection function to display the target area in pixels, while maximum grayscale\nprocessing monitored the target as it was positioned and the altitude of the camera was varied. As\nmentioned, this printing to the shell dramatically slowed execution with a noticeable lag.\nThe final script for target detection and tracking is presented below, where further optimisations have\nalso been performed after the script for the resolution tests and altitude calibration to make the code\n70\nmore efficient and robust. An optimisation which was not exploited, as it was not necessary, is the\nidea to restrict the region in which to look for the target based on the detected location of the target in\nthe previous frame, such that even less computational effort would be required as a result.\n1 # ********************************************************************************\n2 # Date: 2019-18-10. Author: Edward Rycroft. Description: This program is used to\n> perform visual servoing through end-point open-loop control using a Raspberry Pi\n> and Pi Camera for image processing with OpenCV and a Crazyflie to mirror the\n> relative position of a moving target for effective target detection and tracking.\n3 # ********************************************************************************\n4\n5 # --------------------------------------------------------------------------------\n6 # Import Files\n7 # --------------------------------------------------------------------------------\n8\n9 # Import the necessary libraries (note the changes of names).\n10 import time\n11 import logging\n12 import numpy as np\n13 import cv2 as cv\n14 import cflib.crtp\n15 from cflib.crazyflie import Crazyflie\n16 from cflib.crazyflie.log import LogConfig\n17 from cflib.crazyflie.syncCrazyflie import SyncCrazyflie\n18 from cflib.crazyflie.syncLogger import SyncLogger\n19\n20 # --------------------------------------------------------------------------------\n21 # Target Detection And Tracking Functions\n22 # --------------------------------------------------------------------------------\n23\n24 # Function to perform grayscale image processing.\n25 def processing_gray (frame):\n26\n27 # Convert the frame to grayscale, apply a threshold or mask with the limit\n> tuned for the target, and apply an open morphology transformation.\n28 mode = cv.cvtColor (frame, cv.COLOR_BGR2GRAY)\n29 #mode = cv.blur (mode, (5, 5))\n30 ret, threshold = cv.threshold (mode, 200, 255, cv.THRESH_BINARY)\n31 kernel = np.ones ((5, 5), np.uint8)\n32 morphology = cv.morphologyEx (threshold, cv.MORPH_OPEN, kernel)\n33\n34 # Return the relevant variables to store.\n35 return frame, mode, threshold, morphology\n71\n36\n37 # Function to perform colour image processing.\n38 def processing_colour (frame):\n39\n40 # Convert the frame to hue-lightness-saturation, apply a threshold or mask with\n> the limits tuned for the target, and apply an open morphology transformation.\n41 mode = cv.cvtColor (frame, cv.COLOR_BGR2HLS)\n42 #mode = cv.blur (mode, (5, 5))\n43 lower_colour = np.array ([150, 40, 40])\n44 upper_colour = np.array ([210, 250, 250])\n45 threshold = cv.inRange (mode, lower_colour, upper_colour)\n46 kernel = np.ones ((5, 5), np.uint8)\n47 morphology = cv.morphologyEx (threshold, cv.MORPH_OPEN, kernel)\n48\n49 # Return the relevant variables to store.\n50 return frame, mode, threshold, morphology\n51\n52 # Function to detect the centroid and area of the target.\n53 def target_detection (frame, morphology, time_start, res_x, res_y):\n54\n55 # Find and identify the contours within the current frame.\n56 image, contours, hierarchy = cv.findContours (threshold, cv.RETR_TREE,\n> cv.CHAIN_APPROX_SIMPLE) # This line should be used for OpenCV Python 3.X.\n57 #contours, hierarchy = cv.findContours (processed, cv.RETR_TREE,\n> cv.CHAIN_APPROX_SIMPLE) # This line should be used for OpenCV Python 4.X.\n58 #temporary = cv2.findContours (des, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE) #\n> With the line below, this line could be used for OpenCV Python 3.X or 4.X.\n59 #contours = temporary [0] if len (temporary) == 2 else temporary [1]\n60\n61 # Locate the largest contour and find the corresponding properties.\n62 try:\n63 maximum = max (contours, key = cv.contourArea)\n64 moment = cv.moments (maximum)\n65 centroid_x = int (moment [\"m10\"] / moment [\"m00\"])\n66 centroid_y = int (moment [\"m01\"] / moment [\"m00\"])\n67 area = cv.contourArea (maximum)\n68 x, y, w, h = cv.boundingRect (maximum)\n69 cv.rectangle (frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n70 cv.circle (frame, (centroid_x, centroid_y), 3, (255, 0, 0), cv.FILLED)\n71 area = cv.contourArea (maximum)\n72 transform_x = int (res_x / 2) - centroid_y\n73 transform_y = int (res_y / 2) - centroid_x\n74 except:\n75 area = 1\n72\n76 transform_x = 0\n77 transform_y = 0\n78\n79 # Draw a coordinate system and timestamp to the current frame.\n80 time_current = np.around (time.time () - time_start, decimals = 1)\n81 cv.putText (frame, str (time_current), (10, 30), cv.FONT_HERSHEY_SIMPLEX, 1,\n> (255, 255, 255), 2) # (10, 30) = Top-Left Corner\n82 cv.circle (frame, (int (res_x/2), int (res_y/2)), 5, (255, 255, 255), cv.FILLED)\n83\n84 # Return the relevant variables to store.\n85 return frame, contours, transform_x, transform_y, area\n86\n87 # Function to detect the yaw orientation of the target.\n88 def target_detection_orientation (frame, contours):\n89\n90 # Locate the largest contour and find the corresponding properties. Note that\n> the image moments are simply weighted averages based on the pixel intensities.\n91 try:\n92 maximum = max (contours, key = cv.contourArea)\n93 x, y, w, h = cv.boundingRect (maximum)\n94 bounds = cv.minAreaRect (maximum)\n95 orientation = bounds [2]\n96 if bounds [1][0] < bounds [1][1]: # width < height\n97 orientation = - orientation\n98 else:\n99 orientation = - orientation - 90\n100 box = np.int0 (cv.boxPoints (bounds))\n101 cv.drawContours (frame, [box], 0, (0, 0, 255), 2)\n102 except:\n103 orientation = 0\n104\n105 # Return the relevant variables to store.\n106 return frame, orientation\n107\n108 # Function to record and display the basic output as a video.\n109 def monitor_minimum (frame, record):\n110\n111 # Record (optional) and display the basic output.\n112 if record == \"Y\":\n113 video.write (frame)\n114 cv.imshow (\"Original Output\", frame)\n115\n116 # Function to record and display the complete output as a video.\n117 def monitor_maximum (frame, mode, threshold, morphology, record, contours):\n73\n118\n119 # Combine the processed frames into a single frame.\n120 if np.size (mode) == res_x * res_y:\n121 mode = cv.merge ([mode, mode, mode])\n122 elif np.size (mode) == res_x * res_y * 3:\n123 mode = cv.cvtColor (mode, cv.COLOR_HLS2BGR)\n124 mode = cv.bitwise_and (mode, mode, mask = morphology)\n125 threshold = cv.merge ([threshold, threshold, threshold])\n126 morphology = cv.merge ([morphology, morphology, morphology])\n127 if len (contours) != 0:\n128 cv.drawContours (morphology, contours, -1, (255, 0, 0), 2) # cv.FILLED\n129 output = np.zeros ((res_y * 2, res_x * 2, 3), dtype = \"uint8\")\n130 output [0:res_y, 0:res_x] = frame\n131 output [0:res_y, res_x:(res_x * 2)] = mode\n132 output [res_y:(res_y * 2), 0:res_x] = threshold\n133 output [res_y:(res_y * 2), res_x:(res_x * 2)] = morphology\n134\n135 # Record (optional) and display the combined output.\n136 if record == \"Y\":\n137 video.write (output)\n138 cv.imshow (\"Combined Output\", output)\n139\n140 # Function to print the characteristics of the target centroid.\n141 def monitor_text (centroid_x, centroid_y, altitude, orientation):\n142\n143 # Print the target characteristics to the shell.\n144 print (\"Centroid X: \", centroid_x)\n145 print (\"Centroid Y: \", centroid_y)\n146 print (\"Altitude: \", \"{0:.2f}\".format (altitude))\n147 print (\"Orientation: \", \"{0:.2f}\".format (orientation))\n148 print (\"\")\n149\n150 # --------------------------------------------------------------------------------\n151 # Crazyflie Control Functions\n152 # --------------------------------------------------------------------------------\n153\n154 # Function to update the position estimator after the extend Kalman filter is reset.\n155 def wait_for_position_estimator (crazyflie):\n156\n157 # Print an update to the shell for monitoring.\n158 print (\"Waiting for estimator to calibrate the current state.\")\n159\n160 # Set up logging and add the variables to log for updating.\n161 log_config = LogConfig (name = \"Kalman Variance\", period_in_ms = 500)\n74\n162 log_config.add_variable (\"kalman.varPX\", \"float\")\n163 log_config.add_variable (\"kalman.varPY\", \"float\")\n164 log_config.add_variable (\"kalman.varPZ\", \"float\")\n165 var_y_history = [1000] * 10\n166 var_x_history = [1000] * 10\n167 var_z_history = [1000] * 10\n168\n169 # Define a threshold for maximum and minimum variations.\n170 threshold = 0.001\n171\n172 # Begin logging the added variables.\n173 with SyncLogger (crazyflie, log_config) as logger:\n174 for log_entry in logger:\n175\n176 # Append the current values to the stored history.\n177 data = log_entry [1]\n178 var_x_history.append (data [\"kalman.varPX\"])\n179 var_x_history.pop (0)\n180 var_y_history.append (data [\"kalman.varPY\"])\n181 var_y_history.pop (0)\n182 var_z_history.append (data [\"kalman.varPZ\"])\n183 var_z_history.pop (0)\n184\n185 # Compare the maximum and minimum variations until within the threshold.\n186 minimum_x = min (var_x_history)\n187 maximum_x = max (var_x_history)\n188 minimum_y = min (var_y_history)\n189 maximum_y = max (var_y_history)\n190 minimum_z = min (var_z_history)\n191 maximum_z = max (var_z_history)\n192 if (maximum_x - minimum_x) < threshold and (maximum_y - minimum_y) <\n> threshold and (maximum_z - minimum_z) < threshold:\n193 break\n194\n195 # Function to set a custom initial position.\n196 def set_initial_position (crazyflie, initial_x, initial_y, initial_z, initial_yaw):\n197\n198 # Print an update to the shell for monitoring.\n199 print (\"Setting the initial position to (\", initial_x, \",\", initial_y, \",\",\n> initial_z, \") at \", initial_yaw, \" radians.\")\n200\n201 # Setting the initial position.\n202 crazyflie.param.set_value (\"kalman.initialX\", initial_x)\n203 crazyflie.param.set_value (\"kalman.initialY\", initial_y)\n75\n204 crazyflie.param.set_value (\"kalman.initialZ\", initial_z)\n205 crazyflie.param.set_value (\"kalman.initialYaw\", initial_yaw)\n206\n207 # Function to set the initial position as the origin.\n208 def set_initial_position_origin (crazyflie):\n209\n210 # Print an update to the shell for monitoring.\n211 print (\"Setting the initial position as the origin (0,0,0) at 0 radians.\")\n212\n213 # Setting the initial position.\n214 crazyflie.param.set_value (\"kalman.initialX\", \"0\")\n215 crazyflie.param.set_value (\"kalman.initialY\", \"0\")\n216 crazyflie.param.set_value (\"kalman.initialZ\", \"0\")\n217 crazyflie.param.set_value (\"kalman.initialYaw\", \"0\")\n218\n219 # Function to reset the extended Kalman filer.\n220 def reset_estimator (crazyflie):\n221\n222 # Print an update to the shell for monitoring.\n223 print (\"Resetting the extended Kalman filter for a clean state.\")\n224\n225 # Reset the extended Kalman filter and update the position estimator.\n226 crazyflie.param.set_value (\"kalman.resetEstimation\", \"1\")\n227 time.sleep (0.1)\n228 crazyflie.param.set_value (\"kalman.resetEstimation\", \"0\")\n229 wait_for_position_estimator (crazyflie)\n230\n231 # Function to vertically take off the Crazyflie.\n232 def take_off (crazyflie, altitude):\n233\n234 # Print an update to the shell for monitoring.\n235 print (\"Crazyflie is taking off to the starting altitude.\")\n236\n237 # Define the desired time in which to move and the number of setpoints to send.\n238 action_time = 1\n239 setpoint_time = 0.05\n240 steps = int (action_time / setpoint_time)\n241\n242 # Loop to send the required setpoint at the desired time intervals.\n243 for i in range (steps):\n244 crazyflie.commander.send_hover_setpoint (0, 0, (altitude / steps * i), 0)\n245 time.sleep (setpoint_time)\n246\n247 # Ensure the Crazyflie has reached the desired altitude.\n76\n248 crazyflie.commander.send_hover_setpoint (0, 0, 0, altitude)\n249 time.sleep (setpoint_time)\n250\n251 # Function to vertically land the Crazyflie.\n252 def land (crazyflie, altitude):\n253\n254 # Print an update to the shell for monitoring.\n255 print (\"Crazyflie is landing from the current altitude.\")\n256\n257 # Define the desired time in which to move and the number of setpoints to send.\n258 action_time = 1\n259 setpoint_time = 0.05\n260 steps = int (action_time / setpoint_time)\n261\n262 # Loop to send the required setpoint at the desired time intervals.\n263 for i in range (steps):\n264 crazyflie.commander.send_hover_setpoint (0, 0, (- altitude / steps * i), 0)\n265 time.sleep (setpoint_time)\n266\n267 # Ensure the Crazyflie has landed and becomes stationary.\n268 crazyflie.commander.send_stop_setpoint ()\n269 time.sleep (setpoint_time)\n270\n271 # --------------------------------------------------------------------------------\n272 # Define Variables\n273 # --------------------------------------------------------------------------------\n274\n275 # Set the variables for target detection and tracking.\n276 print (\"Setting the variables to be used.\")\n277 res_x = 160\n278 res_y = 120\n279 fps = 30\n280 time_start = 0\n281\n282 # Set the variables for Crazyflie communication control.\n283 uri = \"radio://0/80/2M/E7E7E7E7E8\"\n284 logging.basicConfig (level = logging.ERROR)\n285 crazyflie = Crazyflie (rw_cache = \"./cache\")\n286\n287 # Set the variables for the initial setup before tracking.\n288 altitude = 0.4\n289 yaw = 0\n290 #velocity_max = 0.4\n291 focal_length = 113.5\n77\n292\n293 # Find basic requirements from the user.\n294 record = input (\"Must the source be recorded as a video? [Y/N] \")\n295 if record == \"Y\":\n296 version = input (\"Must basic [B] or combined [C] output be recorded? [B/C] \")\n297 if version != \"B\" and version != \"C\":\n298 print (\"! The input for the recording version is invalid.\")\n299 raise SystemExit\n300 elif record != \"N\":\n301 print (\"! The input for the recording of the source is invalid.\")\n302 raise SystemExit\n303\n304 # --------------------------------------------------------------------------------\n305 # Perform Checks\n306 # --------------------------------------------------------------------------------\n307\n308 # Identify the source for use and recording if desired.\n309 print (\"Identifying the source for use and recording if desired.\")\n310 source = cv.VideoCapture (0)\n311 source.set (cv.CAP_PROP_FRAME_WIDTH, res_x) # Alternate identifier: 3.\n312 source.set (cv.CAP_PROP_FRAME_HEIGHT, res_y) # Alternate identifier: 4.\n313 if record == \"Y\":\n314 codec = cv.VideoWriter_fourcc (*\"XVID\")\n315 if version == \"B\":\n316 video = cv.VideoWriter (\"Out.avi\", codec, fps, (res_x, res_y), True)\n317 elif version == \"C\":\n318 video = cv.VideoWriter (\"Out.avi\", codec, fps, (res_x * 2, res_y * 2), True)\n319\n320 # Ensure the source is open and available.\n321 active = True\n322 strikes = 0\n323 if source.isOpened == False:\n324 print (\"! The source is not open. Trying to open the source.\")\n325 source.Open ()\n326 if source.isOpened == False:\n327 print (\"The source is not open.\")\n328 active == False\n329 elif source.isOpened == True:\n330 print (\"The source is open and available.\")\n331\n332 # Check that the source is operating correctly.\n333 print (\"Checking that the source is operating correctly.\")\n334 check = input (\"Should the source be checked to be capturing correctly? [Y/N] \")\n335 if check == \"Y\":\n78\n336 correct, frame = source.read ()\n337 if correct == False:\n338 print (\"A frame could not be read correctly.\")\n339 correct = \"N\"\n340 elif correct == True:\n341 cv.imshow (\"Image Test\", frame)\n342 cv.waitKey (1)\n343 correct = input (\"Is the capture displayed correctly? [Y/N] \")\n344 if correct == \"N\":\n345 print (\"! The capture is not operating correctly.\")\n346 active = False\n347 cv.destroyAllWindows ()\n348\n349 # --------------------------------------------------------------------------------\n350 # Main Project Loop\n351 # --------------------------------------------------------------------------------\n352\n353 # Execute the functions to perform visual servoing and target tracking.\n354 if __name__ == \"__main__\":\n355\n356 # Initialize the low-level drivers (do not list the debug drivers).\n357 cflib.crtp.init_drivers (enable_debug_driver = False)\n358\n359 # Initialise the SyncCrazyflie class for function blockings.\n360 with SyncCrazyflie (uri, cf = crazyflie) as crazyflie_sync:\n361\n362 # Set the parameters for control and rest the extended Kalman filter.\n363 crazyflie = crazyflie_sync.cf\n364 set_initial_position_origin (crazyflie)\n365 reset_estimator (crazyflie)\n366 #crazyflie.param.set_value (\"posCtlPid.xyVelMax\", \"velocity_max\")\n367 #crazyflie.param.set_value (\"posCtlPid.zVelMax\", \"velocity_max\")\n368 #crazyflie.commander.set_client_xmode (True)\n369\n370 # Load the current frame from the source and process the image. This is not\n> for target detection, but acts as a buffer to load the video window.\n371 correct, frame = source.read ()\n372 frame, mode, threshold, morphology = processing_gray (frame)\n373 frame, contours, centroid_x, centroid_y, area = target_detection (frame,\n> morphology, time_start, res_x, res_y)\n374 monitor_minimum (frame, record)\n375 cv.waitKey (200)\n376\n377 # Record the current time as the start of the test.\n79\n378 time_start = time.time ()\n379\n380 # Take off to an altitude of approximately 0.4m.\n381 take_off (crazyflie, altitude)\n382\n383 # Begin capture of the video frames and image processing.\n384 print (\"Beginning capture of the video frames and image processing.\")\n385 print (\"To terminate the capture, press [Q] in the video window.\")\n386 print (\"Alternatively, press [ctrl+c] in the shell window.\")\n387 try:\n388 while active == True:\n389\n390 # Load the current frame from the source.\n391 correct, frame = source.read ()\n392\n393 # Minimum grayscale processing with results video capture.\n394 frame, mode, threshold, morphology = processing_gray (frame)\n395 frame, contours, centroid_x, centroid_y, area = target_detection\n> (frame, morphology, time_start, res_x, res_y)\n396 ##frame, orientation = target_detection_orientation (frame,\n> contours) # Uncomment for yaw orientation tracking.\n397 monitor_minimum (frame, record)\n398\n399 # Estimate the camera altitude and target centroid position.\n400 if area < 100 or area > 1000:\n401 print (\"The detected area is inconsistent with expectations.\")\n402 land (crazyflie, position_z)\n403 crazyflie.commander.send_stop_setpoint ()\n404 active = False\n405 break\n406 position_z = 9.128 * area ** -0.484 # Disk Target\n407 ##position_z = 13.47 * area ** -0.492 # Rectangle Target\n408 position_x = centroid_x * (position_z / focal_length)\n409 position_y = centroid_y * (position_z / focal_length)\n410 ##yaw = orientation # Uncomment for yaw orientation tracking.\n411\n412 # Based on the target, send a position setpoint to the Crazyflie.\n413 crazyflie.commander.send_position_setpoint (position_x, position_y,\n> position_z, yaw)\n414\n415 # Display the target centroid position and camera altitude. This\n> dramatically slows down video capture due to printing to the shell.\n416 #monitor_text (centroid_x, centroid_y, position_z, orientation)\n417\n80\n418 # Look for the designated key to terminate the capture.\n419 key = cv.waitKey (1)\n420 if key == ord (\"Q\"):\n421 print (\"Termination key from [Q] was detected.\")\n422 land (crazyflie, position_z)\n423 crazyflie.commander.send_stop_setpoint ()\n424 active = False\n425\n426 # Look for the designated key to terminate the capture.\n427 except KeyboardInterrupt:\n428 print (\"KeyboardInterrupt from [ctrl+c] was detected.\")\n429 land (crazyflie, altitude)\n430 crazyflie.commander.send_stop_setpoint ()\n431 active = False\n432\n433 time_end = time.time ()\n434\n435 # --------------------------------------------------------------------------------\n436 # Finishing Commands\n437 # --------------------------------------------------------------------------------\n438\n439 # Terminate the capture and release the source.\n440 print (\"Terminating the capture and releasing the source.\")\n441 source.release ()\n442 if record == \"Y\":\n443 print (\"The output video is \u2019Out.avi\u2019 in the current directory.\")\n444 video.release ()\n445 cv.destroyAllWindows ()\n446\n447 # --------------------------------------------------------------------------------\n448 # End\n449 # --------------------------------------------------------------------------------\nC ETHICS CONSIDERATIONS\nFor the completion of the project, there were no ethical considerations with regards to participants,\nas the requisite knowledge, information, and resources was acquired through self-derived means in\nthe form of published research, online resources, and analytical calculations. Furthermore, the results\nof the experiment were not doctored or plagiarized in any form so that the scientific method was\nthoroughly and sufficiently followed. As evaluated during the project proposal by a member of the\nSchool Ethics Committee, there were no ethical risks and ethical clearance was not required.\n81\nD RISK ASSESSMENT\nThe following precautions must be followed throughout experimentation:\n\u2022 At all times within the motion capture facilities, the operators, supervisors, and nearby bystanders must wear the required personal protective equipment (PPE) in the form of a laboratory dust\ncoat, steel-toed boots, and eye protection to reduce risk in the event of a crash.\n\u2022 There should be at least two operators or an operator and supervisor monitoring the Crazyflie.\n\u2022 The environment must be clear of obstacles not involved in the tests with no debris or loose items\nin the vicinity which could be unpredictably lifted by the thrust of the Crazyflie.\n\u2022 The ground control laptop must be charged or charging before testing or charging while testing\nto ensure it will not power off during a test while the Crazyflie is flying.\n\u2022 The Raspberry Pi must also have a reliable power supply for the duration of testing.\n\u2022 Before charging or testing, it must be ensured that the battery of the Crazyflie is not punctured\nor swollen. If the battery is damaged in any way, a supervisor must be notified immediately.\n\u2022 There must be no interference with the connections between the ground control laptop, Raspberry Pi, and Crazyflie to ensure there will be no disconnections while the Crazyflie is flying.\n\u2022 The state of the hardware should be visually checked before each test to ensure there are no\ndamages and the installation is still correct. This is specifically applicable to the propellers,\nwhere damages may have occurred in previous tests, and the correct blades must be installed on\nthe correct rotors for clockwise or counter-clockwise rotation. For the Crazyflie, A, A1, or A2\nindicate clockwise rotation and B, B1, or B2 indicate counter-clockwise rotation.\n\u2022 At the start of a test, the battery of the Crazyflie should always be fully charged. If so, it must\nalso be ensured that the battery installation is correct and secure to the frame without metal or\nsharp parts contacting the battery and without any possibility of a short-circuit occurring.\n\u2022 Once the Crazyflie is placed on solid ground and powered on, the status LEDs should be check\nfor any errors detected while the firmware performs internal self-checks during start-up. For the\nCrazyflie, the LEDs labelled M1 and M4 will indicate the result of the self-checks, where the M4\nLED rapidly blinks green five times if the self-checks are passed or the M1 LED rapidly blinks\nred five times then pauses and repeats again if the self-checks are failed. After the self-checks\nhave passed, the M1 LED should blink twice per second if the sensors are calibrated or the M1\nLED will blink once every two seconds if the calibration failed (for calibration, the Crazyflie\nmust be still and the ground should be level). If the M4 LED is constantly red, the battery is low\nand the Crazyflie should not be flown. The M2 and M3 LEDs should be constantly blue and are\nnot related to the self-checks (used to indicate orientation), unless in a different state for charging\nor firmware flashing. The motors will also initially rotate in sequence to indicate operation.\n\u2022 The control scripts on the Raspberry Pi must be checked and free from errors and warnings\nbefore connecting to the Crazyflie. If unsure, the Crazyflie can be connected and the control\n82\nscripts can be run while there are no propellers attached to the rotors or while safely holding the\nCrazyflie to observe if there will be any unexpected behaviour (the Crazyflie should be gripped\nfirmly at the bottom of the frame to avoid the propellers).\n\u2022 When it is ready for a test, the Crazyflie should be placed on solid and level ground with the\nforward direction pointing away from the operators, supervisors, and nearby bystanders.\n\u2022 When it begins flying for a test, the Crazyflie should start the motors, take off vertically, and\nhover at a fixed position to ensure correct, controlled, and stable operation before continuing.\n\u2022 Once the test is complete and the Crazyflie has landed with inactivity, the Raspberry Pi should be\ndisconnected and the battery of the Crazyflie should be removed (do not pull the battery cables).\nThe risks involved in the experiment have been identified and evaluated. This involved categorizing\nthe severity, likelihood, and type of the risks, and proposing precautionary actions to further prevent\nthe risks. The complete risk assessment is seen in Table 6 and the official standard operating procedure\nin the motion capture facilities for quadrotor experiments is seen in Figure 51.\nTable 6: Evaluation of the potential risks involved in the experiment.\nActivity:\nVenue:\nRisk Type Risk Description Severity Likelihood Risk Score Action Type Action\nMechanical Due to a loss of control or unpredictable\nbehaviour, the Crazyflie may collide with\nan operator or person in the vicinity of the\nexperiment. This is especially concerning\nfor the propellers possibly causing shortterm injuries to eyes.\nMinor Possible 5 Procedure,\nPPE\nOnly necessary personnel should be\nallowed within the motion capture\nfacilities and operating vicinity. Safety\nglasses may also be worn within the\nmotion capture facilities.\nMechanical Hair or loose fitting clothing may become\ncaught or tangled in the motors and\npropellers of the Crazyflie.\nMinor Possible 5 PPE Hair must be tied up and loose clothing\nmust be sufficiently restricted.\nMechanical If the Crazyflie crashes, parts can be\ndislodged and act as shrapnel.\nMinor Rare 3 PPE Safety glasses may be worn within the\nmotion capture facilities.\nElectrical Minor electric shocks may be experienced\nfrom handling the Crazyflie and\nRaspberry Pi, but the voltage and current\nof these shocks are very minimal.\nMinor Unlikely 4 Procedure In manufacturing and grounding, it is\nunlikely for electrical shocks but the\nCrazyflie and Raspberry Pi must still be\nhandled with care such that they are not\ndamaged and become hazardous.\nChemical The LiPo battery may erupt (fire,\nexplosions, and toxic smoke) if exposed\nto high temperatures or penetrated, where\nthe lithium will be exposed which is\nhighly flammable and potentially\nexplosive when mixed with air and may\ncause chemical burns. This may occur\nduring use, charging, or storage.\nMajor Possible 7 Modification The battery must be housed correctly\nwithin the frame of the Crazyflie so\nexposure is minimised in the event that it\nunexpectedly erupts. The battery must be\ncheck before and after each use. A good\nquality and reliable battery must be used\nfrom the Crazyflie suppliers.\nErgonomic The thrust of the Crazyflie may pick up\ndust, which may be breathed in by or enter\nthe eyes of the operator or personnel in\nthe operating vicinity.\nMinor Rare 3 Elimination It should be ensured that the motion\ncapture facilities and operating vicinity\nare sufficiently clean and dust-free.\nErgonomic To place the target and Crazyflie on the\nfloor, the operator is required to bend\ndown multiple times\nMinor Rare 3 Procedure The operator must correctly bend with\ntheir knees, instead of their back, to\navoid straining muscles.\nErgonomic The black mats in the motion capture\nfacilities form an uneven surface with the\nground, which lead to tripping.\nMinor Rare 3 Procedure The operator must take care when\nmoving around the motion capture\nfacilities to avoid tripping.\nSigned: Edward Rycroft Date: 2019/10/28\nQuadrotor Visual Servoing For Moving Target Tracking\nNorth West Engineering Laboratory, Robotics Lab\n83\nFigure 51: Standard operating procedure in the motion capture facilities for quadrotor experiments.\nE BIGQUAD DEVELOPMENT\nTo complement the end-point open-loop control, an investigation into end-point closed-loop control\nwas initially performed using a larger quadrotor, on-board camera with the Pi Camera, and on-board\nprocessing with the Raspberry Pi. However, it was not possible for the quadrotor to fly safely due\nto the risk of damaging the exposed LiPo battery, so focus was shifted to more in-depth end-point\nopen-loop control only. The partial development is included as a reference for future progress.\nE.1 END-POINT CLOSED-LOOP CONTROL\nFor end-point closed-loop control, the basic arrangement for location estimation is essentially the\nsame as for end-point open-loop control, except the camera would be mounted to the quadrotor instead\nof being fixed in the surroundings. This is illustrated in Figure 52, with similarity to Figure 13.\nIt might be necessary to investigate compensation to stabilize the on-board camera while rolling and\npitching, as seen in Figure 53, where the field of view becomes inaccurately distorted with incorrect\nmeasurements of the position of the target. Compensation could be implemented using mechanical\ncompensation, where the on-board camera is mounted with a two degree-of-freedom gimbal which\n84\nCamera View\nQuadrotor\nTranslational\nDOFs\nTarget Translational DOFs\nGround\nTwo-Dimensional\nPerspective\nFigure 52: Arrangement for end-point closed-loop control through detection and tracking of a target.\nisolates the on-board camera from the effects of rolling and pitching; or digital compensation, where\nthe image is slightly cropped to allow for virtual stabilisation [7]. Mechanical compensation will\nretain the field of view while being faster without processing delays as compared to digital compensation, so it is recommended for mechanical compensation to be used if compensation is required [7].\nHowever, no compensation should first be adopted to judge if it is satisfactory.\nStationary Hover\nQuadrotor\nTarget Camera\nView\nPitch / Roll\nQuadrotor\nTarget Camera\nView\nGimbal Compensation\nQuadrotor\nTarget Camera\nView\nFigure 53: Comparison between the changes in the field of view during extreme/exaggerated rolling\nor pitching without (middle) and with (right) compensation as the target begins a motion.\nE.2 BIGQUAD APPARATUS\nFor the quadrotor, the Crazyflie control board was mounted to a TransTEC Freedom frame, which has\ndiagonals of 215mm and is constructed from 3K carbon fibre with aluminium 7075 supports for the\nshell and plastic bumpers at the rotor mounts to produce a mass of 116g. The electronic components\nfor the flight of the quadrotor include four EMAX Bullet 30A electronic speed controllers (ESCs),\nwith a mass of 4.9g, BB2 processor, current rating up to 30A, and support for DShot, Multishot, and\nOneshot protocols; four EMAX RSII 2206-1700KV rotor motors, with a mass of 26.7g and maximum\nthrust up to 2040N/kg; four plastic propellers, with a mass of 4g and length of 127mm; and Tattu Rline 75C LiPo battery with a mass of 160g, four cells in series, and capacity of 1300mA.hr at 14.8V.\n85\nTo facilitate the connection between the Crazyflie and ESCs, the Bitcraze BigQuad expansion deck\n(subsequently referred to as BigQuad deck) will be used. This deck features breakout header connectors for the four ESCs, where a voltage and ground will be supplied along with a PWM signal at\na default frequency of 400Hz to control the motors [30]. There are also additional breakout header\nconnectors for other accessories, such as a GPS receiver, battery voltage and current monitor, buzzer,\nchaotic pulse position modulation (CPPM) receiver, or I2C communication protocol [30]. The connections of the BigQuad deck are seen in Figure 54 with the final assembly seen in Figure 55.\nUnfortunately, the BigQuad deck is not compatible with the Flow deck without modifying the firmware and components of the hardware. As a result, the control and stabilisation is slightly more difficult and requires a different method based on measurements relative to the target detection. Moreover,\nthe original internal cascading PID controllers for attitude flight control of position and velocity are\ntuned for the original frame, rotor motors, propellers, and battery, so it might be necessary to re-tune\nthe controller gain values if the flight is found to be unstable or unresponsive.\nESC ESC\nESC ESC\nMotor\nOne\nMotor\nTwo\nMotor\nThree\nMotor\nFour\nTop View Bottom View\nLiPo Battery\nSignals\nFrom\nProcess\nMicroController\n25mm 25mm\n40mm\nFigure 54: Schematic (left) and photographs (right) showing the Bitcraze BigQuad expansion deck\nand connections to the EMAX Bullet 30A ESCs and EMAX RSII 2206-1700KV rotor motors [31].\n3D\nPrinted\nStand\n3D\nPrinted\nBase\nRaspberry Pi\nPi Camera Crazyflie,\nBigQuad\nPropeller\nMotor\nPower\nDistribute\nBattery\nTop View\nBottom View\nESCs Frame\nFigure 55: Photographs showing the top isometric (left) and bottom isometric (right) views of the\nlarger quadrotor which was manually assembled, including the parts for visual servoing.\n86"
  },
  {
    "id": "realtime_control/283646155Realtimeges.txt",
    "content": "See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/283646155\nReal-time gesture recognition using a humanoid robot with a deep neural\narchitecture\nArticle \u00b7 February 2015\nDOI: 10.1109/HUMANOIDS.2014.7041431\nCITATIONS\n36\nREADS\n636\n4 authors:\nPablo Barros\nUniversity of Hamburg\n95 PUBLICATIONS   1,746 CITATIONS   \nSEE PROFILE\nGerman I. Parisi\nUniversity of Hamburg\n64 PUBLICATIONS   3,439 CITATIONS   \nSEE PROFILE\nDoreen Jirak\nIstituto Italiano di Tecnologia\n26 PUBLICATIONS   466 CITATIONS   \nSEE PROFILE\nStefan Wermter\nUniversity of Hamburg\n666 PUBLICATIONS   10,341 CITATIONS   \nSEE PROFILE\nAll content following this page was uploaded by German I. Parisi on 01 June 2016.\nThe user has requested enhancement of the downloaded file.\nIn: Proc. of the IEEE-RAS International Conference on Humanoid Robots (Humanoids 14), pp. 83, Madrid, Spain (2014)\nReal-time Gesture Recognition Using a Humanoid Robot with a Deep\nNeural Architecture\nPablo Barros, German I. Parisi, Doreen Jirak and Stefan Wermter\nAbstract\u2014 Dynamic gesture recognition is one of the most\ninteresting and challenging areas of Human-Robot-Interaction\n(HRI). Problems like image segmentation, temporal and spatial\nfeature extraction and real-time recognition are the most prominent issues to name in this context. This work proposes a deep\nneural model to recognize dynamic gestures with minimal image\npreprocessing and real-time recognition in an experimental set\nup using a humanoid robot. We conduct two experiments with\ncommand gestures in an offline fashion and for demonstration\nin a Human-Robot-Interaction (HRI) scenario with the robot\ngiving audio feedback for the user. Our results show that the\nproposed model achieves high classification rates of the gestures\nexecuted by different subjects, who perform them with varying\nspeed. We demonstrate that our system performs in real-time.\nI. INTRODUCTION\nThere is a trend in the robotic community towards integration of robots into assistive systems in everyday life\nsituations and different areas, e.g. in medical surgery or\nhelping systems for elderly people [1].\nIn the context of humanoid robots, the demand for intuitive communication interfaces for natural Human-RobotInteraction (HRI) is increasing. The most significant aspects\nfor HRI comprise the correct understanding and processing\nof the user input, robustness concerning varying environmental situations and realtime recognition performance.\nIn the area of gesture recognition several different approaches have been established using different input devices and learning algorithms. Among them, development\nof neurally inspired algorithms is of special interest as they\noffer a model for brain-like stimuli processing, which allows\nadaption to a changing environment, is robust against noise\nand provides instantaneous reactions. Before performing gestures ourselves, we first perceive them as visual stimuli over\ntime,which motivates us using neural computational models,\nin particular Convolutional Neural Networks (CNN).\nCNN has been introduced as a computational approach\nwhich mirrors the hierarchical stages for visual processing\nin the visual cortex. An incoming visual percept is processed in a simple cell layer extracting edge features. The\noutcome of this extraction is then passed to complex cells\nin the next layer, where these features are pooled together.\nThese computations alternate between the cell types until\nthe neurons show high coding specificity and are invariant to\nscale, rotation and noise. This approach has been successfully\napplied to object recognition where only single images\nThe authors are with University of Hamburg - Department of Computer\nScience, Vogt-Koelln-Strasse 30, 22527 Hamburg - Germany.\nbarros,parisi,jirak,wermter\n@informatik.uni-hamburg.de\nwere used for classification. A prominent example is the\ncipher classification introduced in [2]. A similar approach\ncalled HMAX [3] performs template matching and pooling\noperations from Gabor filtering at different scales and with\ndifferent orientations. It showed very good recognition rates\non benchmark object databases, which underlines the crucial\nimpact of implementing a cascading visual system to obtain\ninvariant and insensitive features.\nDeep learning architectures are also prominently applied\nin different areas of HRI. For autonomous robotic behaviour\nthe work presented in [4] demonstrated higher recognition\nrates using a max-pooling CNN (MPCNN) compared to\nother learning methods like SVM. The idea was to provide\na swarm of mobile robots with reliable vision information\nderived from counting gestures which are performed using\na coloured glove. Although the authors could show superior\nperformance of their architecture in terms of 96% recognition\nrate and real-time processing they did not model the temporal\ndimension.\nTo bridge the gap, a more recent approach for action\nrecognition [5] extends CNN with 3D kernels capturing motion information along the frames of an action performance\nstream. Instead of using single images for convolution,\nthe whole computation is performed on a frame cube of\npredefined size, i.e. frames to consider in the video. The\nfeature maps are created using different kernels to increase\nthe diversity of features. Moreover, the author described\nextraction of high-level motion information by defining auxiliary features presented to the architecture as bag-of-words\nand added to the output layer. The system was evaluated with\nan airport surveillance database that contains three action\ntypes and showed superior results compared to other models\nlike spatial pyramidal matching features. Also for the KTH\nbenchmark DB for action recognition, e.g. boxing and hand\nclapping, the results were competitive to [6] and superior to\nan unsupervised probabilistic learning approach on extracted\ntime-space points of interest [7].\nAs our work focuses on dynamic gestures, we also have to\ndeal with different timescales and long-range dependencies\nto capture the gestures\u2019 semantics. The different demands\non a gesture recognition system combined in a model are\ndescribed in [8], based on data captured with a Kinect\ndepth sensor. The stream is separated into depth information\nemployed as input to a four-layer CNN for each hand and\ninto a skeleton part for the whole body motion. The first\nstage is referred to as dynamic pose and catches only local\ninformation. The output of the different computational steps\nis then aggregated and serves as input to a Recurrent Neural\nNetwork. They evaluated their system on the ChaLearn 2013\ndata set for fused audio and vision recognition and could\ncompete well with other methods, resulting in rank 6 of 20\nfinal presentations.\nAlthough the presented work showed promising results,\nwe point out some critical issues: standard methods for\ngesture recognition is to use specifically coloured objects\nlike a red ball to be tracked or as in [4] to use gloves.\nThis, however, introduces an additional preprocessing step of\nreduce the input to a particular colour or learning a specific\ncolour distribution. We also recognized that in literature only\na few papers deal with CNN in the domain of dynamic\ngestures. As mentioned above, this is due to the fact that\nCNN were introduced rather for single image processing and\nclassification. The extension of this approach as in [5] for\naction recognition motivates us to this more neurobiological\napproach for commanding gestures comprising motions.\nTherefore, we extend the idea of CNNs in two ways:\nfirst, we enhance the computational capacity of the model\nby introducing 3D kernels suitable for noise-affected images\nas is the case when captured in a stream in ambient living\nsituations and sensor limitations. Second, we extend CNN\nto the temporal domain by adding the capability to generate\nand learn motion representations. In our paper, we focus on\ngestural communication with the Nimbro robot platform.\nTherefore, we defined 5 command gestures: \u2019Circle\u2019,\n\u2019Point Left\u2019, \u2019Point Right\u2019, \u2019Stop\u2019 and \u2019Turn Around\u2019, and\n\u2019Stand Still\u2019 as our reference standing position. In our\nscenario, we also embed a simple speech response toprovide\nuser feedback.\nThe paper structure is as follows: In the first section,\nwe introduce our deep neural architecture and processing\nstages in the network. We then explain our experimental\nmethodology in section 2 and present our results derived\nfrom the experiments in the following section. Finally, we\nprovide the reader with a discussion part and some future\nwork suggestions.\nII. DEEP TEMPORAL AND SPATIAL FEATURE\nEXTRACTION LEARNING FRAMEWORK\nIn order to extract the temporal and spatial features of a\ngesture sequence, we use a deep neural network architecture.\nThis architecture is able to create a representation of motion\nand uses a series of deep layers to identify and extract the\nfeatures that represent the changes during the gesture execution as this underlies subject variability. The architecture\nis divided into two steps: Motion representation and motion\nfeature extraction. Both steps work together and are part of\nthe proposed architecture, illustrated in Figure 1.\nA. Motion representation\nThe first layer of the architecture is responsible to create\nthe motion representation. This layer receives N gray scale\nframes, without the application of any preprocessing step,\nand creates a representation based on the difference of each\npair of frames. The layer works in a sequential way, receiving\nthe frames one after the other. After receiving a pair of\nFig. 1: Proposed deep neural architecture used to recognize\ndynamic gestures. The first layer receives a number of\nframes and generates a motion representation. An MCCNN\nimplementation is used to learn and extract the features\nfrom the motion representation and use them to classify the\ngesture.\nframes, this layer computes an absolute difference and sums\nup the resulting frame to a stack of frames. This operation\nis represented by M:\nM =\nX\nN\ni=1\n|(Fi\u22121 \u2212 Fi)| W s, (1)\nwhere N is the number of frames, Fi represents the\ncurrent frame and W s is the weighted shadow. The absolute\ndifference of each pair of frames removes irrelevant parts of\nthe gesture execution, being able to extract the background\nor any other detail in the image that is not part of the\ngesture motion. By summing up the results it is possible to\ncreate a shape representation of the motion, imprinting it in a\nmotion representation image. The weighted shadow is used to\ncreate different gray scale shadows in the final representation\naccording to the time that each frame is presented. The\nweighted shadow is defined as W s = i/t, where t is the\nmemory size. The memory size defines how many frames\nwill be important in the gesture execution. For example,\na \u201dStop\u201d gesture will be faster than a \u201dTurn Around\u201d\ngesture, meaning that it will have a smaller memory size.\nAn adjustment of the memory size based on each gesture\nexecution makes the motion representation robust against\ngestures with varying amounts of frames. The utilization\nof weighted shadows to create the motion representation\nFig. 2: Illustration of the output of each pair of convolution\nand max-pooling operations. This example uses a two layers\nMCCNN. Using a motion representation as input, the MCCNN applies a Sobel operator in both directions, horizontal\n(X) and vertical (Y). At the end a representation containing\n3 feature sets, each one with 3x3 pixels is generated.\nis responsible for creating a time feature imprinted in the\nfinal motion image. This representation contains the shape\nof the motion and, with the help of the weighted shadows,\nthe information of when each single posture happened.\nB. Spatial and time features fusion\nThe second step is responsible for identifying and extracting relevant features in the motion representation. To\nachieve this, the previous layer is attached to a Multi Channel\nConvolutional Neural Network (MCCNN) [9]. The MCCNN\nreceives an image containing the motion representation and\napplies a series of convolutional and max-pooling operations\nthat, at the end, will generate a feature vector. In the proposed\nmodel an MCCNN with three channels is implemented.\nEach channel receives a different version of the motion\nimage. The first one receives the original motion image. The\nsecond and third receive the resulting image after applying\na Sobel operator in both directions, horizontal(Sx) and\nvertical(Sy).The Sobel operators encode our prior knowledge\non features, and our experiments showed a improve in\nthe model performance. The idea behind the multichannel\nimplementation is to use the different information provided\nby each channel input in different ways. As each channel\nhas its own filter maps and weights, it is possible to learn\nwhich features are more important for the final feature set\nin each channel. The Sobel operator uses two different 3x3\nkernel filters, defined as:\nSx =\n\uf8ee\n\uf8f0\n\u22121 0 +1\n\u22122 0 +2\n\u22121 0 +1\n\uf8f9\n\uf8fb , Sy =\n\uf8ee\n\uf8f0\n+1 +2 +1\n0 0 0\n\u22121 \u22122 \u22121\n\uf8f9\n\uf8fb . (2)\nThe utilization of the Sobel filters helps in the discrimination of the motion shape in the image. When applied in\nboth directions these filters can detail the shape aspects of\nthe motion. The channel that receives the original image\nis responsible to extract the time structure created by the\nweighted shadows.\nTo create a feature set invariant to position and scale, a\ncubic kernel implementation is used. In the CNN implementation the convolution layers are applied as 2D filter\nmaps, each one with independent weights, to be robust\nagainst noise and small changes in the pixels intensities\n[2]. The cubic kernel allows the application of a 3D filter\nin a stack of images. Each filter map has 3D kernels, still\nwith independent weights, that are applied to a sequence\nof images of the same motion representation. In the cubic\nimplementation, the value of each unit(x,y,z) at the nth filter\nmap in the cth layer is defined as:\nv\nxyz\nnc = tanh(bcn+\nX\nm\nH\nXi\u22121\nh=0\nW\nXi\u22121\nw=0\nR\nXi\u22121\nr=0\nw\nhwr\ni(c\u22121)mv\n(x+h)(y+w)(z+r)\n(m\u22121) )\n(3)\nwhere tanh is the hyperbolic tangent function, bcn is the\nbias for the nth filter map of the cth layer, m indexes over the\nset of feature maps in the (c-1) layer connected to the current\nlayer c. In the equation, w\nhwr\nijm is the weight of the connection\nbetween the unit (h,w,r) within a region, or kernel, connected\nto the previous layer (c \u2212 1). Hi and Wi are the height\nand width of the kernel and z indexes the image in the\nimage stack, Ri\nis the amount of pictures stacked together\nrepresenting the new dimension of the kernel.\nTo produce invariant features using the cubic kernel, the\nimage stack is created with different examples of the same\nclass. This way, the cubic kernel receives a stack of different\nmotion images, performed with the user in different positions\nand distance to the camera.\nIn the MCCNN implementation each convolutional layer is\nfollowed directly by a max-pooling layer. Each max-pooling\nlayer compresses the data from the convolutional layer in\nsmaller images. Each filter map is divided into regions,\nand each region is used as input for a unit in the maxpooling layer. This operation enhances invariance to scale\nand distortion of the input [10].\nTo train the model, the MCCNN is attached to a hidden\nlayer and then connected to a logistic regression classifier.\nThe result of the classifier is used to calculate the error\nfor the weights update using the backpropagation algorithm.\nThis means that all the filters in the channels are updated\nindividually, but the final error is calculated as a whole.\nUsing this strategy, the filters in each channel can be trained\nto have different roles in the feature extraction but must be\nsynchronized with the final feature representation.\nAfter the training, the channel receiving the original image\nwill be mostly responsible for identifying the different pixel\nintensities in the image, being able to differentiate between\nthe weighted shadows imprinted in the motion representation\nFig. 3: Illustration of the five commands and standing position in the recorded dataset. Following each sequence it is an\nexample of the motion image generated by the proposed model.\nimage. The two channels with the Sobel filters will be\nstrongly trained to extract the motion shape patterns, with\nhighlighted edges in both directions, horizontal and vertical.\nAfter the filters are trained, the hidden layer and logistic\nregression can be detached of the model and the filters can\nbe used to extract features for other classifiers. Figure 2\nillustrates the whole process of feature extraction after the\nmodel is trained. In the example, the model has 2 layers,\neach one composed of a pair of a convolutional and a maxpooling layer. At the end, three feature sets, each one with\n3x3 pixels, are used to represent the full gesture.\nIII. EXPERIMENTS\nWe set up two experiments to evaluate our model. One,\naimed to evaluate the recognition rate, training time and\nrecognition time for the proposed model, was called the\noffline experiment. The other one applied the trained filters\nin a real-time recognition scenario with a humanoid robot\ncalled the Nimbro experiment.\nFor the offline experiment, a data set containing six\nclasses was recorded. The classes represent five gesture\ncommands and a standing position with no gesture execution.\nThe commands are as follows: \u2019Circle\u2019, \u2019Point Left\u2019, \u2019Point\nRight\u2019, \u2019Stop\u2019, and \u2019Turn\u2019. The data set contains 60 examples\nfor each gesture, executed by one subject. Each frame has\na resolution of 640x480 pixels and each gesture sequence\nhas varying amounts of frames. In sum, 360 videos were\nrecorded, and illustrations of the gestures are shown in Figure\n3.\nThe learning was executed with the dataset separated\ninto 60% of the gestures for training and 40% for testing.\nThe frames were resized to 100x100 pixels and all the\nframes were used to compose the motion representation.\nThe MCCNN was implemented with a depth of two layers\nand connected to the hidden layer and logistic regression\nclassifier for training the filters. We performed experiments\nwith different parameter values, following the indications of\n[11], and the best performing parameters are shown in Table\nI.\nThe experiment was performed 30 times and the mean and\nstandard deviation of the F-Score, recognition and training\nTABLE I: Parameters of the MCCNN for training session.\nParameters Layer 1 Layer 2\nFilters 20 50\nKernel size 5x5x5 4x4\nSub sampling size 5x5 5x5\nNeurons hidden layer 500\nLearning rate 0.01\ntimes were collected and are shown in the next section.\nIn each execution, the data for either training or testing is\nrandomly chosen. We implemented the system using Python\nand Theano1\n, running on a machine with an Intel Core I5\nprocessor and 8GB of RAM memory.\nFor the second experiment we applied our framework to\nan HRI scenario with the Nimbro humanoid robot. In this\nscenario, the robot is positioned in a room so that it captures\nthe performing subject frontal to the RGB camera. The robot\ngives voice feedback for each recognized gesture in realtime. The Nimbro is 95cm tall and has a weight of 6.6kg\nincluding the battery [12]. It uses a Zotac Zbox Nano XS\nPC, running a Linux Ubuntu distribution. This PC has a 1.65\nGHz Dual-Core AMD E-50 processor and has 2GB of RAM.\nIt contains a Logitech C905 USB camera with customized\nwide-angle lens, that produces images with a resolution of\n640x480 pixels.\nThe model was deployed in the robot, after training the filters using the recorded dataset, and used for real-time recognition. To provide continuous classification, every frame was\ncollected and sent to the MCCNN. The experiments with\nthe robot were conducted with 3 different subjects, each one\nexecuting 10 times each gesture in a random order. None\nof the subjects executed the gestures in the recorded dataset.\nThe mean of the F-Score is shown in the next session. Figure\n4 illustrates the scenario for this experiment.\nIV. GESTURE RECOGNITION SYSTEM INTERFACE\nTo be able to give spoken feedback, a communication\nsystem was developed and deployed in the robot. The system\n1http://deeplearning.net/software/theano/\nFig. 4: Scenario for the second experiment, using the Nimbro\nrobot. The Robot is positioned in front of the human and\nrecognizes the gestures continuously. After each recognition,\nthe Nimbro gives a spoken feedback with the recognized\ngesture.\nNimbro Camera\nGesture Recognition\nModule\nROS\nPublisher\nROS\nSubscriber\nSpeech Module\nROS\nPublisher\nROS\nSubscriber\nFig. 5: Diagram of system interface over ROS network with\nPublisher-Subscriber nodes.\nis composed of two main modules: one module for recognizing the learned gestures from visual input and the other for\nspeaking the recognized gestures with Nimbro. To interface\nthe different modules and devices of our architecture we use\nthe Robot Operating System (ROS).\nFor our interface implementation, we rely on a synchronous RPC-style communication over a ROS network\nimplemented with publisher-subscriber nodes. The publisher\nnode will continually broadcast a message. We broadcast a\nmessage over the network using a message-adapted class.\nThe subscriber node receives the messages on a given topic\nvia a master node, which keeps a registry of who is publishing and who subscribing. This architecture represents a\nrobust interface to connect different applications, e.g. written\nin different programming languages, over a common network\nof communication.\nA diagram of our system interface over the ROS network\nis illustrated in Figure 5. The gesture recognition module\nreceives input, i.e. raw RGB images, from the Nimbro\ncamera over the ROS network. Results of the recognition,\ni.e. gesture labels, are published for the speech module.\nV. RESULTS\nThe offline experiment used the recorded dataset to train\nthe model and to perform a classification of the gestures. The\nresults showed that the mean F-Score for all the gestures was\nFig. 6: F-Score obtained in both experiments. Nimbro experiment presented lower results, but still demonstrate the\ncapability of the model in recognizing dynamic gestures in\nreal-time using the humanoid robot.\n96.85%. In Figure 6 we show that Point Left and Standing\nproduced a lower F-Score compared to the others, due to the\nfact that the motion images generated from both are very\nsimilar. Even with the visual similarity, the model was still\nable to identify and classify them with an elevated F-Score.\nOne of the problems of a deep neural architecture is the\nnecessary time to train the model. One of the advantages of\nthe MCCNN is to be able to use smaller images and still be\nable to classify the presented patterns. In our experiments,\neach training routine, with 100 epochs, took 165.60 minutes\nto complete, with a standard deviation of 0.027 after 30\nexecutions. The recognition time was 0.039 seconds, with a\nstandard deviation of 0.0022. With such a smaller recognition\ntime, it is possible to use the proposed model in a real-time\nclassification scenario.\nIn the Nimbro experiment, the model was trained using the\nrecorded dataset, in the same way as for the first experiment.\nAfter the training, it was deployed in the Nimbro and used\nto classify the input obtained by its camera. Three different\npersons executed the gestures, none of them present in the\npreviously recorded dataset. The F-Scores for this experiment\nare also shown in Figure 6.\nFigure 7 shows the confusion matrix obtained for the\nNimbro experiment. In the confusion matrix we see that\nmost of the misclassification are related to the \u201dStand\u201d\nposition. This happens because most of the gestures contain\nthe \u201dStand\u201d position in the beginning and ending of their\nexecution. If the gesture is executed too fast or too slow, the\n\u201dStand\u201d position will still be captured and will be highlighted\nby the motion representation layer.\nWhen using the live classification with Nimbro the results\nare lower compared to the offline experiment, but still have\na significant F-score value when applied to a real-world\nscenario. The experiment shows that the model was able\nto recognize gestures with different persons, that were not\npresent in the training set, and in real-time.\nFig. 7: Confusion matrix obtained by Nimbro experiment,\nusing the Nimbro\u2018s camera to recognize the gestures in a\nreal-time recognition scenario.\nVI. CONCLUSION AND FUTURE WORK\nWe presented a neural framework extended from CNNs for\nthe recognition of commanding gestures in a HRI-scenario.\nTo test our approach we set up two experiments and extended\nthe recognition with audio feedback for the user. Opposed\nto [4] our framework needs no additional input devices nor\nspecific colour definitions, which is beneficial for a natural\nuser interface. Our work shows that the proposed model is\nsuited to be used in a real-world scenario. After the training,\nthe recognition time is small and the spatial-temporal features\nare extracted and learned. Although we conducted rather\ninitial experiments, we could show promising results for\ngesture classification. We detected very good accuracy for the\n\u2019circle\u2019, \u2019point right\u2019, \u2018stop\u2018 and the \u2019turn\u2019 gesture, but lower\naccuracy for \u2019point left\u2019 and \u2019stand\u2019, our baseline gesture.\nThis is due to the fact, that our system relies on motion\ninformation and has only minor focus for hand shape. The\n\u2019point left\u2019 gesture executed with the same hand as the \u2019point\nright\u2019 carries more motion information as the arm crosses the\nbody. For the \u2019point right\u2019 on the contrary the arm is raised\nup almost equal to the \u2019stop gesture\u2019. The only difference is\nthe orientation of the hand. So, we suggest to also provide\na shape- and orientation representation for such low-motion\ngestures as can be found in the dichotomized streams in the\nvisual cortex. Another interesting point worth mentioning\nis that in our live experiments with the Nimbro we could\nshow that our command vocabulary is recognized in realtime indifferent to a specific user, which puts emphasis on\nthe generalization capabilities of the MCCNN. In line with\nthat our approach also allows us to cope with intra- and intersubject variability in gesture performance, as our subjects\nperformed each gesture several times and had no information\nabout the execution speed. No time warping mechanisms\nor similar are necessary as is standard in variable-length\nsequence processing, thus avoids additional preprocessing.\nTherefore, we would like to use our extended gesture\ndatabase with gestures performed with one- and two hands\nfrom multiple subjects. Until now, our setting is restricted to\none-hand gestures and simplified illumination conditions. As\nthe model generates the motion features using raw images,\nlight conditions may affect the final results and our system\nis limited to one moving person in the scene. Thus, we are\nworking on a flexible mechanism for changes in lighting and\nadditionally extend the system for multi-person scenarios.\nIn line with the neural architecture proposed so far we are\ngoing to look into unsupervised methods for substituting\nthe labelling of training data. This will further increase the\nautonomous nature of learning, and thus robotic behaviour.\nACKNOWLEDGEMENT\nThis work was partially supported by CAPES Brazilian\nFederal Agency for the Support and Evaluation of Graduate\nEducation (p.n.5951-13-5), the DAAD German Academic\nExchange Service (Kz:A/13/94748) - CASY Project (Cognitive Assistive Systems), and by the DFG German Research\nFoundation (grant #1247) - International Research Training\nGroup CINACS (Cross-modal Interaction in Natural and\nArtificial Cognitive Systems).\nREFERENCES\n[1] G. Parisi and S. Wermter, \u201cHierarchical som-based detection of novel\nbehavior for 3d human tracking,\u201d in Neural Networks (IJCNN), The\n2013 International Joint Conference on, Aug 2013, pp. 1\u20138.\n[2] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, \u201cGradient-based\nlearning applied to document recognition,\u201d in Proceedings of the IEEE,\n1998, pp. 2278\u20132324.\n[3] T. Serre, A. Oliva, and T. Poggio, \u201cA feedforward architecture\naccounts for rapid categorization,\u201d Proceedings of the National\nAcademy of Sciences, vol. 104, no. 15, pp. 6424\u20136429, Apr. 2007.\n[Online]. Available: http://dx.doi.org/10.1073/pnas.0700622104\n[4] J. Nagi, F. Ducatelle, G. A. Di Caro, D. Ciresan, U. Meier, A. Giusti,\nF. Nagi, J. Schmidhuber, and L. M. Gambardella, \u201cMax-pooling convolutional neural networks for vision-based hand gesture recognition,\u201d\nin Proc. IEEE Int Signal and Image Processing Applications (ICSIPA)\nConf, 2011, pp. 342\u2013347.\n[5] S. Ji, W. Xu, M. Yang, and K. Yu, \u201c3D convolutional neural networks\nfor human action recognition,\u201d Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 35, no. 1, pp. 221\u2013231, Jan 2013.\n[6] H. Jhuang, T. Serre, L. Wolf, and T. Poggio, \u201cA\nbiologically inspired system for action recognition.\u201d in ICCV.\nIEEE, 2007, pp. 1\u20138. [Online]. Available: http://dblp.unitrier.de/db/conf/iccv/iccv2007.htmlJhuangSWP07\n[7] J. C. Niebles, H. Wang, and L. Fei-Fei, \u201cUnsupervised learning\nof human action categories using spatial-temporal words,\u201d Int. J.\nComput. Vision, vol. 79, no. 3, pp. 299\u2013318, Sept. 2008. [Online].\nAvailable: http://dx.doi.org/10.1007/s11263-007-0122-4\n[8] N. Neverova, C. Wolf, G. Paci, G. Sommavilla, G. W. Taylor,\nand F. Nebout, \u201cA multi-scale approach to gesture detection and\nrecognition,\u201d in ICCV Workshop on Understanding Human Activities:\nContext and Interactions (HACI 2013), Dec. 2013, pp. 484\u2013491.\n[Online]. Available: http://liris.cnrs.fr/publis/?id=6330\n[9] P. Barros, S. Magg, C. Weber, and S. Wermter, \u201cA multichannel convolutional neural network for hand posture recognition,\u201d in Proceedings\nof the 24th international conference on Artificial neural networks - To\napear, ser. ICANN\u201914, 2014.\n[10] D. C. Ciresan, U. Meier, and J. Schmidhuber, \u201cMulti-column deep\nneural networks for image classification,\u201d CoRR, vol. abs/1202.2745,\n2012.\n[11] P. Simard, D. Steinkraus, and J. C. Platt, \u201cBest practices for convolutional neural networks applied to visual document analysis,\u201d in\nInternational Conference on Document Analysis and Recognition, Aug\n2003, pp. 958\u2013963.\n[12] M. Schwarz, J. Pastrana, M. Schreiber, M. Missura, and S. Behnke,\n\u201cHumanoid teensize open platform nimbro-op.\u201d\nView publication stats"
  },
  {
    "id": "ros2cpp/ros2loggingfmt.txt",
    "content": "Skip to content\n\nToggle navigation\n\n[ ](https://github.com/)\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2Ffacontidavide%2Fros2_logging_fmt)\n\n  * Product \n\n    * [ Actions  Automate any workflow  ](/features/actions)\n    * [ Packages  Host and manage packages  ](/features/packages)\n    * [ Security  Find and fix vulnerabilities  ](/features/security)\n    * [ Codespaces  Instant dev environments  ](/features/codespaces)\n    * [ Copilot  Write better code with AI  ](/features/copilot)\n    * [ Code review  Manage code changes  ](/features/code-review)\n    * [ Issues  Plan and track work  ](/features/issues)\n    * [ Discussions  Collaborate outside of code  ](/features/discussions)\n\nExplore\n\n    * [ All features ](/features)\n    * [ Documentation  ](https://docs.github.com)\n    * [ GitHub Skills  ](https://skills.github.com/)\n    * [ Blog  ](https://github.blog)\n\n  * Solutions \n\nFor\n\n    * [ Enterprise ](/enterprise)\n    * [ Teams ](/team)\n    * [ Startups ](/enterprise/startups)\n    * [ Education  ](https://education.github.com)\n\nBy Solution\n\n    * [ CI/CD & Automation ](/solutions/ci-cd/)\n    * [ DevOps ](/solutions/devops/)\n    * [ DevSecOps  ](https://resources.github.com/devops/fundamentals/devsecops/)\n\nResources\n\n    * [ Learning Pathways  ](https://resources.github.com/learn/pathways/)\n    * [ White papers, Ebooks, Webinars  ](https://resources.github.com/)\n    * [ Customer Stories ](/customer-stories)\n    * [ Partners  ](https://partner.github.com/)\n\n  * Open Source \n\n    * [ GitHub Sponsors  Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project  GitHub community articles  ](/readme)\n\nRepositories\n\n    * [ Topics ](/topics)\n    * [ Trending ](/trending)\n    * [ Collections ](/collections)\n\n  * [ Pricing ](/pricing)\n\nSearch or jump to...\n\n#  Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[ Search syntax tips ](https://docs.github.com/search-github/github-code-\nsearch/understanding-github-code-search-syntax)\n\n#  Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n##  Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [ documentation\n](https://docs.github.com/search-github/github-code-search/understanding-\ngithub-code-search-syntax) .\n\nCancel  Create saved search\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2Ffacontidavide%2Fros2_logging_fmt)\n\n[ Sign up\n](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-\nname%3E%2F%3Crepo-name%3E&source=header-\nrepo&source_repo=facontidavide%2Fros2_logging_fmt)\n\nYou signed in with another tab or window. [ Reload ]() to refresh your\nsession.  You signed out in another tab or window. [ Reload ]() to refresh\nyour session.  You switched accounts on another tab or window. [ Reload ]() to\nrefresh your session.  Dismiss alert\n\n{{ message }}\n\n[ facontidavide ](/facontidavide) /  **[ ros2_logging_fmt\n](/facontidavide/ros2_logging_fmt) ** Public\n\n  * [ Notifications ](/login?return_to=%2Ffacontidavide%2Fros2_logging_fmt)\n  * [ Fork  6  ](/login?return_to=%2Ffacontidavide%2Fros2_logging_fmt)\n  * [ Star  32  ](/login?return_to=%2Ffacontidavide%2Fros2_logging_fmt)\n\n  * \n\n[ 32  stars ](/facontidavide/ros2_logging_fmt/stargazers) [ 6  forks\n](/facontidavide/ros2_logging_fmt/forks) [ Branches\n](/facontidavide/ros2_logging_fmt/branches) [ Tags\n](/facontidavide/ros2_logging_fmt/tags) [ Activity\n](/facontidavide/ros2_logging_fmt/activity)\n\n[ Star  ](/login?return_to=%2Ffacontidavide%2Fros2_logging_fmt)\n\n[ Notifications ](/login?return_to=%2Ffacontidavide%2Fros2_logging_fmt)\n\n  * [ Code  ](/facontidavide/ros2_logging_fmt)\n  * [ Issues  1  ](/facontidavide/ros2_logging_fmt/issues)\n  * [ Pull requests  0  ](/facontidavide/ros2_logging_fmt/pulls)\n  * [ Actions  ](/facontidavide/ros2_logging_fmt/actions)\n  * [ Projects  0  ](/facontidavide/ros2_logging_fmt/projects)\n  * [ Security  ](/facontidavide/ros2_logging_fmt/security)\n  * [ Insights  ](/facontidavide/ros2_logging_fmt/pulse)\n\nAdditional navigation options\n\n  * [ Code  ](/facontidavide/ros2_logging_fmt)\n  * [ Issues  ](/facontidavide/ros2_logging_fmt/issues)\n  * [ Pull requests  ](/facontidavide/ros2_logging_fmt/pulls)\n  * [ Actions  ](/facontidavide/ros2_logging_fmt/actions)\n  * [ Projects  ](/facontidavide/ros2_logging_fmt/projects)\n  * [ Security  ](/facontidavide/ros2_logging_fmt/security)\n  * [ Insights  ](/facontidavide/ros2_logging_fmt/pulse)\n\n#  facontidavide/ros2_logging_fmt\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\nmaster\n\n[ Branches  ](/facontidavide/ros2_logging_fmt/branches) [ Tags\n](/facontidavide/ros2_logging_fmt/tags)\n\n[ ](/facontidavide/ros2_logging_fmt/branches) [\n](/facontidavide/ros2_logging_fmt/tags)\n\nGo to file\n\nCode\n\n##  Folders and files\n\nName  |  Name  |\n\nLast commit message\n\n|\n\nLast commit date  \n  \n---|---|---|---  \n  \n##  Latest commit\n\n##  History\n\n[ 17 Commits  ](/facontidavide/ros2_logging_fmt/commits/master/)\n\n[ ](/facontidavide/ros2_logging_fmt/commits/master/)  \n  \n###\n\n[ include/  ros2_logging_fmt\n](/facontidavide/ros2_logging_fmt/tree/master/include/ros2_logging_fmt \"This\npath skips through empty directories\")\n\n|\n\n###\n\n[ include/  ros2_logging_fmt\n](/facontidavide/ros2_logging_fmt/tree/master/include/ros2_logging_fmt \"This\npath skips through empty directories\")\n\n|\n\n|  \n  \n###\n\n[ src ](/facontidavide/ros2_logging_fmt/tree/master/src \"src\")\n\n|\n\n###\n\n[ src ](/facontidavide/ros2_logging_fmt/tree/master/src \"src\")\n\n|\n\n|  \n  \n###\n\n[ CMakeLists.txt ](/facontidavide/ros2_logging_fmt/blob/master/CMakeLists.txt\n\"CMakeLists.txt\")\n\n|\n\n###\n\n[ CMakeLists.txt ](/facontidavide/ros2_logging_fmt/blob/master/CMakeLists.txt\n\"CMakeLists.txt\")\n\n|\n\n|  \n  \n###\n\n[ README.md ](/facontidavide/ros2_logging_fmt/blob/master/README.md\n\"README.md\")\n\n|\n\n###\n\n[ README.md ](/facontidavide/ros2_logging_fmt/blob/master/README.md\n\"README.md\")\n\n|\n\n|  \n  \n###\n\n[ package.xml ](/facontidavide/ros2_logging_fmt/blob/master/package.xml\n\"package.xml\")\n\n|\n\n###\n\n[ package.xml ](/facontidavide/ros2_logging_fmt/blob/master/package.xml\n\"package.xml\")\n\n|\n\n|  \n  \nView all files  \n  \n##  Repository files navigation\n\n  * README \n\n#  ros2_logging_fmt\n\nIt is the same as [ rclcpp logging\n](https://docs.ros.org/en/foxy/Tutorials/Logging-and-logger-\nconfiguration.html) but much nicer, using [ fmt\n](https://github.com/fmtlib/fmt) instead of **printf-like** formatting.\n\nAdvantages:\n\n  * More type safe that \"printf-style\" API. \n  * [ Faster execution ](https://github.com/fmtlib/fmt#speed-tests) . \n  * Powerful syntax (see [ examples ](https://fmt.dev/latest/syntax.html#format-examples) ). \n  * Thread safe. \n  * It will not allocate any memory (unless for particularly long messages, and only once). \n\n**NOTE: stil under construction. PR and suggestions are welcome.**\n\n##  Example\n\n    \n    \n    #include \"ros2_logging_fmt/ros2_logging_fmt.hpp\"\n    \n    int main(int argc, char * argv[])\n    {\n      rclcpp::init(argc, argv);\n      rclcpp::Node node(\"test_node\");\n    \n      std::string world = \"world\";\n    \n      RCLCPP_INFO(node.get_logger(), \"Hello %s number %d\", world.c_str(), 42);\n      RCLCPP_ERROR(node.get_logger(), \"We have %d errors\", 99);\n      RCLCPP_WARN(node.get_logger(), \"Warning: %f > %f\", 30.1, 30.0);\n      RCLCPP_DEBUG(node.get_logger(), \"DEBUG MESSAGE\");\n    \n      ros2_logging_fmt::Logger logger(node.get_logger());\n    \n      logger.info(\"Hello {} number {}\", world, 42);\n      logger.error(\"We have {} errors\", 99);\n      logger.warn(\"Warning: {} > {}\", 30.1, 30.0);\n      logger.debug(\"DEBUG MESSAGE\");\n    \n      rclcpp::shutdown();\n      return 0;\n    }\n\n##  About\n\nNo description, website, or topics provided.\n\n###  Resources\n\nReadme\n\n[ Activity  ](/facontidavide/ros2_logging_fmt/activity)\n\n###  Stars\n\n[ **32** stars ](/facontidavide/ros2_logging_fmt/stargazers)\n\n###  Watchers\n\n[ **8** watching ](/facontidavide/ros2_logging_fmt/watchers)\n\n###  Forks\n\n[ **6** forks ](/facontidavide/ros2_logging_fmt/forks)\n\n[ Report repository ](/contact/report-\ncontent?content_url=https%3A%2F%2Fgithub.com%2Ffacontidavide%2Fros2_logging_fmt&report=facontidavide+%28user%29)\n\n##  [ Releases ](/facontidavide/ros2_logging_fmt/releases)\n\nNo releases published\n\n##  [ Packages  0  ](/users/facontidavide/packages?repo_name=ros2_logging_fmt)\n\nNo packages published  \n\n##  [ Contributors  2  ](/facontidavide/ros2_logging_fmt/graphs/contributors)\n\n  *   * \n\n##  Languages\n\n  * [ C++  85.6%  ](/facontidavide/ros2_logging_fmt/search?l=c%2B%2B)\n  * [ CMake  14.4%  ](/facontidavide/ros2_logging_fmt/search?l=cmake)\n\n##  Footer\n\n[ ](https://github.com \"GitHub\") \u00a9 2024 GitHub, Inc.\n\n###  Footer navigation\n\n  * [ Terms ](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [ Privacy ](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [ Security ](/security)\n  * [ Status ](https://www.githubstatus.com/)\n  * [ Docs ](https://docs.github.com/)\n  * [ Contact ](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.\n\n"
  },
  {
    "id": "planner_selector/plannerselectornodec.txt",
    "content": "// Copyright (c) 2018 Intel Corporation\n// Copyright (c) 2020 Pablo I\u00f1igo Blasco\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n#include <string>\n#include <memory>\n#include \"std_msgs/msg/string.hpp\"\n#include \"nav2_behavior_tree/plugins/action/planner_selector_node.hpp\"\n#include \"rclcpp/rclcpp.hpp\"\nnamespace nav2_behavior_tree\n{\nusing std::placeholders::_1;\nPlannerSelector::PlannerSelector(\n  const std::string & name,\n  const BT::NodeConfiguration & conf)\n: BT::SyncActionNode(name, conf)\n{\n  node_ = config().blackboard->get<rclcpp::Node::SharedPtr>(\"node\");\n  callback_group_ = node_->create_callback_group(\n    rclcpp::CallbackGroupType::MutuallyExclusive,\n    false);\n  callback_group_executor_.add_callback_group(callback_group_, node_->get_node_base_interface());\n  getInput(\"topic_name\", topic_name_);\n  rclcpp::QoS qos(rclcpp::KeepLast(1));\n  qos.transient_local().reliable();\n  rclcpp::SubscriptionOptions sub_option;\n  sub_option.callback_group = callback_group_;\n  planner_selector_sub_ = node_->create_subscription<std_msgs::msg::String>(\n    topic_name_,\n    qos,\n\n\n\n    std::bind(&PlannerSelector::callbackPlannerSelect, this, _1),\n    sub_option);\n}\nBT::NodeStatus PlannerSelector::tick()\n{\n  callback_group_executor_.spin_some();\n  // This behavior always use the last selected planner received from the topic input.\n  // When no input is specified it uses the default planner.\n  // If the default planner is not specified then we work in \"required planner mode\":\n  // In this mode, the behavior returns failure if the planner selection is not received from\n  // the topic input.\n  if (last_selected_planner_.empty()) {\n    std::string default_planner;\n    getInput(\"default_planner\", default_planner);\n    if (default_planner.empty()) {\n      return BT::NodeStatus::FAILURE;\n    } else {\n      last_selected_planner_ = default_planner;\n    }\n  }\n  setOutput(\"selected_planner\", last_selected_planner_);\n  return BT::NodeStatus::SUCCESS;\n}\nvoid\nPlannerSelector::callbackPlannerSelect(const std_msgs::msg::String::SharedPtr msg)\n{\n  last_selected_planner_ = msg->data;\n}\n}  // namespace nav2_behavior_tree\n#include \"behaviortree_cpp_v3/bt_factory.h\"\nBT_REGISTER_NODES(factory)\n{\n  factory.registerNodeType<nav2_behavior_tree::PlannerSelector>(\"PlannerSelector\");\n}\n\n\n"
  },
  {
    "id": "pthread_not_declared/ldlidarros2.txt",
    "content": "Skip to content\n\nToggle navigation\n\n[ ](https://github.com/)\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2FldrobotSensorTeam%2Fldlidar_ros2)\n\n  * Product \n\n    * [ Actions  Automate any workflow  ](/features/actions)\n    * [ Packages  Host and manage packages  ](/features/packages)\n    * [ Security  Find and fix vulnerabilities  ](/features/security)\n    * [ Codespaces  Instant dev environments  ](/features/codespaces)\n    * [ Copilot  Write better code with AI  ](/features/copilot)\n    * [ Code review  Manage code changes  ](/features/code-review)\n    * [ Issues  Plan and track work  ](/features/issues)\n    * [ Discussions  Collaborate outside of code  ](/features/discussions)\n\nExplore\n\n    * [ All features ](/features)\n    * [ Documentation  ](https://docs.github.com)\n    * [ GitHub Skills  ](https://skills.github.com/)\n    * [ Blog  ](https://github.blog)\n\n  * Solutions \n\nFor\n\n    * [ Enterprise ](/enterprise)\n    * [ Teams ](/team)\n    * [ Startups ](/enterprise/startups)\n    * [ Education  ](https://education.github.com)\n\nBy Solution\n\n    * [ CI/CD & Automation ](/solutions/ci-cd/)\n    * [ DevOps ](/solutions/devops/)\n    * [ DevSecOps  ](https://resources.github.com/devops/fundamentals/devsecops/)\n\nResources\n\n    * [ Learning Pathways  ](https://resources.github.com/learn/pathways/)\n    * [ White papers, Ebooks, Webinars  ](https://resources.github.com/)\n    * [ Customer Stories ](/customer-stories)\n    * [ Partners  ](https://partner.github.com/)\n\n  * Open Source \n\n    * [ GitHub Sponsors  Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project  GitHub community articles  ](/readme)\n\nRepositories\n\n    * [ Topics ](/topics)\n    * [ Trending ](/trending)\n    * [ Collections ](/collections)\n\n  * [ Pricing ](/pricing)\n\nSearch or jump to...\n\n#  Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[ Search syntax tips ](https://docs.github.com/search-github/github-code-\nsearch/understanding-github-code-search-syntax)\n\n#  Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n##  Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [ documentation\n](https://docs.github.com/search-github/github-code-search/understanding-\ngithub-code-search-syntax) .\n\nCancel  Create saved search\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2FldrobotSensorTeam%2Fldlidar_ros2)\n\n[ Sign up\n](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-\nname%3E%2F%3Crepo-name%3E&source=header-\nrepo&source_repo=ldrobotSensorTeam%2Fldlidar_ros2)\n\nYou signed in with another tab or window. [ Reload ]() to refresh your\nsession.  You signed out in another tab or window. [ Reload ]() to refresh\nyour session.  You switched accounts on another tab or window. [ Reload ]() to\nrefresh your session.  Dismiss alert\n\n{{ message }}\n\n[ ldrobotSensorTeam ](/ldrobotSensorTeam) /  **[ ldlidar_ros2\n](/ldrobotSensorTeam/ldlidar_ros2) ** Public\n\n  * [ Notifications ](/login?return_to=%2FldrobotSensorTeam%2Fldlidar_ros2)\n  * [ Fork  4  ](/login?return_to=%2FldrobotSensorTeam%2Fldlidar_ros2)\n  * [ Star  6  ](/login?return_to=%2FldrobotSensorTeam%2Fldlidar_ros2)\n\n  * \n\nLDROBOT LiDAR ROS2 Package(NEW)\n\n###  License\n\n[ MIT license ](/ldrobotSensorTeam/ldlidar_ros2/blob/master/LICENSE)\n\n[ 6  stars ](/ldrobotSensorTeam/ldlidar_ros2/stargazers) [ 4  forks\n](/ldrobotSensorTeam/ldlidar_ros2/forks) [ Branches\n](/ldrobotSensorTeam/ldlidar_ros2/branches) [ Tags\n](/ldrobotSensorTeam/ldlidar_ros2/tags) [ Activity\n](/ldrobotSensorTeam/ldlidar_ros2/activity)\n\n[ Star  ](/login?return_to=%2FldrobotSensorTeam%2Fldlidar_ros2)\n\n[ Notifications ](/login?return_to=%2FldrobotSensorTeam%2Fldlidar_ros2)\n\n  * [ Code  ](/ldrobotSensorTeam/ldlidar_ros2)\n  * [ Issues  0  ](/ldrobotSensorTeam/ldlidar_ros2/issues)\n  * [ Pull requests  0  ](/ldrobotSensorTeam/ldlidar_ros2/pulls)\n  * [ Actions  ](/ldrobotSensorTeam/ldlidar_ros2/actions)\n  * [ Projects  0  ](/ldrobotSensorTeam/ldlidar_ros2/projects)\n  * [ Security  ](/ldrobotSensorTeam/ldlidar_ros2/security)\n  * [ Insights  ](/ldrobotSensorTeam/ldlidar_ros2/pulse)\n\nAdditional navigation options\n\n  * [ Code  ](/ldrobotSensorTeam/ldlidar_ros2)\n  * [ Issues  ](/ldrobotSensorTeam/ldlidar_ros2/issues)\n  * [ Pull requests  ](/ldrobotSensorTeam/ldlidar_ros2/pulls)\n  * [ Actions  ](/ldrobotSensorTeam/ldlidar_ros2/actions)\n  * [ Projects  ](/ldrobotSensorTeam/ldlidar_ros2/projects)\n  * [ Security  ](/ldrobotSensorTeam/ldlidar_ros2/security)\n  * [ Insights  ](/ldrobotSensorTeam/ldlidar_ros2/pulse)\n\n#  ldrobotSensorTeam/ldlidar_ros2\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\nmaster\n\n[ Branches  ](/ldrobotSensorTeam/ldlidar_ros2/branches) [ Tags\n](/ldrobotSensorTeam/ldlidar_ros2/tags)\n\n[ ](/ldrobotSensorTeam/ldlidar_ros2/branches) [\n](/ldrobotSensorTeam/ldlidar_ros2/tags)\n\nGo to file\n\nCode\n\n##  Folders and files\n\nName  |  Name  |\n\nLast commit message\n\n|\n\nLast commit date  \n  \n---|---|---|---  \n  \n##  Latest commit\n\n##  History\n\n[ 17 Commits  ](/ldrobotSensorTeam/ldlidar_ros2/commits/master/)\n\n[ ](/ldrobotSensorTeam/ldlidar_ros2/commits/master/)  \n  \n###\n\n[ include ](/ldrobotSensorTeam/ldlidar_ros2/tree/master/include \"include\")\n\n|\n\n###\n\n[ include ](/ldrobotSensorTeam/ldlidar_ros2/tree/master/include \"include\")\n\n|\n\n|  \n  \n###\n\n[ launch ](/ldrobotSensorTeam/ldlidar_ros2/tree/master/launch \"launch\")\n\n|\n\n###\n\n[ launch ](/ldrobotSensorTeam/ldlidar_ros2/tree/master/launch \"launch\")\n\n|\n\n|  \n  \n###\n\n[ rviz2 ](/ldrobotSensorTeam/ldlidar_ros2/tree/master/rviz2 \"rviz2\")\n\n|\n\n###\n\n[ rviz2 ](/ldrobotSensorTeam/ldlidar_ros2/tree/master/rviz2 \"rviz2\")\n\n|\n\n|  \n  \n###\n\n[ scripts ](/ldrobotSensorTeam/ldlidar_ros2/tree/master/scripts \"scripts\")\n\n|\n\n###\n\n[ scripts ](/ldrobotSensorTeam/ldlidar_ros2/tree/master/scripts \"scripts\")\n\n|\n\n|  \n  \n###\n\n[ sdk @ 6148cd3\n](/ldrobotSensorTeam/ldlidar_sdk/tree/6148cd3c33ae39adbd7e12faf82567fa8f8e7b0d\n\"sdk\")\n\n|\n\n###\n\n[ sdk @ 6148cd3\n](/ldrobotSensorTeam/ldlidar_sdk/tree/6148cd3c33ae39adbd7e12faf82567fa8f8e7b0d\n\"sdk\")\n\n|\n\n|  \n  \n###\n\n[ src ](/ldrobotSensorTeam/ldlidar_ros2/tree/master/src \"src\")\n\n|\n\n###\n\n[ src ](/ldrobotSensorTeam/ldlidar_ros2/tree/master/src \"src\")\n\n|\n\n|  \n  \n###\n\n[ .gitignore ](/ldrobotSensorTeam/ldlidar_ros2/blob/master/.gitignore\n\".gitignore\")\n\n|\n\n###\n\n[ .gitignore ](/ldrobotSensorTeam/ldlidar_ros2/blob/master/.gitignore\n\".gitignore\")\n\n|\n\n|  \n  \n###\n\n[ .gitmodules ](/ldrobotSensorTeam/ldlidar_ros2/blob/master/.gitmodules\n\".gitmodules\")\n\n|\n\n###\n\n[ .gitmodules ](/ldrobotSensorTeam/ldlidar_ros2/blob/master/.gitmodules\n\".gitmodules\")\n\n|\n\n|  \n  \n###\n\n[ CMakeLists.txt ](/ldrobotSensorTeam/ldlidar_ros2/blob/master/CMakeLists.txt\n\"CMakeLists.txt\")\n\n|\n\n###\n\n[ CMakeLists.txt ](/ldrobotSensorTeam/ldlidar_ros2/blob/master/CMakeLists.txt\n\"CMakeLists.txt\")\n\n|\n\n|  \n  \n###\n\n[ LICENSE ](/ldrobotSensorTeam/ldlidar_ros2/blob/master/LICENSE \"LICENSE\")\n\n|\n\n###\n\n[ LICENSE ](/ldrobotSensorTeam/ldlidar_ros2/blob/master/LICENSE \"LICENSE\")\n\n|\n\n|  \n  \n###\n\n[ README.md ](/ldrobotSensorTeam/ldlidar_ros2/blob/master/README.md\n\"README.md\")\n\n|\n\n###\n\n[ README.md ](/ldrobotSensorTeam/ldlidar_ros2/blob/master/README.md\n\"README.md\")\n\n|\n\n|  \n  \n###\n\n[ README_CN.md ](/ldrobotSensorTeam/ldlidar_ros2/blob/master/README_CN.md\n\"README_CN.md\")\n\n|\n\n###\n\n[ README_CN.md ](/ldrobotSensorTeam/ldlidar_ros2/blob/master/README_CN.md\n\"README_CN.md\")\n\n|\n\n|  \n  \n###\n\n[ package.xml ](/ldrobotSensorTeam/ldlidar_ros2/blob/master/package.xml\n\"package.xml\")\n\n|\n\n###\n\n[ package.xml ](/ldrobotSensorTeam/ldlidar_ros2/blob/master/package.xml\n\"package.xml\")\n\n|\n\n|  \n  \nView all files  \n  \n##  Repository files navigation\n\n  * README \n  * MIT license \n\n#  Instructions\n\n##  step 0: get LiDAR ROS2 Package\n\n    \n    \n    cd ~\n    \n    mkdir -p ldlidar_ros2_ws/src\n    \n    cd ldlidar_ros2_ws/src\n    \n    git clone  https://github.com/ldrobotSensorTeam/ldlidar_ros2.git\n    \n    git submodule update --init --recursive\n\n##  step 1: system setup\n\n  * Connect the LiDAR to your system motherboard via an onboard serial port or usB-to-serial module (for example, CP2102 module). \n\n  * Set the -x permission for the serial port device mounted by the radar in the system (for example, /dev/ttyUSB0) \n\n    * In actual use, the LiDAR can be set according to the actual mounted status of your system, you can use 'ls -l /dev' command to view. \n\n    \n    \n    cd ~/ldlidar_ros2_ws\n    \n    sudo chmod 777 /dev/ttyUSB0\n\n  * Modify the ` port_name ` value in the Lanuch file corresponding to the radar product model under ` launch/ ` , using ` ld14.launch.py ` as an example, as shown below. \n\n    \n    \n    #!/usr/bin/env python3\n    from launch import LaunchDescription\n    from launch_ros.actions import Node\n    \n    '''\n    Parameter Description:\n    ---\n    - Set laser scan directon: \n      1. Set counterclockwise, example: {'laser_scan_dir': True}\n      2. Set clockwise,        example: {'laser_scan_dir': False}\n    - Angle crop setting, Mask data within the set angle range:\n      1. Enable angle crop fuction:\n        1.1. enable angle crop,  example: {'enable_angle_crop_func': True}\n        1.2. disable angle crop, example: {'enable_angle_crop_func': False}\n      2. Angle cropping interval setting:\n      - The distance and intensity data within the set angle range will be set to 0.\n      - angle >= 'angle_crop_min' and angle <= 'angle_crop_max' which is [angle_crop_min, angle_crop_max], unit is degress.\n        example:\n          {'angle_crop_min': 135.0}\n          {'angle_crop_max': 225.0}\n          which is [135.0, 225.0], angle unit is degress.\n    '''\n    \n    def generate_launch_description():\n      # LDROBOT LiDAR publisher node\n      ldlidar_node = Node(\n          package='ldlidar_ros2',\n          executable='ldlidar_ros2_node',\n          name='ldlidar_publisher_ld14',\n          output='screen',\n          parameters=[\n            {'product_name': 'LDLiDAR_LD14'},\n            {'laser_scan_topic_name': 'scan'},\n            {'point_cloud_2d_topic_name': 'pointcloud2d'},\n            {'frame_id': 'base_laser'},\n            {'port_name': '/dev/ttyUSB0'},\n            {'serial_baudrate' : 115200},\n            {'laser_scan_dir': True},\n            {'enable_angle_crop_func': False},\n            {'angle_crop_min': 135.0},\n            {'angle_crop_max': 225.0}\n          ]\n      )\n    \n      # base_link to base_laser tf node\n      base_link_to_laser_tf_node = Node(\n        package='tf2_ros',\n        executable='static_transform_publisher',\n        name='base_link_to_base_laser_ld14',\n        arguments=['0','0','0.18','0','0','0','base_link','base_laser']\n      )\n    \n    \n      # Define LaunchDescription variable\n      ld = LaunchDescription()\n    \n      ld.add_action(ldlidar_node)\n      ld.add_action(base_link_to_laser_tf_node)\n    \n      return ld\n\n##  step 2: build\n\nRun the following command.\n\n    \n    \n    cd ~/ldlidar_ros2_ws\n    \n    colcon build\n\n##  step 3: run\n\n###  step3.1: package environment variable settings\n\n  * After the compilation is completed, you need to add the relevant files generated by the compilation to the environment variables, so that the ROS environment can recognize them. The execution command is as follows. This command is to temporarily add environment variables to the terminal, which means that if you reopen a new terminal, you also need to re-execute it. The following command. \n    \n        cd ~/ldlidar_ros2_ws\n    \n    source install/local_setup.bash\n\n  * In order to never need to execute the above command to add environment variables after reopening the terminal, you can do the following. \n    \n        echo \"source ~/ldlidar_ros2_ws/install/local_setup.bash\" >> ~/.bashrc\n    \n    source ~/.bashrc\n\n###  step3.2: start LiDAR node\n\n  * The product is LDROBOT LiDAR LD14 \n\n    * start ld14 lidar node: \n    \n        ros2 launch ldlidar_ros2 ld14.launch.py\n\n    * start ld14 lidar node and show on the Rviz2: \n    \n        ros2 launch ldlidar_ros2 viewer_ld14.launch.py\n\n  * The product is LDROBOT LiDAR LD14P \n\n    * start ld14p lidar node: \n    \n        ros2 launch ldlidar_ros2 ld14p.launch.py\n\n    * start ld14p lidar node and show on the Rviz2: \n    \n        ros2 launch ldlidar_ros2 viewer_ld14p.launch.py\n\n  * The product is LDROBOT LiDAR LD06 \n\n    * start ld06 lidar node: \n    \n        ros2 launch ldlidar_ros2 ld06.launch.py\n\n    * start ld06 lidar node and show on the Rviz2: \n    \n        ros2 launch ldlidar_ros2 viewer_ld06.launch.py\n\n  * The product is LDROBOT LiDAR LD19 \n\n    * start ld19 lidar node: \n    \n        ros2 launch ldlidar_ros2 ld19.launch.py\n\n    * start ld19 lidar node and show on the Rviz2: \n    \n        ros2 launch ldlidar_ros2 viewer_ld19.launch.py\n\n##  step 4: Data visualization\n\n> The code supports ubuntu 20.04 ros2 foxy version and above, using rviz2\n> visualization.\n\n  * new a terminal (Ctrl + Alt + T) and use Rviz2 tool(run command: ` rviz2 ` ) ,open the ` ldlidar.rviz ` file below the rviz2 folder of the readme file directory \n\n    \n    \n    rviz2\n\n##  About\n\nLDROBOT LiDAR ROS2 Package(NEW)\n\n###  Topics\n\n[ ros2 ](/topics/ros2 \"Topic: ros2\") [ ld06 ](/topics/ld06 \"Topic: ld06\") [\nldrobot ](/topics/ldrobot \"Topic: ldrobot\") [ ld19 ](/topics/ld19 \"Topic:\nld19\") [ ld14 ](/topics/ld14 \"Topic: ld14\") [ ld14p ](/topics/ld14p \"Topic:\nld14p\")\n\n###  Resources\n\nReadme\n\n###  License\n\nMIT license\n\n[ Activity  ](/ldrobotSensorTeam/ldlidar_ros2/activity)\n\n[ Custom properties  ](/ldrobotSensorTeam/ldlidar_ros2/custom-properties)\n\n###  Stars\n\n[ **6** stars ](/ldrobotSensorTeam/ldlidar_ros2/stargazers)\n\n###  Watchers\n\n[ **1** watching ](/ldrobotSensorTeam/ldlidar_ros2/watchers)\n\n###  Forks\n\n[ **4** forks ](/ldrobotSensorTeam/ldlidar_ros2/forks)\n\n[ Report repository ](/contact/report-\ncontent?content_url=https%3A%2F%2Fgithub.com%2FldrobotSensorTeam%2Fldlidar_ros2&report=ldrobotSensorTeam+%28user%29)\n\n##  [ Releases ](/ldrobotSensorTeam/ldlidar_ros2/releases)\n\nNo releases published\n\n##  [ Packages  0  ](/orgs/ldrobotSensorTeam/packages?repo_name=ldlidar_ros2)\n\nNo packages published  \n\n##  [ Contributors  2  ](/ldrobotSensorTeam/ldlidar_ros2/graphs/contributors)\n\n  * [ ![@ldrobotsensor](https://avatars.githubusercontent.com/u/66579525?s=64&v=4) ](https://github.com/ldrobotsensor) [ **ldrobotsensor** David  ](https://github.com/ldrobotsensor)\n  * [ ![@mingdonghu](https://avatars.githubusercontent.com/u/52943852?s=64&v=4) ](https://github.com/mingdonghu) [ **mingdonghu** David Hu  ](https://github.com/mingdonghu)\n\n##  Languages\n\n  * [ C++  53.0%  ](/ldrobotSensorTeam/ldlidar_ros2/search?l=c%2B%2B)\n  * [ Python  39.7%  ](/ldrobotSensorTeam/ldlidar_ros2/search?l=python)\n  * [ CMake  5.0%  ](/ldrobotSensorTeam/ldlidar_ros2/search?l=cmake)\n  * [ Shell  2.3%  ](/ldrobotSensorTeam/ldlidar_ros2/search?l=shell)\n\n##  Footer\n\n[ ](https://github.com \"GitHub\") \u00a9 2024 GitHub, Inc.\n\n###  Footer navigation\n\n  * [ Terms ](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [ Privacy ](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [ Security ](/security)\n  * [ Status ](https://www.githubstatus.com/)\n  * [ Docs ](https://docs.github.com/)\n  * [ Contact ](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.\n\n"
  },
  {
    "id": "number_commands/1182.txt",
    "content": "Skip to content\n\nToggle navigation\n\n[ ](https://github.com/)\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fros-\nplanning%2Fmoveit2%2Fissues%2F1182)\n\n  * Product \n\n    * [ Actions  Automate any workflow  ](/features/actions)\n    * [ Packages  Host and manage packages  ](/features/packages)\n    * [ Security  Find and fix vulnerabilities  ](/features/security)\n    * [ Codespaces  Instant dev environments  ](/features/codespaces)\n    * [ Copilot  Write better code with AI  ](/features/copilot)\n    * [ Code review  Manage code changes  ](/features/code-review)\n    * [ Issues  Plan and track work  ](/features/issues)\n    * [ Discussions  Collaborate outside of code  ](/features/discussions)\n\nExplore\n\n    * [ All features ](/features)\n    * [ Documentation  ](https://docs.github.com)\n    * [ GitHub Skills  ](https://skills.github.com/)\n    * [ Blog  ](https://github.blog)\n\n  * Solutions \n\nFor\n\n    * [ Enterprise ](/enterprise)\n    * [ Teams ](/team)\n    * [ Startups ](/enterprise/startups)\n    * [ Education  ](https://education.github.com)\n\nBy Solution\n\n    * [ CI/CD & Automation ](/solutions/ci-cd/)\n    * [ DevOps ](/solutions/devops/)\n    * [ DevSecOps  ](https://resources.github.com/devops/fundamentals/devsecops/)\n\nResources\n\n    * [ Learning Pathways  ](https://resources.github.com/learn/pathways/)\n    * [ White papers, Ebooks, Webinars  ](https://resources.github.com/)\n    * [ Customer Stories ](/customer-stories)\n    * [ Partners  ](https://partner.github.com/)\n\n  * Open Source \n\n    * [ GitHub Sponsors  Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project  GitHub community articles  ](/readme)\n\nRepositories\n\n    * [ Topics ](/topics)\n    * [ Trending ](/trending)\n    * [ Collections ](/collections)\n\n  * [ Pricing ](/pricing)\n\nSearch or jump to...\n\n#  Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[ Search syntax tips ](https://docs.github.com/search-github/github-code-\nsearch/understanding-github-code-search-syntax)\n\n#  Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n##  Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [ documentation\n](https://docs.github.com/search-github/github-code-search/understanding-\ngithub-code-search-syntax) .\n\nCancel  Create saved search\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fros-\nplanning%2Fmoveit2%2Fissues%2F1182)\n\n[ Sign up\n](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-\nname%3E%2F%3Crepo-\nname%3E%2Fvoltron%2Fissues_fragments%2Fissue_layout&source=header-\nrepo&source_repo=ros-planning%2Fmoveit2)\n\nYou signed in with another tab or window. [ Reload ]() to refresh your\nsession.  You signed out in another tab or window. [ Reload ]() to refresh\nyour session.  You switched accounts on another tab or window. [ Reload ]() to\nrefresh your session.  Dismiss alert\n\n{{ message }}\n\n[ ros-planning ](/ros-planning) /  **[ moveit2 ](/ros-planning/moveit2) **\nPublic\n\n  * [ Notifications ](/login?return_to=%2Fros-planning%2Fmoveit2)\n  * [ Fork  471  ](/login?return_to=%2Fros-planning%2Fmoveit2)\n  * [ Star  906  ](/login?return_to=%2Fros-planning%2Fmoveit2)\n\n  * [ Code  ](/ros-planning/moveit2)\n  * [ Issues  245  ](/ros-planning/moveit2/issues)\n  * [ Pull requests  42  ](/ros-planning/moveit2/pulls)\n  * [ Discussions  ](/ros-planning/moveit2/discussions)\n  * [ Actions  ](/ros-planning/moveit2/actions)\n  * [ Projects  1  ](/ros-planning/moveit2/projects)\n  * [ Security  ](/ros-planning/moveit2/security)\n  * [ Insights  ](/ros-planning/moveit2/pulse)\n\nAdditional navigation options\n\n  * [ Code  ](/ros-planning/moveit2)\n  * [ Issues  ](/ros-planning/moveit2/issues)\n  * [ Pull requests  ](/ros-planning/moveit2/pulls)\n  * [ Discussions  ](/ros-planning/moveit2/discussions)\n  * [ Actions  ](/ros-planning/moveit2/actions)\n  * [ Projects  ](/ros-planning/moveit2/projects)\n  * [ Security  ](/ros-planning/moveit2/security)\n  * [ Insights  ](/ros-planning/moveit2/pulse)\n\nNew issue\n\n**Have a question about this project?** Sign up for a free GitHub account to\nopen an issue and contact its maintainers and the community.\n\nPick a username\n\n    \n\nEmail Address\n\n    \n\nPassword\n\n    \nSign up for GitHub\n\nBy clicking \u201cSign up for GitHub\u201d, you agree to our [ terms of service\n](https://docs.github.com/terms) and [ privacy statement\n](https://docs.github.com/privacy) . We\u2019ll occasionally send you account\nrelated emails.\n\nAlready on GitHub? [ Sign in ](/login?return_to=%2Fros-\nplanning%2Fmoveit2%2Fissues%2Fnew%2Fchoose) to your account\n\nJump to bottom\n\n#  How to specify a controller to use when executing a trajectory through the\nMoveGroup ROS interface?  #1182\n\nOpen\n\n[ schornakj ](/schornakj) opened this issue  Apr 14, 2022  \u00b7 7 comments\n\nOpen\n\n#  How to specify a controller to use when executing a trajectory through the\nMoveGroup ROS interface?  #1182\n\n[ schornakj ](/schornakj) opened this issue  Apr 14, 2022  \u00b7 7 comments\n\nLabels\n\n[ enhancement  ](/ros-planning/moveit2/labels/enhancement) New feature or\nrequest\n\n##  Comments\n\n[\n![@schornakj](https://avatars.githubusercontent.com/u/14431472?s=80&u=fcccfc4fa3bebac047c907adad078dc822f22ccc&v=4)\n](/schornakj)\n\nCopy link\n\nContributor\n\n###\n\n**[ schornakj ](/schornakj) ** commented  Apr 14, 2022\n\nWhen the ExecuteTrajectoryAction MoveGroup capability [ pushes a new\ntrajectory ](https://github.com/ros-\nplanning/moveit2/blob/14d2a932c74ab1dc6bed652738d17ee2bae23d4f/moveit_ros/move_group/src/default_capabilities/execute_trajectory_action_capability.cpp#L111)\nto the TrajectoryExecutionManager, it does not have a way to set what\ncontroller should be used to execute the trajectory. This results in the\nTrajectoryExecutionManager being left to [ figure out what controller should\nbe used ](https://github.com/ros-\nplanning/moveit2/blob/14d2a932c74ab1dc6bed652738d17ee2bae23d4f/moveit_ros/planning/trajectory_execution_manager/src/trajectory_execution_manager.cpp#L728-L810)\n. In situations where there are multiple possible controllers for the same set\nof joints (for example, a JointGroupPositionController used for Servo and a\nJointTrajectoryController for regular trajectory execution), the TEM simply\ndoesn't have enough contextual info to make the right decision, which results\nin undesirable results if the wrong controller is selected.\n\nI think the solution to this is to add a field for controller names to the [\nExecuteTrajectory.action message ](https://github.com/ros-\nplanning/moveit_msgs/blob/ros2/action/ExecuteTrajectory.action) to allow the\ncode on the action client side to set the right controllers when the motion is\nplanned. This would require an API change, though.\n\nDoes anyone have other ideas about this?  \n  \n---  \n  \nThe text was updated successfully, but these errors were encountered:\n\n  \n  \nAll reactions\n\n[\n![@schornakj](https://avatars.githubusercontent.com/u/14431472?s=40&u=fcccfc4fa3bebac047c907adad078dc822f22ccc&v=4)\n](/schornakj) [ schornakj ](/schornakj) added the [ enhancement ](/ros-\nplanning/moveit2/labels/enhancement) New feature or request  label  Apr 14,\n2022\n\n[\n![@AndyZe](https://avatars.githubusercontent.com/u/11284393?s=80&u=24eb488e02f9d9ce574f09c9025fa15d8f3814e6&v=4)\n](/AndyZe)\n\nCopy link\n\nContributor\n\n###\n\n**[ AndyZe ](/AndyZe) ** commented  Apr 14, 2022  \u2022\n\nedited\n\nIIRC you can specify a default controller name. For example:\n\n[ https://github.com/ros-\nplanning/moveit_resources/blob/394a3c6aba9da34d5317697fdb0db2c9acc8ebd8/panda_moveit_config/config/moveit_controllers.yaml#L10\n](https://github.com/ros-\nplanning/moveit_resources/blob/394a3c6aba9da34d5317697fdb0db2c9acc8ebd8/panda_moveit_config/config/moveit_controllers.yaml#L10)\n\nJust turn off ` moveit_manage_controllers ` so trajectories execute with that\ncontroller by default, instead of searching for an active controller.\n\nServo can have a different controller and that should not affect things.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@AndyZe](https://avatars.githubusercontent.com/u/11284393?s=80&u=24eb488e02f9d9ce574f09c9025fa15d8f3814e6&v=4)\n](/AndyZe)\n\nCopy link\n\nContributor\n\n###\n\n**[ AndyZe ](/AndyZe) ** commented  Apr 14, 2022\n\nI think the controller search logic should just be deleted. If you try what I\nwrote above and it still doesn't work, then I support your idea \ud83d\udc4d  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@schornakj](https://avatars.githubusercontent.com/u/14431472?s=40&u=fcccfc4fa3bebac047c907adad078dc822f22ccc&v=4)\n](/schornakj) [ schornakj ](/schornakj) mentioned this issue  Apr 14, 2022\n\n[ [ros2] How to specify a controller to use when executing a trajectory\nthrough the ExecuteTaskSolutionCapability ROS interface?  ros-\nplanning/moveit_task_constructor#354  ](/ros-\nplanning/moveit_task_constructor/issues/354)\n\nOpen\n\n[\n![@schornakj](https://avatars.githubusercontent.com/u/14431472?s=80&u=fcccfc4fa3bebac047c907adad078dc822f22ccc&v=4)\n](/schornakj)\n\nCopy link\n\nContributor  Author\n\n###\n\n**[ schornakj ](/schornakj) ** commented  Apr 14, 2022  \u2022\n\nedited\n\n> Just turn off moveit_manage_controllers so trajectories execute with that\n> controller by default, instead of searching for an active controller.\n\nSetting ` moveit_manage_controllers = False ` would require me to switch\nbetween the controllers elsewhere in my code, right? If the controllers aren't\nswitched automatically before handling the trajectory, I would have to make\nsure that the streaming controller is inactive before executing a trajectory\nthat should use the joint trajectory controller.\n\nI think that the TEM actually does not have a way to read if a given\ncontroller is set as default or not. I see that this part of the controller\nstate is read [ here ](https://github.com/ros-\nplanning/moveit2/blob/14d2a932c74ab1dc6bed652738d17ee2bae23d4f/moveit_ros/planning/trajectory_execution_manager/src/trajectory_execution_manager.cpp#L778-L779)\n, but I can't find where we read the parameter you linked and set its value in\nthe controller state info.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@AndyZe](https://avatars.githubusercontent.com/u/11284393?s=80&u=24eb488e02f9d9ce574f09c9025fa15d8f3814e6&v=4)\n](/AndyZe)\n\nCopy link\n\nContributor\n\n###\n\n**[ AndyZe ](/AndyZe) ** commented  Apr 14, 2022\n\n> I would have to make sure that the streaming controller is inactive before\n> executing a trajectory that should use the joint trajectory controller.\n\nThe ros2_control resource manager should prevent that.\n\nI don't want to sound too negative about your idea. If we add this new\nfeature, can we strip out some \"controller searching\" code, too? Don't want to\nkeep adding and adding without removing.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@schornakj](https://avatars.githubusercontent.com/u/14431472?s=80&u=fcccfc4fa3bebac047c907adad078dc822f22ccc&v=4)\n](/schornakj)\n\nCopy link\n\nContributor  Author\n\n###\n\n**[ schornakj ](/schornakj) ** commented  Apr 14, 2022\n\n> The ros2_control resource manager should prevent that.\n\nWhat do you mean when you say \"prevent\"? I should expand a bit on what I\nposted earlier to be clearer:\n\nIf the controllers aren't switched automatically before handling the\ntrajectory **and I want to successfully execute a trajectory using the joint\ntrajectory controller even if the streaming controller is currently active** ,\nI would have to make sure that the streaming controller is inactive before\nexecuting a trajectory that should use the joint trajectory controller\n**because the controllers will no longer be switched automatically if the\ncurrent configuration of the system is different from the configuration needed\nto execute the trajectory with the desired controller** .\n\nI agree that the TEM's controller search logic should be largely removed. It's\nkind of broken anyway. A minor complication is that lots of code that uses\nMoveIt assumes that if no particular controller is specified when executing a\ntrajectory then the TEM will pick the right controller to use. Since most\nprojects just use one controller per set of joints, it's probably acceptable\nto replace the TEM's controller search logic with some simple condition, like\npicking the first currently-active controller that controls the joints\nactuated by the trajectory.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@AndyZe](https://avatars.githubusercontent.com/u/11284393?s=80&u=24eb488e02f9d9ce574f09c9025fa15d8f3814e6&v=4)\n](/AndyZe)\n\nCopy link\n\nContributor\n\n###\n\n**[ AndyZe ](/AndyZe) ** commented  Apr 14, 2022\n\n> Since most projects just use one controller per set of joints, it's probably\n> acceptable to replace the TEM's controller search logic with some simple\n> condition, like picking the first currently-active controller that controls\n> the joints actuated by the trajectory.\n\nI'd prefer something even simpler: just take what's in the [ yaml file\n](https://github.com/ros-\nplanning/moveit_resources/blob/394a3c6aba9da34d5317697fdb0db2c9acc8ebd8/panda_moveit_config/config/moveit_controllers.yaml#L10)\nas the default. If the default is not active, then so be it. MoveIt shouldn't\nbe searching.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@schornakj](https://avatars.githubusercontent.com/u/14431472?s=80&u=fcccfc4fa3bebac047c907adad078dc822f22ccc&v=4)\n](/schornakj)\n\nCopy link\n\nContributor  Author\n\n###\n\n**[ schornakj ](/schornakj) ** commented  Apr 14, 2022\n\n> I'd prefer something even simpler: just take what's in the [ yaml file\n> ](https://github.com/ros-\n> planning/moveit_resources/blob/394a3c6aba9da34d5317697fdb0db2c9acc8ebd8/panda_moveit_config/config/moveit_controllers.yaml#L10)\n> as the default. If the default is not active, then so be it. MoveIt\n> shouldn't be searching.\n\nOne issue: this YAML file is only used by the [ MoveItSimpleControllerManager\n](https://github.com/ros-\nplanning/moveit2/blob/main/moveit_plugins/moveit_simple_controller_manager/src/moveit_simple_controller_manager.cpp)\n, right? I'm using the [ MoveItControllerManager ](https://github.com/ros-\nplanning/moveit2/blob/main/moveit_plugins/moveit_ros_control_interface/src/controller_manager_plugin.cpp)\n, which gets controller states from the ros2_control ControllerManager, and\nros2_control does not have an equivalent concept of a controller being set as\na default.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ Sign up for free ](/join?source=comment-repo) **to join this conversation on\nGitHub** . Already have an account? [ Sign in to comment\n](/login?return_to=https%3A%2F%2Fgithub.com%2Fros-\nplanning%2Fmoveit2%2Fissues%2F1182)\n\nAssignees\n\nNo one assigned\n\nLabels\n\n[ enhancement  ](/ros-planning/moveit2/labels/enhancement) New feature or\nrequest\n\nProjects\n\n[ MoveIt  ](/orgs/ros-planning/projects/5)\n\nStatus: No status  +2 more\n\nMilestone\n\nNo milestone\n\nDevelopment\n\nNo branches or pull requests\n\n2 participants\n\n[ ![@AndyZe](https://avatars.githubusercontent.com/u/11284393?s=52&v=4)\n](/AndyZe) [\n![@schornakj](https://avatars.githubusercontent.com/u/14431472?s=52&v=4)\n](/schornakj)\n\n##  Footer\n\n[ ](https://github.com \"GitHub\") \u00a9 2024 GitHub, Inc.\n\n###  Footer navigation\n\n  * [ Terms ](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [ Privacy ](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [ Security ](/security)\n  * [ Status ](https://www.githubstatus.com/)\n  * [ Docs ](https://docs.github.com/)\n  * [ Contact ](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.\n\n"
  },
  {
    "id": "rclcpp_service_action/Cpphtml.txt",
    "content": "[ ROS 2 Documentation: Rolling ![Logo](../../../_static/rolling-small.png)\n](../../../index.html)\n\n  * [ Installation ](../../../Installation.html)\n    * [ Ubuntu (Debian packages) ](../../../Installation/Ubuntu-Install-Debians.html)\n    * [ Windows (binary) ](../../../Installation/Windows-Install-Binary.html)\n    * [ RHEL (RPM packages) ](../../../Installation/RHEL-Install-RPMs.html)\n    * [ Alternatives ](../../../Installation/Alternatives.html)\n      * [ Ubuntu (source) ](../../../Installation/Alternatives/Ubuntu-Development-Setup.html)\n      * [ Ubuntu (binary) ](../../../Installation/Alternatives/Ubuntu-Install-Binary.html)\n      * [ Windows (source) ](../../../Installation/Alternatives/Windows-Development-Setup.html)\n      * [ RHEL (source) ](../../../Installation/Alternatives/RHEL-Development-Setup.html)\n      * [ RHEL (binary) ](../../../Installation/Alternatives/RHEL-Install-Binary.html)\n      * [ macOS (source) ](../../../Installation/Alternatives/macOS-Development-Setup.html)\n      * [ Latest development (source) ](../../../Installation/Alternatives/Latest-Development-Setup.html)\n    * [ Maintain source checkout ](../../../Installation/Maintaining-a-Source-Checkout.html)\n    * [ Testing with pre-release binaries ](../../../Installation/Testing.html)\n    * [ DDS implementations ](../../../Installation/DDS-Implementations.html)\n      * [ Connext security plugins ](../../../Installation/DDS-Implementations/Install-Connext-Security-Plugins.html)\n      * [ RTI Connext DDS ](../../../Installation/DDS-Implementations/Install-Connext-University-Eval.html)\n      * [ Eclipse Cyclone DDS ](../../../Installation/DDS-Implementations/Working-with-Eclipse-CycloneDDS.html)\n      * [ GurumNetworks GurumDDS ](../../../Installation/DDS-Implementations/Working-with-GurumNetworks-GurumDDS.html)\n      * [ eProsima Fast DDS ](../../../Installation/DDS-Implementations/Working-with-eProsima-Fast-DDS.html)\n  * [ Distributions ](../../../Releases.html)\n    * [ Iron Irwini ( ` iron  ` ) ](../../../Releases/Release-Iron-Irwini.html)\n      * [ Iron Irwini Changelog ](../../../Releases/Iron-Irwini-Complete-Changelog.html)\n    * [ Humble Hawksbill ( ` humble  ` ) ](../../../Releases/Release-Humble-Hawksbill.html)\n      * [ Humble Hawksbill changelog ](../../../Releases/Humble-Hawksbill-Complete-Changelog.html)\n    * [ Rolling Ridley ( ` rolling  ` ) ](../../../Releases/Release-Rolling-Ridley.html)\n    * [ Development Distribution ](../../../Releases/Development.html)\n      * [ Jazzy Jalisco ( ` jazzy  ` ) ](../../../Releases/Release-Jazzy-Jalisco.html)\n    * [ End-of-Life Distributions ](../../../Releases/End-of-Life.html)\n      * [ Galactic Geochelone ( ` galactic  ` ) ](../../../Releases/Release-Galactic-Geochelone.html)\n        * [ Galactic Geochelone changelog ](../../../Releases/Galactic-Geochelone-Complete-Changelog.html)\n      * [ Foxy Fitzroy ( ` foxy  ` ) ](../../../Releases/Release-Foxy-Fitzroy.html)\n      * [ Eloquent Elusor ( ` eloquent  ` ) ](../../../Releases/Release-Eloquent-Elusor.html)\n      * [ Dashing Diademata ( ` dashing  ` ) ](../../../Releases/Release-Dashing-Diademata.html)\n      * [ Crystal Clemmys ( ` crystal  ` ) ](../../../Releases/Release-Crystal-Clemmys.html)\n      * [ Bouncy Bolson ( ` bouncy  ` ) ](../../../Releases/Release-Bouncy-Bolson.html)\n      * [ Ardent Apalone ( ` ardent  ` ) ](../../../Releases/Release-Ardent-Apalone.html)\n      * [ Beta 3 ( ` r2b3  ` ) ](../../../Releases/Beta3-Overview.html)\n      * [ Beta 2 ( ` r2b2  ` ) ](../../../Releases/Beta2-Overview.html)\n      * [ Beta 1 ( ` Asphalt  ` ) ](../../../Releases/Beta1-Overview.html)\n      * [ Alphas ](../../../Releases/Alpha-Overview.html)\n    * [ Development process for a release ](../../../Releases/Release-Process.html)\n  * [ Tutorials ](../../../Tutorials.html)\n    * [ Beginner: CLI tools ](../../Beginner-CLI-Tools.html)\n      * [ Configuring environment ](../../Beginner-CLI-Tools/Configuring-ROS2-Environment.html)\n      * [ Using ` turtlesim  ` , ` ros2  ` , and ` rqt  ` ](../../Beginner-CLI-Tools/Introducing-Turtlesim/Introducing-Turtlesim.html)\n      * [ Understanding nodes ](../../Beginner-CLI-Tools/Understanding-ROS2-Nodes/Understanding-ROS2-Nodes.html)\n      * [ Understanding topics ](../../Beginner-CLI-Tools/Understanding-ROS2-Topics/Understanding-ROS2-Topics.html)\n      * [ Understanding services ](../../Beginner-CLI-Tools/Understanding-ROS2-Services/Understanding-ROS2-Services.html)\n      * [ Understanding parameters ](../../Beginner-CLI-Tools/Understanding-ROS2-Parameters/Understanding-ROS2-Parameters.html)\n      * [ Understanding actions ](../../Beginner-CLI-Tools/Understanding-ROS2-Actions/Understanding-ROS2-Actions.html)\n      * [ Using ` rqt_console  ` to view logs ](../../Beginner-CLI-Tools/Using-Rqt-Console/Using-Rqt-Console.html)\n      * [ Launching nodes ](../../Beginner-CLI-Tools/Launching-Multiple-Nodes/Launching-Multiple-Nodes.html)\n      * [ Recording and playing back data ](../../Beginner-CLI-Tools/Recording-And-Playing-Back-Data/Recording-And-Playing-Back-Data.html)\n    * [ Beginner: Client libraries ](../../Beginner-Client-Libraries.html)\n      * [ Using ` colcon  ` to build packages ](../../Beginner-Client-Libraries/Colcon-Tutorial.html)\n      * [ Creating a workspace ](../../Beginner-Client-Libraries/Creating-A-Workspace/Creating-A-Workspace.html)\n      * [ Creating a package ](../../Beginner-Client-Libraries/Creating-Your-First-ROS2-Package.html)\n      * [ Writing a simple publisher and subscriber (C++) ](../../Beginner-Client-Libraries/Writing-A-Simple-Cpp-Publisher-And-Subscriber.html)\n      * [ Writing a simple publisher and subscriber (Python) ](../../Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html)\n      * [ Writing a simple service and client (C++) ](../../Beginner-Client-Libraries/Writing-A-Simple-Cpp-Service-And-Client.html)\n      * [ Writing a simple service and client (Python) ](../../Beginner-Client-Libraries/Writing-A-Simple-Py-Service-And-Client.html)\n      * [ Creating custom msg and srv files ](../../Beginner-Client-Libraries/Custom-ROS2-Interfaces.html)\n      * [ Implementing custom interfaces ](../../Beginner-Client-Libraries/Single-Package-Define-And-Use-Interface.html)\n      * [ Using parameters in a class (C++) ](../../Beginner-Client-Libraries/Using-Parameters-In-A-Class-CPP.html)\n      * [ Using parameters in a class (Python) ](../../Beginner-Client-Libraries/Using-Parameters-In-A-Class-Python.html)\n      * [ Using ` ros2doctor  ` to identify issues ](../../Beginner-Client-Libraries/Getting-Started-With-Ros2doctor.html)\n      * [ Creating and using plugins (C++) ](../../Beginner-Client-Libraries/Pluginlib.html)\n    * [ Intermediate ](../../Intermediate.html)\n      * [ Managing Dependencies with rosdep ](../Rosdep.html)\n      * [ Creating an action ](../Creating-an-Action.html)\n      * Writing an action server and client (C++) \n      * [ Writing an action server and client (Python) ](Py.html)\n      * [ Writing a Composable Node (C++) ](../Writing-a-Composable-Node.html)\n      * [ Composing multiple nodes in a single process ](../Composition.html)\n      * [ Monitoring for parameter changes (C++) ](../Monitoring-For-Parameter-Changes-CPP.html)\n      * [ Monitoring for parameter changes (Python) ](../Monitoring-For-Parameter-Changes-Python.html)\n      * [ Launch ](../Launch/Launch-Main.html)\n        * [ Creating a launch file ](../Launch/Creating-Launch-Files.html)\n        * [ Integrating launch files into ROS 2 packages ](../Launch/Launch-system.html)\n        * [ Using substitutions ](../Launch/Using-Substitutions.html)\n        * [ Using event handlers ](../Launch/Using-Event-Handlers.html)\n        * [ Managing large projects ](../Launch/Using-ROS2-Launch-For-Large-Projects.html)\n      * [ ` tf2  ` ](../Tf2/Tf2-Main.html)\n        * [ Introducing ` tf2  ` ](../Tf2/Introduction-To-Tf2.html)\n        * [ Writing a static broadcaster (Python) ](../Tf2/Writing-A-Tf2-Static-Broadcaster-Py.html)\n        * [ Writing a static broadcaster (C++) ](../Tf2/Writing-A-Tf2-Static-Broadcaster-Cpp.html)\n        * [ Writing a broadcaster (Python) ](../Tf2/Writing-A-Tf2-Broadcaster-Py.html)\n        * [ Writing a broadcaster (C++) ](../Tf2/Writing-A-Tf2-Broadcaster-Cpp.html)\n        * [ Writing a listener (Python) ](../Tf2/Writing-A-Tf2-Listener-Py.html)\n        * [ Writing a listener (C++) ](../Tf2/Writing-A-Tf2-Listener-Cpp.html)\n        * [ Adding a frame (Python) ](../Tf2/Adding-A-Frame-Py.html)\n        * [ Adding a frame (C++) ](../Tf2/Adding-A-Frame-Cpp.html)\n        * [ Using time (Python) ](../Tf2/Learning-About-Tf2-And-Time-Py.html)\n        * [ Using time (C++) ](../Tf2/Learning-About-Tf2-And-Time-Cpp.html)\n        * [ Traveling in time (Python) ](../Tf2/Time-Travel-With-Tf2-Py.html)\n        * [ Traveling in time (C++) ](../Tf2/Time-Travel-With-Tf2-Cpp.html)\n        * [ Debugging ](../Tf2/Debugging-Tf2-Problems.html)\n        * [ Quaternion fundamentals ](../Tf2/Quaternion-Fundamentals.html)\n        * [ Using stamped datatypes with ` tf2_ros::MessageFilter  ` ](../Tf2/Using-Stamped-Datatypes-With-Tf2-Ros-MessageFilter.html)\n      * [ Testing ](../Testing/Testing-Main.html)\n        * [ Running Tests in ROS 2 from the Command Line ](../Testing/CLI.html)\n        * [ Writing Basic Tests with C++ with GTest ](../Testing/Cpp.html)\n        * [ Writing Basic Tests with Python ](../Testing/Python.html)\n      * [ URDF ](../URDF/URDF-Main.html)\n        * [ Building a visual robot model from scratch ](../URDF/Building-a-Visual-Robot-Model-with-URDF-from-Scratch.html)\n        * [ Building a movable robot model ](../URDF/Building-a-Movable-Robot-Model-with-URDF.html)\n        * [ Adding physical and collision properties ](../URDF/Adding-Physical-and-Collision-Properties-to-a-URDF-Model.html)\n        * [ Using Xacro to clean up your code ](../URDF/Using-Xacro-to-Clean-Up-a-URDF-File.html)\n        * [ Using URDF with ` robot_state_publisher  ` ](../URDF/Using-URDF-with-Robot-State-Publisher.html)\n        * [ Generating an URDF File ](../URDF/Exporting-an-URDF-File.html)\n      * [ RViz ](../RViz/RViz-Main.html)\n        * [ RViz User Guide ](../RViz/RViz-User-Guide/RViz-User-Guide.html)\n        * [ Building a Custom RViz Display ](../RViz/RViz-Custom-Display/RViz-Custom-Display.html)\n    * [ Advanced ](../../Advanced.html)\n      * [ Enabling topic statistics (C++) ](../../Advanced/Topic-Statistics-Tutorial/Topic-Statistics-Tutorial.html)\n      * [ Using Fast DDS Discovery Server as discovery protocol [community-contributed] ](../../Advanced/Discovery-Server/Discovery-Server.html)\n      * [ Implementing a custom memory allocator ](../../Advanced/Allocator-Template-Tutorial.html)\n      * [ Unlocking the potential of Fast DDS middleware [community-contributed] ](../../Advanced/FastDDS-Configuration.html)\n      * [ Improved Dynamic Discovery ](../../Advanced/Improved-Dynamic-Discovery.html)\n      * [ Recording a bag from a node (C++) ](../../Advanced/Recording-A-Bag-From-Your-Own-Node-CPP.html)\n      * [ Recording a bag from a node (Python) ](../../Advanced/Recording-A-Bag-From-Your-Own-Node-Py.html)\n      * [ Reading from a bag file (C++) ](../../Advanced/Reading-From-A-Bag-File-CPP.html)\n      * [ How to use ros2_tracing to trace and analyze an application ](../../Advanced/ROS2-Tracing-Trace-and-Analyze.html)\n      * [ Simulators ](../../Advanced/Simulators/Simulation-Main.html)\n        * [ Webots ](../../Advanced/Simulators/Webots/Simulation-Webots.html)\n          * [ Installation (Ubuntu) ](../../Advanced/Simulators/Webots/Installation-Ubuntu.html)\n          * [ Installation (Windows) ](../../Advanced/Simulators/Webots/Installation-Windows.html)\n          * [ Installation (macOS) ](../../Advanced/Simulators/Webots/Installation-MacOS.html)\n          * [ Setting up a robot simulation (Basic) ](../../Advanced/Simulators/Webots/Setting-Up-Simulation-Webots-Basic.html)\n          * [ Setting up a robot simulation (Advanced) ](../../Advanced/Simulators/Webots/Setting-Up-Simulation-Webots-Advanced.html)\n          * [ Setting up a Reset Handler ](../../Advanced/Simulators/Webots/Simulation-Reset-Handler.html)\n          * [ The Ros2Supervisor Node ](../../Advanced/Simulators/Webots/Simulation-Supervisor.html)\n        * [ Gazebo ](../../Advanced/Simulators/Gazebo/Simulation-Gazebo.html)\n          * [ Setting up a robot simulation (Gazebo) ](../../Advanced/Simulators/Gazebo/Gazebo.html)\n      * [ Security ](../../Advanced/Security/Security-Main.html)\n        * [ Setting up security ](../../Advanced/Security/Introducing-ros2-security.html)\n        * [ Understanding the security keystore ](../../Advanced/Security/The-Keystore.html)\n        * [ Ensuring security across machines ](../../Advanced/Security/Security-on-Two.html)\n        * [ Examining network traffic ](../../Advanced/Security/Examine-Traffic.html)\n        * [ Setting access controls ](../../Advanced/Security/Access-Controls.html)\n        * [ Deployment Guidelines ](../../Advanced/Security/Deployment-Guidelines.html)\n    * [ Demos ](../../Demos.html)\n      * [ Using quality-of-service settings for lossy networks ](../../Demos/Quality-of-Service.html)\n      * [ Managing nodes with managed lifecycles ](../../Demos/Managed-Nodes.html)\n      * [ Setting up efficient intra-process communication ](../../Demos/Intra-Process-Communication.html)\n      * [ Recording and playing back data with ` rosbag  ` using the ROS 1 bridge ](../../Demos/Rosbag-with-ROS1-Bridge.html)\n      * [ Understanding real-time programming ](../../Demos/Real-Time-Programming.html)\n      * [ Experimenting with a dummy robot ](../../Demos/dummy-robot-demo.html)\n      * [ Logging ](../../Demos/Logging-and-logger-configuration.html)\n      * [ Creating a content filtering subscription ](../../Demos/Content-Filtering-Subscription.html)\n      * [ Configure service introspection ](../../Demos/Service-Introspection.html)\n    * [ Miscellaneous ](../../Miscellaneous.html)\n      * [ Deploying on IBM Cloud Kubernetes [community-contributed] ](../../Miscellaneous/Deploying-ROS-2-on-IBM-Cloud.html)\n      * [ Using Eclipse Oxygen with ` rviz2  ` [community-contributed] ](../../Miscellaneous/Eclipse-Oxygen-with-ROS-2-and-rviz2.html)\n      * [ Building a real-time Linux kernel [community-contributed] ](../../Miscellaneous/Building-Realtime-rt_preempt-kernel-for-ROS-2.html)\n      * [ Building a package with Eclipse 2021-06 ](../../Miscellaneous/Building-ROS2-Package-with-eclipse-2021-06.html)\n  * [ How-to Guides ](../../../How-To-Guides.html)\n    * [ Installation troubleshooting ](../../../How-To-Guides/Installation-Troubleshooting.html)\n    * [ Developing a ROS 2 package ](../../../How-To-Guides/Developing-a-ROS-2-Package.html)\n    * [ Documenting a ROS 2 package ](../../../How-To-Guides/Documenting-a-ROS-2-Package.html)\n    * [ ament_cmake user documentation ](../../../How-To-Guides/Ament-CMake-Documentation.html)\n    * [ ament_cmake_python user documentation ](../../../How-To-Guides/Ament-CMake-Python-Documentation.html)\n    * [ Migrating from ROS 1 to ROS 2 ](../../../How-To-Guides/Migrating-from-ROS1.html)\n      * [ Migrating Packages ](../../../How-To-Guides/Migrating-from-ROS1/Migrating-Packages.html)\n      * [ Migrating Interfaces ](../../../How-To-Guides/Migrating-from-ROS1/Migrating-Interfaces.html)\n      * [ Migrating C++ Packages ](../../../How-To-Guides/Migrating-from-ROS1/Migrating-CPP-Packages.html)\n      * [ Migrating Python Packages ](../../../How-To-Guides/Migrating-from-ROS1/Migrating-Python-Packages.html)\n      * [ Migrating Launch Files ](../../../How-To-Guides/Migrating-from-ROS1/Migrating-Launch-Files.html)\n      * [ Migrating Parameters ](../../../How-To-Guides/Migrating-from-ROS1/Migrating-Parameters.html)\n      * [ Migrating Scripts ](../../../How-To-Guides/Migrating-from-ROS1/Migrating-Scripts.html)\n    * [ Using Python, XML, and YAML for ROS 2 Launch Files ](../../../How-To-Guides/Launch-file-different-formats.html)\n    * [ Using ROS 2 launch to launch composable nodes ](../../../How-To-Guides/Launching-composable-nodes.html)\n    * [ Passing ROS arguments to nodes via the command-line ](../../../How-To-Guides/Node-arguments.html)\n    * [ Synchronous vs. asynchronous service clients ](../../../How-To-Guides/Sync-Vs-Async.html)\n    * [ DDS tuning information ](../../../How-To-Guides/DDS-tuning.html)\n    * [ rosbag2: Overriding QoS Policies ](../../../How-To-Guides/Overriding-QoS-Policies-For-Recording-And-Playback.html)\n    * [ Working with multiple ROS 2 middleware implementations ](../../../How-To-Guides/Working-with-multiple-RMW-implementations.html)\n    * [ Cross-compilation ](../../../How-To-Guides/Cross-compilation.html)\n    * [ Releasing a Package ](../../../How-To-Guides/Releasing/Releasing-a-Package.html)\n      * [ First Time Release ](../../../How-To-Guides/Releasing/First-Time-Release.html)\n      * [ Subsequent Releases ](../../../How-To-Guides/Releasing/Subsequent-Releases.html)\n      * [ Release Team / Repository ](../../../How-To-Guides/Releasing/Release-Team-Repository.html)\n      * [ Release Track ](../../../How-To-Guides/Releasing/Release-Track.html)\n    * [ Using Python Packages with ROS 2 ](../../../How-To-Guides/Using-Python-Packages.html)\n    * [ Porting RQt plugins to Windows ](../../../How-To-Guides/RQt-Port-Plugin-Windows.html)\n    * [ Running ROS 2 nodes in Docker [community-contributed] ](../../../How-To-Guides/Run-2-nodes-in-single-or-separate-docker-containers.html)\n    * [ Visualizing ROS 2 data with Foxglove Studio ](../../../How-To-Guides/Visualizing-ROS-2-Data-With-Foxglove-Studio.html)\n    * [ ROS 2 Package Maintainer Guide ](../../../How-To-Guides/Package-maintainer-guide.html)\n    * [ Building a custom Debian package ](../../../How-To-Guides/Building-a-Custom-Debian-Package.html)\n    * [ Building ROS 2 with tracing ](../../../How-To-Guides/Building-ROS-2-with-Tracing.html)\n    * [ Topics vs Services vs Actions ](../../../How-To-Guides/Topics-Services-Actions.html)\n    * [ Using variants ](../../../How-To-Guides/Using-Variants.html)\n    * [ Using the ` ros2  param  ` command-line tool ](../../../How-To-Guides/Using-ros2-param.html)\n    * [ Using ` ros1_bridge  ` with upstream ROS on Ubuntu 22.04 ](../../../How-To-Guides/Using-ros1_bridge-Jammy-upstream.html)\n    * [ Configure Zero Copy Loaned Messages ](../../../How-To-Guides/Configure-ZeroCopy-loaned-messages.html)\n    * [ ROS 2 on Raspberry Pi ](../../../How-To-Guides/Installing-on-Raspberry-Pi.html)\n    * [ Using Callback Groups ](../../../How-To-Guides/Using-callback-groups.html)\n    * [ IDEs and Debugging [community-contributed] ](../../../How-To-Guides/ROS-2-IDEs.html)\n    * [ Setup ROS 2 with VSCode and Docker [community-contributed] ](../../../How-To-Guides/Setup-ROS-2-with-VSCode-and-Docker-Container.html)\n    * [ Using Custom Rosdistro Version ](../../../How-To-Guides/Using-Custom-Rosdistro.html)\n    * [ Building RQt from source ](../../../How-To-Guides/RQt-Source-Install.html)\n      * [ Building RQt from source on macOS ](../../../How-To-Guides/RQt-Source-Install-MacOS.html)\n      * [ Building RQt from source on Windows 10 ](../../../How-To-Guides/RQt-Source-Install-Windows10.html)\n  * [ Concepts ](../../../Concepts.html)\n    * [ Basic Concepts ](../../../Concepts/Basic.html)\n      * [ Nodes ](../../../Concepts/Basic/About-Nodes.html)\n      * [ Discovery ](../../../Concepts/Basic/About-Discovery.html)\n      * [ Interfaces ](../../../Concepts/Basic/About-Interfaces.html)\n      * [ Topics ](../../../Concepts/Basic/About-Topics.html)\n      * [ Services ](../../../Concepts/Basic/About-Services.html)\n      * [ Actions ](../../../Concepts/Basic/About-Actions.html)\n      * [ Parameters ](../../../Concepts/Basic/About-Parameters.html)\n      * [ Introspection with command line tools ](../../../Concepts/Basic/About-Command-Line-Tools.html)\n      * [ Launch ](../../../Concepts/Basic/About-Launch.html)\n      * [ Client libraries ](../../../Concepts/Basic/About-Client-Libraries.html)\n    * [ Intermediate Concepts ](../../../Concepts/Intermediate.html)\n      * [ The ROS_DOMAIN_ID ](../../../Concepts/Intermediate/About-Domain-ID.html)\n      * [ Different ROS 2 middleware vendors ](../../../Concepts/Intermediate/About-Different-Middleware-Vendors.html)\n      * [ Logging and logger configuration ](../../../Concepts/Intermediate/About-Logging.html)\n      * [ Quality of Service settings ](../../../Concepts/Intermediate/About-Quality-of-Service-Settings.html)\n      * [ Executors ](../../../Concepts/Intermediate/About-Executors.html)\n      * [ Topic statistics ](../../../Concepts/Intermediate/About-Topic-Statistics.html)\n      * [ Overview and usage of RQt ](../../../Concepts/Intermediate/About-RQt.html)\n      * [ Composition ](../../../Concepts/Intermediate/About-Composition.html)\n      * [ Cross-compilation ](../../../Concepts/Intermediate/About-Cross-Compilation.html)\n      * [ ROS 2 Security ](../../../Concepts/Intermediate/About-Security.html)\n      * [ Tf2 ](../../../Concepts/Intermediate/About-Tf2.html)\n    * [ Advanced Concepts ](../../../Concepts/Advanced.html)\n      * [ The build system ](../../../Concepts/Advanced/About-Build-System.html)\n      * [ Internal ROS 2 interfaces ](../../../Concepts/Advanced/About-Internal-Interfaces.html)\n      * [ ROS 2 middleware implementations ](../../../Concepts/Advanced/About-Middleware-Implementations.html)\n  * [ Contact ](../../../Contact.html)\n  * [ The ROS 2 Project ](../../../The-ROS2-Project.html)\n    * [ Contributing ](../../../The-ROS2-Project/Contributing.html)\n      * [ ROS 2 developer guide ](../../../The-ROS2-Project/Contributing/Developer-Guide.html)\n      * [ Code style and language versions ](../../../The-ROS2-Project/Contributing/Code-Style-Language-Versions.html)\n      * [ Quality guide: ensuring code quality ](../../../The-ROS2-Project/Contributing/Quality-Guide.html)\n      * [ ROS Build Farms ](../../../The-ROS2-Project/Contributing/Build-Farms.html)\n      * [ Windows Tips and Tricks ](../../../The-ROS2-Project/Contributing/Windows-Tips-and-Tricks.html)\n      * [ Contributing to ROS 2 Documentation ](../../../The-ROS2-Project/Contributing/Contributing-To-ROS-2-Documentation.html)\n    * [ Features Status ](../../../The-ROS2-Project/Features.html)\n    * [ Feature Ideas ](../../../The-ROS2-Project/Feature-Ideas.html)\n    * [ Roadmap ](../../../The-ROS2-Project/Roadmap.html)\n    * [ ROSCon Talks ](../../../The-ROS2-Project/ROSCon-Content.html)\n    * [ Project Governance ](../../../The-ROS2-Project/Governance.html)\n      * [ ROS 2 Technical Steering Committee Charter ](../../../The-ROS2-Project/Governance/ROS2-TSC-Charter.html)\n      * [ ROS 2 TSC applicant intake process ](../../../The-ROS2-Project/Governance/ROS2-TSC-Intake-process.html)\n      * [ About Working Groups ](../../../The-ROS2-Project/Governance/Working-Groups.html)\n      * [ How to Start a Community Working Group ](../../../The-ROS2-Project/Governance/How-To-Start-A-Community-Working-Group.html)\n    * [ Marketing ](../../../The-ROS2-Project/Marketing.html)\n    * [ Metrics ](../../../The-ROS2-Project/Metrics.html)\n  * [ API Documentation ](../../../API-Docs.html)\n  * [ Related Projects ](../../../Related-Projects.html)\n    * [ Intel ROS 2 Projects ](../../../Related-Projects/Intel-ROS2-Projects.html)\n    * [ NVIDIA ROS 2 Projects ](../../../Related-Projects/Nvidia-ROS2-Projects.html)\n  * [ Glossary ](../../../Glossary.html)\n  * [ Citations ](../../../Citations.html)\n\n__ [ ROS 2 Documentation: Rolling ](../../../index.html)\n\n  * [ ](../../../index.html)\n  * [ Tutorials ](../../../Tutorials.html)\n  * [ Intermediate ](../../Intermediate.html)\n  * Writing an action server and client (C++) \n  * [ Edit on GitHub ](https://github.com/ros2/ros2_documentation/blob/rolling/source/Tutorials/Intermediate/Writing-an-Action-Server-Client/Cpp.rst)\n\n* * *\n\n**You're reading the documentation for a development version. For the latest\nreleased version, please have a look at[ Iron\n](../../../../iron/Tutorials/Intermediate/Writing-an-Action-Server-\nClient/Cpp.html) . **\n\n#  Writing an action server and client (C++)  \u00ef\u0083\u0081\n\n**Goal:** Implement an action server and client in C++.\n\n**Tutorial level:** Intermediate\n\n**Time:** 15 minutes\n\nContents\n\n  * Background \n\n  * Prerequisites \n\n  * Tasks \n\n    * 1 Creating the custom_action_cpp package \n\n    * 2 Writing an action server \n\n    * 3 Writing an action client \n\n  * Summary \n\n  * Related content \n\n##  Background  \u00ef\u0083\u0081\n\nActions are a form of asynchronous communication in ROS. _Action clients_ send\ngoal requests to _action servers_ . _Action servers_ send goal feedback and\nresults to _action clients_ .\n\n##  Prerequisites  \u00ef\u0083\u0081\n\nYou will need the ` custom_action_interfaces  ` package and the `\nFibonacci.action  ` interface defined in the previous tutorial, [ Creating an\naction  ](../Creating-an-Action.html) .\n\n##  Tasks  \u00ef\u0083\u0081\n\n###  1 Creating the custom_action_cpp package  \u00ef\u0083\u0081\n\nAs we saw in the [ Creating a package  ](../../Beginner-Client-\nLibraries/Creating-Your-First-ROS2-Package.html) tutorial, we need to create a\nnew package to hold our C++ and supporting code.\n\n####  1.1 Creating the custom_action_cpp package  \u00ef\u0083\u0081\n\nGo into the action workspace you created in the [ previous tutorial\n](../Creating-an-Action.html) (remember to source the workspace), and create a\nnew package for the C++ action server:\n\nLinux  macOS  Windows\n\n    \n    \n    cd ~/ros2_ws/src\n    ros2 pkg create --dependencies custom_action_interfaces rclcpp rclcpp_action rclcpp_components --license Apache-2.0 -- custom_action_cpp\n    \n    \n    \n    cd ~/ros2_ws/src\n    ros2 pkg create --dependencies custom_action_interfaces rclcpp rclcpp_action rclcpp_components --license Apache-2.0 -- custom_action_cpp\n    \n    \n    \n    cd \\ros2_ws\\src\n    ros2 pkg create --dependencies custom_action_interfaces rclcpp rclcpp_action rclcpp_components --license Apache-2.0 -- custom_action_cpp\n    \n\n####  1.2 Adding in visibility control  \u00ef\u0083\u0081\n\nIn order to make the package compile and work on Windows, we need to add in\nsome \u00e2\u0080\u009cvisibility control\u00e2\u0080\u009d. For more details, see [ Windows Symbol\nVisibility in the Windows Tips and Tricks document  ](../../../The-\nROS2-Project/Contributing/Windows-Tips-and-Tricks.html#windows-symbol-\nvisibility) .\n\nOpen up ` custom_action_cpp/include/custom_action_cpp/visibility_control.h  `\n, and put the following code in:\n\n    \n    \n    #ifndef CUSTOM_ACTION_CPP__VISIBILITY_CONTROL_H_\n    #define CUSTOM_ACTION_CPP__VISIBILITY_CONTROL_H_\n    \n    #ifdef __cplusplus\n    extern \"C\"\n    {\n    #endif\n    \n    // This logic was borrowed (then namespaced) from the examples on the gcc wiki:\n    //     https://gcc.gnu.org/wiki/Visibility\n    \n    #if defined _WIN32 || defined __CYGWIN__\n      #ifdef __GNUC__\n        #define CUSTOM_ACTION_CPP_EXPORT __attribute__ ((dllexport))\n        #define CUSTOM_ACTION_CPP_IMPORT __attribute__ ((dllimport))\n      #else\n        #define CUSTOM_ACTION_CPP_EXPORT __declspec(dllexport)\n        #define CUSTOM_ACTION_CPP_IMPORT __declspec(dllimport)\n      #endif\n      #ifdef CUSTOM_ACTION_CPP_BUILDING_DLL\n        #define CUSTOM_ACTION_CPP_PUBLIC CUSTOM_ACTION_CPP_EXPORT\n      #else\n        #define CUSTOM_ACTION_CPP_PUBLIC CUSTOM_ACTION_CPP_IMPORT\n      #endif\n      #define CUSTOM_ACTION_CPP_PUBLIC_TYPE CUSTOM_ACTION_CPP_PUBLIC\n      #define CUSTOM_ACTION_CPP_LOCAL\n    #else\n      #define CUSTOM_ACTION_CPP_EXPORT __attribute__ ((visibility(\"default\")))\n      #define CUSTOM_ACTION_CPP_IMPORT\n      #if __GNUC__ >= 4\n        #define CUSTOM_ACTION_CPP_PUBLIC __attribute__ ((visibility(\"default\")))\n        #define CUSTOM_ACTION_CPP_LOCAL  __attribute__ ((visibility(\"hidden\")))\n      #else\n        #define CUSTOM_ACTION_CPP_PUBLIC\n        #define CUSTOM_ACTION_CPP_LOCAL\n      #endif\n      #define CUSTOM_ACTION_CPP_PUBLIC_TYPE\n    #endif\n    \n    #ifdef __cplusplus\n    }\n    #endif\n    \n    #endif  // CUSTOM_ACTION_CPP__VISIBILITY_CONTROL_H_\n    \n\n###  2 Writing an action server  \u00ef\u0083\u0081\n\nLet\u00e2\u0080\u0099s focus on writing an action server that computes the Fibonacci sequence\nusing the action we created in the [ Creating an action  ](../Creating-an-\nAction.html) tutorial.\n\n####  2.1 Writing the action server code  \u00ef\u0083\u0081\n\nOpen up ` custom_action_cpp/src/fibonacci_action_server.cpp  ` , and put the\nfollowing code in:\n\n    \n    \n    #include <functional>\n    #include <memory>\n    #include <thread>\n    \n    #include \"custom_action_interfaces/action/fibonacci.hpp\"\n    #include \"rclcpp/rclcpp.hpp\"\n    #include \"rclcpp_action/rclcpp_action.hpp\"\n    #include \"rclcpp_components/register_node_macro.hpp\"\n    \n    #include \"custom_action_cpp/visibility_control.h\"\n    \n    namespace custom_action_cpp\n    {\n    class FibonacciActionServer : public rclcpp::Node\n    {\n    public:\n      using Fibonacci = custom_action_interfaces::action::Fibonacci;\n      using GoalHandleFibonacci = rclcpp_action::ServerGoalHandle<Fibonacci>;\n    \n      CUSTOM_ACTION_CPP_PUBLIC\n      explicit FibonacciActionServer(const rclcpp::NodeOptions & options = rclcpp::NodeOptions())\n      : Node(\"fibonacci_action_server\", options)\n      {\n        using namespace std::placeholders;\n    \n        auto handle_goal = [this](\n          const rclcpp_action::GoalUUID & uuid,\n          std::shared_ptr<const Fibonacci::Goal> goal)\n        {\n          RCLCPP_INFO(this->get_logger(), \"Received goal request with order %d\", goal->order);\n          (void)uuid;\n          return rclcpp_action::GoalResponse::ACCEPT_AND_EXECUTE;\n        };\n    \n        auto handle_cancel = [this](\n          const std::shared_ptr<GoalHandleFibonacci> goal_handle)\n        {\n          RCLCPP_INFO(this->get_logger(), \"Received request to cancel goal\");\n          (void)goal_handle;\n          return rclcpp_action::CancelResponse::ACCEPT;\n        };\n    \n        auto handle_accepted = [this](\n          const std::shared_ptr<GoalHandleFibonacci> goal_handle)\n        {\n          // this needs to return quickly to avoid blocking the executor,\n          // so we declare a lambda function to be called inside a new thread\n          auto execute_in_thread = [this, goal_handle](){return this->execute(goal_handle);};\n          std::thread{execute_in_thread}.detach();\n        };\n    \n        this->action_server_ = rclcpp_action::create_server<Fibonacci>(\n          this,\n          \"fibonacci\",\n          handle_goal,\n          handle_cancel,\n          handle_accepted);\n      }\n    \n    private:\n      rclcpp_action::Server<Fibonacci>::SharedPtr action_server_;\n    \n      void execute(const std::shared_ptr<GoalHandleFibonacci> goal_handle) {\n        RCLCPP_INFO(this->get_logger(), \"Executing goal\");\n        rclcpp::Rate loop_rate(1);\n        const auto goal = goal_handle->get_goal();\n        auto feedback = std::make_shared<Fibonacci::Feedback>();\n        auto & sequence = feedback->partial_sequence;\n        sequence.push_back(0);\n        sequence.push_back(1);\n        auto result = std::make_shared<Fibonacci::Result>();\n    \n        for (int i = 1; (i < goal->order) && rclcpp::ok(); ++i) {\n          // Check if there is a cancel request\n          if (goal_handle->is_canceling()) {\n            result->sequence = sequence;\n            goal_handle->canceled(result);\n            RCLCPP_INFO(this->get_logger(), \"Goal canceled\");\n            return;\n          }\n          // Update sequence\n          sequence.push_back(sequence[i] + sequence[i - 1]);\n          // Publish feedback\n          goal_handle->publish_feedback(feedback);\n          RCLCPP_INFO(this->get_logger(), \"Publish feedback\");\n    \n          loop_rate.sleep();\n        }\n    \n        // Check if goal is done\n        if (rclcpp::ok()) {\n          result->sequence = sequence;\n          goal_handle->succeed(result);\n          RCLCPP_INFO(this->get_logger(), \"Goal succeeded\");\n        }\n      };\n    \n    };  // class FibonacciActionServer\n    \n    }  // namespace custom_action_cpp\n    \n    RCLCPP_COMPONENTS_REGISTER_NODE(custom_action_cpp::FibonacciActionServer)\n    \n\nThe first few lines include all of the headers we need to compile.\n\nNext we create a class that is a derived class of ` rclcpp::Node  ` :\n\n    \n    \n    class FibonacciActionServer : public rclcpp::Node\n    \n\nThe constructor for the ` FibonacciActionServer  ` class initializes the node\nname as ` fibonacci_action_server  ` :\n\n    \n    \n      explicit FibonacciActionServer(const rclcpp::NodeOptions & options = rclcpp::NodeOptions())\n      : Node(\"fibonacci_action_server\", options)\n    \n\nThe constructor also instantiates a new action server:\n\n    \n    \n          loop_rate.sleep();\n        }\n    \n        // Check if goal is done\n        if (rclcpp::ok()) {\n    \n\nAn action server requires 6 things:\n\n  1. The templated action type name: ` Fibonacci  ` . \n\n  2. A ROS 2 node to add the action to: ` this  ` . \n\n  3. The action name: ` 'fibonacci'  ` . \n\n  4. A callback function for handling goals: ` handle_goal  `\n\n  5. A callback function for handling cancellation: ` handle_cancel  ` . \n\n  6. A callback function for handling goal accept: ` handle_accept  ` . \n\nThe implementation of the various callbacks is done with [lambda expressions](\n[ https://en.cppreference.com/w/cpp/language/lambda\n](https://en.cppreference.com/w/cpp/language/lambda) ) within the constructor.\nNote that all of the callbacks need to return quickly, otherwise we risk\nstarving the executor.\n\nWe start with the callback for handling new goals:\n\n    \n    \n        auto handle_goal = [this](\n          const rclcpp_action::GoalUUID & uuid,\n          std::shared_ptr<const Fibonacci::Goal> goal)\n        {\n          RCLCPP_INFO(this->get_logger(), \"Received goal request with order %d\", goal->order);\n          (void)uuid;\n          return rclcpp_action::GoalResponse::ACCEPT_AND_EXECUTE;\n        };\n    \n\nThis implementation just accepts all goals.\n\nNext up is the callback for dealing with cancellation:\n\n    \n    \n        auto handle_cancel = [this](\n          const std::shared_ptr<GoalHandleFibonacci> goal_handle)\n        {\n          RCLCPP_INFO(this->get_logger(), \"Received request to cancel goal\");\n          (void)goal_handle;\n          return rclcpp_action::CancelResponse::ACCEPT;\n        };\n    \n\nThis implementation just tells the client that it accepted the cancellation.\n\nThe last of the callbacks accepts a new goal and starts processing it:\n\n    \n    \n        auto handle_accepted = [this](\n          const std::shared_ptr<GoalHandleFibonacci> goal_handle)\n        {\n          // this needs to return quickly to avoid blocking the executor,\n          // so we declare a lambda function to be called inside a new thread\n          auto execute_in_thread = [this, goal_handle](){return this->execute(goal_handle);};\n          std::thread{execute_in_thread}.detach();\n        };\n    \n\nSince the execution is a long-running operation, we spawn off a thread to do\nthe actual work and return from ` handle_accepted  ` quickly.\n\nAll further processing and updates are done in the ` execute  ` method in the\nnew thread:\n\n    \n    \n      void execute(const std::shared_ptr<GoalHandleFibonacci> goal_handle) {\n        RCLCPP_INFO(this->get_logger(), \"Executing goal\");\n        rclcpp::Rate loop_rate(1);\n        const auto goal = goal_handle->get_goal();\n        auto feedback = std::make_shared<Fibonacci::Feedback>();\n        auto & sequence = feedback->partial_sequence;\n        sequence.push_back(0);\n        sequence.push_back(1);\n        auto result = std::make_shared<Fibonacci::Result>();\n    \n        for (int i = 1; (i < goal->order) && rclcpp::ok(); ++i) {\n          // Check if there is a cancel request\n          if (goal_handle->is_canceling()) {\n            result->sequence = sequence;\n            goal_handle->canceled(result);\n            RCLCPP_INFO(this->get_logger(), \"Goal canceled\");\n            return;\n          }\n          // Update sequence\n          sequence.push_back(sequence[i] + sequence[i - 1]);\n          // Publish feedback\n          goal_handle->publish_feedback(feedback);\n          RCLCPP_INFO(this->get_logger(), \"Publish feedback\");\n    \n          loop_rate.sleep();\n        }\n    \n        // Check if goal is done\n        if (rclcpp::ok()) {\n          result->sequence = sequence;\n          goal_handle->succeed(result);\n          RCLCPP_INFO(this->get_logger(), \"Goal succeeded\");\n        }\n      };\n    \n\nThis work thread processes one sequence number of the Fibonacci sequence every\nsecond, publishing a feedback update for each step. When it has finished\nprocessing, it marks the ` goal_handle  ` as succeeded, and quits.\n\nWe now have a fully functioning action server. Let\u00e2\u0080\u0099s get it built and\nrunning.\n\n####  2.2 Compiling the action server  \u00ef\u0083\u0081\n\nIn the previous section we put the action server code into place. To get it to\ncompile and run, we need to do a couple of additional things.\n\nFirst we need to setup the CMakeLists.txt so that the action server is\ncompiled. Open up ` custom_action_cpp/CMakeLists.txt  ` , and add the\nfollowing right after the ` find_package  ` calls:\n\n    \n    \n    add_library(action_server SHARED\n      src/fibonacci_action_server.cpp)\n    target_include_directories(action_server PRIVATE\n      $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include>\n      $<INSTALL_INTERFACE:include>)\n    target_compile_definitions(action_server\n      PRIVATE \"CUSTOM_ACTION_CPP_BUILDING_DLL\")\n    ament_target_dependencies(action_server\n      \"custom_action_interfaces\"\n      \"rclcpp\"\n      \"rclcpp_action\"\n      \"rclcpp_components\")\n    rclcpp_components_register_node(action_server PLUGIN \"custom_action_cpp::FibonacciActionServer\" EXECUTABLE fibonacci_action_server)\n    install(TARGETS\n      action_server\n      ARCHIVE DESTINATION lib\n      LIBRARY DESTINATION lib\n      RUNTIME DESTINATION bin)\n    \n\nAnd now we can compile the package. Go to the top-level of the ` ros2_ws  ` ,\nand run:\n\n    \n    \n    colcon build\n    \n\nThis should compile the entire workspace, including the `\nfibonacci_action_server  ` in the ` custom_action_cpp  ` package.\n\n####  2.3 Running the action server  \u00ef\u0083\u0081\n\nNow that we have the action server built, we can run it. Source the workspace\nwe just built ( ` ros2_ws  ` ), and try to run the action server:\n\n    \n    \n    ros2 run custom_action_cpp fibonacci_action_server\n    \n\n###  3 Writing an action client  \u00ef\u0083\u0081\n\n####  3.1 Writing the action client code  \u00ef\u0083\u0081\n\nOpen up ` custom_action_cpp/src/fibonacci_action_client.cpp  ` , and put the\nfollowing code in:\n\n    \n    \n    #include <functional>\n    #include <future>\n    #include <memory>\n    #include <string>\n    #include <sstream>\n    \n    #include \"custom_action_interfaces/action/fibonacci.hpp\"\n    \n    #include \"rclcpp/rclcpp.hpp\"\n    #include \"rclcpp_action/rclcpp_action.hpp\"\n    #include \"rclcpp_components/register_node_macro.hpp\"\n    \n    namespace custom_action_cpp\n    {\n    class FibonacciActionClient : public rclcpp::Node\n    {\n    public:\n      using Fibonacci = custom_action_interfaces::action::Fibonacci;\n      using GoalHandleFibonacci = rclcpp_action::ClientGoalHandle<Fibonacci>;\n    \n      explicit FibonacciActionClient(const rclcpp::NodeOptions & options)\n      : Node(\"fibonacci_action_client\", options)\n      {\n        this->client_ptr_ = rclcpp_action::create_client<Fibonacci>(\n          this,\n          \"fibonacci\");\n    \n        auto timer_callback_lambda = [this](){ return this->send_goal(); };\n        this->timer_ = this->create_wall_timer(\n          std::chrono::milliseconds(500),\n          timer_callback_lambda);\n      }\n    \n      void send_goal()\n      {\n        using namespace std::placeholders;\n    \n        this->timer_->cancel();\n    \n        if (!this->client_ptr_->wait_for_action_server()) {\n          RCLCPP_ERROR(this->get_logger(), \"Action server not available after waiting\");\n          rclcpp::shutdown();\n        }\n    \n        auto goal_msg = Fibonacci::Goal();\n        goal_msg.order = 10;\n    \n        RCLCPP_INFO(this->get_logger(), \"Sending goal\");\n    \n        auto send_goal_options = rclcpp_action::Client<Fibonacci>::SendGoalOptions();\n        send_goal_options.goal_response_callback = [this](const GoalHandleFibonacci::SharedPtr & goal_handle)\n        {\n          if (!goal_handle) {\n            RCLCPP_ERROR(this->get_logger(), \"Goal was rejected by server\");\n          } else {\n            RCLCPP_INFO(this->get_logger(), \"Goal accepted by server, waiting for result\");\n          }\n        };\n    \n        send_goal_options.feedback_callback = [this](\n          GoalHandleFibonacci::SharedPtr,\n          const std::shared_ptr<const Fibonacci::Feedback> feedback)\n        {\n          std::stringstream ss;\n          ss << \"Next number in sequence received: \";\n          for (auto number : feedback->partial_sequence) {\n            ss << number << \" \";\n          }\n          RCLCPP_INFO(this->get_logger(), ss.str().c_str());\n        };\n    \n        send_goal_options.result_callback = [this](const GoalHandleFibonacci::WrappedResult & result)\n        {\n          switch (result.code) {\n            case rclcpp_action::ResultCode::SUCCEEDED:\n              break;\n            case rclcpp_action::ResultCode::ABORTED:\n              RCLCPP_ERROR(this->get_logger(), \"Goal was aborted\");\n              return;\n            case rclcpp_action::ResultCode::CANCELED:\n              RCLCPP_ERROR(this->get_logger(), \"Goal was canceled\");\n              return;\n            default:\n              RCLCPP_ERROR(this->get_logger(), \"Unknown result code\");\n              return;\n          }\n          std::stringstream ss;\n          ss << \"Result received: \";\n          for (auto number : result.result->sequence) {\n            ss << number << \" \";\n          }\n          RCLCPP_INFO(this->get_logger(), ss.str().c_str());\n          rclcpp::shutdown();\n        };\n        this->client_ptr_->async_send_goal(goal_msg, send_goal_options);\n      }\n    \n    private:\n      rclcpp_action::Client<Fibonacci>::SharedPtr client_ptr_;\n      rclcpp::TimerBase::SharedPtr timer_;\n    };  // class FibonacciActionClient\n    \n    }  // namespace custom_action_cpp\n    \n    RCLCPP_COMPONENTS_REGISTER_NODE(custom_action_cpp::FibonacciActionClient)\n    \n\nThe first few lines include all of the headers we need to compile.\n\nNext we create a class that is a derived class of ` rclcpp::Node  ` :\n\n    \n    \n    class FibonacciActionClient : public rclcpp::Node\n    \n\nThe constructor for the ` FibonacciActionClient  ` class initializes the node\nname as ` fibonacci_action_client  ` :\n\n    \n    \n      explicit FibonacciActionClient(const rclcpp::NodeOptions & options)\n      : Node(\"fibonacci_action_client\", options)\n    \n\nThe constructor also instantiates a new action client:\n\n    \n    \n        this->client_ptr_ = rclcpp_action::create_client<Fibonacci>(\n          this,\n          \"fibonacci\");\n    \n\nAn action client requires 3 things:\n\n  1. The templated action type name: ` Fibonacci  ` . \n\n  2. A ROS 2 node to add the action client to: ` this  ` . \n\n  3. The action name: ` 'fibonacci'  ` . \n\nWe also instantiate a ROS timer that will kick off the one and only call to `\nsend_goal  ` :\n\n    \n    \n        auto timer_callback_lambda = [this](){ return this->send_goal(); };\n        this->timer_ = this->create_wall_timer(\n          std::chrono::milliseconds(500),\n          timer_callback_lambda);\n    \n\nWhen the timer expires, it will call ` send_goal  ` :\n\n    \n    \n      void send_goal()\n      {\n        using namespace std::placeholders;\n    \n        this->timer_->cancel();\n    \n        if (!this->client_ptr_->wait_for_action_server()) {\n          RCLCPP_ERROR(this->get_logger(), \"Action server not available after waiting\");\n          rclcpp::shutdown();\n        }\n    \n        auto goal_msg = Fibonacci::Goal();\n        goal_msg.order = 10;\n    \n        RCLCPP_INFO(this->get_logger(), \"Sending goal\");\n    \n        auto send_goal_options = rclcpp_action::Client<Fibonacci>::SendGoalOptions();\n        send_goal_options.goal_response_callback = [this](const GoalHandleFibonacci::SharedPtr & goal_handle)\n        {\n          if (!goal_handle) {\n            RCLCPP_ERROR(this->get_logger(), \"Goal was rejected by server\");\n          } else {\n            RCLCPP_INFO(this->get_logger(), \"Goal accepted by server, waiting for result\");\n          }\n        };\n    \n        send_goal_options.feedback_callback = [this](\n          GoalHandleFibonacci::SharedPtr,\n          const std::shared_ptr<const Fibonacci::Feedback> feedback)\n        {\n          std::stringstream ss;\n          ss << \"Next number in sequence received: \";\n          for (auto number : feedback->partial_sequence) {\n            ss << number << \" \";\n          }\n          RCLCPP_INFO(this->get_logger(), ss.str().c_str());\n        };\n    \n        send_goal_options.result_callback = [this](const GoalHandleFibonacci::WrappedResult & result)\n        {\n          switch (result.code) {\n            case rclcpp_action::ResultCode::SUCCEEDED:\n              break;\n            case rclcpp_action::ResultCode::ABORTED:\n              RCLCPP_ERROR(this->get_logger(), \"Goal was aborted\");\n              return;\n            case rclcpp_action::ResultCode::CANCELED:\n              RCLCPP_ERROR(this->get_logger(), \"Goal was canceled\");\n              return;\n            default:\n              RCLCPP_ERROR(this->get_logger(), \"Unknown result code\");\n              return;\n          }\n          std::stringstream ss;\n          ss << \"Result received: \";\n          for (auto number : result.result->sequence) {\n            ss << number << \" \";\n          }\n          RCLCPP_INFO(this->get_logger(), ss.str().c_str());\n          rclcpp::shutdown();\n        };\n        this->client_ptr_->async_send_goal(goal_msg, send_goal_options);\n      }\n    \n\nThis function does the following:\n\n  1. Cancels the timer (so it is only called once). \n\n  2. Waits for the action server to come up. \n\n  3. Instantiates a new ` Fibonacci::Goal  ` . \n\n  4. Sets the response, feedback, and result callbacks. \n\n  5. Sends the goal to the server. \n\nWhen the server receives and accepts the goal, it will send a response to the\nclient. That response is handled by ` goal_response_callback  ` :\n\n    \n    \n        send_goal_options.goal_response_callback = [this](const GoalHandleFibonacci::SharedPtr & goal_handle)\n        {\n          if (!goal_handle) {\n            RCLCPP_ERROR(this->get_logger(), \"Goal was rejected by server\");\n          } else {\n            RCLCPP_INFO(this->get_logger(), \"Goal accepted by server, waiting for result\");\n          }\n        };\n    \n\nAssuming the goal was accepted by the server, it will start processing. Any\nfeedback to the client will be handled by the ` feedback_callback  ` :\n\n    \n    \n        send_goal_options.feedback_callback = [this](\n          GoalHandleFibonacci::SharedPtr,\n          const std::shared_ptr<const Fibonacci::Feedback> feedback)\n        {\n          std::stringstream ss;\n          ss << \"Next number in sequence received: \";\n          for (auto number : feedback->partial_sequence) {\n            ss << number << \" \";\n          }\n          RCLCPP_INFO(this->get_logger(), ss.str().c_str());\n        };\n    \n\nWhen the server is finished processing, it will return a result to the client.\nThe result is handled by the ` result_callback  ` :\n\n    \n    \n        send_goal_options.result_callback = [this](const GoalHandleFibonacci::WrappedResult & result)\n        {\n          switch (result.code) {\n            case rclcpp_action::ResultCode::SUCCEEDED:\n              break;\n            case rclcpp_action::ResultCode::ABORTED:\n              RCLCPP_ERROR(this->get_logger(), \"Goal was aborted\");\n              return;\n            case rclcpp_action::ResultCode::CANCELED:\n              RCLCPP_ERROR(this->get_logger(), \"Goal was canceled\");\n              return;\n            default:\n              RCLCPP_ERROR(this->get_logger(), \"Unknown result code\");\n              return;\n          }\n          std::stringstream ss;\n          ss << \"Result received: \";\n          for (auto number : result.result->sequence) {\n            ss << number << \" \";\n          }\n          RCLCPP_INFO(this->get_logger(), ss.str().c_str());\n          rclcpp::shutdown();\n        };\n    \n\nWe now have a fully functioning action client. Let\u00e2\u0080\u0099s get it built and\nrunning.\n\n####  3.2 Compiling the action client  \u00ef\u0083\u0081\n\nIn the previous section we put the action client code into place. To get it to\ncompile and run, we need to do a couple of additional things.\n\nFirst we need to setup the CMakeLists.txt so that the action client is\ncompiled. Open up ` custom_action_cpp/CMakeLists.txt  ` , and add the\nfollowing right after the ` find_package  ` calls:\n\n    \n    \n    add_library(action_client SHARED\n      src/fibonacci_action_client.cpp)\n    target_include_directories(action_client PRIVATE\n      $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include>\n      $<INSTALL_INTERFACE:include>)\n    target_compile_definitions(action_client\n      PRIVATE \"CUSTOM_ACTION_CPP_BUILDING_DLL\")\n    ament_target_dependencies(action_client\n      \"custom_action_interfaces\"\n      \"rclcpp\"\n      \"rclcpp_action\"\n      \"rclcpp_components\")\n    rclcpp_components_register_node(action_client PLUGIN \"custom_action_cpp::FibonacciActionClient\" EXECUTABLE fibonacci_action_client)\n    install(TARGETS\n      action_client\n      ARCHIVE DESTINATION lib\n      LIBRARY DESTINATION lib\n      RUNTIME DESTINATION bin)\n    \n\nAnd now we can compile the package. Go to the top-level of the ` ros2_ws  ` ,\nand run:\n\n    \n    \n    colcon build\n    \n\nThis should compile the entire workspace, including the `\nfibonacci_action_client  ` in the ` custom_action_cpp  ` package.\n\n####  3.3 Running the action client  \u00ef\u0083\u0081\n\nNow that we have the action client built, we can run it. First make sure that\nan action server is running in a separate terminal. Now source the workspace\nwe just built ( ` ros2_ws  ` ), and try to run the action client:\n\n    \n    \n    ros2 run custom_action_cpp fibonacci_action_client\n    \n\nYou should see logged messages for the goal being accepted, feedback being\nprinted, and the final result.\n\n##  Summary  \u00ef\u0083\u0081\n\nIn this tutorial, you put together a C++ action server and action client line\nby line, and configured them to exchange goals, feedback, and results.\n\n##  Related content  \u00ef\u0083\u0081\n\n  * There are several ways you could write an action server and client in C++; check out the ` minimal_action_server  ` and ` minimal_action_client  ` packages in the [ ros2/examples ](https://github.com/ros2/examples/tree/rolling/rclcpp) repo. \n\n  * For more detailed information about ROS actions, please refer to the [ design article ](http://design.ros2.org/articles/actions.html) . \n\n[ Previous ](../Creating-an-Action.html \"Creating an action\") [ Next\n](Py.html \"Writing an action server and client \\(Python\\)\")\n\n* * *\n\n\u00a9 Copyright 2024, Open Robotics.\n\nBuilt with [ Sphinx ](https://www.sphinx-doc.org/) using a [ theme\n](https://github.com/readthedocs/sphinx_rtd_theme) provided by [ Read the Docs\n](https://readthedocs.org) .\n\nOther Versions  v: rolling\n\nReleases\n\n     [ Iron (latest) ](../../../../iron/Tutorials/Intermediate/Writing-an-Action-Server-Client/Cpp.html)\n     [ Humble ](../../../../humble/Tutorials/Intermediate/Writing-an-Action-Server-Client/Cpp.html)\n     [ Galactic (EOL) ](../../../../galactic/Tutorials/Intermediate/Writing-an-Action-Server-Client/Cpp.html)\n     [ Foxy (EOL) ](../../../../foxy/Tutorials/Intermediate/Writing-an-Action-Server-Client/Cpp.html)\n     [ Eloquent (EOL) ](../../../../eloquent/index.html)\n     [ Dashing (EOL) ](../../../../dashing/index.html)\n     [ Crystal (EOL) ](../../../../crystal/index.html)\n\nIn Development\n\n     [ Rolling ](Cpp.html)\n\n"
  },
  {
    "id": "roslib_message/roscontrollers1.txt",
    "content": "Skip to content\n\nToggle navigation\n\n[ ](https://github.com/)\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fros-\ncontrols%2Fros_controllers)\n\n  * Product \n\n    * [ Actions  Automate any workflow  ](/features/actions)\n    * [ Packages  Host and manage packages  ](/features/packages)\n    * [ Security  Find and fix vulnerabilities  ](/features/security)\n    * [ Codespaces  Instant dev environments  ](/features/codespaces)\n    * [ Copilot  Write better code with AI  ](/features/copilot)\n    * [ Code review  Manage code changes  ](/features/code-review)\n    * [ Issues  Plan and track work  ](/features/issues)\n    * [ Discussions  Collaborate outside of code  ](/features/discussions)\n\nExplore\n\n    * [ All features ](/features)\n    * [ Documentation  ](https://docs.github.com)\n    * [ GitHub Skills  ](https://skills.github.com/)\n    * [ Blog  ](https://github.blog)\n\n  * Solutions \n\nFor\n\n    * [ Enterprise ](/enterprise)\n    * [ Teams ](/team)\n    * [ Startups ](/enterprise/startups)\n    * [ Education  ](https://education.github.com)\n\nBy Solution\n\n    * [ CI/CD & Automation ](/solutions/ci-cd/)\n    * [ DevOps ](/solutions/devops/)\n    * [ DevSecOps  ](https://resources.github.com/devops/fundamentals/devsecops/)\n\nResources\n\n    * [ Learning Pathways  ](https://resources.github.com/learn/pathways/)\n    * [ White papers, Ebooks, Webinars  ](https://resources.github.com/)\n    * [ Customer Stories ](/customer-stories)\n    * [ Partners  ](https://partner.github.com/)\n\n  * Open Source \n\n    * [ GitHub Sponsors  Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project  GitHub community articles  ](/readme)\n\nRepositories\n\n    * [ Topics ](/topics)\n    * [ Trending ](/trending)\n    * [ Collections ](/collections)\n\n  * [ Pricing ](/pricing)\n\nSearch or jump to...\n\n#  Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[ Search syntax tips ](https://docs.github.com/search-github/github-code-\nsearch/understanding-github-code-search-syntax)\n\n#  Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n##  Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [ documentation\n](https://docs.github.com/search-github/github-code-search/understanding-\ngithub-code-search-syntax) .\n\nCancel  Create saved search\n\n[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fros-\ncontrols%2Fros_controllers)\n\n[ Sign up\n](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-\nname%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=ros-\ncontrols%2Fros_controllers)\n\nYou signed in with another tab or window. [ Reload ]() to refresh your\nsession.  You signed out in another tab or window. [ Reload ]() to refresh\nyour session.  You switched accounts on another tab or window. [ Reload ]() to\nrefresh your session.  Dismiss alert\n\n{{ message }}\n\n[ ros-controls ](/ros-controls) /  **[ ros_controllers ](/ros-\ncontrols/ros_controllers) ** Public\n\n  * [ Notifications ](/login?return_to=%2Fros-controls%2Fros_controllers)\n  * [ Fork  522  ](/login?return_to=%2Fros-controls%2Fros_controllers)\n  * [ Star  532  ](/login?return_to=%2Fros-controls%2Fros_controllers)\n\n  * \n\nGeneric robotic controllers to accompany ros_control\n\n[ wiki.ros.org/ros_control ](http://wiki.ros.org/ros_control\n\"http://wiki.ros.org/ros_control\")\n\n###  License\n\n[ BSD-3-Clause license ](/ros-controls/ros_controllers/blob/noetic-\ndevel/LICENSE)\n\n[ 532  stars ](/ros-controls/ros_controllers/stargazers) [ 522  forks ](/ros-\ncontrols/ros_controllers/forks) [ Branches  ](/ros-\ncontrols/ros_controllers/branches) [ Tags  ](/ros-\ncontrols/ros_controllers/tags) [ Activity  ](/ros-\ncontrols/ros_controllers/activity)\n\n[ Star  ](/login?return_to=%2Fros-controls%2Fros_controllers)\n\n[ Notifications ](/login?return_to=%2Fros-controls%2Fros_controllers)\n\n  * [ Code  ](/ros-controls/ros_controllers)\n  * [ Issues  97  ](/ros-controls/ros_controllers/issues)\n  * [ Pull requests  26  ](/ros-controls/ros_controllers/pulls)\n  * [ Actions  ](/ros-controls/ros_controllers/actions)\n  * [ Projects  0  ](/ros-controls/ros_controllers/projects)\n  * [ Wiki  ](/ros-controls/ros_controllers/wiki)\n  * [ Security  ](/ros-controls/ros_controllers/security)\n  * [ Insights  ](/ros-controls/ros_controllers/pulse)\n\nAdditional navigation options\n\n  * [ Code  ](/ros-controls/ros_controllers)\n  * [ Issues  ](/ros-controls/ros_controllers/issues)\n  * [ Pull requests  ](/ros-controls/ros_controllers/pulls)\n  * [ Actions  ](/ros-controls/ros_controllers/actions)\n  * [ Projects  ](/ros-controls/ros_controllers/projects)\n  * [ Wiki  ](/ros-controls/ros_controllers/wiki)\n  * [ Security  ](/ros-controls/ros_controllers/security)\n  * [ Insights  ](/ros-controls/ros_controllers/pulse)\n\n#  ros-controls/ros_controllers\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\nnoetic-devel\n\n[ Branches  ](/ros-controls/ros_controllers/branches) [ Tags  ](/ros-\ncontrols/ros_controllers/tags)\n\n[ ](/ros-controls/ros_controllers/branches) [ ](/ros-\ncontrols/ros_controllers/tags)\n\nGo to file\n\nCode\n\n##  Folders and files\n\nName  |  Name  |\n\nLast commit message\n\n|\n\nLast commit date  \n  \n---|---|---|---  \n  \n##  Latest commit\n\n##  History\n\n[ 954 Commits  ](/ros-controls/ros_controllers/commits/noetic-devel/)\n\n[ ](/ros-controls/ros_controllers/commits/noetic-devel/)  \n  \n###\n\n[ .github/  workflows  ](/ros-controls/ros_controllers/tree/noetic-\ndevel/.github/workflows \"This path skips through empty directories\")\n\n|\n\n###\n\n[ .github/  workflows  ](/ros-controls/ros_controllers/tree/noetic-\ndevel/.github/workflows \"This path skips through empty directories\")\n\n|\n\n|  \n  \n###\n\n[ ackermann_steering_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/ackermann_steering_controller \"ackermann_steering_controller\")\n\n|\n\n###\n\n[ ackermann_steering_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/ackermann_steering_controller \"ackermann_steering_controller\")\n\n|\n\n|  \n  \n###\n\n[ diff_drive_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/diff_drive_controller \"diff_drive_controller\")\n\n|\n\n###\n\n[ diff_drive_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/diff_drive_controller \"diff_drive_controller\")\n\n|\n\n|  \n  \n###\n\n[ effort_controllers ](/ros-controls/ros_controllers/tree/noetic-\ndevel/effort_controllers \"effort_controllers\")\n\n|\n\n###\n\n[ effort_controllers ](/ros-controls/ros_controllers/tree/noetic-\ndevel/effort_controllers \"effort_controllers\")\n\n|\n\n|  \n  \n###\n\n[ force_torque_sensor_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/force_torque_sensor_controller \"force_torque_sensor_controller\")\n\n|\n\n###\n\n[ force_torque_sensor_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/force_torque_sensor_controller \"force_torque_sensor_controller\")\n\n|\n\n|  \n  \n###\n\n[ forward_command_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/forward_command_controller \"forward_command_controller\")\n\n|\n\n###\n\n[ forward_command_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/forward_command_controller \"forward_command_controller\")\n\n|\n\n|  \n  \n###\n\n[ four_wheel_steering_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/four_wheel_steering_controller \"four_wheel_steering_controller\")\n\n|\n\n###\n\n[ four_wheel_steering_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/four_wheel_steering_controller \"four_wheel_steering_controller\")\n\n|\n\n|  \n  \n###\n\n[ gripper_action_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/gripper_action_controller \"gripper_action_controller\")\n\n|\n\n###\n\n[ gripper_action_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/gripper_action_controller \"gripper_action_controller\")\n\n|\n\n|  \n  \n###\n\n[ imu_sensor_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/imu_sensor_controller \"imu_sensor_controller\")\n\n|\n\n###\n\n[ imu_sensor_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/imu_sensor_controller \"imu_sensor_controller\")\n\n|\n\n|  \n  \n###\n\n[ joint_state_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/joint_state_controller \"joint_state_controller\")\n\n|\n\n###\n\n[ joint_state_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/joint_state_controller \"joint_state_controller\")\n\n|\n\n|  \n  \n###\n\n[ joint_trajectory_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/joint_trajectory_controller \"joint_trajectory_controller\")\n\n|\n\n###\n\n[ joint_trajectory_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/joint_trajectory_controller \"joint_trajectory_controller\")\n\n|\n\n|  \n  \n###\n\n[ position_controllers ](/ros-controls/ros_controllers/tree/noetic-\ndevel/position_controllers \"position_controllers\")\n\n|\n\n###\n\n[ position_controllers ](/ros-controls/ros_controllers/tree/noetic-\ndevel/position_controllers \"position_controllers\")\n\n|\n\n|  \n  \n###\n\n[ ros_controllers ](/ros-controls/ros_controllers/tree/noetic-\ndevel/ros_controllers \"ros_controllers\")\n\n|\n\n###\n\n[ ros_controllers ](/ros-controls/ros_controllers/tree/noetic-\ndevel/ros_controllers \"ros_controllers\")\n\n|\n\n|  \n  \n###\n\n[ rqt_joint_trajectory_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/rqt_joint_trajectory_controller \"rqt_joint_trajectory_controller\")\n\n|\n\n###\n\n[ rqt_joint_trajectory_controller ](/ros-controls/ros_controllers/tree/noetic-\ndevel/rqt_joint_trajectory_controller \"rqt_joint_trajectory_controller\")\n\n|\n\n|  \n  \n###\n\n[ velocity_controllers ](/ros-controls/ros_controllers/tree/noetic-\ndevel/velocity_controllers \"velocity_controllers\")\n\n|\n\n###\n\n[ velocity_controllers ](/ros-controls/ros_controllers/tree/noetic-\ndevel/velocity_controllers \"velocity_controllers\")\n\n|\n\n|  \n  \n###\n\n[ .clang-format ](/ros-controls/ros_controllers/blob/noetic-devel/.clang-\nformat \".clang-format\")\n\n|\n\n###\n\n[ .clang-format ](/ros-controls/ros_controllers/blob/noetic-devel/.clang-\nformat \".clang-format\")\n\n|\n\n|  \n  \n###\n\n[ .gitignore ](/ros-controls/ros_controllers/blob/noetic-devel/.gitignore\n\".gitignore\")\n\n|\n\n###\n\n[ .gitignore ](/ros-controls/ros_controllers/blob/noetic-devel/.gitignore\n\".gitignore\")\n\n|\n\n|  \n  \n###\n\n[ LICENSE ](/ros-controls/ros_controllers/blob/noetic-devel/LICENSE \"LICENSE\")\n\n|\n\n###\n\n[ LICENSE ](/ros-controls/ros_controllers/blob/noetic-devel/LICENSE \"LICENSE\")\n\n|\n\n|  \n  \n###\n\n[ README.md ](/ros-controls/ros_controllers/blob/noetic-devel/README.md\n\"README.md\")\n\n|\n\n###\n\n[ README.md ](/ros-controls/ros_controllers/blob/noetic-devel/README.md\n\"README.md\")\n\n|\n\n|  \n  \nView all files  \n  \n##  Repository files navigation\n\n  * README \n  * BSD-3-Clause license \n\n#  ros_controllers\n\nSee [ ros_control ](http://wiki.ros.org/ros_control) and [ ros_controllers\n](http://wiki.ros.org/ros_controllers) documentation on ros.org\n\n###  Build Status\n\nIndigo  |  Kinetic  |  Lunar  |  Melodic  |  Noetic  \n---|---|---|---|---  \n[ ![Build\nStatus](https://camo.githubusercontent.com/288c12c167a882842c5c78e289f2d01cea6c21b3e4926ed31137092cbb97239c/68747470733a2f2f7472617669732d63692e6f72672f726f732d636f6e74726f6c732f726f735f636f6e74726f6c6c6572732e706e673f6272616e63683d696e6469676f2d646576656c)\n](https://travis-ci.org/ros-controls/ros_controllers) |  [ ![Build\nStatus](https://camo.githubusercontent.com/aa6d3d87c7e43ec9e747187752a7ba3250f432540b5c5adaf8545592543d825e/68747470733a2f2f7472617669732d63692e6f72672f726f732d636f6e74726f6c732f726f735f636f6e74726f6c6c6572732e706e673f6272616e63683d6b696e657469632d646576656c)\n](https://travis-ci.org/ros-controls/ros_controllers) |  [ ![Build\nStatus](https://camo.githubusercontent.com/aa6d3d87c7e43ec9e747187752a7ba3250f432540b5c5adaf8545592543d825e/68747470733a2f2f7472617669732d63692e6f72672f726f732d636f6e74726f6c732f726f735f636f6e74726f6c6c6572732e706e673f6272616e63683d6b696e657469632d646576656c)\n](https://travis-ci.org/ros-controls/ros_controllers) |  [ ![Build\nStatus](https://camo.githubusercontent.com/eca27c6f58278efa76276fde346f041ccde83f4eb631ef15ac66201b62bfe741/68747470733a2f2f7472617669732d63692e6f72672f726f732d636f6e74726f6c732f726f735f636f6e74726f6c6c6572732e706e673f6272616e63683d6d656c6f6469632d646576656c)\n](https://travis-ci.org/ros-controls/ros_controllers) |  [ ![Build\nStatus](https://camo.githubusercontent.com/25e8514fd8d4c412384b20b1b7eb42fa25b49684227a06d0801c383d3f61efd0/68747470733a2f2f7472617669732d63692e6f72672f726f732d636f6e74726f6c732f726f735f636f6e74726f6c6c6572732e706e673f6272616e63683d6e6f657469632d646576656c)\n](https://travis-ci.org/ros-controls/ros_controllers)  \n  \n###  Branches for source-based installation\n\nROS Indigo  |  ROS Kinetic  |  ROS Lunar  |  ROS Melodic  \n---|---|---|---  \nindigo-devel  |  kinetic-devel  |  kinetic-devel  |  melodic-devel  \n  \n##  Publication\n\nIf you find this work useful please give credits to the authors by citing:\n\n  * S. Chitta, E. Marder-Eppstein, W. Meeussen, V. Pradeep, A. Rodr\u00edguez Tsouroukdissian, J. Bohren, D. Coleman, B. Magyar, G. Raiola, M. L\u00fcdtke and E. Fernandez Perdomo **\"ros_control: A generic and simple control framework for ROS\"** , The Journal of Open Source Software, 2017. ( [ PDF ](http://www.theoj.org/joss-papers/joss.00456/10.21105.joss.00456.pdf) ) \n\n    \n    \n    @article{ros_control,\n    author = {Chitta, Sachin and Marder-Eppstein, Eitan and Meeussen, Wim and Pradeep, Vijay and Rodr{\\'i}guez Tsouroukdissian, Adolfo  and Bohren, Jonathan and Coleman, David and Magyar, Bence and Raiola, Gennaro and L{\\\"u}dtke, Mathias and Fern{\\'a}ndez Perdomo, Enrique},\n    title = {ros\\_control: A generic and simple control framework for ROS},\n    journal = {The Journal of Open Source Software},\n    year = {2017},\n    doi = {10.21105/joss.00456},\n    URL = {http://www.theoj.org/joss-papers/joss.00456/10.21105.joss.00456.pdf}\n    }\n    \n\n##  About\n\nGeneric robotic controllers to accompany ros_control\n\n[ wiki.ros.org/ros_control ](http://wiki.ros.org/ros_control\n\"http://wiki.ros.org/ros_control\")\n\n###  Resources\n\nReadme\n\n###  License\n\nBSD-3-Clause license\n\n[ Activity  ](/ros-controls/ros_controllers/activity)\n\n[ Custom properties  ](/ros-controls/ros_controllers/custom-properties)\n\n###  Stars\n\n[ **532** stars ](/ros-controls/ros_controllers/stargazers)\n\n###  Watchers\n\n[ **43** watching ](/ros-controls/ros_controllers/watchers)\n\n###  Forks\n\n[ **522** forks ](/ros-controls/ros_controllers/forks)\n\n[ Report repository ](/contact/report-\ncontent?content_url=https%3A%2F%2Fgithub.com%2Fros-\ncontrols%2Fros_controllers&report=ros-controls+%28user%29)\n\n##  [ Releases ](/ros-controls/ros_controllers/releases)\n\n[ 55  tags  ](/ros-controls/ros_controllers/tags)\n\n##  [ Packages  0  ](/orgs/ros-controls/packages?repo_name=ros_controllers)\n\nNo packages published  \n\n##  [ Contributors  78  ](/ros-controls/ros_controllers/graphs/contributors)\n\n  *   *   *   *   *   *   *   *   *   *   *   *   *   * \n\n[ \\+ 64 contributors ](/ros-controls/ros_controllers/graphs/contributors)\n\n##  Languages\n\n  * [ C++  91.2%  ](/ros-controls/ros_controllers/search?l=c%2B%2B)\n  * [ CMake  3.5%  ](/ros-controls/ros_controllers/search?l=cmake)\n  * [ Python  3.3%  ](/ros-controls/ros_controllers/search?l=python)\n  * [ Objective-C  2.0%  ](/ros-controls/ros_controllers/search?l=objective-c)\n\n##  Footer\n\n[ ](https://github.com \"GitHub\") \u00a9 2024 GitHub, Inc.\n\n###  Footer navigation\n\n  * [ Terms ](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [ Privacy ](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [ Security ](/security)\n  * [ Status ](https://www.githubstatus.com/)\n  * [ Docs ](https://docs.github.com/)\n  * [ Contact ](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.\n\n"
  },
  {
    "id": "crazyswarm/latest.txt",
    "content": "Crazyswarm\n\nlatest\n\n  * [ Changelog ](changelog.html)\n  * [ Getting Started ](gettingstarted.html)\n  * [ Installation ](installation.html)\n  * [ Overview ](overview.html)\n  * [ Configuration ](configuration.html)\n  * [ Tutorials ](tutorials/tutorials.html)\n  * [ How-To Guides ](howto/howto.html)\n  * [ Python API Reference ](api.html)\n  * [ Crazyswarm Internals ](internals.html)\n  * [ Hardware ](hardware.html)\n  * [ Glossary ](glossary.html)\n\n__ Crazyswarm\n\n  * Docs  \u00bb \n  * Welcome to Crazyswarm\u00e2\u0080\u0099s documentation! \n  * [ Edit on GitHub ](https://github.com/USC-ACTLab/crazyswarm/blob/master/docs/index.rst)\n\n* * *\n\n#  Welcome to Crazyswarm\u00e2\u0080\u0099s documentation!  \u00c2\u00b6\n\nWarning\n\nCrazyswarm1 is not recommended for new projects and has no/minimal\nmaintainance. Please use [ Crazyswarm2\n](https://imrclab.github.io/crazyswarm2/) instead.\n\nThe Crazyswarm platform allows you to fly a swarm of [ Bitcraze Crazyflie 2.x\n](https://www.bitcraze.io/products/crazyflie-2-1/) and [ Bitcraze Crazyflie\nBolt-based ](https://store.bitcraze.io/products/crazyflie-bolt) quadcopters in\ntight, synchronized formations. Different localization systems are supported:\nLightHouse, LPS, and motion capture. The Crazyswarm is particularly optimized\nfor motion capture systems and supports VICON, NOKOV, OptiTrack, and Qualisys.\nWe successfully flew 49 Crazyflies using three Crazyradios. An example video\nfor what you can do is shown below:\n\n##  How is Crazyswarm different from Bitcraze\u00e2\u0080\u0099s [ Crazyflie Python API\n](https://github.com/bitcraze/crazyflie-lib-python) ?  \u00c2\u00b6\n\nBoth can be used to control several Crazyflies from a Python script. Here are\nsome differences:\n\n  * **Motion capture integration.** Crazyswarm contains drivers for common motion capture systems. The Bitcraze API can _send_ position measurements to the Crazyflie, but does not know how to _get_ position measurements from mocap hardware. \n\n  * **Identical or single motion capture markers.** Via [ libobjecttracker ](https://github.com/USC-ACTLab/libobjecttracker) , Crazyswarm can track multiple quadrotors with identical motion capture marker arrangements, or quadrotors with only one marker each. Most motion capture devices do not support this natively. To make it possible, the user must supply the quadrotors\u00e2\u0080\u0099 initial positions in a configuration file at startup to establish the mapping from radio addresses to positions. \n\n  * **Broadcasts.** Crazyswarm uses broadcast communication whenever possible to require fewer radios per Crazyflie. In contrast, the official SDK uses unicast communication instead. \n\n  * **Simulation.** Crazyswarm has a simulation mode with 3D graphics, which makes it easy to validate complex scripts before running them on real hardware. \n\n  * **Python firmware bindings.** Crazyswarm\u00e2\u0080\u0099s simulator is built upon automatically generated Python bindings for certain modules in the Crazyflie firmware. The binding system can be helpful when developing new firmware modules, especially when they are mathematically complex and hard to debug. \n\n  * **ROS foundation.** The Crazyswarm server program is a ROS node. The [ Python API Reference  ](api.html#api) is a thin wrapper around the ROS interface. While we recommend the Python API for most applications, the ROS interface is fully supported. \n\n##  Crazyswarm\u00e2\u0080\u0099s academic origins  \u00c2\u00b6\n\nThe Crazyswarm architecture, including some motivation for the design\ndecisions, is described in [ our paper ](http://usc-\nactlab.github.io/publications/Preiss_ICRA2017.pdf) [pdf].\n\nA talk at the [ BAM days 2021 ](https://www.bitcraze.io/about/events/bam2021/)\nincludes a primer on how to use the Crazyswarm and a bibliography of papers\nusing the Crazyswarm: [ Slides\n](https://www.bitcraze.io/about/events/documents/bam2021/hoenig_crazyswarm_bam2021.pdf)\n[pdf], [ Video ](https://youtu.be/9KlfFpv6NIQ) [youtube].\n\nIf you use our work in academic research, please cite us:\n\n    \n    \n    @inproceedings{crazyswarm,\n      author    = {James A. Preiss* and\n                   Wolfgang  H\\\"onig* and\n                   Gaurav S. Sukhatme and\n                   Nora Ayanian},\n      title     = {Crazyswarm: {A} large nano-quadcopter swarm},\n      booktitle = {{IEEE} International Conference on Robotics and Automation ({ICRA})},\n      pages     = {3299--3304},\n      publisher = {{IEEE}},\n      year      = {2017},\n      url       = {https://doi.org/10.1109/ICRA.2017.7989376},\n      doi       = {10.1109/ICRA.2017.7989376},\n      note      = {Software available at \\url{https://github.com/USC-ACTLab/crazyswarm}},\n    }\n    \n\nOur contributed code is licensed under the permissive MIT license, however\nsome of the parts (such as the firmware) are licensed under their respective\nlicense.\n\n##  Contents  \u00c2\u00b6\n\n  * [ Changelog ](changelog.html)\n    * [ October 4th, 2019 ](changelog.html#october-4th-2019)\n    * [ April 22nd, 2018 ](changelog.html#april-22nd-2018)\n    * [ March 2nd, 2018 ](changelog.html#march-2nd-2018)\n  * [ Getting Started ](gettingstarted.html)\n  * [ Installation ](installation.html)\n  * [ Overview ](overview.html)\n    * [ More Information ](overview.html#more-information)\n  * [ Configuration ](configuration.html)\n    * [ Set up radio communication ](configuration.html#set-up-radio-communication)\n    * [ Update firmware ](configuration.html#update-firmware)\n    * [ Adjust configuration files ](configuration.html#adjust-configuration-files)\n    * [ Manage fleet with the Chooser ](configuration.html#manage-fleet-with-the-chooser)\n    * [ Testing configuration ](configuration.html#testing-configuration)\n  * [ Tutorials ](tutorials/tutorials.html)\n    * [ Hovering (hello, world) ](tutorials/tutorials.html#hovering-hello-world)\n  * [ How-To Guides ](howto/howto.html)\n    * [ Crazyswarm Integration with Git ](howto/howto.html#crazyswarm-integration-with-git)\n    * [ Creating a new streaming setpoint mode ](howto/howto.html#creating-a-new-streaming-setpoint-mode)\n  * [ Python API Reference ](api.html)\n    * [ ` Crazyflie  ` class ](api.html#crazyflie-class)\n    * [ ` CrazyflieServer  ` class ](api.html#crazyflieserver-class)\n    * [ ` TimeHelper  ` class ](api.html#timehelper-class)\n    * [ Switching between simulation and real hardware ](api.html#switching-between-simulation-and-real-hardware)\n  * [ Crazyswarm Internals ](internals.html)\n    * [ Firmware bindings ](internals.html#firmware-bindings)\n  * [ Hardware ](hardware.html)\n    * [ Components ](hardware.html#components)\n    * [ Medium Quadrotor ](hardware.html#medium-quadrotor)\n    * [ Large Quadrotor ](hardware.html#large-quadrotor)\n  * [ Glossary ](glossary.html)\n\n##  Indices and tables  \u00c2\u00b6\n\n  * [ Index  ](genindex.html)\n\n  * [ Module Index  ](py-modindex.html)\n\n  * [ Search Page  ](search.html)\n\n[ Next  ](changelog.html \"Changelog\")\n\n* * *\n\n\u00a9 Copyright 2018-2021, Wolfgang Hoenig, James A. Preiss, and contributors.\nRevision ` beb05492 ` .\n\nBuilt with [ Sphinx ](http://sphinx-doc.org/) using a [ theme\n](https://github.com/rtfd/sphinx_rtd_theme) provided by [ Read the Docs\n](https://readthedocs.org) .\n\nRead the Docs  v: latest\n\nVersions\n\n     [ latest ](/en/latest/)\n\nDownloads\n\nOn Read the Docs\n\n     [ Project Home ](//readthedocs.org/projects/crazyswarm/?fromdocs=crazyswarm)\n     [ Builds ](//readthedocs.org/builds/crazyswarm/?fromdocs=crazyswarm)\n\n* * *\n\nFree document hosting provided by [ Read the Docs\n](http://www.readthedocs.org) .\n\n"
  },
  {
    "id": "ros_regular/buildingaros2control.txt",
    "content": "[ ![logo](/img/Logo_light.svg) ](/)\n\nMenu\n\nSearch for content\n\n` ` Ctrl ` ` K ` `\n\n[ Home  ](/) [ Tags  ](/tags)\n\nFeatured Spaces\n\n[ Cost Optimization  ](/cost-optimization)\n\n[ DevOps  ](/devops)\n\n[ Generative AI  ](/generative-ai)\n\n[ Kubernetes  ](/kubernetes)\n\n[ Livestreams  ](/livestreams)\n\n[ Resilience  ](/resilience)\n\n[ Training and Certification  ](/training)\n\nCommunity Programs\n\n[ AWS Heroes  ](https://aws.amazon.com/developer/community/heroes/?community-\nheroes-all.sort-by=item\\[\u2026\\]location=*all&awsf.filter-year=*all&awsf.filter-\nactivity=*all)\n\n[ AWS Community Builders\n](https://aws.amazon.com/developer/community/community-builders/?intClick=dev-\ncenter-2021_main)\n\n[ AWS User Groups\n](https://aws.amazon.com/developer/community/usergroups/?intClick=dev-\ncenter-2021_main)\n\n[ Student Communities  ](/students)\n\n* * *\n\n[ ](https://twitter.com/awsdevelopers)\n\n[ ](https://www.linkedin.com/showcase/aws-developers/)\n\n[ ](https://www.youtube.com/channel/UCT-nPlVzJI-ccQXlxjSvJmw)\n\n[ ](https://stackoverflow.com/collectives/aws)\n\n[ ](https://www.instagram.com/awsdevelopers/)\n\n###\n\n##  Site Terms, Privacy, and more.\n\n#  Building a ros2_control System: ROS2 Control with the JetBot Part 2\n\n##  See how to build a ros2_control System with the Motor and I2CDevice\nclasses from the previous post, and how to integrate this System with a\nDifferential Drive Controller from ROS2.\n\n[ robotics ](/tags/robotics)\n\n[ ML  ](/@mikelikesrobots)\n\n[ Mike Likes Robots ](/@mikelikesrobots)\n\nPublished  Mar 18, 2024\n\nThis is the second part of the \"ROS2 Control with the JetBot\" series, where I\nshow you how to get a JetBot working with ROS2 Control! This is a sequel to\nthe [ part 1 blog post ](http://localhost:3000/blog/jetbot-motors-pt2) , where\nI showed how to drive the JetBot's motors using I2C and PWM with code written\nin C++.\n\nIn this post, I show the next step in making ROS2 Control work with the\nWaveShare JetBot - wrapping the motor control code in a System. I'll walk\nthrough some concepts, show the example repository for ROS2 Control\nimplementations, and then show how to implement the System for JetBot and see\nit running.\n\nThis post is also available in video form - check the video link below if you\nwant to follow along!\n\n##\n\nROS2 Control Concepts\n\nFirst, before talking about any of these concepts, there's an important\ndistinction to make: [ ROS Control ](http://wiki.ros.org/ros_control) and [\nROS2 Control ](https://control.ros.org/master/index.html) are _different\nframeworks_ , and are not compatible with one another. This post is focused on\nROS2 Control - or as their documentation calls it, ros2_control.\n\nros2_control's purpose is to simplify integrating new hardware into ROS2. The\ncentral idea is to separate controllers from [ systems, actuators, and sensors\n](https://control.ros.org/master/doc/getting_started/getting_started.html#hardware-\ncomponents) . A controller is responsible for controlling the movement of a\nrobot; an actuator is responsible for moving a particular joint, like a motor\nmoving a wheel. There's a good reason for this separation: it allows us to\nwrite a controller for a wheel configuration, without knowing which specific\nmotors are used to move the wheels.\n\nLet's take an example: the Turtlebot and the [ JetBot\n](https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetbot-ai-\nrobot-kit/) are both driven using one wheel on each side and casters to keep\nthe robots level. These are known as differential drive robots.\n\n![Turtlebot image with arrows noting\nwheels](https://assets.community.aws/a/2dkAG4luugjr8IbiSUSsZkVM0BA/turtl.webp)\n\nTurtlebot 3 Burger image edited from\nhttps://www.robotis.us/turtlebot-3-burger-us/\n\n![JetBot image with arrows noting wheels and\ncaster](https://assets.community.aws/a/2dkAMR4tUTmJ1M7I28ySU5cDQ3n/jetbo.webp)\n\nWaveShare JetBot AI Kit image edited from https://www.nvidia.com/en-\nus/autonomous-machines/embedded  \nAs the motor configuration is the same, the mathematics for controlling them\nis also the same, which means we can write one controller to control either\nrobot - assuming we can abstract away the code to move the motors.\n\nIn fact, this is exactly what's provided by the [ ros2_controllers\n](https://control.ros.org/master/doc/ros2_controllers/doc/controllers_index.html)\nlibrary. This library contains several standard controllers, including our\ndifferential drive controller. We could build a JetBot and a Turtlebot by\nsetting up this standard controller to be able to move their motors - all we\nneed to do is write the code for moving the motors when commanded to by the\ncontroller.\n\nros2_control also provides the controller manager, which is used to manage\nresources and activate/deactivate controllers, to allow for advanced\nfunctionality like switching between controllers. Our use case is simple, so\nwe will only use it to activate the controller. This architecture is explained\nwell in the ros2_control documentation - see the [ architecture page\n](https://control.ros.org/master/doc/getting_started/getting_started.html#architecture)\nfor more information.\n\nThis post shows how to perform this process for the JetBot. We're going to use\nthe I2C and motor classes from the [ previous post in the series\n](http://localhost:3000/blog/jetbot-motors-pt2) to define a ros2_control\nsystem that will work with the differential drive controller. We use a System\nrather than an Actuator because we want to define one class that can control\nboth motors in one ` write ` call, instead of having two separate Actuators.\n\n##\n\nROS2 Control Demos Repository\n\nTo help us with our ros2_control system implementation, the ros2_control\nframework has helpfully provided us with a [ set of examples\n](https://control.ros.org/master/doc/ros2_control_demos/doc/index.html) . One\nof these examples is exactly what we want - building a differential drive\nrobot (or diffbot, in the examples) with a custom System for driving the\nmotors.\n\nThe repository has a great many examples available. If you're here to learn\nabout ros2_control, but not to build a diffbot, there are examples of building\nsimulations, building URDF files representing robots, externally connected\nsensors, and many more.\n\nWe will be using [ example 2 ](https://github.com/ros-\ncontrols/ros2_control_demos/tree/master/example_2) from this demo repository\nas a basis, but stripping out anything we don't require right now, like\nsupporting simulation; we can return these parts in later iterations as we\ncome to understand them.\n\n##\n\nJetBot System Implementation\n\nIn this section, I'll take you through the key parts of my JetBot System\nimplementation for ros2_control. The code is available on [ Github\n](https://github.com/mikelikesrobots/jetbot-ros-control/tree/jetbot-motors-\npt2) \\- remember that this repository will be updated over time, so select the\ntag ` jetbot-motors-pt2 ` to get the same code version as in this article!\n\n###\n\nComponents are libraries, not nodes\n\nros2_control uses a different method of communication from the standard ROS2\npublish/subscribe messaging. Instead, the controller will load the code for\nthe motors as a **plugin library** , and directly call functions inside it.\nThis is the reason we had to rewrite the motor driver in C++ - it _has_ to be\na library that can be loaded by ros2_control, which is written in C++.\n\nPreviously, we wrote an example node that span the wheels using the motor\ndriver; now we are replacing this **executable** by a **library** that can be\nloaded by ros2_control. In CMakeLists.txt, we can see:\n\n`\n\n1  \n2  \n3  \n4  \n5  \n6  \n7  \n8  \n9  \n10  \n\nadd_library(${PROJECT_NAME}  \nSHARED  \nhardware/src/jetbot_system.cpp  \nhardware/src/i2c_device.cpp  \nhardware/src/motor.cpp  \n)  \n  \n...  \n  \npluginlib_export_plugin_description_file(hardware_interface\njetbot_control.xml)\n\n`\n\nThese are the lines that build the JetBot code as a library instead of a\nsystem, and export definitions that show it is a valid plugin library to be\nloaded by ros2_control. A new file, ` jetbot_control.xml ` , tells\nros2_control more information about this library to allow it to be loaded - in\nthis case, the library name and ros2_control plugin type (SystemInterface -\nwe'll discuss this more in the [ Describing the JetBot\n](http://localhost:3000/blog/jetbot-motors-pt2#describing-the-jetbot)\nsection).\n\n###\n\nCode Deep Dive\n\nFor all of the concepts in ros2_control, the actual implementation of a System\nis quite simple. Our ` JetBotSystemHardware ` class extends the\nSystemInterface class:\n\n`\n\n1  \n\nclass  JetBotSystemHardware  :  public  hardware_interface::SystemInterface {\n\n`\n\nIn the private fields of the class, we create the fields that we will need\nduring execution. This includes the ` I2CDevice ` and two ` Motor ` classes\nfrom the [ previous post ](http://localhost:3000/blog/jetbot-motors-pt1) ,\nalong with two vectors for the hardware commands and hardware velocities:\n\n`\n\n1  \n2  \n3  \n4  \n5  \n6  \n\nprivate  :  \nstd::vector<MotorPins> motor_pin_sets_;  \nstd::vector<Motor> motors_;  \nstd::shared_ptr<I2CDevice> i2c_device_;  \nstd::vector< double  > hw_commands_;  \nstd::vector< double  > hw_velocities_;\n\n`\n\nThen, a number of methods need to be overridden from the base class. Take a\nlook at the [ full header file ](https://github.com/mikelikesrobots/jetbot-\nros-control/blob/jetbot-motors-\npt2/hardware/include/jetbot_control/jetbot_system.hpp) to see them, but\nessentially it boils down to three concepts:\n\n  1. ` export_state_interfaces ` / ` export_command_interfaces ` : report the state and command interfaces supported by this system class. These interfaces can then be checked by the controller for compatibility. \n\n  2. ` on_init ` / ` on_activate ` / ` on_deactivate ` : lifecycle methods automatically called by the controller. Different setup stages for the System occur in these methods, including enabling the motors in the ` on_activate ` method and stopping them in ` on_deactivate ` . \n\n  3. ` read ` / ` write ` : methods called every controller update. ` read ` is for reading the velocities from the motors, and ` write ` is for writing requested speeds into the motors. \n\nFrom these, we use the ` on_init ` method to:\n\n  1. Initialize the base SystemInterface class \n\n  2. Read the pin configuration used for connecting to the motors from the parameters \n\n  3. Check that the provided hardware information matches the expected information - for example, that there are two velocity command interfaces \n\n  4. Initialize the ` I2CDevice ` and ` Motor ` s \n\nThis leaves the System initialized, but not yet activated. Once ` on_activate\n` is called, the motors are enabled and ready to receive commands. The ` read\n` and ` write ` methods are then repeatedly called for reading from and\nwriting to the motors respectively. When it's time to shutdown, `\non_deactivate ` will stop the motors, and the destructors of the classes\nperform any required cleanup. There are more lifecycle states that could\npotentially be used for a more complex system - these are documented in the [\nros2 demos repository\n](https://github.com/ros2/demos/blob/humble/lifecycle/README.rst) .\n\nThis System class, plus the ` I2CDevice ` and ` Motor ` classes, are compiled\ninto the plugin library, ready to be loaded by the controller.\n\n###\n\nDescribing the JetBot\n\nThe SystemInterface then comes into play when _describing_ the robot. The `\ndescription ` folder from the example contains the files that define the\nrobot, including its ros2_control configuration, simulation configuration, and\nmaterials used to represent it during simulation. As this implementation has\nbeen pared down to basics, only the ros2_control configuration with mock\nhardware flag have been kept in.\n\nThe ` jetbot.ros2_control.xacro ` file defines the ros2_control configuration\nneeded to control the robot. It uses ` xacro ` files to define this\nconfiguration, where ` xacro ` is a tool that extends XML files by allowing us\nto define macros that can be referenced in other files:\n\n`\n\n1  \n\n< xacro:macro  name  =  \"jetbot_ros2_control\"  params  =  \"name prefix\nuse_mock_hardware\"  >\n\n`\n\nIn this case, we are defining a macro for the ros2_control part of the JetBot\nthat can be used in the overall robot description.\n\nWe then define the ros2_control portion with type ` system ` :\n\n`\n\n1  \n\n< ros2_control  name  =  \"${name}\"  type  =  \"system\"  >\n\n`\n\nInside this block, we give the path to the [ plugin library\n](http://localhost:3000/blog/jetbot-motors-pt2#code-deep-dive) , along with\nthe parameters needed to configure it. You may recognize the pin numbers in\nthis section!\n\n`\n\n1  \n2  \n3  \n4  \n5  \n6  \n7  \n8  \n9  \n\n< hardware  >  \n< plugin  > jetbot_control/JetBotSystemHardware  </  plugin  >  \n< param  name  =  \"pin_enable_0\"  > 8  </  param  >  \n< param  name  =  \"pin_pos_0\"  > 9  </  param  >  \n< param  name  =  \"pin_neg_0\"  > 10  </  param  >  \n< param  name  =  \"pin_enable_1\"  > 13  </  param  >  \n< param  name  =  \"pin_pos_1\"  > 12  </  param  >  \n< param  name  =  \"pin_neg_1\"  > 11  </  param  >  \n</  hardware  >\n\n`\n\nThis tells any controller loading our JetBot system hardware which pins are\nused to drive the PWM chip. But, we're not done yet - we also need to tell\nros2_control the _command_ and _state_ interfaces available.\n\n####\n\nros2_control Joints, Command Interfaces, and State Interfaces\n\nros2_control uses joints to understand what the movable parts of a robot are.\nIn our case, we define one joint for each motor.\n\nEach joint then defines a number of command and state interfaces. Each command\ninterface accepts velocity, position, or effort commands, which allows\nros2_control controllers to command the joints to move as it needs. State\ninterfaces report a measurement from the joint out of velocity, position, or\neffort, which allows ros2_control to monitor how much the joint has actually\nmoved and adjust itself. In our case, each joint accepts velocity commands and\nreports measured velocity - although we configure the controller to ignore the\nvelocity, because we don't actually have a sensor like an encoder in the\nJetBot. This means we're using **open loop** control, as opposed to **closed\nloop** control.\n\n`\n\n1  \n2  \n3  \n4  \n\n< joint  name  =  \"${prefix}left_wheel_joint\"  >  \n< command_interface  name  =  \"velocity\"  />  \n< state_interface  name  =  \"velocity\"  />  \n</  joint  >\n\n`\n\nClosed loop control is far more accurate than open loop control. Imagine\nyou're trying to sprint exactly 100 metres from a starting line, but you have\nto do it once blindfolded, and once again without a blindfold and line\nmarkings every ten metres - which run is likely to be more accurate? In the\nJetBot, there's no sensor to measure how much it has moved, so the robot is\neffectively blindfolded and guessing how far it has travelled. This means our\nnavigation won't be as accurate - we are limited by hardware.\n\n####\n\nJetBot Description\n\nWith the ros2_control part of the JetBot defined, we can import and use this\nmacro in the overall JetBot definition. As we've stripped out all other\ndefinitions, such as simulation parameters, this forms the only part of the\noverall JetBot definition:\n\n`\n\n1  \n2  \n3  \n\n< xacro:include  filename  =  \"$(find\njetbot_control)/ros2_control/jetbot.ros2_control.xacro\"  />  \n< xacro:jetbot_ros2_control  \nname  =  \"JetBot\"  prefix  =  \"$(arg prefix)\"  use_mock_hardware  =  \"$(arg\nuse_mock_hardware)\"  />\n\n`\n\nLet's summarize what we've created so far:\n\n  1. A plugin library capable of writing commands to the JetBot motors \n\n  2. A ros2_control xacro file, describing the plugin to load and the parameters to give it \n\n  3. One joint per motor, each with a velocity command and state interface \n\n  4. An overall description file that imports the ros2_control file and calls the macro \n\nNow when we use ` xacro ` to build the overall description file, it will\nimport the ros2_control file macro and expand it, giving a complete robot\ndescription that we can add to later. It's now time to look at creating a\ncontroller manager and a differential drive controller.\n\n###\n\nCreating A Controller\n\nSo far, we've defined a JetBot using description files. Now we want to be able\nto launch ros2_control and tell it what controller to create, how to configure\nit, and how load our defined JetBot. For this, we use the `\njetbot_controllers.yaml ` file.\n\nWe start with the controller_manager. This is used to load one or more\ncontrollers and swap between them. It also makes sure that resources are only\nused by one controller at a time and manages the change between controllers.\nIn our case, we're only using it to load and run one controller:\n\n`\n\n1  \n2  \n3  \n4  \n5  \n6  \n\ncontroller_manager:  \nros__parameters:  \nupdate_rate:  10  # Hz  \n  \njetbot_base_controller:  \ntype:  diff_drive_controller/DiffDriveController\n\n`\n\nWe tell the manager to update at 10Hz and to load the `\ndiff_drive_controller/DiffDriveController ` controller. This is the standard\ndifferential drive controller discussed earlier. If we take a look at the [\ninformation page\n](https://control.ros.org/master/doc/ros2_controllers/diff_drive_controller/doc/userdoc.html)\n, we can see a lot of configuration for it - we provide this configuration in\nthe same file.\n\nWe define that the controller is open loop, as there is no feedback. We give\nthe names of the joints for the controller to control - this is how the\ncontroller knows it can send velocities to the two wheels implemented by our\nsystem class. We also set velocity limits on both linear and angular movement:\n\n`\n\n1  \n2  \n3  \n4  \n\nlinear.x.max_velocity:  0.016  \nlinear.x.min_velocity:  -0.016  \nangular.z.max_velocity:  0.25  \nangular.z.min_velocity:  -0.25\n\n`\n\nThese numbers are obtained through experimentation! ros2_control operates\nusing target velocities specified in radians per second [ [ source\n](https://answers.ros.org/question/242766/what-is-the-unit-of-the-commands-\nfrom-the-diff_drive_controller/) ]. However, the velocity we send to motors\ndoesn't correspond to radians per second - the range of -1 to +1 is the\nminimum velocity up to maximum velocity of the motors, which change with the\nbattery level of the robot. I obtained the numbers given through\nexperimentation - these move the robot at a reasonable pace.\n\nFinally, we supply the wheel separation and radius, specified in metres. I\nmeasured these from my own robot. The separation is the minimum separation\nbetween wheels, and the radius is from the centre of one wheel to the very\nedge:\n\n`\n\n1  \n2  \n\nwheel_separation:  0.104  \nwheel_radius:  0.032\n\n`\n\nWith this, we have described how to configure a controller manager with a\ndifferential drive controller to control our JetBot!\n\n###\n\nLaunching the Controller\n\nThe last step here is to provide a launch script to bring everything up. The\nexample again provides us with the launch script, including a field that\nallows us to launch with mock hardware if we want - this is great for testing\nthat everything loads correctly on a system that doesn't have the right\nhardware.\n\nThe launch script goes through a few steps to get to the full ros2_control\nsystem, starting with loading the [ robot description\n](http://localhost:3000/blog/jetbot-motors-pt2#describing-the-jetbot) . We\nspecify the path to the description file relative to the package, and use the\n` xacro ` tool to generate the full XML for us:\n\n`\n\n1  \n2  \n3  \n4  \n5  \n6  \n7  \n8  \n9  \n10  \n11  \n12  \n13  \n14  \n\n# Get URDF via xacro  \nrobot_description_content = Command(  \n[  \nPathJoinSubstitution([FindExecutable(name=  \"xacro\"  )]),  \n\" \"  ,  \nPathJoinSubstitution(  \n[FindPackageShare(  \"jetbot_control\"  ),  \"urdf\"  ,  \"jetbot.urdf.xacro\"  ]  \n),  \n\" \"  ,  \n\"use_mock_hardware:=\"  ,  \nuse_mock_hardware,  \n]  \n)  \nrobot_description = {  \"robot_description\"  : robot_description_content}\n\n`\n\nFollowing this, we load the [ jetbot controller configuration\n](http://localhost:3000/blog/jetbot-motors-pt2#creating-a-controller) :\n\n`\n\n1  \n2  \n3  \n4  \n5  \n6  \n7  \n\nrobot_controllers = PathJoinSubstitution(  \n[  \nFindPackageShare(  \"jetbot_control\"  ),  \n\"config\"  ,  \n\"jetbot_controllers.yaml\"  ,  \n]  \n)\n\n`\n\nWith the robot description and the robot controller configuration loaded, we\ncan pass these to the [ controller manager\n](http://localhost:3000/blog/jetbot-motors-pt2#creating-a-controller) :\n\n`\n\n1  \n2  \n3  \n4  \n5  \n6  \n\ncontrol_node = Node(  \npackage=  \"controller_manager\"  ,  \nexecutable=  \"ros2_control_node\"  ,  \nparameters=[robot_description, robot_controllers],  \noutput=  \"both\"  ,  \n)\n\n`\n\nFinally, we ask the launched controller manager to start up the `\njetbot_base_controller ` :\n\n`\n\n1  \n2  \n3  \n4  \n5  \n6  \n7  \n8  \n9  \n\nrobot_controller_spawner = Node(  \npackage=  \"controller_manager\"  ,  \nexecutable=  \"spawner\"  ,  \narguments=[  \n\"jetbot_base_controller\"  ,  \n\"--controller-manager\"  ,  \n\"/controller_manager\"  ,  \n],  \n)\n\n`\n\nAll that remains is to build the package and launch the new launch file!\n\n###\n\nros2_control Launch Execution\n\nThis article has been written from the bottom up, but now we have the full\nstory, we can look from the top down:\n\n  1. We launch the JetBot launch file defined in the package \n\n  2. The launch file spawns the **controller manager** , which is used to load controllers and manage resources \n\n  3. The launch file requests that the controller manager launches the differential drive controller \n\n  4. The differential drive controller loads the JetBot System as a plugin library \n\n  5. The System connects to the I2C bus, and hence, the motors \n\n  6. The controller can then command the System to move the motors as requested by ROS2 messaging \n\n**Hooray!** We have defined everything we need to launch ros2_control and\nconfigure it to control our JetBot! Now we have a controller that is able to\nmove our robot around.\n\n##\n\nRunning on the JetBot\n\nTo try the package out, we first need a working JetBot. If you're not sure how\nto do the initial setup, I've created a video on exactly that:\n\nWith the JetBot working, we can create a workspace and clone the code into it.\nUse VSCode over SSH to execute the following commands:\n\n`\n\n1  \n2  \n3  \n4  \n\nmkdir  ~/dev_ws  \ncd  ~/dev_ws  \ngit  clone  https://github.com/mikelikesrobots/jetbot-ros-control -b jetbot-\nmotors-pt2  \ncp  -r ./jetbot-ros-control/.devcontainer .\n\n`\n\nThen use the Dev Containers plugin to rebuild and reload the container. This\nwill take a few minutes, but the step is crucial to allow us to run ROS2\nHumble on the JetBot, which uses an older version of Ubuntu. Once complete, we\ncan build the workspace, source it, and launch the controller:\n\n`\n\n1  \n2  \n3  \n4  \n\nsource  /opt/ros/humble/setup.bash  \ncolcon build --symlink-install  \nsource  install/setup.bash  \nros2 launch jetbot_control jetbot.launch.py\n\n`\n\nThis should launch the controller and allow it to connect to the motors\nsuccessfully. Now we can use ` teleop_twist_keyboard ` to test it - but with a\ncouple of changes.\n\nFirst, we now expect messages to go to ` /jetbot_base_controller/cmd_vel `\ntopic instead of the previous ` /cmd_vel ` topic. We can fix that by asking `\nteleop_twist_keyboard ` to remap the topic it normally publishes to.\n\nSecondly, we normally expect ` /cmd_vel ` to accept [ Twist\n](https://docs.ros2.org/galactic/api/geometry_msgs/msg/Twist.html) messages,\nbut the controller expects [ TwistStamped\n](https://docs.ros2.org/galactic/api/geometry_msgs/msg/TwistStamped.html)\nmessages. There is a parameter for ` teleop_twist_keyboard ` that turns its\nmessages into TwistStamped messages, but while trying it out I found that the\nnode ignored that parameter. Checking it out from source fixed it for me, so\nin order to run the keyboard test, I recommend building and running from\nsource:\n\n`\n\n1  \n2  \n3  \n4  \n5  \n6  \n7  \n\ngit  clone  https://github.com/ros2/teleop_twist_keyboard  \ncolcon build --symlink-install  \nsource  install/setup.bash  \nros2 run teleop_twist_keyboard teleop_twist_keyboard \\  \n--ros-args \\  \n-p stamped:=  true  \\   \n-r /cmd_vel:=/jetbot_base_controller/cmd_vel \n\n`\n\nOnce running, you should be able to use the standard keyboard controls written\non screen to move the robot around. Cool!\n\nLet's do one more experiment, to see how the configuration works. Go into the\n` jetbot_controllers.yaml ` file and play with the maximum velocity and\nacceleration fields, to see how the robot reacts. Relaunch after every\nconfiguration change to see the result. You can also tune these parameters to\nmatch what you expect more closely.\n\nThat's all for this stage - we have successfully integrated our JetBot's\nmotors into a ros2_control System interface!\n\n##\n\nNext Steps\n\nHaving this setup gives us a couple of options going forwards.\n\nFirst, we stripped out a lot of configuration that supported simulation - we\ncould add this back in to support Gazebo simulation, where the robot in the\nsimulation should act nearly identically to the real life robot. This allows\nus to start developing robotics applications purely in simulation, which is\nlikely to be faster due to the reset speed of the simulation, lack of hardware\nrequirements, and so on.\n\nSecond, we could start running a navigation stack that can move the robot for\nus; for example, we could request that the robot reaches an end point, and the\nnavigation system will plan a path to take the robot to that point, and even\nface the right direction.\n\nStay tuned for more posts in this series, where we will explore one or both of\nthese options, now that we have the robot integrated into ROS2 using\nros2_control.  \n\n"
  },
  {
    "id": "odometry_trajectory/allp22html.txt",
    "content": "[ ](//www.rssing.com/index.php \"Home\")\n\n  * [ Login  ](//www.rssing.com/account.php?a=lgi&t=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Fall_p22.html)\n    * [ Account ](//www.rssing.com/account.php)\n    * [ Sign Up ](//www.rssing.com/account.php?a=reg&t=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Fall_p22.html)\n\n  * [ Home  ](//www.rssing.com/index.php)\n    * [ About Us ](//www.rssing.com/about.php)\n    * [ Catalog ](//www.rssing.com/catalog.php)\n  * [ Search  ](//www.rssing.com/search.php)\n  * [ Register RSS  ](//www.rssing.com/register.php)\n  * [ Embed RSS  ](//www.rssing.com/embed.php)\n    * [ FAQ ](//www.rssing.com/embed.php?a=whe)\n    * [ Get Embed Code ](//www.rssing.com/embed.php)\n    * [ Example: Default CSS ](//www.rssing.com/embed.php?a=ex1)\n    * [ Example: Custom CSS ](//www.rssing.com/embed.php?a=ex2)\n    * [ Example: Custom CSS per Embedding ](//www.rssing.com/embed.php?a=ex3)\n  * [ Super RSS  ](//www.rssing.com/super.php)\n    * [ Usage ](//www.rssing.com/super.php)\n    * [ View Latest ](//www.rssing.com/super.php?a=l)\n    * [ Create ](//www.rssing.com/super.php?a=crt)\n\n  * [ Contact Us  ](//www.rssing.com/contact.php)\n    * [ Technical Support ](//www.rssing.com/contact.php)\n    * [ Guest Posts/Articles ](//www.rssing.com/contact.php?r=o9)\n    * [ Report Violations ](//www.rssing.com/contact.php)\n    * [ Google Warnings ](//www.rssing.com/contact.php?r=o4)\n    * [ Article Removal Requests ](//www.rssing.com/contact.php?r=o5_0)\n    * [ Channel Removal Requests ](//www.rssing.com/contact.php?r=o5_0)\n    * [ General Questions ](//www.rssing.com/contact.php?r=o8)\n    * [ DMCA Takedown Notice ](//www.rssing.com/contact.php)\n\n[ ](//www.rssing.com/index.php)\n\n  * [ RSSing>> ](//www.rssing.com/index.php)\n    * Collections: \n    * [ RSSing ](//www.rssing.com/index.php)\n    * [ EDA ](//www.rssing.com/d/eda/index.php)\n    * [ Intel ](//www.rssing.com/d/intel/index.php)\n    * [ Mesothelioma ](//www.rssing.com/d/mesothelioma/index.php)\n    * [ SAP ](//www.rssing.com/d/sap/index.php)\n    * [ SEO ](//www.rssing.com/d/seo/index.php)\n  * [ Latest  ](//www.rssing.com/index.php?l=l)\n    * [ Articles ](//www.rssing.com/index.php?l=la)\n    * [ Channels ](//www.rssing.com/index.php?l=lc)\n    * [ Super Channels ](//www.rssing.com/index.php?l=ls)\n  * [ Popular  ](//www.rssing.com/index.php?l=p)\n    * [ Articles ](//www.rssing.com/index.php?l=pa)\n    * [ Pages ](//www.rssing.com/index.php?l=pp)\n    * [ Channels ](//www.rssing.com/index.php?l=pc)\n    * [ Super Channels ](//www.rssing.com/index.php?l=ps)\n  * [ Top Rated  ](//www.rssing.com/index.php?l=r)\n    * [ Articles ](//www.rssing.com/index.php?l=ra)\n    * [ Pages ](//www.rssing.com/index.php?l=rp)\n    * [ Channels ](//www.rssing.com/index.php?l=rc)\n    * [ Super Channels ](//www.rssing.com/index.php?l=rs)\n  * [ Trending  ](//www.rssing.com/index.php?l=t)\n    * [ Articles ](//www.rssing.com/index.php?l=ta)\n    * [ Pages ](//www.rssing.com/index.php?l=tp)\n    * [ Channels ](//www.rssing.com/index.php?l=tc)\n    * [ Super Channels ](//www.rssing.com/index.php?l=ts)\n\n[ ](javascript:;)\n\n[ ](javascript:;) Switch Editions?  \n[ Cancel ](javascript:;)\n\n[ ](javascript:;)\n\n[ ](javascript:;)\n\nSharing:\n\nTitle:\n\nURL:\n\n[ Copy Share URL ](javascript:;)\n\n[ ](javascript:; \"Share Page\")\n\n[ English  ](javascript:; \"English\")\n\nRSSing.com\n\n[ RSSing>> ](//www.rssing.com/index.php) [ Latest\n](//www.rssing.com/index.php?l=l) [ Popular ](//www.rssing.com/index.php?l=p)\n[ Top Rated ](//www.rssing.com/index.php?l=r) [ Trending\n](//www.rssing.com/index.php?l=t)\n\nChannel: ROS Answers: Open Source Q&A Forum - RSS feed  \n\n[ NSFW?  ](javascript:; \"Mark channel Not-Safe-For-Work\")\n\n[ Claim  ](javascript:; \"Claim Chan\")\n\n[ ](javascript:; \"Share Chan\")\n\n[ 0  ](javascript:; \"Show Rating\")\n\n  \n  \n\n[ X ](javascript:;) Mark channel Not-Safe-For-Work?  [ cancel ](javascript:;)\n[ confirm ](javascript:;) NSFW Votes:  (  0  votes)\n\n[ X ](javascript:;) Are you the publisher? [ Claim\n](//www.rssing.com/account.php?a=mmc&r=47151955) or [ contact us\n](//www.rssing.com/contact.php?a=ssm&r=o5&u=//question3152.rssing.com/chan-47151955/all_p22.html)\nabout this channel.\n\n[ X ](javascript:;) 0\n\nShowing article 421 to 440 of 521 in channel 47151955  \nChannel Details:\n\n  * Title: ROS Answers: Open Source Q&A Forum - RSS feed \n  * Channel Number: 47151955 \n  * Language: English \n  * Registered On: July 12, 2015, 5:27 pm \n  * Number of Articles: 521 \n  * Latest Snapshot: July 2, 2019, 9:52 am \n  * RSS URL: [ http://answers.ros.org/feeds/rss/?tags=robot_localization ](javascript:;)\n  * Publisher: [ http://answers.ros.org/questions/ ](javascript:;)\n  * Description: Open source question and answer forum written in Python and Django \n  * Catalog: [ //question3152.rssing.com/catalog.php?indx=47151955 ](//question3152.rssing.com/catalog.php?indx=47151955)\n\n[ Remove ADS ](//www.rssing.com/account.php?r=27)\n\nViewing all 521 articles\n\n[ ](//question3152.rssing.com/chan-47151955/all_p21.html \"older\") First Page\n...  Page 20  Page 21  Page 22  Page 23  Page 24  ...  Last Page  [\n](//question3152.rssing.com/chan-47151955/all_p23.html \"newer\")\n\n[ Browse latest ](//question3152.rssing.com/chan-47151955/index-latest.php) [\nView live ](//question3152.rssing.com/chan-47151955/article421-live.html)\n\n#  [ Wheel Odometry Covariance\n](//question3152.rssing.com/chan-47151955/article421-live.html)\n\nJuly 27, 2018, 9:17 am\n\n[ _\u226b_ Next: IMU orientation mismatch with RVIZ\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a422 \"Next\nArticle\")\n\n[ _\u226a_ Previous: IMU data to be used with robot_localization\n](//question3152.rssing.com/chan-47151955/all_p21.html#c47151955a420 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle421-live.html\n\"Article Support\")\n\nHi, I am using robot_localization. I'm using the typical setup EKF1 fuses\nencoders + IMU EKF2 fuses encoders + IMU + GPS My question is about encoder\ncovariances. The robot_localization documentation says >\\- If the odometry\nprovides both position and linear velocity, fuse the linear velocity. \\- If\nthe odometry provides both orientation and angular velocity, fuse the\norientation. Following this advice I am fusing the orientation that the wheel\nencoders report, but I don't know what to set the encoders pose covariance to.\nLogically I would think the pose covariance should grow every time you move.\nIt would just keep growing and growing without bound. But when I look at the\nexample pose covariance diagonals of the diff_drive_contoller package it says\nto use static values >pose_covariance_diagonal: [0.001, 0.001, 1000000.0,\n1000000.0, 1000000.0, 0.03] I'm very confused because diff_drive_controller\nseems like a commonly used package but those covariances don't make sense to\nme.\n\n\u21a7\n\n[ Search ](javascript:;)\n\nRSSing.com\n\n* * *\n\n\u21a7\n\n#  [ IMU orientation mismatch with RVIZ\n](//question3152.rssing.com/chan-47151955/article422-live.html)\n\nAugust 9, 2018, 12:34 pm\n\n[ _\u226b_ Next: Robot Localization Package: Transform from base_link to odom was\nunavailable for the time requested. Using latest instead. (IMU+GPS)\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a423 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Wheel Odometry Covariance\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a421 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle422-live.html\n\"Article Support\")\n\nHello everyone, I am using the [robot\nlocalization](http://wiki.ros.org/robot_localization) package to fuse together\ndata from wheel odometry and imu. For my robot, the imu frame is placed at\n0.5m on top of the base_link (it is placed flat, paralleled to the ground\nplane on my robot). When I visualize the imu data in rviz, i see that it does\nnot match the frame that I have broadcasted. This is shown in the image below\nwith the larger frame representing the orientation of the imu (UM7) sensor. It\nis shown that it is on an angle however the imu is placed flat. Can someone\nexplain why this happens? ![image description](/upfiles/15338428133342698.png)\nThis is what I am using to launch the IMU and broadcase the imu transform\n\n\u21a7\n\n#  [ Robot Localization Package: Transform from base_link to odom was\nunavailable for the time requested. Using latest instead. (IMU+GPS)\n](//question3152.rssing.com/chan-47151955/article423-live.html)\n\nAugust 11, 2018, 5:41 pm\n\n[ _\u226b_ Next: Confused with setup for robot_localization\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a424 \"Next\nArticle\")\n\n[ _\u226a_ Previous: IMU orientation mismatch with RVIZ\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a422 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle423-live.html\n\"Article Support\")\n\nHello, I want to record data from a tripod, so I started by creating a *urdf*\nfile, where I say that *laser_base* is 1m above of *base_link*, like this:\nAfter this, I want to move the tripod around, so I need to keep track of its\nXYZ position, as well as orientation, so that the data I record is properly\nlocated. For that, I am using an ArduPilot board for retrieving IMU and GPS\ninformation, which I am fusing with the robot_localization_package\n([Wiki](http://docs.ros.org/melodic/api/robot_localization/html/index.html))\n(ekf and navsat_transform_node). The launch file for this is as follows:\n[true, true, true, false, false, false, false, false, false, false, false,\nfalse, false, false, false]  [false, false, false, true, true, true, false,\nfalse, false, true, true, true, false, false, false]  So, I walked around with\nthe ArduPilot board and recorded a [bag\nfile](https://drive.google.com/file/d/1M2MFGphi7RlgL0C9nhJLVwJTc55kpS05/view?usp=sharing)\nwith the IMU and GPS topics (*/mavros/imu/data* and\n*/mavros/global_position/raw/fix*). I have also created another [bag\nfile](https://drive.google.com/file/d/1Ak7llCgtoWKseN6uswIcInIN5MbLBjCd/view?usp=sharing)\nwhere I am running the launch file above and recorded all topics. So, I have\ntwo problems: **1ST:** When I do `rostopic hz` with the 2 topics above, it\nshows a rate of approximately 1Hz. That is very slow, isn't it? I have tried\n[this](https://github.com/mavlink/mavros/blob/master/mavros/launch/px4_pluginlists.yaml),\nbut it didn't work, showing the message: RLException: unused args\n[config_yaml, pluginlists_yaml] for include of\n[/opt/ros/kinetic/share/mavros/launch/apm2.launch] **2ND:** When I use the\nlaunch file above, it starts by showing: [ INFO] [1534032142.676696240]:\nInitial odometry pose is Origin: (0 0 0) Rotation (RPY):\n(0.061743952333927182297, -0.017582930624485095666, -0.89866225322219372984) [\nINFO] [1534032142.776689397]: Initial odometry pose is Origin: (0 0 0)\nRotation (RPY): (0.061743952333927182297, -0.017582930624485095666,\n-0.89866225322219372984) ... And, after a couple of this messages, it shows: [\nINFO] [1534032142.878153405]: World frame->utm transform is Origin:\n(-475554.63263590750284 -4278148.5965311238542 -133980.14933940110495)\nRotation (RPY): (0.024644147360516073519, -0.059266088787775804414,\n-0.00012297369933011960061) [ WARN] [1534032143.376845932]: Transform from\nbase_link to odom_combined was unavailable for the time requested. Using\nlatest instead. And the latter line starts repeating. Once this happens, the\nOutput on RViz also gets strange, Where the transform between *odom* and\n*base_link* starts changing randomly. Any idea of what the problem with the\ntransforms might be? Thank you.\n\n\u21a7\n\n#  [ Confused with setup for robot_localization\n](//question3152.rssing.com/chan-47151955/article424-live.html)\n\nAugust 13, 2018, 11:45 am\n\n[ _\u226b_ Next: Kalman Filter implementation for a drone. Help confirming my\nsensor inputs are correct.\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a425 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Robot Localization Package: Transform from base_link to odom\nwas unavailable for the time requested. Using latest instead. (IMU+GPS)\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a423 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle424-live.html\n\"Article Support\")\n\nHello, I've just recently started trying to implemented the robot_localization\nnode, and I'm having trouble understanding what all to enable, and what I\nshould be expecting back. Here is my current setup: * I have a robot which\nreports its odometry as (x, y, yaw) based on ticks from the wheel's encoder.\nIt also has an IMU that is reporting (roll, pitch, yaw). * I am attempting to\nfuse the (x, y, yaw) odometry information with the (yaw) information from the\nIMU. * I haven't really tweaked covariances or anything yet, I am mostly using\nthe default values from the template. What I am not understanding: * The wheel\nodometry is inherently going to be incorrect due to wheel slippage, so while\nthe distance the robot traveled is still pretty accurate, the odometry value\nfor yaw is not to be trusted after a long time. But x, y for odometry are\ncalculated using yaw, so I guess those would be wrong as well. Am I supposed\nto be taking the result of the robot_localization output and \"resetting\" the\nstate of the odometry (specifically yaw) of the wheels? I'm not sure if this\nis something the node handles internally or not. * My main concern is that\nodometry reports being at (5, 5, 45 degrees) after a bit of movement, and the\nIMU reports yaw is actually 180. Then the X, Y that the odometry reported\nwould also be wrong. How does this node handle a situation like that? Would it\nsomehow understand to adjust the X, Y values based on the IMU yaw reading\nbeing the correct one? * Should I be passing more information to the node? I\nam only passing x, y, yaw (odometry), and yaw (IMU). I can't really understand\nhow it can take that information and correct the x, y position relative to\nwhat the IMU is saying. If the IMU and odometry disagree entirely on the yaw\nvalue, what happens? I.e. what happens to the X and Y values when my odometry\nsays I'm turned 45 degrees and the IMU says I'm at 180 degrees? * I saw\nsomewhere that I shouldn't be fusing X, Y of the odometry, instead I should\nfuse veloicty_x, velocity_y. But in regards to my first bullet point in this\nlist, wouldn't the velocities be subject to the same issues as position? The\nyaw known by odometrty would be used to calculate the velocities as well, thus\ngiving the same error as the position if the yaw is wrong. * When I look at\nthe transform in rviz, I notice that if I lift the robot up off the floor and\nturn it 180 degrees, the transform does not change. It's almost as if it's\ncompletely ignoring the IMU yaw position and setting itself purely with the\nodometry information. Why would I not see a change in the transform if I pick\nup the robot and rotate it to change the IMU value? I don't really have much\nexperience with sensor fusion, so I'm sure some of these questions will need\nmore explanation, which I'd be happy to provide. My config file: frequency: 30\nsensor_timeout: 0.1 two_d_mode: true transform_time_offset: 0.0\ntransform_timeout: 0.0 print_diagnostics: true publish_tf: true\npublish_acceleration: false odom0: odom odom0_config: [true, true, false,\nfalse, false, false, false, false, false, false, false, false, false, false,\nfalse] odom0_queue_size: 5 odom0_nodelay: false odom0_differential: false\nodom0_relative: false odom0_pose_rejection_threshold: 5\nodom0_twist_rejection_threshold: 1 imu0: imu imu0_config: [false, false,\nfalse, false, false, true, false, false, false, false, false, false, false,\nfalse, false] imu0_nodelay: false imu0_differential: false imu0_relative:\nfalse imu0_queue_size: 5 imu0_pose_rejection_threshold: 0.8\nimu0_twist_rejection_threshold: 0.8\nimu0_linear_acceleration_rejection_threshold: 0.8\nimu0_remove_gravitational_acceleration: false use_control: true\nstamped_control: false control_timeout: 0.2 control_config: [true, false,\nfalse, false, false, true] acceleration_limits: [1.3, 0.0, 0.0, 0.0, 0.0, 3.4]\ndeceleration_limits: [1.3, 0.0, 0.0, 0.0, 0.0, 4.5] acceleration_gains: [0.8,\n0.0, 0.0, 0.0, 0.0, 0.9] deceleration_gains: [1.0, 0.0, 0.0, 0.0, 0.0, 1.0]\nprocess_noise_covariance: [0.05, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0.05, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0.03, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0.03, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0.025, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0.025, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.04, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0.01, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0.01, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.02, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0.01, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0.01, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.015]\ninitial_estimate_covariance: [1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9]\n\n\u21a7\n\n#  [ Kalman Filter implementation for a drone. Help confirming my sensor\ninputs are correct.\n](//question3152.rssing.com/chan-47151955/article425-live.html)\n\nAugust 13, 2018, 2:48 pm\n\n[ _\u226b_ Next: robot_localization : no output from navsat_transform on\nodometry/gps\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a426 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Confused with setup for robot_localization\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a424 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle425-live.html\n\"Article Support\")\n\nHi, I'm learning more about the kalman filter and I thought I'd write a simple\nimplementation for position tracking based on the details at this\n[link](http://campar.in.tum.de/Chair/KalmanFilter) and this\n[link](http://nbviewer.jupyter.org/github/balzer82/Kalman/blob/master/Kalman-\nFilter-CA-Ball.ipynb?create=1) However, The filter estimates and the real\nsensor readings are far off. I'm using a Matrice 100 drone and subscribing to\nthe following messages to populate my state estimate: /dji_sdk/imu ( publishes\nimu data) /dji_sdk/velocity ( publishes velocity) /dji_sdk/local_position (\npublishes local position in Cartesian coordinates) My state estimate is a 9 x\n1 vector tracking position, velocity and acceleration x\n\n\u21a7\n\n\u21a7\n\n#  [ robot_localization : no output from navsat_transform on odometry/gps\n](//question3152.rssing.com/chan-47151955/article426-live.html)\n\nAugust 15, 2018, 4:05 pm\n\n[ _\u226b_ Next: navSat with hectorMapping for outdoor navigation\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a427 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Kalman Filter implementation for a drone. Help confirming my\nsensor inputs are correct.\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a425 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle426-live.html\n\"Article Support\")\n\nHi, I have a bag file which has IMU, GPS and wheel odometry and I'm trying to\nfuse it through robot_localization. I have followed everything as per the\ndocument. the ekf node is working fine but there is no output on the topic\nodometry/gps. I am manually tuning the covariance values for all the three\nsensors. For this I have a small code which runs above the bag file and just\nadds up the values in covariance matrix. Please find the attached launch file\nand config file . Also, I am pasting few messages for IMU, GOS and odometry\nIMU: header: seq: 122 stamp: secs: 1531127130 nsecs: 412077068 frame_id:\n\"imu_link\" orientation: x: 0.01904296875 y: -0.0274047851562 z:\n-0.852172851562 w: 0.522216796875 orientation_covariance: [24.0, 0.0, 0.0,\n0.0, 24.0, 0.0, 0.0, 0.0, 24.0] angular_velocity: x: 2.375 y: -0.875 z: 2.75\nangular_velocity_covariance: [24.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 24.0]\nlinear_acceleration: x: -0.270000010729 y: 1.48000001907 z: -1.27999997139\nlinear_acceleration_covariance: [24.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0,\n24.0] \\--- header: seq: 123 stamp: secs: 1531127130 nsecs: 530077068 frame_id:\n\"imu_link\" orientation: x: 0.0189208984375 y: -0.0271606445312 z:\n-0.852966308594 w: 0.520935058594 orientation_covariance: [24.0, 0.0, 0.0,\n0.0, 24.0, 0.0, 0.0, 0.0, 24.0] angular_velocity: x: 1.25 y: -3.125 z: -0.375\nangular_velocity_covariance: [24.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 24.0]\nlinear_acceleration: x: -0.819999992847 y: 0.689999997616 z: -2.44000005722\nlinear_acceleration_covariance: [24.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0,\n24.0] GPS: header: seq: 8 stamp: secs: 1531127123 nsecs: 87058067 frame_id:\n\"gps_link\" status: status: 0 service: 1 latitude: 50.72745 longitude: 7.087071\naltitude: 110.3 position_covariance: [0.01, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0,\n0.0, 0.01] position_covariance_type: 1 \\--- header: seq: 9 stamp: secs:\n1531127124 nsecs: 89728116 frame_id: \"gps_link\" status: status: 0 service: 1\nlatitude: 50.7274498333 longitude: 7.087071 altitude: 110.3\nposition_covariance: [0.01, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.01]\nposition_covariance_type: 1 \\--- header: seq: 10 stamp: secs: 1531127125\nnsecs: 81310987 frame_id: \"gps_link\" status: status: 0 service: 1 latitude:\n50.7274498333 longitude: 7.087071 altitude: 110.3 position_covariance: [0.01,\n0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.01] position_covariance_type: 1 wheel\nodometry: header: seq: 632 stamp: secs: 1531127147 nsecs: 65554528 frame_id:\n\"odom\" child_frame_id: \"base_link\" pose: pose: position: x: 8.1543953277 y:\n-7.6454593772 z: 0.0 orientation: x: 0.0 y: 0.0 z: -0.657809962921 w:\n0.753183943457 covariance: [0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0,\n0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0,\n0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375] twist: twist:\nlinear: x: 0.896675902811 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z:\n0.0266669413475 covariance: [0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0,\n0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0,\n0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01] \\--- ^Cheader:\nseq: 633 stamp: secs: 1531127147 nsecs: 190536275 frame_id: \"odom\"\nchild_frame_id: \"base_link\" pose: pose: position: x: 8.16897660416 y:\n-7.75282666754 z: 0.0 orientation: x: 0.0 y: 0.0 z: -0.6552952454 w:\n0.755372849231 covariance: [0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0,\n0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0,\n0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375] twist: twist:\nlinear: x: 0.866949711312 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z:\n0.0533507514654 covariance: [0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0,\n0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0,\n0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01] \\--- [CONFIG\nFILE](https://goo.gl/vA3wXA) [LAUNCH FILE](https://goo.gl/tP4oQW)\n\n\u21a7\n\n#  [ navSat with hectorMapping for outdoor navigation\n](//question3152.rssing.com/chan-47151955/article427-live.html)\n\nAugust 20, 2018, 11:36 am\n\n[ _\u226b_ Next: Robot_localization result is unpredictable\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a428 \"Next\nArticle\")\n\n[ _\u226a_ Previous: robot_localization : no output from navsat_transform on\nodometry/gps\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a426 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle427-live.html\n\"Article Support\")\n\nHello, I'm trying to configure a robot with GPS for outdoor navigation. For\nthat I'm using robot_localization package with the navSat transform and I want\nto fuse hectorMapping for pathPlanning and obsctacle avoindance. I've seen\nthis package I tried to replicate for my purposes, so I have this\nlocalization.yaml file: # For parameter descriptions, please refer to the\ntemplate parameter files for each node. ekf_se_odom: # Used only for\nbroadcasting odom to base_link transforms frequency: 30 sensor_timeout: 0.1\ntwo_d_mode: true transform_time_offset: 0.0 transform_timeout: 0.0\nprint_diagnostics: true debug: false map_frame: map odom_frame: odom\nbase_link_frame: base_link world_frame: odom #\n------------------------------------- # Wheel odometry: odom0:\n/husky_velocity_controller/odom odom0_config: [false, false, false, false,\nfalse, false, true, true, true, false, false, false, false, false, false]\nodom0_queue_size: 10 odom0_nodelay: true odom0_differential: false\nodom0_relative: false # ------------------------------------- # Laser\nscanmatching odometry: odom1: scanmatch_odom odom1_config: [false, false,\nfalse, false, false, false, true, true, true, false, false, true, false,\nfalse, false] odom1_queue_size: 10 odom1_nodelay: true odom1_differential:\nfalse odom1_relative: false # -------------------------------------- # imu\nconfigure: imu0: /imu/data imu0_config: [false, false, false, true, true,\nfalse, false, false, false, true, true, true, true, true, true] imu0_nodelay:\nfalse imu0_differential: false imu0_relative: false imu0_queue_size: 10\nimu0_remove_gravitational_acceleration: true use_control: false\nprocess_noise_covariance: [--- ] initial_estimate_covariance: [ ----]\nekf_se_map: frequency: 30 sensor_timeout: 0.1 two_d_mode: true\ntransform_time_offset: 0.0 transform_timeout: 0.0 print_diagnostics: true\ndebug: false map_frame: map odom_frame: odom base_link_frame: base_link\nworld_frame: map # ------------------------------------- # Wheel odometry:\nodom0: /husky_velocity_controller/odom odom0_config: [false, false, false,\nfalse, false, false, true, true, true, false, false, true, false, false,\nfalse] odom0_queue_size: 10 odom0_nodelay: true odom0_differential: false\nodom0_relative: false # ------------------------------------- # GPS odometry:\nodom1: /gps/rtkfix odom1_config: [true, true, false, false, false, false,\nfalse, false, false, false, false, false, false, false, false]\nodom1_queue_size: 10 odom1_nodelay: true odom1_differential: false\nodom1_relative: false # ------------------------------------- # Laser\nscanmatching odometry: odom2: scanmatch_odom odom2_config: [false, false,\nfalse, false, false, false, true, true, true, false, false, true, false,\nfalse, false] odom2_queue_size: 10 odom2_nodelay: true odom2_differential:\nfalse odom2_relative: false # -------------------------------------- # imu\nconfigure: (IMU is too noisy for this) imu0: /imu_um7/data imu0_config:\n[false, false, false, false, false, false, false, false, false, false, false,\nfalse, false, false, false] imu0_nodelay: true imu0_differential: false\nimu0_relative: false imu0_queue_size: 10\nimu0_remove_gravitational_acceleration: true use_control: false\nprocess_noise_covariance: [...] initial_estimate_covariance: [...] My launch\nfile for localization:  Here's the rviz image with the result after a rotation\nwith the robot. The laser drifts from the map. Such thing does not happen if I\nuse hector map to publish the tf between map and odom (but I don't do that\nbecause I want to use GPS) ![rviz_image](https://imgur.com/a/w8TCBZJ)\nhttps://imgur.com/a/w8TCBZJ\n\n\u21a7\n\n#  [ Robot_localization result is unpredictable\n](//question3152.rssing.com/chan-47151955/article428-live.html)\n\nAugust 21, 2018, 7:38 am\n\n[ _\u226b_ Next: robot_localization estimate (using only IMU) drifts for a\nstationary robot (Gazebo Model)\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a429 \"Next\nArticle\")\n\n[ _\u226a_ Previous: navSat with hectorMapping for outdoor navigation\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a427 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle428-live.html\n\"Article Support\")\n\nHello, I very recently posted a question about the robot_localization package,\nand received some very good insight. I managed to fuse my wheel odometry with\nmy IMU readings, but the result is not what I was expecting. I'm noticing a\nvery significant bit of lag in updating the filtered transform. My initial\napproach was to start out trying to fuse all the data at once, but I quickly\nlearned I needed to try this with individual data (i.e. just velocity of\nodometry). Hopefully showing my setup and some example videos will help\nexplain the problem I'm having. In the following example, I'm attempting the\nsimplest setup possible. I only want the EKF to use my odometry's forward\nvelocity value. Here's the setup & config file I'm using for this: On ros-\nkinetic: frequency: 30 sensor_timeout: 0.1 two_d_mode: true\ntransform_time_offset: 0.0 transform_timeout: 0.0 print_diagnostics: true\npublish_tf: true publish_acceleration: false use_control: false #map_frame:\nmap # Defaults to \"map\" if unspecified #odom_frame: odom_raw # Defaults to\n\"odom\" if unspecified #base_link_frame: base_link_raw # Defaults to\n\"base_link\" if unspecified #world_frame: odom # Defaults to the value of\nodom_frame if unspecified odom0: odom #x, y, z, roll, pitch, yaw, vx, vy, vz,\nvroll, vpitch, vyaw, ax, ay, az odom0_config: [false, false, false, false,\nfalse, false, true , false, false, false, false, false, false, false, false]\nodom0_queue_size: 10 odom0_nodelay: false odom0_differential: false\nodom0_relative: false odom0_pose_rejection_threshold: 5\nodom0_twist_rejection_threshold: 1 process_noise_covariance: [0.05, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.05, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0.06, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.03, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.03, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0.06, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.025, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.025, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0.04, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.01, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0.01, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0.02, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.01, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0.01, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0.015] initial_estimate_covariance: [1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9] When I use this\nconfig, and move the robot forward and backward about 3 meters, I'm getting\nvery unstable results from the EKF. I'm aware there's noise added to each\nmeasurement, so no two runs should be exactly the same, but the results I'm\nseeing imply there's a differently problem, because there's way too much\nvariation between each time I run the node and run a bag file of odometry\ndata. Here is the bag file:\nhttps://drive.google.com/open?id=1qRLqguLdRAeyw2bFAf5Oqm7Ld6nu7-VP Here is the\nconfig file for convenience:\nhttps://drive.google.com/open?id=1EDMMsNDVhrHEbWVt54QPb1E47eJ3-TSQ This\n(https://drive.google.com/open?id=1ZwiPXWEPunMa995JTfYKNci_ipliAVxa) is a\nvideo of how the odometry transform would look without the EKF node running.\nIt's stable enough for what I'm looking for, and I verified integrating the\nvelocity data gives the same output as the original odometry calculation. This\n(https://drive.google.com/open?id=1kAMzJfIboZbXN-XQi6lFgqe324qQ3lmS) is a\nvideo of the EKF node running the first time on the bag file. You'll notice at\nthe beginning it is slow to respond to the velocity changes, and jumps into\nposition. I've been unable to understand why there's so much jumping. This\nstill happens when I increase the \"frequency\" parameter to about 100Hz. This\n(https://drive.google.com/open?id=12HbN_7vwyj5BASEJeNO2yKO0TKOBAPgO) is a\nsecond video of the EKF node running on the bag file. Now I expect some\ndifferent results, but these are wildly different than the last run. It's far\ntoo unstable for me to use this in any sort of real-time path planning\nenvironment. At the end of the video, the bag file ends, and the EKF node\nkeeps running, so that's why it continues to fly off the screen. My initial\nguess as to why this would be occurring would be this package doesn't handle\nthe fusing of one data point very well, but that would surprise me. I have\nnoticed that the acceleration values in the state matrix are non-zero, and\nthis was pretty confusing to me, considering I never introduced acceleration\nvalues. Wouldn't integrating my velocity values cause more instability? If\nanyone has any insight into why I am experiencing these issues, I would\ngreatly appreciate the advice. Thank you!\n\n\u21a7\n\n[ Search ](javascript:;)\n\nRSSing.com\n\n* * *\n\n#  [ robot_localization estimate (using only IMU) drifts for a stationary\nrobot (Gazebo Model)\n](//question3152.rssing.com/chan-47151955/article429-live.html)\n\nAugust 21, 2018, 8:27 am\n\n[ _\u226b_ Next: Robot Localization not transforms from input's frame_id\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a430 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Robot_localization result is unpredictable\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a428 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle429-live.html\n\"Article Support\")\n\nI am trying to localize my robot (Gazebo model) in a known map. The robot has\na lidar and IMU on it. To start with I tried visualizing the\nrobot_localization estimate in rviz. I am feeding only IMU data to the ekf\nestimator. I did not expect the Odometry estimate to be very accurate, however\neven when the robot is not moving the estimate generated by robot_localization\nkeeps on moving. Also the estimate covariance keeps on increasing (this can be\nobserved in rviz). What could possibly be going wrong? ____ I am publishing a\nstatic transform to place the map frame at the odom frame. Here is how my tf\ntree looks like (only relevant part shown): ![image\ndescription](/upfiles/15348652023326518.png) This is the robot_localization\nconfiguration: frequency: 30 sensor_timeout: 0.05 two_d_mode: true\ntransform_time_offset: 0.0 transform_timeout: 1.0 print_diagnostics: false\ndebug: false publish_tf: true publish_acceleration: false odom_frame: odom\nbase_link_frame: base_footprint world_frame: odom imu0: /imu imu0_config:\n[false, false, false, false, false, true, false, false, false, false, false,\ntrue, true, false, false] imu0_nodelay: false imu0_differential: false\nimu0_relative: true imu0_queue_size: 5 imu0_pose_rejection_threshold: 0.8\nimu0_twist_rejection_threshold: 0.8\nimu0_linear_acceleration_rejection_threshold: 0.8\nimu0_remove_gravitational_acceleration: true dynamic_process_noise_covariance:\ntrue process_noise_covariance: [ sample values from robot_localization github\nrepo] initial_estimate_covariance: [ value of 0.01 for variables set to true\nin imu0_config] Here are the ROS IMU plugin settings:  true  true  100  /imu\n/imu  base_imu_link  100  0.05  0 0 0  0 0 0  base_imu_link  0 0 0 0 0 0  Here\nis the IMU data: header: seq: 1791 stamp: secs: 37 nsecs: 148000000 frame_id:\n\"base_imu_link\" orientation: x: 0.0246637627368 y: -0.026593164317 z:\n0.0668625611945 w: 1.02289534517 orientation_covariance:\n[0.0025000000000000005, 0.0, 0.0, 0.0, 0.0025000000000000005, 0.0, 0.0, 0.0,\n0.0025000000000000005] angular_velocity: x: -0.0326675653364 y:\n-0.0340936938196 z: -0.0323116318276 angular_velocity_covariance:\n[0.0025000000000000005, 0.0, 0.0, 0.0, 0.0025000000000000005, 0.0, 0.0, 0.0,\n0.0025000000000000005] linear_acceleration: x: -0.0783367912198 y:\n-0.00500801404049 z: 9.79784343093 linear_acceleration_covariance:\n[0.0025000000000000005, 0.0, 0.0, 0.0, 0.0025000000000000005, 0.0, 0.0, 0.0,\n0.0025000000000000005]\n\n\u21a7\n\n\u21a7\n\n#  [ Robot Localization not transforms from input's frame_id\n](//question3152.rssing.com/chan-47151955/article430-live.html)\n\nAugust 22, 2018, 7:18 am\n\n[ _\u226b_ Next: robot_localization non uniform inaccurate odometry\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a431 \"Next\nArticle\")\n\n[ _\u226a_ Previous: robot_localization estimate (using only IMU) drifts for a\nstationary robot (Gazebo Model)\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a429 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle430-live.html\n\"Article Support\")\n\nHi, I am trying to fuse the output of ORB-SLAM2 (as PoseWithCovarianceStamped\nmsg) into ekf_localization_node instance. The frame_id of the pose msg is an\noptical frame called \"zed_optical_frame\". I want to get the output in the\nstandard X-forward Y-left Z-up frame. In the TF tree I have \"base_link\" ->\n\"zed_center\" -> \"zed_optical_frame\". The \"zed_optical_frame\" is just a\nrotation from \"zed_center\" with RPY=(-PI/2,0.0,-PI/2). Still, I get the output\nin the same optical frame as the input. I made a test and left only this input\nto the ekf_localization_node, when I turned on the Differential flag. I'm\nrunning on Jetson TX2 with Ubuntu 16.04 and ROS Kinetic. Thanks\n\n\u21a7\n\n#  [ robot_localization non uniform inaccurate odometry\n](//question3152.rssing.com/chan-47151955/article431-live.html)\n\nApril 4, 2018, 12:13 am\n\n[ _\u226b_ Next: robot localization weird bahavior when playing bag\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a432 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Robot Localization not transforms from input's frame_id\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a430 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle431-live.html\n\"Article Support\")\n\nIm running a simulation in Gazebo combining the odomery data (coming from the\ndifferential drive plugin) and the imu data (from GazeboRosImuSensor plugin).\nIm quite new to ROS and im totally confused with the ENU and NED frames ..\nThis is what I did 1)placed the IMU in its neutral position 2)setup a static\ntransform broadcaster which broadcasts my base_link to odom frame here i made\nthe rotation. I have rolled it by 180 and yaw by 90 . this is the code snippet\nin my launch file  I tested the IMU and it shows correct accelerations as\nshown ( http://docs.ros.org/lunar/api/robot_l... ) This is my paramter config\nfile for the robot_localization package odom0_config: [false, false, false,\nfalse, false, false, true, true, false, false, false, true, false, false,\nfalse] imu0_config: [false, false, false, false, false, true, false, false,\nfalse, false, false, true, true, true, false] odom0_queue_size: 2\nimu0_queue_size: 5 odom0_nodelay: false imu0_nodelay: false\nodom0_differential: false imu0_differential: false odom0_relative: false\nimu0_relative: false The problem is that the filtered odometry data is moving\nat 90 degees to original raw odometry data ![image\ndescription](https://answers.ros.org/question/287438/robot_localization-non-\nuniform-inaccurate-odometry/)\n\n\u21a7\n\n#  [ robot localization weird bahavior when playing bag\n](//question3152.rssing.com/chan-47151955/article432-live.html)\n\nAugust 29, 2018, 6:32 am\n\n[ _\u226b_ Next: What amount of odometry drift would be considered having an\naccurate base?\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a433 \"Next\nArticle\")\n\n[ _\u226a_ Previous: robot_localization non uniform inaccurate odometry\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a431 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle432-live.html\n\"Article Support\")\n\nI used GPS and IMU to localize my robot with `robot_localization`. After I\nrecorded my data, which includes topics `Imu`, `NavSatFix` and\n`TwistWithCovarianceStamped`, I played the bag and launch the nodes. The bag\nis available at [here](https://drive.google.com/open?id=1eWlI-\nHZNObzHEJd82FHVk-2koPGhWmuh) The launch files are as following: \\- Top level:\n[gps_imu_localization_bag.launch](https://github.com/seanNCTU/answer_ros/blob/master/robot_localization/launch/gps_imu_localization_bag.launch)\n\\- robot_localization: \\- ekf_node:\n[wam_v_ekf.launch](https://github.com/seanNCTU/answer_ros/blob/master/robot_localization/launch/wam_v_ekf.launch)\n\\- nav_sat_transform_node:\n[wam_v_navsat.launch](https://github.com/seanNCTU/answer_ros/blob/master/robot_localization/launch/wam_v_navsat.launch)\nThe parameter files for my robot are: \\- ekf:\n[wam_v_ekf.yaml](https://github.com/seanNCTU/answer_ros/blob/master/robot_localization/config/wam_v_ekf.yaml)\n\\- nav_sat:\n[wam_v_navsat](https://github.com/seanNCTU/answer_ros/blob/master/robot_localization/config/wam_v_navsat.yaml)\nAfter I launched the file several times, I notices that the results are not\nalways the same, sometimes the result seems good[Fig. 1], while sometimes the\nresult were very terrible[Fig. 2]. [Fig. 1](/upfiles/15355490726149153.jpg)\n[Fig. 2](/upfiles/15355491077533439.jpg) It really confused me that with the\nsame topics and the same parameters, I got the different results. Notice also\nthat the direction of oscillation of Fig. 2 is from northeast to southwest,\nwhich northeast is the direction from the origin of UTM to my position,\na,k,a., Taiwan.\n\n\u21a7\n\n#  [ What amount of odometry drift would be considered having an accurate\nbase? ](//question3152.rssing.com/chan-47151955/article433-live.html)\n\nAugust 30, 2018, 2:11 pm\n\n[ _\u226b_ Next: what should the frame_id of \"poseX\" be, before use\nrobot_localization package?\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a434 \"Next\nArticle\")\n\n[ _\u226a_ Previous: robot localization weird bahavior when playing bag\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a432 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle433-live.html\n\"Article Support\")\n\nI'm working on some projects and it occurred to me that I've never seen any\ndocuments where people specify their robot base odometry drift to benchmark\nwhat a typical amount of drift would be and what's the point where I can say I\nhave \"good\" odometry. For instance, when I move my base in a 20 meter\nperimeter square, in forward direction I have about 20cm drift (1%) and in the\nlateral direction, I have about 50cm (2.5%) drift on a differential drive\nbase. Can anyone share here their specification or documentation of others?\n\n\u21a7\n\n\u21a7\n\n#  [ what should the frame_id of \"poseX\" be, before use robot_localization\npackage? ](//question3152.rssing.com/chan-47151955/article434-live.html)\n\nAugust 30, 2018, 9:04 pm\n\n[ _\u226b_ Next: Indoor localization with 2D lidar and IMU\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a435 \"Next\nArticle\")\n\n[ _\u226a_ Previous: What amount of odometry drift would be considered having an\naccurate base?\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a433 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle434-live.html\n\"Article Support\")\n\nHello: According to `r_l`(robot_localization) wiki, [coordinate-frames-and-\ntransforming-sensor-data\ndoc](http://docs.ros.org/melodic/api/robot_localization/html/preparing_sensor_data.html?#coordinate-\nframes-and-transforming-sensor-data), it can transforms\n`geometry_msgs/PoseWithCovarianceStamped,` on topic \"poseX\", in message\nheader\u2019s frame_id into the coordinate frame specified by the world_frame\nparameter (typically map or odom). I think this topic probably can be provided\nby a stereo VO, because mono VO cannot provide real scale info. when i see the\n[\"poseX\" callback function](https://github.com/cra-ros-\npkg/robot_localization/blob/kinetic-devel/src/ros_filter.cpp#L1135), it then\ncalls [preparePose func](https://github.com/cra-ros-\npkg/robot_localization/blob/kinetic-devel/src/ros_filter.cpp#L2481), in this\nline [RosFilterUtilities::lookupTransformSafe()](https://github.com/cra-ros-\npkg/robot_localization/blob/kinetic-devel/src/ros_filter.cpp#L2570), it\nlookuptransform from \"finalTargetFrame\"(if we set it as odom), to pose\nmsg.frame_id, **what should this frame_id on this topic be?** It looks like\n`r_l` thinks this frame is odom, the transform msg work should be done by\nusers before use `r_l`, just like [viso2_ros](http://wiki.ros.org/viso2_ros)?\nGenerally speaking, the frame_id of pose on this topic is a fixed frame, such\nas a camera_0 frame(in some moment, camea is launched by its driver ros node).\nOnly when we know what time stamp of camera is launched, we can get from odom\nframe to this camera_0 frame from tf tree, let we mark this as\n`T_odom_to_camera0`, and then we can transform msg on topic poseX to odom\nframe, `T_odom_to_camera = T_odom_to_camera0 * T(msg_on_poseX)`,\n`T_odom_to_baselink = T_odom_to_camera * T_camera_to_baselink`., which\n`T_odom_to_baselink` is from odom frame to baselink with camera pictures\nestimated, `T_camera_to_baselink` is a tf static transform. In other words, if\nrobot base node and camera driver node are launched on the same time from\nstart, `T_odom_to_camera0` equals to `T_baselink_to_camera` ,we can get this\nTF directlly from tf tree. If they does not launched on the same time, we need\nto record time stamp of camera launched, because we need to calculate\n`T_odom_to_camera0`, anything wrong??\n\n\u21a7\n\n#  [ Indoor localization with 2D lidar and IMU\n](//question3152.rssing.com/chan-47151955/article435-live.html)\n\nAugust 31, 2018, 4:15 am\n\n[ _\u226b_ Next: robot_localization with cartographer and amcl\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a436 \"Next\nArticle\")\n\n[ _\u226a_ Previous: what should the frame_id of \"poseX\" be, before use\nrobot_localization package?\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a434 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle435-live.html\n\"Article Support\")\n\nI have a 3 wheeled differential drive robot (2 wheels + 1 castor) which has a\n9 DOF IMU (3d acceleration, heading and angular velocities) and a 2D lidar\n(RPLidar). I have a pre-computed map. To localize the robot I am using the ROS\npackage [amcl](http://wiki.ros.org/amcl). AMCL requires 3 inputs: 1\\. 2D Laser\nscan data 2\\. odom -> base_link transform. This is typically published by an\nodometry source. 3\\. Map Odometry is estimated using the ROS package\n[robot_localization](http://wiki.ros.org/robot_localization), which uses\nKalman filters to fuse data from the IMU's 3 sensors - accelerometer,\ngyroscope and magnetometer. The localization works reasonably well at slow\nspeeds. However sometimes the estimated position is way off the actual\nposition. My questions : 1\\. Is this the right approach to perform\nlocalization using an IMU and 2D lidar? 2\\. Will the odometry estimated using\nthe IMU data be good enough for amcl?\n\n\u21a7\n\n[ Search ](javascript:;)\n\nRSSing.com\n\n* * *\n\n#  [ robot_localization with cartographer and amcl\n](//question3152.rssing.com/chan-47151955/article436-live.html)\n\nSeptember 3, 2018, 9:01 pm\n\n[ _\u226b_ Next: robot_localization covariance grows too big\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a437 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Indoor localization with 2D lidar and IMU\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a435 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle436-live.html\n\"Article Support\")\n\nI am using cartographer_ros along with amcl and an imu and wheel odometry for\nlocalization. Robot_localization seems ideal for this. I modified the sources\nfor cartographer and amcl so that they publish poses and do not broadcast\ntransforms. I used the following robot_localization setup and it seems to be\nworking well, but I am not sure it is entirely correct. If someone would be\nkind enough to look it over, I would sure appreciate that. I am particularly\ninterested to know whether I set the frame ID and child frames correctly for\nthe inputs from amcl and cartographer (frame ID = map, child ID =\nbase_footprint) robot_localization ukf instance 1, continuous inputs, 2D mode\nis true, neither of the inputs is set to differential.  odom0 is from the\nwheel encoders, reporting vx and vYaw (vy = 0), 2D mode, with frame id= odom,\nchild frame is base_footprint  [false, false, false,  false, false, false,\ntrue, true, false,  false, false, true,  false, false, false]  imu0 is from\nthe IMU, reporting vYaw, frame ID is imu_link  [false, false, false, true,\ntrue, true,  false, false, false, true, true, true,  true, false, false]\nrobot_localization ukf instance 2 brings in amcl and cartographer (and\neventually GPS)  pose0 is from amcl, with a frame ID = map, it is set to\ndifferential.  [true, true, false,  true, true, true,  false, false, false,\nfalse, false, false, false, false, false]  odom0 is from cartographer, the\nframe ID is map, the child is base_footprint  [true, true, false, true, true,\nfalse, false, false, false, false, false, true, false, false, false]\n\n\u21a7\n\n#  [ robot_localization covariance grows too big\n](//question3152.rssing.com/chan-47151955/article437-live.html)\n\nSeptember 7, 2018, 5:33 pm\n\n[ _\u226b_ Next: Robot Localization Package: Transform was unavailable for the time\nrequested. Using latest instead.\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a438 \"Next\nArticle\")\n\n[ _\u226a_ Previous: robot_localization with cartographer and amcl\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a436 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle437-live.html\n\"Article Support\")\n\nI am trying to localize using GPS+IMU only. For now, I am running `test1.bag`\nincluded in `robot_localization/test` folder. My configuration file:\nekf_se_odom: frequency: 30 sensor_timeout: 0.1 two_d_mode: false\ntransform_time_offset: 0.0 transform_timeout: 0.0 print_diagnostics: true\ndebug: false map_frame: map odom_frame: odom base_link_frame: base_link\nworld_frame: odom odom0: odometry/wheel odom0_config: [false, false, false,\nfalse, false, false, false, false, false, false, false, false, false, false,\nfalse] odom0_queue_size: 10 odom0_nodelay: true odom0_differential: false\nodom0_relative: false imu0: imu/data imu0_config: [false, false, false, true,\ntrue, true, false, false, false, true, true, true, true, true, true]\nimu0_nodelay: false imu0_differential: false imu0_relative: false\nimu0_queue_size: 10 imu0_remove_gravitational_acceleration: true use_control:\nfalse process_noise_covariance: [1e-3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 1e-3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-3, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.01, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.03, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.03, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0.03, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.03, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.03] initial_estimate_covariance:\n[1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 1.0] ekf_se_map: frequency: 30 sensor_timeout: 0.1 two_d_mode: false\ntransform_time_offset: 0.0 transform_timeout: 0.0 print_diagnostics: true\ndebug: false map_frame: map odom_frame: odom base_link_frame: base_link\nworld_frame: map odom0: odometry/wheel odom0_config: [false, false, false,\nfalse, false, false, false, false, false, false, false, false, false, false,\nfalse] odom0_queue_size: 10 odom0_nodelay: true odom0_differential: false\nodom0_relative: false odom1: odometry/gps odom1_config: [true, true, true,\nfalse, false, false, false, false, false, false, false, false, false, false,\nfalse] odom1_queue_size: 10 odom1_nodelay: true odom1_differential: false\nodom1_relative: false imu0: imu/data imu0_config: [false, false, false, true,\ntrue, true, false, false, false, true, true, true, true, true, true]\nimu0_nodelay: true imu0_differential: false imu0_relative: false\nimu0_queue_size: 10 imu0_remove_gravitational_acceleration: true use_control:\nfalse process_noise_covariance: [1e-3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 1e-3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-3, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.01, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.02, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0.03, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.03, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.03] initial_estimate_covariance:\n[1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 1.0] navsat_transform: frequency: 30 delay: 3.0\nmagnetic_declination_radians: 0.0429351 # For lat/long 55.944831, -3.186998\nyaw_offset: 1.570796327 # IMU reads 0 facing magnetic north, not east\nzero_altitude: false broadcast_utm_transform: true publish_filtered_gps: true\nuse_odometry_yaw: false wait_for_datum: false My launch file:  Then, here is\nmy sample messages from `odometry/filtered` topic header: seq: 1593 stamp:\nsecs: 1432235551 nsecs: 133883715 frame_id: \"odom\" child_frame_id: \"base_link\"\npose: pose: position: x: -25.6806186578 y: -41.0579199887 z: -16.2050460107\norientation: x: 0.364113953192 y: -0.600499821833 z: -0.610551127453 w:\n0.366126090078 covariance: [5001.069390243607, 1405.9635232709018,\n12.89263293200848, 2.119036688494102e-06, 1.1326755032269357e-06,\n3.531822011990498e-05, 1405.963523270896, 7048.953656918936,\n-6.1034919043737235, -1.107525856395083e-06, 2.1428042670635376e-06,\n-3.2979372797959194e-05, 12.892632932008365, -6.103491904373762,\n7837.97657165255, -2.0927081487748503e-06, -7.79505181473767e-06,\n2.910017471539165e-08, 2.1190366884941023e-06, -1.1075258563950824e-06,\n-2.0927081487748503e-06, 0.001103250724986751, 5.157131696321912e-10,\n3.6306968185466776e-08, 1.1326755032269357e-06, 2.142804267063538e-06,\n-7.795051814737668e-06, 5.157131696321911e-10, 0.001103251490413962,\n-4.92147153421835e-08, 3.531822011990498e-05, -3.2979372797959194e-05,\n2.910017471539165e-08, 3.6306968185466776e-08, -4.9214715342183496e-08,\n0.000493887418752126] twist: twist: linear: x: 1.91971096583 y:\n-0.598022689859 z: 0.50493344106 angular: x: 0.0262928035401 y:\n-0.0102758377666 z: -0.00745906155821 covariance: [6.331493813516004, 0.0,\n0.0, 0.0, 0.0, 0.0, 0.0, 6.331493813516004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n2.6113483803761124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003851594532902605,\n4.605563489112172e-13, 4.061455269627516e-14, 0.0, 0.0, 0.0,\n4.605563489112171e-13, 0.0003851593561959551, -8.36557957900773e-12, 0.0, 0.0,\n0.0, 4.0614552696283576e-14, -8.365579579007733e-12, 0.00030620271386102107]\n\\--- header: seq: 1594 stamp: secs: 1432235551 nsecs: 167203903 frame_id:\n\"odom\" child_frame_id: \"base_link\" pose: pose: position: x: -25.7253968478 y:\n-41.1062007752 z: -16.2245404066 orientation: x: 0.364273043958 y:\n-0.600533967326 z: -0.61048560356 w: 0.366021080512 covariance:\n[5008.802031236015, 1408.6378258257955, 12.947200327348586,\n2.1325978785158645e-06, 1.1403697067180848e-06, 3.538685081620088e-05,\n1408.6378258257903, 7060.5058708601255, -6.132336376448345,\n-1.114938972991315e-06, 2.1561376318999096e-06, -3.2932407512073215e-05,\n12.947200327348469, -6.132336376448385, 7850.958226821027,\n-2.079979981832892e-06, -7.783246537269239e-06, 5.323378112419656e-08,\n2.132597878515865e-06, -1.114938972991315e-06, -2.079979981832892e-06,\n0.001103248400879815, 5.201962220313453e-10, 4.4160578457126984e-08,\n1.1403697067180844e-06, 2.1561376318999096e-06, -7.783246537269235e-06,\n5.201962220313455e-10, 0.001103249182621376, -6.583465241377887e-08,\n3.538685081620088e-05, -3.2932407512073215e-05, 5.323378112419657e-08,\n4.4160578457126984e-08, -6.58346524137789e-08, 0.0004938869557253063] twist:\ntwist: linear: x: 1.91857693379 y: -0.59495115496 z: 0.503116769612 angular:\nx: 0.00799503491898 y: -0.00256190295846 z: -0.00737636371411 covariance:\n[6.334836495079762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.334836495079762, 0.0, 0.0,\n0.0, 0.0, 0.0, 0.0, 2.6123586487433075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n0.0003851593549689014, 4.813698073764745e-13, 3.9415549023586156e-14, 0.0,\n0.0, 0.0, 4.813698073764745e-13, 0.00038515925787299216,\n-7.917437114678017e-12, 0.0, 0.0, 0.0, 3.941554902359113e-14,\n-7.917437114678017e-12, 0.0003062023411378149] As shown, position (x, y)\ncovariance only grows and never seems to shrink. Could anyone please help on\nthis? Thank you in advance!\n\n\u21a7\n\n\u21a7\n\n#  [ Robot Localization Package: Transform was unavailable for the time\nrequested. Using latest instead.\n](//question3152.rssing.com/chan-47151955/article438-live.html)\n\nSeptember 9, 2018, 5:35 pm\n\n[ _\u226b_ Next: Robot Localization with Odometry and UM7\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a439 \"Next\nArticle\")\n\n[ _\u226a_ Previous: robot_localization covariance grows too big\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a437 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle438-live.html\n\"Article Support\")\n\nHello, I am using an ArduPilot board with an internal IMU connected to an\nexternal GPS+Compass module. I wanted to localize a frame `base_link` in\nrelation to `odom_combined`. This base link is connected to other frames, so I\nhave created a simple URDF file:  So, I went outside and with the sensors,\nmoved around making a rectangle (moving forwards + turn right + forwards ...).\nThis the trajectory I did: ![Trajectory seen on a\nmap.](/upfiles/15365375007771977.jpg) If I plot the latitude and longitude\nfrom the NavsatFix data, I have the following: ![GPS\nData](/upfiles/15365375856519358.jpg) (I recorded the data from two GPS\nmodules, but the External Module is the one I am talking about). Everything\nseems fine, but if I try to use the `robot_localization_package` with the\n`navsat_transform_node` to estimate IMU which will then be the input to the\nekf_localization_node, it shows the error: [ WARN] Transform from base_link to\nodom_combined was unavailable for the time requested. Using latest instead.\nAnd the frame in RViz does not seems fine at all, with very aggressive\ndiscrete jumps. Based on another\n[question](https://answers.ros.org/question/300345/robot-localization-package-\ntransform-from-base_link-to-odom-was-unavailable-for-the-time-requested-using-\nlatest-instead-imugps/ \"Robot Localization Package: Transform from base_link\nto odom was unavailable for the time requested. Using latest instead.\n(IMU+GPS)\") I did, I set the `predict_to_current_time` parameter to true, but\nit did not solve the problem. Also, the `gps/filtered` output (shown below)\nfrom `navsat_transform_node` is very different from the original gps data:\n![gps/filtered](/upfiles/15365633543078592.jpg) Yet, the gps output from\n`navsat_transform_node` that will be the input from `ekf_localization_node` is\ncorrect (makes a perfect rectangle). This means that the problem is related to\nthe IMU, right? I really do not know how I can solve this problem because, the\ninformation from the sensors seems correct. The IMU frequency is around 2Hz. I\nknow that it is too low, but I can not figure why (the mavros launch is\ncommented below). Also, here is the result of `$ rosrun tf view_frames`:\n![frames](/upfiles/15365388161711451.png)\n[Here](https://drive.google.com/file/d/1JfDAmth4XxFW5PAUjCmiiXku8CiDvswg/view?usp=sharing\n\"Bag\") is the bag recorded in the parking lot (containing the IMU and\nNavSat/fix data). Also, I have created a [another\nbag](https://drive.google.com/file/d/1zHSjjpEPaycbnvna9Nl90DmRRsk04Qhz/view?usp=sharing\n\"Bag EKF\") which, not only contains the IMU+Navsat information, but also, the\ntopics associated with the `robot_localization_package`, when running\n`navsat_transform_node` and `ekf_localization_node`.  [true, true, false,\nfalse, false, false, false, false, false, false, false, false, false, false,\nfalse]  [false, false, false, true, true, true,  false, false, false, true,\ntrue, true,  false, false, false]  In the launch file above, I have commented\nthe fusion of Z on the odom because when I plot the z, it does not seems\ncorrect. Also, I do not know why, but I only have the IMU publishing at 2Hz.\nAlso, here is a sample of sensor output: IMU: header: seq: 480 stamp: secs:\n1536196132 nsecs: 675659339 frame_id: \"base_link\" orientation: x:\n-0.01038560877 y: 0.0207573504383 z: 0.354425421472 w: -0.934796176794\norientation_covariance: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]\nangular_velocity: x: 0.0015384554863 y: -0.000201269984245 z: 0.0021977359429\nangular_velocity_covariance: [1.2184696791468346e-07, 0.0, 0.0, 0.0,\n1.2184696791468346e-07, 0.0, 0.0, 0.0, 1.2184696791468346e-07]\nlinear_acceleration: x: 0.00980665 y: 0.1176798 z: 9.6693569\nlinear_acceleration_covariance: [8.999999999999999e-08, 0.0, 0.0, 0.0,\n8.999999999999999e-08, 0.0, 0.0, 0.0, 8.999999999999999e-08] And from the GPS:\nheader: seq: 1336 stamp: secs: 1536196628 nsecs: 257958525 frame_id:\n\"base_link\" status: status: 0 service: 1 latitude: 38.6603919 longitude:\n-9.2061606 altitude: 143.787508098 position_covariance: [-1.0, 0.0, 0.0, 0.0,\n0.0, 0.0, 0.0, 0.0, 0.0] position_covariance_type: 0 Any help is appreciated.\nThank you.\n\n\u21a7\n\n#  [ Robot Localization with Odometry and UM7\n](//question3152.rssing.com/chan-47151955/article439-live.html)\n\nSeptember 10, 2018, 4:34 pm\n\n[ _\u226b_ Next: navsat_transform_node outputs\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a440 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Robot Localization Package: Transform was unavailable for the\ntime requested. Using latest instead.\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a438 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle439-live.html\n\"Article Support\")\n\nHello all, I am trying to get localization to work for a custom car like\nrobot. I am able to publish odom from wheel encoders and imu/data from my UM7\nimu sensor. I would like to fuse together these two data using the [robot\nlocalization](http://docs.ros.org/indigo/api/robot_localization/html/index.html)\npackage and then show it with base_link in rviz. Without proper localization\nof base_link, I will not be able to run the navigation stack properly. In my\ncurrent setup, rviz is able to show forward and backward movement with\nbase_link; however, when I manually rotate the um7 imu sensor, it does not\nreflect within rviz. I can see that the odometry/filtered topic is receiving\ninput from the um7 but how do i visualize this in rviz? My end goal is to\nplace this um7 on my custom car like robot. I want rviz to display the\nbase_link mimicking its real life counterpart in terms of position/orientation\nand velocities (moving forward/backward, turing left/right...etc). It is to my\nunderstanding that this is what the robot localization package is for, please\ncorrect my understanding if i am making a mistake. Here are two videos\ndescribing my problem: [1st\nvideo](https://www.youtube.com/watch?v=Sa5ZqVbpd6o&feature=youtu.be) shows the\nscreen recording from my computer. You can see that moving forward and\nbackward is okay, but I do not know how to turn the base_link. [2nd\nvideo](https://www.youtube.com/watch?v=40nO4phqiqI&feature=youtu.be) shows\nwhat I am trying to do Below is the configuration file for the\nrobot_localization package: frequency: 50 sensor_timeout: 0.1 two_d_mode: true\ntransform_time_offset: 0.0 transform_timeout: 0.0 print_diagnostics: true\ndebug: false debug_out_file: /path/to/debug/file.txt publish_tf: true\npublish_acceleration: false odom_frame: odom # Defaults to \"odom\" if\nunspecified base_link_frame: base_link # Defaults to \"base_link\" if\nunspecified world_frame: odom # Defaults to the value of odom_frame if\nunspecified odom0: /odom odom0_config: [false, false, false, false, false,\ntrue, true, true, false, false, false, true, false, false, false]\nodom0_queue_size: 2 odom0_nodelay: false odom0_differential: false\nodom0_relative: false odom0_pose_rejection_threshold: 5\nodom0_twist_rejection_threshold: 1 imu0: /imu/data imu0_config: [false, false,\nfalse, false, false, true, false, false, false, false, false, true, false,\nfalse, false] imu0_nodelay: false imu0_differential: false imu0_relative: true\nimu0_queue_size: 5 imu0_pose_rejection_threshold: 0.8 # Note the difference in\nparameter names imu0_twist_rejection_threshold: 0.8 #\nimu0_linear_acceleration_rejection_threshold: 0.8 #\nimu0_remove_gravitational_acceleration: true use_control: true\nstamped_control: false control_timeout: 0.2 control_config: [true, false,\nfalse, false, false, true] acceleration_limits: [1.3, 0.0, 0.0, 0.0, 0.0, 3.4]\ndeceleration_limits: [1.3, 0.0, 0.0, 0.0, 0.0, 4.5] acceleration_gains: [0.8,\n0.0, 0.0, 0.0, 0.0, 0.9] deceleration_gains: [1.0, 0.0, 0.0, 0.0, 0.0, 1.0]\nprocess_noise_covariance: [0.05, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0.05, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0.03, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0.03, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0.025, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0.025, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.04, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0.01, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0.01, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.02, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0.01, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0.01, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.015]\ninitial_estimate_covariance: [1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n1e-9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1e-9]\n\n\u21a7\n\n#  [ navsat_transform_node outputs\n](//question3152.rssing.com/chan-47151955/article440-live.html)\n\nSeptember 11, 2018, 10:11 am\n\n[ _\u226b_ Next: Configuring robot_localization for odom msgs only\n](//question3152.rssing.com/chan-47151955/all_p23.html#c47151955a441 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Robot Localization with Odometry and UM7\n](//question3152.rssing.com/chan-47151955/all_p22.html#c47151955a439 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion3152.rssing.com%2Fchan-47151955%2Farticle440-live.html\n\"Article Support\")\n\nI am trying to use `robot_localization` package to fuse GPS and IMU to\nlocalize a robot. First, I am just trying to run the package using a provided\n`test1.bag` file. This bag file contains wheel odometry, GPS and IMU data.\nPublished topics: * /fix [sensor_msgs/NavSatFix] 1 publisher *\n/husky_velocity_controller/odom [nav_msgs/Odometry] 1 publisher * /rosout\n[rosgraph_msgs/Log] 1 publisher * /imu/data [sensor_msgs/Imu] 1 publisher *\n/rosout_agg [rosgraph_msgs/Log] 1 publisher * /clock [rosgraph_msgs/Clock] 1\npublisher Subscribed topics: * /rosout [rosgraph_msgs/Log] 1 subscriber When I\nrun my launch file (attached below), `navsat_transform_node` doesn't look like\noutputting correct GPS data on `/odometry/gps` topic. Here is a sample message\nand position x, y, z are always 0. \\--- header: seq: 34 stamp: secs:\n1432235513 nsecs: 236048936 frame_id: \"map\" child_frame_id: '' pose: pose:\nposition: x: 0.0 y: 0.0 z: 0.0 orientation: x: 0.0 y: 0.0 z: 0.0 w: 1.0\ncovariance: [0.8894928039375595, -0.43224622199958357, 0.003407529530502812,\n0.0, 0.0, 0.0, -0.43224622199958346, 3.1603611292875122,\n-0.018528617597497184, 0.0, 0.0, 0.0, 0.003407529530502812,\n-0.018528617597497184, 0.8101460667749296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] twist:\ntwist: linear: x: 0.0 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z: 0.0 covariance:\n[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n0.0, 0.0, 0.0, 0.0, 0.0, 0.0] \\--- I am guessing it has something to do with\nthe warning message? ![image description](/upfiles/15366855064377583.png) Here\nis my launch file:  Here is my .YAML file: ekf_se_odom: frequency: 30\nsensor_timeout: 0.1 two_d_mode: false transform_time_offset: 0.0\ntransform_timeout: 0.0 print_diagnostics: true debug: false map_frame: map\nodom_frame: odom base_link_frame: base_link world_frame: odom odom0:\n/husky_velocity_controller/odom odom0_config: [false, false, false, false,\nfalse, false, true, true, true, false, false, true, false, false, false]\nodom0_queue_size: 10 odom0_nodelay: true odom0_differential: false\nodom0_relative: false imu0: imu/data imu0_config: [false, false, false, true,\ntrue, false, false, false, false, true, true, true, true, true, true]\nimu0_nodelay: false imu0_differential: false imu0_relative: false\nimu0_queue_size: 10 imu0_remove_gravitational_acceleration: true use_control:\nfalse process_noise_covariance: ... initial_estimate_covariance: ...\nekf_se_map: frequency: 30 sensor_timeout: 0.1 two_d_mode: false\ntransform_time_offset: 0.0 transform_timeout: 0.0 print_diagnostics: true\ndebug: false map_frame: map odom_frame: odom base_link_frame: base_link\nworld_frame: map odom0: /husky_velocity_controller/odom odom0_config: [false,\nfalse, false, false, false, false, true, true, true, false, false, true,\nfalse, false, false] odom0_queue_size: 10 odom0_nodelay: true\nodom0_differential: false odom0_relative: false odom1: odometry/gps\nodom1_config: [true, true, false, false, false, false, false, false, false,\nfalse, false, false, false, false, false] odom1_queue_size: 10 odom1_nodelay:\ntrue odom1_differential: false odom1_relative: false imu0: imu/data\nimu0_config: [false, false, false, true, true, false, false, false, false,\ntrue, true, true, true, true, true] imu0_nodelay: true imu0_differential:\nfalse imu0_relative: false imu0_queue_size: 10\nimu0_remove_gravitational_acceleration: true use_control: false\nprocess_noise_covariance: ... initial_estimate_covariance: ...\nnavsat_transform: frequency: 30 delay: 3.0 magnetic_declination_radians:\n0.0429351 # For lat/long 55.944831, -3.186998 yaw_offset: 1.570796327 # IMU\nreads 0 facing magnetic north, not east zero_altitude: false\nbroadcast_utm_transform: true publish_filtered_gps: true use_odometry_yaw:\nfalse wait_for_datum: false Can anyone please point out what I am doing wrong?\nThank you in advance!\n\n\u21a7\n\n[ Remove ADS ](//www.rssing.com/account.php?r=27)\n\nViewing all 521 articles\n\n[ ](//question3152.rssing.com/chan-47151955/all_p21.html \"older\") First Page\n...  Page 20  Page 21  Page 22  Page 23  Page 24  ...  Last Page  [\n](//question3152.rssing.com/chan-47151955/all_p23.html \"newer\")\n\n[ Browse latest ](//question3152.rssing.com/chan-47151955/index-latest.php) [\nView live ](//question3152.rssing.com/chan-47151955/article421-live.html)\n\n* * *\n\nMore Pages to Explore .....\n\n  * [ //apkmirror717.rssing.com/chan-75476424/article41.html ](//apkmirror717.rssing.com/chan-75476424/article41.html)\n  * [ //lordisimo307.rssing.com/chan-17645870/index-page1.html ](//lordisimo307.rssing.com/chan-17645870/index-page1.html)\n  * [ //nightsbridge83.rssing.com/chan-24852476/index-page1.html ](//nightsbridge83.rssing.com/chan-24852476/index-page1.html)\n  * [ //decimal218.rssing.com/chan-51975378/index-page1.html ](//decimal218.rssing.com/chan-51975378/index-page1.html)\n  * [ //thefantasyfix475.rssing.com/chan-17645945/index-latest.php ](//thefantasyfix475.rssing.com/chan-17645945/index-latest.php)\n  * [ //roughriders189.rssing.com/chan-17645322/index-latest.php ](//roughriders189.rssing.com/chan-17645322/index-latest.php)\n  * [ //advised150.rssing.com/chan-75476119/article9.html ](//advised150.rssing.com/chan-75476119/article9.html)\n  * [ //advocating2909.rssing.com/chan-51975165/index-page1.html ](//advocating2909.rssing.com/chan-51975165/index-page1.html)\n  * [ //vergessene196.rssing.com/chan-17645232/article25.html ](//vergessene196.rssing.com/chan-17645232/article25.html)\n  * [ //aqqiah1.rssing.com/chan-34493024/article101.html ](//aqqiah1.rssing.com/chan-34493024/article101.html)\n  * [ //complus11.rssing.com/chan-17645693/index-latest.php ](//complus11.rssing.com/chan-17645693/index-latest.php)\n  * [ //ireland10002.rssing.com/chan-34493064/index-page1.html ](//ireland10002.rssing.com/chan-34493064/index-page1.html)\n  * [ //twitter17421.rssing.com/chan-17645471/article10.html ](//twitter17421.rssing.com/chan-17645471/article10.html)\n  * [ //mattbannister14.rssing.com/chan-24852962/index-latest.php ](//mattbannister14.rssing.com/chan-24852962/index-latest.php)\n  * [ //latin3479.rssing.com/chan-51976324/index-page1.html ](//latin3479.rssing.com/chan-51976324/index-page1.html)\n  * [ //tales3526.rssing.com/chan-42358061/index-page1.html ](//tales3526.rssing.com/chan-42358061/index-page1.html)\n  * [ //elliott2512.rssing.com/chan-42357707/article14.html ](//elliott2512.rssing.com/chan-42357707/article14.html)\n  * [ //realty3005.rssing.com/chan-24852848/index-page1.html ](//realty3005.rssing.com/chan-24852848/index-page1.html)\n  * [ //inhumane102.rssing.com/chan-8557661/article6.html ](//inhumane102.rssing.com/chan-8557661/article6.html)\n  * [ //junqueira56.rssing.com/chan-51975502/index-latest.php ](//junqueira56.rssing.com/chan-51975502/index-latest.php)\n\n* * *\n\n* * *\n\n[ Search ](javascript:;)\n\nRSSing.com\n\n* * *\n\n##  Top-Rated Images\n\n[ \u2182\n](////learn4804.rssing.com/chan-65098560/article5050.html#c65098560a5050i1047598914\n\"Class 10 Sanskrit Grammar Book Solutions \u0938\u0928\u094d\u0927\u093f\u0903\")\n\n![Class 10 Sanskrit Grammar Book Solutions \u0938\u0928\u094d\u0927\u093f\u0903](//www.learncbse.in/wp-\ncontent/uploads/2017/08/NCERT-Solutions-for-Class-10th-Sanskrit-\nChapter-1-\u0938\u0928\u094d\u0927\u093f-1.jpg)\n\n###  [ Class 10 Sanskrit Grammar Book Solutions \u0938\u0928\u094d\u0927\u093f\u0903\n](////learn4804.rssing.com/chan-65098560/article5050.html#c65098560a5050i1047598914)\n\n[ \u2182\n](////starve149.rssing.com/chan-67795027/article12985.html#c67795027a12985i625842650\n\"Giant Crop Cheat Sheet\")\n\n![Giant Crop Cheat\nSheet](//s3.amazonaws.com/kleiforums/monthly_2021_01/1434035901_SpringGiantCrops.thumb.png.da7c62531af2e491e13151bbb10b0f2f.png)\n\n###  [ Giant Crop Cheat Sheet\n](////starve149.rssing.com/chan-67795027/article12985.html#c67795027a12985i625842650)\n\n[ \u2182\n](////daily12844.rssing.com/chan-58023368/article3450.html#c58023368a3450i2041549972\n\"Who Is Junior Pope?| Biography| Profile| History Of Nollywood Actor \u201cPope\nObumneme Odonwodo\u201d Popularly known as \u201cJunior Pope\u201d\")\n\n![Who Is Junior Pope?| Biography| Profile| History Of Nollywood Actor \u201cPope\nObumneme Odonwodo\u201d Popularly known as \u201cJunior\nPope\u201d](//i2.wp.com/austinemedia.com/wp-\ncontent/uploads/2017/05/jp2.jpg?resize=642%2C361)\n\n###  [ Who Is Junior Pope?| Biography| Profile| History Of Nollywood Actor\n\u201cPope Obumneme Odonwodo\u201d Popularly known as \u201cJunior Pope\u201d\n](////daily12844.rssing.com/chan-58023368/article3450.html#c58023368a3450i2041549972)\n\n[ \u2182\n](////topics4280.rssing.com/chan-62228694/article43158.html#c62228694a43158i1887057775\n\"Wondershare PDFelement v7.x.x Patch v3.4 By Deltafox\")\n\n![Wondershare PDFelement v7.x.x Patch v3.4 By\nDeltafox](//i.imgur.com/u8v9Ga1.jpg)\n\n###  [ Wondershare PDFelement v7.x.x Patch v3.4 By Deltafox\n](////topics4280.rssing.com/chan-62228694/article43158.html#c62228694a43158i1887057775)\n\n[ \u2182\n](////downloadhub26.rssing.com/chan-63389705/article159.html#c63389705a159i1981662480\n\"Good Will Hunting 1997 Dual Audio 720p BRRip \\[Hindi \u2013 English\\] ESubs\")\n\n![Good Will Hunting 1997 Dual Audio 720p BRRip \\[Hindi \u2013 English\\]\nESubs](//i0.wp.com/2.bp.blogspot.com/-BNeRHGE6vos/V1gESmKp3AI/AAAAAAAADVM/SBOnE2K617oqzf7FLZQMMtFmvLYnIJqegCLcB/s1600/Good%2BWill%2BHunting%2B%25281997%2529%2BBluray.jpg?resize=350%2C450&ssl=1)\n\n###  [ Good Will Hunting 1997 Dual Audio 720p BRRip [Hindi \u2013 English] ESubs\n](////downloadhub26.rssing.com/chan-63389705/article159.html#c63389705a159i1981662480)\n\n[ \u2182\n](////kerala860.rssing.com/chan-63836988/article296.html#c63836988a296i25562831\n\"Kerala Christian Convention Maramon 2018 Songs Lyrics\")\n\n![Kerala Christian Convention Maramon 2018 Songs\nLyrics](//2.bp.blogspot.com/-3Ma00SZ4B5c/WsT8cNOvj7I/AAAAAAAAFTg/ddTpRksYfOQ7lhUTgOQr6HdEcVcWHjkxQCLcBGAs/s1600/Maramon%2BConvention%2B2018%2BSongs%2BLyrics8.jpg)\n\n###  [ Kerala Christian Convention Maramon 2018 Songs Lyrics\n](////kerala860.rssing.com/chan-63836988/article296.html#c63836988a296i25562831)\n\n[ \u2182\n](////cigar1191.rssing.com/chan-66583770/article5.html#c66583770a5i1448705673\n\"Royals by Lorde \u2013 3-string Open G \u201cGDG\u201d\u2013 Tablature and Chords for Cigar Box\nGuitar\")\n\n![Royals by Lorde \u2013 3-string Open G \u201cGDG\u201d\u2013 Tablature and Chords for Cigar Box\nGuitar](//www.cigarboxguitar.com/wp-content/uploads/2015/01/Royals-by-Lorde-\nPDF-Screenshot-227x300.jpg)\n\n###  [ Royals by Lorde \u2013 3-string Open G \u201cGDG\u201d\u2013 Tablature and Chords for Cigar\nBox Guitar\n](////cigar1191.rssing.com/chan-66583770/article5.html#c66583770a5i1448705673)\n\n[ \u2182\n](////murder540.rssing.com/chan-6412619/article1.html#c6412619a1i1155785771\n\"Murder in Australia: 2010\")\n\n![Murder in Australia:\n2010](//2.bp.blogspot.com/-zEjZIawSSso/UMBtH81fykI/AAAAAAAAAMU/PNsllPLf124/s640/hunterian.jpg)\n\n###  [ Murder in Australia: 2010\n](////murder540.rssing.com/chan-6412619/article1.html#c6412619a1i1155785771)\n\n[ \u2182\n](////brokerage105.rssing.com/chan-6647811/article3361.html#c6647811a3361i1214292647\n\"Robert Lyn Nelson - \")\n\n![Robert Lyn Nelson -\n](//www.artbrokerage.com/art/nelsonrobert/_images/nelsonrobert_58879_2.jpg)\n\n###  [ Robert Lyn Nelson - \"Faces of Africa\"\n](////brokerage105.rssing.com/chan-6647811/article3361.html#c6647811a3361i1214292647)\n\n[ \u2182\n](////salina38.rssing.com/chan-7227570/article681.html#c7227570a681i1053563629\n\"Saline County Jail Booking Activity \u2013 Saturday, May 30th\")\n\n![Saline County Jail Booking Activity \u2013 Saturday, May\n30th](//thepost.s3.amazonaws.com/wp-content/uploads/2015/05/Weis-Sheets-\nAshley-Jane-300x203.jpg)\n\n###  [ Saline County Jail Booking Activity \u2013 Saturday, May 30th\n](////salina38.rssing.com/chan-7227570/article681.html#c7227570a681i1053563629)\n\n[ \u2182\n](////myanmar19.rssing.com/chan-7313589/article889.html#c7313589a889i784670228\n\"Last Day of Yangon Thingyan Festival Celebration 2014\")\n\n![Last Day of Yangon Thingyan Festival Celebration\n2014](//1.bp.blogspot.com/-QCOXV-h52KE/U06vO3LGp6I/AAAAAAACCzk/eFTAQF1gkxk/s1600/IMG_9920.jpg)\n\n###  [ Last Day of Yangon Thingyan Festival Celebration 2014\n](////myanmar19.rssing.com/chan-7313589/article889.html#c7313589a889i784670228)\n\n[ \u2182 ](////nazam1.rssing.com/chan-8572938/article97.html#c8572938a97i52404577\n\"Ghafil Tujhe Gharyal Ye Deta Hai Manadi\")\n\n![Ghafil Tujhe Gharyal Ye Deta Hai\nManadi](//lh4.ggpht.com/-Tms8XN2rRKk/UbaawljfJEI/AAAAAAAAJks/DuLSCBxA3v8/Inspiration-\nwatch-poetry_thumb%25255B3%25255D.jpg?imgmax=800)\n\n###  [ Ghafil Tujhe Gharyal Ye Deta Hai Manadi\n](////nazam1.rssing.com/chan-8572938/article97.html#c8572938a97i52404577)\n\n[ \u2182\n](////arrests130.rssing.com/chan-8670761/article2736.html#c8670761a2736i331208640\n\"CALIFORNIA: DUI arrests by Chico Police March 2019\")\n\n![CALIFORNIA: DUI arrests by Chico Police March\n2019](//i2.wp.com/www.dwihitparade.com/wp-\ncontent/uploads/2019/04/Sean-P.-Biswurm-33-of-Chico-Calif.-DUI-arrest-on-\nMarch-18-2019-by-Chico-Police.png?w=550)\n\n###  [ CALIFORNIA: DUI arrests by Chico Police March 2019\n](////arrests130.rssing.com/chan-8670761/article2736.html#c8670761a2736i331208640)\n\n[ \u2182\n](////salawats2.rssing.com/chan-11490042/article47.html#c11490042a47i371003744\n\"Duas for Difficulties, Ism Adham-'Allah\u2019s Greatest Name' and Secrets of Ya\nHayyu Ya Qayyum\")\n\n![Duas for Difficulties, Ism Adham-'Allah\u2019s Greatest Name' and Secrets of Ya\nHayyu Ya\nQayyum](//2.bp.blogspot.com/-IJM3qg4P1NQ/Ugc0BBcHquI/AAAAAAAAAVc/XjnDYEvefA8/s400/Istighfar+al-\nKabir.jpg)\n\n###  [ Duas for Difficulties, Ism Adham-'Allah\u2019s Greatest Name' and Secrets of\nYa Hayyu Ya Qayyum\n](////salawats2.rssing.com/chan-11490042/article47.html#c11490042a47i371003744)\n\n[ \u2182\n](////electro404.rssing.com/chan-13553321/article484.html#c13553321a484i592237786\n\"PANASONIC SC AKX50LB - CD Stereo system - Power Amp - Main power SMPS -\nSchematic \\(Circuit Diagram\\) - C1BA00000497 \\(Power Amp IC\\) -\\[TDA 8950J\\]\n\")\n\n![PANASONIC SC AKX50LB - CD Stereo system - Power Amp - Main power SMPS -\nSchematic \\(Circuit Diagram\\) - C1BA00000497 \\(Power Amp IC\\) -\\[TDA 8950J\\]\n](//4.bp.blogspot.com/-QQbgcQ8R1MM/UicZj96-4MI/AAAAAAAA4No/YLSvbnvbK5I/s1600/Power+Amp+Circuit.bmp)\n\n###  [ PANASONIC SC AKX50LB - CD Stereo system - Power Amp - Main power SMPS -\nSchematic (Circuit Diagram) - C1BA00000497 (Power Amp IC) -[TDA 8950J]\n](////electro404.rssing.com/chan-13553321/article484.html#c13553321a484i592237786)\n\n[ \u2182\n](////heroturko111.rssing.com/chan-16832457/article82.html#c16832457a82i1004730930\n\"Noise Industries FxFactory Pro 3.0.2 \\[MAC\\]\")\n\n![Noise Industries FxFactory Pro 3.0.2 \\[MAC\\]](//www.techwench.com/wp-\ncontent/uploads/2010/11/Noise-Industries-FxFactory-Pro-2.jpg)\n\n###  [ Noise Industries FxFactory Pro 3.0.2 [MAC]\n](////heroturko111.rssing.com/chan-16832457/article82.html#c16832457a82i1004730930)\n\n[ \u2182\n](////filator3.rssing.com/chan-3245654/article2282.html#c3245654a2282i1151529573\n\"Hustisya para kay Randy Echanis\")\n\n![Hustisya para kay Randy Echanis](//www.pinoyweekly.org/wp-\ncontent/uploads/2020/08/PW-randy-echanis-featured.jpg)\n\n###  [ Hustisya para kay Randy Echanis\n](////filator3.rssing.com/chan-3245654/article2282.html#c3245654a2282i1151529573)\n\n[ \u2182\n](////drama1031.rssing.com/chan-27446141/article21.html#c27446141a21i856785604\n\"Za Pakhtoon Yum: A mind-altering foray into Pukhtun life and culture\")\n\n![Za Pakhtoon Yum: A mind-altering foray into Pukhtun life and\nculture](//blogs.tribune.com.pk/application/../wp-\ncontent/uploads/2014/10/24552-zpy-1414239961-635-160x120.jpg)\n\n###  [ Za Pakhtoon Yum: A mind-altering foray into Pukhtun life and culture\n](////drama1031.rssing.com/chan-27446141/article21.html#c27446141a21i856785604)\n\n[ \u2182\n](////metro2989.rssing.com/chan-40972540/article57410.html#c40972540a57410i495009908\n\"The Umbrella Academy\u2019s Justin Min shares adorable first selfie with new\nboyfriend\")\n\n![The Umbrella Academy\u2019s Justin Min shares adorable first selfie with new\nboyfriend](//metro.co.uk/wp-content/uploads/2020/03/JUSTIN-MIN-2-0be4.png)\n\n###  [ The Umbrella Academy\u2019s Justin Min shares adorable first selfie with new\nboyfriend\n](////metro2989.rssing.com/chan-40972540/article57410.html#c40972540a57410i495009908)\n\n[ \u2182\n](////fonts1404.rssing.com/chan-57741102/article185.html#c57741102a185i1833605640\n\"Pumas 2022/2023 Font \\(TTF & OTF\\)\")\n\n![Pumas 2022/2023 Font \\(TTF &\nOTF\\)](//footballfonts.com/u/img/pumas-22-23-otf-font-installation.jpg)\n\n###  [ Pumas 2022/2023 Font (TTF & OTF)\n](////fonts1404.rssing.com/chan-57741102/article185.html#c57741102a185i1833605640)\n\n\u02c2\n\n\u02c3\n\n####  Latest Images\n\n[ ![Very Hungry Caterpillar\u2122 Shirt: World of Eric Carle\u2122+ Little Goodall\nby...](//i.etsystatic.com/6018612/r/il/7591e4/3868173454/il_570xN.3868173454_gxfr.jpg)\n](////cryptomnesia.rssing.com/chan-1183730/article16627.html#c1183730a16627i1139077293)\n\n###  [ Very Hungry Caterpillar\u2122 Shirt: World of Eric Carle\u2122+ Little Goodall\nby...\n](////cryptomnesia.rssing.com/chan-1183730/article16627.html#c1183730a16627i1139077293)\n\nApril 14, 2024, 8:14 am\n\n[ ![Have you seen Michael Wines? Burien man has been missing since\nSaturday,...](//b-townblog.com/wp-\ncontent/uploads/2024/04/michael-3shoe.jpg?_t=1712879471)\n](////normandy480.rssing.com/chan-74604448/article56.html#c74604448a56i1857302427)\n\n###  [ Have you seen Michael Wines? Burien man has been missing since\nSaturday,...\n](////normandy480.rssing.com/chan-74604448/article56.html#c74604448a56i1857302427)\n\nApril 12, 2024, 3:59 pm\n\n[ ![Stay Salty POTS Awareness Stretchy Stacking Bracelets | Set of\nThree|...](//i.etsystatic.com/28677176/r/il/b2413c/4350795851/il_570xN.4350795851_fflz.jpg)\n](////pomaces4.rssing.com/chan-3795444/article11960.html#c3795444a11960i1086411135)\n\n###  [ Stay Salty POTS Awareness Stretchy Stacking Bracelets | Set of\nThree|...\n](////pomaces4.rssing.com/chan-3795444/article11960.html#c3795444a11960i1086411135)\n\nApril 11, 2024, 5:27 pm\n\n[ ![19 Reader-Favourite March Purchases \u2014 From Steals To\nSplurges](//www.refinery29.com/images/11700602.png?auto=webp&width=750&height=938&quality=85&crop=375:469)\n](////refinery1042.rssing.com/chan-72297680/article18978.html#c72297680a18978i1490871663)\n\n###  [ 19 Reader-Favourite March Purchases \u2014 From Steals To Splurges\n](////refinery1042.rssing.com/chan-72297680/article18978.html#c72297680a18978i1490871663)\n\nApril 11, 2024, 5:07 am\n\n[ ![Fake lip ring, silver lip ring, simple lip ring, unisex lip ring by\nAIRlab](//i.etsystatic.com/10798216/r/il/3a91cc/761285074/il_570xN.761285074_fu8j.jpg)\n](////kuteriot1.rssing.com/chan-5865851/article17035.html#c5865851a17035i913072506)\n\n###  [ Fake lip ring, silver lip ring, simple lip ring, unisex lip ring by\nAIRlab\n](////kuteriot1.rssing.com/chan-5865851/article17035.html#c5865851a17035i913072506)\n\nApril 9, 2024, 4:00 pm\n\n[ ![First Pictures of the Eclipse ! !\n!](//thepeoplescube.com/red/download/file.php?id=57244&sid=5311a0068099bb708e6eae6fd0456e59)\n](////political6691.rssing.com/chan-78391714/article69.html#c78391714a69i477360060)\n\n###  [ First Pictures of the Eclipse ! ! !\n](////political6691.rssing.com/chan-78391714/article69.html#c78391714a69i477360060)\n\nApril 8, 2024, 1:08 pm\n\n[ ![People's Blog \u2022 First Pictures of the Eclipse ! !\n!](//thepeoplescube.com/red/download/file.php?id=57243&sid=3721c68912ad1a7b63f4cf1eafba9b41)\n](////satire3490.rssing.com/chan-77006292/article253.html#c77006292a253i838655542)\n\n###  [ People's Blog \u2022 First Pictures of the Eclipse ! ! !\n](////satire3490.rssing.com/chan-77006292/article253.html#c77006292a253i838655542)\n\nApril 8, 2024, 1:08 pm\n\n[ ![People's Blog \u2022 First Pictures of the Eclipse ! !\n!](//thepeoplescube.com/red/download/file.php?id=57243&sid=d61d4527be50ef499d8f3761aad83688)\n](////satire6144.rssing.com/chan-78334822/article122.html#c78334822a122i1295535114)\n\n###  [ People's Blog \u2022 First Pictures of the Eclipse ! ! !\n](////satire6144.rssing.com/chan-78334822/article122.html#c78334822a122i1295535114)\n\nApril 8, 2024, 1:08 pm\n\n[ ![Highlights - Bringing young people to the forefront of EU policy making\n-...](//www.europarl.europa.eu/resources/library/images/20200115PHT70307/20200115PHT70307-ms.jpg)\n](////europees185.rssing.com/chan-78228109/article559.html#c78228109a559i1335926349)\n\n###  [ Highlights - Bringing young people to the forefront of EU policy making\n-...\n](////europees185.rssing.com/chan-78228109/article559.html#c78228109a559i1335926349)\n\nApril 8, 2024, 8:41 am\n\n[ ![People's Blog \u2022 Germany Bans the Number\n44](//thepeoplescube.com/red/download/file.php?id=57239&sid=5e19e13fd670da65c8b6b496c0630b51)\n](////political6769.rssing.com/chan-78425830/article66.html#c78425830a66i1994484930)\n\n###  [ People's Blog \u2022 Germany Bans the Number 44\n](////political6769.rssing.com/chan-78425830/article66.html#c78425830a66i1994484930)\n\nApril 8, 2024, 2:19 am\n\n  * [ RSSing>> ](//www.rssing.com/index.php)\n  * [ Latest ](//www.rssing.com/index.php?l=l)\n  * [ Popular ](//www.rssing.com/index.php?l=p)\n  * [ Top Rated ](//www.rssing.com/index.php?l=r)\n  * [ Trending ](//www.rssing.com/index.php?l=t)\n\n\u00a9 2024 //www.rssing.com\n\n"
  },
  {
    "id": "spawn_gui/tutorialstutrosrosla.txt",
    "content": "Toggle navigation  [\n![gazebo](/assets/masthead-0bd44817978df8069f427d8ca1657998789065a2b242edfd1a3d8ab4a329dd4c.png)\n](/)\n\n  * [ Tutorials ](/tutorials)\n  * [ Download ](/download)\n  * [ Blog ](/blog.html)\n  * [ Media ](/media)\n  * [ Projects ](/projects)\n\n__\n\n** WARNING ** : This documentation is for Gazebo-classic, which has been\nsuperseded by Gazebo. [ Click here to see the documentation for the latest\nGazebo release ](https://gazebosim.org/docs)\n\n[ Back ](/tutorials?cat=install)\n\n#  Using roslaunch\n\n[ Edit\n](https://github.com/osrf/gazebo_tutorials/blob/master/ros_roslaunch/tutorial.md)\nVersion: 1.9+\n\n* * *\n\n####  Table of Contents\n\n#  Tutorial: Using roslaunch to start Gazebo, world files and URDF models\n\nThere are many ways to start Gazebo, open world models and spawn robot models\ninto the simulated environment. In this tutorial we cover the ROS-way of doing\nthings: using ` rosrun ` and ` roslaunch ` . This includes storing your URDF\nfiles in ROS packages and keeping your various resource paths relative to your\nROS workspace.\n\n##  Using ` roslaunch ` to Open World Models\n\nThe [ roslaunch ](http://www.ros.org/wiki/roslaunch) tool is the standard\nmethod for starting ROS nodes and bringing up robots in ROS. To start an empty\nGazebo world similar to the ` rosrun ` command in the previous tutorial,\nsimply run\n\n    \n    \n    roslaunch gazebo_ros empty_world.launch\n    \n\n###  ` roslaunch ` Arguments\n\nYou can append the following arguments to the launch files to change the\nbehavior of Gazebo:\n\n**paused**\n\n> Start Gazebo in a paused state (default false)\n\n**use_sim_time**\n\n> Tells ROS nodes asking for time to get the Gazebo-published simulation time,\n> published over the ROS topic /clock (default true)\n\n**gui**\n\n> Launch the user interface window of Gazebo (default true)\n\n**headless** (deprecated) **recording** (previously called headless)\n\n> Enable gazebo state log recording\n\n**debug**\n\n> Start gzserver (Gazebo Server) in debug mode using gdb (default false)\n\n**verbose**\n\n> Run gzserver and gzclient with --verbose, printing errors and warnings to\n> the terminal (default false)\n\n**server_required**\n\n> Terminate launch script when gzserver (Gazebo Server) exits (default false)\n\n**gui_required**\n\n> Terminate launch script when gzclient (user interface window) exits (default\n> false)\n\n###  Example ` roslaunch ` command\n\nNormally the default values for these arguments are all you need, but just as\nan example:\n\n    \n    \n    roslaunch gazebo_ros empty_world.launch paused:=true use_sim_time:=false gui:=true throttled:=false recording:=false debug:=true verbose:=true gui_required:=true\n    \n\n###  Launching Other Demo Worlds\n\nOther demo worlds are already included in the ` gazebo_ros ` package,\nincluding:\n\n    \n    \n    roslaunch gazebo_ros willowgarage_world.launch\n    roslaunch gazebo_ros mud_world.launch\n    roslaunch gazebo_ros shapes_world.launch\n    roslaunch gazebo_ros rubble_world.launch\n    \n\nNotice in ` mud_world.launch ` a simple jointed mechanism is launched. The\nlaunch file for ` mud_world.launch ` contains the following:\n\n    \n    \n    <launch>\n      <!-- We resume the logic in empty_world.launch, changing only the name of the world to be launched -->\n      <include file=\"$(find gazebo_ros)/launch/empty_world.launch\">\n        <arg name=\"world_name\" value=\"worlds/mud.world\"/> <!-- Note: the world_name is with respect to GAZEBO_RESOURCE_PATH environmental variable -->\n        <arg name=\"paused\" value=\"false\"/>\n        <arg name=\"use_sim_time\" value=\"true\"/>\n        <arg name=\"gui\" value=\"true\"/>\n        <arg name=\"recording\" value=\"false\"/>\n        <arg name=\"debug\" value=\"false\"/>\n      </include>\n    </launch>\n    \n\nIn this launch file we inherit most of the necessary functionality from\nempty_world.launch. The only parameter we need to change is the ` world_name `\nparameter, substituting the ` empty.world ` world file with the ` mud.world `\nfile. The other arguments are simply set to their default values.\n\n###  World Files\n\nContinuing with our examination of the ` mud_world.launch ` file, we will now\nlook at the contents of the ` mud.world ` file. The first several components\nof the mud world is shown below:\n\n    \n    \n      <sdf version=\"1.4\">\n        <world name=\"default\">\n          <include>\n            <uri>model://sun</uri>\n          </include>\n          <include>\n            <uri>model://ground_plane</uri>\n          </include>\n          <include>\n            <uri>model://double_pendulum_with_base</uri>\n            <name>pendulum_thick_mud</name>\n            <pose>-2.0 0 0 0 0 0</pose>\n          </include>\n          ...\n        </world>\n      </sdf>\n    \n\n**See the section below to view this full world file on your computer.**\n\nIn this world file snippet you can see that three models are referenced. The\nthree models are searched for within your local Gazebo Model Database. If not\nfound there, they are automatically pulled from Gazebo's online database.\n\nYou can learn more about world files in the [ Build A World\n](/tutorials?cat=build_world) tutorial.\n\n####  Finding World Files On Your Computer\n\nWorld files are found within the ` /worlds ` directory of your Gazebo resource\npath. The location of this path depends on how you installed Gazebo and the\ntype of system your are on. To find the location of your Gazebo resources, use\nthe following command:\n\n    \n    \n    env | grep GAZEBO_RESOURCE_PATH\n    \n\nAn typical path might be something like ` /usr/local/share/gazebo-1.9 ` . Add\n` /worlds ` to the end of the path and you should have the directory\ncontaining the world files Gazebo uses, including the ` mud.world ` file.\n\n##  Creating your own Gazebo ROS Package\n\nBefore continuing on how to spawn robots into Gazebo, we will first go over\nfile hierarchy standards for using ROS with Gazebo so that we can make later\nassumptions.\n\nFor now, we will assume your catkin workspace is named ` catkin_ws ` , though\nyou can name this to whatever you want. Thus, your catkin workspace might be\nlocated on your computer at something like:\n\n    \n    \n    /home/user/catkin_ws/src\n    \n\nEverything concerning your robot's model and description is located, as per\nROS standards, in a package named ` /MYROBOT_description ` and all the world\nfiles and launch files used with Gazebo is located in a ROS package named `\n/MYROBOT_gazebo ` . Replace 'MYROBOT' with the name of your bot in lower case\nletters. With these two packages, your hierarchy should be as follows:\n\n    \n    \n    ../catkin_ws/src\n        /MYROBOT_description\n            package.xml\n            CMakeLists.txt\n            /urdf\n                MYROBOT.urdf\n            /meshes\n                mesh1.dae\n                mesh2.dae\n                ...\n            /materials\n            /cad\n        /MYROBOT_gazebo\n            /launch\n                MYROBOT.launch\n            /worlds\n                MYROBOT.world\n            /models\n                world_object1.dae\n                world_object2.stl\n                world_object3.urdf\n            /materials\n            /plugins\n    \n\nRemember that the command ` catkin_create_pkg ` is used for creating new\npackages, though this can also easily be adapted for rosbuild if you must.\nMost of these folders and files should be self explanatory.\n\nThe next section will walk you through making some of this setup for use with\na custom world file.\n\n###  Creating a Custom World File\n\nYou can create custom ` .world ` files within your own ROS packages that are\nspecific to your robots and packages. In this mini tutorial we'll make an\nempty world with a ground, a sun, and a gas station. The following is our\nrecommended convention. Be sure to replace MYROBOT with the name of your bot,\nor if you don't have a robot to test with just replace it with something like\n'test':\n\n  * Create a ROS package with the convention MYROBOT_gazebo \n  * Within this package, create a ` launch ` folder \n  * Within the ` launch ` folder create a YOUROBOT.launch file with the following contents (default arguments excluded): \n\n    \n    \n    <launch>\n      <!-- We resume the logic in empty_world.launch, changing only the name of the world to be launched -->\n      <include file=\"$(find gazebo_ros)/launch/empty_world.launch\">\n        <arg name=\"world_name\" value=\"$(find MYROBOT_gazebo)/worlds/MYROBOT.world\"/>\n        <!-- more default parameters can be changed here -->\n      </include>\n    </launch>\n    \n\n  * Within the same package, create a ` worlds ` folder, and create a MYROBOT.world file with the following contents: \n\n    \n    \n    <?xml version=\"1.0\" ?>\n    <sdf version=\"1.4\">\n      <world name=\"default\">\n        <include>\n          <uri>model://ground_plane</uri>\n        </include>\n        <include>\n          <uri>model://sun</uri>\n        </include>\n        <include>\n          <uri>model://gas_station</uri>\n          <name>gas_station</name>\n          <pose>-2.0 7.0 0 0 0 0</pose>\n        </include>\n      </world>\n    </sdf>\n    \n\n  * You should now be able to launch your custom world (with a gas station) into Gazebo using the following command: \n\n    \n    \n    . ~/catkin_ws/devel/setup.bash\n    roslaunch MYROBOT_gazebo MYROBOT.launch\n    \n\nYou should see the following world model (zoom out with the scroll wheel on\nyour mouse):\n\n![](https://github.com/osrf/gazebo_tutorials/raw/master/ros_roslaunch/figs/GasStation.png)\n\nFor the rest of the tutorial, your MYROBOT_gazebo empty world needs to be\nrunning.\n\n###  Editing the World File Within Gazebo\n\nYou can insert additional models into your robot's world file and use the `\nFile->Save ` As command to export your edited world back into your ROS\npackage.\n\n##  Using ` roslaunch ` to Spawn URDF Robots\n\nThere are two ways to launch your URDF-based robot into Gazebo using `\nroslaunch ` :\n\n**ROS Service Call Spawn Method**\n\n> The first method keeps your robot's ROS packages more portable between\n> computers and repository check outs. It allows you to keep your robot's\n> location relative to a ROS package path, but also requires you to make a ROS\n> service call using a small (python) script.\n\n**Model Database Method**\n\n> The second method allows you to include your robot within the ` .world `\n> file, which seems cleaner and more convenient but requires you to add your\n> robot to the Gazebo model database by setting an environment variable.\n\nWe will go over both methods. Overall our recommended method is using the\n'''ROS Service Call Spawn Method'''\n\n###  \"ROS Service Call\" Robot Spawn Method\n\nThis method uses a small python script called ` spawn_model ` to make a\nservice call request to the ` gazebo_ros ` ROS node (named simply \"gazebo\" in\nthe rostopic namespace) to add a custom URDF into Gazebo. The ` spawn_model `\nscript is located within the ` gazebo_ros ` package. You can use this script\nin the following way:\n\n    \n    \n    rosrun gazebo_ros spawn_model -file `rospack find MYROBOT_description`/urdf/MYROBOT.urdf -urdf -x 0 -y 0 -z 1 -model MYROBOT\n    \n\nTo see all of the available arguments for ` spawn_model ` including\nnamespaces, trimesh properties, joint positions and RPY orientation run:\n\n    \n    \n    rosrun gazebo_ros spawn_model -h\n    \n\n####  URDF Example with Baxter\n\nIf you do not yet have a URDF to test, as an example you can download the\nbaxter_description package from Rethink Robotics's [ baxter_common\n](https://github.com/RethinkRobotics/baxter_common) repo. Put this package\ninto your catkin workspace by running:\n\n    \n    \n    git clone https://github.com/RethinkRobotics/baxter_common.git\n    \n\nYou should now have a URDF file named ` baxter.urdf ` located in a within\nbaxter_description/urdf/, and you can run:\n\n    \n    \n    rosrun gazebo_ros spawn_model -file `rospack find baxter_description`/urdf/baxter.urdf -urdf -z 1 -model baxter\n    \n\nYou should then see something similar to:\n\n![](https://github.com/osrf/gazebo_tutorials/raw/master/ros_roslaunch/figs/Gas_baxter.png)\n\nTo integrate this directly into a ROS launch file, reopen the file `\nMYROBOT_gazebo/launch/YOUROBOT.launch ` and add the following before the `\n</launch> ` tag:\n\n    \n    \n    <!-- Spawn a robot into Gazebo -->\n    <node name=\"spawn_urdf\" pkg=\"gazebo_ros\" type=\"spawn_model\" args=\"-file $(find baxter_description)/urdf/baxter.urdf -urdf -z 1 -model baxter\" />\n    \n\nLaunching this file, you should see the same results as when using ` rosrun `\n.\n\n####  XACRO Example with PR2\n\nIf your URDF is not in XML format but rather in [ XACRO\n](http://ros.org/wiki/xacro) format, you can make a similar modification to\nyour launch file. You can run this PR2 example by installing this package:\n\n**ROS Jade:**\n\n    \n    \n    sudo apt-get install ros-jade-pr2-common\n    \n\nThen adding this to your launch file created previously in this tutorial:\n\n    \n    \n    <!-- Convert an xacro and put on parameter server -->\n    <param name=\"robot_description\" command=\"$(find xacro)/xacro.py $(find pr2_description)/robots/pr2.urdf.xacro\" />\n    \n    <!-- Spawn a robot into Gazebo -->\n    <node name=\"spawn_urdf\" pkg=\"gazebo_ros\" type=\"spawn_model\" args=\"-param robot_description -urdf -model pr2\" />\n    \n\nLaunching this file, you should see the PR2 in the gas station as pictured:\n\n![](https://github.com/osrf/gazebo_tutorials/raw/master/ros_roslaunch/figs/PR2_GasStation.png)\n\nNote: at this writing there are still a lot of errors and warnings from the\nconsole output that need to be fixed from the PR2's URDF due to Gazebo API\nchanges.\n\n* * *\n\n###  \"Model Database\" Robot Spawn Method\n\nThe second method of spawning robots into Gazebo allows you to include your\nrobot within the ` .world ` file, which seems cleaner and more convenient but\nalso requires you to add your robot to the Gazebo model database by setting an\nenvironment variable. This environment variable is required because of the\nseparation of ROS dependencies from Gazebo; URDF package paths cannot be used\ndirectly inside ` .world ` files because Gazebo does not have a notion of ROS\npackages.\n\nTo accomplish this method, you must make a new model database that contains\njust your single robot. This isn't the cleanest way to load your URDF into\nGazebo but accomplishes the goal of not having to keep two copies of your\nrobot URDF on your computer. If the following instructions are confusing,\nrefer back to the [ Gazebo Model Database\n](http://gazebosim.org/user_guide/started__models__database.html)\ndocumentation to understand why these steps are required.\n\nWe will assume your ROS workspace file hierarchy is setup as described in the\nabove sections. The only difference is that now a ` model.config ` file is\nadded to your ` MYROBOT_description ` package like so:\n\n    \n    \n    ../catkin_ws/src\n        /MYROBOT_description\n            package.xml\n            CMakeLists.txt\n            model.config\n            /urdf\n                MYROBOT.urdf\n            /meshes\n                mesh1.dae\n                mesh2.dae\n                ...\n            /materials\n            /plugins\n            /cad\n    \n\nThis hierarchy is specially adapted for use as a Gazebo model database by\nmeans of the following folders/files:\n\n  * **/home/user/catkin_workspace/src** \\- this is treated as the location of a Gazebo Model Database \n  * **/MYROBOT_description** \\- this directory is treated as a single Gazebo model folder \n  * **model.config** \\- this is a required configuration file for Gazebo to find this model in its database \n  * **MYROBOT.urdf** \\- this is your robot description file, also used by Rviz, MoveIt!, etc \n  * **/meshes** \\- put your .stl or .dae files in here, just as you would with regular URDFs \n\n####  model.config\n\nEach model must have a model.config file in the model's root directory that\ncontains meta information about the model. Basically copy this into a\nmodel.config file, replacing MYROBOT.urdf with your file name:\n\n    \n    \n      <?xml version=\"1.0\"?>\n      <model>\n        <name>MYROBOT</name>\n        <version>1.0</version>\n        <sdf>urdf/MYROBOT.urdf</sdf>\n        <author>\n          <name>My name</name>\n          <email>name@email.address</email>\n        </author>\n        <description>\n          A description of the model\n        </description>\n      </model>\n    \n\nUnlike for SDFs, no version is required for the  tag when it is used for\nURDFs. See the Gazebo Model Database documentation for more info.\n\n####  Environment Variable\n\nFinally, you need to add an environment variable to your .bashrc file that\ntells Gazebo where to look for model databases. Using the editor of your\nchoice edit \"~/.bashrc\". Check if you already have a ` GAZEBO_MODEL_PATH `\ndefined. If you already have one, append to it using a semi-colon, otherwise\nadd the new export. Assuming your Catkin workspace is in ` ~/catkin_ws/ ` Your\npath should look something like:\n\n    \n    \n      export GAZEBO_MODEL_PATH=/home/user/catkin_ws/src/\n    \n\n####  Viewing In Gazebo - Manually\n\nNow test to see if your new Gazebo Model Database is properly configured by\nlaunching Gazebo:\n\n    \n    \n      gazebo\n    \n\nAnd clicking the \"Insert\" tab on the left. You will probably see several\ndifferent drop down lists that represent different model databases available\non your system, including the online database. Find the database corresponding\nto your robot, open the sub menu, click on the name of your robot and then\nchoose a location within Gazebo to place the robot, using your mouse.\n\n####  Viewing In Gazebo - ` roslaunch ` with the Model Database\n\nThe advantage of the model database method is that now you can include your\nrobot directly within your world files, without using a ROS package path.\nWe'll use the same setup from the section \"Creating a world file\" but modify\nthe world file:\n\n  * Within the same ` MYROBOT_description/launch ` folder, edit the MYROBOT.world file with the following contents: \n\n    \n    \n    <?xml version=\"1.0\" ?>\n    <sdf version=\"1.4\">\n      <world name=\"default\">\n        <include>\n          <uri>model://ground_plane</uri>\n        </include>\n        <include>\n          <uri>model://sun</uri>\n        </include>\n        <include>\n          <uri>model://gas_station</uri>\n          <name>gas_station</name>\n          <pose>-2.0 7.0 0 0 0 0</pose>\n        </include>\n        <include>\n          <uri>model://MYROBOT_description</uri>\n        </include>\n      </world>\n    </sdf>\n    \n\n  * You should now be able to launch your custom world with both the gas station and robot into Gazebo using the following command: \n    \n        roslaunch MYROBOT_gazebo MYROBOT.launch\n    \n\nThe disadvantage of this method is that your packaged ` MYROBOT_description `\nand ` MYROBOT_gazebo ` are not as easily portable between computers - you\nfirst have to set the ` GAZEBO_MODEL_PATH ` on any new system before being\nable to use these ROS packages.\n\n##  Exporting model paths from a package.xml\n\nThe useful info would be the format for exporting model paths from a\npackage.xml:\n\n    \n    \n    <run_depend>gazebo_ros</run_depend>\n    <export>\n      <gazebo_ros gazebo_model_path=\"${prefix}/models\"/>\n      <gazebo_ros gazebo_media_path=\"${prefix}/models\"/>\n    </export>\n    \n\nThe '${prefix}` is something that new users might not immediately know about\neither, and necessary here.\n\nAlso would be useful to have some info on how to debug these paths from the\nROS side, e.g. that you can use ` rospack plugins --attrib=\"gazebo_media_path\"\ngazebo_ros ` To check the media path that will be picked up by gazebo.\n\n##  Next Steps\n\nNow that you know how to create ` roslaunch ` files that open Gazebo, world\nfiles and URDF models, you are now ready to create your own Gazebo-ready URDF\nmodel in the tutorial [ Using A URDF In Gazebo ](/tutorials/?tut=ros_urdf)\n\n\u00a92014 Open Source Robotics Foundation\n\nGazebo is open-source licensed under [ Apache 2.0\n](http://www.apache.org/licenses/LICENSE-2.0.html)\n\n[ ![Google+](/assets/google_gray-\ncc34826f560f99c7a9b7db88cd5f2db4d28fd4b3afcfa4b897435c51e3b25518.png)\n](//plus.google.com/u/0/115981436296571800301?prsrc=3) [\n![YouTube](/assets/youtube_gray-978838444154eb6aa5e4aa38489f66d10e40361dd06a3814411c211cba013752.png)\n](https://www.youtube.com/channel/UCJyqf9XJpDoM9XnpAwW6WxA) [\n![YouTube](/assets/twitter_gray-8e9dfe74c6cab12171992a40add9a65e5bba92ac93063a4ac0eeba58c77e774a.png)\n](https://twitter.com/GazeboSim)\n\n"
  },
  {
    "id": "rclcpp_service_action/14671.txt",
    "content": "  \nROS Resources: [ ROS Homepage ](http://ros.org/) | [ Media and Trademarks\n](https://www.ros.org/blog/media/) | [ Documentation ](http://docs.ros.org/) |\n[ ROS Index ](https://index.ros.org/) | [ How to Get Help\n](http://wiki.ros.org/Support) | [ Q&A Help Site\n](https://robotics.stackexchange.com/) | [ Discussion Forum\n](http://discourse.ros.org/) | [ Service Status ](http://status.ros.org/)  \n---  \n  \n[ ROS Discourse ](/)\n\n#  [ ROS2 C++ Generic Action / Service Client ](/t/ros2-c-generic-action-\nservice-client/14671)\n\n[ Client Libraries  ](/c/client-libraries/22)\n\n[ rclcpp ](https://discourse.ros.org/tag/rclcpp) , [ ros2\n](https://discourse.ros.org/tag/ros2)\n\n[ rokel_race  ](https://discourse.ros.org/u/rokel_race) June 15, 2020, 4:25pm\n1\n\nHello, I\u2019m trying to make a generic C++ application for controlling ROS\nrobots. The idea is to allow design of GUIs in a higher-level language (QML)\nwithout requiring modifying the C++ when integrating new ROS systems.\n\nSo far I\u2019ve been using the [ generic subscription\n](https://github.com/ros2/rosbag2/blob/master/rosbag2_transport/src/rosbag2_transport/generic_subscription.hpp)\nfrom ` rosbag2_transport ` along with introspection via [ ros2_introspection\n](https://github.com/facontidavide/ros2_introspection) , which has worked\ngreat for topic data.\n\nHowever, now I\u2019d like to do the same for calling services and actions. From\nlooking at the code, it looks like a writing a \u201cGenericClient\u201d for services\nwould mean creating a new subclass of [ ` rclcpp::ClientBase `\n](http://docs.ros2.org/foxy/api/rclcpp/classrclcpp_1_1ClientBase.html) and\ninstantiating it with the relevant typesupport handle. Similarly for actions\nwith [ ` rclcpp_action::ClientBase `\n](http://docs.ros2.org/foxy/api/rclcpp_action/classrclcpp__action_1_1ClientBase.html)\n. Or perhaps I am misreading it, and using the ` ClientBase ` classes directly\nwould suffice.\n\nIs developing this functionality on any current roadmap, or has anybody\nattempted this before?\n\n[ gbiggs  ](https://discourse.ros.org/u/gbiggs) June 18, 2020, 4:56am  2\n\nThanks for your question. However we ask that you please ask questions on [\nhttp://answers.ros.org ](http://answers.ros.org) following our support\nguidelines: [ http://wiki.ros.org/Support ](http://wiki.ros.org/Support)\n\nROS Discourse is for news and general interest discussions. [ ROS Answers\n](http://answers.ros.org) provides a Q&A site which can be filtered by tags to\nmake sure the relevant people can find and/or answer the question, and not\noverload everyone with hundreds of posts.\n\n[ phuicy  ](https://discourse.ros.org/u/phuicy) June 19, 2020, 12:10pm  3\n\nI think this doesn\u2019t count as a Q&A, as there is an answer to this yet.  \nI think there is a lot possible design concepts that could be discussed.\n\n[ wjwwood  ](https://discourse.ros.org/u/wjwwood) June 22, 2020, 8:00pm  4\n\n![](https://avatars.discourse-cdn.com/v4/letter/r/8797f3/48.png) rokel_race:\n\n> Is developing this functionality on any current roadmap, or has anybody\n> attempted this before?\n\nNo one is planning to do this as far as I know. It sounds like what you\nproposed might work, but without digging into it, I\u2019d have a hard time saying\none way or the other.\n\nThis (interacting with unknown types at runtime) is an area that we need to\nimprove on still in the core API, in my opinion. But it is not on any\nimmediate road map that I\u2019m aware of.\n\n1 Like\n\n[ rokel_race  ](https://discourse.ros.org/u/rokel_race) July 10, 2020, 10:53am\n5\n\nI managed to cobble together a generic service client, following in the\nfootsteps of the rosbag2 [ generic subscription\n](https://github.com/ros2/rosbag2/blob/master/rosbag2_transport/src/rosbag2_transport/generic_subscription.hpp)\nand [ ros2_introspection\n](https://github.com/facontidavide/ros2_introspection) .\n\nThe principles are the same, just using the service type support instead of\nthe message type support. One oddity I did find is that I had to use an rmw-\nspecific typesupport library ( ` rosidl_typesupport_fastrtps_cpp ` ) to get\nthe service typesupport for a given type, which wasn\u2019t necessary for messages.\n\n![](https://sea2.discourse-\ncdn.com/business7/user_avatar/discourse.ros.org/wjwwood/48/13715_2.png)\nwjwwood:\n\n> This (interacting with unknown types at runtime) is an area that we need to\n> improve on still in the core API, in my opinion.\n\nAgreed - being a bit of a ROS2 novice I was disappointed to find that I needed\nto duplicate the(de)serialization method used in the specific rmw\nimplementation I was using in order to get usable data out of a\nSerializedMessage. It feels like something that should be possible without\ncoupling my application to a specific rmw implementation.\n\nIt occurs to me that there is another approach to solve the problem of writing\ngeneric C++ applications that work with message / service types not known\nuntil runtime. That is to follow the path of [ SOSS\n](https://github.com/osrf/soss/) and use generated code which is compiled to\nplugins that are loaded at runtime. As far as I can tell the key advantage of\nthat route is you don\u2019t have to mess around with the sort of serialisation\nroutines I mentioned above, and should be fully insulated from the rmw. But I\ndon\u2019t know if using using SOSS as a library for an existing application one of\nits intended uses, rather than as a standalone gateway.\n\n1 Like\n\n[ iaamp  ](https://discourse.ros.org/u/iaamp) April 27, 2023, 11:17am  6\n\nHello,  \nthis is an old topic, but i am currently still looking for a solution for a\ngeneric service client (i don\u2019t need a generic server, only client).\nApparently [ @rokel_race ](/u/rokel_race) created a solution for this, but i\nam not sure that it is released somewhere. Maybe someone else has solved this\nin the meantime and published a working implementation of a generic service\nclient for rclcpp?\n\nSome additional context on the problem:  \nSince the last message in this topic, the ` Node::create_generic_subscription\n` function was integrated from rosbag2 into the rclcpp library, which is\ngreat. However, either i don\u2019t understand how to use it for services, or a\ngeneric service is still missing from rclcpp.  \nI believe that the service message types can be generically converted between\nYAML and ROS 2 types via the [ osrf/dynamic_type_introspection\n](https://github.com/osrf/dynamic_message_introspection) library, just like\nfor topic messages. What is explicitly missing though, is the service\nequivalent to the generic pub/sub, e.g. this part:\n\n    \n    \n            subscription_ = this->node_handle_->create_generic_subscription(\n                topic_name_,\n                topic_type_,\n                qos,\n                [this](std::shared_ptr<const rclcpp::SerializedMessage> message)\n                {\n                    this->process_message(message);\n                }\n            );\n    \n\n###  Related Topics\n\nTopic  |  |  Replies  |  Views  |  Activity  \n---|---|---|---|---  \n[ Rust support for embedded devices ](https://discourse.ros.org/t/rust-\nsupport-for-embedded-devices/22263)\n\n[ Client Libraries  ](/c/client-libraries/22)\n\n[ rust ](https://discourse.ros.org/tag/rust)\n\n|  5  |  4300  |  September 29, 2021  \n[ Actions in ROS 2 ](https://discourse.ros.org/t/actions-in-ros-2/6254)\n\n[ Next Generation ROS  ](/c/ng-ros/25)\n\n|  21  |  6946  |  May 1, 2019  \n[ ROS2 client library for Julialang ](https://discourse.ros.org/t/ros2-client-\nlibrary-for-julialang/11858)\n\n[ Client Libraries  ](/c/client-libraries/22)\n\n[ ros2 ](https://discourse.ros.org/tag/ros2)\n\n|  7  |  5014  |  May 29, 2022  \n[ ROS2 C based dynamic typesupport example?\n](https://discourse.ros.org/t/ros2-c-based-dynamic-typesupport-example/19079)\n\n[ Next Generation ROS  ](/c/ng-ros/25)\n\n|  6  |  1931  |  February 23, 2021  \n[ Plain C API ](https://discourse.ros.org/t/plain-c-api/11911)\n\n[ Next Generation ROS  ](/c/ng-ros/25)\n\n|  8  |  1648  |  September 14, 2022  \n  \n  * [ Home ](/)\n  * [ Categories ](/categories)\n  * [ FAQ/Guidelines ](/guidelines)\n  * [ Terms of Service ](/tos)\n  * [ Privacy Policy ](/privacy)\n\nPowered by [ Discourse ](https://www.discourse.org) , best viewed with\nJavaScript enabled\n\n"
  },
  {
    "id": "moveit_config/CMakeCachetxt.txt",
    "content": "# This is the CMakeCache file. # For build in directory:\n/home/robuter/catkin_ws/build # It was generated by CMake: /usr/bin/cmake #\nYou can edit this file to change values found and used by cmake. # If you do\nnot want to change any of the values, simply exit the editor. # If you do want\nto change a value, simply edit, save, and exit the editor. # The syntax for\nthe file is as follows: # KEY:TYPE=VALUE # KEY is the name of a variable in\nthe cache. # TYPE is a hint to GUIs for the type of VALUE, DO NOT EDIT TYPE!.\n# VALUE is the current value for the KEY. ######################## # EXTERNAL\ncache entries ######################## //Path to a library.\nBLAS_Accelerate_LIBRARY:FILEPATH=BLAS_Accelerate_LIBRARY-NOTFOUND //Path to a\nlibrary. BLAS_acml_LIBRARY:FILEPATH=BLAS_acml_LIBRARY-NOTFOUND //Path to a\nlibrary. BLAS_acml_mp_LIBRARY:FILEPATH=BLAS_acml_mp_LIBRARY-NOTFOUND //Path to\na library. BLAS_blas_LIBRARY:FILEPATH=/usr/lib/libblas.so //Path to a library.\nBLAS_complib.sgimath_LIBRARY:FILEPATH=BLAS_complib.sgimath_LIBRARY-NOTFOUND\n//Path to a library. BLAS_cxml_LIBRARY:FILEPATH=BLAS_cxml_LIBRARY-NOTFOUND\n//Path to a library. BLAS_dxml_LIBRARY:FILEPATH=BLAS_dxml_LIBRARY-NOTFOUND\n//Path to a library. BLAS_essl_LIBRARY:FILEPATH=BLAS_essl_LIBRARY-NOTFOUND\n//Path to a library. BLAS_f77blas_LIBRARY:FILEPATH=BLAS_f77blas_LIBRARY-\nNOTFOUND //Path to a library. BLAS_goto2_LIBRARY:FILEPATH=BLAS_goto2_LIBRARY-\nNOTFOUND //Path to a library. BLAS_scsl_LIBRARY:FILEPATH=BLAS_scsl_LIBRARY-\nNOTFOUND //Path to a library. BLAS_sgemm_LIBRARY:FILEPATH=BLAS_sgemm_LIBRARY-\nNOTFOUND //Path to a library.\nBLAS_sunperf_LIBRARY:FILEPATH=BLAS_sunperf_LIBRARY-NOTFOUND //Path to a\nlibrary. BLAS_vecLib_LIBRARY:FILEPATH=BLAS_vecLib_LIBRARY-NOTFOUND //The\nthreading library used by boost-thread\nBOOST_THREAD_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libpthread.so //Build\nshared libraries (DLLs). BUILD_SHARED_LIBS:BOOL=ON //Boost atomic library\n(debug) Boost_ATOMIC_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so //Boost atomic library (release)\nBoost_ATOMIC_LIBRARY_RELEASE:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so //Boost chrono library (debug)\nBoost_CHRONO_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so //Boost chrono library (release)\nBoost_CHRONO_LIBRARY_RELEASE:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so //Boost date_time library (debug)\nBoost_DATE_TIME_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so //Boost date_time library (release)\nBoost_DATE_TIME_LIBRARY_RELEASE:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so //The directory containing a CMake configuration\nfile for Boost. Boost_DIR:PATH=Boost_DIR-NOTFOUND //Boost filesystem library\n(debug) Boost_FILESYSTEM_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so //Boost filesystem library (release)\nBoost_FILESYSTEM_LIBRARY_RELEASE:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so //Path to a file.\nBoost_INCLUDE_DIR:PATH=/usr/include //Boost iostreams library (debug)\nBoost_IOSTREAMS_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so //Boost iostreams library (release)\nBoost_IOSTREAMS_LIBRARY_RELEASE:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so //Boost library directory DEBUG\nBoost_LIBRARY_DIR_DEBUG:PATH=/usr/lib/x86_64-linux-gnu //Boost library\ndirectory RELEASE Boost_LIBRARY_DIR_RELEASE:PATH=/usr/lib/x86_64-linux-gnu\n//Boost program_options library (debug)\nBoost_PROGRAM_OPTIONS_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so //Boost program_options library (release)\nBoost_PROGRAM_OPTIONS_LIBRARY_RELEASE:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so //Boost python library (debug)\nBoost_PYTHON_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_python.so //Boost python library (release)\nBoost_PYTHON_LIBRARY_RELEASE:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_python.so //Boost regex library (debug)\nBoost_REGEX_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-gnu/libboost_regex.so\n//Boost regex library (release)\nBoost_REGEX_LIBRARY_RELEASE:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_regex.so //Boost serialization library (debug)\nBoost_SERIALIZATION_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_serialization.so //Boost serialization library (release)\nBoost_SERIALIZATION_LIBRARY_RELEASE:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_serialization.so //Boost signals library (debug)\nBoost_SIGNALS_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_signals.so //Boost signals library (release)\nBoost_SIGNALS_LIBRARY_RELEASE:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_signals.so //Boost system library (debug)\nBoost_SYSTEM_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_system.so //Boost system library (release)\nBoost_SYSTEM_LIBRARY_RELEASE:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_system.so //Boost thread library (debug)\nBoost_THREAD_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_thread.so //Boost thread library (release)\nBoost_THREAD_LIBRARY_RELEASE:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libboost_thread.so //List of ';' separated packages to exclude\nCATKIN_BLACKLIST_PACKAGES:STRING= //catkin devel space\nCATKIN_DEVEL_PREFIX:PATH=/home/robuter/catkin_ws/devel //Catkin enable testing\nCATKIN_ENABLE_TESTING:BOOL=ON //Catkin skip testing\nCATKIN_SKIP_TESTING:BOOL=OFF //List of ';' separated packages to build\nCATKIN_WHITELIST_PACKAGES:STRING= //Path to a program.\nCMAKE_AR:FILEPATH=/usr/bin/ar //Choose the type of build, options are:\nNone(CMAKE_CXX_FLAGS or // CMAKE_C_FLAGS used) Debug Release RelWithDebInfo\nMinSizeRel. CMAKE_BUILD_TYPE:STRING= //Enable/Disable color output during\nbuild. CMAKE_COLOR_MAKEFILE:BOOL=ON //CXX compiler\nCMAKE_CXX_COMPILER:FILEPATH=/usr/bin/c++ //Flags used by the compiler during\nall build types. CMAKE_CXX_FLAGS:STRING= //Flags used by the compiler during\ndebug builds. CMAKE_CXX_FLAGS_DEBUG:STRING=-g //Flags used by the compiler\nduring release builds for minimum // size.\nCMAKE_CXX_FLAGS_MINSIZEREL:STRING=-Os -DNDEBUG //Flags used by the compiler\nduring release builds. CMAKE_CXX_FLAGS_RELEASE:STRING=-O3 -DNDEBUG //Flags\nused by the compiler during release builds with debug info.\nCMAKE_CXX_FLAGS_RELWITHDEBINFO:STRING=-O2 -g -DNDEBUG //C compiler\nCMAKE_C_COMPILER:FILEPATH=/usr/bin/cc //Flags used by the compiler during all\nbuild types. CMAKE_C_FLAGS:STRING= //Flags used by the compiler during debug\nbuilds. CMAKE_C_FLAGS_DEBUG:STRING=-g //Flags used by the compiler during\nrelease builds for minimum // size. CMAKE_C_FLAGS_MINSIZEREL:STRING=-Os\n-DNDEBUG //Flags used by the compiler during release builds.\nCMAKE_C_FLAGS_RELEASE:STRING=-O3 -DNDEBUG //Flags used by the compiler during\nrelease builds with debug info. CMAKE_C_FLAGS_RELWITHDEBINFO:STRING=-O2 -g\n-DNDEBUG //Flags used by the linker. CMAKE_EXE_LINKER_FLAGS:STRING= //Flags\nused by the linker during debug builds. CMAKE_EXE_LINKER_FLAGS_DEBUG:STRING=\n//Flags used by the linker during release minsize builds.\nCMAKE_EXE_LINKER_FLAGS_MINSIZEREL:STRING= //Flags used by the linker during\nrelease builds. CMAKE_EXE_LINKER_FLAGS_RELEASE:STRING= //Flags used by the\nlinker during Release with Debug Info builds.\nCMAKE_EXE_LINKER_FLAGS_RELWITHDEBINFO:STRING= //Enable/Disable output of\ncompile commands during generation. CMAKE_EXPORT_COMPILE_COMMANDS:BOOL=OFF\n//Install path prefix, prepended onto install directories.\nCMAKE_INSTALL_PREFIX:PATH=/home/robuter/catkin_ws/install //Path to a program.\nCMAKE_LINKER:FILEPATH=/usr/bin/ld //Path to a program.\nCMAKE_MAKE_PROGRAM:FILEPATH=/usr/bin/make //Flags used by the linker during\nthe creation of modules. CMAKE_MODULE_LINKER_FLAGS:STRING= //Flags used by the\nlinker during debug builds. CMAKE_MODULE_LINKER_FLAGS_DEBUG:STRING= //Flags\nused by the linker during release minsize builds.\nCMAKE_MODULE_LINKER_FLAGS_MINSIZEREL:STRING= //Flags used by the linker during\nrelease builds. CMAKE_MODULE_LINKER_FLAGS_RELEASE:STRING= //Flags used by the\nlinker during Release with Debug Info builds.\nCMAKE_MODULE_LINKER_FLAGS_RELWITHDEBINFO:STRING= //Path to a program.\nCMAKE_NM:FILEPATH=/usr/bin/nm //Path to a program.\nCMAKE_OBJCOPY:FILEPATH=/usr/bin/objcopy //Path to a program.\nCMAKE_OBJDUMP:FILEPATH=/usr/bin/objdump //Value Computed by CMake\nCMAKE_PROJECT_NAME:STATIC=Project //Path to a program.\nCMAKE_RANLIB:FILEPATH=/usr/bin/ranlib //Flags used by the linker during the\ncreation of dll's. CMAKE_SHARED_LINKER_FLAGS:STRING= //Flags used by the\nlinker during debug builds. CMAKE_SHARED_LINKER_FLAGS_DEBUG:STRING= //Flags\nused by the linker during release minsize builds.\nCMAKE_SHARED_LINKER_FLAGS_MINSIZEREL:STRING= //Flags used by the linker during\nrelease builds. CMAKE_SHARED_LINKER_FLAGS_RELEASE:STRING= //Flags used by the\nlinker during Release with Debug Info builds.\nCMAKE_SHARED_LINKER_FLAGS_RELWITHDEBINFO:STRING= //If set, runtime paths are\nnot added when installing shared libraries, // but are added when building.\nCMAKE_SKIP_INSTALL_RPATH:BOOL=NO //If set, runtime paths are not added when\nusing shared libraries. CMAKE_SKIP_RPATH:BOOL=NO //Flags used by the linker\nduring the creation of static libraries. CMAKE_STATIC_LINKER_FLAGS:STRING=\n//Flags used by the linker during debug builds.\nCMAKE_STATIC_LINKER_FLAGS_DEBUG:STRING= //Flags used by the linker during\nrelease minsize builds. CMAKE_STATIC_LINKER_FLAGS_MINSIZEREL:STRING= //Flags\nused by the linker during release builds.\nCMAKE_STATIC_LINKER_FLAGS_RELEASE:STRING= //Flags used by the linker during\nRelease with Debug Info builds.\nCMAKE_STATIC_LINKER_FLAGS_RELWITHDEBINFO:STRING= //Path to a program.\nCMAKE_STRIP:FILEPATH=/usr/bin/strip //If this value is on, makefiles will be\ngenerated without the // .SILENT directive, and all commands will be echoed to\nthe console // during the make. This is useful for debugging only. With Visual\n// Studio IDE projects all commands are done without /nologo.\nCMAKE_VERBOSE_MAKEFILE:BOOL=FALSE //Path to a file.\nCURL_INCLUDE_DIR:PATH=/usr/include //Path to a library.\nCURL_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libcurl.so //Path to a\nprogram. DOXYGEN_EXECUTABLE:FILEPATH=/usr/bin/doxygen //Doxygen found\nDOXYGEN_FOUND:BOOL=TRUE //Path to a file.\nEIGEN_INCLUDE_DIRS:PATH=/usr/include/eigen3 //Path to a program.\nEMPY_EXECUTABLE:FILEPATH=/usr/bin/empy //Empy script\nEMPY_SCRIPT:STRING=/usr/bin/empy //The directory containing a CMake\nconfiguration file for Eigen3. Eigen3_DIR:PATH=/usr/lib/cmake/eigen3 //Path to\na file. FLANN_INCLUDE_DIRS:PATH=/usr/include //Path to a library.\nFLANN_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libflann_cpp_s.a //Path to a\nlibrary. FLANN_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libflann_cpp_s.a //Path to a library.\nFLYCAPTURE2:FILEPATH=/usr/lib/libflycapture.so //Path to a file.\nGLEW_INCLUDE_DIR:PATH=/usr/include //Path to a library.\nGLEW_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libGLEW.so //Path to a file.\nGLUT_INCLUDE_DIR:PATH=/usr/include //Path to a library.\nGLUT_Xi_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libXi.so //Path to a\nlibrary. GLUT_Xmu_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libXmu.so //Path\nto a library. GLUT_glut_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libglut.so\n//Path to a file. GTEST_INCLUDE_DIR:PATH=/usr/include //Path to a library.\nGTEST_LIBRARY:FILEPATH=GTEST_LIBRARY-NOTFOUND //Path to a library.\nGTEST_LIBRARY_DEBUG:FILEPATH=GTEST_LIBRARY_DEBUG-NOTFOUND //Path to a library.\nGTEST_MAIN_LIBRARY:FILEPATH=GTEST_MAIN_LIBRARY-NOTFOUND //Path to a library.\nGTEST_MAIN_LIBRARY_DEBUG:FILEPATH=GTEST_MAIN_LIBRARY_DEBUG-NOTFOUND //Path to\na library. LAPACK_Accelerate_LIBRARY:FILEPATH=LAPACK_Accelerate_LIBRARY-\nNOTFOUND //Path to a library.\nLAPACK_goto2_LIBRARY:FILEPATH=LAPACK_goto2_LIBRARY-NOTFOUND //Path to a\nlibrary. LAPACK_lapack_LIBRARY:FILEPATH=/usr/lib/liblapack.so //Path to a\nlibrary. LAPACK_vecLib_LIBRARY:FILEPATH=LAPACK_vecLib_LIBRARY-NOTFOUND //Path\nto a library. LIBFCL_LIBRARIES_FULL:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libfcl.so //Path to a file. LIBUSB_1_INCLUDE_DIR:PATH=/usr/include //Path\nto a library. LIBUSB_1_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libusb-1.0.so //Path to a library.\nLOG4CXX_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/liblog4cxx.so //lsb_release\nexecutable was found LSB_FOUND:BOOL=TRUE //Path to a program.\nLSB_RELEASE_EXECUTABLE:FILEPATH=/usr/bin/lsb_release //Path to a program.\nNOSETESTS:FILEPATH=/usr/bin/nosetests-2.7 //Path to a library.\nOMPLAPPBASE_LIBRARY:FILEPATH=OMPLAPPBASE_LIBRARY-NOTFOUND //Path to a library.\nOMPLAPP_LIBRARY:FILEPATH=OMPLAPP_LIBRARY-NOTFOUND //Path to a file.\nOMPL_CONFIG:FILEPATH=/opt/ros/kinetic/include/ompl/config.h //The directory\ncontaining a CMake configuration file for OMPL.\nOMPL_DIR:PATH=/opt/ros/kinetic/share/ompl //Path to a file.\nOMPL_INCLUDE_DIRS:PATH=/opt/ros/kinetic/include/ompl/base //Path to OMPL\nlibrary OMPL_LIBRARIES:FILEPATH=/opt/ros/kinetic/lib/x86_64-linux-\ngnu/libompl.so //Path to a library.\nOMPL_LIBRARY:FILEPATH=/opt/ros/kinetic/lib/x86_64-linux-gnu/libompl.so //Path\nto a file. OPENGL_INCLUDE_DIR:PATH=/usr/include //Path to a library.\nOPENGL_gl_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libGL.so //Path to a\nlibrary. OPENGL_glu_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libGLU.so\n//Path to a file. OPENGL_xmesa_INCLUDE_DIR:PATH=OPENGL_xmesa_INCLUDE_DIR-\nNOTFOUND //Path to a file. OPENNI2_INCLUDE_DIRS:PATH=OPENNI2_INCLUDE_DIRS-\nNOTFOUND //Path to a library. OPENNI2_LIBRARY:FILEPATH=OPENNI2_LIBRARY-\nNOTFOUND //Path to a file. OPENNI_INCLUDE_DIRS:PATH=/usr/include/ni //Path to\na library. OPENNI_LIBRARY:FILEPATH=/usr/lib/libOpenNI.so //The directory\ncontaining a CMake configuration file for OpenCV.\nOpenCV_DIR:PATH=/opt/ros/kinetic/share/OpenCV-3.2.0-dev //C++ compiler flags\nfor OpenMP parallization OpenMP_CXX_FLAGS:STRING=-fopenmp //C compiler flags\nfor OpenMP parallization OpenMP_C_FLAGS:STRING=-fopenmp //path to apps headers\nPCL_APPS_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to pcl_apps library\nPCL_APPS_LIBRARY:FILEPATH=PCL_APPS_LIBRARY-NOTFOUND //path to pcl_apps library\ndebug PCL_APPS_LIBRARY_DEBUG:FILEPATH=PCL_APPS_LIBRARY_DEBUG-NOTFOUND //path\nto common headers PCL_COMMON_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to\npcl_common library PCL_COMMON_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_common.so //path to pcl_common library debug\nPCL_COMMON_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-gnu/libpcl_common.so\n//The directory containing a CMake configuration file for PCL.\nPCL_DIR:PATH=/usr/lib/x86_64-linux-gnu/cmake/pcl //path to features headers\nPCL_FEATURES_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to pcl_features\nlibrary PCL_FEATURES_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_features.so //path to pcl_features library debug\nPCL_FEATURES_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_features.so //path to filters headers\nPCL_FILTERS_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to pcl_filters\nlibrary PCL_FILTERS_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_filters.so //path to pcl_filters library debug\nPCL_FILTERS_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-gnu/libpcl_filters.so\n//path to geometry headers PCL_GEOMETRY_INCLUDE_DIR:PATH=/usr/include/pcl-1.7\n//path to in_hand_scanner headers\nPCL_IN_HAND_SCANNER_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to io headers\nPCL_IO_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to pcl_io library\nPCL_IO_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libpcl_io.so //path to\npcl_io library debug PCL_IO_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_io.so //path to kdtree headers\nPCL_KDTREE_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to pcl_kdtree library\nPCL_KDTREE_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libpcl_kdtree.so //path\nto pcl_kdtree library debug\nPCL_KDTREE_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-gnu/libpcl_kdtree.so\n//path to keypoints headers\nPCL_KEYPOINTS_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to pcl_keypoints\nlibrary PCL_KEYPOINTS_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_keypoints.so //path to pcl_keypoints library debug\nPCL_KEYPOINTS_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_keypoints.so //path to modeler headers\nPCL_MODELER_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to octree headers\nPCL_OCTREE_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to pcl_octree library\nPCL_OCTREE_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libpcl_octree.so //path\nto pcl_octree library debug\nPCL_OCTREE_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-gnu/libpcl_octree.so\n//path to outofcore headers\nPCL_OUTOFCORE_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to pcl_outofcore\nlibrary PCL_OUTOFCORE_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_outofcore.so //path to pcl_outofcore library debug\nPCL_OUTOFCORE_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_outofcore.so //path to people headers\nPCL_PEOPLE_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to pcl_people library\nPCL_PEOPLE_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libpcl_people.so //path\nto pcl_people library debug\nPCL_PEOPLE_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-gnu/libpcl_people.so\n//path to point_cloud_editor headers\nPCL_POINT_CLOUD_EDITOR_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to\nrecognition headers PCL_RECOGNITION_INCLUDE_DIR:PATH=/usr/include/pcl-1.7\n//path to pcl_recognition library\nPCL_RECOGNITION_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_recognition.so //path to pcl_recognition library debug\nPCL_RECOGNITION_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_recognition.so //path to registration headers\nPCL_REGISTRATION_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to\npcl_registration library\nPCL_REGISTRATION_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_registration.so //path to pcl_registration library debug\nPCL_REGISTRATION_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_registration.so //path to sample_consensus headers\nPCL_SAMPLE_CONSENSUS_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to\npcl_sample_consensus library\nPCL_SAMPLE_CONSENSUS_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_sample_consensus.so //path to pcl_sample_consensus library debug\nPCL_SAMPLE_CONSENSUS_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_sample_consensus.so //path to search headers\nPCL_SEARCH_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to pcl_search library\nPCL_SEARCH_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libpcl_search.so //path\nto pcl_search library debug\nPCL_SEARCH_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-gnu/libpcl_search.so\n//path to segmentation headers\nPCL_SEGMENTATION_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to\npcl_segmentation library\nPCL_SEGMENTATION_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_segmentation.so //path to pcl_segmentation library debug\nPCL_SEGMENTATION_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_segmentation.so //path to surface headers\nPCL_SURFACE_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to pcl_surface\nlibrary PCL_SURFACE_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_surface.so //path to pcl_surface library debug\nPCL_SURFACE_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-gnu/libpcl_surface.so\n//path to tracking headers PCL_TRACKING_INCLUDE_DIR:PATH=/usr/include/pcl-1.7\n//path to pcl_tracking library\nPCL_TRACKING_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libpcl_tracking.so\n//path to pcl_tracking library debug\nPCL_TRACKING_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_tracking.so //path to visualization headers\nPCL_VISUALIZATION_INCLUDE_DIR:PATH=/usr/include/pcl-1.7 //path to\npcl_visualization library\nPCL_VISUALIZATION_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_visualization.so //path to pcl_visualization library debug\nPCL_VISUALIZATION_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-\ngnu/libpcl_visualization.so //pkg-config executable\nPKG_CONFIG_EXECUTABLE:FILEPATH=/usr/bin/pkg-config //Path to a program.\nPYTHON_EXECUTABLE:FILEPATH=/usr/bin/python //Path to a file.\nPYTHON_INCLUDE_DIR:PATH=/usr/include/python2.7 //Path to a library.\nPYTHON_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libpython2.7.so //Path to a\nlibrary. PYTHON_LIBRARY_DEBUG:FILEPATH=PYTHON_LIBRARY_DEBUG-NOTFOUND //Specify\nspecific Python version to use ('major.minor' or 'major')\nPYTHON_VERSION:STRING= //Value Computed by CMake\nProject_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build //Value Computed by\nCMake Project_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src //Path to a file.\nQHULL_INCLUDE_DIRS:PATH=/usr/include //Path to a library.\nQHULL_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/libqhull.so //Path to a\nlibrary. QHULL_LIBRARY_DEBUG:FILEPATH=/usr/lib/x86_64-linux-gnu/libqhull.so\n//The directory containing a CMake configuration file for Qt5Core.\nQt5Core_DIR:PATH=/usr/lib/x86_64-linux-gnu/cmake/Qt5Core //The directory\ncontaining a CMake configuration file for Qt5Gui.\nQt5Gui_DIR:PATH=/usr/lib/x86_64-linux-gnu/cmake/Qt5Gui //The directory\ncontaining a CMake configuration file for Qt5Network.\nQt5Network_DIR:PATH=/usr/lib/x86_64-linux-gnu/cmake/Qt5Network //The directory\ncontaining a CMake configuration file for Qt5WebKit.\nQt5WebKit_DIR:PATH=/usr/lib/x86_64-linux-gnu/cmake/Qt5WebKit //The directory\ncontaining a CMake configuration file for Qt5Widgets.\nQt5Widgets_DIR:PATH=/usr/lib/x86_64-linux-gnu/cmake/Qt5Widgets //The directory\ncontaining a CMake configuration file for Qt5.\nQt5_DIR:PATH=/usr/lib/x86_64-linux-gnu/cmake/Qt5 //Path to a library.\nRT_LIBRARY:FILEPATH=/usr/lib/x86_64-linux-gnu/librt.so //Enable debian style\npython package layout SETUPTOOLS_DEB_LAYOUT:BOOL=ON //LSB Distrib tag\nUBUNTU:BOOL=TRUE //LSB Distrib - codename tag UBUNTU_XENIAL:BOOL=TRUE //Path\nto a library. YAML:FILEPATH=/usr/lib/x86_64-linux-gnu/libyaml-cpp.so //Path to\na file. _CATKIN_GTEST_INCLUDE:FILEPATH=/usr/include/gtest/gtest.h //Path to a\nfile. _CATKIN_GTEST_SRC:FILEPATH=/usr/src/gtest/src/gtest.cc //Path to a file.\n_file_name:FILEPATH=/home/robuter/catkin_ws/src/moveit-kinetic-\ndevel/moveit_ros/visualization/test/moveit_joy.test //Path to a file.\n_path_name:FILEPATH=/home/robuter/catkin_ws/src/image_common/camera_calibration_parsers/test/parser.py\n//The directory containing a CMake configuration file for actionlib.\nactionlib_DIR:PATH=/opt/ros/kinetic/share/actionlib/cmake //The directory\ncontaining a CMake configuration file for actionlib_msgs.\nactionlib_msgs_DIR:PATH=/opt/ros/kinetic/share/actionlib_msgs/cmake //The\ndirectory containing a CMake configuration file for angles.\nangles_DIR:PATH=/opt/ros/kinetic/share/angles/cmake //The directory containing\na CMake configuration file for bond.\nbond_DIR:PATH=/opt/ros/kinetic/share/bond/cmake //The directory containing a\nCMake configuration file for bondcpp.\nbondcpp_DIR:PATH=/opt/ros/kinetic/share/bondcpp/cmake //Value Computed by\nCMake\ncamera_calibration_parsers_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/image_common/camera_calibration_parsers\n//The directory containing a CMake configuration file for\ncamera_calibration_parsers.\ncamera_calibration_parsers_DIR:PATH=/home/robuter/catkin_ws/devel/share/camera_calibration_parsers/cmake\n//Dependencies for the target\ncamera_calibration_parsers_LIB_DEPENDS:STATIC=general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;yaml-cpp;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so; //Value Computed by CMake\ncamera_calibration_parsers_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/image_common/camera_calibration_parsers\n//Dependencies for the target\ncamera_calibration_parsers_wrapper_LIB_DEPENDS:STATIC=general;camera_calibration_parsers;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_python.so;general;/usr/lib/x86_64-linux-gnu/libpython2.7.so;\n//Value Computed by CMake\ncamera_info_manager_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/image_common/camera_info_manager\n//Dependencies for the target\ncamera_info_manager_LIB_DEPENDS:STATIC=general;camera_calibration_parsers;general;image_transport;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-gnu/libtinyxml.so;\n//Value Computed by CMake\ncamera_info_manager_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/image_common/camera_info_manager\n//The directory containing a CMake configuration file for catkin.\ncatkin_DIR:PATH=/opt/ros/kinetic/share/catkin/cmake //Value Computed by CMake\nchomp_motion_planner_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_planners/chomp/chomp_motion_planner //The directory\ncontaining a CMake configuration file for chomp_motion_planner.\nchomp_motion_planner_DIR:PATH=/home/robuter/catkin_ws/devel/share/chomp_motion_planner/cmake\n//Dependencies for the target\nchomp_motion_planner_LIB_DEPENDS:STATIC=general;moveit_collision_distance_field;general;collision_detector_hybrid_plugin;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//Value Computed by CMake\nchomp_motion_planner_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_planners/chomp/chomp_motion_planner //Dependencies for\nthe target\nchomp_planner_plugin_LIB_DEPENDS:STATIC=general;moveit_planners_chomp;general;chomp_motion_planner;general;moveit_collision_distance_field;general;collision_detector_hybrid_plugin;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-gnu/libtinyxml.so; //The\ndirectory containing a CMake configuration file for class_loader.\nclass_loader_DIR:PATH=/opt/ros/kinetic/share/class_loader/cmake //The\ndirectory containing a CMake configuration file for cmake_modules.\ncmake_modules_DIR:PATH=/opt/ros/kinetic/share/cmake_modules/cmake\n//Dependencies for the target\ncollision_detector_hybrid_plugin_LIB_DEPENDS:STATIC=general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libresource_retriever.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;moveit_collision_distance_field; //Value Computed by\nCMake comm_tcp_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/comm_tcp-master\n//Value Computed by CMake\ncomm_tcp_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/comm_tcp-master //The\ndirectory containing a CMake configuration file for console_bridge.\nconsole_bridge_DIR:PATH=/usr/lib/x86_64-linux-gnu/console_bridge/cmake //The\ndirectory containing a CMake configuration file for control_msgs.\ncontrol_msgs_DIR:PATH=/opt/ros/kinetic/share/control_msgs/cmake //The\ndirectory containing a CMake configuration file for controller_manager_msgs.\ncontroller_manager_msgs_DIR:PATH=/opt/ros/kinetic/share/controller_manager_msgs/cmake\n//The directory containing a CMake configuration file for cpp_common.\ncpp_common_DIR:PATH=/opt/ros/kinetic/share/cpp_common/cmake //Dependencies for\ntarget curlite_LIB_DEPENDS:STATIC= //The directory containing a CMake\nconfiguration file for cv_bridge.\ncv_bridge_DIR:PATH=/opt/ros/kinetic/share/cv_bridge/cmake //Value Computed by\nCMake damas_hsv_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/damas_hsv\n//Value Computed by CMake\ndamas_hsv_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/damas_hsv //The\ndirectory containing a CMake configuration file for diagnostic_msgs.\ndiagnostic_msgs_DIR:PATH=/opt/ros/kinetic/share/diagnostic_msgs/cmake //The\ndirectory containing a CMake configuration file for diagnostic_updater.\ndiagnostic_updater_DIR:PATH=/opt/ros/kinetic/share/diagnostic_updater/cmake\n//Value Computed by CMake\ndriver_base_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/driver_common/driver_base\n//The directory containing a CMake configuration file for driver_base.\ndriver_base_DIR:PATH=/home/robuter/catkin_ws/devel/share/driver_base/cmake\n//Value Computed by CMake\ndriver_base_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/driver_common/driver_base\n//Value Computed by CMake\ndriver_common_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/driver_common/driver_common\n//Value Computed by CMake\ndriver_common_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/driver_common/driver_common\n//The directory containing a CMake configuration file for dynamic_reconfigure.\ndynamic_reconfigure_DIR:PATH=/opt/ros/kinetic/share/dynamic_reconfigure/cmake\n//The directory containing a CMake configuration file for eigen_conversions.\neigen_conversions_DIR:PATH=/opt/ros/kinetic/share/eigen_conversions/cmake\n//The directory containing a CMake configuration file for\neigen_stl_containers.\neigen_stl_containers_DIR:PATH=/opt/ros/kinetic/share/eigen_stl_containers/cmake\n//Value Computed by CMake\nfanuc_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/fanuc/fanuc //Value\nComputed by CMake\nfanuc_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/fanuc/fanuc //Value\nComputed by CMake\nfanuc_driver_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/fanuc/fanuc_driver\n//Value Computed by CMake\nfanuc_driver_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/fanuc/fanuc_driver\n//Dependencies for the target\nfanuc_lrmate200id_manipulator_moveit_ikfast_plugin_LIB_DEPENDS:STATIC=general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/liblapack.so;general;/usr/lib/libblas.so;\n//Value Computed by CMake\nfanuc_lrmate200id_moveit_config_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/fanuc/fanuc_lrmate200id_moveit_config\n//Value Computed by CMake\nfanuc_lrmate200id_moveit_config_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/fanuc/fanuc_lrmate200id_moveit_config\n//Value Computed by CMake\nfanuc_lrmate200id_moveit_plugins_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/fanuc/fanuc_lrmate200id_moveit_plugins\n//Value Computed by CMake\nfanuc_lrmate200id_moveit_plugins_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/fanuc/fanuc_lrmate200id_moveit_plugins\n//Value Computed by CMake\nfanuc_lrmate200id_support_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/fanuc/fanuc_lrmate200id_support\n//Value Computed by CMake\nfanuc_lrmate200id_support_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/fanuc/fanuc_lrmate200id_support\n//Value Computed by CMake\nfanuc_post_processor_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/Programacao/fanuc_rep/fanuc_post_processor-\nindigo-devel_tiago/fanuc_post_processor //Value Computed by CMake\nfanuc_post_processor_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/Programacao/fanuc_rep/fanuc_post_processor-\nindigo-devel_tiago/fanuc_post_processor //Value Computed by CMake\nfanuc_post_processor_application_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/Programacao/fanuc_rep/fanuc_post_processor-\nindigo-devel_tiago/fanuc_post_processor_application //Value Computed by CMake\nfanuc_post_processor_application_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/Programacao/fanuc_rep/fanuc_post_processor-\nindigo-devel_tiago/fanuc_post_processor_application //Value Computed by CMake\nfanuc_post_processor_library_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/Programacao/fanuc_rep/fanuc_post_processor-\nindigo-devel_tiago/fanuc_post_processor_library //The directory containing a\nCMake configuration file for fanuc_post_processor_library.\nfanuc_post_processor_library_DIR:PATH=/home/robuter/catkin_ws/devel/share/fanuc_post_processor_library/cmake\n//Dependencies for target fanuc_post_processor_library_LIB_DEPENDS:STATIC=\n//Value Computed by CMake\nfanuc_post_processor_library_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/Programacao/fanuc_rep/fanuc_post_processor-\nindigo-devel_tiago/fanuc_post_processor_library //Value Computed by CMake\nfanuc_resources_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/fanuc/fanuc_resources\n//Value Computed by CMake\nfanuc_resources_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/fanuc/fanuc_resources\n//The directory containing a CMake configuration file for gencpp.\ngencpp_DIR:PATH=/opt/ros/kinetic/share/gencpp/cmake //The directory containing\na CMake configuration file for geneus.\ngeneus_DIR:PATH=/opt/ros/kinetic/share/geneus/cmake //The directory containing\na CMake configuration file for genlisp.\ngenlisp_DIR:PATH=/opt/ros/kinetic/share/genlisp/cmake //The directory\ncontaining a CMake configuration file for genmsg.\ngenmsg_DIR:PATH=/opt/ros/kinetic/share/genmsg/cmake //The directory containing\na CMake configuration file for gennodejs.\ngennodejs_DIR:PATH=/opt/ros/kinetic/share/gennodejs/cmake //The directory\ncontaining a CMake configuration file for genpy.\ngenpy_DIR:PATH=/opt/ros/kinetic/share/genpy/cmake //The directory containing a\nCMake configuration file for geometric_shapes.\ngeometric_shapes_DIR:PATH=/opt/ros/kinetic/share/geometric_shapes/cmake //The\ndirectory containing a CMake configuration file for geometry_msgs.\ngeometry_msgs_DIR:PATH=/opt/ros/kinetic/share/geometry_msgs/cmake //Value\nComputed by CMake gtest_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/gtest\n//Dependencies for the target gtest_LIB_DEPENDS:STATIC=general;-lpthread;\n//Value Computed by CMake gtest_SOURCE_DIR:STATIC=/usr/src/gtest //Build\ngtest's sample programs. gtest_build_samples:BOOL=OFF //Build all of gtest's\nown tests. gtest_build_tests:BOOL=OFF //Disable uses of pthreads in gtest.\ngtest_disable_pthreads:BOOL=OFF //Use shared (DLL) run-time lib even when\nGoogle Test is built // as static lib. gtest_force_shared_crt:BOOL=OFF\n//Dependencies for the target\ngtest_main_LIB_DEPENDS:STATIC=general;-lpthread;general;gtest; //Value\nComputed by CMake\nhokuyo_node_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/hokuyo_node-\nindigo-devel //Value Computed by CMake\nhokuyo_node_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/hokuyo_node-indigo-\ndevel //Value Computed by CMake\nimage_common_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/image_common/image_common\n//Value Computed by CMake\nimage_common_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/image_common/image_common\n//Value Computed by CMake\nimage_transport_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/image_common/image_transport\n//The directory containing a CMake configuration file for image_transport.\nimage_transport_DIR:PATH=/home/robuter/catkin_ws/devel/share/image_transport/cmake\n//Dependencies for the target\nimage_transport_LIB_DEPENDS:STATIC=general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//Value Computed by CMake\nimage_transport_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/image_common/image_transport\n//Dependencies for the target\nimage_transport_plugins_LIB_DEPENDS:STATIC=general;image_transport; //Value\nComputed by CMake\nindustrial_core_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/industrial_core/industrial_core\n//Value Computed by CMake\nindustrial_core_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/industrial_core/industrial_core\n//Value Computed by CMake\nindustrial_deprecated_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/industrial_core/industrial_deprecated\n//Value Computed by CMake\nindustrial_deprecated_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/industrial_core/industrial_deprecated\n//Value Computed by CMake\nindustrial_msgs_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/industrial_core/industrial_msgs\n//The directory containing a CMake configuration file for industrial_msgs.\nindustrial_msgs_DIR:PATH=/home/robuter/catkin_ws/devel/share/industrial_msgs/cmake\n//Value Computed by CMake\nindustrial_msgs_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/industrial_core/industrial_msgs\n//Value Computed by CMake\nindustrial_robot_client_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/industrial_core/industrial_robot_client\n//The directory containing a CMake configuration file for\nindustrial_robot_client.\nindustrial_robot_client_DIR:PATH=/home/robuter/catkin_ws/devel/share/industrial_robot_client/cmake\n//Dependencies for the target\nindustrial_robot_client_LIB_DEPENDS:STATIC=general;simple_message; //Value\nComputed by CMake\nindustrial_robot_client_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/industrial_core/industrial_robot_client\n//Dependencies for the target\nindustrial_robot_client_bswap_LIB_DEPENDS:STATIC=general;simple_message_bswap;\n//Dependencies for target industrial_robot_client_dummy_LIB_DEPENDS:STATIC=\n//Value Computed by CMake\nindustrial_robot_simulator_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/industrial_core/industrial_robot_simulator\n//Value Computed by CMake\nindustrial_robot_simulator_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/industrial_core/industrial_robot_simulator\n//Value Computed by CMake\nindustrial_trajectory_filters_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/industrial_core/industrial_trajectory_filters\n//The directory containing a CMake configuration file for\nindustrial_trajectory_filters.\nindustrial_trajectory_filters_DIR:PATH=/home/robuter/catkin_ws/devel/share/industrial_trajectory_filters/cmake\n//Dependencies for the target\nindustrial_trajectory_filters_LIB_DEPENDS:STATIC=general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//Value Computed by CMake\nindustrial_trajectory_filters_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/industrial_core/industrial_trajectory_filters\n//Value Computed by CMake\nindustrial_utils_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/industrial_core/industrial_utils\n//The directory containing a CMake configuration file for industrial_utils.\nindustrial_utils_DIR:PATH=/home/robuter/catkin_ws/devel/share/industrial_utils/cmake\n//Dependencies for the target\nindustrial_utils_LIB_DEPENDS:STATIC=general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//Value Computed by CMake\nindustrial_utils_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/industrial_core/industrial_utils\n//The directory containing a CMake configuration file for interactive_markers.\ninteractive_markers_DIR:PATH=/opt/ros/kinetic/share/interactive_markers/cmake\n//The directory containing a CMake configuration file for kdl_conversions.\nkdl_conversions_DIR:PATH=/opt/ros/kinetic/share/kdl_conversions/cmake //The\ndirectory containing a CMake configuration file for kdl_parser.\nkdl_parser_DIR:PATH=/opt/ros/kinetic/share/kdl_parser/cmake //The directory\ncontaining a CMake configuration file for laser_geometry.\nlaser_geometry_DIR:PATH=/opt/ros/kinetic/share/laser_geometry/cmake //Path to\na library. lib:FILEPATH=/opt/ros/kinetic/lib/libkdl_conversions.so\n//Dependencies for the target\nlibhokuyo_LIB_DEPENDS:STATIC=general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//The directory containing a CMake configuration file for map_msgs.\nmap_msgs_DIR:PATH=/opt/ros/kinetic/share/map_msgs/cmake //The directory\ncontaining a CMake configuration file for message_filters.\nmessage_filters_DIR:PATH=/opt/ros/kinetic/share/message_filters/cmake //The\ndirectory containing a CMake configuration file for message_generation.\nmessage_generation_DIR:PATH=/opt/ros/kinetic/share/message_generation/cmake\n//The directory containing a CMake configuration file for message_runtime.\nmessage_runtime_DIR:PATH=/opt/ros/kinetic/share/message_runtime/cmake //Value\nComputed by CMake\nmoveit_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-kinetic-\ndevel/moveit //Value Computed by CMake\nmoveit_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-kinetic-\ndevel/moveit //Dependencies for the target\nmoveit_background_processing_LIB_DEPENDS:STATIC=general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_collision_detection_LIB_DEPENDS:STATIC=general;moveit_robot_state;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_collision_detection_fcl_LIB_DEPENDS:STATIC=general;moveit_collision_detection;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libfcl.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_collision_distance_field_LIB_DEPENDS:STATIC=general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libresource_retriever.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_collision_plugin_loader_LIB_DEPENDS:STATIC=general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libdynamic_reconfigure_config_init_mutex.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//Value Computed by CMake\nmoveit_commander_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_commander //Value Computed by CMake\nmoveit_commander_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-kinetic-\ndevel/moveit_commander //Dependencies for the target\nmoveit_common_planning_interface_objects_LIB_DEPENDS:STATIC=general;moveit_warehouse;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_python.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_constraint_sampler_manager_loader_LIB_DEPENDS:STATIC=general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libdynamic_reconfigure_config_init_mutex.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//Dependencies for the target\nmoveit_constraint_samplers_LIB_DEPENDS:STATIC=general;moveit_robot_state;general;moveit_kinematic_constraints;general;moveit_kinematics_base;general;moveit_planning_scene;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so; //Value\nComputed by CMake\nmoveit_controller_manager_example_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_plugins/moveit_controller_manager_example //Dependencies\nfor the target\nmoveit_controller_manager_example_LIB_DEPENDS:STATIC=general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Value Computed by CMake\nmoveit_controller_manager_example_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_plugins/moveit_controller_manager_example //Value\nComputed by CMake\nmoveit_core_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-kinetic-\ndevel/moveit_core //The directory containing a CMake configuration file for\nmoveit_core.\nmoveit_core_DIR:PATH=/home/robuter/catkin_ws/devel/share/moveit_core/cmake\n//Value Computed by CMake\nmoveit_core_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-kinetic-\ndevel/moveit_core //Dependencies for the target\nmoveit_default_planning_request_adapter_plugins_LIB_DEPENDS:STATIC=general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libdynamic_reconfigure_config_init_mutex.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_depth_image_octomap_updater_LIB_DEPENDS:STATIC=general;moveit_depth_image_octomap_updater_core;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libtf2.so;general;image_transport;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_depth_image_octomap_updater_core_LIB_DEPENDS:STATIC=general;moveit_lazy_free_space_updater;general;moveit_mesh_filter;general;moveit_occupancy_map_monitor;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libtf2.so;general;image_transport;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_distance_field_LIB_DEPENDS:STATIC=general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_dynamics_solver_LIB_DEPENDS:STATIC=general;moveit_robot_state;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_exceptions_LIB_DEPENDS:STATIC=general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so; //Value\nComputed by CMake\nmoveit_experimental_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_experimental //The directory containing a CMake\nconfiguration file for moveit_experimental.\nmoveit_experimental_DIR:PATH=/home/robuter/catkin_ws/devel/share/moveit_experimental/cmake\n//Value Computed by CMake\nmoveit_experimental_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_experimental //Value Computed by CMake\nmoveit_fake_controller_manager_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_plugins/moveit_fake_controller_manager //Dependencies for\nthe target\nmoveit_fake_controller_manager_LIB_DEPENDS:STATIC=general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Value Computed by CMake\nmoveit_fake_controller_manager_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_plugins/moveit_fake_controller_manager //Dependencies for\nthe target\nmoveit_kdl_kinematics_plugin_LIB_DEPENDS:STATIC=general;moveit_rdf_loader;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//Dependencies for the target\nmoveit_kinematic_constraints_LIB_DEPENDS:STATIC=general;moveit_robot_model;general;moveit_kinematics_base;general;moveit_robot_state;general;moveit_collision_detection_fcl;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so; //Value\nComputed by CMake\nmoveit_kinematics_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_kinematics //Value Computed by CMake\nmoveit_kinematics_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_kinematics //Dependencies for the target\nmoveit_kinematics_base_LIB_DEPENDS:STATIC=general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_kinematics_metrics_LIB_DEPENDS:STATIC=general;moveit_robot_state;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_kinematics_plugin_loader_LIB_DEPENDS:STATIC=general;moveit_rdf_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libdynamic_reconfigure_config_init_mutex.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//Dependencies for the target\nmoveit_lazy_free_space_updater_LIB_DEPENDS:STATIC=general;moveit_occupancy_map_monitor;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libtf2.so;general;image_transport;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_lma_kinematics_plugin_LIB_DEPENDS:STATIC=general;moveit_rdf_loader;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//Dependencies for the target\nmoveit_mesh_filter_LIB_DEPENDS:STATIC=general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libtf2.so;general;image_transport;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libGLU.so;general;/usr/lib/x86_64-linux-\ngnu/libGL.so;general;glut;general;GLEW; //Dependencies for the target\nmoveit_motion_planning_rviz_plugin_LIB_DEPENDS:STATIC=general;moveit_motion_planning_rviz_plugin_core;general;moveit_common_planning_interface_objects;general;moveit_planning_scene_interface;general;moveit_move_group_interface;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_robot_interaction;general;moveit_warehouse;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/librviz.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreOverlay.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreMain.so;general;/usr/lib/x86_64-linux-\ngnu/libGLU.so;general;/usr/lib/x86_64-linux-\ngnu/libGL.so;general;image_transport;general;/opt/ros/kinetic/lib/libinteractive_markers.so;general;/opt/ros/kinetic/lib/liblaser_geometry.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libresource_retriever.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_motion_planning_rviz_plugin_core_LIB_DEPENDS:STATIC=general;moveit_rviz_plugin_render_tools;general;moveit_planning_scene_rviz_plugin_core;general;moveit_common_planning_interface_objects;general;moveit_planning_scene_interface;general;moveit_move_group_interface;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_robot_interaction;general;moveit_warehouse;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/librviz.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreOverlay.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreMain.so;general;/usr/lib/x86_64-linux-\ngnu/libGLU.so;general;/usr/lib/x86_64-linux-\ngnu/libGL.so;general;image_transport;general;/opt/ros/kinetic/lib/libinteractive_markers.so;general;/opt/ros/kinetic/lib/liblaser_geometry.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libresource_retriever.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/opt/ros/kinetic/share/rviz/cmake/../../../lib/librviz_default_plugin.so;general;OgreMain;general;pthread;general;Qt5::Widgets;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_move_group_capabilities_base_LIB_DEPENDS:STATIC=general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_move_group_default_capabilities_LIB_DEPENDS:STATIC=general;moveit_move_group_capabilities_base;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_move_group_interface_LIB_DEPENDS:STATIC=general;moveit_common_planning_interface_objects;general;moveit_planning_scene_interface;general;moveit_warehouse;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_python.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_move_group_interface_python_LIB_DEPENDS:STATIC=general;moveit_move_group_interface;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;moveit_warehouse;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_python.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;moveit_py_bindings_tools; //Dependencies for the\ntarget\nmoveit_move_group_pick_place_capability_LIB_DEPENDS:STATIC=general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libdynamic_reconfigure_config_init_mutex.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so; //The\ndirectory containing a CMake configuration file for moveit_msgs.\nmoveit_msgs_DIR:PATH=/opt/ros/kinetic/share/moveit_msgs/cmake //Dependencies\nfor the target\nmoveit_occupancy_map_monitor_LIB_DEPENDS:STATIC=general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libtf2.so;general;image_transport;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_ompl_interface_LIB_DEPENDS:STATIC=general;/opt/ros/kinetic/lib/x86_64-linux-\ngnu/libompl.so;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libdynamic_reconfigure_config_init_mutex.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_serialization.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_ompl_planner_plugin_LIB_DEPENDS:STATIC=general;moveit_ompl_interface;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libdynamic_reconfigure_config_init_mutex.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_serialization.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_pick_place_planner_LIB_DEPENDS:STATIC=general;moveit_move_group_capabilities_base;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libdynamic_reconfigure_config_init_mutex.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_plan_execution_LIB_DEPENDS:STATIC=general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_planning_scene_monitor;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libdynamic_reconfigure_config_init_mutex.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Value Computed by CMake\nmoveit_planners_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_planners/moveit_planners //Value Computed by CMake\nmoveit_planners_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-kinetic-\ndevel/moveit_planners/moveit_planners //Value Computed by CMake\nmoveit_planners_chomp_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_planners/chomp/chomp_interface //Dependencies for the\ntarget\nmoveit_planners_chomp_LIB_DEPENDS:STATIC=general;chomp_motion_planner;general;moveit_collision_distance_field;general;collision_detector_hybrid_plugin;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-gnu/libtinyxml.so;\n//Value Computed by CMake\nmoveit_planners_chomp_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_planners/chomp/chomp_interface //Value Computed by CMake\nmoveit_planners_ompl_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_planners/ompl //Value Computed by CMake\nmoveit_planners_ompl_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_planners/ompl //Dependencies for the target\nmoveit_planning_interface_LIB_DEPENDS:STATIC=general;moveit_robot_state;general;moveit_robot_trajectory;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_planning_pipeline_LIB_DEPENDS:STATIC=general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libdynamic_reconfigure_config_init_mutex.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_planning_request_adapter_LIB_DEPENDS:STATIC=general;moveit_planning_scene;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_planning_scene_LIB_DEPENDS:STATIC=general;moveit_robot_model;general;moveit_robot_state;general;moveit_exceptions;general;moveit_transforms;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_robot_trajectory;general;moveit_trajectory_processing;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_planning_scene_interface_LIB_DEPENDS:STATIC=general;moveit_common_planning_interface_objects;general;moveit_warehouse;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_python.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_planning_scene_interface_python_LIB_DEPENDS:STATIC=general;moveit_planning_scene_interface;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;moveit_warehouse;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_python.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;moveit_py_bindings_tools; //Dependencies for the\ntarget\nmoveit_planning_scene_monitor_LIB_DEPENDS:STATIC=general;moveit_robot_model_loader;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libdynamic_reconfigure_config_init_mutex.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_planning_scene_rviz_plugin_LIB_DEPENDS:STATIC=general;moveit_planning_scene_rviz_plugin_core;general;moveit_common_planning_interface_objects;general;moveit_planning_scene_interface;general;moveit_move_group_interface;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_robot_interaction;general;moveit_warehouse;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/librviz.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreOverlay.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreMain.so;general;/usr/lib/x86_64-linux-\ngnu/libGLU.so;general;/usr/lib/x86_64-linux-\ngnu/libGL.so;general;image_transport;general;/opt/ros/kinetic/lib/libinteractive_markers.so;general;/opt/ros/kinetic/lib/liblaser_geometry.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libresource_retriever.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_planning_scene_rviz_plugin_core_LIB_DEPENDS:STATIC=general;moveit_rviz_plugin_render_tools;general;moveit_common_planning_interface_objects;general;moveit_planning_scene_interface;general;moveit_move_group_interface;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_robot_interaction;general;moveit_warehouse;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/librviz.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreOverlay.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreMain.so;general;/usr/lib/x86_64-linux-\ngnu/libGLU.so;general;/usr/lib/x86_64-linux-\ngnu/libGL.so;general;image_transport;general;/opt/ros/kinetic/lib/libinteractive_markers.so;general;/opt/ros/kinetic/lib/liblaser_geometry.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libresource_retriever.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;OgreMain;general;pthread;general;Qt5::Widgets;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Value Computed by CMake\nmoveit_plugins_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-kinetic-\ndevel/moveit_plugins/moveit_plugins //Value Computed by CMake\nmoveit_plugins_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-kinetic-\ndevel/moveit_plugins/moveit_plugins //Dependencies for the target\nmoveit_point_containment_filter_LIB_DEPENDS:STATIC=general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libtf2.so;general;image_transport;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_pointcloud_octomap_updater_LIB_DEPENDS:STATIC=general;moveit_pointcloud_octomap_updater_core;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libtf2.so;general;image_transport;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_pointcloud_octomap_updater_core_LIB_DEPENDS:STATIC=general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libtf2.so;general;image_transport;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_profiler_LIB_DEPENDS:STATIC=general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_py_bindings_tools_LIB_DEPENDS:STATIC=general;moveit_warehouse;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_python.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libpython2.7.so;\n//Dependencies for the target\nmoveit_py_bindings_tools_python_LIB_DEPENDS:STATIC=general;moveit_py_bindings_tools;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;moveit_warehouse;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_python.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_rdf_loader_LIB_DEPENDS:STATIC=general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libdynamic_reconfigure_config_init_mutex.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//Value Computed by CMake\nmoveit_resources_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit_resources-\nmaster //The directory containing a CMake configuration file for\nmoveit_resources.\nmoveit_resources_DIR:PATH=/home/robuter/catkin_ws/devel/share/moveit_resources/cmake\n//Value Computed by CMake\nmoveit_resources_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit_resources-\nmaster //Dependencies for the target\nmoveit_robot_interaction_LIB_DEPENDS:STATIC=general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libinteractive_markers.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_robot_interface_python_LIB_DEPENDS:STATIC=general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;moveit_warehouse;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_python.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;moveit_common_planning_interface_objects;general;moveit_py_bindings_tools;\n//Dependencies for the target\nmoveit_robot_model_LIB_DEPENDS:STATIC=general;moveit_profiler;general;moveit_exceptions;general;moveit_kinematics_base;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_robot_model_loader_LIB_DEPENDS:STATIC=general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libdynamic_reconfigure_config_init_mutex.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//Dependencies for the target\nmoveit_robot_state_LIB_DEPENDS:STATIC=general;moveit_robot_model;general;moveit_kinematics_base;general;moveit_transforms;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_robot_state_rviz_plugin_LIB_DEPENDS:STATIC=general;moveit_robot_state_rviz_plugin_core;general;moveit_common_planning_interface_objects;general;moveit_planning_scene_interface;general;moveit_move_group_interface;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_robot_interaction;general;moveit_warehouse;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/librviz.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreOverlay.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreMain.so;general;/usr/lib/x86_64-linux-\ngnu/libGLU.so;general;/usr/lib/x86_64-linux-\ngnu/libGL.so;general;image_transport;general;/opt/ros/kinetic/lib/libinteractive_markers.so;general;/opt/ros/kinetic/lib/liblaser_geometry.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libresource_retriever.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_robot_state_rviz_plugin_core_LIB_DEPENDS:STATIC=general;moveit_rviz_plugin_render_tools;general;moveit_common_planning_interface_objects;general;moveit_planning_scene_interface;general;moveit_move_group_interface;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_robot_interaction;general;moveit_warehouse;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/librviz.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreOverlay.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreMain.so;general;/usr/lib/x86_64-linux-\ngnu/libGLU.so;general;/usr/lib/x86_64-linux-\ngnu/libGL.so;general;image_transport;general;/opt/ros/kinetic/lib/libinteractive_markers.so;general;/opt/ros/kinetic/lib/liblaser_geometry.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libresource_retriever.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;OgreMain;general;pthread;general;Qt5::Widgets;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_robot_trajectory_LIB_DEPENDS:STATIC=general;moveit_robot_model;general;moveit_robot_state;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so; //Value\nComputed by CMake\nmoveit_ros_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-kinetic-\ndevel/moveit_ros/moveit_ros //Value Computed by CMake\nmoveit_ros_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-kinetic-\ndevel/moveit_ros/moveit_ros //Value Computed by CMake\nmoveit_ros_benchmarks_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_ros/benchmarks //Dependencies for the target\nmoveit_ros_benchmarks_LIB_DEPENDS:STATIC=general;moveit_warehouse;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so; //Value Computed by CMake\nmoveit_ros_benchmarks_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_ros/benchmarks //Value Computed by CMake\nmoveit_ros_control_interface_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_plugins/moveit_ros_control_interface //Value Computed by\nCMake\nmoveit_ros_control_interface_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_plugins/moveit_ros_control_interface //Dependencies for\nthe target\nmoveit_ros_control_interface_plugin_LIB_DEPENDS:STATIC=general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_ros_control_interface_trajectory_plugin_LIB_DEPENDS:STATIC=general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Value Computed by CMake\nmoveit_ros_manipulation_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_ros/manipulation //The directory containing a CMake\nconfiguration file for moveit_ros_manipulation.\nmoveit_ros_manipulation_DIR:PATH=/home/robuter/catkin_ws/devel/share/moveit_ros_manipulation/cmake\n//Value Computed by CMake\nmoveit_ros_manipulation_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_ros/manipulation //Value Computed by CMake\nmoveit_ros_move_group_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_ros/move_group //The directory containing a CMake\nconfiguration file for moveit_ros_move_group.\nmoveit_ros_move_group_DIR:PATH=/home/robuter/catkin_ws/devel/share/moveit_ros_move_group/cmake\n//Value Computed by CMake\nmoveit_ros_move_group_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_ros/move_group //Value Computed by CMake\nmoveit_ros_perception_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_ros/perception //The directory containing a CMake\nconfiguration file for moveit_ros_perception.\nmoveit_ros_perception_DIR:PATH=/home/robuter/catkin_ws/devel/share/moveit_ros_perception/cmake\n//Value Computed by CMake\nmoveit_ros_perception_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_ros/perception //Value Computed by CMake\nmoveit_ros_planning_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_ros/planning //The directory containing a CMake\nconfiguration file for moveit_ros_planning.\nmoveit_ros_planning_DIR:PATH=/home/robuter/catkin_ws/devel/share/moveit_ros_planning/cmake\n//Value Computed by CMake\nmoveit_ros_planning_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_ros/planning //Value Computed by CMake\nmoveit_ros_planning_interface_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_ros/planning_interface //The directory containing a CMake\nconfiguration file for moveit_ros_planning_interface.\nmoveit_ros_planning_interface_DIR:PATH=/home/robuter/catkin_ws/devel/share/moveit_ros_planning_interface/cmake\n//Value Computed by CMake\nmoveit_ros_planning_interface_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_ros/planning_interface //Value Computed by CMake\nmoveit_ros_robot_interaction_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_ros/robot_interaction //The directory containing a CMake\nconfiguration file for moveit_ros_robot_interaction.\nmoveit_ros_robot_interaction_DIR:PATH=/home/robuter/catkin_ws/devel/share/moveit_ros_robot_interaction/cmake\n//Value Computed by CMake\nmoveit_ros_robot_interaction_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_ros/robot_interaction //Value Computed by CMake\nmoveit_ros_visualization_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_ros/visualization //The directory containing a CMake\nconfiguration file for moveit_ros_visualization.\nmoveit_ros_visualization_DIR:PATH=/home/robuter/catkin_ws/devel/share/moveit_ros_visualization/cmake\n//Value Computed by CMake\nmoveit_ros_visualization_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_ros/visualization //Value Computed by CMake\nmoveit_ros_warehouse_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_ros/warehouse //The directory containing a CMake\nconfiguration file for moveit_ros_warehouse.\nmoveit_ros_warehouse_DIR:PATH=/home/robuter/catkin_ws/devel/share/moveit_ros_warehouse/cmake\n//Value Computed by CMake\nmoveit_ros_warehouse_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_ros/warehouse //Value Computed by CMake\nmoveit_runtime_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-kinetic-\ndevel/moveit_runtime //Value Computed by CMake\nmoveit_runtime_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-kinetic-\ndevel/moveit_runtime //Dependencies for the target\nmoveit_rviz_plugin_render_tools_LIB_DEPENDS:STATIC=general;moveit_common_planning_interface_objects;general;moveit_planning_scene_interface;general;moveit_move_group_interface;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_robot_interaction;general;moveit_warehouse;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/librviz.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreOverlay.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreMain.so;general;/usr/lib/x86_64-linux-\ngnu/libGLU.so;general;/usr/lib/x86_64-linux-\ngnu/libGL.so;general;image_transport;general;/opt/ros/kinetic/lib/libinteractive_markers.so;general;/opt/ros/kinetic/lib/liblaser_geometry.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libresource_retriever.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;OgreMain;general;pthread;general;Qt5::Widgets;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_semantic_world_LIB_DEPENDS:STATIC=general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libtf2.so;general;image_transport;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;opencv_calib3d;general;opencv_core;general;opencv_features2d;general;opencv_flann;general;opencv_highgui;general;opencv_imgcodecs;general;opencv_imgproc;general;opencv_ml;general;opencv_objdetect;general;opencv_photo;general;opencv_shape;general;opencv_stitching;general;opencv_superres;general;opencv_video;general;opencv_videoio;general;opencv_videostab;general;opencv_viz;general;opencv_aruco;general;opencv_bgsegm;general;opencv_bioinspired;general;opencv_ccalib;general;opencv_cvv;general;opencv_datasets;general;opencv_dpm;general;opencv_face;general;opencv_fuzzy;general;opencv_hdf;general;opencv_line_descriptor;general;opencv_optflow;general;opencv_phase_unwrapping;general;opencv_plot;general;opencv_reg;general;opencv_rgbd;general;opencv_saliency;general;opencv_stereo;general;opencv_structured_light;general;opencv_surface_matching;general;opencv_text;general;opencv_xfeatures2d;general;opencv_ximgproc;general;opencv_xobjdetect;general;opencv_xphoto;\n//Value Computed by CMake\nmoveit_setup_assistant_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_setup_assistant //Value Computed by CMake\nmoveit_setup_assistant_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_setup_assistant //Dependencies for the target\nmoveit_setup_assistant_tools_LIB_DEPENDS:STATIC=general;/usr/lib/x86_64-linux-\ngnu/libyaml-\ncpp.so;general;moveit_rviz_plugin_render_tools;general;moveit_robot_state_rviz_plugin_core;general;moveit_motion_planning_rviz_plugin_core;general;moveit_trajectory_rviz_plugin_core;general;moveit_planning_scene_rviz_plugin_core;general;moveit_common_planning_interface_objects;general;moveit_planning_scene_interface;general;moveit_move_group_interface;general;moveit_warehouse;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_robot_interaction;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/librviz.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreOverlay.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreMain.so;general;/usr/lib/x86_64-linux-\ngnu/libGLU.so;general;/usr/lib/x86_64-linux-\ngnu/libGL.so;general;image_transport;general;/opt/ros/kinetic/lib/libinteractive_markers.so;general;/opt/ros/kinetic/lib/liblaser_geometry.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libresource_retriever.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;Qt5::Widgets; //Dependencies for the target\nmoveit_setup_assistant_widgets_LIB_DEPENDS:STATIC=general;moveit_setup_assistant_tools;general;Qt5::Widgets;general;moveit_rviz_plugin_render_tools;general;moveit_robot_state_rviz_plugin_core;general;moveit_motion_planning_rviz_plugin_core;general;moveit_trajectory_rviz_plugin_core;general;moveit_planning_scene_rviz_plugin_core;general;moveit_common_planning_interface_objects;general;moveit_planning_scene_interface;general;moveit_move_group_interface;general;moveit_warehouse;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_robot_interaction;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/librviz.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreOverlay.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreMain.so;general;/usr/lib/x86_64-linux-\ngnu/libGLU.so;general;/usr/lib/x86_64-linux-\ngnu/libGL.so;general;image_transport;general;/opt/ros/kinetic/lib/libinteractive_markers.so;general;/opt/ros/kinetic/lib/liblaser_geometry.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libresource_retriever.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Value Computed by CMake\nmoveit_simple_controller_manager_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/moveit-\nkinetic-devel/moveit_plugins/moveit_simple_controller_manager //The directory\ncontaining a CMake configuration file for moveit_simple_controller_manager.\nmoveit_simple_controller_manager_DIR:PATH=/home/robuter/catkin_ws/devel/share/moveit_simple_controller_manager/cmake\n//Dependencies for the target\nmoveit_simple_controller_manager_LIB_DEPENDS:STATIC=general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Value Computed by CMake\nmoveit_simple_controller_manager_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/moveit-\nkinetic-devel/moveit_plugins/moveit_simple_controller_manager //Dependencies\nfor the target\nmoveit_srv_kinematics_plugin_LIB_DEPENDS:STATIC=general;moveit_rdf_loader;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//Dependencies for the target\nmoveit_trajectory_execution_manager_LIB_DEPENDS:STATIC=general;moveit_planning_scene_monitor;general;moveit_robot_model_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libdynamic_reconfigure_config_init_mutex.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_trajectory_processing_LIB_DEPENDS:STATIC=general;moveit_robot_state;general;moveit_robot_trajectory;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_trajectory_rviz_plugin_LIB_DEPENDS:STATIC=general;moveit_trajectory_rviz_plugin_core;general;moveit_common_planning_interface_objects;general;moveit_planning_scene_interface;general;moveit_move_group_interface;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_robot_interaction;general;moveit_warehouse;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/librviz.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreOverlay.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreMain.so;general;/usr/lib/x86_64-linux-\ngnu/libGLU.so;general;/usr/lib/x86_64-linux-\ngnu/libGL.so;general;image_transport;general;/opt/ros/kinetic/lib/libinteractive_markers.so;general;/opt/ros/kinetic/lib/liblaser_geometry.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libresource_retriever.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_trajectory_rviz_plugin_core_LIB_DEPENDS:STATIC=general;moveit_rviz_plugin_render_tools;general;moveit_planning_scene_rviz_plugin_core;general;moveit_common_planning_interface_objects;general;moveit_planning_scene_interface;general;moveit_move_group_interface;general;moveit_pick_place_planner;general;moveit_move_group_capabilities_base;general;moveit_robot_interaction;general;moveit_warehouse;general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/librviz.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreOverlay.so;general;/usr/lib/x86_64-linux-\ngnu/libOgreMain.so;general;/usr/lib/x86_64-linux-\ngnu/libGLU.so;general;/usr/lib/x86_64-linux-\ngnu/libGL.so;general;image_transport;general;/opt/ros/kinetic/lib/libinteractive_markers.so;general;/opt/ros/kinetic/lib/liblaser_geometry.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libresource_retriever.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;OgreMain;general;pthread;general;Qt5::Widgets;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_transforms_LIB_DEPENDS:STATIC=general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Dependencies for the target\nmoveit_warehouse_LIB_DEPENDS:STATIC=general;moveit_rdf_loader;general;moveit_kinematics_plugin_loader;general;moveit_robot_model_loader;general;moveit_constraint_sampler_manager_loader;general;moveit_planning_pipeline;general;moveit_trajectory_execution_manager;general;moveit_plan_execution;general;moveit_planning_scene_monitor;general;moveit_collision_plugin_loader;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libwarehouse_ros.so;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so; //The\ndirectory containing a CMake configuration file for nav_msgs.\nnav_msgs_DIR:PATH=/opt/ros/kinetic/share/nav_msgs/cmake //The directory\ncontaining a CMake configuration file for nodelet.\nnodelet_DIR:PATH=/opt/ros/kinetic/share/nodelet/cmake //The directory\ncontaining a CMake configuration file for object_recognition_msgs.\nobject_recognition_msgs_DIR:PATH=/opt/ros/kinetic/share/object_recognition_msgs/cmake\n//The directory containing a CMake configuration file for octomap.\noctomap_DIR:PATH=/opt/ros/kinetic/share/octomap //The directory containing a\nCMake configuration file for octomap_msgs.\noctomap_msgs_DIR:PATH=/opt/ros/kinetic/share/octomap_msgs/cmake //Path to a\nlibrary. onelib:FILEPATH=/usr/lib/x86_64-linux-gnu/liburdfdom_world.so //The\ndirectory containing a CMake configuration file for orocos_kdl.\norocos_kdl_DIR:PATH=/opt/ros/kinetic/share/orocos_kdl //The directory\ncontaining a CMake configuration file for pcl_conversions.\npcl_conversions_DIR:PATH=/opt/ros/kinetic/share/pcl_conversions/cmake //The\ndirectory containing a CMake configuration file for pcl_msgs.\npcl_msgs_DIR:PATH=/opt/ros/kinetic/share/pcl_msgs/cmake //The directory\ncontaining a CMake configuration file for pcl_ros.\npcl_ros_DIR:PATH=/opt/ros/kinetic/share/pcl_ros/cmake //The directory\ncontaining a CMake configuration file for pluginlib.\npluginlib_DIR:PATH=/opt/ros/kinetic/share/pluginlib/cmake //Value Computed by\nCMake\npolled_camera_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/image_common/polled_camera\n//Dependencies for the target\npolled_camera_LIB_DEPENDS:STATIC=general;image_transport;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//Value Computed by CMake\npolled_camera_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/image_common/polled_camera\n//The directory containing a CMake configuration file for qt_gui.\nqt_gui_DIR:PATH=/opt/ros/kinetic/share/qt_gui/cmake //The directory containing\na CMake configuration file for qt_gui_cpp.\nqt_gui_cpp_DIR:PATH=/opt/ros/kinetic/share/qt_gui_cpp/cmake //Value Computed\nby CMake r_image_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/r_image\n//Value Computed by CMake\nr_image_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/r_image //Value Computed\nby CMake r_platform_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/r_platform\n//The directory containing a CMake configuration file for r_platform.\nr_platform_DIR:PATH=/home/robuter/catkin_ws/devel/share/r_platform/cmake\n//Value Computed by CMake\nr_platform_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/r_platform //The\ndirectory containing a CMake configuration file for random_numbers.\nrandom_numbers_DIR:PATH=/opt/ros/kinetic/share/random_numbers/cmake //The\ndirectory containing a CMake configuration file for resource_retriever.\nresource_retriever_DIR:PATH=/opt/ros/kinetic/share/resource_retriever/cmake\n//Value Computed by CMake\nrobanuc_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/robanuc //Value\nComputed by CMake\nrobanuc_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/robanuc //Value Computed\nby CMake robonuc_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/robonuc\n//Value Computed by CMake\nrobonuc_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/robonuc //The directory\ncontaining a CMake configuration file for rosbag.\nrosbag_DIR:PATH=/opt/ros/kinetic/share/rosbag/cmake //The directory containing\na CMake configuration file for rosbag_storage.\nrosbag_storage_DIR:PATH=/opt/ros/kinetic/share/rosbag_storage/cmake //The\ndirectory containing a CMake configuration file for rosconsole.\nrosconsole_DIR:PATH=/opt/ros/kinetic/share/rosconsole/cmake //The directory\ncontaining a CMake configuration file for rosconsole_bridge.\nrosconsole_bridge_DIR:PATH=/opt/ros/kinetic/share/rosconsole_bridge/cmake\n//The directory containing a CMake configuration file for roscpp.\nroscpp_DIR:PATH=/opt/ros/kinetic/share/roscpp/cmake //The directory containing\na CMake configuration file for roscpp_serialization.\nroscpp_serialization_DIR:PATH=/opt/ros/kinetic/share/roscpp_serialization/cmake\n//The directory containing a CMake configuration file for roscpp_traits.\nroscpp_traits_DIR:PATH=/opt/ros/kinetic/share/roscpp_traits/cmake //The\ndirectory containing a CMake configuration file for rosgraph.\nrosgraph_DIR:PATH=/opt/ros/kinetic/share/rosgraph/cmake //The directory\ncontaining a CMake configuration file for rosgraph_msgs.\nrosgraph_msgs_DIR:PATH=/opt/ros/kinetic/share/rosgraph_msgs/cmake //The\ndirectory containing a CMake configuration file for roslaunch.\nroslaunch_DIR:PATH=/opt/ros/kinetic/share/roslaunch/cmake //The directory\ncontaining a CMake configuration file for roslib.\nroslib_DIR:PATH=/opt/ros/kinetic/share/roslib/cmake //The directory containing\na CMake configuration file for roslz4.\nroslz4_DIR:PATH=/opt/ros/kinetic/share/roslz4/cmake //The directory containing\na CMake configuration file for rospack.\nrospack_DIR:PATH=/opt/ros/kinetic/share/rospack/cmake //The directory\ncontaining a CMake configuration file for rospy.\nrospy_DIR:PATH=/opt/ros/kinetic/share/rospy/cmake //The directory containing a\nCMake configuration file for rostest.\nrostest_DIR:PATH=/opt/ros/kinetic/share/rostest/cmake //The directory\ncontaining a CMake configuration file for rostime.\nrostime_DIR:PATH=/opt/ros/kinetic/share/rostime/cmake //The directory\ncontaining a CMake configuration file for rqt_gui.\nrqt_gui_DIR:PATH=/opt/ros/kinetic/share/rqt_gui/cmake //The directory\ncontaining a CMake configuration file for rqt_gui_cpp.\nrqt_gui_cpp_DIR:PATH=/opt/ros/kinetic/share/rqt_gui_cpp/cmake //The directory\ncontaining a CMake configuration file for rviz.\nrviz_DIR:PATH=/opt/ros/kinetic/share/rviz/cmake //The directory containing a\nCMake configuration file for self_test.\nself_test_DIR:PATH=/opt/ros/kinetic/share/self_test/cmake //The directory\ncontaining a CMake configuration file for sensor_msgs.\nsensor_msgs_DIR:PATH=/opt/ros/kinetic/share/sensor_msgs/cmake //The directory\ncontaining a CMake configuration file for shape_msgs.\nshape_msgs_DIR:PATH=/opt/ros/kinetic/share/shape_msgs/cmake //Value Computed\nby CMake\nsimple_message_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/industrial_core/simple_message\n//The directory containing a CMake configuration file for simple_message.\nsimple_message_DIR:PATH=/home/robuter/catkin_ws/devel/share/simple_message/cmake\n//Dependencies for the target\nsimple_message_LIB_DEPENDS:STATIC=general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//Value Computed by CMake\nsimple_message_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/industrial_core/simple_message\n//Dependencies for the target\nsimple_message_bswap_LIB_DEPENDS:STATIC=general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//Dependencies for target simple_message_dummy_LIB_DEPENDS:STATIC=\n//Dependencies for the target\nsimple_message_float64_LIB_DEPENDS:STATIC=general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-gnu/libconsole_bridge.so;\n//The directory containing a CMake configuration file for smclib.\nsmclib_DIR:PATH=/opt/ros/kinetic/share/smclib/cmake //The directory containing\na CMake configuration file for srdfdom.\nsrdfdom_DIR:PATH=/opt/ros/kinetic/share/srdfdom/cmake //The directory\ncontaining a CMake configuration file for std_msgs.\nstd_msgs_DIR:PATH=/opt/ros/kinetic/share/std_msgs/cmake //The directory\ncontaining a CMake configuration file for std_srvs.\nstd_srvs_DIR:PATH=/opt/ros/kinetic/share/std_srvs/cmake //Dependencies for the\ntarget\ntest_controller_manager_plugin_LIB_DEPENDS:STATIC=general;moveit_trajectory_execution_manager;general;moveit_lazy_free_space_updater;general;moveit_point_containment_filter;general;moveit_occupancy_map_monitor;general;moveit_pointcloud_octomap_updater_core;general;moveit_semantic_world;general;moveit_exceptions;general;moveit_background_processing;general;moveit_kinematics_base;general;moveit_robot_model;general;moveit_transforms;general;moveit_robot_state;general;moveit_robot_trajectory;general;moveit_planning_interface;general;moveit_collision_detection;general;moveit_collision_detection_fcl;general;moveit_kinematic_constraints;general;moveit_planning_scene;general;moveit_constraint_samplers;general;moveit_planning_request_adapter;general;moveit_profiler;general;moveit_trajectory_processing;general;moveit_distance_field;general;moveit_kinematics_metrics;general;moveit_dynamics_solver;general;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;general;/opt/ros/kinetic/lib/libeigen_conversions.so;general;/opt/ros/kinetic/lib/libgeometric_shapes.so;general;/opt/ros/kinetic/lib/liboctomap.so;general;/opt/ros/kinetic/lib/liboctomath.so;general;/opt/ros/kinetic/lib/libkdl_parser.so;general;/opt/ros/kinetic/lib/librandom_numbers.so;general;image_transport;general;/opt/ros/kinetic/lib/libclass_loader.so;general;/usr/lib/libPocoFoundation.so;general;/usr/lib/x86_64-linux-\ngnu/libdl.so;general;/opt/ros/kinetic/lib/libroslib.so;general;/opt/ros/kinetic/lib/librospack.so;general;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libtinyxml.so;general;/opt/ros/kinetic/lib/libdynamic_reconfigure_config_init_mutex.so;general;/opt/ros/kinetic/lib/libsrdfdom.so;general;/opt/ros/kinetic/lib/liburdf.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_sensor.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model_state.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_model.so;general;/usr/lib/x86_64-linux-\ngnu/liburdfdom_world.so;general;/opt/ros/kinetic/lib/librosconsole_bridge.so;general;/opt/ros/kinetic/lib/libtf_conversions.so;general;/opt/ros/kinetic/lib/libkdl_conversions.so;general;/opt/ros/kinetic/lib/liborocos-\nkdl.so.1.3.0;general;/opt/ros/kinetic/lib/libtf.so;general;/opt/ros/kinetic/lib/libtf2_ros.so;general;/opt/ros/kinetic/lib/libactionlib.so;general;/opt/ros/kinetic/lib/libmessage_filters.so;general;/opt/ros/kinetic/lib/libroscpp.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/opt/ros/kinetic/lib/libxmlrpcpp.so;general;/opt/ros/kinetic/lib/libtf2.so;general;/opt/ros/kinetic/lib/libroscpp_serialization.so;general;/opt/ros/kinetic/lib/librosconsole.so;general;/opt/ros/kinetic/lib/librosconsole_log4cxx.so;general;/opt/ros/kinetic/lib/librosconsole_backend_interface.so;general;/usr/lib/x86_64-linux-\ngnu/liblog4cxx.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;general;/opt/ros/kinetic/lib/librostime.so;general;/opt/ros/kinetic/lib/libcpp_common.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-\ngnu/libpthread.so;general;/usr/lib/x86_64-linux-\ngnu/libconsole_bridge.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_program_options.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_signals.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;general;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;general;/usr/lib/x86_64-linux-gnu/libpthread.so;\n//Value Computed by CMake\ntest_move_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/Programacao/fanuc_rep/Fanuc/test_move\n//Value Computed by CMake\ntest_move_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/Programacao/fanuc_rep/Fanuc/test_move\n//The directory containing a CMake configuration file for tf2.\ntf2_DIR:PATH=/opt/ros/kinetic/share/tf2/cmake //The directory containing a\nCMake configuration file for tf2_msgs.\ntf2_msgs_DIR:PATH=/opt/ros/kinetic/share/tf2_msgs/cmake //The directory\ncontaining a CMake configuration file for tf2_py.\ntf2_py_DIR:PATH=/opt/ros/kinetic/share/tf2_py/cmake //The directory containing\na CMake configuration file for tf2_ros.\ntf2_ros_DIR:PATH=/opt/ros/kinetic/share/tf2_ros/cmake //The directory\ncontaining a CMake configuration file for tf.\ntf_DIR:PATH=/opt/ros/kinetic/share/tf/cmake //The directory containing a CMake\nconfiguration file for tf_conversions.\ntf_conversions_DIR:PATH=/opt/ros/kinetic/share/tf_conversions/cmake //Value\nComputed by CMake\ntimestamp_tools_BINARY_DIR:STATIC=/home/robuter/catkin_ws/build/driver_common/timestamp_tools\n//Value Computed by CMake\ntimestamp_tools_SOURCE_DIR:STATIC=/home/robuter/catkin_ws/src/driver_common/timestamp_tools\n//The directory containing a CMake configuration file for topic_tools.\ntopic_tools_DIR:PATH=/opt/ros/kinetic/share/topic_tools/cmake //The directory\ncontaining a CMake configuration file for trajectory_msgs.\ntrajectory_msgs_DIR:PATH=/opt/ros/kinetic/share/trajectory_msgs/cmake //The\ndirectory containing a CMake configuration file for urdf.\nurdf_DIR:PATH=/opt/ros/kinetic/share/urdf/cmake //The directory containing a\nCMake configuration file for urdfdom.\nurdfdom_DIR:PATH=/usr/share/urdfdom/cmake //The directory containing a CMake\nconfiguration file for urdfdom_headers.\nurdfdom_headers_DIR:PATH=/usr/share/urdfdom_headers/cmake //The directory\ncontaining a CMake configuration file for urdfdom_py.\nurdfdom_py_DIR:PATH=/opt/ros/kinetic/share/urdfdom_py/cmake //The directory\ncontaining a CMake configuration file for visualization_msgs.\nvisualization_msgs_DIR:PATH=/opt/ros/kinetic/share/visualization_msgs/cmake\n//The directory containing a CMake configuration file for warehouse_ros.\nwarehouse_ros_DIR:PATH=/opt/ros/kinetic/share/warehouse_ros/cmake //The\ndirectory containing a CMake configuration file for xmlrpcpp.\nxmlrpcpp_DIR:PATH=/opt/ros/kinetic/share/xmlrpcpp/cmake\n######################## # INTERNAL cache entries ########################\n//ADVANCED property for variable: BLAS_Accelerate_LIBRARY\nBLAS_Accelerate_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nBLAS_acml_LIBRARY BLAS_acml_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property\nfor variable: BLAS_acml_mp_LIBRARY BLAS_acml_mp_LIBRARY-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: BLAS_blas_LIBRARY BLAS_blas_LIBRARY-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: BLAS_blas_WORKS\nBLAS_blas_WORKS-ADVANCED:INTERNAL=1 //Have function sgemm_\nBLAS_blas_WORKS:INTERNAL=1 //ADVANCED property for variable:\nBLAS_complib.sgimath_LIBRARY BLAS_complib.sgimath_LIBRARY-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: BLAS_cxml_LIBRARY BLAS_cxml_LIBRARY-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: BLAS_dxml_LIBRARY\nBLAS_dxml_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nBLAS_essl_LIBRARY BLAS_essl_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property\nfor variable: BLAS_f77blas_LIBRARY BLAS_f77blas_LIBRARY-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: BLAS_goto2_LIBRARY BLAS_goto2_LIBRARY-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: BLAS_scsl_LIBRARY\nBLAS_scsl_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nBLAS_sgemm_LIBRARY BLAS_sgemm_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property\nfor variable: BLAS_sunperf_LIBRARY BLAS_sunperf_LIBRARY-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: BLAS_vecLib_LIBRARY BLAS_vecLib_LIBRARY-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nBoost_ATOMIC_LIBRARY_DEBUG Boost_ATOMIC_LIBRARY_DEBUG-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: Boost_ATOMIC_LIBRARY_RELEASE\nBoost_ATOMIC_LIBRARY_RELEASE-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: Boost_CHRONO_LIBRARY_DEBUG Boost_CHRONO_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nBoost_CHRONO_LIBRARY_RELEASE Boost_CHRONO_LIBRARY_RELEASE-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: Boost_DATE_TIME_LIBRARY_DEBUG\nBoost_DATE_TIME_LIBRARY_DEBUG-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: Boost_DATE_TIME_LIBRARY_RELEASE Boost_DATE_TIME_LIBRARY_RELEASE-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: Boost_DIR Boost_DIR-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nBoost_FILESYSTEM_LIBRARY_DEBUG Boost_FILESYSTEM_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nBoost_FILESYSTEM_LIBRARY_RELEASE Boost_FILESYSTEM_LIBRARY_RELEASE-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: Boost_INCLUDE_DIR\nBoost_INCLUDE_DIR-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nBoost_IOSTREAMS_LIBRARY_DEBUG Boost_IOSTREAMS_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nBoost_IOSTREAMS_LIBRARY_RELEASE Boost_IOSTREAMS_LIBRARY_RELEASE-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: Boost_LIBRARY_DIR_DEBUG\nBoost_LIBRARY_DIR_DEBUG-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nBoost_LIBRARY_DIR_RELEASE Boost_LIBRARY_DIR_RELEASE-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: Boost_PROGRAM_OPTIONS_LIBRARY_DEBUG\nBoost_PROGRAM_OPTIONS_LIBRARY_DEBUG-ADVANCED:INTERNAL=1 //ADVANCED property\nfor variable: Boost_PROGRAM_OPTIONS_LIBRARY_RELEASE\nBoost_PROGRAM_OPTIONS_LIBRARY_RELEASE-ADVANCED:INTERNAL=1 //ADVANCED property\nfor variable: Boost_PYTHON_LIBRARY_DEBUG Boost_PYTHON_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nBoost_PYTHON_LIBRARY_RELEASE Boost_PYTHON_LIBRARY_RELEASE-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: Boost_REGEX_LIBRARY_DEBUG\nBoost_REGEX_LIBRARY_DEBUG-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: Boost_REGEX_LIBRARY_RELEASE Boost_REGEX_LIBRARY_RELEASE-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nBoost_SERIALIZATION_LIBRARY_DEBUG Boost_SERIALIZATION_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nBoost_SERIALIZATION_LIBRARY_RELEASE Boost_SERIALIZATION_LIBRARY_RELEASE-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nBoost_SIGNALS_LIBRARY_DEBUG Boost_SIGNALS_LIBRARY_DEBUG-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: Boost_SIGNALS_LIBRARY_RELEASE\nBoost_SIGNALS_LIBRARY_RELEASE-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: Boost_SYSTEM_LIBRARY_DEBUG Boost_SYSTEM_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nBoost_SYSTEM_LIBRARY_RELEASE Boost_SYSTEM_LIBRARY_RELEASE-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: Boost_THREAD_LIBRARY_DEBUG\nBoost_THREAD_LIBRARY_DEBUG-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: Boost_THREAD_LIBRARY_RELEASE Boost_THREAD_LIBRARY_RELEASE-\nADVANCED:INTERNAL=1 //catkin environment\nCATKIN_ENV:INTERNAL=/home/robuter/catkin_ws/build/catkin_generated/env_cached.sh\nCATKIN_TEST_RESULTS_DIR:INTERNAL=/home/robuter/catkin_ws/build/test_results\n//ADVANCED property for variable: CMAKE_AR CMAKE_AR-ADVANCED:INTERNAL=1 //This\nis the directory where this CMakeCache.txt was created\nCMAKE_CACHEFILE_DIR:INTERNAL=/home/robuter/catkin_ws/build //Major version of\ncmake used to create the current loaded cache\nCMAKE_CACHE_MAJOR_VERSION:INTERNAL=3 //Minor version of cmake used to create\nthe current loaded cache CMAKE_CACHE_MINOR_VERSION:INTERNAL=5 //Patch version\nof cmake used to create the current loaded cache\nCMAKE_CACHE_PATCH_VERSION:INTERNAL=1 //ADVANCED property for variable:\nCMAKE_COLOR_MAKEFILE CMAKE_COLOR_MAKEFILE-ADVANCED:INTERNAL=1 //Path to CMake\nexecutable. CMAKE_COMMAND:INTERNAL=/usr/bin/cmake //Path to cpack program\nexecutable. CMAKE_CPACK_COMMAND:INTERNAL=/usr/bin/cpack //Path to ctest\nprogram executable. CMAKE_CTEST_COMMAND:INTERNAL=/usr/bin/ctest //ADVANCED\nproperty for variable: CMAKE_CXX_COMPILER CMAKE_CXX_COMPILER-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: CMAKE_CXX_FLAGS\nCMAKE_CXX_FLAGS-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nCMAKE_CXX_FLAGS_DEBUG CMAKE_CXX_FLAGS_DEBUG-ADVANCED:INTERNAL=1 //ADVANCED\nproperty for variable: CMAKE_CXX_FLAGS_MINSIZEREL CMAKE_CXX_FLAGS_MINSIZEREL-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: CMAKE_CXX_FLAGS_RELEASE\nCMAKE_CXX_FLAGS_RELEASE-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nCMAKE_CXX_FLAGS_RELWITHDEBINFO CMAKE_CXX_FLAGS_RELWITHDEBINFO-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: CMAKE_C_COMPILER\nCMAKE_C_COMPILER-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nCMAKE_C_FLAGS CMAKE_C_FLAGS-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: CMAKE_C_FLAGS_DEBUG CMAKE_C_FLAGS_DEBUG-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: CMAKE_C_FLAGS_MINSIZEREL\nCMAKE_C_FLAGS_MINSIZEREL-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nCMAKE_C_FLAGS_RELEASE CMAKE_C_FLAGS_RELEASE-ADVANCED:INTERNAL=1 //ADVANCED\nproperty for variable: CMAKE_C_FLAGS_RELWITHDEBINFO\nCMAKE_C_FLAGS_RELWITHDEBINFO-ADVANCED:INTERNAL=1 //Executable file format\nCMAKE_EXECUTABLE_FORMAT:INTERNAL=ELF //ADVANCED property for variable:\nCMAKE_EXE_LINKER_FLAGS CMAKE_EXE_LINKER_FLAGS-ADVANCED:INTERNAL=1 //ADVANCED\nproperty for variable: CMAKE_EXE_LINKER_FLAGS_DEBUG\nCMAKE_EXE_LINKER_FLAGS_DEBUG-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: CMAKE_EXE_LINKER_FLAGS_MINSIZEREL CMAKE_EXE_LINKER_FLAGS_MINSIZEREL-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nCMAKE_EXE_LINKER_FLAGS_RELEASE CMAKE_EXE_LINKER_FLAGS_RELEASE-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nCMAKE_EXE_LINKER_FLAGS_RELWITHDEBINFO CMAKE_EXE_LINKER_FLAGS_RELWITHDEBINFO-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nCMAKE_EXPORT_COMPILE_COMMANDS CMAKE_EXPORT_COMPILE_COMMANDS-\nADVANCED:INTERNAL=1 //Name of external makefile project generator.\nCMAKE_EXTRA_GENERATOR:INTERNAL= //Name of generator.\nCMAKE_GENERATOR:INTERNAL=Unix Makefiles //Name of generator platform.\nCMAKE_GENERATOR_PLATFORM:INTERNAL= //Name of generator toolset.\nCMAKE_GENERATOR_TOOLSET:INTERNAL= //Have symbol pthread_create\nCMAKE_HAVE_LIBC_CREATE:INTERNAL= //Have library pthreads\nCMAKE_HAVE_PTHREADS_CREATE:INTERNAL= //Have library pthread\nCMAKE_HAVE_PTHREAD_CREATE:INTERNAL=1 //Have include pthread.h\nCMAKE_HAVE_PTHREAD_H:INTERNAL=1 //Source directory with the top level\nCMakeLists.txt file for this // project\nCMAKE_HOME_DIRECTORY:INTERNAL=/home/robuter/catkin_ws/src //Install .so files\nwithout execute permission. CMAKE_INSTALL_SO_NO_EXE:INTERNAL=1 //ADVANCED\nproperty for variable: CMAKE_LINKER CMAKE_LINKER-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: CMAKE_MAKE_PROGRAM CMAKE_MAKE_PROGRAM-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nCMAKE_MODULE_LINKER_FLAGS CMAKE_MODULE_LINKER_FLAGS-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: CMAKE_MODULE_LINKER_FLAGS_DEBUG\nCMAKE_MODULE_LINKER_FLAGS_DEBUG-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: CMAKE_MODULE_LINKER_FLAGS_MINSIZEREL\nCMAKE_MODULE_LINKER_FLAGS_MINSIZEREL-ADVANCED:INTERNAL=1 //ADVANCED property\nfor variable: CMAKE_MODULE_LINKER_FLAGS_RELEASE\nCMAKE_MODULE_LINKER_FLAGS_RELEASE-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: CMAKE_MODULE_LINKER_FLAGS_RELWITHDEBINFO\nCMAKE_MODULE_LINKER_FLAGS_RELWITHDEBINFO-ADVANCED:INTERNAL=1 //ADVANCED\nproperty for variable: CMAKE_NM CMAKE_NM-ADVANCED:INTERNAL=1 //number of local\ngenerators CMAKE_NUMBER_OF_MAKEFILES:INTERNAL=123 //ADVANCED property for\nvariable: CMAKE_OBJCOPY CMAKE_OBJCOPY-ADVANCED:INTERNAL=1 //ADVANCED property\nfor variable: CMAKE_OBJDUMP CMAKE_OBJDUMP-ADVANCED:INTERNAL=1 //ADVANCED\nproperty for variable: CMAKE_RANLIB CMAKE_RANLIB-ADVANCED:INTERNAL=1 //Path to\nCMake installation. CMAKE_ROOT:INTERNAL=/usr/share/cmake-3.5 //ADVANCED\nproperty for variable: CMAKE_SHARED_LINKER_FLAGS CMAKE_SHARED_LINKER_FLAGS-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nCMAKE_SHARED_LINKER_FLAGS_DEBUG CMAKE_SHARED_LINKER_FLAGS_DEBUG-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nCMAKE_SHARED_LINKER_FLAGS_MINSIZEREL CMAKE_SHARED_LINKER_FLAGS_MINSIZEREL-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nCMAKE_SHARED_LINKER_FLAGS_RELEASE CMAKE_SHARED_LINKER_FLAGS_RELEASE-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nCMAKE_SHARED_LINKER_FLAGS_RELWITHDEBINFO\nCMAKE_SHARED_LINKER_FLAGS_RELWITHDEBINFO-ADVANCED:INTERNAL=1 //ADVANCED\nproperty for variable: CMAKE_SKIP_INSTALL_RPATH CMAKE_SKIP_INSTALL_RPATH-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: CMAKE_SKIP_RPATH\nCMAKE_SKIP_RPATH-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nCMAKE_STATIC_LINKER_FLAGS CMAKE_STATIC_LINKER_FLAGS-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: CMAKE_STATIC_LINKER_FLAGS_DEBUG\nCMAKE_STATIC_LINKER_FLAGS_DEBUG-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: CMAKE_STATIC_LINKER_FLAGS_MINSIZEREL\nCMAKE_STATIC_LINKER_FLAGS_MINSIZEREL-ADVANCED:INTERNAL=1 //ADVANCED property\nfor variable: CMAKE_STATIC_LINKER_FLAGS_RELEASE\nCMAKE_STATIC_LINKER_FLAGS_RELEASE-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: CMAKE_STATIC_LINKER_FLAGS_RELWITHDEBINFO\nCMAKE_STATIC_LINKER_FLAGS_RELWITHDEBINFO-ADVANCED:INTERNAL=1 //ADVANCED\nproperty for variable: CMAKE_STRIP CMAKE_STRIP-ADVANCED:INTERNAL=1 //uname\ncommand CMAKE_UNAME:INTERNAL=/bin/uname //ADVANCED property for variable:\nCMAKE_VERBOSE_MAKEFILE CMAKE_VERBOSE_MAKEFILE-ADVANCED:INTERNAL=1 //ADVANCED\nproperty for variable: CURL_INCLUDE_DIR CURL_INCLUDE_DIR-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: CURL_LIBRARY CURL_LIBRARY-\nADVANCED:INTERNAL=1 EIGEN3_CFLAGS:INTERNAL=-I/usr/include/eigen3\nEIGEN3_CFLAGS_I:INTERNAL= EIGEN3_CFLAGS_OTHER:INTERNAL=\nEIGEN3_FOUND:INTERNAL=1 EIGEN3_INCLUDEDIR:INTERNAL=\nEIGEN3_INCLUDE_DIRS:INTERNAL=/usr/include/eigen3 EIGEN3_LDFLAGS:INTERNAL=\nEIGEN3_LDFLAGS_OTHER:INTERNAL= EIGEN3_LIBDIR:INTERNAL=\nEIGEN3_LIBRARIES:INTERNAL= EIGEN3_LIBRARY_DIRS:INTERNAL= EIGEN3_LIBS:INTERNAL=\nEIGEN3_LIBS_L:INTERNAL= EIGEN3_LIBS_OTHER:INTERNAL=\nEIGEN3_LIBS_PATHS:INTERNAL= EIGEN3_PREFIX:INTERNAL=/usr\nEIGEN3_STATIC_CFLAGS:INTERNAL=-I/usr/include/eigen3\nEIGEN3_STATIC_CFLAGS_I:INTERNAL= EIGEN3_STATIC_CFLAGS_OTHER:INTERNAL=\nEIGEN3_STATIC_INCLUDE_DIRS:INTERNAL=/usr/include/eigen3\nEIGEN3_STATIC_LDFLAGS:INTERNAL= EIGEN3_STATIC_LDFLAGS_OTHER:INTERNAL=\nEIGEN3_STATIC_LIBDIR:INTERNAL= EIGEN3_STATIC_LIBRARIES:INTERNAL=\nEIGEN3_STATIC_LIBRARY_DIRS:INTERNAL= EIGEN3_STATIC_LIBS:INTERNAL=\nEIGEN3_STATIC_LIBS_L:INTERNAL= EIGEN3_STATIC_LIBS_OTHER:INTERNAL=\nEIGEN3_STATIC_LIBS_PATHS:INTERNAL= EIGEN3_VERSION:INTERNAL=3.2.92\nEIGEN3_eigen3_INCLUDEDIR:INTERNAL= EIGEN3_eigen3_LIBDIR:INTERNAL=\nEIGEN3_eigen3_PREFIX:INTERNAL= EIGEN3_eigen3_VERSION:INTERNAL= //Details about\nfinding CURL\nFIND_PACKAGE_MESSAGE_DETAILS_CURL:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libcurl.so][/usr/include][v7.47.0()] //Details about finding Flann\nFIND_PACKAGE_MESSAGE_DETAILS_Flann:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libflann_cpp_s.a][/usr/include][v()] //Details about finding GLEW\nFIND_PACKAGE_MESSAGE_DETAILS_GLEW:INTERNAL=[/usr/include][/usr/lib/x86_64-linux-\ngnu/libGLEW.so][v()] //Details about finding GLUT\nFIND_PACKAGE_MESSAGE_DETAILS_GLUT:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libglut.so][/usr/include][v()] //Details about finding OMPL\nFIND_PACKAGE_MESSAGE_DETAILS_OMPL:INTERNAL=[/opt/ros/kinetic/lib/x86_64-linux-\ngnu/libompl.so][/opt/ros/kinetic/include][v()] //Details about finding OpenCV\nFIND_PACKAGE_MESSAGE_DETAILS_OpenCV:INTERNAL=[/opt/ros/kinetic][v3.2.0()]\n//Details about finding OpenGL\nFIND_PACKAGE_MESSAGE_DETAILS_OpenGL:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libGL.so][/usr/include][v()] //Details about finding OpenMP\nFIND_PACKAGE_MESSAGE_DETAILS_OpenMP:INTERNAL=[-fopenmp][-fopenmp][v()]\n//Details about finding PCL\nFIND_PACKAGE_MESSAGE_DETAILS_PCL:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libboost_system.so;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;/usr/lib/x86_64-linux-\ngnu/libboost_serialization.so;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;/usr/lib/x86_64-linux-\ngnu/libpthread.so;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_common.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_common.so;optimized;/usr/lib/x86_64-linux-\ngnu/libflann_cpp_s.a;debug;/usr/lib/x86_64-linux-\ngnu/libflann_cpp_s.a;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_kdtree.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_kdtree.so;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_octree.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_octree.so;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_search.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_search.so;/usr/lib/libOpenNI.so;vtkImagingStencil;vtkCommonComputationalGeometry;vtkCommonDataModel;vtkCommonMath;vtkCommonCore;vtksys;vtkCommonMisc;vtkCommonSystem;vtkCommonTransforms;vtkImagingCore;vtkCommonExecutionModel;vtkFiltersAMR;vtkFiltersGeneral;vtkFiltersCore;vtkParallelCore;vtkIOLegacy;vtkIOCore;/usr/lib/x86_64-linux-\ngnu/libz.so;vtkInteractionWidgets;vtkFiltersHybrid;vtkImagingSources;vtkRenderingCore;vtkCommonColor;vtkFiltersExtraction;vtkFiltersStatistics;vtkImagingFourier;vtkalglib;vtkFiltersGeometry;vtkFiltersSources;vtkFiltersModeling;vtkImagingGeneral;vtkImagingHybrid;vtkIOImage;vtkDICOMParser;vtkmetaio;/usr/lib/x86_64-linux-\ngnu/libjpeg.so;/usr/lib/x86_64-linux-gnu/libpng.so;/usr/lib/x86_64-linux-\ngnu/libtiff.so;vtkInteractionStyle;vtkRenderingAnnotation;vtkImagingColor;vtkRenderingFreeType;/usr/lib/x86_64-linux-\ngnu/libfreetype.so;vtkftgl;vtkRenderingVolume;vtkIOParallelNetCDF;vtkParallelMPI;/usr/lib/x86_64-linux-\ngnu/libnetcdf_c++.so;/usr/lib/x86_64-linux-\ngnu/libnetcdf.so;/usr/lib/x86_64-linux-\ngnu/hdf5/serial/lib/libhdf5.so;/usr/lib/x86_64-linux-\ngnu/libsz.so;/usr/lib/x86_64-linux-gnu/libdl.so;/usr/lib/x86_64-linux-\ngnu/libm.so;/usr/lib/x86_64-linux-\ngnu/hdf5/serial/lib/libhdf5_hl.so;vtkRenderingOpenGL;vtkIOLSDyna;vtkIOXML;vtkIOGeometry;/usr/lib/x86_64-linux-\ngnu/libjsoncpp.so;vtkIOXMLParser;/usr/lib/x86_64-linux-\ngnu/libexpat.so;vtkLocalExample;vtkInfovisCore;vtkGeovisCore;vtkInfovisLayout;vtkViewsCore;vtkproj4;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;vtkTestingGenericBridge;/usr/lib/libgl2ps.so;verdict;vtkIOMovie;/usr/lib/x86_64-linux-\ngnu/libtheoraenc.so;/usr/lib/x86_64-linux-\ngnu/libtheoradec.so;/usr/lib/x86_64-linux-\ngnu/libogg.so;vtkFiltersImaging;vtkIOMINC;vtkRenderingLOD;vtkViewsQt;vtkGUISupportQt;vtkViewsInfovis;vtkChartsCore;vtkRenderingContext2D;vtkRenderingLabel;vtkRenderingImage;vtkFiltersFlowPaths;vtkxdmf2;/usr/lib/x86_64-linux-\ngnu/libxml2.so;vtkFiltersReebGraph;vtkViewsContext2D;vtkIOXdmf2;vtkIOAMR;vtkRenderingContextOpenGL;vtkImagingStatistics;vtkIOParallel;vtkFiltersParallel;vtkIONetCDF;vtkexoIIc;vtkGUISupportQtOpenGL;vtkIOParallelLSDyna;vtkFiltersParallelGeometry;vtkGUISupportQtWebkit;vtkIOPLY;vtkWrappingTools;vtkFiltersHyperTree;vtkRenderingVolumeOpenGL;vtkIOExodus;vtkIOPostgreSQL;vtkIOSQL;sqlite3;vtkWrappingJava;vtkFiltersParallelFlowPaths;vtkFiltersParallelStatistics;vtkFiltersProgrammable;vtkFiltersParallelImaging;vtkRenderingParallelLIC;vtkRenderingLIC;vtkInteractionImage;vtkFiltersPython;vtkWrappingPythonCore;vtkIOParallelExodus;vtkFiltersGeneric;vtkIOVideo;vtkRenderingQt;vtkFiltersTexture;vtkIOInfovis;vtkGUISupportQtSQL;vtkRenderingFreeTypeOpenGL;vtkInfovisBoostGraphAlgorithms;vtkRenderingGL2PS;vtkIOGeoJSON;vtkFiltersVerdict;vtkViewsGeovis;vtkIOImport;vtkTestingIOSQL;vtkPythonInterpreter;vtkIOODBC;vtkIOEnSight;vtkIOMySQL;vtkRenderingMatplotlib;vtkDomainsChemistry;vtkIOExport;vtkFiltersParallelMPI;vtkIOParallelXML;vtkTestingRendering;vtkIOMPIParallel;vtkParallelMPI4Py;vtkFiltersSMP;vtkFiltersSelection;vtkIOVPIC;VPIC;vtkImagingMath;vtkImagingMorphological;vtkRenderingParallel;vtkRenderingFreeTypeFontConfig;vtkIOFFMPEG;vtkIOMPIImage;vtkIOGDAL;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_io.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_io.so;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_sample_consensus.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_sample_consensus.so;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_filters.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_filters.so;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_features.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_features.so;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_segmentation.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_segmentation.so;optimized;/usr/lib/x86_64-linux-\ngnu/libqhull.so;debug;/usr/lib/x86_64-linux-\ngnu/libqhull.so;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_surface.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_surface.so;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_registration.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_registration.so;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_recognition.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_recognition.so;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_keypoints.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_keypoints.so;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_visualization.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_visualization.so;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_people.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_people.so;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_outofcore.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_outofcore.so;optimized;/usr/lib/x86_64-linux-\ngnu/libpcl_tracking.so;debug;/usr/lib/x86_64-linux-\ngnu/libpcl_tracking.so;/usr/lib/x86_64-linux-\ngnu/libboost_system.so;/usr/lib/x86_64-linux-\ngnu/libboost_filesystem.so;/usr/lib/x86_64-linux-\ngnu/libboost_thread.so;/usr/lib/x86_64-linux-\ngnu/libboost_date_time.so;/usr/lib/x86_64-linux-\ngnu/libboost_iostreams.so;/usr/lib/x86_64-linux-\ngnu/libboost_serialization.so;/usr/lib/x86_64-linux-\ngnu/libboost_chrono.so;/usr/lib/x86_64-linux-\ngnu/libboost_atomic.so;/usr/lib/x86_64-linux-\ngnu/libboost_regex.so;/usr/lib/x86_64-linux-\ngnu/libpthread.so;optimized;/usr/lib/x86_64-linux-\ngnu/libqhull.so;debug;/usr/lib/x86_64-linux-\ngnu/libqhull.so;/usr/lib/libOpenNI.so;optimized;/usr/lib/x86_64-linux-\ngnu/libflann_cpp_s.a;debug;/usr/lib/x86_64-linux-\ngnu/libflann_cpp_s.a;vtkImagingStencil;vtkCommonComputationalGeometry;vtkCommonDataModel;vtkCommonMath;vtkCommonCore;vtksys;vtkCommonMisc;vtkCommonSystem;vtkCommonTransforms;vtkImagingCore;vtkCommonExecutionModel;vtkFiltersAMR;vtkFiltersGeneral;vtkFiltersCore;vtkParallelCore;vtkIOLegacy;vtkIOCore;/usr/lib/x86_64-linux-\ngnu/libz.so;vtkInteractionWidgets;vtkFiltersHybrid;vtkImagingSources;vtkRenderingCore;vtkCommonColor;vtkFiltersExtraction;vtkFiltersStatistics;vtkImagingFourier;vtkalglib;vtkFiltersGeometry;vtkFiltersSources;vtkFiltersModeling;vtkImagingGeneral;vtkImagingHybrid;vtkIOImage;vtkDICOMParser;vtkmetaio;/usr/lib/x86_64-linux-\ngnu/libjpeg.so;/usr/lib/x86_64-linux-gnu/libpng.so;/usr/lib/x86_64-linux-\ngnu/libtiff.so;vtkInteractionStyle;vtkRenderingAnnotation;vtkImagingColor;vtkRenderingFreeType;/usr/lib/x86_64-linux-\ngnu/libfreetype.so;vtkftgl;vtkRenderingVolume;vtkIOParallelNetCDF;vtkParallelMPI;/usr/lib/x86_64-linux-\ngnu/libnetcdf_c++.so;/usr/lib/x86_64-linux-\ngnu/libnetcdf.so;/usr/lib/x86_64-linux-\ngnu/hdf5/serial/lib/libhdf5.so;/usr/lib/x86_64-linux-\ngnu/libpthread.so;/usr/lib/x86_64-linux-gnu/libsz.so;/usr/lib/x86_64-linux-\ngnu/libdl.so;/usr/lib/x86_64-linux-gnu/libm.so;/usr/lib/x86_64-linux-\ngnu/hdf5/serial/lib/libhdf5_hl.so;vtkRenderingOpenGL;vtkIOLSDyna;vtkIOXML;vtkIOGeometry;/usr/lib/x86_64-linux-\ngnu/libjsoncpp.so;vtkIOXMLParser;/usr/lib/x86_64-linux-\ngnu/libexpat.so;vtkLocalExample;vtkInfovisCore;vtkGeovisCore;vtkInfovisLayout;vtkViewsCore;vtkproj4;/usr/lib/x86_64-linux-\ngnu/libpython2.7.so;vtkTestingGenericBridge;/usr/lib/libgl2ps.so;verdict;vtkIOMovie;/usr/lib/x86_64-linux-\ngnu/libtheoraenc.so;/usr/lib/x86_64-linux-\ngnu/libtheoradec.so;/usr/lib/x86_64-linux-\ngnu/libogg.so;vtkFiltersImaging;vtkIOMINC;vtkRenderingLOD;vtkViewsQt;vtkGUISupportQt;vtkViewsInfovis;vtkChartsCore;vtkRenderingContext2D;vtkRenderingLabel;vtkRenderingImage;vtkFiltersFlowPaths;vtkxdmf2;/usr/lib/x86_64-linux-\ngnu/libxml2.so;vtkFiltersReebGraph;vtkViewsContext2D;vtkIOXdmf2;vtkIOAMR;vtkRenderingContextOpenGL;vtkImagingStatistics;vtkIOParallel;vtkFiltersParallel;vtkIONetCDF;vtkexoIIc;vtkGUISupportQtOpenGL;vtkIOParallelLSDyna;vtkFiltersParallelGeometry;vtkGUISupportQtWebkit;vtkIOPLY;vtkWrappingTools;vtkFiltersHyperTree;vtkRenderingVolumeOpenGL;vtkIOExodus;vtkIOPostgreSQL;vtkIOSQL;sqlite3;vtkWrappingJava;vtkFiltersParallelFlowPaths;vtkFiltersParallelStatistics;vtkFiltersProgrammable;vtkFiltersParallelImaging;vtkRenderingParallelLIC;vtkRenderingLIC;vtkInteractionImage;vtkFiltersPython;vtkWrappingPythonCore;vtkIOParallelExodus;vtkFiltersGeneric;vtkIOVideo;vtkRenderingQt;vtkFiltersTexture;vtkIOInfovis;vtkGUISupportQtSQL;vtkRenderingFreeTypeOpenGL;vtkInfovisBoostGraphAlgorithms;vtkRenderingGL2PS;vtkIOGeoJSON;vtkFiltersVerdict;vtkViewsGeovis;vtkIOImport;vtkTestingIOSQL;vtkPythonInterpreter;vtkIOODBC;vtkIOEnSight;vtkIOMySQL;vtkRenderingMatplotlib;vtkDomainsChemistry;vtkIOExport;vtkFiltersParallelMPI;vtkIOParallelXML;vtkTestingRendering;vtkIOMPIParallel;vtkParallelMPI4Py;vtkFiltersSMP;vtkFiltersSelection;vtkIOVPIC;VPIC;vtkImagingMath;vtkImagingMorphological;vtkRenderingParallel;vtkRenderingFreeTypeFontConfig;vtkIOFFMPEG;vtkIOMPIImage;vtkIOGDAL][/usr/include/pcl-1.7;/usr/include/eigen3;/usr/include;/usr/include/ni;/usr/include/vtk-6.2;/usr/include/tcl;/usr/include/x86_64-linux-\ngnu;/usr/include/freetype2;/usr/include/x86_64-linux-\ngnu/freetype2;/usr/include/jsoncpp;/usr/lib/openmpi/include/openmpi/opal/mca/event/libevent2021/libevent;/usr/lib/openmpi/include/openmpi/opal/mca/event/libevent2021/libevent/include;/usr/lib/openmpi/include;/usr/lib/openmpi/include/openmpi;/usr/include/python2.7;/usr/include/hdf5/openmpi;/usr/include/libxml2][v()]\n//Details about finding PCL_COMMON\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_COMMON:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_common.so][/usr/include/pcl-1.7][v()] //Details about finding\nPCL_FEATURES\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_FEATURES:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_features.so][/usr/include/pcl-1.7][v()] //Details about finding\nPCL_FILTERS\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_FILTERS:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_filters.so][/usr/include/pcl-1.7][v()] //Details about finding\nPCL_GEOMETRY\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_GEOMETRY:INTERNAL=[/usr/include/pcl-1.7][v()]\n//Details about finding PCL_IN_HAND_SCANNER\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_IN_HAND_SCANNER:INTERNAL=[/usr/include/pcl-1.7][v()]\n//Details about finding PCL_IO\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_IO:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_io.so][/usr/include/pcl-1.7][v()] //Details about finding\nPCL_KDTREE\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_KDTREE:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_kdtree.so][/usr/include/pcl-1.7][v()] //Details about finding\nPCL_KEYPOINTS\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_KEYPOINTS:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_keypoints.so][/usr/include/pcl-1.7][v()] //Details about finding\nPCL_MODELER\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_MODELER:INTERNAL=[/usr/include/pcl-1.7][v()]\n//Details about finding PCL_OCTREE\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_OCTREE:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_octree.so][/usr/include/pcl-1.7][v()] //Details about finding\nPCL_OUTOFCORE\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_OUTOFCORE:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_outofcore.so][/usr/include/pcl-1.7][v()] //Details about finding\nPCL_PEOPLE\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_PEOPLE:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_people.so][/usr/include/pcl-1.7][v()] //Details about finding\nPCL_POINT_CLOUD_EDITOR\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_POINT_CLOUD_EDITOR:INTERNAL=[/usr/include/pcl-1.7][v()]\n//Details about finding PCL_RECOGNITION\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_RECOGNITION:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_recognition.so][/usr/include/pcl-1.7][v()] //Details about finding\nPCL_REGISTRATION\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_REGISTRATION:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_registration.so][/usr/include/pcl-1.7][v()] //Details about finding\nPCL_SAMPLE_CONSENSUS\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_SAMPLE_CONSENSUS:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_sample_consensus.so][/usr/include/pcl-1.7][v()] //Details about\nfinding PCL_SEARCH\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_SEARCH:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_search.so][/usr/include/pcl-1.7][v()] //Details about finding\nPCL_SEGMENTATION\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_SEGMENTATION:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_segmentation.so][/usr/include/pcl-1.7][v()] //Details about finding\nPCL_SURFACE\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_SURFACE:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_surface.so][/usr/include/pcl-1.7][v()] //Details about finding\nPCL_TRACKING\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_TRACKING:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_tracking.so][/usr/include/pcl-1.7][v()] //Details about finding\nPCL_VISUALIZATION\nFIND_PACKAGE_MESSAGE_DETAILS_PCL_VISUALIZATION:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpcl_visualization.so][/usr/include/pcl-1.7][v()] //Details about\nfinding PkgConfig\nFIND_PACKAGE_MESSAGE_DETAILS_PkgConfig:INTERNAL=[/usr/bin/pkg-\nconfig][v0.29.1()] //Details about finding PythonInterp\nFIND_PACKAGE_MESSAGE_DETAILS_PythonInterp:INTERNAL=[/usr/bin/python][v2.7.12()]\n//Details about finding PythonLibs\nFIND_PACKAGE_MESSAGE_DETAILS_PythonLibs:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libpython2.7.so][/usr/include/python2.7][v2.7.12(2.7)] //Details about\nfinding Threads FIND_PACKAGE_MESSAGE_DETAILS_Threads:INTERNAL=[TRUE][v()]\n//Details about finding eigen\nFIND_PACKAGE_MESSAGE_DETAILS_eigen:INTERNAL=[/usr/include/eigen3][v()]\n//Details about finding libusb-1.0\nFIND_PACKAGE_MESSAGE_DETAILS_libusb-1.0:INTERNAL=[/usr/include][v()] //Details\nabout finding openni\nFIND_PACKAGE_MESSAGE_DETAILS_openni:INTERNAL=[/usr/lib/libOpenNI.so][/usr/include/ni][v()]\n//Details about finding qhull\nFIND_PACKAGE_MESSAGE_DETAILS_qhull:INTERNAL=[/usr/lib/x86_64-linux-\ngnu/libqhull.so][/usr/include][v()] //ADVANCED property for variable:\nGLEW_INCLUDE_DIR GLEW_INCLUDE_DIR-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: GLEW_LIBRARY GLEW_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property\nfor variable: GLUT_INCLUDE_DIR GLUT_INCLUDE_DIR-ADVANCED:INTERNAL=1 //ADVANCED\nproperty for variable: GLUT_Xi_LIBRARY GLUT_Xi_LIBRARY-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: GLUT_Xmu_LIBRARY GLUT_Xmu_LIBRARY-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: GLUT_glut_LIBRARY\nGLUT_glut_LIBRARY-ADVANCED:INTERNAL=1 GTEST_FROM_SOURCE_FOUND:INTERNAL=TRUE\nGTEST_FROM_SOURCE_INCLUDE_DIRS:INTERNAL=/usr/include\nGTEST_FROM_SOURCE_LIBRARIES:INTERNAL=gtest\nGTEST_FROM_SOURCE_LIBRARY_DIRS:INTERNAL=/home/robuter/catkin_ws/build/gtest\nGTEST_FROM_SOURCE_MAIN_LIBRARIES:INTERNAL=gtest_main //ADVANCED property for\nvariable: GTEST_INCLUDE_DIR GTEST_INCLUDE_DIR-ADVANCED:INTERNAL=1 //ADVANCED\nproperty for variable: GTEST_LIBRARY GTEST_LIBRARY-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: GTEST_LIBRARY_DEBUG GTEST_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: GTEST_MAIN_LIBRARY\nGTEST_MAIN_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nGTEST_MAIN_LIBRARY_DEBUG GTEST_MAIN_LIBRARY_DEBUG-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: LAPACK_Accelerate_LIBRARY\nLAPACK_Accelerate_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: LAPACK_goto2_LIBRARY LAPACK_goto2_LIBRARY-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: LAPACK_lapack_LIBRARY LAPACK_lapack_LIBRARY-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: LAPACK_lapack_WORKS\nLAPACK_lapack_WORKS-ADVANCED:INTERNAL=1 //Have function cheev_\nLAPACK_lapack_WORKS:INTERNAL=1 //ADVANCED property for variable:\nLAPACK_vecLib_LIBRARY LAPACK_vecLib_LIBRARY-ADVANCED:INTERNAL=1\nLIBFCL_CFLAGS:INTERNAL=-std=c++11 LIBFCL_CFLAGS_I:INTERNAL=\nLIBFCL_CFLAGS_OTHER:INTERNAL=-std=c++11 LIBFCL_FOUND:INTERNAL=1\nLIBFCL_INCLUDEDIR:INTERNAL=/usr/include LIBFCL_INCLUDE_DIRS:INTERNAL=\nLIBFCL_LDFLAGS:INTERNAL=-lfcl LIBFCL_LDFLAGS_OTHER:INTERNAL=\nLIBFCL_LIBDIR:INTERNAL=/usr/lib/x86_64-linux-gnu LIBFCL_LIBRARIES:INTERNAL=fcl\nLIBFCL_LIBRARY_DIRS:INTERNAL= LIBFCL_LIBS:INTERNAL= LIBFCL_LIBS_L:INTERNAL=\nLIBFCL_LIBS_OTHER:INTERNAL= LIBFCL_LIBS_PATHS:INTERNAL=\nLIBFCL_PREFIX:INTERNAL=/usr LIBFCL_STATIC_CFLAGS:INTERNAL=-std=c++11\nLIBFCL_STATIC_CFLAGS_I:INTERNAL=\nLIBFCL_STATIC_CFLAGS_OTHER:INTERNAL=-std=c++11\nLIBFCL_STATIC_INCLUDE_DIRS:INTERNAL= LIBFCL_STATIC_LDFLAGS:INTERNAL=-lfcl\nLIBFCL_STATIC_LDFLAGS_OTHER:INTERNAL= LIBFCL_STATIC_LIBDIR:INTERNAL=\nLIBFCL_STATIC_LIBRARIES:INTERNAL=fcl LIBFCL_STATIC_LIBRARY_DIRS:INTERNAL=\nLIBFCL_STATIC_LIBS:INTERNAL= LIBFCL_STATIC_LIBS_L:INTERNAL=\nLIBFCL_STATIC_LIBS_OTHER:INTERNAL= LIBFCL_STATIC_LIBS_PATHS:INTERNAL=\nLIBFCL_VERSION:INTERNAL=0.5.0 LIBFCL_fcl_INCLUDEDIR:INTERNAL=\nLIBFCL_fcl_LIBDIR:INTERNAL= LIBFCL_fcl_PREFIX:INTERNAL=\nLIBFCL_fcl_VERSION:INTERNAL= NEW_YAMLCPP_CFLAGS:INTERNAL=\nNEW_YAMLCPP_CFLAGS_I:INTERNAL= NEW_YAMLCPP_CFLAGS_OTHER:INTERNAL=\nNEW_YAMLCPP_FOUND:INTERNAL=1 NEW_YAMLCPP_INCLUDEDIR:INTERNAL=/usr/include\nNEW_YAMLCPP_INCLUDE_DIRS:INTERNAL= NEW_YAMLCPP_LDFLAGS:INTERNAL=-lyaml-cpp\nNEW_YAMLCPP_LDFLAGS_OTHER:INTERNAL= NEW_YAMLCPP_LIBDIR:INTERNAL=\nNEW_YAMLCPP_LIBRARIES:INTERNAL=yaml-cpp NEW_YAMLCPP_LIBRARY_DIRS:INTERNAL=\nNEW_YAMLCPP_LIBS:INTERNAL= NEW_YAMLCPP_LIBS_L:INTERNAL=\nNEW_YAMLCPP_LIBS_OTHER:INTERNAL= NEW_YAMLCPP_LIBS_PATHS:INTERNAL=\nNEW_YAMLCPP_PREFIX:INTERNAL=/usr NEW_YAMLCPP_STATIC_CFLAGS:INTERNAL=\nNEW_YAMLCPP_STATIC_CFLAGS_I:INTERNAL=\nNEW_YAMLCPP_STATIC_CFLAGS_OTHER:INTERNAL=\nNEW_YAMLCPP_STATIC_INCLUDE_DIRS:INTERNAL=\nNEW_YAMLCPP_STATIC_LDFLAGS:INTERNAL=-lyaml-cpp\nNEW_YAMLCPP_STATIC_LDFLAGS_OTHER:INTERNAL= NEW_YAMLCPP_STATIC_LIBDIR:INTERNAL=\nNEW_YAMLCPP_STATIC_LIBRARIES:INTERNAL=yaml-cpp\nNEW_YAMLCPP_STATIC_LIBRARY_DIRS:INTERNAL= NEW_YAMLCPP_STATIC_LIBS:INTERNAL=\nNEW_YAMLCPP_STATIC_LIBS_L:INTERNAL= NEW_YAMLCPP_STATIC_LIBS_OTHER:INTERNAL=\nNEW_YAMLCPP_STATIC_LIBS_PATHS:INTERNAL= NEW_YAMLCPP_VERSION:INTERNAL=0.5.2\nNEW_YAMLCPP_yaml-cpp_INCLUDEDIR:INTERNAL= NEW_YAMLCPP_yaml-\ncpp_LIBDIR:INTERNAL= NEW_YAMLCPP_yaml-cpp_PREFIX:INTERNAL= NEW_YAMLCPP_yaml-\ncpp_VERSION:INTERNAL= OGRE_CFLAGS:INTERNAL=-pthread;-I/usr/include/OGRE\nOGRE_CFLAGS_I:INTERNAL= OGRE_CFLAGS_OTHER:INTERNAL=-pthread\nOGRE_FOUND:INTERNAL=1 OGRE_INCLUDEDIR:INTERNAL=/usr/include\nOGRE_INCLUDE_DIRS:INTERNAL=/usr/include/OGRE\nOGRE_LDFLAGS:INTERNAL=-lOgreMain;-lpthread OGRE_LDFLAGS_OTHER:INTERNAL=\nOGRE_LIBDIR:INTERNAL=/usr/lib/x86_64-linux-gnu\nOGRE_LIBRARIES:INTERNAL=OgreMain;pthread OGRE_LIBRARY_DIRS:INTERNAL=\nOGRE_LIBS:INTERNAL= OGRE_LIBS_L:INTERNAL= OGRE_LIBS_OTHER:INTERNAL=\nOGRE_LIBS_PATHS:INTERNAL= OGRE_OGRE_INCLUDEDIR:INTERNAL=\nOGRE_OGRE_LIBDIR:INTERNAL= OGRE_OGRE_PREFIX:INTERNAL=\nOGRE_OGRE_VERSION:INTERNAL= OGRE_PREFIX:INTERNAL=/usr\nOGRE_STATIC_CFLAGS:INTERNAL=-pthread;-I/usr/include/OGRE\nOGRE_STATIC_CFLAGS_I:INTERNAL= OGRE_STATIC_CFLAGS_OTHER:INTERNAL=-pthread\nOGRE_STATIC_INCLUDE_DIRS:INTERNAL=/usr/include/OGRE\nOGRE_STATIC_LDFLAGS:INTERNAL=-lOgreMain;-lpthread\nOGRE_STATIC_LDFLAGS_OTHER:INTERNAL= OGRE_STATIC_LIBDIR:INTERNAL=\nOGRE_STATIC_LIBRARIES:INTERNAL=OgreMain;pthread\nOGRE_STATIC_LIBRARY_DIRS:INTERNAL= OGRE_STATIC_LIBS:INTERNAL=\nOGRE_STATIC_LIBS_L:INTERNAL= OGRE_STATIC_LIBS_OTHER:INTERNAL=\nOGRE_STATIC_LIBS_PATHS:INTERNAL= OGRE_VERSION:INTERNAL=1.9.0 //ADVANCED\nproperty for variable: OPENGL_INCLUDE_DIR OPENGL_INCLUDE_DIR-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: OPENGL_gl_LIBRARY\nOPENGL_gl_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nOPENGL_glu_LIBRARY OPENGL_glu_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property\nfor variable: OPENGL_xmesa_INCLUDE_DIR OPENGL_xmesa_INCLUDE_DIR-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: OpenMP_CXX_FLAGS\nOpenMP_CXX_FLAGS-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nOpenMP_C_FLAGS OpenMP_C_FLAGS-ADVANCED:INTERNAL=1 //Test OpenMP_FLAG_DETECTED\nOpenMP_FLAG_DETECTED:INTERNAL=1 //ADVANCED property for variable:\nPCL_COMMON_LIBRARY PCL_COMMON_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property\nfor variable: PCL_COMMON_LIBRARY_DEBUG PCL_COMMON_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: PCL_FEATURES_LIBRARY\nPCL_FEATURES_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nPCL_FEATURES_LIBRARY_DEBUG PCL_FEATURES_LIBRARY_DEBUG-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: PCL_FILTERS_LIBRARY PCL_FILTERS_LIBRARY-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nPCL_FILTERS_LIBRARY_DEBUG PCL_FILTERS_LIBRARY_DEBUG-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: PCL_IO_LIBRARY PCL_IO_LIBRARY-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: PCL_IO_LIBRARY_DEBUG\nPCL_IO_LIBRARY_DEBUG-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nPCL_KDTREE_LIBRARY PCL_KDTREE_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property\nfor variable: PCL_KDTREE_LIBRARY_DEBUG PCL_KDTREE_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: PCL_KEYPOINTS_LIBRARY\nPCL_KEYPOINTS_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nPCL_KEYPOINTS_LIBRARY_DEBUG PCL_KEYPOINTS_LIBRARY_DEBUG-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: PCL_OCTREE_LIBRARY PCL_OCTREE_LIBRARY-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: PCL_OCTREE_LIBRARY_DEBUG\nPCL_OCTREE_LIBRARY_DEBUG-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nPCL_OUTOFCORE_LIBRARY PCL_OUTOFCORE_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED\nproperty for variable: PCL_OUTOFCORE_LIBRARY_DEBUG\nPCL_OUTOFCORE_LIBRARY_DEBUG-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: PCL_PEOPLE_LIBRARY PCL_PEOPLE_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED\nproperty for variable: PCL_PEOPLE_LIBRARY_DEBUG PCL_PEOPLE_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: PCL_RECOGNITION_LIBRARY\nPCL_RECOGNITION_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nPCL_RECOGNITION_LIBRARY_DEBUG PCL_RECOGNITION_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: PCL_REGISTRATION_LIBRARY\nPCL_REGISTRATION_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nPCL_REGISTRATION_LIBRARY_DEBUG PCL_REGISTRATION_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nPCL_SAMPLE_CONSENSUS_LIBRARY PCL_SAMPLE_CONSENSUS_LIBRARY-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: PCL_SAMPLE_CONSENSUS_LIBRARY_DEBUG\nPCL_SAMPLE_CONSENSUS_LIBRARY_DEBUG-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: PCL_SEARCH_LIBRARY PCL_SEARCH_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED\nproperty for variable: PCL_SEARCH_LIBRARY_DEBUG PCL_SEARCH_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: PCL_SEGMENTATION_LIBRARY\nPCL_SEGMENTATION_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nPCL_SEGMENTATION_LIBRARY_DEBUG PCL_SEGMENTATION_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: PCL_SURFACE_LIBRARY\nPCL_SURFACE_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nPCL_SURFACE_LIBRARY_DEBUG PCL_SURFACE_LIBRARY_DEBUG-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: PCL_TRACKING_LIBRARY PCL_TRACKING_LIBRARY-\nADVANCED:INTERNAL=1 //ADVANCED property for variable:\nPCL_TRACKING_LIBRARY_DEBUG PCL_TRACKING_LIBRARY_DEBUG-ADVANCED:INTERNAL=1\n//ADVANCED property for variable: PCL_VISUALIZATION_LIBRARY\nPCL_VISUALIZATION_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED property for\nvariable: PCL_VISUALIZATION_LIBRARY_DEBUG PCL_VISUALIZATION_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 PC_EIGEN_CFLAGS:INTERNAL=-I/usr/include/eigen3\nPC_EIGEN_CFLAGS_I:INTERNAL= PC_EIGEN_CFLAGS_OTHER:INTERNAL=\nPC_EIGEN_FOUND:INTERNAL=1 PC_EIGEN_INCLUDEDIR:INTERNAL=\nPC_EIGEN_INCLUDE_DIRS:INTERNAL=/usr/include/eigen3 PC_EIGEN_LDFLAGS:INTERNAL=\nPC_EIGEN_LDFLAGS_OTHER:INTERNAL= PC_EIGEN_LIBDIR:INTERNAL=\nPC_EIGEN_LIBRARIES:INTERNAL= PC_EIGEN_LIBRARY_DIRS:INTERNAL=\nPC_EIGEN_LIBS:INTERNAL= PC_EIGEN_LIBS_L:INTERNAL=\nPC_EIGEN_LIBS_OTHER:INTERNAL= PC_EIGEN_LIBS_PATHS:INTERNAL=\nPC_EIGEN_PREFIX:INTERNAL=/usr\nPC_EIGEN_STATIC_CFLAGS:INTERNAL=-I/usr/include/eigen3\nPC_EIGEN_STATIC_CFLAGS_I:INTERNAL= PC_EIGEN_STATIC_CFLAGS_OTHER:INTERNAL=\nPC_EIGEN_STATIC_INCLUDE_DIRS:INTERNAL=/usr/include/eigen3\nPC_EIGEN_STATIC_LDFLAGS:INTERNAL= PC_EIGEN_STATIC_LDFLAGS_OTHER:INTERNAL=\nPC_EIGEN_STATIC_LIBDIR:INTERNAL= PC_EIGEN_STATIC_LIBRARIES:INTERNAL=\nPC_EIGEN_STATIC_LIBRARY_DIRS:INTERNAL= PC_EIGEN_STATIC_LIBS:INTERNAL=\nPC_EIGEN_STATIC_LIBS_L:INTERNAL= PC_EIGEN_STATIC_LIBS_OTHER:INTERNAL=\nPC_EIGEN_STATIC_LIBS_PATHS:INTERNAL= PC_EIGEN_VERSION:INTERNAL=3.2.92\nPC_EIGEN_eigen3_INCLUDEDIR:INTERNAL= PC_EIGEN_eigen3_LIBDIR:INTERNAL=\nPC_EIGEN_eigen3_PREFIX:INTERNAL= PC_EIGEN_eigen3_VERSION:INTERNAL=\nPC_FLANN_CFLAGS:INTERNAL= PC_FLANN_CFLAGS_I:INTERNAL=\nPC_FLANN_CFLAGS_OTHER:INTERNAL= PC_FLANN_FOUND:INTERNAL=1\nPC_FLANN_INCLUDEDIR:INTERNAL=/usr/include PC_FLANN_INCLUDE_DIRS:INTERNAL=\nPC_FLANN_LDFLAGS:INTERNAL=-lflann_cpp PC_FLANN_LDFLAGS_OTHER:INTERNAL=\nPC_FLANN_LIBDIR:INTERNAL=/usr/lib/x86_64-linux-gnu\nPC_FLANN_LIBRARIES:INTERNAL=flann_cpp PC_FLANN_LIBRARY_DIRS:INTERNAL=\nPC_FLANN_LIBS:INTERNAL= PC_FLANN_LIBS_L:INTERNAL=\nPC_FLANN_LIBS_OTHER:INTERNAL= PC_FLANN_LIBS_PATHS:INTERNAL=\nPC_FLANN_PREFIX:INTERNAL=/usr PC_FLANN_STATIC_CFLAGS:INTERNAL=\nPC_FLANN_STATIC_CFLAGS_I:INTERNAL= PC_FLANN_STATIC_CFLAGS_OTHER:INTERNAL=\nPC_FLANN_STATIC_INCLUDE_DIRS:INTERNAL=\nPC_FLANN_STATIC_LDFLAGS:INTERNAL=-lflann_cpp\nPC_FLANN_STATIC_LDFLAGS_OTHER:INTERNAL= PC_FLANN_STATIC_LIBDIR:INTERNAL=\nPC_FLANN_STATIC_LIBRARIES:INTERNAL=flann_cpp\nPC_FLANN_STATIC_LIBRARY_DIRS:INTERNAL= PC_FLANN_STATIC_LIBS:INTERNAL=\nPC_FLANN_STATIC_LIBS_L:INTERNAL= PC_FLANN_STATIC_LIBS_OTHER:INTERNAL=\nPC_FLANN_STATIC_LIBS_PATHS:INTERNAL= PC_FLANN_VERSION:INTERNAL=1.8.4\nPC_FLANN_flann_INCLUDEDIR:INTERNAL= PC_FLANN_flann_LIBDIR:INTERNAL=\nPC_FLANN_flann_PREFIX:INTERNAL= PC_FLANN_flann_VERSION:INTERNAL=\nPC_OPENNI2_CFLAGS:INTERNAL= PC_OPENNI2_CFLAGS_I:INTERNAL=\nPC_OPENNI2_CFLAGS_OTHER:INTERNAL= PC_OPENNI2_FOUND:INTERNAL=\nPC_OPENNI2_INCLUDEDIR:INTERNAL= PC_OPENNI2_LIBDIR:INTERNAL=\nPC_OPENNI2_LIBS:INTERNAL= PC_OPENNI2_LIBS_L:INTERNAL=\nPC_OPENNI2_LIBS_OTHER:INTERNAL= PC_OPENNI2_LIBS_PATHS:INTERNAL=\nPC_OPENNI2_PREFIX:INTERNAL= PC_OPENNI2_STATIC_CFLAGS:INTERNAL=\nPC_OPENNI2_STATIC_CFLAGS_I:INTERNAL= PC_OPENNI2_STATIC_CFLAGS_OTHER:INTERNAL=\nPC_OPENNI2_STATIC_LIBDIR:INTERNAL= PC_OPENNI2_STATIC_LIBS:INTERNAL=\nPC_OPENNI2_STATIC_LIBS_L:INTERNAL= PC_OPENNI2_STATIC_LIBS_OTHER:INTERNAL=\nPC_OPENNI2_STATIC_LIBS_PATHS:INTERNAL= PC_OPENNI2_VERSION:INTERNAL=\nPC_OPENNI2_libopenni2_INCLUDEDIR:INTERNAL=\nPC_OPENNI2_libopenni2_LIBDIR:INTERNAL= PC_OPENNI2_libopenni2_PREFIX:INTERNAL=\nPC_OPENNI2_libopenni2_VERSION:INTERNAL=\nPC_OPENNI_CFLAGS:INTERNAL=-I/usr/include/ni PC_OPENNI_CFLAGS_I:INTERNAL=\nPC_OPENNI_CFLAGS_OTHER:INTERNAL= PC_OPENNI_FOUND:INTERNAL=1\nPC_OPENNI_INCLUDEDIR:INTERNAL=/usr/include/ni\nPC_OPENNI_INCLUDE_DIRS:INTERNAL=/usr/include/ni\nPC_OPENNI_LDFLAGS:INTERNAL=-lOpenNI PC_OPENNI_LDFLAGS_OTHER:INTERNAL=\nPC_OPENNI_LIBDIR:INTERNAL=/usr/lib PC_OPENNI_LIBRARIES:INTERNAL=OpenNI\nPC_OPENNI_LIBRARY_DIRS:INTERNAL= PC_OPENNI_LIBS:INTERNAL=\nPC_OPENNI_LIBS_L:INTERNAL= PC_OPENNI_LIBS_OTHER:INTERNAL=\nPC_OPENNI_LIBS_PATHS:INTERNAL= PC_OPENNI_PREFIX:INTERNAL=/usr\nPC_OPENNI_STATIC_CFLAGS:INTERNAL=-I/usr/include/ni\nPC_OPENNI_STATIC_CFLAGS_I:INTERNAL= PC_OPENNI_STATIC_CFLAGS_OTHER:INTERNAL=\nPC_OPENNI_STATIC_INCLUDE_DIRS:INTERNAL=/usr/include/ni\nPC_OPENNI_STATIC_LDFLAGS:INTERNAL=-lOpenNI\nPC_OPENNI_STATIC_LDFLAGS_OTHER:INTERNAL= PC_OPENNI_STATIC_LIBDIR:INTERNAL=\nPC_OPENNI_STATIC_LIBRARIES:INTERNAL=OpenNI\nPC_OPENNI_STATIC_LIBRARY_DIRS:INTERNAL= PC_OPENNI_STATIC_LIBS:INTERNAL=\nPC_OPENNI_STATIC_LIBS_L:INTERNAL= PC_OPENNI_STATIC_LIBS_OTHER:INTERNAL=\nPC_OPENNI_STATIC_LIBS_PATHS:INTERNAL= PC_OPENNI_VERSION:INTERNAL=1.5.4.0\nPC_OPENNI_libopenni_INCLUDEDIR:INTERNAL= PC_OPENNI_libopenni_LIBDIR:INTERNAL=\nPC_OPENNI_libopenni_PREFIX:INTERNAL= PC_OPENNI_libopenni_VERSION:INTERNAL=\n//ADVANCED property for variable: PKG_CONFIG_EXECUTABLE PKG_CONFIG_EXECUTABLE-\nADVANCED:INTERNAL=1 //ADVANCED property for variable: PYTHON_EXECUTABLE\nPYTHON_EXECUTABLE-ADVANCED:INTERNAL=1 //ADVANCED property for variable:\nPYTHON_INCLUDE_DIR PYTHON_INCLUDE_DIR-ADVANCED:INTERNAL=1 //This needs to be\nin PYTHONPATH when 'setup.py install' is called. // And it needs to match. But\nsetuptools won't tell us where // it will install things.\nPYTHON_INSTALL_DIR:INTERNAL=lib/python2.7/dist-packages //ADVANCED property\nfor variable: PYTHON_LIBRARY PYTHON_LIBRARY-ADVANCED:INTERNAL=1 //ADVANCED\nproperty for variable: PYTHON_LIBRARY_DEBUG PYTHON_LIBRARY_DEBUG-\nADVANCED:INTERNAL=1 YAML_CPP_CFLAGS:INTERNAL= YAML_CPP_CFLAGS_I:INTERNAL=\nYAML_CPP_CFLAGS_OTHER:INTERNAL= YAML_CPP_FOUND:INTERNAL=1\nYAML_CPP_INCLUDEDIR:INTERNAL=/usr/include YAML_CPP_INCLUDE_DIRS:INTERNAL=\nYAML_CPP_LDFLAGS:INTERNAL=-lyaml-cpp YAML_CPP_LDFLAGS_OTHER:INTERNAL=\nYAML_CPP_LIBDIR:INTERNAL= YAML_CPP_LIBRARIES:INTERNAL=yaml-cpp\nYAML_CPP_LIBRARY_DIRS:INTERNAL= YAML_CPP_LIBS:INTERNAL=\nYAML_CPP_LIBS_L:INTERNAL= YAML_CPP_LIBS_OTHER:INTERNAL=\nYAML_CPP_LIBS_PATHS:INTERNAL= YAML_CPP_PREFIX:INTERNAL=/usr\nYAML_CPP_STATIC_CFLAGS:INTERNAL= YAML_CPP_STATIC_CFLAGS_I:INTERNAL=\nYAML_CPP_STATIC_CFLAGS_OTHER:INTERNAL= YAML_CPP_STATIC_INCLUDE_DIRS:INTERNAL=\nYAML_CPP_STATIC_LDFLAGS:INTERNAL=-lyaml-cpp\nYAML_CPP_STATIC_LDFLAGS_OTHER:INTERNAL= YAML_CPP_STATIC_LIBDIR:INTERNAL=\nYAML_CPP_STATIC_LIBRARIES:INTERNAL=yaml-cpp\nYAML_CPP_STATIC_LIBRARY_DIRS:INTERNAL= YAML_CPP_STATIC_LIBS:INTERNAL=\nYAML_CPP_STATIC_LIBS_L:INTERNAL= YAML_CPP_STATIC_LIBS_OTHER:INTERNAL=\nYAML_CPP_STATIC_LIBS_PATHS:INTERNAL= YAML_CPP_VERSION:INTERNAL=0.5.2\nYAML_CPP_yaml-cpp_INCLUDEDIR:INTERNAL= YAML_CPP_yaml-cpp_LIBDIR:INTERNAL=\nYAML_CPP_yaml-cpp_PREFIX:INTERNAL= YAML_CPP_yaml-cpp_VERSION:INTERNAL=\n//Components requested for this build tree.\n_Boost_COMPONENTS_SEARCHED:INTERNAL=atomic;chrono;date_time;filesystem;iostreams;program_options;python;regex;serialization;signals;system;thread\n//Last used Boost_INCLUDE_DIR value.\n_Boost_INCLUDE_DIR_LAST:INTERNAL=/usr/include //Last used\nBoost_LIBRARY_DIR_DEBUG value.\n_Boost_LIBRARY_DIR_DEBUG_LAST:INTERNAL=/usr/lib/x86_64-linux-gnu //Last used\nBoost_LIBRARY_DIR_RELEASE value.\n_Boost_LIBRARY_DIR_RELEASE_LAST:INTERNAL=/usr/lib/x86_64-linux-gnu //Last used\nBoost_NAMESPACE value. _Boost_NAMESPACE_LAST:INTERNAL=boost //Last used\nBoost_USE_MULTITHREADED value. _Boost_USE_MULTITHREADED_LAST:INTERNAL=TRUE\n__pkg_config_checked_EIGEN3:INTERNAL=1 __pkg_config_checked_LIBFCL:INTERNAL=1\n__pkg_config_checked_NEW_YAMLCPP:INTERNAL=1\n__pkg_config_checked_OGRE:INTERNAL=1 __pkg_config_checked_PC_EIGEN:INTERNAL=1\n__pkg_config_checked_PC_FLANN:INTERNAL=1\n__pkg_config_checked_PC_OPENNI:INTERNAL=1\n__pkg_config_checked_PC_OPENNI2:INTERNAL=1\n__pkg_config_checked_YAML_CPP:INTERNAL=1 prefix_result:INTERNAL=/usr/lib\n\n"
  },
  {
    "id": "depth_frame/allp4html.txt",
    "content": "[ ](//www.rssing.com/index.php \"Home\")\n\n  * [ Login  ](//www.rssing.com/account.php?a=lgi&t=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Fall_p4.html)\n    * [ Account ](//www.rssing.com/account.php)\n    * [ Sign Up ](//www.rssing.com/account.php?a=reg&t=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Fall_p4.html)\n\n  * [ Home  ](//www.rssing.com/index.php)\n    * [ About Us ](//www.rssing.com/about.php)\n    * [ Catalog ](//www.rssing.com/catalog.php)\n  * [ Search  ](//www.rssing.com/search.php)\n  * [ Register RSS  ](//www.rssing.com/register.php)\n  * [ Embed RSS  ](//www.rssing.com/embed.php)\n    * [ FAQ ](//www.rssing.com/embed.php?a=whe)\n    * [ Get Embed Code ](//www.rssing.com/embed.php)\n    * [ Example: Default CSS ](//www.rssing.com/embed.php?a=ex1)\n    * [ Example: Custom CSS ](//www.rssing.com/embed.php?a=ex2)\n    * [ Example: Custom CSS per Embedding ](//www.rssing.com/embed.php?a=ex3)\n  * [ Super RSS  ](//www.rssing.com/super.php)\n    * [ Usage ](//www.rssing.com/super.php)\n    * [ View Latest ](//www.rssing.com/super.php?a=l)\n    * [ Create ](//www.rssing.com/super.php?a=crt)\n\n  * [ Contact Us  ](//www.rssing.com/contact.php)\n    * [ Technical Support ](//www.rssing.com/contact.php)\n    * [ Guest Posts/Articles ](//www.rssing.com/contact.php?r=o9)\n    * [ Report Violations ](//www.rssing.com/contact.php)\n    * [ Google Warnings ](//www.rssing.com/contact.php?r=o4)\n    * [ Article Removal Requests ](//www.rssing.com/contact.php?r=o5_0)\n    * [ Channel Removal Requests ](//www.rssing.com/contact.php?r=o5_0)\n    * [ General Questions ](//www.rssing.com/contact.php?r=o8)\n    * [ DMCA Takedown Notice ](//www.rssing.com/contact.php)\n\n[ ](//www.rssing.com/index.php)\n\n  * [ RSSing>> ](//www.rssing.com/index.php)\n    * Collections: \n    * [ RSSing ](//www.rssing.com/index.php)\n    * [ EDA ](//www.rssing.com/d/eda/index.php)\n    * [ Intel ](//www.rssing.com/d/intel/index.php)\n    * [ Mesothelioma ](//www.rssing.com/d/mesothelioma/index.php)\n    * [ SAP ](//www.rssing.com/d/sap/index.php)\n    * [ SEO ](//www.rssing.com/d/seo/index.php)\n  * [ Latest  ](//www.rssing.com/index.php?l=l)\n    * [ Articles ](//www.rssing.com/index.php?l=la)\n    * [ Channels ](//www.rssing.com/index.php?l=lc)\n    * [ Super Channels ](//www.rssing.com/index.php?l=ls)\n  * [ Popular  ](//www.rssing.com/index.php?l=p)\n    * [ Articles ](//www.rssing.com/index.php?l=pa)\n    * [ Pages ](//www.rssing.com/index.php?l=pp)\n    * [ Channels ](//www.rssing.com/index.php?l=pc)\n    * [ Super Channels ](//www.rssing.com/index.php?l=ps)\n  * [ Top Rated  ](//www.rssing.com/index.php?l=r)\n    * [ Articles ](//www.rssing.com/index.php?l=ra)\n    * [ Pages ](//www.rssing.com/index.php?l=rp)\n    * [ Channels ](//www.rssing.com/index.php?l=rc)\n    * [ Super Channels ](//www.rssing.com/index.php?l=rs)\n  * [ Trending  ](//www.rssing.com/index.php?l=t)\n    * [ Articles ](//www.rssing.com/index.php?l=ta)\n    * [ Pages ](//www.rssing.com/index.php?l=tp)\n    * [ Channels ](//www.rssing.com/index.php?l=tc)\n    * [ Super Channels ](//www.rssing.com/index.php?l=ts)\n\n[ ](javascript:;)\n\n[ ](javascript:;) Switch Editions?  \n[ Cancel ](javascript:;)\n\n[ ](javascript:;)\n\n[ ](javascript:;)\n\nSharing:\n\nTitle:\n\nURL:\n\n[ Copy Share URL ](javascript:;)\n\n[ ](javascript:; \"Share Page\")\n\n[ English  ](javascript:; \"English\")\n\nRSSing.com\n\n[ RSSing>> ](//www.rssing.com/index.php) [ Latest\n](//www.rssing.com/index.php?l=l) [ Popular ](//www.rssing.com/index.php?l=p)\n[ Top Rated ](//www.rssing.com/index.php?l=r) [ Trending\n](//www.rssing.com/index.php?l=t)\n\nChannel: ROS Answers: Open Source Q&A Forum - RSS feed  \n\n[ NSFW?  ](javascript:; \"Mark channel Not-Safe-For-Work\")\n\n[ Claim  ](javascript:; \"Claim Chan\")\n\n[ ](javascript:; \"Share Chan\")\n\n[ 0  ](javascript:; \"Show Rating\")\n\n  \n  \n\n[ X ](javascript:;) Mark channel Not-Safe-For-Work?  [ cancel ](javascript:;)\n[ confirm ](javascript:;) NSFW Votes:  (  0  votes)\n\n[ X ](javascript:;) Are you the publisher? [ Claim\n](//www.rssing.com/account.php?a=mmc&r=36145539) or [ contact us\n](//www.rssing.com/contact.php?a=ssm&r=o5&u=//question2135.rssing.com/chan-36145539/all_p4.html)\nabout this channel.\n\n[ X ](javascript:;) 0\n\nShowing article 61 to 80 of 122 in channel 36145539  \nChannel Details:\n\n  * Title: ROS Answers: Open Source Q&A Forum - RSS feed \n  * Channel Number: 36145539 \n  * Language: English \n  * Registered On: November 3, 2014, 11:32 am \n  * Number of Articles: 122 \n  * Latest Snapshot: April 3, 2019, 11:53 pm \n  * RSS URL: [ http://answers.ros.org/feeds/rss/?tags=depth ](javascript:;)\n  * Publisher: [ http://answers.ros.org/questions/ ](javascript:;)\n  * Description: Open source question and answer forum written in Python and Django \n  * Catalog: [ //question2135.rssing.com/catalog.php?indx=36145539 ](//question2135.rssing.com/catalog.php?indx=36145539)\n\n[ Remove ADS ](//www.rssing.com/account.php?r=27)\n\nViewing all 122 articles\n\n[ ](//question2135.rssing.com/chan-36145539/all_p3.html \"older\") First Page\nPage 2  Page 3  Page 4  Page 5  Page 6  Last Page  [\n](//question2135.rssing.com/chan-36145539/all_p5.html \"newer\")\n\n[ Browse latest ](//question2135.rssing.com/chan-36145539/index-latest.php) [\nView live ](//question2135.rssing.com/chan-36145539/article61-live.html)\n\n#  [ publish disparity from depth - Kinect\n](//question2135.rssing.com/chan-36145539/article61-live.html)\n\nFebruary 15, 2016, 5:44 am\n\n[ _\u226b_ Next: why RGB and depth Image synchronization not working?\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a62 \"Next\nArticle\")\n\n[ _\u226a_ Previous: depth_image_proc point_cloud_xyzrgb\n](//question2135.rssing.com/chan-36145539/all_p3.html#c36145539a60 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle61-live.html\n\"Article Support\")\n\nHi, I want to publish disparity from the depth topic of type sensor_msgs/Image\nand the camera info topic of type sensor_msgs/CameraInfo, using the nodelet\ndepth_image_proc/disparity. I want then to save it in a png file. When I\nlaunch the nodelet depth_image_proc/disparity and the disparity_view, I got\nonly an empty window. Here is the launch file:  The depth and the camera info\nare good. Any idea why I don't see anything in the disparity_view? I want to\nsave the disparity in a png file and use it with opencv in python. Thanks!\n\n\u21a7\n\n[ Search ](javascript:;)\n\nRSSing.com\n\n* * *\n\n\u21a7\n\n#  [ why RGB and depth Image synchronization not working?\n](//question2135.rssing.com/chan-36145539/article62-live.html)\n\nFebruary 18, 2016, 12:26 pm\n\n[ _\u226b_ Next: Any suggestions for combining scans of different frequencies?\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a63 \"Next\nArticle\")\n\n[ _\u226a_ Previous: publish disparity from depth - Kinect\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a61 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle62-live.html\n\"Article Support\")\n\nwhy this works ? but not the bottom one? #include  #include  #include\n#include  #include  #include  #include  #include  #include  #include  #include\n#include  #include  #include  #include  #include  #include  #include  #include\n#include  #include  #include  //names that will appear at the top of each\nwindow static const std::string windowName = \"Original Image\"; using namespace\nstd; using namespace sensor_msgs; using namespace message_filters; void\ncallback(const ImageConstPtr& image_rgb, const CameraInfoConstPtr& cam_info) {\n// Solve all of perception here... cv::Mat image_color =\ncv_bridge::toCvCopy(image_rgb)->image; cv::imshow(windowName,image_color);\ncv::waitKey(3); } int main(int argc, char** argv) { ros::init(argc, argv,\n\"vision_node\"); ros::NodeHandle nh; message_filters::Subscriber\nrgb_sub(nh,\"/camera/rgb/image_color\", 1); message_filters::Subscriber\ninfo_color_sub(nh,\"/camera/rgb/camera_info\", 1); TimeSynchronizer\nsync(rgb_sub, info_color_sub, 10);\nsync.registerCallback(boost::bind(&callback, _1, _2)); ros::spin(); return 0;\n} In the upper code I'm able to see the RGB image . BUT This is not giving any\nresult. I'm trying to synchronize both the images and then separate then\ninside callback . then process the RGB image to find the object. I want ti\nfind depth of particular pixel u,v . but this is not working when I'm trying\nto send both RGB and depth image. void callback(const ImageConstPtr&\nimage_rgb, const ImageConstPtr& image_depth_source) { // Solve all of\nperception here... cv::Mat image_color =\ncv_bridge::toCvCopy(image_rgb)->image; cv::Mat image_depth =\ncv_bridge::toCvCopy(image_depth_source)->image;\ncv::imshow(windowName1,image_color); cv::imshow(windowName2,image_depth);\ncv::waitKey(3); } int main(int argc, char** argv) { ros::init(argc, argv,\n\"vision_node\"); ros::NodeHandle nh; message_filters::Subscriber\nrgb_sub(nh,\"/camera/rgb/image_color\", 1); message_filters::Subscriber\ndepth_sub(nh,\"/camera/depth_registered/image_raw\", 1); TimeSynchronizer\nsync(rgb_sub, depth_sub, 10); sync.registerCallback(boost::bind(&callback, _1,\n_2)); ros::spin(); return 0; }\n\n\u21a7\n\n#  [ Any suggestions for combining scans of different frequencies?\n](//question2135.rssing.com/chan-36145539/article63-live.html)\n\nFebruary 19, 2016, 12:30 am\n\n[ _\u226b_ Next: Intel RealSense depth camera on Ubuntu Arm\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a64 \"Next\nArticle\")\n\n[ _\u226a_ Previous: why RGB and depth Image synchronization not working?\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a62 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle63-live.html\n\"Article Support\")\n\nI'm combining two scans, one extracted from a depth camera, and the other from\na 2D LIDAR. But I'm getting some jitter from the depth camera's scan's\ncontribution. I suppose it's to be expected when combining a 30Hz depth scan\nwith a 40Hz LIDAR, but I was wondering if there was anything that could be\ndone better. A qualitative example of the jitter artifact in RVIZ; red/LIDAR,\ngreen/depth-camera, yellow/combined. Note how combined lagges with the camera,\nand the LIDAR remains quite static. ![image\ndescription](https://cloud.githubusercontent.com/assets/2293573/13169970/f20197fa-d6b6-11e5-9bb6-e128d5a7444d.gif)\nThe example you see here is a turtlebot simulation from gazebo, with a asus\npointing forward, and a gpu_lidar pointing backwards, using this small PR of\nira_laser_tools: [#7](https://github.com/iralabdisco/ira_laser_tools/pull/7).\nI made an issue [#8](https://github.com/iralabdisco/ira_laser_tools/issues/8)\nof this, but thought It could be general enough for a good old approach\nquestion here.\n\n\u21a7\n\n#  [ Intel RealSense depth camera on Ubuntu Arm\n](//question2135.rssing.com/chan-36145539/article64-live.html)\n\nMarch 3, 2016, 3:07 am\n\n[ _\u226b_ Next: Kinect accuracy in depth\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a65 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Any suggestions for combining scans of different frequencies?\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a63 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle64-live.html\n\"Article Support\")\n\nHi all, Im going to develop some package with the [Intel RealSense depth\ncamera](http://click.intel.com/intelrrealsensetm-developer-kit-featuring-\nsr300.html), but before i get that hardware, i wanna know if its possible to\nuse it on the Ubuntu Arm version of ROS. Thank you so much!!\n\n\u21a7\n\n#  [ Kinect accuracy in depth\n](//question2135.rssing.com/chan-36145539/article65-live.html)\n\nMarch 14, 2016, 2:27 pm\n\n[ _\u226b_ Next: Openni or Freenect?\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a66 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Intel RealSense depth camera on Ubuntu Arm\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a64 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle65-live.html\n\"Article Support\")\n\nHi, I use a Kinect for Xbox 360. What is the accuracy of depth in the\ndifferent ranges ? Thanks for reply.\n\n\u21a7\n\n\u21a7\n\n#  [ Openni or Freenect?\n](//question2135.rssing.com/chan-36145539/article66-live.html)\n\nApril 4, 2016, 4:20 am\n\n[ _\u226b_ Next: rviz does not display the depth cloud\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a67 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Kinect accuracy in depth\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a65 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle66-live.html\n\"Article Support\")\n\nHi guys, I'm quite new in ROS and I would like to know a general opinion about\nwhich one would you use, or which are you using nowadays and why. I would like\nto use a KINECT to do a SLAM and try to subscribe to topics related with the\nmeasured depth. Thanks everyone.\n\n\u21a7\n\n#  [ rviz does not display the depth cloud\n](//question2135.rssing.com/chan-36145539/article67-live.html)\n\nMay 5, 2016, 7:34 am\n\n[ _\u226b_ Next: Turtlebot depth image not showing in image_view\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a68 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Openni or Freenect?\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a66 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle67-live.html\n\"Article Support\")\n\nI have a bag fille recorded with a kinect camera. RVIZ displays correctly the\nRGB but it does not display the depth cloud any more. It used to work ( the\nsame bag fille) using oppeni_camera as fixed frame and using the raw\nconfiguration. But it's not working any more.\n\n\u21a7\n\n#  [ Turtlebot depth image not showing in image_view\n](//question2135.rssing.com/chan-36145539/article68-live.html)\n\nMarch 1, 2014, 10:11 am\n\n[ _\u226b_ Next: subscribing rgb and depth simutaneously very slow\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a69 \"Next\nArticle\")\n\n[ _\u226a_ Previous: rviz does not display the depth cloud\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a67 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle68-live.html\n\"Article Support\")\n\nHello, I want to try some opencv algorithms with depth images from the\nturtlebot1 (create base). I want to save them for later use because of the\ncomplexity of modifying and remaking a node. We have our Turtlebot started\nwith Turtlebot_bringup minimal.launch and turtlebot_bringup 3dsensor.launch.\nRVIZ is currently showing */camera/depth_registered/image_raw* (which dont\nlook as detailed as I imagined looking at the IR image) but not any\n*/camera/depth/* topic. I tried `rostopic hz /camera/depth/image_raw` but it\nis not publishing. `rosrun image_view image_view\nimage:=/camera/depth_registered/image_raw` says: > Unable to convert '16UC1'\nimage to bgr8: '[16UC1] is not a color format. but [bgr8] is. The conversion\ndoes not make sense' Can I somehow easily save these images for later\nprocessing?\n\n\u21a7\n\n[ Search ](javascript:;)\n\nRSSing.com\n\n* * *\n\n#  [ subscribing rgb and depth simutaneously very slow\n](//question2135.rssing.com/chan-36145539/article69-live.html)\n\nMay 25, 2016, 8:26 am\n\n[ _\u226b_ Next: get a depth image using a kinect and openCV.\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a70 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Turtlebot depth image not showing in image_view\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a68 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle69-live.html\n\"Article Support\")\n\nI am subscribing the rgb and depth images published by openni_launch at the\nsame time. However, my problem becomes very slow and can only run at 15Hz. How\nto solve the problem?\n\n\u21a7\n\n\u21a7\n\n#  [ get a depth image using a kinect and openCV.\n](//question2135.rssing.com/chan-36145539/article70-live.html)\n\nJune 8, 2016, 4:35 pm\n\n[ _\u226b_ Next: Save images kinect - 30fps\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a71 \"Next\nArticle\")\n\n[ _\u226a_ Previous: subscribing rgb and depth simutaneously very slow\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a69 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle70-live.html\n\"Article Support\")\n\nI have a code in C ++ that stores a Kinect's depth image, I wonder if there is\nany way to get an image, in where I can define the depth of the things\ncaptured into this image. for example, I only want the things that are at max\nat 1 meter of distance of the Kinect's sensor I found the code into a thread\nhere, so I edited it so I can try to get the image, the code is the next.\n\\---------- #include  #include  #include  #include  #include  #include  using\nnamespace std; unsigned int cnt = 0; void RetornoImagen(const\nsensor_msgs::ImageConstPtr& msg_depth ) { //convertimos a un tipo de imagen de\nopencV cv_bridge::CvImagePtr img_ptr_depth; try{ img_ptr_depth =\ncv_bridge::toCvCopy(*msg_depth, sensor_msgs::image_encodings::TYPE_32FC1); }\ncatch (cv_bridge::Exception& e) { ROS_ERROR(\"cv_bridge exception: %s\",\ne.what()); return; } double minVal, maxVal; cv::Mat &mat =\nimg_ptr_depth->image; cv::Mat img2; cv::Mat invertida;\ncv::imshow(\"windowName\",mat ); //mat.convertTo(img2,CV_8U, 255.0/(maxVal -\nminVal), 100.0 ); minMaxLoc(mat, &minVal, &maxVal,NULL,NULL); //find minimum\nand maximum intensities img2=mat; mat.convertTo(img2,CV_32FC1,65535.0/(maxVal\n- minVal), -minVal * 65535.0/(maxVal - minVal)); cv::imshow(\"ventana2\",img2);\nbbbb cv::waitKey(3); //ROS_INFO(\"asdasd\"); char file1[100]; char file2[100];\ncnt++; sprintf( file1, \"%04d_depth.png\", cnt ); ; //parametros de compresion\nstd::vector  pp; pp.push_back(CV_IMWRITE_PNG_COMPRESSION); pp.push_back(0);\n//guardamos la imagen en el disco duro, donde se ejecuta el nodo.\nimwrite(file1,img2,pp); //imwrite(file2,img2); ROS_INFO_STREAM(\"El minimo es:\"\n\n\u21a7\n\n#  [ Save images kinect - 30fps\n](//question2135.rssing.com/chan-36145539/article71-live.html)\n\nJune 20, 2016, 12:55 am\n\n[ _\u226b_ Next: Depth map from bumblebee2 camera?\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a72 \"Next\nArticle\")\n\n[ _\u226a_ Previous: get a depth image using a kinect and openCV.\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a70 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle71-live.html\n\"Article Support\")\n\nI have to record a dataset using the kinect, it should contains RBG images and\ndepth images.. Using this code: char filename[80]; int i=0,j=0; void\nimageCallbackdepth(const sensor_msgs::ImageConstPtr& msg) { // convert message\nfrom ROS to openCV cv_bridge::CvImagePtr cv_ptr; try { cv_ptr =\ncv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::TYPE_32FC1); } catch\n(cv_bridge::Exception& e) { ROS_ERROR(\"cv_bridge exception: %s\", e.what());\nreturn; } sprintf(filename,\"depth_%d.png\", i++);\ncv::imwrite(filename,cv_ptr->image); } void imageCallbackrgb(const\nsensor_msgs::ImageConstPtr& msg) { //The same for RGB } I have a couple of\nquestions: How can I make sure that I'm saving images at 30fps? Am I not\nmissing any frame? How can I change this parameter? Saving RBG and depth at\nthe same time and adding another sensor (stereocamera) doesn't effect that? My\nprogram is correct, is it the right way to do this?\n\n\u21a7\n\n#  [ Depth map from bumblebee2 camera?\n](//question2135.rssing.com/chan-36145539/article72-live.html)\n\nDecember 9, 2013, 2:57 am\n\n[ _\u226b_ Next: How to obtain depth coordinate using two,widely sperated, cameras:\nROS, python Baxter\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a73 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Save images kinect - 30fps\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a71 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle72-live.html\n\"Article Support\")\n\nHi, I am trying to get the coordinates in space (X,Y,Z) of an object. For\nthis, I am detecting the object using the image from the bumblebee's left\ncamera (from here I can obtain the X and Y coordinates), and would like to\nobtain the Z-coordinate. I have the code for doing this with an Asus Xtion,\nbut this uses a depth map. Can I get a depth map as well from my bumblebee2\ncamera? Or should I just use the disparity image I get from stereo_image_proc?\nThanks!\n\n\u21a7\n\n#  [ How to obtain depth coordinate using two,widely sperated, cameras: ROS,\npython Baxter ](//question2135.rssing.com/chan-36145539/article73-live.html)\n\nJune 22, 2016, 9:00 am\n\n[ _\u226b_ Next: Is this the right way to obatin depth information?\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a74 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Depth map from bumblebee2 camera?\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a72 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle73-live.html\n\"Article Support\")\n\nHi, So basically I want to be able to obtain the depth,z, coordinate of a\ncertain object. I figured since I am using two cameras, there could be some\ntriangulation that can be done. I also looked into the disparity map process,\nbut my cameras are far apart, and the disparity map created is rubbish, so i\nneed another method\n\n\u21a7\n\n\u21a7\n\n#  [ Is this the right way to obatin depth information?\n](//question2135.rssing.com/chan-36145539/article74-live.html)\n\nJuly 1, 2016, 2:36 pm\n\n[ _\u226b_ Next: How to interpret data matrix in sensor_msgs/Image?\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a75 \"Next\nArticle\")\n\n[ _\u226a_ Previous: How to obtain depth coordinate using two,widely sperated,\ncameras: ROS, python Baxter\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a73 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle74-live.html\n\"Article Support\")\n\nHello, I am trying to find the closest object to a zed camera. I am using the\npackage: [zed_wrapper](http://wiki.ros.org/zed-ros-wrapper). I need to find\nthe depth (z value) of each pixel in the scene. My understanding is that the\ntopic: > /camera/depth/image_rect_color will provide me the required\ninformation. The command `rostopic type /camera/depth/image_rect_color`\nreturned sensor_msgs/Image which I believe is the msg type for depth images.\nThe command `rosmsg show sensor_msgs/Image` returned std_msgs/Header header\nuint32 seq time stamp string frame_id uint32 height uint32 width string\nencoding uint8 is_bigendian uint32 step uint8[] data I believe that the last\nfield: > uint8[] data gives the actual info. I believe that at this point, I\nshould write a subscriber. Do I have enough information to write a subscriber?\nIs there any other way I can get this information without writing a\nsubscriber? Kindly help. Thank You.\n\n\u21a7\n\n#  [ How to interpret data matrix in sensor_msgs/Image?\n](//question2135.rssing.com/chan-36145539/article75-live.html)\n\nJuly 20, 2016, 9:38 am\n\n[ _\u226b_ Next: Image array size is not consistent with the message type\ndocumentation\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a76 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Is this the right way to obatin depth information?\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a74 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle75-live.html\n\"Article Support\")\n\nI am subscribing to the topic `/camera/depth/image_rect_color` in the package\n[zed-ros-wrapper](http://wiki.ros.org/zed-ros-wrapper) to obtain depth\ninformation using a zed camera. Right now, my subscriber looks at a random\npixel and reads the depth information. Is there any way to find out which\npixel corresponds to what element(index) in the matrix? Also if I run\n`rostopic echo /camera/depth/image_rect_color`, I find that the encoding is\n`32FC1`. But the data matrix is `int` (I believe `unit8` denotes `int`). Also,\nI haven't seen any value above 255. So, the matrix looks like `8UC1`. What am\nI missing here or how does a 32FC1 matrix looks like?\n\n\u21a7\n\n[ Search ](javascript:;)\n\nRSSing.com\n\n* * *\n\n#  [ Image array size is not consistent with the message type documentation\n](//question2135.rssing.com/chan-36145539/article76-live.html)\n\nJuly 21, 2016, 10:48 am\n\n[ _\u226b_ Next: Get depth from Kinect sensor in gazebo simulator\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a77 \"Next\nArticle\")\n\n[ _\u226a_ Previous: How to interpret data matrix in sensor_msgs/Image?\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a75 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle76-live.html\n\"Article Support\")\n\nI am trying to interpret data from a message of the type `sensor_msgs/Image`.\nWhen I run `rostopic echo ...` for the topic, I get the following, along with\nthe data array: height: 720 width: 1280 encoding: 32FC1 is_bigendian: 0 step:\n5120 The\n[documentation](http://docs.ros.org/api/sensor_msgs/html/msg/Image.html) says\nthat the size of the array should be `step` times `rows` (i.e. height). This\ngives `720` times `5120` = 3686400 which is good because it says that 4 uint8\ndata elements in data array should be combined to get the 32 bit float value\n(see the encoding; `4` times `1280`=5120 which is the step size). To confirm\nthe size of the data array, I edited my subscriber (added at the end) to read\narray elements corresponding to indices `3686400 to 4686400`. I expected an\nerror at the very beginning, but it threw a segmentation fault only after the\nindex `3690487` . How can this be explained? What am I doing wrong? All the\noutput values corresponding to these indices are zero. Right now this is how\nmy subscriber looks: #include  #include \"ros/ros.h\" //#include\n\"std_msgs/String.h\" #include \"sensor_msgs/Image.h\" using namespace std; void\ndepthCallback(const sensor_msgs::Image::ConstPtr& msg) { for(int\ni=3686400;iheight); ROS_INFO(\"Depth Info: [%d]\", msg->data[i]); cout\n\n\u21a7\n\n#  [ Get depth from Kinect sensor in gazebo simulator\n](//question2135.rssing.com/chan-36145539/article77-live.html)\n\nOctober 14, 2013, 3:54 am\n\n[ _\u226b_ Next: Depth map estimation from monocular camera\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a78 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Image array size is not consistent with the message type\ndocumentation\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a76 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle77-live.html\n\"Article Support\")\n\nI'm trying to find a specific pixel's depth of `/depth/image_raw` topic that\nis published by Kinect sensor mounted on **Turtlebot** robot. It's what I get:\nwww.uppic.com/do.php?img=97090) (Sorry I have not enough karma to upload\nimage. It's what I see in **rviz**: www.uppic.com/do.php?img=97092 How can I\nfix it to get depth of pixels?\n\n\u21a7\n\n\u21a7\n\n#  [ Depth map estimation from monocular camera\n](//question2135.rssing.com/chan-36145539/article78-live.html)\n\nAugust 17, 2016, 12:05 pm\n\n[ _\u226b_ Next: Kinect invalid flag less than 0.4 m\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a79 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Get depth from Kinect sensor in gazebo simulator\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a77 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle78-live.html\n\"Article Support\")\n\nIs anyone aware of ROS nodes implementing an algorithm to estimate a depth map\nfrom a monocular camera, like described in [this\npaper](https://papers.nips.cc/paper/2921-learning-depth-from-single-monocular-\nimages.pdf)? I've found a little published code such as\n[this](https://bitbucket.org/fayao/dcnf-fcsp) and\n[this](http://make3d.cs.cornell.edu/code.html) and\n[this](https://github.com/asousa/DepthPrediction), but it's all buggy Matlab\ncode and undocumented.\n\n\u21a7\n\n#  [ Kinect invalid flag less than 0.4 m\n](//question2135.rssing.com/chan-36145539/article79-live.html)\n\nAugust 25, 2016, 9:37 am\n\n[ _\u226b_ Next: ros indigo / xtion : getting depth from pixel coordinates\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a80 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Depth map estimation from monocular camera\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a78 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle79-live.html\n\"Article Support\")\n\nHello, I came to know from\n[this](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6521938) , kinect\ngives a invalid flag on for depth value less than 40cm distance. My question\nwas how using ROS, I can read the invalid flag within the blind zone(less than\n40 cm). I wrote a publisher which read from /camera/depth/points as PCL2 and\nthen calculated the ibstacle distacle. It publishes data to another topic. But\nfor moving objects which suddenly came in front of kinect in les the 40 cm\nthen it cannot detect obstacle. Can anyone please help me regarding this?\nthank you.\n\n\u21a7\n\n#  [ ros indigo / xtion : getting depth from pixel coordinates\n](//question2135.rssing.com/chan-36145539/article80-live.html)\n\nSeptember 25, 2016, 12:44 pm\n\n[ _\u226b_ Next: How can i get object distance using camera/depth/image_raw\n](//question2135.rssing.com/chan-36145539/all_p5.html#c36145539a81 \"Next\nArticle\")\n\n[ _\u226a_ Previous: Kinect invalid flag less than 0.4 m\n](//question2135.rssing.com/chan-36145539/all_p4.html#c36145539a79 \"Previous\nArticle\")\n\n[ ](//www.rssing.com/index.php?zw=2123 \"Home\") [ $ ](javascript:; \"MoMoney\")\n\n[ ](javascript:; \"Like\") 0\n\n[ ](javascript:; \"Ouch\") 0\n\n[ ](javascript:; \"Share Article\") [\n](//www.rssing.com/contact.php?r=o6&u=%2F%2Fquestion2135.rssing.com%2Fchan-36145539%2Farticle80-live.html\n\"Article Support\")\n\nHi, Giving x,y pixels coordinate in camera/rgb/image_raw, I am trying to\nextract the related depth from camera/depth_registered/image_raw. I start the\nxtion via \"roslaunch openni2_launch openni2\" Running \"rosrun rqt_reconfigure\nrqt_reconfigure\" and checking camera/driver confirms depth_registration is\nactive. Also, displaying the /camera/depth_registered/points in rviz shows\nsomething that looks nice. It seems to me that when using an xtion pro live,\nthere is no need for calibration, so I did not do any. It also seems to me\nthat if registration is done, coordinates in the depth image and in the rgb\nimage are the same, so I do the following in python: in the callback for the\nrgb image (bridge is an instance of CvBridge): cv_image =\nbridge.imgmsg_to_cv2(image, image.encoding) # code for getting x,y coordinate\nof a pixel of interest in the image I run some code that displays the image\nand shows the pixel x,y: cv2.circle(cv_image,(x,y),2,(255,0,0),-1) this\nconfirms x,y are correct, in this case at the center of a colored ball in\nfront of the camera callback for depth image: image_cv =\nbridge.imgmsg_to_cv2(depth_image, depth_image.encoding) depth_image =\nnp.squeeze(np.array(image_cv, dtype=np.float32)) depth =\nfloat(depth_image[x][y]) but I just get \"0.0\" for the depth, no matter where\nthe ball is in the field of vision. Anything I am doing incorrectly ?\n\n\u21a7\n\n[ Remove ADS ](//www.rssing.com/account.php?r=27)\n\nViewing all 122 articles\n\n[ ](//question2135.rssing.com/chan-36145539/all_p3.html \"older\") First Page\nPage 2  Page 3  Page 4  Page 5  Page 6  Last Page  [\n](//question2135.rssing.com/chan-36145539/all_p5.html \"newer\")\n\n[ Browse latest ](//question2135.rssing.com/chan-36145539/index-latest.php) [\nView live ](//question2135.rssing.com/chan-36145539/article61-live.html)\n\n* * *\n\nMore Pages to Explore .....\n\n  * [ //javier1830.rssing.com/chan-79050542/index-page1.html ](//javier1830.rssing.com/chan-79050542/index-page1.html)\n  * [ //myteespot208.rssing.com/chan-10670238/index-page1.html ](//myteespot208.rssing.com/chan-10670238/index-page1.html)\n  * [ //anomos11.rssing.com/chan-38630269/index-latest.php ](//anomos11.rssing.com/chan-38630269/index-latest.php)\n  * [ //rejuvenation911.rssing.com/chan-79051226/index-page1.html ](//rejuvenation911.rssing.com/chan-79051226/index-page1.html)\n  * [ //ansehen267.rssing.com/chan-44928903/article2.html ](//ansehen267.rssing.com/chan-44928903/article2.html)\n  * [ //swisscleantech15.rssing.com/chan-79051200/article10.html ](//swisscleantech15.rssing.com/chan-79051200/article10.html)\n  * [ //shortening164.rssing.com/chan-79051083/article10.html ](//shortening164.rssing.com/chan-79051083/article10.html)\n  * [ //fanatic7799.rssing.com/chan-79051176/index-latest.php ](//fanatic7799.rssing.com/chan-79051176/index-latest.php)\n  * [ //daybooks78.rssing.com/chan-79050875/index-page1.html ](//daybooks78.rssing.com/chan-79050875/index-page1.html)\n  * [ //brasil4599.rssing.com/chan-79050718/index-page1.html ](//brasil4599.rssing.com/chan-79050718/index-page1.html)\n  * [ //darlleen78.rssing.com/chan-79050407/article4.html ](//darlleen78.rssing.com/chan-79050407/article4.html)\n  * [ //pockmarking19.rssing.com/chan-10669134/index-latest.php ](//pockmarking19.rssing.com/chan-10669134/index-latest.php)\n  * [ //dasyurid78.rssing.com/chan-79050579/article1.html ](//dasyurid78.rssing.com/chan-79050579/article1.html)\n  * [ //fanatic7795.rssing.com/chan-79051036/index-page1.html ](//fanatic7795.rssing.com/chan-79051036/index-page1.html)\n  * [ //dayflies78.rssing.com/chan-79050911/article23.html ](//dayflies78.rssing.com/chan-79050911/article23.html)\n  * [ //regions2049.rssing.com/chan-79050969/article9.html ](//regions2049.rssing.com/chan-79050969/article9.html)\n  * [ //participatory719.rssing.com/chan-79051344/index-page1.html ](//participatory719.rssing.com/chan-79051344/index-page1.html)\n  * [ //waste4928.rssing.com/chan-79051090/index-latest.php ](//waste4928.rssing.com/chan-79051090/index-latest.php)\n  * [ //datiscosid78.rssing.com/chan-79050663/index-page1.html ](//datiscosid78.rssing.com/chan-79050663/index-page1.html)\n  * [ //datapoint78.rssing.com/chan-79050620/article29.html ](//datapoint78.rssing.com/chan-79050620/article29.html)\n\n* * *\n\n* * *\n\n[ Search ](javascript:;)\n\nRSSing.com\n\n* * *\n\n##  Top-Rated Images\n\n[ \u2182\n](////talos181.rssing.com/chan-58296078/article541.html#c58296078a541i381855922\n\"JasperLoader Emerges, Targets Italy with Gootkit Banking Trojan\")\n\n![JasperLoader Emerges, Targets Italy with Gootkit Banking\nTrojan](//3.bp.blogspot.com/-PsLw92lxTvA/XMGnQCXq8uI/AAAAAAAABI4/KJ5XDuqo8PsOIDiWSJs9sqmx5UPuCaB5gCLcBGAs/s640/image36.png)\n\n###  [ JasperLoader Emerges, Targets Italy with Gootkit Banking Trojan\n](////talos181.rssing.com/chan-58296078/article541.html#c58296078a541i381855922)\n\n[ \u2182\n](////ngemu1.rssing.com/chan-25253293/article13362.html#c25253293a13362i1209846253\n\"Epsxe On-screen Gamepad skins \\(For Android\\)\")\n\n![Epsxe On-screen Gamepad skins \\(For Android\\)](//i.imgur.com/Oc5rtZR.jpg)\n\n###  [ Epsxe On-screen Gamepad skins (For Android)\n](////ngemu1.rssing.com/chan-25253293/article13362.html#c25253293a13362i1209846253)\n\n[ \u2182\n](////barbados171.rssing.com/chan-13839764/article16821.html#c13839764a16821i186843027\n\"Woman is 21st murder victim\")\n\n![Woman is 21st murder victim](//barbadostoday.bb/wp-\ncontent/uploads/2019/04/MG_3723.jpg)\n\n###  [ Woman is 21st murder victim\n](////barbados171.rssing.com/chan-13839764/article16821.html#c13839764a16821i186843027)\n\n[ \u2182\n](////lists288.rssing.com/chan-11077187/article374.html#c11077187a374i164684108\n\"Top 20 Hot and Sexy Dragon Ball Z Girls \\(Characters\\)\")\n\n![Top 20 Hot and Sexy Dragon Ball Z Girls\n\\(Characters\\)](//1.bp.blogspot.com/-OqJPaiXp4As/U1r7dNW2ElI/AAAAAAAAk_I/J7YbqMD1OJk/s1600/pan-\nof-dragon-ball-z.jpg)\n\n###  [ Top 20 Hot and Sexy Dragon Ball Z Girls (Characters)\n](////lists288.rssing.com/chan-11077187/article374.html#c11077187a374i164684108)\n\n[ \u2182\n](////dailyentertainmentnews33.rssing.com/chan-41166720/article94.html#c41166720a94i1969999888\n\"Meet Peter Nygard Girlfriends & Children\")\n\n![Meet Peter Nygard Girlfriends &\nChildren](//dailyentertainmentnews.com/wpgo/wp-content/uploads/2020/02/kai-\nnygard-184x300.jpg)\n\n###  [ Meet Peter Nygard Girlfriends & Children\n](////dailyentertainmentnews33.rssing.com/chan-41166720/article94.html#c41166720a94i1969999888)\n\n[ \u2182\n](////murder540.rssing.com/chan-6412619/article1.html#c6412619a1i1155785771\n\"Murder in Australia: 2010\")\n\n![Murder in Australia:\n2010](//2.bp.blogspot.com/-zEjZIawSSso/UMBtH81fykI/AAAAAAAAAMU/PNsllPLf124/s640/hunterian.jpg)\n\n###  [ Murder in Australia: 2010\n](////murder540.rssing.com/chan-6412619/article1.html#c6412619a1i1155785771)\n\n[ \u2182\n](////salina38.rssing.com/chan-7227570/article826.html#c7227570a826i536103691\n\"Saline County Jail Booking Activity \u2013 Saturday, October 3rd\")\n\n![Saline County Jail Booking Activity \u2013 Saturday, October\n3rd](//thepost.s3.amazonaws.com/wp-content/uploads/2015/10/Quinn-Brian-\nWade-300x203.jpg)\n\n###  [ Saline County Jail Booking Activity \u2013 Saturday, October 3rd\n](////salina38.rssing.com/chan-7227570/article826.html#c7227570a826i536103691)\n\n[ \u2182\n](////hullabaloo16.rssing.com/chan-9145637/article818.html#c9145637a818i695428444\n\"Calgary Hells Angels implicated in another fraud\")\n\n![Calgary Hells Angels implicated in another\nfraud](//2.bp.blogspot.com/-qpKtSMmZQDE/VDeynZXmedI/AAAAAAAAV04/yx0T_VyHhsc/s320/IMG_60691061533681.jpeg)\n\n###  [ Calgary Hells Angels implicated in another fraud\n](////hullabaloo16.rssing.com/chan-9145637/article818.html#c9145637a818i695428444)\n\n[ \u2182\n](////nickalive1.rssing.com/chan-12111484/article19428.html#c12111484a19428i709189718\n\"Wicked Cool Toys Announces 'The Loud House' Plush Toy Line | NYTF 2018\n\\[Updated\\]\")\n\n![Wicked Cool Toys Announces 'The Loud House' Plush Toy Line | NYTF 2018\n\\[Updated\\]](//3.bp.blogspot.com/-nOI76eg4gOE/W5arvkqxY5I/AAAAAAAA-\nbs/dk80jyd1o5ICOU25r8SLjyKQySQQUb0lACLcBGAs/s400/The-Loud-House-Wicked-Cool-\nToys-Booth-Toy-Nickelodeon-Nick-TFNY-NYTF_1.jpg)\n\n###  [ Wicked Cool Toys Announces 'The Loud House' Plush Toy Line | NYTF 2018\n[Updated]\n](////nickalive1.rssing.com/chan-12111484/article19428.html#c12111484a19428i709189718)\n\n[ \u2182\n](////electro404.rssing.com/chan-13553321/article882.html#c13553321a882i1547750503\n\"MICOM & POWER AMP SCHEMATIC - LG RAT376B - Mini Hi-Fi System\")\n\n![MICOM & POWER AMP SCHEMATIC - LG RAT376B - Mini Hi-Fi\nSystem](//3.bp.blogspot.com/-92Oskeb2C5M/Uyl-\nlaWjxPI/AAAAAAAA_o0/039IkqhyYmk/s1600/MICOM.bmp.jpg)\n\n###  [ MICOM & POWER AMP SCHEMATIC - LG RAT376B - Mini Hi-Fi System\n](////electro404.rssing.com/chan-13553321/article882.html#c13553321a882i1547750503)\n\n[ \u2182\n](////adverbs45.rssing.com/chan-14763103/article227.html#c14763103a227i286089440\n\"Frequency Adverbs\")\n\n![Frequency\nAdverbs](//busyteacher.org/uploads/posts/2014-04/thumbs/1396577766_adverbs-of-\nfrecuency-0.png)\n\n###  [ Frequency Adverbs\n](////adverbs45.rssing.com/chan-14763103/article227.html#c14763103a227i286089440)\n\n[ \u2182\n](////ailsby1.rssing.com/chan-14855252/article8.html#c14855252a8i1619676318\n\"Decoration of the High Command of the Hitler Youth for Distinguished\nForeigners\")\n\n![Decoration of the High Command of the Hitler Youth for Distinguished\nForeigners](//4.bp.blogspot.com/-16fApX0rWmw/UBO8cvq9qpI/AAAAAAAABX0/UTZiUUYnjIU/s640/the+Hitler+Youth+for+Distinguished+Foreigners+-+obverse+-+fake+board.jpg)\n\n###  [ Decoration of the High Command of the Hitler Youth for Distinguished\nForeigners\n](////ailsby1.rssing.com/chan-14855252/article8.html#c14855252a8i1619676318)\n\n[ \u2182\n](////myhome191.rssing.com/chan-15086300/article8401.html#c15086300a8401i282862088\n\"5 Dromlee Crescent, Beaumont, Dublin 9 - \u20ac399,950\")\n\n![5 Dromlee Crescent, Beaumont, Dublin 9 -\n\u20ac399,950](//photos-a.propertyimages.ie/media/9/1/6/3382619/e9276a2d-0ce4-4db4-bd26-f758a44477dd_l.jpg)\n\n###  [ 5 Dromlee Crescent, Beaumont, Dublin 9 - \u20ac399,950\n](////myhome191.rssing.com/chan-15086300/article8401.html#c15086300a8401i282862088)\n\n[ \u2182\n](////augustacrime16.rssing.com/chan-36733858/article181.html#c36733858a181i777026533\n\"HAFSA ROBINSON\")\n\n![HAFSA ROBINSON](//augustacrime.com/wp-content/uploads/2016/12/Hafsa-\nRobinson-23-Theft-by-taking-240x300.jpg)\n\n###  [ HAFSA ROBINSON\n](////augustacrime16.rssing.com/chan-36733858/article181.html#c36733858a181i777026533)\n\n[ \u2182\n](////metro2989.rssing.com/chan-40972540/article57410.html#c40972540a57410i495009908\n\"The Umbrella Academy\u2019s Justin Min shares adorable first selfie with new\nboyfriend\")\n\n![The Umbrella Academy\u2019s Justin Min shares adorable first selfie with new\nboyfriend](//metro.co.uk/wp-content/uploads/2020/03/JUSTIN-MIN-2-0be4.png)\n\n###  [ The Umbrella Academy\u2019s Justin Min shares adorable first selfie with new\nboyfriend\n](////metro2989.rssing.com/chan-40972540/article57410.html#c40972540a57410i495009908)\n\n[ \u2182\n](////fonts1404.rssing.com/chan-57741102/article185.html#c57741102a185i1833605640\n\"Pumas 2022/2023 Font \\(TTF & OTF\\)\")\n\n![Pumas 2022/2023 Font \\(TTF &\nOTF\\)](//footballfonts.com/u/img/pumas-22-23-otf-font-installation.jpg)\n\n###  [ Pumas 2022/2023 Font (TTF & OTF)\n](////fonts1404.rssing.com/chan-57741102/article185.html#c57741102a185i1833605640)\n\n[ \u2182\n](////learn4804.rssing.com/chan-65098560/article5043.html#c65098560a5043i329832300\n\"Class 10 Sanskrit Grammar Book Solutions \u0905\u092a\u0920\u093f\u0924-\u0905\u0935\u092c\u094b\u0927\u0928\u092e\u094d\")\n\n![Class 10 Sanskrit Grammar Book Solutions\n\u0905\u092a\u0920\u093f\u0924-\u0905\u0935\u092c\u094b\u0927\u0928\u092e\u094d](//www.learncbse.in/wp-content/uploads/2017/08/NCERT-Solutions-\nfor-Class-10th-Sanskrit-Chapter-1-\u0905\u092a\u0920\u093f\u0924-\u0905\u0935\u092c\u094b\u0927\u0928\u092e-2.jpg)\n\n###  [ Class 10 Sanskrit Grammar Book Solutions \u0905\u092a\u0920\u093f\u0924-\u0905\u0935\u092c\u094b\u0927\u0928\u092e\u094d\n](////learn4804.rssing.com/chan-65098560/article5043.html#c65098560a5043i329832300)\n\n[ \u2182\n](////busyteacher96.rssing.com/chan-4234831/article296.html#c4234831a296i495218235\n\"Movie Worksheet: The Short Life of Anne Frank\")\n\n![Movie Worksheet: The Short Life of Anne\nFrank](//busyteacher.org/uploads/posts/2015-04/thumbs/1430406847_the-short-\nlife-of-anne-frank-0.png)\n\n###  [ Movie Worksheet: The Short Life of Anne Frank\n](////busyteacher96.rssing.com/chan-4234831/article296.html#c4234831a296i495218235)\n\n[ \u2182\n](////prasar9.rssing.com/chan-61257419/article6109.html#c61257419a6109i818610802\n\"Padmasree for Sri K G Jayan ,a senior musician of AIR Thrissur\")\n\n![Padmasree for Sri K G Jayan ,a senior musician of AIR\nThrissur](//2.bp.blogspot.com/-tLgIZZjIOWI/XEwatKG_qzI/AAAAAAAANYA/Irjv1Z-4URUW5-GlyA-\n_D4bLyIe8lbJhgCLcBGAs/s400/1.jpg)\n\n###  [ Padmasree for Sri K G Jayan ,a senior musician of AIR Thrissur\n](////prasar9.rssing.com/chan-61257419/article6109.html#c61257419a6109i818610802)\n\n[ \u2182\n](////ourhappyschool15.rssing.com/chan-59119707/article22.html#c59119707a22i1030558410\n\"Consuelo Ortiga y Rey: The \")\n\n![Consuelo Ortiga y Rey: The\n](//ourhappyschool.com/sites/default/files/LoveRizalJensen_0.jpg)\n\n###  [ Consuelo Ortiga y Rey: The \"Crush ng Bayan\" in Rizal's Time\n](////ourhappyschool15.rssing.com/chan-59119707/article22.html#c59119707a22i1030558410)\n\n\u02c2\n\n\u02c3\n\n####  Latest Images\n\n[ ![Very Hungry Caterpillar\u2122 Shirt: World of Eric Carle\u2122+ Little Goodall\nby...](//i.etsystatic.com/6018612/r/il/7591e4/3868173454/il_570xN.3868173454_gxfr.jpg)\n](////cryptomnesia.rssing.com/chan-1183730/article16627.html#c1183730a16627i1139077293)\n\n###  [ Very Hungry Caterpillar\u2122 Shirt: World of Eric Carle\u2122+ Little Goodall\nby...\n](////cryptomnesia.rssing.com/chan-1183730/article16627.html#c1183730a16627i1139077293)\n\nApril 14, 2024, 8:14 am\n\n[ ![Have you seen Michael Wines? Burien man has been missing since\nSaturday,...](//b-townblog.com/wp-\ncontent/uploads/2024/04/michael-3shoe.jpg?_t=1712879471)\n](////normandy480.rssing.com/chan-74604448/article56.html#c74604448a56i1857302427)\n\n###  [ Have you seen Michael Wines? Burien man has been missing since\nSaturday,...\n](////normandy480.rssing.com/chan-74604448/article56.html#c74604448a56i1857302427)\n\nApril 12, 2024, 3:59 pm\n\n[ ![Stay Salty POTS Awareness Stretchy Stacking Bracelets | Set of\nThree|...](//i.etsystatic.com/28677176/r/il/b2413c/4350795851/il_570xN.4350795851_fflz.jpg)\n](////pomaces4.rssing.com/chan-3795444/article11960.html#c3795444a11960i1086411135)\n\n###  [ Stay Salty POTS Awareness Stretchy Stacking Bracelets | Set of\nThree|...\n](////pomaces4.rssing.com/chan-3795444/article11960.html#c3795444a11960i1086411135)\n\nApril 11, 2024, 5:27 pm\n\n[ ![19 Reader-Favourite March Purchases \u2014 From Steals To\nSplurges](//www.refinery29.com/images/11700583.png?auto=webp&width=600&height=600&quality=85&crop=1:1)\n](////refinery1042.rssing.com/chan-72297680/article18978.html#c72297680a18978i36572736)\n\n###  [ 19 Reader-Favourite March Purchases \u2014 From Steals To Splurges\n](////refinery1042.rssing.com/chan-72297680/article18978.html#c72297680a18978i36572736)\n\nApril 11, 2024, 5:07 am\n\n[ ![Fake lip ring, silver lip ring, simple lip ring, unisex lip ring by\nAIRlab](//i.etsystatic.com/10798216/r/il/3a91cc/761285074/il_570xN.761285074_fu8j.jpg)\n](////kuteriot1.rssing.com/chan-5865851/article17035.html#c5865851a17035i913072506)\n\n###  [ Fake lip ring, silver lip ring, simple lip ring, unisex lip ring by\nAIRlab\n](////kuteriot1.rssing.com/chan-5865851/article17035.html#c5865851a17035i913072506)\n\nApril 9, 2024, 4:00 pm\n\n[ ![People's Blog \u2022 First Pictures of the Eclipse ! !\n!](//thepeoplescube.com/red/download/file.php?id=57243&sid=3721c68912ad1a7b63f4cf1eafba9b41)\n](////satire3490.rssing.com/chan-77006292/article253.html#c77006292a253i838655542)\n\n###  [ People's Blog \u2022 First Pictures of the Eclipse ! ! !\n](////satire3490.rssing.com/chan-77006292/article253.html#c77006292a253i838655542)\n\nApril 8, 2024, 1:08 pm\n\n[ ![People's Blog \u2022 First Pictures of the Eclipse ! !\n!](//thepeoplescube.com/red/download/file.php?id=57243&sid=d61d4527be50ef499d8f3761aad83688)\n](////satire6144.rssing.com/chan-78334822/article122.html#c78334822a122i1295535114)\n\n###  [ People's Blog \u2022 First Pictures of the Eclipse ! ! !\n](////satire6144.rssing.com/chan-78334822/article122.html#c78334822a122i1295535114)\n\nApril 8, 2024, 1:08 pm\n\n[ ![First Pictures of the Eclipse ! !\n!](//thepeoplescube.com/red/download/file.php?id=57243&sid=5311a0068099bb708e6eae6fd0456e59)\n](////political6691.rssing.com/chan-78391714/article69.html#c78391714a69i1437484910)\n\n###  [ First Pictures of the Eclipse ! ! !\n](////political6691.rssing.com/chan-78391714/article69.html#c78391714a69i1437484910)\n\nApril 8, 2024, 1:08 pm\n\n[ ![Highlights - Bringing young people to the forefront of EU policy making\n-...](//www.europarl.europa.eu/resources/library/images/20200115PHT70307/20200115PHT70307-ms.jpg)\n](////europees185.rssing.com/chan-78228109/article559.html#c78228109a559i1335926349)\n\n###  [ Highlights - Bringing young people to the forefront of EU policy making\n-...\n](////europees185.rssing.com/chan-78228109/article559.html#c78228109a559i1335926349)\n\nApril 8, 2024, 8:41 am\n\n[ ![People's Blog \u2022 Germany Bans the Number\n44](//thepeoplescube.com/red/download/file.php?id=57239&sid=5e19e13fd670da65c8b6b496c0630b51)\n](////political6769.rssing.com/chan-78425830/article66.html#c78425830a66i1994484930)\n\n###  [ People's Blog \u2022 Germany Bans the Number 44\n](////political6769.rssing.com/chan-78425830/article66.html#c78425830a66i1994484930)\n\nApril 8, 2024, 2:19 am\n\n  * [ RSSing>> ](//www.rssing.com/index.php)\n  * [ Latest ](//www.rssing.com/index.php?l=l)\n  * [ Popular ](//www.rssing.com/index.php?l=p)\n  * [ Top Rated ](//www.rssing.com/index.php?l=r)\n  * [ Trending ](//www.rssing.com/index.php?l=t)\n\n\u00a9 2024 //www.rssing.com\n\n"
  },
  {
    "id": "dynamic_reconfig/rangesensorlayer8cpp.txt",
    "content": "Main Page\n+Namespaces\n+Classes\n+Files\nsrc\nrange_sensor_layer.cpp\nGo to the documentation of this file.\n // Copyright 2018 David V. Lu!!\n #include <range_sensor_layer/range_sensor_layer.h>\n #include <boost/algorithm/string.hpp>\n #include <geometry_msgs/PointStamped.h>\n #include <pluginlib/class_list_macros.h>\n #include <angles/angles.h>\n #include <algorithm>\n #include <list>\n #include <limits>\n #include <map>\n #include <string>\n #include <utility>\n \n PLUGINLIB_EXPORT_CLASS(range_sensor_layer::RangeSensorLayer, costmap_2d::Layer)\n \n using costmap_2d::NO_INFORMATION;\n \n namespace range_sensor_layer\n {\n \n RangeSensorLayer::RangeSensorLayer() {}\n \n void RangeSensorLayer::onInitialize()\n {\n   ros::NodeHandle nh(\"~/\" + name_);\n   current_ = true;\n   buffered_readings_ = 0;\n   last_reading_time_ = ros::Time::now();\n   default_value_ = to_cost(0.5);\n \n   matchSize();\n   resetRange();\n \n   // Default topic names list contains a single topic: /sonar\n   // We use the XmlRpcValue constructor that takes a XML string and reading start offset\n   const char* xml = \"<value><array><data><value>/sonar</value></data></array></value>\";\n   int zero_offset = 0;\n   std::string topics_ns;\n   XmlRpc::XmlRpcValue topic_names(xml, &zero_offset);\n \n   nh.param(\"ns\", topics_ns, std::string());\n   nh.param(\"topics\", topic_names, topic_names);\n \n   InputSensorType input_sensor_type = ALL;\n   std::string sensor_type_name;\n   nh.param(\"input_sensor_type\", sensor_type_name, std::string(\"ALL\"));\n \n   nh.param(\"use_decay\", use_decay_, false);\n   nh.param(\"pixel_decay\", pixel_decay_, 10.0);\n   nh.param(\"transform_tolerance_\", transform_tolerance_, 0.3);\n \n   boost::to_upper(sensor_type_name);\n   ROS_INFO(\"%s: %s as input_sensor_type given\", name_.c_str(), sensor_type_name.c_str());\n \n   if (sensor_type_name == \"VARIABLE\")\n     input_sensor_type = VARIABLE;\n   else if (sensor_type_name == \"FIXED\")\n     input_sensor_type = FIXED;\n   else if (sensor_type_name == \"ALL\")\n     input_sensor_type = ALL;\n   else\n   {\n     ROS_ERROR(\"%s: Invalid input sensor type: %s\", name_.c_str(), sensor_type_name.c_str());\n   }\n \n   // Validate topic names list: it must be a (normally non-empty) list of strings\n   if ((topic_names.valid() == false) || (topic_names.getType() != XmlRpc::XmlRpcValue::TypeArray))\n   {\n     ROS_ERROR(\"Invalid topic names list: it must be a non-empty list of strings\");\n     return;\n   }\n \n   if (topic_names.size() < 1)\n   {\n     // This could be an error, but I keep it as it can be useful for debug\n     ROS_WARN(\"Empty topic names list: range sensor layer will have no effect on costmap\");\n   }\n \n   // Traverse the topic names list subscribing to all of them with the same callback method\n   for (int i = 0; i < topic_names.size(); i++)\n   {\n     if (topic_names[i].getType() != XmlRpc::XmlRpcValue::TypeString)\n     {\n       ROS_WARN(\"Invalid topic names list: element %d is not a string, so it will be ignored\", i);\n     }\n     else\n     {\n       std::string topic_name(topics_ns);\n       if ((topic_name.size() > 0) && (topic_name.at(topic_name.size() - 1) != '/'))\n         topic_name += \"/\";\n       topic_name += static_cast<std::string>(topic_names[i]);\n \n       if (input_sensor_type == VARIABLE)\n         processRangeMessageFunc_ = boost::bind(&RangeSensorLayer::processVariableRangeMsg, this, _1);\n       else if (input_sensor_type == FIXED)\n         processRangeMessageFunc_ = boost::bind(&RangeSensorLayer::processFixedRangeMsg, this, _1);\n       else if (input_sensor_type == ALL)\n         processRangeMessageFunc_ = boost::bind(&RangeSensorLayer::processRangeMsg, this, _1);\n       else\n       {\n         ROS_ERROR(\n           \"%s: Invalid input sensor type: %s. Did you make a new type and forgot to choose the subscriber for it?\",\n           name_.c_str(), sensor_type_name.c_str());\n       }\n \n       range_subs_.push_back(nh.subscribe(topic_name, 100, &RangeSensorLayer::bufferIncomingRangeMsg, this));\n \n       ROS_INFO(\"RangeSensorLayer: subscribed to topic %s\", range_subs_.back().getTopic().c_str());\n     }\n   }\n \n   dsrv_ = new dynamic_reconfigure::Server<range_sensor_layer::RangeSensorLayerConfig>(nh);\n   dynamic_reconfigure::Server<range_sensor_layer::RangeSensorLayerConfig>::CallbackType cb =\n     boost::bind(&RangeSensorLayer::reconfigureCB, this, _1, _2);\n   dsrv_->setCallback(cb);\n   global_frame_ = layered_costmap_->getGlobalFrameID();\n }\n \n \n double RangeSensorLayer::gamma(double theta)\n {\n   if (fabs(theta) > max_angle_)\n     return 0.0;\n   else\n     return 1 - pow(theta / max_angle_, 2);\n }\n \n double RangeSensorLayer::delta(double phi)\n {\n   return 1 - (1 + tanh(2 * (phi - phi_v_))) / 2;\n }\n \n void RangeSensorLayer::get_deltas(double angle, double *dx, double *dy)\n {\n   double ta = tan(angle);\n   if (ta == 0)\n     *dx = 0;\n   else\n     *dx = resolution_ / ta;\n \n   *dx = copysign(*dx, cos(angle));\n   *dy = copysign(resolution_, sin(angle));\n }\n \n double RangeSensorLayer::sensor_model(double r, double phi, double theta)\n {\n   double lbda = delta(phi) * gamma(theta);\n \n   double delta = resolution_;\n \n   if (phi >= 0.0 && phi < r - 2 * delta * r)\n     return (1 - lbda) * (0.5);\n   else if (phi < r - delta * r)\n     return lbda * 0.5 * pow((phi - (r - 2 * delta * r)) / (delta * r), 2) + (1 - lbda) * .5;\n   else if (phi < r + delta * r)\n   {\n     double J = (r - phi) / (delta * r);\n     return lbda * ((1 - (0.5) * pow(J, 2)) - 0.5) + 0.5;\n   }\n   else\n     return 0.5;\n }\n \n \n void RangeSensorLayer::reconfigureCB(range_sensor_layer::RangeSensorLayerConfig &config, uint32_t level)\n {\n   phi_v_ = config.phi;\n   inflate_cone_ = config.inflate_cone;\n   no_readings_timeout_ = config.no_readings_timeout;\n   clear_threshold_ = config.clear_threshold;\n   mark_threshold_ = config.mark_threshold;\n   clear_on_max_reading_ = config.clear_on_max_reading;\n \n   if (enabled_ != config.enabled)\n   {\n     enabled_ = config.enabled;\n     current_ = false;\n   }\n }\n \n void RangeSensorLayer::bufferIncomingRangeMsg(const sensor_msgs::RangeConstPtr& range_message)\n {\n   boost::mutex::scoped_lock lock(range_message_mutex_);\n   range_msgs_buffer_.push_back(*range_message);\n }\n \n void RangeSensorLayer::updateCostmap()\n {\n   std::list<sensor_msgs::Range> range_msgs_buffer_copy;\n \n   range_message_mutex_.lock();\n   range_msgs_buffer_copy = std::list<sensor_msgs::Range>(range_msgs_buffer_);\n   range_msgs_buffer_.clear();\n   range_message_mutex_.unlock();\n \n   for (std::list<sensor_msgs::Range>::iterator range_msgs_it = range_msgs_buffer_copy.begin();\n        range_msgs_it != range_msgs_buffer_copy.end(); range_msgs_it++)\n   {\n     processRangeMessageFunc_(*range_msgs_it);\n   }\n }\n \n void RangeSensorLayer::processRangeMsg(sensor_msgs::Range& range_message)\n {\n   if (range_message.min_range == range_message.max_range)\n     processFixedRangeMsg(range_message);\n   else\n     processVariableRangeMsg(range_message);\n }\n \n void RangeSensorLayer::processFixedRangeMsg(sensor_msgs::Range& range_message)\n {\n   if (!std::isinf(range_message.range))\n   {\n     ROS_ERROR_THROTTLE(1.0,\n                        \"Fixed distance ranger (min_range == max_range) in frame %s sent invalid value. \"\n                        \"Only -Inf (== object detected) and Inf (== no object detected) are valid.\",\n                        range_message.header.frame_id.c_str());\n     return;\n   }\n \n   bool clear_sensor_cone = false;\n \n   if (range_message.range > 0)  // +inf\n   {\n     if (!clear_on_max_reading_)\n       return;  // no clearing at all\n \n     clear_sensor_cone = true;\n   }\n \n   range_message.range = range_message.min_range;\n \n   updateCostmap(range_message, clear_sensor_cone);\n }\n \n void RangeSensorLayer::processVariableRangeMsg(sensor_msgs::Range& range_message)\n {\n   if (range_message.range < range_message.min_range || range_message.range > range_message.max_range)\n     return;\n \n   bool clear_sensor_cone = false;\n \n   if (range_message.range == range_message.max_range && clear_on_max_reading_)\n     clear_sensor_cone = true;\n \n   updateCostmap(range_message, clear_sensor_cone);\n }\n \n void RangeSensorLayer::updateCostmap(sensor_msgs::Range& range_message, bool clear_sensor_cone)\n {\n   max_angle_ = range_message.field_of_view / 2;\n \n   geometry_msgs::PointStamped in, out;\n   in.header.stamp = range_message.header.stamp;\n   in.header.frame_id = range_message.header.frame_id;\n \n   if (!tf_->canTransform(global_frame_, in.header.frame_id, in.header.stamp, ros::Duration(transform_tolerance_)))\n   {\n     ROS_ERROR_THROTTLE(1.0, \"Range sensor layer can't transform from %s to %s at %f\",\n                        global_frame_.c_str(), in.header.frame_id.c_str(),\n                        in.header.stamp.toSec());\n     return;\n   }\n \n   tf_->transform(in, out, global_frame_);\n \n   double ox = out.point.x, oy = out.point.y;\n \n   in.point.x = range_message.range;\n \n   tf_->transform(in, out, global_frame_);\n \n   double tx = out.point.x, ty = out.point.y;\n \n   // calculate target props\n   double dx = tx - ox, dy = ty - oy, theta = atan2(dy, dx), d = sqrt(dx * dx + dy * dy);\n \n   // Integer Bounds of Update\n   int bx0, by0, bx1, by1;\n \n   // Triangle that will be really updated; the other cells within bounds are ignored\n   // This triangle is formed by the origin and left and right sides of sonar cone\n   int Ox, Oy, Ax, Ay, Bx, By;\n \n   // Bounds includes the origin\n   worldToMapNoBounds(ox, oy, Ox, Oy);\n   bx1 = bx0 = Ox;\n   by1 = by0 = Oy;\n   touch(ox, oy, &min_x_, &min_y_, &max_x_, &max_y_);\n \n   // Update Map with Target Point\n   unsigned int aa, ab;\n   if (worldToMap(tx, ty, aa, ab))\n   {\n     setCost(aa, ab, 233);\n     touch(tx, ty, &min_x_, &min_y_, &max_x_, &max_y_);\n   }\n \n   double mx, my;\n \n   // Update left side of sonar cone\n   mx = ox + cos(theta - max_angle_) * d * 1.2;\n   my = oy + sin(theta - max_angle_) * d * 1.2;\n   worldToMapNoBounds(mx, my, Ax, Ay);\n   bx0 = std::min(bx0, Ax);\n   bx1 = std::max(bx1, Ax);\n   by0 = std::min(by0, Ay);\n   by1 = std::max(by1, Ay);\n   touch(mx, my, &min_x_, &min_y_, &max_x_, &max_y_);\n \n   // Update right side of sonar cone\n   mx = ox + cos(theta + max_angle_) * d * 1.2;\n   my = oy + sin(theta + max_angle_) * d * 1.2;\n \n   worldToMapNoBounds(mx, my, Bx, By);\n   bx0 = std::min(bx0, Bx);\n   bx1 = std::max(bx1, Bx);\n   by0 = std::min(by0, By);\n   by1 = std::max(by1, By);\n   touch(mx, my, &min_x_, &min_y_, &max_x_, &max_y_);\n \n   // Limit Bounds to Grid\n   bx0 = std::max(0, bx0);\n   by0 = std::max(0, by0);\n   bx1 = std::min(static_cast<int>(size_x_), bx1);\n   by1 = std::min(static_cast<int>(size_y_), by1);\n \n   for (unsigned int x = bx0; x <= (unsigned int)bx1; x++)\n   {\n     for (unsigned int y = by0; y <= (unsigned int)by1; y++)\n     {\n       bool update_xy_cell = true;\n \n       // Unless inflate_cone_ is set to 100 %, we update cells only within the (partially inflated) sensor cone,\n       // projected on the costmap as a triangle. 0 % corresponds to just the triangle, but if your sensor fov is\n       // very narrow, the covered area can become zero due to cell discretization. See wiki description for more\n       // details\n       if (inflate_cone_ < 1.0)\n       {\n         // Determine barycentric coordinates\n         int w0 = orient2d(Ax, Ay, Bx, By, x, y);\n         int w1 = orient2d(Bx, By, Ox, Oy, x, y);\n         int w2 = orient2d(Ox, Oy, Ax, Ay, x, y);\n \n         // Barycentric coordinates inside area threshold; this is not mathematically sound at all, but it works!\n         float bcciath = -inflate_cone_ * area(Ax, Ay, Bx, By, Ox, Oy);\n         update_xy_cell = w0 >= bcciath && w1 >= bcciath && w2 >= bcciath;\n       }\n \n       if (update_xy_cell)\n       {\n         double wx, wy;\n         mapToWorld(x, y, wx, wy);\n         update_cell(ox, oy, theta, range_message.range, wx, wy, clear_sensor_cone);\n       }\n     }\n   }\n \n   buffered_readings_++;\n   last_reading_time_ = ros::Time::now();\n   if (use_decay_)\n     removeOutdatedReadings();\n }\n \n void RangeSensorLayer::removeOutdatedReadings()\n {\n   std::map<std::pair<unsigned int, unsigned int>, double>::iterator it_map;\n \n   double removal_time = last_reading_time_.toSec() - pixel_decay_;\n   for (it_map = marked_point_history_.begin() ; it_map != marked_point_history_.end() ; it_map++ )\n   {\n     if (it_map->second < removal_time)\n     {\n       marked_point_history_.erase(it_map);\n       setCost(std::get<0>(it_map->first), std::get<1>(it_map->first), costmap_2d::FREE_SPACE);\n     }\n   }\n }\n \n void RangeSensorLayer::update_cell(double ox, double oy, double ot, double r, double nx, double ny, bool clear)\n {\n   unsigned int x, y;\n   if (worldToMap(nx, ny, x, y))\n   {\n     double dx = nx - ox, dy = ny - oy;\n     double theta = atan2(dy, dx) - ot;\n     theta = angles::normalize_angle(theta);\n     double phi = sqrt(dx * dx + dy * dy);\n     double sensor = 0.0;\n     if (!clear)\n       sensor = sensor_model(r, phi, theta);\n     double prior = to_prob(getCost(x, y));\n     double prob_occ = sensor * prior;\n     double prob_not = (1 - sensor) * (1 - prior);\n     double new_prob = prob_occ / (prob_occ + prob_not);\n \n     ROS_DEBUG(\"%f %f | %f %f = %f\", dx, dy, theta, phi, sensor);\n     ROS_DEBUG(\"%f | %f %f | %f\", prior, prob_occ, prob_not, new_prob);\n     unsigned char c = to_cost(new_prob);\n \n     setCost(x, y, c);\n     if (use_decay_)\n     {\n       std::pair<unsigned int, unsigned int> coordinate_pair(x, y);\n       // If the point has a score high enough to be marked in the costmap, we add it's time to the marked_point_history\n       if (c > to_cost(mark_threshold_))\n         marked_point_history_[coordinate_pair] = last_reading_time_.toSec();\n       // If the point score is not high enough, we try to find it in the mark history point.\n       // In the case we find it in the marked_point_history\n       // we clear it from the map so we won't checked already cleared point\n       else if (c < to_cost(clear_threshold_))\n       {\n         std::map<std::pair<unsigned int, unsigned int>, double>::iterator it_clear;\n         it_clear = marked_point_history_.find(coordinate_pair);\n         if (it_clear != marked_point_history_.end())\n           marked_point_history_.erase(it_clear);\n       }\n     }\n   }\n }\n \n void RangeSensorLayer::resetRange()\n {\n   min_x_ = min_y_ =  std::numeric_limits<double>::max();\n   max_x_ = max_y_ = -std::numeric_limits<double>::max();\n }\n \n void RangeSensorLayer::updateBounds(double robot_x, double robot_y, double robot_yaw,\n                                     double* min_x, double* min_y, double* max_x, double* max_y)\n {\n   if (layered_costmap_->isRolling())\n     updateOrigin(robot_x - getSizeInMetersX() / 2, robot_y - getSizeInMetersY() / 2);\n \n   updateCostmap();\n \n   *min_x = std::min(*min_x, min_x_);\n   *min_y = std::min(*min_y, min_y_);\n   *max_x = std::max(*max_x, max_x_);\n   *max_y = std::max(*max_y, max_y_);\n \n   resetRange();\n \n   if (!enabled_)\n   {\n     current_ = true;\n     return;\n   }\n \n   if (buffered_readings_ == 0)\n   {\n     if (no_readings_timeout_ > 0.0 &&\n         (ros::Time::now() - last_reading_time_).toSec() > no_readings_timeout_)\n     {\n       ROS_WARN_THROTTLE(2.0, \"No range readings received for %.2f seconds, \" \\\n                         \"while expected at least every %.2f seconds.\",\n                         (ros::Time::now() - last_reading_time_).toSec(), no_readings_timeout_);\n       current_ = false;\n     }\n   }\n }\n \n void RangeSensorLayer::updateCosts(costmap_2d::Costmap2D& master_grid, int min_i, int min_j, int max_i, int max_j)\n {\n   if (!enabled_)\n     return;\n \n   unsigned char* master_array = master_grid.getCharMap();\n   unsigned int span = master_grid.getSizeInCellsX();\n   unsigned char clear = to_cost(clear_threshold_), mark = to_cost(mark_threshold_);\n \n   for (int j = min_j; j < max_j; j++)\n   {\n     unsigned int it = j * span + min_i;\n     for (int i = min_i; i < max_i; i++)\n     {\n       unsigned char prob = costmap_[it];\n       unsigned char current;\n       if (prob == costmap_2d::NO_INFORMATION)\n       {\n         it++;\n         continue;\n       }\n       else if (prob > mark)\n         current = costmap_2d::LETHAL_OBSTACLE;\n       else if (prob < clear)\n         current = costmap_2d::FREE_SPACE;\n       else\n       {\n         it++;\n         continue;\n       }\n \n       unsigned char old_cost = master_array[it];\n \n       if (old_cost == NO_INFORMATION || old_cost < current)\n         master_array[it] = current;\n       it++;\n     }\n   }\n \n   buffered_readings_ = 0;\n   current_ = true;\n }\n \n void RangeSensorLayer::reset()\n {\n   ROS_DEBUG(\"Reseting range sensor layer...\");\n   deactivate();\n   resetMaps();\n   current_ = true;\n   activate();\n }\n \n void RangeSensorLayer::deactivate()\n {\n   range_msgs_buffer_.clear();\n }\n \n void RangeSensorLayer::activate()\n {\n   range_msgs_buffer_.clear();\n }\n \n }  // namespace range_sensor_layer\n\nrange_sensor_layer\nAuthor(s): David!!\nautogenerated on Mon Feb 28 2022 22:55:28"
  },
  {
    "id": "gazebo_detach/26.txt",
    "content": "Skip to content\n\nToggle navigation\n\n[ ](https://github.com/)\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2FJenniferBuehler%2Fgazebo-\npkgs%2Fissues%2F26)\n\n  * Product \n\n    * [ Actions  Automate any workflow  ](/features/actions)\n    * [ Packages  Host and manage packages  ](/features/packages)\n    * [ Security  Find and fix vulnerabilities  ](/features/security)\n    * [ Codespaces  Instant dev environments  ](/features/codespaces)\n    * [ Copilot  Write better code with AI  ](/features/copilot)\n    * [ Code review  Manage code changes  ](/features/code-review)\n    * [ Issues  Plan and track work  ](/features/issues)\n    * [ Discussions  Collaborate outside of code  ](/features/discussions)\n\nExplore\n\n    * [ All features ](/features)\n    * [ Documentation  ](https://docs.github.com)\n    * [ GitHub Skills  ](https://skills.github.com/)\n    * [ Blog  ](https://github.blog)\n\n  * Solutions \n\nFor\n\n    * [ Enterprise ](/enterprise)\n    * [ Teams ](/team)\n    * [ Startups ](/enterprise/startups)\n    * [ Education  ](https://education.github.com)\n\nBy Solution\n\n    * [ CI/CD & Automation ](/solutions/ci-cd/)\n    * [ DevOps ](/solutions/devops/)\n    * [ DevSecOps  ](https://resources.github.com/devops/fundamentals/devsecops/)\n\nResources\n\n    * [ Learning Pathways  ](https://resources.github.com/learn/pathways/)\n    * [ White papers, Ebooks, Webinars  ](https://resources.github.com/)\n    * [ Customer Stories ](/customer-stories)\n    * [ Partners  ](https://partner.github.com/)\n\n  * Open Source \n\n    * [ GitHub Sponsors  Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project  GitHub community articles  ](/readme)\n\nRepositories\n\n    * [ Topics ](/topics)\n    * [ Trending ](/trending)\n    * [ Collections ](/collections)\n\n  * [ Pricing ](/pricing)\n\nSearch or jump to...\n\n#  Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[ Search syntax tips ](https://docs.github.com/search-github/github-code-\nsearch/understanding-github-code-search-syntax)\n\n#  Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n##  Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [ documentation\n](https://docs.github.com/search-github/github-code-search/understanding-\ngithub-code-search-syntax) .\n\nCancel  Create saved search\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2FJenniferBuehler%2Fgazebo-\npkgs%2Fissues%2F26)\n\n[ Sign up\n](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-\nname%3E%2F%3Crepo-\nname%3E%2Fvoltron%2Fissues_fragments%2Fissue_layout&source=header-\nrepo&source_repo=JenniferBuehler%2Fgazebo-pkgs)\n\nYou signed in with another tab or window. [ Reload ]() to refresh your\nsession.  You signed out in another tab or window. [ Reload ]() to refresh\nyour session.  You switched accounts on another tab or window. [ Reload ]() to\nrefresh your session.  Dismiss alert\n\n{{ message }}\n\n[ JenniferBuehler ](/JenniferBuehler) /  **[ gazebo-pkgs\n](/JenniferBuehler/gazebo-pkgs) ** Public\n\n  * [ Notifications ](/login?return_to=%2FJenniferBuehler%2Fgazebo-pkgs)\n  * [ Fork  100  ](/login?return_to=%2FJenniferBuehler%2Fgazebo-pkgs)\n  * [ Star  188  ](/login?return_to=%2FJenniferBuehler%2Fgazebo-pkgs)\n\n  * [ Code  ](/JenniferBuehler/gazebo-pkgs)\n  * [ Issues  9  ](/JenniferBuehler/gazebo-pkgs/issues)\n  * [ Pull requests  0  ](/JenniferBuehler/gazebo-pkgs/pulls)\n  * [ Actions  ](/JenniferBuehler/gazebo-pkgs/actions)\n  * [ Projects  0  ](/JenniferBuehler/gazebo-pkgs/projects)\n  * [ Wiki  ](/JenniferBuehler/gazebo-pkgs/wiki)\n  * [ Security  ](/JenniferBuehler/gazebo-pkgs/security)\n  * [ Insights  ](/JenniferBuehler/gazebo-pkgs/pulse)\n\nAdditional navigation options\n\n  * [ Code  ](/JenniferBuehler/gazebo-pkgs)\n  * [ Issues  ](/JenniferBuehler/gazebo-pkgs/issues)\n  * [ Pull requests  ](/JenniferBuehler/gazebo-pkgs/pulls)\n  * [ Actions  ](/JenniferBuehler/gazebo-pkgs/actions)\n  * [ Projects  ](/JenniferBuehler/gazebo-pkgs/projects)\n  * [ Wiki  ](/JenniferBuehler/gazebo-pkgs/wiki)\n  * [ Security  ](/JenniferBuehler/gazebo-pkgs/security)\n  * [ Insights  ](/JenniferBuehler/gazebo-pkgs/pulse)\n\nNew issue\n\n**Have a question about this project?** Sign up for a free GitHub account to\nopen an issue and contact its maintainers and the community.\n\nPick a username\n\n    \n\nEmail Address\n\n    \n\nPassword\n\n    \nSign up for GitHub\n\nBy clicking \u201cSign up for GitHub\u201d, you agree to our [ terms of service\n](https://docs.github.com/terms) and [ privacy statement\n](https://docs.github.com/privacy) . We\u2019ll occasionally send you account\nrelated emails.\n\nAlready on GitHub? [ Sign in ](/login?return_to=%2FJenniferBuehler%2Fgazebo-\npkgs%2Fissues%2Fnew%2Fchoose) to your account\n\nJump to bottom\n\n#  Velocity seems to be set to 0 after detaching  #26\n\nOpen\n\n[ sven-hoek ](/sven-hoek) opened this issue  Feb 3, 2019  \u00b7 30 comments\n\nOpen\n\n#  Velocity seems to be set to 0 after detaching  #26\n\n[ sven-hoek ](/sven-hoek) opened this issue  Feb 3, 2019  \u00b7 30 comments\n\n##  Comments\n\n[ ![@sven-\nhoek](https://avatars.githubusercontent.com/u/15048669?s=80&u=1184c86424c64f25eb98710ad8c40e72cc3fb679&v=4)\n](/sven-hoek)\n\nCopy link\n\n###\n\n**[ sven-hoek ](/sven-hoek) ** commented  Feb 3, 2019\n\nThe plugin seems to work pretty well but I was checking what happened, when\nthe gripper opens while in motion. It seems that the gripped object's velocity\nis reset and falls straight down by gravity.  \nFor example in situations, where the simulated robot is supposed to throw an\nobject, it would be important, that the gripped object keeps its velocity.  \n  \n---  \n  \nThe text was updated successfully, but these errors were encountered:\n\n  \n  \nAll reactions\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Feb 3, 2019  \u2022\n\nedited\n\nIt's quite possible I haven't considered this. Detachment is handled [ here\n](https://github.com/JenniferBuehler/gazebo-\npkgs/blob/f4700ea772e4757ed6a0ebffb50a288dd131dcf4/gazebo_grasp_plugin/src/GazeboGraspGripper.cpp#L167)\n\\- ignore the ` USE_MODEL_ATTACH ` flag, I should remove that some time, it\nwas for testing. I'm not explicitly resetting velocity, but it could be that\ndetaching a joint from another joint with ` Joint::Detach() ` causes this. The\n` fixedJoint ` is a fake joint which is added to connect the object to the\ngripper while the object is attached. It would of course be possible to store\nthe velocity before detachment and restore it after, as a simple solution (if\ndetaching is the cause of the issue at all).\n\nI don't have time this week to check up on this but will try as soon as I can,\nif you haven't solved it until then.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@sven-\nhoek](https://avatars.githubusercontent.com/u/15048669?s=80&u=1184c86424c64f25eb98710ad8c40e72cc3fb679&v=4)\n](/sven-hoek)\n\nCopy link\n\nAuthor\n\n###\n\n**[ sven-hoek ](/sven-hoek) ** commented  Feb 4, 2019  \u2022\n\nedited\n\nOkay, so I've had no experience with Gazebo plugins before and naively tried\nto set the object link's velocity to its previous, without seeing a change in\nbehavior:\n\n    \n    \n    physics::LinkPtr objLink = boost::dynamic_pointer_cast<physics::Link>(obj->GetParent());\n    ignition::math::Vector3d linVel = objLink->WorldLinearVel();\n    ignition::math::Vector3d angVel = objLink->WorldAngularVel();\n    \n    this->fixedJoint->Detach();\n    \n    objLink->SetLinearVel(linVel);\n    objLink->SetAngularVel(angVel);\n    \n\nThen, when checking the velocities of the link before and after ` Detach() ` ,\nthey stay the same, even when I don't set them myself.  \nDid I set the velocity of the wrong object or have any other misconceptions?\nAny other suggestions where the velocity could be set/reset? I also tried\nworking with the parent of my objLink, which was the ` Model ` with name ` Box\n` (corresponding to the box I'm gripping).\n\nNote, that I am using Gazebo9 with the plugin modifications from the open pull\nrequest in this repo, so the method names should be ` GetWorldLinearVel ` , `\nGetWorldAngularVel ` for Gazebo versions below 8.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Feb 4, 2019\n\nI'm not sure about ` obj->getParent() ` , what is ` obj ` is in your case, is\nit the  \nsame object as [ here ](https://github.com/JenniferBuehler/gazebo-\npkgs/blob/f4700ea772e4757ed6a0ebffb50a288dd131dcf4/gazebo_grasp_plugin/src/GazeboGraspGripper.cpp#L183)\n? Maybe try ` obj->getLink() ` ?  \nWhat is the velocity of the object before detachment? Does it have any?\n\nIn any case, you need to set the velocity to the _link_ of your object (the\nroot link of all the object parts). If it doesn't have an easy to recognize\nname in your SDF/URDF, then maybe give it one for testing, and make sure this\nis the link you are setting the velocity to.  \nSee also [ this tutorial ](http://gazebosim.org/tutorials?tut=set_velocity)\n(section \"Set Link Velocity Instantaneously\").\n\nAnother thing to consider is the object properties, like weight. Once the\nobject is detached, it will be subject to gravity again. So if it's very heavy\nand the speed isn't that high, it would fall to the ground pretty quickly,\nmaybe the linear velocity won't be noticed as much then, as the gravity force\npulling it causes it to change too much?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Feb 4, 2019\n\nBTW, if you are using the open pull request, I guess you reverted the faulty\ncommits at the end, which were done automatically by verifying the suggestions\nI wrote in the discussion (which were meant to be like pseudo code only, but\nthen they were commited). I guess so, otherwise it probably wouldn't be\ncompiling...  \nI have so little time at hand that I still wasn't able to fix the PR myself. I\nwill try to do this on the weekend, it's long overdue ;)  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@sven-\nhoek](https://avatars.githubusercontent.com/u/15048669?s=80&u=1184c86424c64f25eb98710ad8c40e72cc3fb679&v=4)\n](/sven-hoek)\n\nCopy link\n\nAuthor\n\n###\n\n**[ sven-hoek ](/sven-hoek) ** commented  Feb 5, 2019\n\n> is it the same object as [ here ](https://github.com/JenniferBuehler/gazebo-\n> pkgs/blob/f4700ea772e4757ed6a0ebffb50a288dd131dcf4/gazebo_grasp_plugin/src/GazeboGraspGripper.cpp#L183)\n> ?\n\nYes, it's the same object/scope and yes, it does have velocity before. My\nobject is just a box, so there is only one link, which is the parent of ` obj\n` . Using ` GetLink() ` unfortunately didn't change anything. I checked, if\nit's really the right link.  \nI lowered the execution speed a lot by lowering the step size/limiting the\nreal time update rate and also reduced the gravity a lot. At the point of\nreleasing the object, it just stops abruptly.\n\nI'm using an earlier commit of the PR, where everything version-related was\nenclosed by ` #if ` -macros. Thanks for your support and for your work! Hope,\nI can be of help by trying to resolve this. I'll check if the velocity\nrestoration works when done in the update method of the plugin.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@sven-\nhoek](https://avatars.githubusercontent.com/u/15048669?s=80&u=1184c86424c64f25eb98710ad8c40e72cc3fb679&v=4)\n](/sven-hoek)\n\nCopy link\n\nAuthor\n\n###\n\n**[ sven-hoek ](/sven-hoek) ** commented  Feb 5, 2019\n\nOk, so unfortunately it also doesn't seem to work when restoring the velocity\nafter [ this line ](https://github.com/JenniferBuehler/gazebo-\npkgs/blob/f4700ea772e4757ed6a0ebffb50a288dd131dcf4/gazebo_grasp_plugin/src/GazeboGraspFix.cpp#L621)\n.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Feb 7, 2019\n\nHi,  \nok, that sounds like something is off. With your object, if you set its\nvelocity like that before you do any attachment, does it react to it at all?  \nI'll have to look into the Gazebo set velocity code again to refresh my memory\non how it works. First, can you check if the object's velocity can be set\nbefore you use the attachment with the plugin?  \nAlso, you can try to set force and/or acceleration and see if that makes a\ndifference, just to see if everything works fine with the object in general.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@sven-\nhoek](https://avatars.githubusercontent.com/u/15048669?s=80&u=1184c86424c64f25eb98710ad8c40e72cc3fb679&v=4)\n](/sven-hoek)\n\nCopy link\n\nAuthor\n\n###\n\n**[ sven-hoek ](/sven-hoek) ** commented  Feb 7, 2019\n\nI tried setting an arbitrary velocity at the end of ` GazeboGraspFix::Load() `\nand it works without any problems. I then added an arbitrary force or velocity\nafter the detachment process inside ` GazeboGraspFix::OnUpdate() ` and both\nalso worked. This means at least, that the velocity won't be reset after this\nstep.  \nSo, even though the object has a velocity right before the detachment, they\nare too small to be seen or realistic. For example, I mostly got velocities\nlike ` (0.002224 -0.000124 0.003645) ` but sometimes something like `\n(-0.01131 0.124148 0.007077) ` , which is still small but at least in\ny-direction not negligible small. Maybe just noise, though.  \nIf I find the time, I will see, whether I find a better way to get the\nvelocity. It seems weird, though, that the velocity is that low, which would\nmake some sense if it were in relation to the gripper, whereas the name `\nWorldLinearVel() ` suggests, that it's in relation to the world frame.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Feb 12, 2019\n\nHmmm... maybe the velocity of links which are attached to a moving joint are\nnot updated, though I would have thought so. Sorry I'm being so slow on\ntesting this, I had too much work to get done, and tomorrow I'm going away for\na week. I still have this on my radar, and eventually I will get to test this.\nMeanwhile, let me know if you find out more.\n\nMy first thought would be to check the links of the gripper while they are\nmoving obviously fast, and see if they have a reasonable velocity. Just to\nconfirm whether links attached to moving joints have a realistic world\nvelocity.  \nIf that's the case, then maybe try to assign the velocity which the gripper\nhad at the moment of detachment. Though my guess would be that if the cube\ndoesn't have a significant velocity while it is still attached, the gripping\nlink probably won't be much different. But it would be worth a check.\n\nNext step would be to look up in the Gazebo code how exactly the velocity of\nLinks is updated. I can't remember exactly how it worked, but a look at the\ncode will tell the truth ;)\n\nOne other random try would also be to try a different physics engine (e.g. `\ngazebo -e bullet ` ) to see if that's the same there.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@sven-\nhoek](https://avatars.githubusercontent.com/u/15048669?s=80&u=1184c86424c64f25eb98710ad8c40e72cc3fb679&v=4)\n](/sven-hoek)\n\nCopy link\n\nAuthor\n\n###\n\n**[ sven-hoek ](/sven-hoek) ** commented  Feb 17, 2019\n\nI appreciate every bit of work and help that you put into this and right now\nthis is also not my main work, so I'm also kinda slow on this. But I just\nplotted the velocity of the link of the object and of the gripper (inside\nGazebo).  \n2 things are really weird:\n\n  * The velocity of the gripper link is way smaller than the one of the object and this cannot be because of some lever action \n  * When moving the arm back and forth with the object attached, the velocity of the object is always negative and the velocity of the gripper is always positive, no matter which direction the robot moves. Like the absolute value was taken (negated on the object's velocity, though) \n\n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@sven-\nhoek](https://avatars.githubusercontent.com/u/15048669?s=80&u=1184c86424c64f25eb98710ad8c40e72cc3fb679&v=4)\n](/sven-hoek)\n\nCopy link\n\nAuthor\n\n###\n\n**[ sven-hoek ](/sven-hoek) ** commented  Feb 21, 2019\n\nSo for another simple test I printed out the velocities retrieved by `\nWorldLinearVel() ` of each link of the robot when ` GazeboGraspFix::OnUpdate()\n` ist called and even when the robot is moving with considerable speed, they\nstay close to zero or at least not larger than when standing still. Maybe the\n` world ` variable which is set by ` model->GetWorld() ` inside `\nGazeboGraspFix::Load() ` is somehow not able to access the velocities?  \nDo you maybe have a hint where to look in the Gazebo code, or another\npossibility to get the link velocities?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ JenniferBuehler ](/JenniferBuehler) added a commit that referenced this\nissue  Feb 25, 2019\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=40&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\n` [ Style formatting, and some test prints for issue\n](/JenniferBuehler/gazebo-pkgs/commit/a5500d64cbc047a9cd13438798023cc704f30a16\n\"Style formatting, and some test prints for issue #26\") [ #26\n](https://github.com/JenniferBuehler/gazebo-pkgs/issues/26) `\n\n` [ a5500d6 ](/JenniferBuehler/gazebo-\npkgs/commit/a5500d64cbc047a9cd13438798023cc704f30a16) `\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Feb 25, 2019  \u2022\n\nedited\n\nHi, so finally I got a spare hour to check this ;)\n\nI've just used my Jaco test setup to test this, and I printed the velocities.\nFor me they actually make sense - only while the object is not moving, there\nis still a very small (insignificant) velocity. However I've so far only\ntested it on my current work computer with Indigo with the default install of\nGazebo 2, which is ancient. I will test it with a newer Gazebo version and\nreport back.\n\nMeanwhile, can you check if the velocities still remain insignificant for you,\nif possible with the Jaco arm. I've updated the code and you can use the same\ntest prints in [ this line ](https://github.com/JenniferBuehler/gazebo-\npkgs/blob/a5500d64cbc047a9cd13438798023cc704f30a16/gazebo_grasp_plugin/src/GazeboGraspFix.cpp#L489)\nand [ here ](https://github.com/JenniferBuehler/gazebo-\npkgs/blob/a5500d64cbc047a9cd13438798023cc704f30a16/gazebo_grasp_plugin/src/GazeboGraspGripper.cpp#L242)\nby just setting it to ` #if 1 ` (my probably not so common way to make it\neasier to comment/uncomment blocks with only one type ;D). I will remove those\ntest prints once we've fixed this issue here.\n\nIf you have also installed+compiled my grasp-execution-pkgs, then you can test\neasily on the Jaco like this:\n\n` roslaunch grasp_execution_jaco_tutorial\njaco_on_table_gazebo_objects_controlled.launch load_grasp_fix:=true `\n\nand in another terminal, put all other commands to one line to save you some\nheadaches ;) (you may need to adjust the sleep values if this doesn't go\nsmooth for you):\n\n` roslaunch grasp_execution_jaco_tutorial spawn_and_reach_test_cube.launch &&\nsleep 1.5 && rosrun grasp_execution_jaco_tutorial grasp_cube_test && sleep 1\n&& rosrun grasp_execution_jaco_tutorial set_arm_to_cube_test --home --no-\nfingers `\n\nYou can release the cube with this:\n\n` rosrun grasp_execution_jaco_tutorial grasp_cube_test --ungrasp `\n\nalthough if the arm is still moving, it will stop to release the cube first,\nso you can't really throw it around with this test setup. However the\nvelocities reported are exactly the same as before the detachment (even if\nsmall), so I think I wouldn't have the issue if the arm was moving.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Feb 26, 2019\n\nI just remembered my update will conflict with your settings because you're\nusing the PR for melodic. I'm just processing that PR to finalise it actually,\nthen you'll be able to use the new code on master directly.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Mar 1, 2019\n\nI have updated all my packages to support Melodic. You can now try again using\nall my master branches.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Mar 1, 2019  \u2022\n\nedited\n\nI've just tested this again. The velocity values while the object is moving\nactually make sense (using the test setup with the Jaco mentioned above):\n\n    \n    \n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.000127 0.000334 0.000235, absolute val 0.000427883\n    [Msg] Velocity for link link (collision name cube1::link::collision): 8.7e-05 0.000283 0.000201, absolute val 0.000358163\n    [Msg] Velocity for link link (collision name cube1::link::collision): 8e-05 -0.000419 -0.000735, absolute val 0.000849296\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.000143 -0.000386 -0.000534, absolute val 0.000674358\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.257508 0.367559 0.279731, absolute val 0.528828\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.289677 0.319544 0.284859, absolute val 0.51688\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.314252 0.273718 0.287556, absolute val 0.506325\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.329963 0.231457 0.289894, absolute val 0.496474\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.323467 0.037872 0.289916, absolute val 0.436023\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.313703 -0.123585 0.290164, absolute val 0.444835\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.315365 -0.171255 0.29009, absolute val 0.46145\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.319376 -0.182716 0.288207, absolute val 0.467386\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.324368 -0.188044 0.286177, absolute val 0.47167\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.329308 -0.189511 0.282151, absolute val 0.473252\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.327746 -0.18948 0.274998, absolute val 0.467915\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.329393 -0.188287 0.267562, absolute val 0.464264\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.331628 -0.186817 0.260241, absolute val 0.461089\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.242179 -0.202395 0.220052, absolute val 0.384756\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.214991 -0.204539 0.201868, absolute val 0.358899\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.208103 -0.201454 0.190138, absolute val 0.346472\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.206403 -0.196861 0.180527, absolute val 0.33756\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.20569 -0.191597 0.17143, absolute val 0.329251\n    \n\nAnd just when detaching, it seems to go down a little bit when the object\nisn't touching the gripper any more, but still BEFORE it is detached (as said,\nunfortunately detaching while the arm is moving doesn't work with my simple\ntest setup, so the velocity is already low before detaching).  \nHowever, what's most important, is that pre/post detachment doesn't affect the\nvelocity. It's exactly the same value, so I'm guessing that would be the same\nif the velocity was higher...\n\n    \n    \n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.000155 -2.5e-05 -0.00053, absolute val 0.000552371\n    [Msg] Velocity for link link (collision name cube1::link::collision): -0.000159 -5.9e-05 0.000483, absolute val 0.000511539\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.000165 -4.4e-05 -0.000527, absolute val 0.000553946\n    [Msg] Velocity for link link (collision name cube1::link::collision): -0.000162 5e-05 0.000531, absolute val 0.000557578\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.000849 0.000197 -0.003541, absolute val 0.00364716\n    [Msg] GazeboGraspFix: Detaching cube1::link::collision from gripper JacoArm1.\n    [Msg] PRE-DETACH Velocity for link link (collision name cube1::link::collision): 1.7e-05 -6e-06 8e-06, absolute val 1.92592e-05\n    [Msg] POST-DETACH Velocity for link link (collision name cube1::link::collision): 1.7e-05 -6e-06 8e-06, absolute val 1.92592e-05\n    \n\nand right afterwards it starts to fall down:\n\n    \n    \n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.01772 -0.008722 -0.113658, absolute val 0.115361\n    [Msg] Velocity for link link (collision name cube1::link::collision): -0.033747 -0.115394 -0.134026, absolute val 0.180049\n    [Msg] Velocity for link link (collision name cube1::link::collision): -0.03044 -0.101856 -1.0324, absolute val 1.03786\n    \n\nCan you confirm this is similar on your setup, using the new versions of all\nmy packages? (all on master branches)  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@sven-\nhoek](https://avatars.githubusercontent.com/u/15048669?s=80&u=1184c86424c64f25eb98710ad8c40e72cc3fb679&v=4)\n](/sven-hoek)\n\nCopy link\n\nAuthor\n\n###\n\n**[ sven-hoek ](/sven-hoek) ** commented  Mar 3, 2019\n\nOk, I created a new workspace with your jaco packages and got similar,\nreasonable results:\n\n    \n    \n    [Msg] Velocity for link link (collision name cube1::link::collision): -4e-06 -1e-06 -0, absolute val 3.93345e-06\n    [Msg] Velocity for link link (collision name cube1::link::collision): 1.1e-05 -5e-06 0.000106, absolute val 0.00010672\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.264903 0.357312 0.281031, absolute val 0.52614\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.33405 0.20541 0.289578, absolute val 0.487481\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.322413 -0.186705 0.287224, absolute val 0.470432\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.32949 -0.188507 0.267178, absolute val 0.464201\n    [Msg] Velocity for link link (collision name cube1::link::collision): 0.209733 -0.202451 0.193545, absolute val 0.349906\n    \n\nAfter that I replaced the new version of the grasp plugin in my other\nworkspace. While compiling I got the following warning, which I got rid of by\npointing cmake to the right places. They also occured when using the Jaco\npackages but there I got no error while starting Gazebo/loading the plugin\n(see below). Just mentioning it in case it might have to do with the issue.\n\n    \n    \n    CMake Warning at /opt/ros/kinetic/share/catkin/cmake/catkin_package.cmake:166 (message):\n      catkin_package() DEPENDS on 'gazebo' but neither 'gazebo_INCLUDE_DIRS' nor\n      'gazebo_LIBRARIES' is defined.\n    Call Stack (most recent call first):\n      /opt/ros/kinetic/share/catkin/cmake/catkin_package.cmake:102 (_catkin_package)\n      CMakeLists.txt:26 (catkin_package)\n    \n\nSo it compiles, but when I try to start Gazebo with our Franka robot in that\nworkspace, gazebo crashes and I get the following info:\n\n    \n    \n    gzserver: symbol lookup error: /home/franka2/marcus_ws/devel/lib/libgazebo_grasp_fix.so: undefined symbol: _ZN6gazebo10GetPhysicsERKN5boost10shared_ptrINS_7physics5WorldEEE\n    \n\nWhich seems to coincide with line 259 in ` GazeboGraspFix.cpp ` :\n\n    \n    \n    physics::PhysicsEnginePtr physics = GetPhysics(this->world);\n    \n\nThe error occurs with or without setting the cmake variables before\n(re)compilation. Also after cleaning the workspace or adding our packages to\nthe new jaco workspace, it still remained. But weirdly, it doesn't occur when\nstarting gazebo with the jaco packages.  \nAny idea why this symbol lookup error could occur despite using the same\nGazebo and plugin version?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Mar 4, 2019\n\nHi,  \nYes I should get rid of the warnings at some point, however they relate to the\ncatkin_package() command and that shouldn't be related to the issue you're\nhaving.  \nIt looks like the grasp fix plugin may have been compiled with the wrong\nversion, though it's strange it happens only with that line then.  \nHave you tried to completely re-compile all packages including your Franka\npackage, by removing the ` build ` and ` devel ` directories in your catkin\nworkspace and compile again?  \nLet me know if the issue still comes up then.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@sven-\nhoek](https://avatars.githubusercontent.com/u/15048669?s=80&u=1184c86424c64f25eb98710ad8c40e72cc3fb679&v=4)\n](/sven-hoek)\n\nCopy link\n\nAuthor\n\n###\n\n**[ sven-hoek ](/sven-hoek) ** commented  Mar 4, 2019\n\nYes, I did. Unfortunately it persists, I even tried it on another machine (I\nwas using the older version of the plugin there before, too, though). What's\nreally weird is that the error doesn't occur with the Jaco, even in the same\nworkspace. After all, it should do the same call...  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Mar 4, 2019\n\nHm that's weird. Your Franka repositories aren't public by any chance, so I\ncould try to reproduce it?\n\nSo it doesn't happen if you comment out ` GetPhysics(this->world) ` (so just\nleave it to be a nullptr even if at runtime that would segfault), it then\ncompiles? No issues with the other new helper functions in\ngazebo_version_helpers?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@sven-\nhoek](https://avatars.githubusercontent.com/u/15048669?s=80&u=1184c86424c64f25eb98710ad8c40e72cc3fb679&v=4)\n](/sven-hoek)\n\nCopy link\n\nAuthor\n\n###\n\n**[ sven-hoek ](/sven-hoek) ** commented  Mar 4, 2019  \u2022\n\nedited\n\nYeah, they are: [ https://github.com/sven-hoek/franka_ros\n](https://github.com/sven-hoek/franka_ros)  \nJust run ` roslaunch franka_gazebo franka_gazebo ` . The plugin is included on\nthe bottom of ` franka_description/robots/hand.xacro ` .\n\nI compiled it again, leaving ` physics ` a nullptr. Somehow exactly the same\nerror occurs as before when I launch Gazebo. I double checked whether I am\nediting/compiling the right file.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Mar 4, 2019\n\nThat's then because it is having trouble with the gazebo::physics::Physics\ntype itself. I'm just cloning the repo and will try as well.  \nAh you're talking about the official Franka repo, cool! I love the Franka :)  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Mar 4, 2019\n\nAh silly me, I am currently finishing other work on Trusty. Here I've had\ntrouble building libfranka so I didn't build all the franka_ros packages.\nfranka_gazebo was OK but I can't run the launch file because of the\ndependencies I removed. Anyway the whole issue probably doesn't come up on\nTrusty anyway, so I'd rather test on Bionic once I reboot into it again.  \nUnfortunately I'll have to wait until I finish the work on my Trusty boot\nbefore I reboot.\n\nMeanwhile, general thoughts. If you still keep having the error\n\n` gzserver: symbol lookup error:\n/home/franka2/marcus_ws/devel/lib/libgazebo_grasp_fix.so: undefined symbol:\n_ZN6gazebo10GetPhysicsERKN5boost10shared_ptrINS_7physics5WorldEEE `\n\nafter you remove _all_ the calls to GetPhysics() then something is truly\nweird. Maybe take out the call in GazeboGraspGripper too, to make sure that `\nGetPhysics ` is never called. To be 100%, just comment the whole ` GetPhysics\n` functions from .cpp/.h files in gazebo_version_helpers. If you still get the\nsame error, then it's definitely something with your build.\n\ngzserver throws the lookup error at runtime, when it loads the grasp fix\nplugin. That could mean that either libgazebo_grasp_fix.so isn't linked up\nproperly with libgazebo_version_helpers.so (but I dont' think so otherwise\nyou'd have the problem with the Jaco too), or libgazebo_version_helpers.so are\nnot in the LD_LIBRARY_PATH, or something like that (and also then, it's weird\nthat you don't get that with Jaco).\n\nIf you do ` sudo updatedb && locate libgazebo_grasp_fix.so ` , does it come up\nwith only one library of libgazebo_grasp_fix.so?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Mar 4, 2019\n\nAlso, what's the output of\n\n` nm ` locate libgazebo_version_helpers.so` | grep GetPhysics `  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Mar 4, 2019\n\nHmmmmm I think I may just have found something which I noticed with\n\n` ldd ` locate libgazebo_grasp_fix.so` | grep gazebo `\n\nwhich doesn't include gazebo_version_helpers ! Though that still wouldn't\nexplain why it works with the Jaco, how puzzling...\n\nIt was a minor change in the gazebo_grasp_plugin CMakeLists.txt which changed\nthis.\n\nCan you please pull gazebo-pkgs again and try again?  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@sven-\nhoek](https://avatars.githubusercontent.com/u/15048669?s=80&u=1184c86424c64f25eb98710ad8c40e72cc3fb679&v=4)\n](/sven-hoek)\n\nCopy link\n\nAuthor\n\n###\n\n**[ sven-hoek ](/sven-hoek) ** commented  Mar 5, 2019\n\nOk, now it runs again, thanks. With your diagnostic print I realized 2 unusual\nthings:\n\n  1. The velocity drops to a very small value right before detaching: \n\n    \n    \n    [Msg] Velocity for link box_link1 (collision name box::box_link1::collision): -0.18197 0.135352 0.000549, absolute val 0.226789\n    [Msg] Velocity for link box_link1 (collision name box::box_link1::collision): -0.187825 0.039643 0.000692, absolute val 0.191964\n    [Msg] Velocity for link box_link1 (collision name box::box_link1::collision): 0.001451 0.002234 0.000948, absolute val 0.00282756\n    [Msg] GazeboGraspFix: Detaching box::box_link1::collision from gripper gripper.\n    \n\n  2. Don't know if directly related to the issue, but currently I just pick a box up from the ground and let it go while moving to a more upright position. The absolute linvel as from your output is close to 0 when in the lower (pick up) position, goes up to ~0.3-0.35, but stays at ~0.25 when in the upright position. I realized that there is some jittering visible when zooming in.   \nUnfortunately, Franka Emika didn't provide a proper model for simulation,\ntherefore I tried to setup one myself (wanted to provide it for the Franka\nCommunity, too, but haven't posted it in the forum yet). So the inertia values\nare rather guesstimated and I wonder now, if the links of the collision model\nmight be too close together to end up in a jittering control behaviour. I'm\nstill getting to know ROS/Gazebo, so I don't know if this might be part of\nthis problem.\n\n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Mar 5, 2019\n\nYes I've noticed the same steep drop in velocity just before detaching (as\nposted above) with the Jaco, not sure why this happens. It's still when the\nobject is attached, but the gripper would have opened and would not be\ntouching the cube any more.\n\nIt may be a while before I get around to reboot into Bionic and test again, so\nhopefully I can help you with some suggestions and guess work in the meantime\n;)\n\nFirst I would try to reduce the release tolerance (parameter `\nrelease_tolerance ` in xacro) and see if this still happens then. Can you try\nthat?\n\nAlso, can you set [ this ](https://github.com/JenniferBuehler/gazebo-\npkgs/blob/e54939f6a80982dc1b89c3c2fb288e989f758b20/gazebo_grasp_plugin/src/GazeboGraspGripper.cpp#L236)\nand [ this ](https://github.com/JenniferBuehler/gazebo-\npkgs/blob/e54939f6a80982dc1b89c3c2fb288e989f758b20/gazebo_grasp_plugin/src/GazeboGraspGripper.cpp#L250)\nfrom 0 to 1 and post the output of that as well? Thanks :)  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@sven-\nhoek](https://avatars.githubusercontent.com/u/15048669?s=80&u=1184c86424c64f25eb98710ad8c40e72cc3fb679&v=4)\n](/sven-hoek)\n\nCopy link\n\nAuthor\n\n###\n\n**[ sven-hoek ](/sven-hoek) ** commented  Mar 5, 2019\n\nIt persists when I reduce the release tolerance:(\n\n    \n    \n    [Msg] Velocity for link box_link1 (collision name box::box_link1::collision): -0.138627 -0.174153 0.001265, absolute val 0.222594\n    [Msg] Velocity for link box_link1 (collision name box::box_link1::collision): -0.138036 -0.172628 0.001995, absolute val 0.221039\n    [Msg] Velocity for link box_link1 (collision name box::box_link1::collision): -0.040687 -0.013907 -0.000555, absolute val 0.0430015\n    [Msg] GazeboGraspFix: Detaching box::box_link1::collision from gripper gripper.\n    [Msg] PRE-DETACH Velocity for link box_link1 (collision name box::box_link1::collision): -0.040687 -0.013907 -0.000555, absolute val 0.0430015\n    [Msg] POST-DETACH Velocity for link box_link1 (collision name box::box_link1::collision): -0.040687 -0.013907 -0.000555, absolute val 0.0430015\n      \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=40&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler) [ JenniferBuehler ](/JenniferBuehler) mentioned this issue\nMar 5, 2019\n\n[ gzserver: symbol lookup error  #28  ](/JenniferBuehler/gazebo-\npkgs/issues/28)\n\nClosed\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Mar 5, 2019\n\nHmmmm ok that's something that needs closer looking into, seems very strange.\nIf you increase the release tolerance (even if it's so high it will never be\nreleased) and fully open the hand, does this steep drop still happen at some\npoint?\n\nI'll have to look into this more, unfortunately I will probably not have time\nfor that this week. Meanwhile, I hope you can work with it despite the\nvelocity reduction? Or maybe you end up finding the reason for that weird\nbehaviour, that would be great too :)  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[ ![@sven-\nhoek](https://avatars.githubusercontent.com/u/15048669?s=80&u=1184c86424c64f25eb98710ad8c40e72cc3fb679&v=4)\n](/sven-hoek)\n\nCopy link\n\nAuthor\n\n###\n\n**[ sven-hoek ](/sven-hoek) ** commented  Mar 6, 2019  \u2022\n\nedited\n\nThe drop seems to be smaller but it seems to persist:\n\n    \n    \n    [Msg] Velocity for link box_link1 (collision name box::box_link1::collision): -0.179151 0.134644 -0.006592, absolute val 0.224204\n    [Msg] Velocity for link box_link1 (collision name box::box_link1::collision): -0.058385 0.00709 -0.024909, absolute val 0.0638714\n    \n\nIt happens right when opening the gripper (the messages stop afterwards but\nthe object is not being detached).\n\nLike I said, I'm also mostly working on a different project but trying to make\na little progress on this issue from time to time. I'm trying to get this\nrunning for other users who want to do throwing experiments using\nreinforcement learning.  \nI checked, if the jittering was caused by the constant collisions of the\nadjacent links by disabling the collision model for the robot links except the\ngripper, but it didn't seem to change much. If I have the time, I will check\nit more deeply and think of other problems that might cause issues.  \n  \n---  \n  \nAll reactions\n\nSorry, something went wrong.\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=80&u=c4f3910a93a4f048638fcf101ad78f41d509d516&v=4)\n](/JenniferBuehler)\n\nCopy link\n\nOwner\n\n###\n\n**[ JenniferBuehler ](/JenniferBuehler) ** commented  Mar 8, 2019\n\nThanks for testing this!  \nIt makes sense when this happens as the gripper open, as the conditions\nchange. Though I would have thought the properties are not affected with self-\ncollisions, and technically the object becomes part of the robot, but maybe\nit's not considered the same for self-collisions.  \nThis will require some more detailed looking into. It looks like in 1-2 weeks\nI'll have some time freed up, so then I can look into this more.  \n  \n---  \n  \n\ud83d\udc4d  1  sven-hoek reacted with thumbs up emoji\n\nAll reactions\n\n  * \ud83d\udc4d  1 reaction \n\nSorry, something went wrong.\n\n[ Sign up for free ](/join?source=comment-repo) **to join this conversation on\nGitHub** . Already have an account? [ Sign in to comment\n](/login?return_to=https%3A%2F%2Fgithub.com%2FJenniferBuehler%2Fgazebo-\npkgs%2Fissues%2F26)\n\nAssignees\n\nNo one assigned\n\nLabels\n\nNone yet\n\nProjects\n\nNone yet\n\nMilestone\n\nNo milestone\n\nDevelopment\n\nNo branches or pull requests\n\n2 participants\n\n[\n![@JenniferBuehler](https://avatars.githubusercontent.com/u/12842634?s=52&v=4)\n](/JenniferBuehler) [ ![@sven-\nhoek](https://avatars.githubusercontent.com/u/15048669?s=52&v=4) ](/sven-hoek)\n\n##  Footer\n\n[ ](https://github.com \"GitHub\") \u00a9 2024 GitHub, Inc.\n\n###  Footer navigation\n\n  * [ Terms ](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [ Privacy ](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [ Security ](/security)\n  * [ Status ](https://www.githubstatus.com/)\n  * [ Docs ](https://docs.github.com/)\n  * [ Contact ](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.\n\n"
  },
  {
    "id": "camera_plugin/gazebodvsplugin.txt",
    "content": "Skip to content\n\nToggle navigation\n\n[ ](https://github.com/)\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2FHBPNeurorobotics%2Fgazebo_dvs_plugin)\n\n  * Product \n\n    * [ Actions  Automate any workflow  ](/features/actions)\n    * [ Packages  Host and manage packages  ](/features/packages)\n    * [ Security  Find and fix vulnerabilities  ](/features/security)\n    * [ Codespaces  Instant dev environments  ](/features/codespaces)\n    * [ Copilot  Write better code with AI  ](/features/copilot)\n    * [ Code review  Manage code changes  ](/features/code-review)\n    * [ Issues  Plan and track work  ](/features/issues)\n    * [ Discussions  Collaborate outside of code  ](/features/discussions)\n\nExplore\n\n    * [ All features ](/features)\n    * [ Documentation  ](https://docs.github.com)\n    * [ GitHub Skills  ](https://skills.github.com/)\n    * [ Blog  ](https://github.blog)\n\n  * Solutions \n\nFor\n\n    * [ Enterprise ](/enterprise)\n    * [ Teams ](/team)\n    * [ Startups ](/enterprise/startups)\n    * [ Education  ](https://education.github.com)\n\nBy Solution\n\n    * [ CI/CD & Automation ](/solutions/ci-cd/)\n    * [ DevOps ](/solutions/devops/)\n    * [ DevSecOps  ](https://resources.github.com/devops/fundamentals/devsecops/)\n\nResources\n\n    * [ Learning Pathways  ](https://resources.github.com/learn/pathways/)\n    * [ White papers, Ebooks, Webinars  ](https://resources.github.com/)\n    * [ Customer Stories ](/customer-stories)\n    * [ Partners  ](https://partner.github.com/)\n\n  * Open Source \n\n    * [ GitHub Sponsors  Fund open source developers  ](/sponsors)\n\n    * [ The ReadME Project  GitHub community articles  ](/readme)\n\nRepositories\n\n    * [ Topics ](/topics)\n    * [ Trending ](/trending)\n    * [ Collections ](/collections)\n\n  * [ Pricing ](/pricing)\n\nSearch or jump to...\n\n#  Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[ Search syntax tips ](https://docs.github.com/search-github/github-code-\nsearch/understanding-github-code-search-syntax)\n\n#  Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\nInclude my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n##  Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our [ documentation\n](https://docs.github.com/search-github/github-code-search/understanding-\ngithub-code-search-syntax) .\n\nCancel  Create saved search\n\n[ Sign in\n](/login?return_to=https%3A%2F%2Fgithub.com%2FHBPNeurorobotics%2Fgazebo_dvs_plugin)\n\n[ Sign up\n](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-\nname%3E%2F%3Crepo-name%3E&source=header-\nrepo&source_repo=HBPNeurorobotics%2Fgazebo_dvs_plugin)\n\nYou signed in with another tab or window. [ Reload ]() to refresh your\nsession.  You signed out in another tab or window. [ Reload ]() to refresh\nyour session.  You switched accounts on another tab or window. [ Reload ]() to\nrefresh your session.  Dismiss alert\n\n{{ message }}\n\n[ HBPNeurorobotics ](/HBPNeurorobotics) /  **[ gazebo_dvs_plugin\n](/HBPNeurorobotics/gazebo_dvs_plugin) ** Public\n\n  * [ Notifications ](/login?return_to=%2FHBPNeurorobotics%2Fgazebo_dvs_plugin)\n  * [ Fork  16  ](/login?return_to=%2FHBPNeurorobotics%2Fgazebo_dvs_plugin)\n  * [ Star  29  ](/login?return_to=%2FHBPNeurorobotics%2Fgazebo_dvs_plugin)\n\n  * \n\nThis package provides a DVS simulation implemented as Gazebo plugin.\n\n###  License\n\n[ GPL-2.0 license ](/HBPNeurorobotics/gazebo_dvs_plugin/blob/master/LICENSE)\n\n[ 29  stars ](/HBPNeurorobotics/gazebo_dvs_plugin/stargazers) [ 16  forks\n](/HBPNeurorobotics/gazebo_dvs_plugin/forks) [ Branches\n](/HBPNeurorobotics/gazebo_dvs_plugin/branches) [ Tags\n](/HBPNeurorobotics/gazebo_dvs_plugin/tags) [ Activity\n](/HBPNeurorobotics/gazebo_dvs_plugin/activity)\n\n[ Star  ](/login?return_to=%2FHBPNeurorobotics%2Fgazebo_dvs_plugin)\n\n[ Notifications ](/login?return_to=%2FHBPNeurorobotics%2Fgazebo_dvs_plugin)\n\n  * [ Code  ](/HBPNeurorobotics/gazebo_dvs_plugin)\n  * [ Issues  1  ](/HBPNeurorobotics/gazebo_dvs_plugin/issues)\n  * [ Pull requests  1  ](/HBPNeurorobotics/gazebo_dvs_plugin/pulls)\n  * [ Actions  ](/HBPNeurorobotics/gazebo_dvs_plugin/actions)\n  * [ Projects  0  ](/HBPNeurorobotics/gazebo_dvs_plugin/projects)\n  * [ Security  ](/HBPNeurorobotics/gazebo_dvs_plugin/security)\n  * [ Insights  ](/HBPNeurorobotics/gazebo_dvs_plugin/pulse)\n\nAdditional navigation options\n\n  * [ Code  ](/HBPNeurorobotics/gazebo_dvs_plugin)\n  * [ Issues  ](/HBPNeurorobotics/gazebo_dvs_plugin/issues)\n  * [ Pull requests  ](/HBPNeurorobotics/gazebo_dvs_plugin/pulls)\n  * [ Actions  ](/HBPNeurorobotics/gazebo_dvs_plugin/actions)\n  * [ Projects  ](/HBPNeurorobotics/gazebo_dvs_plugin/projects)\n  * [ Security  ](/HBPNeurorobotics/gazebo_dvs_plugin/security)\n  * [ Insights  ](/HBPNeurorobotics/gazebo_dvs_plugin/pulse)\n\n#  HBPNeurorobotics/gazebo_dvs_plugin\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\nmaster\n\n[ Branches  ](/HBPNeurorobotics/gazebo_dvs_plugin/branches) [ Tags\n](/HBPNeurorobotics/gazebo_dvs_plugin/tags)\n\n[ ](/HBPNeurorobotics/gazebo_dvs_plugin/branches) [\n](/HBPNeurorobotics/gazebo_dvs_plugin/tags)\n\nGo to file\n\nCode\n\n##  Folders and files\n\nName  |  Name  |\n\nLast commit message\n\n|\n\nLast commit date  \n  \n---|---|---|---  \n  \n##  Latest commit\n\n##  History\n\n[ 15 Commits  ](/HBPNeurorobotics/gazebo_dvs_plugin/commits/master/)\n\n[ ](/HBPNeurorobotics/gazebo_dvs_plugin/commits/master/)  \n  \n###\n\n[ include/  gazebo_dvs_plugin\n](/HBPNeurorobotics/gazebo_dvs_plugin/tree/master/include/gazebo_dvs_plugin\n\"This path skips through empty directories\")\n\n|\n\n###\n\n[ include/  gazebo_dvs_plugin\n](/HBPNeurorobotics/gazebo_dvs_plugin/tree/master/include/gazebo_dvs_plugin\n\"This path skips through empty directories\")\n\n|\n\n|  \n  \n###\n\n[ src ](/HBPNeurorobotics/gazebo_dvs_plugin/tree/master/src \"src\")\n\n|\n\n###\n\n[ src ](/HBPNeurorobotics/gazebo_dvs_plugin/tree/master/src \"src\")\n\n|\n\n|  \n  \n###\n\n[ CMakeLists.txt\n](/HBPNeurorobotics/gazebo_dvs_plugin/blob/master/CMakeLists.txt\n\"CMakeLists.txt\")\n\n|\n\n###\n\n[ CMakeLists.txt\n](/HBPNeurorobotics/gazebo_dvs_plugin/blob/master/CMakeLists.txt\n\"CMakeLists.txt\")\n\n|\n\n|  \n  \n###\n\n[ LICENSE ](/HBPNeurorobotics/gazebo_dvs_plugin/blob/master/LICENSE \"LICENSE\")\n\n|\n\n###\n\n[ LICENSE ](/HBPNeurorobotics/gazebo_dvs_plugin/blob/master/LICENSE \"LICENSE\")\n\n|\n\n|  \n  \n###\n\n[ README.md ](/HBPNeurorobotics/gazebo_dvs_plugin/blob/master/README.md\n\"README.md\")\n\n|\n\n###\n\n[ README.md ](/HBPNeurorobotics/gazebo_dvs_plugin/blob/master/README.md\n\"README.md\")\n\n|\n\n|  \n  \n###\n\n[ package.xml ](/HBPNeurorobotics/gazebo_dvs_plugin/blob/master/package.xml\n\"package.xml\")\n\n|\n\n###\n\n[ package.xml ](/HBPNeurorobotics/gazebo_dvs_plugin/blob/master/package.xml\n\"package.xml\")\n\n|\n\n|  \n  \nView all files  \n  \n##  Repository files navigation\n\n  * README \n  * GPL-2.0 license \n\n#  DVS Gazebo Plugin\n\nThis package provides a DVS simulation implemented as Gazebo plugin.\n\n##  Install\n\nFirst, make sure the DVS datatypes are available in your installation. For\nthis, clone the [ RPG DVS ROS ](https://github.com/uzh-rpg/rpg_dvs_ros)\npackage into your catkin workspace.\n\nThen, clone this package into your workspace and rebuild.\n\n##  Usage\n\nThis plugin can be used as a drop-in replacement for normal Gazebo camera\nplugins. Both, the DVS plugin and the [ CameraPlugin\n](https://bitbucket.org/osrf/gazebo/src/666bf30ad9a3c042955b55f79cf1a5416a70d83d/plugins/CameraPlugin.cc)\nuse the Gazebo [ CameraSensor\n](https://bitbucket.org/osrf/gazebo/src/666bf30ad9a3c042955b55f79cf1a5416a70d83d/gazebo/sensors/CameraSensor.cc)\ninternally.\n\nThe following SDF snippet shows an example usage:\n\n    \n    \n    <sensor name='camera' type='camera'>\n        <camera name='__default__'>\n            <horizontal_fov>1.8</horizontal_fov>\n            <image>\n                <width>128</width>\n                <height>128</height>\n            </image>\n            <clip>\n                <near>0.1</near>\n                <far>100</far>\n            </clip>\n        </camera>\n        <always_on>1</always_on>\n        <update_rate>60</update_rate>\n        <visualize>0</visualize>\n        <plugin name='camera_controller' filename='libgazebo_dvs_plugin.so'>\n            <cameraName>camera_front</cameraName>\n            <robotNamespace>AADC_AudiTT</robotNamespace>\n            <eventThreshold>10</eventThreshold>\n            <cameraInfoTopicName>camera_info</cameraInfoTopicName>\n            <!-- <eventsTopicName>events</eventsTopicName> -->\n        </plugin>\n    </sensor>\n    \n\nThe parameters ` robotNamespace ` , ` cameraName ` and ` eventsTopicName `\n(default: \"events\") result in ` \"$robotNamespace/$cameraName/$eventsTopicName\"\n` as the identifier of the provided events topic. In this case, events will be\naccessible from ` \"/AADC_AudiTT/camera_front/events\" ` .\n\nThe parameter ` eventThreshold ` specifies the pixel-wise threshold which has\nto be exceeded for a event to be emitted for this pixel.\n\nThe sensor parameter ` update_rate ` has only limited effect in Gazebo. The\nreal rate is determined by the rendering pipeline and can be way lower than\nthe specified rate. Still, this implementation yields a higher event frequency\nthan similar Python-based implementations as a standalone node.\n\n#  Acknowledgement\n\nIf you used this code for your research, please consider citing the paper [\nTowards a framework for end-to-end control of a simulated vehicle with spiking\nneural networks ](http://ieeexplore.ieee.org/document/7862386/) .\n\n    \n    \n    @INPROCEEDINGS{7862386,\n    author={J. Kaiser and J. C. V. Tieck and C. Hubschneider and P. Wolf and M. Weber and M. Hoff and A. Friedrich and K. Wojtasik and A. Roennau and R. Kohlhaas and R. Dillmann and J. M. Z\u00f6llner},\n    booktitle={2016 IEEE International Conference on Simulation, Modeling, and Programming for Autonomous Robots (SIMPAR)},\n    title={Towards a framework for end-to-end control of a simulated vehicle with spiking neural networks},\n    year={2016},\n    pages={127-134},\n    keywords={automobiles;cameras;complex networks;feedforward neural nets;learning (artificial intelligence);mobile robots;DVS;camera images;complex networks;deep learning architectures;end-to-end simulated vehicle control;hand-crafted feature detectors;neural self-driving vehicle applications;neurorobotics applications;rate-based neural networks;silicon retina;spiking neural networks;steering wheel decoder;vehicle end-to-end for lane following behavior;Biological neural networks;Brain modeling;Cameras;Robot sensing systems;Voltage control},\n    doi={10.1109/SIMPAR.2016.7862386},\n    month={Dec},}\n    \n\n##  About\n\nThis package provides a DVS simulation implemented as Gazebo plugin.\n\n###  Resources\n\nReadme\n\n###  License\n\nGPL-2.0 license\n\n[ Activity  ](/HBPNeurorobotics/gazebo_dvs_plugin/activity)\n\n[ Custom properties  ](/HBPNeurorobotics/gazebo_dvs_plugin/custom-properties)\n\n###  Stars\n\n[ **29** stars ](/HBPNeurorobotics/gazebo_dvs_plugin/stargazers)\n\n###  Watchers\n\n[ **10** watching ](/HBPNeurorobotics/gazebo_dvs_plugin/watchers)\n\n###  Forks\n\n[ **16** forks ](/HBPNeurorobotics/gazebo_dvs_plugin/forks)\n\n[ Report repository ](/contact/report-\ncontent?content_url=https%3A%2F%2Fgithub.com%2FHBPNeurorobotics%2Fgazebo_dvs_plugin&report=HBPNeurorobotics+%28user%29)\n\n##  [ Releases ](/HBPNeurorobotics/gazebo_dvs_plugin/releases)\n\nNo releases published\n\n##  [ Packages  0\n](/orgs/HBPNeurorobotics/packages?repo_name=gazebo_dvs_plugin)\n\nNo packages published  \n\n##  [ Contributors  3\n](/HBPNeurorobotics/gazebo_dvs_plugin/graphs/contributors)\n\n  *   *   * \n\n##  Languages\n\n  * [ C++  89.8%  ](/HBPNeurorobotics/gazebo_dvs_plugin/search?l=c%2B%2B)\n  * [ CMake  10.2%  ](/HBPNeurorobotics/gazebo_dvs_plugin/search?l=cmake)\n\n##  Footer\n\n[ ](https://github.com \"GitHub\") \u00a9 2024 GitHub, Inc.\n\n###  Footer navigation\n\n  * [ Terms ](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [ Privacy ](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [ Security ](/security)\n  * [ Status ](https://www.githubstatus.com/)\n  * [ Docs ](https://docs.github.com/)\n  * [ Contact ](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.\n\n"
  },
  {
    "id": "hardware_control/25749.txt",
    "content": "[ The Construct ROS Community ](/)\n\n#  [ Cannot build the dynamixel hardware interface in ros2_control course\n](/t/cannot-build-the-dynamixel-hardware-interface-in-ros2-control-\ncourse/25749)\n\n[ Course Support  ](/c/course-support/ros2-control/69) [ ROS2 Control\nFramework  ](/c/course-support/ros2-control/69)\n\n[ error ](https://get-help.theconstruct.ai/tag/error) , [ ros2 ](https://get-\nhelp.theconstruct.ai/tag/ros2) , [ simulation ](https://get-\nhelp.theconstruct.ai/tag/simulation)\n\n[ pbnpama  ](https://get-help.theconstruct.ai/u/pbnpama) August 8, 2023,\n7:53pm  1\n\nI followed the ros2 control course and tried to use the dynamixel hardware\ninterface in my own labtop and this error was come. I\u2019m not familiar with C++\nso If someone know what should I fix, please tell me. Basically, I just copy\nand paste the code from the code to my pkg. I use ros2 foxy and DynamixelSDK\nand also workbench were also cloned from foxy-devel branch. In the terminal\ninside the Construct, nothing error.\n\n    \n    \n    In file included from /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:7:\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/include/dynamixel_hardware_interface/dynamixel_hardware_interface.hpp:44:3: error: \u2018CallbackReturn\u2019 does not name a type\n       44 |   CallbackReturn on_init(const hardware_interface::HardwareInfo & info) override;\n          |   ^~~~~~~~~~~~~~\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/include/dynamixel_hardware_interface/dynamixel_hardware_interface.hpp:50:3: error: \u2018CallbackReturn\u2019 does not name a type\n       50 |   CallbackReturn on_activate(const rclcpp_lifecycle::State & previous_state) override;\n          |   ^~~~~~~~~~~~~~\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/include/dynamixel_hardware_interface/dynamixel_hardware_interface.hpp:52:3: error: \u2018CallbackReturn\u2019 does not name a type\n       52 |   CallbackReturn on_deactivate(const rclcpp_lifecycle::State & previous_state) override;\n          |   ^~~~~~~~~~~~~~\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:27:1: error: \u2018CallbackReturn\u2019 does not name a type\n       27 | CallbackReturn DynamixelHardware::on_init(const hardware_interface::HardwareInfo & info)\n          | ^~~~~~~~~~~~~~\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp: In member function \u2018virtual std::vector<hardware_interface::StateInterface> dynamixel_hardware::DynamixelHardware::export_state_interfaces()\u2019:\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:157:24: error: \u2018info_\u2019 was not declared in this scope\n      157 |   for (uint i = 0; i < info_.joints.size(); i++) {\n          |                        ^~~~~\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp: In member function \u2018virtual std::vector<hardware_interface::CommandInterface> dynamixel_hardware::DynamixelHardware::export_command_interfaces()\u2019:\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:173:24: error: \u2018info_\u2019 was not declared in this scope\n      173 |   for (uint i = 0; i < info_.joints.size(); i++) {\n          |                        ^~~~~\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp: At global scope:\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:183:1: error: \u2018CallbackReturn\u2019 does not name a type\n      183 | CallbackReturn DynamixelHardware::on_activate(const rclcpp_lifecycle::State & previous_state)\n          | ^~~~~~~~~~~~~~\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:200:1: error: \u2018CallbackReturn\u2019 does not name a type\n      200 | CallbackReturn DynamixelHardware::on_deactivate(const rclcpp_lifecycle::State & previous_state)\n          | ^~~~~~~~~~~~~~\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp: In member function \u2018virtual hardware_interface::return_type dynamixel_hardware::DynamixelHardware::read()\u2019:\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:212:28: error: \u2018info_\u2019 was not declared in this scope\n      212 |   std::vector<uint8_t> ids(info_.joints.size(), 0);\n          |                            ^~~~~\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp: In member function \u2018virtual hardware_interface::return_type dynamixel_hardware::DynamixelHardware::write()\u2019:\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:265:28: error: \u2018info_\u2019 was not declared in this scope\n      265 |   std::vector<uint8_t> ids(info_.joints.size(), 0);\n          |                            ^~~~~\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp: In member function \u2018hardware_interface::return_type dynamixel_hardware::DynamixelHardware::enable_torque(bool)\u2019:\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:310:26: error: \u2018info_\u2019 was not declared in this scope\n      310 |     for (uint i = 0; i < info_.joints.size(); ++i) {\n          |                          ^~~~~\n    /home/tharit/ros2_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:319:26: error: \u2018info_\u2019 was not declared in this scope\n      319 |     for (uint i = 0; i < info_.joints.size(); ++i) {\n          |                          ^~~~~\n    make[2]: *** [CMakeFiles/dynamixel_hardware_interface.dir/build.make:63: CMakeFiles/dynamixel_hardware_interface.dir/src/dynamixel_hardware_interface.cpp.o] Error 1\n    make[1]: *** [CMakeFiles/Makefile2:78: CMakeFiles/dynamixel_hardware_interface.dir/all] Error 2\n    make: *** [Makefile:141: all] Error 2\n    ---\n    Failed   <<< dynamixel_hardware_interface [1.83s, exited with code 2]\n    \n    Summary: 12 packages finished [2.98s]\n      1 package failed: dynamixel_hardware_interface\n      1 package had stderr output: dynamixel_hardware_interface\n    \n    \n\nHere is the .cpp code\n\n    \n    \n    #include <algorithm>\n    #include <array>\n    #include <string>\n    #include <limits>\n    #include <vector>\n    \n    #include \"dynamixel_hardware_interface/dynamixel_hardware_interface.hpp\"\n    #include \"hardware_interface/types/hardware_interface_return_values.hpp\"\n    #include \"hardware_interface/types/hardware_interface_type_values.hpp\"\n    #include \"rclcpp/rclcpp.hpp\"\n    \n    namespace dynamixel_hardware\n    {\n    constexpr const char * kDynamixelHardware = \"DynamixelHardware\";\n    constexpr uint8_t kGoalPositionIndex = 0;\n    constexpr uint8_t kGoalVelocityIndex = 1;\n    constexpr uint8_t kPresentPositionVelocityCurrentIndex = 0;\n    constexpr const char * kGoalPositionItem = \"Goal_Position\";\n    constexpr const char * kGoalVelocityItem = \"Goal_Velocity\";\n    constexpr const char * kMovingSpeedItem = \"Moving_Speed\";\n    constexpr const char * kPresentPositionItem = \"Present_Position\";\n    constexpr const char * kPresentVelocityItem = \"Present_Velocity\";\n    constexpr const char * kPresentSpeedItem = \"Present_Speed\";\n    constexpr const char * kPresentCurrentItem = \"Present_Current\";\n    constexpr const char * kPresentLoadItem = \"Present_Load\";\n    \n    CallbackReturn DynamixelHardware::on_init(const hardware_interface::HardwareInfo & info)\n    {\n      RCLCPP_DEBUG(rclcpp::get_logger(kDynamixelHardware), \"configure\");\n      if (hardware_interface::SystemInterface::on_init(info) != CallbackReturn::SUCCESS)\n      {\n        return CallbackReturn::ERROR;\n      }\n    \n      joints_.resize(info_.joints.size(), Joint());\n      joint_ids_.resize(info_.joints.size(), 0);\n    \n      for (uint i = 0; i < info_.joints.size(); i++) {\n        joint_ids_[i] = std::stoi(info_.joints[i].parameters.at(\"id\"));\n        joints_[i].state.position = std::numeric_limits<double>::quiet_NaN();\n        joints_[i].state.velocity = std::numeric_limits<double>::quiet_NaN();\n        joints_[i].state.effort = std::numeric_limits<double>::quiet_NaN();\n        joints_[i].command.position = std::numeric_limits<double>::quiet_NaN();\n        joints_[i].command.velocity = std::numeric_limits<double>::quiet_NaN();\n        joints_[i].command.effort = std::numeric_limits<double>::quiet_NaN();\n        RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"joint_id %d: %d\", i, joint_ids_[i]);\n      }\n    \n      if (\n        info_.hardware_parameters.find(\"use_dummy\") != info_.hardware_parameters.end() &&\n        info_.hardware_parameters.at(\"use_dummy\") == \"true\") {\n        use_dummy_ = true;\n        RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"dummy mode\");\n        return CallbackReturn::SUCCESS;\n      }\n    \n      auto usb_port = info_.hardware_parameters.at(\"usb_port\");\n      auto baud_rate = std::stoi(info_.hardware_parameters.at(\"baud_rate\"));\n      const char * log = nullptr;\n    \n      RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"usb_port: %s\", usb_port.c_str());\n      RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"baud_rate: %d\", baud_rate);\n    \n      if (!dynamixel_workbench_.init(usb_port.c_str(), baud_rate, &log)) {\n        RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n        return CallbackReturn::ERROR;\n      }\n    \n      for (uint i = 0; i < info_.joints.size(); ++i) {\n        uint16_t model_number = 0;\n        if (!dynamixel_workbench_.ping(joint_ids_[i], &model_number, &log)) {\n          RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n          return CallbackReturn::ERROR;\n        }\n      }\n    \n      enable_torque(false);\n      set_control_mode(ControlMode::Position, true);\n      enable_torque(true);\n    \n      const ControlItem * goal_position =\n        dynamixel_workbench_.getItemInfo(joint_ids_[0], kGoalPositionItem);\n      if (goal_position == nullptr) {\n        return CallbackReturn::ERROR;\n      }\n    \n      const ControlItem * goal_velocity =\n        dynamixel_workbench_.getItemInfo(joint_ids_[0], kGoalVelocityItem);\n      if (goal_velocity == nullptr) {\n        goal_velocity = dynamixel_workbench_.getItemInfo(joint_ids_[0], kMovingSpeedItem);\n      }\n      if (goal_velocity == nullptr) {\n        return CallbackReturn::ERROR;\n      }\n    \n      const ControlItem * present_position =\n        dynamixel_workbench_.getItemInfo(joint_ids_[0], kPresentPositionItem);\n      if (present_position == nullptr) {\n        return CallbackReturn::ERROR;\n      }\n    \n      const ControlItem * present_velocity =\n        dynamixel_workbench_.getItemInfo(joint_ids_[0], kPresentVelocityItem);\n      if (present_velocity == nullptr) {\n        present_velocity = dynamixel_workbench_.getItemInfo(joint_ids_[0], kPresentSpeedItem);\n      }\n      if (present_velocity == nullptr) {\n        return CallbackReturn::ERROR;\n      }\n    \n      const ControlItem * present_current =\n        dynamixel_workbench_.getItemInfo(joint_ids_[0], kPresentCurrentItem);\n      if (present_current == nullptr) {\n        present_current = dynamixel_workbench_.getItemInfo(joint_ids_[0], kPresentLoadItem);\n      }\n      if (present_current == nullptr) {\n        return CallbackReturn::ERROR;\n      }\n    \n      control_items_[kGoalPositionItem] = goal_position;\n      control_items_[kGoalVelocityItem] = goal_velocity;\n      control_items_[kPresentPositionItem] = present_position;\n      control_items_[kPresentVelocityItem] = present_velocity;\n      control_items_[kPresentCurrentItem] = present_current;\n    \n      if (!dynamixel_workbench_.addSyncWriteHandler(\n            control_items_[kGoalPositionItem]->address, control_items_[kGoalPositionItem]->data_length,\n            &log)) {\n        RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n        return CallbackReturn::ERROR;\n      }\n    \n      if (!dynamixel_workbench_.addSyncWriteHandler(\n            control_items_[kGoalVelocityItem]->address, control_items_[kGoalVelocityItem]->data_length,\n            &log)) {\n        RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n        return CallbackReturn::ERROR;\n      }\n    \n      uint16_t start_address = std::min(\n        control_items_[kPresentPositionItem]->address, control_items_[kPresentCurrentItem]->address);\n      uint16_t read_length = control_items_[kPresentPositionItem]->data_length +\n                             control_items_[kPresentVelocityItem]->data_length +\n                             control_items_[kPresentCurrentItem]->data_length + 2;\n      if (!dynamixel_workbench_.addSyncReadHandler(start_address, read_length, &log)) {\n        RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n        return CallbackReturn::ERROR;\n      }\n    \n      return CallbackReturn::SUCCESS;\n    }\n    \n    std::vector<hardware_interface::StateInterface> DynamixelHardware::export_state_interfaces()\n    {\n      RCLCPP_DEBUG(rclcpp::get_logger(kDynamixelHardware), \"export_state_interfaces\");\n      std::vector<hardware_interface::StateInterface> state_interfaces;\n      for (uint i = 0; i < info_.joints.size(); i++) {\n        state_interfaces.emplace_back(hardware_interface::StateInterface(\n          info_.joints[i].name, hardware_interface::HW_IF_POSITION, &joints_[i].state.position));\n        state_interfaces.emplace_back(hardware_interface::StateInterface(\n          info_.joints[i].name, hardware_interface::HW_IF_VELOCITY, &joints_[i].state.velocity));\n        state_interfaces.emplace_back(hardware_interface::StateInterface(\n          info_.joints[i].name, hardware_interface::HW_IF_EFFORT, &joints_[i].state.effort));\n      }\n    \n      return state_interfaces;\n    }\n    \n    std::vector<hardware_interface::CommandInterface> DynamixelHardware::export_command_interfaces()\n    {\n      RCLCPP_DEBUG(rclcpp::get_logger(kDynamixelHardware), \"export_command_interfaces\");\n      std::vector<hardware_interface::CommandInterface> command_interfaces;\n      for (uint i = 0; i < info_.joints.size(); i++) {\n        command_interfaces.emplace_back(hardware_interface::CommandInterface(\n          info_.joints[i].name, hardware_interface::HW_IF_POSITION, &joints_[i].command.position));\n        command_interfaces.emplace_back(hardware_interface::CommandInterface(\n          info_.joints[i].name, hardware_interface::HW_IF_VELOCITY, &joints_[i].command.velocity));\n      }\n    \n      return command_interfaces;\n    }\n    \n    CallbackReturn DynamixelHardware::on_activate(const rclcpp_lifecycle::State & previous_state)\n    {\n      RCLCPP_DEBUG(rclcpp::get_logger(kDynamixelHardware), \"start\");\n      for (uint i = 0; i < joints_.size(); i++) {\n        if (use_dummy_ && std::isnan(joints_[i].state.position)) {\n          joints_[i].state.position = 0.0;\n          joints_[i].state.velocity = 0.0;\n          joints_[i].state.effort = 0.0;\n        }\n      }\n      read();\n      reset_command();\n      write();\n    \n      return CallbackReturn::SUCCESS;\n    }\n    \n    CallbackReturn DynamixelHardware::on_deactivate(const rclcpp_lifecycle::State & previous_state)\n    {\n      RCLCPP_DEBUG(rclcpp::get_logger(kDynamixelHardware), \"stop\");\n      return CallbackReturn::SUCCESS;\n    }\n    \n    return_type DynamixelHardware::read()\n    {\n      if (use_dummy_) {\n        return return_type::OK;\n      }\n    \n      std::vector<uint8_t> ids(info_.joints.size(), 0);\n      std::vector<int32_t> positions(info_.joints.size(), 0);\n      std::vector<int32_t> velocities(info_.joints.size(), 0);\n      std::vector<int32_t> currents(info_.joints.size(), 0);\n    \n      std::copy(joint_ids_.begin(), joint_ids_.end(), ids.begin());\n      const char * log = nullptr;\n    \n      if (!dynamixel_workbench_.syncRead(\n            kPresentPositionVelocityCurrentIndex, ids.data(), ids.size(), &log)) {\n        RCLCPP_ERROR(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n      }\n    \n      if (!dynamixel_workbench_.getSyncReadData(\n            kPresentPositionVelocityCurrentIndex, ids.data(), ids.size(),\n            control_items_[kPresentCurrentItem]->address,\n            control_items_[kPresentCurrentItem]->data_length, currents.data(), &log)) {\n        RCLCPP_ERROR(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n      }\n    \n      if (!dynamixel_workbench_.getSyncReadData(\n            kPresentPositionVelocityCurrentIndex, ids.data(), ids.size(),\n            control_items_[kPresentVelocityItem]->address,\n            control_items_[kPresentVelocityItem]->data_length, velocities.data(), &log)) {\n        RCLCPP_ERROR(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n      }\n    \n      if (!dynamixel_workbench_.getSyncReadData(\n            kPresentPositionVelocityCurrentIndex, ids.data(), ids.size(),\n            control_items_[kPresentPositionItem]->address,\n            control_items_[kPresentPositionItem]->data_length, positions.data(), &log)) {\n        RCLCPP_ERROR(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n      }\n    \n      for (uint i = 0; i < ids.size(); i++) {\n        joints_[i].state.position = dynamixel_workbench_.convertValue2Radian(ids[i], positions[i]);\n        joints_[i].state.velocity = dynamixel_workbench_.convertValue2Velocity(ids[i], velocities[i]);\n        joints_[i].state.effort = dynamixel_workbench_.convertValue2Current(currents[i]);\n      }\n    \n      return return_type::OK;\n    }\n    \n    return_type DynamixelHardware::write()\n    {\n      if (use_dummy_) {\n        for (auto & joint : joints_) {\n          joint.state.position = joint.command.position;\n        }\n    \n        return return_type::OK;\n      }\n    \n      std::vector<uint8_t> ids(info_.joints.size(), 0);\n      std::vector<int32_t> commands(info_.joints.size(), 0);\n    \n      std::copy(joint_ids_.begin(), joint_ids_.end(), ids.begin());\n      const char * log = nullptr;\n    \n      if (std::any_of(\n            joints_.cbegin(), joints_.cend(), [](auto j) { return j.command.velocity != 0.0; })) {\n        // Velocity control\n        set_control_mode(ControlMode::Velocity);\n        for (uint i = 0; i < ids.size(); i++) {\n          commands[i] = dynamixel_workbench_.convertVelocity2Value(\n            ids[i], static_cast<float>(joints_[i].command.velocity));\n        }\n        if (!dynamixel_workbench_.syncWrite(\n              kGoalVelocityIndex, ids.data(), ids.size(), commands.data(), 1, &log)) {\n          RCLCPP_ERROR(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n        }\n        return return_type::OK;\n      } else if (std::any_of(\n                   joints_.cbegin(), joints_.cend(), [](auto j) { return j.command.effort != 0.0; })) {\n        // Effort control\n        RCLCPP_ERROR(rclcpp::get_logger(kDynamixelHardware), \"Effort control is not implemented\");\n        return return_type::ERROR;\n      }\n    \n      // Position control\n      set_control_mode(ControlMode::Position);\n      for (uint i = 0; i < ids.size(); i++) {\n        commands[i] = dynamixel_workbench_.convertRadian2Value(\n          ids[i], static_cast<float>(joints_[i].command.position));\n      }\n      if (!dynamixel_workbench_.syncWrite(\n            kGoalPositionIndex, ids.data(), ids.size(), commands.data(), 1, &log)) {\n        RCLCPP_ERROR(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n      }\n    \n      return return_type::OK;\n    }\n    \n    return_type DynamixelHardware::enable_torque(const bool enabled)\n    {\n      const char * log = nullptr;\n    \n      if (enabled && !torque_enabled_) {\n        for (uint i = 0; i < info_.joints.size(); ++i) {\n          if (!dynamixel_workbench_.torqueOn(joint_ids_[i], &log)) {\n            RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n            return return_type::ERROR;\n          }\n        }\n        reset_command();\n        RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"Torque enabled\");\n      } else if (!enabled && torque_enabled_) {\n        for (uint i = 0; i < info_.joints.size(); ++i) {\n          if (!dynamixel_workbench_.torqueOff(joint_ids_[i], &log)) {\n            RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n            return return_type::ERROR;\n          }\n        }\n        RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"Torque disabled\");\n      }\n    \n      torque_enabled_ = enabled;\n      return return_type::OK;\n    }\n    \n    return_type DynamixelHardware::set_control_mode(const ControlMode & mode, const bool force_set)\n    {\n      const char * log = nullptr;\n    \n      if (mode == ControlMode::Velocity && (force_set || control_mode_ != ControlMode::Velocity)) {\n        bool torque_enabled = torque_enabled_;\n        if (torque_enabled) {\n          enable_torque(false);\n        }\n    \n        for (uint i = 0; i < joint_ids_.size(); ++i) {\n          if (!dynamixel_workbench_.setVelocityControlMode(joint_ids_[i], &log)) {\n            RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n            return return_type::ERROR;\n          }\n        }\n        RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"Velocity control\");\n        control_mode_ = ControlMode::Velocity;\n    \n        if (torque_enabled) {\n          enable_torque(true);\n        }\n      } else if (\n        mode == ControlMode::Position && (force_set || control_mode_ != ControlMode::Position)) {\n        bool torque_enabled = torque_enabled_;\n        if (torque_enabled) {\n          enable_torque(false);\n        }\n    \n        for (uint i = 0; i < joint_ids_.size(); ++i) {\n          if (!dynamixel_workbench_.setPositionControlMode(joint_ids_[i], &log)) {\n            RCLCPP_FATAL(rclcpp::get_logger(kDynamixelHardware), \"%s\", log);\n            return return_type::ERROR;\n          }\n        }\n        RCLCPP_INFO(rclcpp::get_logger(kDynamixelHardware), \"Position control\");\n        control_mode_ = ControlMode::Position;\n    \n        if (torque_enabled) {\n          enable_torque(true);\n        }\n      } else if (control_mode_ != ControlMode::Velocity && control_mode_ != ControlMode::Position) {\n        RCLCPP_FATAL(\n          rclcpp::get_logger(kDynamixelHardware), \"Only position/velocity control are implemented\");\n        return return_type::ERROR;\n      }\n    \n      return return_type::OK;\n    }\n    \n    return_type DynamixelHardware::reset_command()\n    {\n      for (uint i = 0; i < joints_.size(); i++) {\n        joints_[i].command.position = joints_[i].state.position;\n        joints_[i].command.velocity = 0.0;\n        joints_[i].command.effort = 0.0;\n      }\n    \n      return return_type::OK;\n    }\n    \n    }  // namespace dynamixel_hardware \n    \n    #include \"pluginlib/class_list_macros.hpp\"\n    \n    PLUGINLIB_EXPORT_CLASS(dynamixel_hardware::DynamixelHardware, hardware_interface::SystemInterface)\n    \n    \n\n[ albertoezquerro  ](https://get-help.theconstruct.ai/u/albertoezquerro)\nAugust 9, 2023, 7:55am  2\n\nHello [ @pbnpama ](/u/pbnpama) ,\n\nThe course has been developed and tested on a specific environment (for\ninstance, this course is in ROS2 Galactic). So, trying it outside the course\nenvironment might not work directly. Unfortunately, it\u2019s impossible for us to\nprovide support for each specific local environment (every student has a\ndifferent local environment). If you are working in ROS2 Foxy, make sure that\nall the packages/code you are trying to build is compatible with this\ndistribution. If you copy/pasted code from the course, it might not be\ndirectly compatible.\n\n[ pbnpama  ](https://get-help.theconstruct.ai/u/pbnpama) August 9, 2023,\n8:12am  3\n\nThank you for your answer, I also think that the distro is the main problem.\nI\u2019ve tried to edit some part but still error.\n\n[ pbnpama  ](https://get-help.theconstruct.ai/u/pbnpama) August 9, 2023,\n8:21am  4\n\nCurrently, the error is solved by define the CallbackReturn in the .hpp file.\n\n    \n    \n    #ifndef DYNAMIXEL_HARDWARE__DYNAMIXEL_HARDWARE_HPP_\n    #define DYNAMIXEL_HARDWARE__DYNAMIXEL_HARDWARE_HPP_\n    \n    #include <vector>\n    #include <map>\n    \n    #include <hardware_interface/handle.hpp>\n    #include <hardware_interface/hardware_info.hpp>\n    #include <hardware_interface/system_interface.hpp>\n    #include <rclcpp_lifecycle/state.hpp> \n    #include \"rclcpp/macros.hpp\"\n    \n    #include \"rclcpp_lifecycle/node_interfaces/lifecycle_node_interface.hpp\"\n    #include \"rclcpp_lifecycle/lifecycle_publisher.hpp\"\n    \n    #include <dynamixel_workbench_toolbox/dynamixel_workbench.h>\n    \n    using hardware_interface::return_type;\n    \n    using CallbackReturn = rclcpp_lifecycle::node_interfaces::LifecycleNodeInterface::CallbackReturn;\n    \n    namespace dynamixel_hardware {\n    struct JointValue {\n      double position{0.0};\n      double velocity{0.0};\n      double effort{0.0};\n    };\n    \n    struct Joint {\n      JointValue state{};\n      JointValue command{};\n    };\n    \n    enum class ControlMode {\n      Position,\n      Velocity,\n      Torque,\n      Currrent,\n      ExtendedPosition,\n      MultiTurn,\n      CurrentBasedPosition,\n      PWM,\n    };\n    \n    class DynamixelHardware : public hardware_interface::SystemInterface {\n    public:\n      RCLCPP_SHARED_PTR_DEFINITIONS(DynamixelHardware)\n    \n      CallbackReturn on_init(const hardware_interface::HardwareInfo & info) override;\n    \n      std::vector<hardware_interface::StateInterface> export_state_interfaces() override;\n    \n      std::vector<hardware_interface::CommandInterface> export_command_interfaces() override;\n    \n      CallbackReturn on_activate(const rclcpp_lifecycle::State & previous_state) override;\n    \n      CallbackReturn on_deactivate(const rclcpp_lifecycle::State & previous_state) override;\n    \n      return_type read() override;\n    \n      return_type write() override;\n    \n    private:\n      return_type enable_torque(const bool enabled);\n      return_type set_control_mode(const ControlMode & mode, const bool force_set = false);\n      return_type reset_command();\n    \n      DynamixelWorkbench dynamixel_workbench_;\n      std::map<const char * const, const ControlItem *> control_items_;\n      std::vector<Joint> joints_;\n      std::vector<uint8_t> joint_ids_;\n      bool torque_enabled_{false};\n      ControlMode control_mode_{ControlMode::Position};\n      bool use_dummy_{false};\n    };\n    }  // namespace dynamixel_hardware\n    \n    #endif  // DYNAMIXEL_HARDWARE__DYNAMIXEL_HARDWARE_HPP_\n    \n\nBy this the error about override came. So I just delete overrride specifier\nnow the error is here\n\n    \n    \n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:30:44: error: \u2018on_init\u2019 is not a member of \u2018hardware_interface::SystemInterface\u2019\n       30 |   if (hardware_interface::SystemInterface::on_init(info) != CallbackReturn::SUCCESS)\n          |                                            ^~~~~~~\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:35:18: error: \u2018info_\u2019 was not declared in this scope; did you mean \u2018info\u2019?\n       35 |   joints_.resize(info_.joints.size(), Joint());\n          |                  ^~~~~\n          |                  info\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp: In member function \u2018virtual std::vector<hardware_interface::StateInterface> dynamixel_hardware::DynamixelHardware::export_state_interfaces()\u2019:\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:157:24: error: \u2018info_\u2019 was not declared in this scope\n      157 |   for (uint i = 0; i < info_.joints.size(); i++) {\n          |                        ^~~~~\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp: In member function \u2018virtual std::vector<hardware_interface::CommandInterface> dynamixel_hardware::DynamixelHardware::export_command_interfaces()\u2019:\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:173:24: error: \u2018info_\u2019 was not declared in this scope\n      173 |   for (uint i = 0; i < info_.joints.size(); i++) {\n          |                        ^~~~~\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp: In member function \u2018CallbackReturn dynamixel_hardware::DynamixelHardware::on_activate(const rclcpp_lifecycle::State&)\u2019:\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:183:79: warning: unused parameter \u2018previous_state\u2019 [-Wunused-parameter]\n      183 | CallbackReturn DynamixelHardware::on_activate(const rclcpp_lifecycle::State & previous_state)\n          |                                               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp: In member function \u2018CallbackReturn dynamixel_hardware::DynamixelHardware::on_deactivate(const rclcpp_lifecycle::State&)\u2019:\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:200:81: warning: unused parameter \u2018previous_state\u2019 [-Wunused-parameter]\n      200 | CallbackReturn DynamixelHardware::on_deactivate(const rclcpp_lifecycle::State & previous_state)\n          |                                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp: In member function \u2018virtual hardware_interface::return_type dynamixel_hardware::DynamixelHardware::read()\u2019:\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:212:28: error: \u2018info_\u2019 was not declared in this scope\n      212 |   std::vector<uint8_t> ids(info_.joints.size(), 0);\n          |                            ^~~~~\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp: In member function \u2018virtual hardware_interface::return_type dynamixel_hardware::DynamixelHardware::write()\u2019:\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:265:28: error: \u2018info_\u2019 was not declared in this scope\n      265 |   std::vector<uint8_t> ids(info_.joints.size(), 0);\n          |                            ^~~~~\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp: In member function \u2018hardware_interface::return_type dynamixel_hardware::DynamixelHardware::enable_torque(bool)\u2019:\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:310:26: error: \u2018info_\u2019 was not declared in this scope\n      310 |     for (uint i = 0; i < info_.joints.size(); ++i) {\n          |                          ^~~~~\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:319:26: error: \u2018info_\u2019 was not declared in this scope\n      319 |     for (uint i = 0; i < info_.joints.size(); ++i) {\n          |                          ^~~~~\n    In file included from /opt/ros/foxy/include/class_loader/class_loader_core.hpp:57,\n                     from /opt/ros/foxy/include/class_loader/class_loader.hpp:55,\n                     from /opt/ros/foxy/include/pluginlib/class_list_macros.hpp:40,\n                     from /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:395:\n    /opt/ros/foxy/include/class_loader/meta_object.hpp: In instantiation of \u2018B* class_loader::impl::MetaObject<C, B>::create() const [with C = dynamixel_hardware::DynamixelHardware; B = hardware_interface::SystemInterface]\u2019:\n    /opt/ros/foxy/include/class_loader/meta_object.hpp:216:7:   required from here\n    /opt/ros/foxy/include/class_loader/meta_object.hpp:218:12: error: invalid new-expression of abstract class type \u2018dynamixel_hardware::DynamixelHardware\u2019\n      218 |     return new C;\n          |            ^~~~~\n    In file included from /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:7:\n    /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/include/dynamixel_hardware_interface/dynamixel_hardware_interface.hpp:45:7: note:   because the following virtual functions are pure within \u2018dynamixel_hardware::DynamixelHardware\u2019:\n       45 | class DynamixelHardware : public hardware_interface::SystemInterface {\n          |       ^~~~~~~~~~~~~~~~~\n    In file included from /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/include/dynamixel_hardware_interface/dynamixel_hardware_interface.hpp:9,\n                     from /home/tharit/moonbot_ws/src/dynamixel_hardware_interface/src/dynamixel_hardware_interface.cpp:7:\n    /opt/ros/foxy/include/hardware_interface/system_interface.hpp:48:23: note: \t\u2018virtual hardware_interface::return_type hardware_interface::SystemInterface::configure(const hardware_interface::HardwareInfo&)\u2019\n       48 |   virtual return_type configure(const HardwareInfo & system_info) = 0;\n          |                       ^~~~~~~~~\n    /opt/ros/foxy/include/hardware_interface/system_interface.hpp:116:23: note: \t\u2018virtual hardware_interface::return_type hardware_interface::SystemInterface::start()\u2019\n      116 |   virtual return_type start() = 0;\n          |                       ^~~~~\n    /opt/ros/foxy/include/hardware_interface/system_interface.hpp:122:23: note: \t\u2018virtual hardware_interface::return_type hardware_interface::SystemInterface::stop()\u2019\n      122 |   virtual return_type stop() = 0;\n          |                       ^~~~\n    /opt/ros/foxy/include/hardware_interface/system_interface.hpp:128:23: note: \t\u2018virtual std::string hardware_interface::SystemInterface::get_name() const\u2019\n      128 |   virtual std::string get_name() const = 0;\n          |                       ^~~~~~~~\n    /opt/ros/foxy/include/hardware_interface/system_interface.hpp:134:18: note: \t\u2018virtual hardware_interface::status hardware_interface::SystemInterface::get_status() const\u2019\n      134 |   virtual status get_status() const = 0;\n          |                  ^~~~~~~~~~\n    make[2]: *** [CMakeFiles/dynamixel_hardware_interface.dir/build.make:63: CMakeFiles/dynamixel_hardware_interface.dir/src/dynamixel_hardware_interface.cpp.o] Error 1\n    make[1]: *** [CMakeFiles/Makefile2:78: CMakeFiles/dynamixel_hardware_interface.dir/all] Error 2\n    make: *** [Makefile:141: all] Error 2\n    ---\n    Failed   <<< dynamixel_hardware_interface [1.90s, exited with code 2]\n    \n    Summary: 12 packages finished [2.63s]\n      1 package failed: dynamixel_hardware_interface\n      1 package had stderr output: dynamixel_hardware_interface\n    \n    \n\nI\u2019m not sure that should I change info_ to info or not.\n\n[ system  ](https://get-help.theconstruct.ai/u/system) Closed  August 16,\n2023, 8:21am  5\n\nThis topic was automatically closed 7 days after the last reply. New replies\nare no longer allowed.\n\n  * [ Home ](/)\n  * [ Categories ](/categories)\n  * [ FAQ/Guidelines ](/guidelines)\n  * [ Terms of Service ](http://www.theconstructsim.com/terms_and_conditions/)\n  * [ Privacy Policy ](http://www.theconstructsim.com/privacy_policy/)\n\nPowered by [ Discourse ](https://www.discourse.org) , best viewed with\nJavaScript enabled\n\n"
  },
  {
    "id": "launch_moveit/namespacemoveitconfi.txt",
    "content": "moveit2\n\nThe MoveIt Motion Planning Framework for ROS 2.  \n  \n---  \n  \n  * [ moveit_configs_utils ](namespacemoveit__configs__utils.html)\n  * [ launches ](namespacemoveit__configs__utils_1_1launches.html)\n\nFunctions\n\nmoveit_configs_utils.launches Namespace Reference\n\n##  Functions  \n  \n---  \ndef  |  [ generate_rsp_launch\n](namespacemoveit__configs__utils_1_1launches.html#a76138c9e926fe212b8f829faaf3a13f1)\n(moveit_config)  \ndef  |  [ generate_moveit_rviz_launch\n](namespacemoveit__configs__utils_1_1launches.html#a58d2e37c105df55435db0ebc4cb55546)\n(moveit_config)  \ndef  |  [ generate_setup_assistant_launch\n](namespacemoveit__configs__utils_1_1launches.html#a4c2d855ac0654fb6d38fcc769bc5f36a)\n(moveit_config)  \ndef  |  [ generate_static_virtual_joint_tfs_launch\n](namespacemoveit__configs__utils_1_1launches.html#ae1a3c2ef604780f01ba7b15f6847839a)\n(moveit_config)  \ndef  |  [ generate_spawn_controllers_launch\n](namespacemoveit__configs__utils_1_1launches.html#ac0092436526e7dee0231cdbc2c4d26e0)\n(moveit_config)  \ndef  |  [ generate_warehouse_db_launch\n](namespacemoveit__configs__utils_1_1launches.html#af25ac5985fddc387b129fdffbaa972e1)\n(moveit_config)  \ndef  |  [ generate_move_group_launch\n](namespacemoveit__configs__utils_1_1launches.html#afd16396f7fda60749b1c8e8019f72aad)\n(moveit_config)  \ndef  |  [ generate_demo_launch\n](namespacemoveit__configs__utils_1_1launches.html#a9478fc6a76264b9eccf1d78b246f1d1c)\n(moveit_config)  \n  \n##  Function Documentation\n\n##  \u25c6  generate_demo_launch()\n\ndef moveit_configs_utils.launches.generate_demo_launch  |  (  |  |\n_moveit_config_ |  )  |  \n---|---|---|---|---|---  \n      \n    \n    Launches a self contained demo\n    \n    Includes\n     * static_virtual_joint_tfs\n     * robot_state_publisher\n     * move_group\n     * moveit_rviz\n     * warehouse_db (optional)\n     * ros2_control_node + controller spawners\n    \n\nDefinition at line [ 252 ](launches_8py_source.html#l00252) of file [\nlaunches.py ](launches_8py_source.html) .\n\n##  \u25c6  generate_move_group_launch()\n\ndef moveit_configs_utils.launches.generate_move_group_launch  |  (  |  |\n_moveit_config_ |  )  |  \n---|---|---|---|---|---  \n  \nDefinition at line [ 189 ](launches_8py_source.html#l00189) of file [\nlaunches.py ](launches_8py_source.html) .\n\nHere is the call graph for this function:\n\n![](namespacemoveit__configs__utils_1_1launches_afd16396f7fda60749b1c8e8019f72aad_cgraph.png)\n\n##  \u25c6  generate_moveit_rviz_launch()\n\ndef moveit_configs_utils.launches.generate_moveit_rviz_launch  |  (  |  |\n_moveit_config_ |  )  |  \n---|---|---|---|---|---  \n      \n    \n    Launch file for rviz\n\nDefinition at line [ 47 ](launches_8py_source.html#l00047) of file [\nlaunches.py ](launches_8py_source.html) .\n\nHere is the call graph for this function:\n\n![](namespacemoveit__configs__utils_1_1launches_a58d2e37c105df55435db0ebc4cb55546_cgraph.png)\n\n##  \u25c6  generate_rsp_launch()\n\ndef moveit_configs_utils.launches.generate_rsp_launch  |  (  |  |\n_moveit_config_ |  )  |  \n---|---|---|---|---|---  \n      \n    \n    Launch file for robot state publisher (rsp)\n\nDefinition at line [ 23 ](launches_8py_source.html#l00023) of file [\nlaunches.py ](launches_8py_source.html) .\n\n##  \u25c6  generate_setup_assistant_launch()\n\ndef moveit_configs_utils.launches.generate_setup_assistant_launch  |  (  |  |\n_moveit_config_ |  )  |  \n---|---|---|---|---|---  \n      \n    \n    Launch file for MoveIt Setup Assistant\n\nDefinition at line [ 77 ](launches_8py_source.html#l00077) of file [\nlaunches.py ](launches_8py_source.html) .\n\nHere is the call graph for this function:\n\n![](namespacemoveit__configs__utils_1_1launches_a4c2d855ac0654fb6d38fcc769bc5f36a_cgraph.png)\n\n##  \u25c6  generate_spawn_controllers_launch()\n\ndef moveit_configs_utils.launches.generate_spawn_controllers_launch  |  (  |\n|  _moveit_config_ |  )  |  \n---|---|---|---|---|---  \n  \nDefinition at line [ 118 ](launches_8py_source.html#l00118) of file [\nlaunches.py ](launches_8py_source.html) .\n\n##  \u25c6  generate_static_virtual_joint_tfs_launch()\n\ndef moveit_configs_utils.launches.generate_static_virtual_joint_tfs_launch  |\n(  |  |  _moveit_config_ |  )  |  \n---|---|---|---|---|---  \n  \nDefinition at line [ 92 ](launches_8py_source.html#l00092) of file [\nlaunches.py ](launches_8py_source.html) .\n\n##  \u25c6  generate_warehouse_db_launch()\n\ndef moveit_configs_utils.launches.generate_warehouse_db_launch  |  (  |  |\n_moveit_config_ |  )  |  \n---|---|---|---|---|---  \n      \n    \n    Launch file for warehouse database\n\nDefinition at line [ 135 ](launches_8py_source.html#l00135) of file [\nlaunches.py ](launches_8py_source.html) .\n\n* * *\n\nGenerated by [ ![doxygen](doxygen.svg) ](https://www.doxygen.org/index.html)\n1.9.1\n\n"
  },
  {
    "id": "automap_project/hornung13auropdf.txt",
    "content": "Autonomous Robots (2013)\nPreprint, final version available at DOI 10.1007/s10514-012-9321-0\nOctoMap:\nAn Efficient Probabilistic 3D Mapping Framework Based on Octrees\nArmin Hornung \u00b7 Kai M. Wurm \u00b7 Maren Bennewitz \u00b7\nCyrill Stachniss \u00b7 Wolfram Burgard\nReceived: 30 April 2012 / Accepted: 31 December 2012\nAbstract Three-dimensional models provide a volumetric\nrepresentation of space which is important for a variety of\nrobotic applications including flying robots and robots that\nare equipped with manipulators. In this paper, we present an\nopen-source framework to generate volumetric 3D environment models. Our mapping approach is based on octrees and\nuses probabilistic occupancy estimation. It explicitly represents not only occupied space, but also free and unknown\nareas. Furthermore, we propose an octree map compression\nmethod that keeps the 3D models compact. Our framework\nis available as an open-source C++ library and has already\nbeen successfully applied in several robotics projects. We\npresent a series of experimental results carried out with real\nrobots and on publicly available real-world datasets. The results demonstrate that our approach is able to update the\nrepresentation efficiently and models the data consistently\nwhile keeping the memory requirement at a minimum.\nKeywords 3D \u00b7 Probabilistic \u00b7 Mapping \u00b7 Navigation\n1 Introduction\nSeveral robotic applications require a 3D model of the environment. These include airborne, underwater, outdoor, or\nextra-terrestrial missions. However, 3D models are also relevant for many domestic scenarios, for example, for mobile\nmanipulation and also navigation tasks.\nThis work has been supported by the German Research Foundation\n(DFG) under contract number SFB/TR-8 and by the European Commission under grant agreement numbers FP7-248258-First-MM and\nFP7-600890-ROVINA.\nA. Hornung \u00b7 K.M. Wurm \u00b7 M. Bennewitz \u00b7 C. Stachniss \u00b7 W. Burgard\nDepartment of Computer Science, University of Freiburg,\nGeorges-Koehler-Allee 74, 79110 Freiburg, Germany\nE-mail: {hornunga,wurm,maren,stachnis,burgard}@informatik.unifreiburg.de\nAlthough 3D mapping is an integral component of many\nrobotic systems, there exist few readily available, reliable,\nand efficient implementations. The lack of such implementations leads to the re-creation of basic software components\nand, thus, can be seen as a bottleneck in robotics research.\nWe therefore believe that the development of an open-source\n3D mapping framework will greatly facilitate the development of robotic systems that require a three-dimensional geometric representation of the environment.\nMost robotics applications require a probabilistic representation, modeling of free, occupied, and unmapped areas, and additionally efficiency with respect to runtime and\n\n\n\nmemory usage. We will now discuss these three requirements in detail.\n\u2013 Probabilistic representation: To create 3D maps, mobile robots sense the environment by taking 3D range\nmeasurements. Such measurements are afflicted with\nuncertainty: Typically, the error in the range measurements is in the order of centimeters. But there may also\nbe seemingly random measurements that are caused by\nreflections or dynamic obstacles. When the task is to\ncreate an accurate model of the environment from such\nnoisy measurements, the underlying uncertainty has to\nbe taken into account probabilistically. Multiple uncertain measurements can then be fused into a robust estimate of the true state of the environment. Another important aspect is that probabilistic sensor fusion allows\nfor the integration of data from multiple sensors and of\nmultiple robots.\n\u2013 Modeling of unmapped areas: In autonomous navigation tasks, a robot can plan collision-free paths only for\nthose areas that have been covered by sensor measurements and detected to be free. Unmapped areas, in contrast, need to be avoided and for this reason the map\nhas to represent such areas. Furthermore, the knowledge\n2 Armin Hornung et al.\nFig. 1 3D representations of a tree scanned with a laser range sensor (from left to right): Point cloud, elevation map, multi-level surface map, and\nour volumetric (voxel) representation. Please note that our volumetric representation explicitly models free space but that for clarity only occupied\nvolumes are visualized.\nabout unmapped areas is essential during exploration.\nWhen maps are created autonomously, the robot has to\nplan its actions so that measurements are taken in previously unmapped areas.\n\u2013 Efficiency: The map is a central component of any autonomous system because it is used during action planning and execution. For this reason, the map needs to\nbe efficient with respect to access times but also with\nrespect to memory consumption. From a practical point\nof view, memory consumption is often the major bottleneck in 3D mapping systems. Therefore, it is important\nthat the model is compact in memory so that large environments can be mapped, a robot can keep the model\nin its main memory, and it can be transmitted efficiently\nbetween multiple robots.\nSeveral approaches have been proposed to model 3D environments in robotics. As an illustration, we compare our\napproach to three common mapping approaches \u2013 a visualization of the results is given in Fig. 1. In the example,\n3D measurements are represented using point clouds, elevation maps (Hebert et al., 1989), multi-level surface maps\n(Triebel et al., 2006), and in a volumetric way using our\nframework. None of the previous approaches fulfill all of\nthe requirements we set out above. Point clouds store large\namounts of measurement points and hence are not memoryefficient. They furthermore do not allow to differentiate between obstacle-free and unmapped areas and provide no\nmeans of fusing multiple measurements probabilistically.\nElevation maps and multi-level surface maps are efficient\nbut do not represent unmapped areas either. Most importantly, these approaches cannot represent arbitrary 3D environments, such as the branches of the tree in the example.\nIn this work we present OctoMap, an integrated framework based on octrees for the representation of threedimensional environments. In our framework, we combine\nthe advantages of previous approaches to 3D environment\n\n\n\nmodeling in order to meet the requirements discussed above.\nA central property of our approach is that it allows for efficient and probabilistic updates of occupied and free space\nwhile keeping the memory consumption at a minimum. Occupied space is obtained by the end points of a distance\nsensor such as a laser range finder, while free space corresponds to the observed area between the sensor and the end\npoint. As a key contribution of our approach, we introduce a\ncompression method that reduces the memory requirement\nby locally combining coherent map volumes, both in the\nmapped free areas and the occupied space. We implemented\nour approach and thoroughly evaluated it using various publicly available real-world robotics datasets of both indoor\nand outdoor environments.\nOur open source implementation is freely available\nin form of a self-contained C++ library. It was released under the BSD-license and can be obtained from\nhttp://octomap.github.com. The library supports several\nplatforms, such as Linux, Mac OS, and Windows. It has been\nintegrated into the Robot Operating System (ROS) and can\nbe used in other software frameworks in a straightforward\nway. Since its first introduction in 2010 (Wurm et al., 2010),\nthe OctoMap framework was constantly improved and used\nin an increasing number of robotics research projects.\nThis paper is organized as follows. After providing a\ndetailed discussion of related work in the area of 3D data\nstructures and mapping approaches in the next section, we\npresent our OctoMap framework in Sect. 3. Implementation\ndetails are given in Sect. 4, followed by an evaluation of the\nproposed framework in Sect. 5. Finally, case studies on how\nOctoMap has been used in various areas of robotics demonstrate the versatility and ease of integration in Sect. 6.\n2 Related Work\nThree-dimensional models of the environment are a key prerequisite for many robotic systems and consequently they\nhave been the subject of research for more than two decades.\nA popular approach to modeling environments in 3D is\nto use a grid of cubic volumes of equal size, called voxels, to\ndiscretize the mapped area. Roth-Tabak and Jain (1989) as\nwell as Moravec (1996) presented early works using such a\nOctoMap: An Efficient Probabilistic 3D Mapping Framework Based on Octrees 3\nrepresentation. A major drawback of rigid grids is their large\nmemory requirement. The grid map needs to be initialized\nso that it is at least as big as the bounding box of the mapped\narea, regardless of the actual distribution of map cells in\nthe volume. In large-scale outdoor scenarios or when there\nis the need for fine resolutions, memory consumption can\n\n\n\nbecome prohibitive. Furthermore, the extent of the mapped\narea needs to be known beforehand or costly copy operations\nneed to be performed every time the map area is expanded.\nA discretization of the environment can be avoided\nby storing 3D range measurements directly. The occupied\nspace in the environment is then modeled by the 3D point\nclouds returned by range sensors such as laser range finders or stereo cameras. This point cloud approach has been\nused in several 3D SLAM systems such as those presented\nby Cole and Newman (2006) as well as in the SLAM approach of Nuchter et al. \u00a8 (2007). The drawbacks of this\nmethod are that neither free space nor unknown areas are\nmodeled and that sensor noise and dynamic objects cannot\nbe dealt with directly. Thus, point clouds are only suitable\nfor high precision sensors in static environments and when\nunknown areas do not need to be represented. Furthermore,\nthe memory consumption of this representation increases\nwith the number of measurements which is problematic as\nthere is no upper bound.\nIf certain assumptions about the mapped area can be\nmade, 2.5D maps are sufficient to model the environment.\nTypically, a 2D grid is used to store the measured height for\neach cell. In its most basic form, this results in an elevation\nmap where the map stores exactly one value per cell (Hebert\net al., 1989). One approach in which such maps have been\ndemonstrated to be sufficient is the outdoor terrain navigation method described by Hadsell et al. (2009). Whenever\nthere is a single surface that the robot uses for navigation,\nan elevation map is sufficient to model the environment,\nsince overhanging obstacles that are higher than the vehicle, such as trees, bridges or underpasses, can be safely ignored. The strict assumption of a single surface can be relaxed by allowing multiple surfaces per cell (Triebel et al.,\n2006; Pfaff et al., 2007), or by using classes of cells which\ncorrespond to different types of structures (Gutmann et al.,\n2008). A general drawback of most 2.5D maps is that they\ndo not represent the environment in a volumetric way but\ndiscretize it in the vertical dimension based on the robot\u2019s\nheight. While this is sufficient for path planning and navigation with a fixed robot shape, the map does not represent the\nactual environment, e.g. for localization.\nTo overcome this problem, a related approach was proposed by Ryde and Hu (2010). The approach stores a list of\noccupied voxels for each cell in a 2D grid. Although this representation is volumetric, it does not differentiate between\nfree and unknown volumes. Dryanovski et al. (2010) store\nlists of occupied and free voxels for each 2D cell in their\nMulti-Volume Occupancy Grid approach. In contrast to our\napproach, however, the map extent needs to be known beforehand, map updates are more computationally involved,\n\n\n\nand there is no multi-resolution capability. Another potential\nproblem is that subsequent map updates cannot subdivide\nexisting volumes, leading to an incorrect model of the environment. Similarly, Douillard et al. (2010) combine a coarse\nelevation map for background structures with object voxel\nmaps at a higher resolution. In contrast to our work, this approach focuses on 3D segmentation of single measurements\nand does not integrate several measurements into a model of\nthe environment.\nIn robotic mapping, octrees avoid one of the main shortcomings of fixed grid structures: They delay the initialization of map volumes until measurements need to be integrated. In this way, the extent of the mapped environment\ndoes not need to be known beforehand and the map only\ncontains volumes that have been measured. If inner nodes\nof a tree are updated properly, the tree can also be used\nas a multi-resolution representation since it can be cut at\nany level to obtain a coarser subdivision. The use of octrees\nfor mapping was originally proposed by Meagher (1982).\nEarly works mainly focused on modeling a Boolean property such as occupancy (Wilhelms and Van Gelder, 1992).\nPayeur et al. (1997) used octrees to adapt occupancy grid\nmapping from 2D to 3D and thereby introduced a probabilistic way of modeling occupied and free space. A similar\napproach was used by Fournier et al. (2007) and Pathak et al.\n(2007). In contrast to the approach presented in this paper,\nhowever, the authors did not explicitly address the issues of\nmap compression or bounded confidence in the map.\nAn octree-based 3D map representation was also proposed by Fairfield et al. (2007). Their map structure called\nDeferred Reference Counting Octree is designed to allow for efficient map updates, especially in the context\nof particle filter SLAM. To achieve map compactness, a\nlossy maximum-likelihood compression is performed periodically. Compared to the compression technique used in\nour approach, this discards the probability information for\nfuture updates. Furthermore, the problem of overconfident\nmaps and multi-resolution queries are not addressed.\nAs a data structure, octrees are applied in a variety of\napplications, most notably in the area of computer graphics\nfor efficient rendering (Botsch et al., 2002; Surmann et al.,\n2003; Laine and Karras, 2010) and in the field of photogrammetry to store and address large point clouds (GirardeauMontaut et al., 2005; Elseberg et al., 2011). Another popular\nuse case is the compression of static point clouds (Schnabel\nand Klein, 2006) or point cloud streams (Kammerl et al.,\n2012). While our framework is general enough to also store\nraw point clouds, its main purpose is to integrate these point\nclouds into a memory-efficient, volumetric occupancy map,\nsince point clouds as environment representation in robotics\n4 Armin Hornung et al.\nhave a number of disadvantages as detailed at the beginning\n\n\n\nof this section.\nYguel et al. (2007b) presented a 3D map based on\nthe Haar wavelet data structure. This representation is also\nmulti-resolution and probabilistic. However, the authors did\nnot evaluate applications to 3D modeling in-depth. In their\nevaluation, unknown areas are not modeled and only a single simulated 3D dataset is used. Whether this map structure\nis as memory-efficient as octrees is hard to assess without a\npublicly available implementation.\nSurface representations such as the 3D Normal Distribution Transform (Magnusson et al., 2007) or Surfels (Habbecke and Kobbelt, 2007) were recently used for\n3D path planning (Stoyanov et al., 2010) and object modeling (Weise et al., 2009; Krainin et al., 2011). Similarly, an\naccurate real-time 3D SLAM system based on a low-cost\ndepth camera and GPU processing was proposed by Newcombe et al. (2011) to reconstruct dense surfaces in indoor\nscenes. Recently, this work has been extended to work in\nlarger indoor environments (Whelan et al., 2012). However,\nsurface representations are unable to distinguish between\nfree and unknown space, may require large memory particularly outdoors, and are often based on strong assumptions\nabout the corresponding environment. In mobile manipulation scenarios, for example, being able to differentiate free\nfrom unknown space is essential for safe navigation.\nFinally, to the best of our knowledge, no open source implementation of a 3D occupancy mapping framework meeting the requirements outlined in the introduction is freely\navailable.\n3 OctoMap Mapping Framework\nThe approach proposed in this paper uses a tree-based representation to offer maximum flexibility with regard to the\nmapped area and resolution. It performs a probabilistic occupancy estimation to ensure updatability and to cope with\nsensor noise. Furthermore, compression methods ensure the\ncompactness of the resulting models.\n3.1 Octrees\nAn octree is a hierarchical data structure for spatial subdivision in 3D (Meagher, 1982; Wilhelms and Van Gelder,\n1992). Each node in an octree represents the space contained\nin a cubic volume, usually called a voxel. This volume is\nrecursively subdivided into eight sub-volumes until a given\nminimum voxel size is reached, as illustrated in Fig. 2. The\nminimum voxel size determines the resolution of the octree.\nSince an octree is a hierarchical data structure, the tree can\nbe cut at any level to obtain a coarser subdivision if the inner nodes are maintained accordingly. An example of an ocFig. 2 Example of an octree storing free (shaded white) and occupied\n(black) cells. The volumetric model is shown on the left and the corresponding tree representation on the right.\nFig. 3 By limiting the depth of a query, multiple resolutions of the\nsame map can be obtained at any time. Occupied voxels are displayed\nin resolutions 0.08 m, 0.64 , and 1.28 m.\ntree map queried for occupied voxels at several resolutions\nis shown in Fig. 3.\n\n\n\nIn its most basic form, octrees can be used to model a\nBoolean property. In the context of robotic mapping, this\nis usually the occupancy of a volume. If a certain volume\nis measured as occupied, the corresponding node in the octree is initialized. Any uninitialized node could be free or\nunknown in this Boolean setting. To resolve this ambiguity, we explicitly represent free volumes in the tree. These\nare created in the area between the sensor and the measured\nend point, e.g., along a ray determined with raycasting. Areas that are not initialized implicitly model unknown space.\nAn illustration of an octree containing free and occupied\nnodes from real laser sensor data can be seen in Fig. 4. Using\nBoolean occupancy states or discrete labels allows for compact representations of the octree: If all children of a node\nhave the same state (occupied or free) they can be pruned.\nThis leads to a substantial reduction in the number of nodes\nthat need to be maintained in the tree.\nIn robotic systems, one typically has to cope with sensor noise and temporarily or permanently changing environments. In such cases, a discrete occupancy label will not\nbe sufficient. Instead, occupancy has to be modeled probabilistically, for instance by applying occupancy grid mapping (Moravec and Elfes, 1985). However, such a probabilistic model lacks the possibility of lossless compression\nby pruning.\nThe approach presented in this paper offers means of\ncombining the compactness of octrees that use discrete labels with the updatability and flexibility of probabilistic\nmodeling as we will discuss in Sect. 3.4.\nOctoMap: An Efficient Probabilistic 3D Mapping Framework Based on Octrees 5\nFig. 4 An octree map generated from example data. Left: Point cloud recorded in a corridor with a tilting laser range finder. Center: Octree\ngenerated from the data, showing occupied voxels only. Right: Visualization of the octree showing occupied voxels (dark) and free voxels (white).\nThe free areas are obtained by clearing the space on a ray from the sensor origin to each end point. Lossless pruning results in leaf nodes of\ndifferent sizes, mostly visible in the free areas on the right.\nIn terms of data access complexity, octrees require an\noverhead compared to a fixed-size 3D grid due to the tree\nstructure. A single, random query on a tree data structure\ncontaining n nodes with a tree depth of d can be performed\nwith a complexity of O(d) = O(logn). Traversing the complete tree in a depth-first manner requires a complexity of\nO(n). Note that, in practice, our octree is limited to a fixed\nmaximum depth dmax. This results in a random node lookup\ncomplexity of O(dmax) with dmax being constant. Therefore,\nfor a fixed depth dmax, the overhead compared to a corresponding 3D grid is constant. Note that in all our experiments a maximum depth of 16 was used, which is sufficient\nto cover a cube with a vollume of (655.36 m)\n3\nat 1 cm resolution. The exact timings for this setting are provided in\nSect. 5.5.\n3.2 Probabilistic Sensor Fusion\nIn our approach, sensor readings are integrated using occupancy grid mapping as introduced by Moravec and Elfes\n(1985). The probability P(n | z1:t) of a leaf node n to be occupied given the sensor measurements z1:t\n\n\n\nis estimated according to\nP(n | z1:t) = (1)\n\u0014\n1+\n1\u2212P(n | zt)\nP(n | zt)\n1\u2212P(n | z1:t\u22121)\nP(n | z1:t\u22121)\nP(n)\n1\u2212P(n)\n\u0015\u22121\nThis update formula depends on the current measurement zt\n, a prior probability P(n), and the previous estimate\nP(n | z1:t\u22121). The term P(n | zt) denotes the probability of\nvoxel n to be occupied given the measurement zt\n. This value\nis specific to the sensor that generated zt\n. We provide details on the sensor model used throughout our experiments\nin Sect. 5.1.\nThe common assumption of a uniform prior probability leads to P(n) = 0.5 and by using the log-odds notation,\nEq. (1) can be rewritten as\nL(n | z1:t) = L(n | z1:t\u22121) +L(n | zt), (2)\nwith\nL(n) = log\u0014\nP(n)\n1\u2212P(n)\n\u0015\n. (3)\nThis formulation of the update rule allows for faster updates since multiplications are replaced by additions. In case\nof pre-computed sensor models, the logarithms do not have\nto be computed during the update step. Note that log-odds\nvalues can be converted into probabilities and vice versa\nand we therefore store this value for each voxel instead of\nthe occupancy probability. It is worth noting that for certain configurations of the sensor model that are symmetric,\ni.e., nodes being updated as hits have the same weight as the\nones updated as misses, this probability update has the same\neffect as counting hits and misses similar to (Kelly et al.,\n2006).\nWhen a 3D map is used for navigation, a threshold on the\noccupancy probability P(n | z1:t) is often applied. A voxel\n\n\n\nis considered to be occupied when the threshold is reached\nand is assumed to be free otherwise, thereby defining two\ndiscrete states. From Eq. (2) it is evident that to change the\nstate of a voxel we need to integrate as many observations\nas have been integrated to define its current state. In other\nwords, if a voxel was observed free for k times, then it has\nto be observed occupied at least k times before it is considered occupied according to the threshold (assuming that\nfree and occupied measurements are equally likely in the\nsensor model). While this property is desirable in static environments, a mobile robot is often faced with temporary or\npermanent changes in the environment and the map has to\nadapt to these changes quickly. To ensure this adaptability,\nYguel et al. (2007a) proposed a clamping update policy that\ndefines an upper and lower bound on the occupancy estimate. Instead of using Eq. (2) directly, occupancy estimates\n6 Armin Hornung et al.\nare updated according to\nL(n | z1:t) = (4)\nmax(min(L(n | z1:t\u22121) +L(n | zt),lmax),lmin),\nwhere lmin and lmax denote the lower and upper bound on\nthe log-odds value. Intuitively, this modified update formula\nlimits the number of updates that are needed to change the\nstate of a voxel. Applying the clamping update policy in our\napproach leads to two advantages: we ensure that the confidence in the map remains bounded and as a consequence the\nmodel can adapt to changes in the environment quickly. Furthermore, we are able to compress neighboring voxels with\npruning (see Sect. 3.4). As we will discuss in Sect. 5.4, this\nleads to a considerable reduction in the number of voxels\nthat have to be maintained. The compression achieved with\nclamping is no longer completely lossless in terms of the full\nprobabilities, since information close to zero and one is lost.\nIn between the clamping thresholds, however, full probabilities are preserved.\n3.3 Multi-Resolution Queries\nWhen measurements are integrated into our map structure,\nprobabilistic updates are performed only for the leaf nodes\nin the octree. But since an octree is a hierarchical data structure, we can make use of the inner nodes in the tree to enable\nmulti-resolution queries. Observe that we yield a coarser\nsubdivision of the 3D space when the tree is traversed only\nup to a given depth that is not the depth of the leaf nodes.\nEach inner node spans the volume that its eight children occupy, so to determine the occupancy probability of an inner\nnode, we have to aggregate the probabilities of its children.\nSeveral strategies could be pursued to determine the occupancy probability of a node n given its eight sub-volumes ni\n(Kraetzschmar et al., 2004). Depending on the application at\n\n\n\nhand, either the average occupancy\n\u00afl(n) = 1\n8\n8\n\u2211\ni=1\nL(ni) (5)\nor the maximum occupancy\n\u02c6l(n) = max\ni\nL(ni) (6)\ncan be used, where L(n) returns the current log-odds occupancy value of a node n. Using the maximum child occupancy to update inner nodes can be regarded a conservative\nstrategy which is well suited for robot navigation. By assuming that a volume is occupied if any part of it has been\nmeasured occupied, collision-free paths can be planned and\nfor this reason the maximum occupancy update is used in\nour system. Note that in an even more conservative setting,\nL(n) can be defined to return a positive occupancy probability for unknown cells as well. An example of an octree\nqueried for occupied voxels at several resolutions is shown\nin Fig. 3.\n3.4 Octree Map Compression\nIn Sect. 3.1, we explained how tree pruning can reduce the\namount of redundant information in octrees with discrete\noccupancy states in which a voxel can be either occupied\nor free. The same technique can also be applied in maps\nthat use probabilistic occupancy estimates to model occupied and free space. In general, however, one cannot expect\nthe occupancy probability of neighboring nodes to be identical, even if both voxel are occupied by the same physical\nobstacle. Sensor noise and discretization errors can lead to\ndifferent probabilities and therefore interfere with compression schemes that rely on identical node information. A possible solution to this problem is to apply a threshold on the\nvoxel probability, for example 0.5, and in this way generate a discrete state estimation as suggested by Fairfield et al.\n(2007). With that approach, however, individual probability\nestimates cannot be recovered after the tree has been pruned.\nIn our approach, we achieve map compression by applying the clamping update policy given in Eq. (4). Whenever the log-odds value of a voxel reaches either the lower\nbound lmin or the upper bound lmax, we consider the node as\nstable in our approach. Intuitively, stable nodes have been\nmeasured free or occupied with high confidence. In a static\nenvironment, all voxels will converge to a stable state after\na sufficient number of measurements have been integrated.\nWith the parameters chosen in our experiments, for example, five agreeing measurements are sufficient to render an\nunknown voxel into a stable voxel. If all children of an inner tree node are stable leaf nodes with the same occupancy\nstate, then the children can be pruned. Should future measurements be integrated that contradict the state of the corresponding inner node, then its children are regenerated and\n\n\n\nupdated accordingly. Applying this compression only leads\nto a loss of information close to P(n) = 0 and P(n) = 1 while\npreserving the probabilities in between. In our experiments,\ncombining octree pruning and clamping leads to a compression improvement of up to 44%.\nIn many robotic navigation tasks such as obstacle avoidance or localization, only the maximum likelihood map containing either free or occupied nodes is sufficient. In these\ncases, a lossy compression based on the occupancy threshold, as suggested by Fairfield et al. (2007), can be performed. For this compression, all nodes are converted to\ntheir maximum likelihood (clamped) probabilities, followed\nby tree pruning. This yields an even greater compression and\nless memory requirements.\nOctoMap: An Efficient Probabilistic 3D Mapping Framework Based on Octrees 7\nFig. 5 Detail of a volumetric indoor OctoMap containing color information. The complete map covers an area of 7.3 m \u00d7 7.9 m \u00d7 4.6 m at\n2 cm resolution.\n3.5 Extensions\n3.5.1 Maps with Rich Information\nOctree nodes can be extended to store additional data to enrich the map representation. Voxels could, for example, store\nterrain information, environmental data such as the temperature, or color information. Each additional voxel property\nrequires a method that allows several measurements to be\nfused. As an example, we extended our mapping framework\nto store the average color of each voxel. This creates visualizations for the user and enables a color-based classification\nof the environment or appearance-based robot localization\nfrom virtual views (similar to (Einhorn et al., 2011; Mason\net al., 2011)). It can also be used as a starting point to create colored, high-resolution surface meshes (Hoppe et al.,\n1992). Figure 5 shows an octree map that was created by\nintegrating colored point clouds recorded with a hand-held\nMicrosoft Kinect sensor. The data is available in the sequence called freiburg1 360 of the RGBD-dataset (Sturm\net al., 2012) and was aligned using RGB-D SLAM (Endres\net al., 2012).\n3.5.2 Octree Hierarchies\nWe developed an extension to our mapping approach that exploits hierarchical dependencies in the environment (Wurm\net al., 2011). This extension maintains a collection of\nsubmaps in a tree-structure, where each node represents a\nsubspace of the environment. The subdivision applied in our\nsystem is based on a user-defined segmentation of the input and on a given spatial relation that expresses the relation\nbetween segments.\nFigure 6 gives an illustration of a hierarchy that is based\non the assumption that objects are located on top of supporting planes. In this application, we first estimated supporting\nFig. 6 Hierarchical octree model of a tabletop scene. Background (yellow), table (magenta), and objects (cyan) are represented by individual\noctree maps of different resolutions.\nplanes in the input. Objects on top of these supporting planes\nwere then segmented in the input data and modeled in individual volumetric submaps. As a result, the table is a submap\n\n\n\nthat is on top of the floor and several household objects are\nin turn represented as submaps on top of the table.\nCompared to a single, monolithic map of the environment, our hierarchical approach exhibits a number of advantages: First, each submap is maintained independently and\nmapping parameters such as the resolution can be adapted\nfor each submap. Second, submaps can be manipulated independently. For example, one of the submaps representing\nan individual object can be moved while the rest remains\nstatic. Third, hierarchical dependencies of submaps can be\nencoded in the hierarchy. For example, all objects on a table\ncan be associated to this table and if the table is moved then\nthe objects are moved along with it.\nThe approach has been evaluated in the context of tabletop manipulation. Objects on a table were mapped at very\nfine resolutions while the table and background structures\nwere mapped at lower resolutions. This approach led to\nmodels that were about an order of magnitude more compact than a single map that represents the complete scene.\n4 Implementation Details\n4.1 Memory-Efficient Node Implementation\nIn a straight-forward octree implementation, each node in\nthe tree stores in addition to the data payload the coordinate of its center location, its voxel size, and pointers to its\nchildren. This, however, can lead to a substantial memory\noverhead. Since the node location and its voxel size can be\nreconstructed while traversing the octree, we do not explicitly store this information in the nodes to reduce the memory\noverhead.\nIn general, octree nodes need to maintain an ordered list\nof their children. This can be directly achieved by using\neight pointers per node. If sparse data are modeled, the memory requirement of those pointers (8\u00d74 byte = 32 byte on a\n8 Armin Hornung et al.\n32 bit architecture) will lead to a significant memory overhead (Wilhelms and Van Gelder, 1992). We overcome that\nby using one child pointer per node that points to an array of\neight pointers (Fig. 7, left). This array is only allocated if the\nnode indeed has children and is not allocated for leaf nodes.\nThus, any leaf node in the octree only stores the mapping\ndata itself (e.g., the occupancy probability) and one (null)\npointer. Inner nodes additionally store eight pointers to their\nchildren. In the robotics-related datasets used in our evaluation, 80% \u2013 85% of the octree nodes are leafs. In our experiments, the above-mentioned implementation saves 60% \u2013\n65% of memory compared to allocating 8 pointers for each\nnode.\nTo store a per-voxel occupancy probability, a single float\nvalue (usually 4 byte) is sufficient to represent the log-odds\nvalue. This results in a node size of 40 byte for inner nodes\nand 8 byte for leafs on a 32-bit architecture. Note that most\n\n\n\ncompilers align member data in memory for runtime efficiency, that is, the data of a node is padded to be multiples\nof one word large (4 byte on a 32-bit architecture). 64-bit architectures can address large amounts of memory at the cost\nof pointers and words having twice the size. On such architectures, the memory size of inner nodes increases to 80 byte\nand the size of leaf nodes to 16 byte. Note that the actual size\nof the data structure (76 byte for inner nodes and 12 byte for\nleaf nodes) is again padded to multiples of the word size (8\nbyte on a 64-bit architecture) by most compilers.\nIn our approach, the octree is homogeneous by design,\nthat is, all nodes have the same structure and store occupancy. While inner nodes could potentially save 8 byte by\nomitting occupancy information, maintaining it according\nto Eq. (5) or (6) enables multi-resolution queries, where tree\ntraversal is stopped at a fixed depth.\nVirtual inheritance between classes allows dynamic dispatch during run-time, at the cost of one extra pointer to the\nvirtual function table (vtable) for each object instance. To\nminimize the memory footprint, we avoided this overhead in\nthe octree node implementation. We apply direct inheritance\nand casts for the nodes, and use virtual inheritance only in\nthe octree classes. This method results in an overhead of the\nsize of only one pointer per octree map.\n4.2 Octree Types\nThe most common octree and node types in our framework\nare summarized in Fig. 8 as a UML diagram. The basic octree functionality is implemented in OcTreeBase, and the\nbasic node functionality is implemented in OcTreeDataNode. OcTreeDataNode is templated over data that is stored in\nthe node while OcTreeBase is templated over the node type.\nOccupancyOcTreeBase adds occupancy mapping functionality to the tree implementation, such as scan insertions and\ndata child ptr\n... ... ... ...\n0.9\n0.9 0.2 0.1\nFig. 7 Left: The first nodes of the octree example from Fig. 2 in memory connected by pointers. Data is stored as one float denoting occupancy. Right: The complete tree from Fig. 2 as compact serialized bitstream. All maximum-likelihood occupancy information can be stored\nserially in only six bytes, using two bits for each of a node\u2019s eight child\nlabels (00: unknown; 01: occupied; 10: free; 11: inner node with child\nnext in the stream).\nFig. 8 UML diagram of the most common octree and node classes.\nray casting. The main occupancy octree class OcTree derives from OccupancyOcTreeBase using OcTreeNode for its\nnodes. This structure allows for flexible extensions of our\nframework at different levels, e.g., to extend nodes with custom data or to add new functionality to the octree. One example is the implementation of ColorOcTree that uses ColorOcTreeNodes (illustrated in Fig. 5). These nodes store\ncolor in addition to an occupancy estimate, as introduced\nin Sect. 3.5.1.\nThe maximum tree depth is limited to 16 levels in our\n\n\n\ncurrent implementation. This enables fast tree traversals by\nusing computable voxel addresses. However, the depth limit\nalso poses a limit on the maximum spatial extent of the octree. At a resolution of 1 cm, for example, the map can cover\na maximum of 216 \u00d70.01m = 655.36m in each dimension.\nWhile this is sufficient for most indoor applications, the implementation can directly be extended to 32 depth levels,\nallowing to cover 232 \u00d70.01m = 42 949 672.96m at a resolution of 1 cm.\n4.3 Map File Generation\nMany robotic applications require maps to be stored in files.\nThis includes cases where a map is generated during a setup\nphase and is later used by mobile robots for path planning\nOctoMap: An Efficient Probabilistic 3D Mapping Framework Based on Octrees 9\nand localization. Another scenario is a multi-robot system\nwhere maps are exchanged between robots. In either case,\na compact serialized representation is required to minimize\nthe consumption of disk space or communication bandwidth.\nThe most compact files can be generated whenever a\nmaximum likelihood estimate of the map is sufficient for the\ntask at hand. In this case the per-node probabilities are discarded. As motivated above, volumes in which no information has been recorded can be of special interest in robotic\nsystems, for example, during exploration. For this reason,\nwe explicitly differentiate between free and unknown areas\nand encode nodes as either occupied, free, unknown, or as\ninner nodes in our map files. Using these labels, octree maps\ncan be recursively encoded as a compact bit stream. Each\nnode is represented only by the eight labels of its children.\nBeginning at the root node, each child that is not a leaf is\nrecursively added to the bit stream. Leaf nodes do not have\nto be added since they can be reconstructed from their label\nduring the decoding process. Figure 7 (right) illustrates the\nbit-stream encoding. Each row represents one node with the\nupper row corresponding to the root node. The last row only\ncontains leafs so no further nodes are added.\nIn this maximum likelihood representation, each node\noccupies 16 bits of memory, 2 bits per child, resulting in a\ncompact map file. In our experiments, file sizes never exceeded 15 MB even for large outdoor environments at a fine\nresolution (see Sect. 5.4 for details).\nThere exist applications in which all information in a\nmap needs to be stored and maintained. This includes cases\nin which hard disk space is used as a secondary memory and\nmaps are temporarily saved to disk until they need to be accessed again. Another use case is the storage of additional\nnode data such as color or terrain information which would\n\n\n\nbe lost in a maximum likelihood encoding. In these cases,\nwe encode nodes by storing their data (occupancy and additional data) and eight bits per node which specify whether\na child node exists. This, however, results in considerably\nlarger files as we will show in the experiments.\nNote that, analog to the octree representation in memory, the serialized stream does not contain any actual 3D\ncoordinates. To reconstruct a map, only the location of the\nroot node needs to be known. All other spatial relationships\nbetween the nodes are implicitly stored in the encoding.\n4.4 Our OctoMap Implementation\nOctoMap is available as a self-contained C++ library. It is\nreleased under the BSD-license and can be obtained from\nhttp://octomap.github.com. The source code is thoroughly\ndocumented and the library uses CMake to support several\nplatforms (Linux and Mac OS X with GCC, Windows with\nFig. 9 The OctoMap visualization application octovis\nMinGW or Visual Studio). Within the Robot Operating System (ROS), OctoMap is available as a pre-compiled Debian\npackage, e.g., for the Ubuntu distribution1\n. Further ROS integration is available in the packages octomap ros and octomap msgs.\nOctoMap can be easily integrated into any other framework by compiling and linking against it with the help\nof pkg-config, or with the find package mechanism in the\nCMake build system.\nAn OpenGL-based 3D visualization application is available along with the library to view stored octree files and to\nincrementally build up maps from range data, which eases\ntroubleshooting and map data inspection (see Fig. 9). It also\noffers basic editing functionality.\n4.4.1 Integrating Sensor Measurements\nIndividual range measurements are integrated using raycasting by calling the method insertRay(\u00b7) of the occupancy\noctree class OcTree. This updates the end point of the measurement as occupied while all other voxels along a ray to\nthe sensor origin are updated as free.\nPoint clouds, e.g., from 3D laser scans or stereo cameras\nare integrated using insertScan(\u00b7). This batch operation has\nbeen optimized to be more efficient than tracing each single\nray from the origin.\nFinally, a single node in the octree can be updated with\na point measurement by calling updateNode(\u00b7).\n4.4.2 Accessing Data\nIndividual octree nodes can be accessed by searching for\ntheir coordinate. For efficient batch queries, our implementation provides iterators to traverse the octree analogous to a\nstandard C++ container class. With these iterators, all nodes,\n1 http://www.ros.org/wiki/octomap\n\n\n\n10 Armin Hornung et al.\nleaf nodes, or leaf nodes in a certain bounding box can be\nqueried or they can be filtered according to further criteria.\nRay intersection queries, i.e., casting a ray from an origin into a given direction until it hits an occupied volume,\nare an important use-case for a 3D map in robotics. This kind\nof query is used for visibility checks or to localize with range\nsensors. Thus, we provide this functionality in the castRay(\u00b7)\nmethod.\n5 Evaluation\nThe approach presented in this paper has been evaluated using several real world datasets as well as simulated ones.\nThe experiments are designed to verify that the proposed\nrepresentation is meeting the requirements formulated in the\nintroduction. More specifically, we demonstrate that our approach is able to adequately model various types of environments and that it is an updatable and flexible map structure\nthat can be compactly stored.\nFor evaluation, we used the current implementation of\nOctoMap 1.5.12\n. The evaluated datasets are available online3\nand can be converted from 3D point clouds into octree maps with the tool graph2tree, which also prints all\nnecessary statistics.\n5.1 Sensor Model for Laser Range Data\nOctoMap can be used with any kind of distance sensor, as\nlong as an inverse sensor model is available. Since our realworld datasets were mostly acquired with laser range finders, we employ a beam-based inverse sensor model which\nassumes that endpoints of a measurement correspond to obstacle surfaces and that the line of sight between sensor origin end endpoint does not contain any obstacles. The occupancy probability of all volumes is initialized to the uniform prior of P(n) = 0.5. To efficiently determine the map\ncells which need to be updated, a ray-casting operation is\nperformed that determines voxels along a beam from the\nsensor origin to the measured endpoint. For efficiency, we\nuse a 3D variant of the Bresenham algorithm to approximate\nthe beam (Amanatides and Woo, 1987). Volumes along the\nbeam are updated as described in Sect. 3.2 using the following inverse sensor model:\nL(n | zt) = (\nlocc if beam is reflected within volume\nlfree if beam traversed volume\n(7)\nThroughout our experiments, we used log-odds values of\nlocc = 0.85 and lfree = \u22120.4, corresponding to probabilities\nof 0.7 and 0.4 for occupied and free volumes, respectively.\n2 https://github.com/OctoMap/octomap/archive/v1.5.3.tar.gz\n3 http://ais.informatik.uni-freiburg.de/projects/datasets/octomap surface sensor\nsurface\nsensor\n\n\n\nFig. 10 A laser scanner sweeps over a flat surface at a shallow angle by\nrotating. A cell measured occupied in the first scan (top) is updated as\nfree in the following scan (bottom) after the sensor rotated. Occupied\ncells are visualized as gray boxes, free cells are visualized in white.\nFig. 11 A simulated noise-free 3D laser scan (left) is integrated into\nour 3D map structure. Sensor sweeps at shallow angles lead to undesired discretization effects (center). By updating each volume at most\nonce, the map correctly represents the environment (right). For clarity,\nonly occupied cells are shown.\nThe clamping thresholds are set to lmin = \u22122 and lmax = 3.5,\ncorresponding to the probabilities of 0.12 and 0.97. We experimentally determined these values to work best for our\nuse case of mapping mostly static environments with laser\nrange finders, while still preserving map updatability for occasional changes. By adapting these changeable thresholds,\na stronger compression can be achieved. As we will evaluate\nin Sect. 5.6, there is a trade-off between map confidence and\ncompression.\nDiscretization effects of the ray-casting operation can\nlead to undesired results when using a sweeping laser range\nfinder. During a sensor sweep over flat surfaces at shallow\nangles, volumes measured occupied in one 2D scan may be\nmarked as free in the ray-casting of following scans. This\neffect is illustrated in Fig. 10. Such undesired updates usually creates holes in the modeled surface, as shown in the\nexample in Fig. 11. To overcome this problem, we treat a\ncollection of scan lines in a sensor sweep from the same location as single 3D point cloud in our mapping approach.\nSince measurements of laser scanners usually result from\nreflections at obstacle surfaces, we ensure that the voxels\ncorresponding to endpoints are updated as occupied. More\nprecisely, whenever a voxel is updated as occupied according to Eq. (7), it is not updated as free in the same measurement update of the map. By updating the map in this way,\nthe described effect can be prevented and the environment is\nrepresented accurately, as can be seen in Fig. 11 (right).\nOctoMap: An Efficient Probabilistic 3D Mapping Framework Based on Octrees 11\n5.2 3D Models from Real Sensor Data\nIn this experiment, we demonstrate the ability of our approach to model real-world environments. A variety of different datasets has been used. Note that the free space was\nexplicitly modeled in the experiments but is not shown in\nthe figures for clarity.\nThe indoor dataset called FR-079 corridor was recorded\nusing a Pioneer2 AT platform equipped with a SICK LMS\nlaser range finder on a pan-tilt unit. We reduced odometry\nerrors by applying a 3D scan matching approach. The robot\ntraversed the corridor of building 079 at the Freiburg campus three times, resulting in 66 3D scans with 6 million end\npoints in total. When processing this dataset, we limited the\n\n\n\nmaximum range of the laser beams to 10 m. This removes\nstray measurements outside of the building which were observed through windows. Figure 12 shows the resulting map.\nA fairly large outdoor dataset was recorded at the computer science campus in Freiburg4\n. It consists of 81 dense\n3D scans covering an area of 292m \u00d7 167m along a trajectory of 723 m. This dataset contains a total of 20 million end points. In a further experiment, we used laser range\ndata of the New College data set (Smith et al., 2009) (Epoch\nC, 14 million end points in total). This data was recorded\nin a large-scale outdoor environment with two fixed laser\nscanners sweeping to the left and right side of the robot\nas it advances. For this dataset, an optimized estimate of\nthe robot\u2019s trajectory generated by visual odometry was\nused (Sibley et al., 2009). The resulting outdoor maps are\nshown in Fig. 13.\nFinally, we integrated data of the freiburg1 360 RGBDdataset into our map representation with a total of 210\nmillion end points from the Microsoft Kinect sensor (see\nSect. 3.5.1). The final map, visualized in Fig. 5, represents\nan office environment at a resolution of 2 cm. In this map,\nwe additionally stored per-voxel color information.\n5.3 Map Accuracy\nThis experiment demonstrates how accurate a 3D map represents the data that was used to build that map. Note that this\nparticular evaluation is independent of the underlying octree structure since our mapping approach is able to model\nthe same data as a 3D grid. We measure the accuracy as\nthe percentage of correctly mapped cells in all 3D scans. A\n3D map cell counts as correctly mapped, if it has the same\nmaximum-likelihood state (free or occupied) in the map and\nthe evaluated 3D scan. The scan is hereby treated as if it\nwere inserted into the already-built map, i.e., endpoints must\nbe occupied and all cells along a ray between the sensor and\n4 Courtesy of B. Steder, available at\nhttp://ais.informatik.uni-freiburg.de/projects/datasets/fr360/\nMap dataset Accuracy Cross-validation\nFR-079 corridor (5 cm) 97.27% 96.00%\nFreiburg campus (10 cm) 97.89% 95.80%\nNew College (Ep. C) (10 cm) 98.79% 98.46%\nTable 1 Map accuracy and cross-validation as percentage of correctly\nmapped cells between evaluated 3D scans and the built map. For the\naccuracy, we used all scans for map construction and evaluation. For\ncross-validation, we used 80% of all scans to build the map, and the\nremaining 20% for evaluation.\nthe endpoint must be free. As a second measure, we crossvalidate the map by skipping each 5th scan when building\n\n\n\nthe map, and using these skipped scans to evaluate the percentage of correctly mapped cells.\nThe results in Table 1 show that our mapping approach\naccurately represents the environment. The remaining error\nis most likely due to sensor noise, discretization effects, or a\nnot completely perfect scan alignment. The cross-validation\nresults only lose little accuracy, which demonstrates that the\nprobabilistic sensor model yields realistic and predictive results.\n5.4 Memory Consumption\nIn this experiment, we evaluate the memory consumption\nof our approach. Several datasets were processed at various tree resolutions. We analyzed the memory usage of our\nrepresentation with and without performing octree compression, as well as the maximum-likelihood compression that\nconverts each node to be either completely free or occupied.\nFor comparison, we also determined the amount of memory that would be required by an optimally aligned 3D grid\nof minimal size that is initialized linearly in memory. According to Sect. 4.1, the memory consumption of occupancy\nstored in an octree on a 32-bit architecture is given by\nmemtree = ninner \u00d740B+nleafs \u00d78B , (8)\nwhere ninner is the number of inner nodes and nleafs the number of leaf nodes. The size of the minimal 3D grid storing the\nsame information (one float for the occupancy probability)\nis given by\nmemgrid =\nx\u00d7y\u00d7z\nr\n3\n4B , (9)\nwhere x, y,z is the size of the map\u2019s minimal bounding box\nin each dimension and r is the map resolution.\nWe furthermore wrote each map to disk using the full\nprobabilistic model and the compressed binary format described in Sect. 4.3, and evaluated the resulting file sizes.\nThe memory usage for exemplary resolutions is given\nin Table 2. It can be seen that high compression ratios can\nbe achieved especially in large outdoor environments. Here,\n12 Armin Hornung et al.\nFig. 12 3D map of the FR-079 corridor dataset, as seen from the top. The structure of the adjacent rooms has been partially observed through the\nglass doors (size of the scene: 43.7m\u00d718.2m\u00d73.3m).\nFig. 13 Resulting octree maps of two outdoor environments at 0.2 m resolution. For clarity, only occupied volumes are shown with height visualized by a color (gray scale) coding. Top: Freiburg campus dataset (size of the scene: 292m\u00d7167m\u00d728m), bottom: New College dataset (size of\nthe scene: 250m\u00d7161m\u00d733m).\nOctoMap: An Efficient Probabilistic 3D Mapping Framework Based on Octrees 13\nMemory w. octree compression [MB] File size [MB]\nMap dataset Mapped area [m3\n] Res. [cm] Mem. 3D grid [MB] None Pruned Max. likelih. Full Lossy\n\n\n\nFR-079 corridor 43.7\u00d718.2\u00d73.3 5 78.88 73.55 41.62 24.72 15.76 0.67\n10 10.01 10.87 7.22 5.02 2.70 0.14\nFreiburg campus 292\u00d7167\u00d728 10 5162.90 1257.57 990.66 504.76 379.70 13.82\n20 648.52 187.93 130.24 74.12 49.68 2.00\n80 10.58 4.55 4.12 3.09 1.53 0.08\nNew College (Ep. C) 250\u00d7161\u00d733 10 5058.76 607.92 395.42 230.33 148.75 6.40\n20 633.64 91.33 50.57 35.95 18.65 0.99\n80 10.13 2.34 1.79 1.69 0.63 0.05\nfreiburg1 360 (RGBD) 7.9\u00d77.3\u00d74.6 2 252.99\u2217 159.97\u2217 45.52\u2217 20.05 21.59\u2217 0.52\n5 16.19\u2217 11.24\u2217 4.55\u2217 2.52 2.11\u2217 0.07\nTable 2 Memory consumption of different octree compression types compared to full 3D occupancy maps (called 3D grid) on a 32-bit architecture.\nOctree compression in memory is achieved by merging identical children into the parent node (called Pruned). A more efficient but more lossy\ncompression in memory is achieved by converting each node to its maximum-likelihood value (completely free or occupied) followed by pruning\nthe complete tree. A maximum-likelihood tree containing only free and occupied nodes can then be serialized to a compact binary file format\n(called Lossy file). (\u2217\n): Voxels contain the full color information from the RGBD dataset.\npruning will merge considerable amounts of free space volumes and areas of unknown space don\u2019t use any memory.\nNote that a 3D grid of the outdoor data sets with a resolution of 10 cm would not even fit into the addressable main\nmemory of a 32-bit machine. On the other hand, our map\nstructure is also able to model fine-graded indoor environments with moderate memory requirements. In very confined spaces, an optimally aligned 3D grid may take less\nmemory than an uncompressed mapping octree. However,\nthis effect is diminished as soon as compression techniques\nare used.\nThe evolution of memory consumption over time is\nshown in Fig. 14. Memory usage grows when the robot explores new areas (scans 1\u201322 and 39\u201344 in FR-079 corridor,\nscans 1\u201350 and 65\u201381 in Freiburg campus). In the remaining\ntime, previously mapped areas were revisited where memory usage remained nearly constant or even decreased due\nto pruning.\nAs expected, memory usage increases exponentially\nwith the tree resolution. This effect can be seen in Fig. 15,\nwhere we used a logarithmic scaling in the plot.\nTable 2 gives the file sizes of the serialized binary maximum likelihood map (denoted as \u201cLossy\u201d) and the full\nprobabilistic model (\u201cFull\u201d). Note that map files can be\ncompressed even further by using standard file compression methods. Even maps of the fairly large outdoor datasets\nFreiburg campus and New College result in file sizes of less\nthan 14 MB.\n5.5 Runtimes\nIn the following experiments, we analyzed the time required\nto integrate and access data in our framework. All runtimes\n10 20 30 40 50 60\n\n\n\n0\n50\n100\nScan number\nMemory [MB]\nFR-079 corridor (5 cm res.)\nFull 3D grid\nNo compression\nOctree compression\nML octree compression\n20 40 60 80\n0\n200\n400\n600\nScan number\nMemory [MB]\nFreiburg campus (20 cm res.)\nFull 3D grid\nNo compression\nOctree compression\nML octree compression\nFig. 14 Memory usage while mapping the two data sets FR-079 corridor and Freiburg campus.\nwere evaluated on a single core of a standard desktop CPU\n(Intel Core i7-2600, 3.4 GHz) for various map data sets.\n5.5.1 Map Generation\nFirst, we analyzed the time required to generate maps by\nintegrating range data. This time depends on the map resolution and the length of the beams that are integrated. We\nprocessed the FR-079 corridor and Freiburg campus datasets\nboth with the full laser range (up to 50 m) and with a limited\n14 Armin Hornung et al.\n0.1 0.2 0.4 0.8 1 2\n100\n101\n102\n103\nResolution [m]\nMemory [MB]\nFull 3D grid\nNo compression\n\n\n\nOctree compression\nML Octree compression\nFig. 15 Effect of resolution on memory usage of the Freiburg campus\ndataset. Note that a logarithmic scaling is used.\nmaximum range of 10 m for several resolutions. The average\ninsert times for one beam are given in Fig. 16.\nIn our experiments, 3D scans usually consisted of about\n90 000 \u2013 250 000 valid measurements. Typically, such a scan\ncould be integrated into the map in less than a second. This\ndemonstrates that our current implementation can cope even\nwith the demanding data of RGBD-cameras that output up\nto 300 000 points at fast frame rates, albeit at shorter ranges.\nWith long measurement beams and large outdoor areas\nas in Freiburg campus dataset, a speedup can be obtained by\nlimiting the map update range. Indoors, however, where only\nfew sensor beams reach far, there is no noticeable speedup\nby limiting the sensor range.\n5.5.2 Map Queries\nWe evaluated the time to traverse all leaf nodes (free or occupied) in an existing map using iterators (see Sect. 4.4.2).\nThe depth of a query can be limited during run time which\nin our data structure is equivalent to a map query in a coarser\nmap. This allows for more efficient tree traversals in those\ncases when a coarser resolution is sufficient.\nFigure 17 shows the time to traverse several maps to\ntheir maximum tree depth of 16 corresponding to the full\nmap resolution (depth cutoff=0). The plot furthermore gives\nthe times to query all leaf nodes when the query depth is\nlimited. Each increment in the depth cutoff doubles the edge\nlength of the smallest voxels and speeds up the traversal by a\nfactor of about two. It can be seen that map traversals are efficient. Even at full map resolution, the large map of the Freiburg campus containing 1 087 014 occupied and 3 377 882\nfree leaf nodes can be traversed within 51 ms.\n5.6 Clamping parameters\nFinally, we analyzed the impact of the clamping thresholds\non map accuracy and compression. Since these thresholds\nprovide a lower and upper bound for the occupancy probability, information close to P = 0 and P = 1 is lost compared to the full map with no clamping. A clamped map\n0.1 0.2 0.4 0.8 1\n0\n2.5\n5\n7.5\n\n\n\n10\n\u00b710\u22123\nResolution [m]\nTime [ms]\nFreiburg campus\nFreiburg campus, trunc.\nFR-079 corridor\nFR-079 corridor, trunc.\nFig. 16 Average time to update an octree map by inserting one data\npoint for the datasets Freiburg campus and FR-079 corridor. The truncated versions insert rays up to a maximum sensor range of 10 m only.\n0 1 2 3 4\n10\n20\n30\n40\n50\nDepth cutoff\nTime [ms]\nFreiburg campus (20 cm)\nNew College (20 cm)\nFR-079 corridor (5 cm)\nFig. 17 Time to traverse all octree leaf nodes in several maps. By limiting the depth of the query (called depth cutoff) a coarser map is traversed.\nrepresents an approximation of the full map, thus we use the\nKullback-Leibler divergence (KLD) summed over the complete map as measure. Since occupancy is a binary random\nvariable with the discrete states free and occupied, the KLD\nof a clamped map Mc from the full map Mf can be computed\nby summing over all map nodes n:\nKLD(Mf\n,Mc) = (10)\n\u2211n\n\u0010\nln\u0010\nP(n)\nQ(n)\n\u0011\nP(n) +ln\u0010\n1\u2212P(n)\n1\u2212Q(n)\n\u0011\n(1\u2212P(n))\u0011\n\n\n\n,\nwhere P(n) is the occupancy probability of node n in Mf\n,\nand Q(n) in Mc.\nThe results for a series of occupancy ranges\nfrom [0 : 1] (no clamping, lossless) to [0.4 : 0.6] (strong\nclamping, most loss) and different maps can be seen\nin Fig. 18. The values for our chosen default threshold [0.12 : 0.97] are shown as thin horizontal lines, dashed\nblue for the memory consumption and red for the KLD.\nThis clamping range was chosen primarily to work best in\nthe context of laser-based mapping and occasional changes\nin the environment, such as people moving through the\nscans or doors closing. As can be seen, a stronger compression can be achieved with higher clamping, at the cost of\nlosing map confidence. In the most degenerated case, one\nsensor update can be enough to mark a voxel as completely\nOctoMap: An Efficient Probabilistic 3D Mapping Framework Based on Octrees 15\n[0:\n1]\n[0.05:\n0.95]\n[0.1:\n0.9]\n[0.15:\n0.85]\n[0.2:\n0.8]\n[0.25:\n0.75]\n[0.3:\n0.7]\n[0.35:\n0.65]\n[0.4:\n0.6]\n0\n2\n4\n6\n8\n\u00b7105\n\n\n\nOccupancy range\nKLD\nFR-079 corridor (5 cm res.)\nKLD\nMemory\nMemory with clamping\n[0.12:0.97]\nKLD with clamping [0.12:0.97] 30\n40\n50\n60\nMemory [MB]\n[0:\n1]\n[0.05:\n0.95]\n[0.1:\n0.9]\n[0.15:\n0.85]\n[0.2:\n0.8]\n[0.25:\n0.75]\n[0.3:\n0.7]\n[0.35:\n0.65]\n[0.4:\n0.6]\n0\n2\n4\n6\n8\n\u00b7105\nOccupancy range\nKLD\nFreiburg campus (20 cm res.)\nKLD\n\n\n\nMemory\nMemory with clamping\n[0.12:0.97]\nKLD with clamping\n[0.12:0.97] 80\n100\n120\nMemory [MB]\n[0:\n1]\n[0.05:\n0.95]\n[0.1:\n0.9]\n[0.15:\n0.85]\n[0.2:\n0.8]\n[0.25:\n0.75]\n[0.3:\n0.7]\n[0.35:\n0.65]\n[0.4:\n0.6]\n0\n1\n2\n\u00b7106\nOccupancy range\nKLD\nNew College (20 cm res.)\nKLD\nMemory\nMemory with clamping [0.12:0.97]\nKLD with clamping [0.12:0.97] 40\n60\n80\nMemory [MB]\n\n\n\nFig. 18 Effect of different clamping ranges on map compression and\naccuracy in our three datasets. A higher clamping, resulting in a\nsmaller occupancy range, increases the efficiency of the octree compression (memory consumption, dashed blue). The Kullback-Leibler\ndivergence (KLD, red) measures the information loss between the unclamped map with full probabilities in [0:1] and a clamped representation. Our default clamping range [0.12:0.97] is shown for comparison\nby horizontal lines in blue (dashed) for memory consumption and red\nfor the KLD.\nfree or occupied, losing any ability to filter noise with a\nprobabilistic update. Note that, while clamping is beneficial\nfor map compression, even with no clamping the lossless\ncompressed maps are smaller than a 3D grid (cf. Table 2).\n6 Case Studies\nSince its first introduction in 2010 (Wurm et al., 2010), the\nOctoMap framework received a considerable interest and\nhas been used in several applications. These include 6D localization (Hornung et al., 2010), autonomous navigation\nwith air vehicles (Heng et al., 2011; Muller et al. \u00a8 , 2011),\nautonomous navigation with humanoid robots (O\u00dfwald\net al., 2012; Maier et al., 2012), 3D exploration (Shade\nand Newman, 2011; Dornhege and Kleiner, 2011), 3D\nSLAM (Hertzberg et al., 2011), 3D arm navigation (Ciocarlie et al., 2010), semantic mapping (Blodow et al., 2011),\nand navigation in cluttered environments (Hornung et al.,\n2012).\nIn the following, we will describe some of these use\ncases in more detail in order to demonstrate the versatility\nand ease of integration of the OctoMap library.\n6.1 Localization in 3D\nIn our previous work (Hornung et al., 2010), we developed\na localization method based on OctoMap as 3D environment model. In this approach, the 6D torso pose of a humanoid robot in a complex indoor environment is tracked\nwith Monte Carlo localization based on 2D laser range\nmeasurements, as well as IMU and joint encoder data.\nFor the particle filter observation model, we first used the\nendpoint model and later an optimized ray-casting method\nin combination with visual observations for local refinement (O\u00dfwald et al., 2012). The resulting localization is\nhighly accurate and even enables the humanoid to climb spiral staircases. Our implementation is available open-source5\nand uses the ray-casting functionality in OctoMap (see\nSect. 4.4.2). This enables the re-use for other robot localization systems.\n6.2 Tabletop Manipulation\nThe ROS collider package6 builds a collision map based\non 3D point clouds. Sensor data from several sources, such\nas a tilting laser and a stereo camera, are fused using OctoMap. Octree nodes were extended to store a time stamp\nattribute that allows to gradually clear out nodes in dynamically changing environments. This new collision map enables the ROS arm navigation and grasping pipeline (Ciocarlie et al., 2010) to dynamically react to changes and to\n\n\n\ncope with sensor noise. In contrast to the previous fixed-size\nvoxel grid, the new implementation allows for an initially\nunbounded workspace, the integration of data from multiple\nsensors, and it is more memory-efficient.\n5 http://www.ros.org/wiki/humanoid localization\n6 http://www.ros.org/wiki/collider\n16 Armin Hornung et al.\n6.3 Navigation in Cluttered Environments\nOctoMap was furthermore used to create a navigation module for mobile manipulation. In this project, a PR2 robot\npicked up large objects from one table with two arms and\ncarried it to another table through narrow passages (Hornung et al., 2012). The system integrates 3D sensor data\nin OctoMap. The resulting 3D occupancy map is then used\nto perform collision checks based on the robot\u2019s full kinematic configuration and the attached objects. Multi-layered\nprojected 2D maps and an anytime planner using motion primitives allow for planning in almost real time with\nbounded sub-optimality. The navigation system and incremental mapping framework based on OctoMap are both\navailable open-source in ROS7\n.\n7 Conclusion\nIn this paper, we presented OctoMap, an open source framework for three-dimensional mapping. Our approach uses\nan efficient data structure based on octrees that enables a\ncompact memory representation and multi-resolution map\nqueries. Using probabilistic occupancy estimation, our approach is able to represent volumetric 3D models that include free and unknown areas. The proposed approach uses\na bounded per-volume confidence that allows for a lossless compression scheme and leads to substantially reduced\nmemory usage. We evaluated our approach with various\nreal-world data sets. The results demonstrate that our approach is able to model the environment in an accurate way\nand, at the same time, minimizes memory requirements.\nOctoMap can easily be integrated into robotic systems\nand has already been successfully applied in a variety of\nrobotic projects. The implementation is available as BSDlicensed C++ source code. Data sets are available online to\nverify our experimental results and to compare against them.\nAcknowledgements The authors would like to thank J. Muller, \u00a8\nS. O\u00dfwald, R.B. Rusu, R. Schmitt, and C. Sprunk for the fruitful discussions and their contributions to the OctoMap library.\nReferences\nAmanatides J, Woo A (1987) A fast voxel traversal algorithm for ray\ntracing. In: Proceedings of Eurographics, Amsterdam, The Netherlands\nBlodow N, Goron L, Marton Z, Pangercic D, Ruhr T, Tenorth M, Beetz\nM (2011) Autonomous semantic mapping for robots performing everyday manipulation tasks in kitchen environments. In: Proc. of the\nIEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS)\n7 http://www.ros.org/wiki/3d navigation\nand http://www.ros.org/wiki/octomap server\n\n\n\nBotsch M, Wiratanaya A, Kobbelt L (2002) Efficient high quality rendering of point sampled geometry. In: EGRW \u201902: Proc. of the 13th\nEurographics workshop on Rendering, pp 53\u201364\nCiocarlie M, Hsiao K, Jones EG, Chitta S, Rusu RB, Sucan IA (2010)\nTowards reliable grasping and manipulation in household environments. In: Intl. Symposium on Experimental Robotics (ISER)\nCole D, Newman P (2006) Using laser range data for 3D SLAM in\noutdoor environments. In: Proc. of the IEEE Int. Conf. on Robotics\n& Automation (ICRA)\nDornhege C, Kleiner A (2011) A frontier-void-based approach for autonomous exploration in 3D. In: IEEE International Symposium on\nSafety, Security and Rescue Robotics (SSRR)\nDouillard B, Underwood J, Melkumyan N, Singh S, Vasudevan S,\nBrunner C, Quadros A (2010) Hybrid elevation maps: 3D surface\nmodels for segmentation. In: Proc. of the IEEE/RSJ Int. Conf. on\nIntelligent Robots and Systems (IROS)\nDryanovski I, Morris W, Xiao J (2010) Multi-volume occupancy grids:\nAn efficient probabilistic 3D mapping model for micro aerial vehicles. In: Proc. of the IEEE/RSJ Int. Conf. on Intelligent Robots and\nSystems (IROS)\nEinhorn E, Schroter C, Gro\u00df HM (2011) Attention-driven monocu- \u00a8\nlar scene reconstruction for obstacle detection, robot navigation and\nmap building. Robotics & Autonomous Systems 59(5):296\u2013309\nElseberg J, Borrmann D, Nuchter A (2011) Efficient processing of \u00a8\nlarge 3d point clouds. In: Proc. of the XXIII Int. Symp. on Information, Communication and Automation Technologies (ICAT \u201911)\nEndres F, Hess J, Engelhard N, Sturm J, Cremers D, Burgard W (2012)\nAn evaluation of the RGB-D SLAM system. In: Proc. of the IEEE\nInt. Conf. on Robotics & Automation (ICRA)\nFairfield N, Kantor G, Wettergreen D (2007) Real-time SLAM with\noctree evidence grids for exploration in underwater tunnels. Journal\nof Field Robotics\nFournier J, Ricard B, Laurendeau D (2007) Mapping and exploration\nof complex environments using persistent 3D model. In: Computer\nand Robot Vision, 2007. Fourth Canadian Conf. on, pp 403\u2013410\nGirardeau-Montaut D, Roux M, Marc R, Thibault G (2005) Change\ndetection on points cloud data acquired with a ground laser scanner.\nInternational Archives of the Photogrammetry, Remote Sensing and\nSpatial Information Sciences 36:30\u201335\nGutmann JS, Fukuchi M, Fujita M (2008) 3D perception and environment map generation for humanoid robot navigation. Int J Rob Res\n27(10):1117\u20131134\nHabbecke M, Kobbelt L (2007) A surface-growing approach to multiview stereo reconstruction. In: Proc. of the IEEE Conf. on Computer\nVision and Pattern Recognition (CVPR)\nHadsell R, Bagnell JA, Hebert M (2009) Accurate rough terrain estimation with space-carving kernels. In: Proc. of Robotics: Science\nand Systems (RSS)\n\n\n\nHebert M, Caillas C, Krotkov E, Kweon IS, Kanade T (1989) Terrain mapping for a roving planetary explorer. In: Proc. of the IEEE\nInt. Conf. on Robotics & Automation (ICRA)\nHeng L, Meier L, Tanskanen P, Fraundorfer F, Pollefeys M (2011) Autonomous obstacle avoidance and maneuvering on a vision-guided\nMAV using on-board processing. In: Proc. of the IEEE Int. Conf. on\nRobotics & Automation (ICRA)\nHertzberg C, Wagner R, Birbach O, Hammer T, Frese U (2011) Experiences in building a visual slam system from open source components. In: Proc. of the IEEE Int. Conf. on Robotics & Automation\n(ICRA)\nHoppe H, DeRose T, Duchamp T, Mcdonald J, Stuetzle W (1992)\nSurface reconstruction from unorganized points. SIGGRAPH Computer Graphics 26(2):71\u201378\nHornung A, Wurm KM, Bennewitz M (2010) Humanoid robot localization in complex indoor environments. In: Proc. of the IEEE/RSJ\nInt. Conf. on Intelligent Robots and Systems (IROS)\nOctoMap: An Efficient Probabilistic 3D Mapping Framework Based on Octrees 17\nHornung A, Phillips M, Jones EG, Bennewitz M, Likhachev M,\nChitta S (2012) Navigation in three-dimensional cluttered environments for mobile manipulation. In: Proc. of the IEEE Int. Conf. on\nRobotics & Automation (ICRA)\nKammerl J, Blodow N, Rusu RB, Gedikli S, Beetz M, Steinbach EG\n(2012) Real-time compression of point cloud streams. In: Proc. of\nthe IEEE Int. Conf. on Robotics & Automation (ICRA)\nKelly A, Stentz A, Amidi O, Bode M, Bradley DM, Diaz-Calderon\nA, Happold M, Herman H, Mandelbaum R, Pilarski T, Rander P,\nThayer S, Vallidis N, Warner R (2006) Toward reliable off road\nautonomous vehicles operating in challenging environments. J of\nRobotics Research 25(5-6):449\u2013483\nKraetzschmar G, Gassull G, Uhl K (2004) Probabilistic quadtrees for\nvariable-resolution mapping of large environments. In: Ribeiro MI,\nVictor SJ (eds) Proc. of the 5th IFAC/EURON Symposium on Intelligent Autonomous Vehicles, Lisbon, Portugal\nKrainin M, Henry P, Ren X, Fox D (2011) Manipulator and object\ntracking for in-hand 3d object modeling. J of Robotics Research\n30(11):1311\u20131327\nLaine S, Karras T (2010) Efficient sparse voxel octrees. In: ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games\nMagnusson M, Duckett T, Lilienthal AJ (2007) Scan registration\nfor autonomous mining vehicles using 3D-NDT. Journal of Field\nRobotics 24(10):803\u2013827\nMaier D, Hornung A, Bennewitz M (2012) Real-time navigation in 3d\nenvironments based on depth camera data. In: Proc. of the IEEERAS Int. Conf. on Humanoid Robots (Humanoids)\nMason J, Ricco S, Parr R (2011) Textured occupancy grids for monocular localization without features. In: Proc. of the IEEE Int. Conf. on\nRobotics & Automation (ICRA)\nMeagher D (1982) Geometric modeling using octree encoding. Computer Graphics and Image Processing 19(2):129\u2013147\nMoravec H (1996) Robot spatial perception by stereoscopic vision and\n3D evidence grids. Tech. Rep. CMU-RI-TR-96-34, Robotics Institute, Pittsburgh, PA\n\n\n\nMoravec H, Elfes A (1985) High resolution maps from wide angle\nsonar. In: Proc. of the IEEE Int. Conf. on Robotics & Automation\n(ICRA), St. Louis, MO, USA, pp 116\u2013121\nMuller J, Kohler N, Burgard W (2011) Autonomous miniature blimp \u00a8\nnavigation with online motion planning and re-planning. In: Proc. of\nthe IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS)\nNewcombe R, Izadi S, Hilliges O, Molyneaux D, Kim D, Davison\nA, Kohli P, Shotton J, Hodges S, Fitzgibbon A (2011) KinectFusion: Real-time dense surface mapping and tracking. In: Mixed and\nAugmented Reality (ISMAR), 2011 10th IEEE International Symposium on, IEEE, pp 127\u2013136\nNuchter A, Lingemann K, Hertzberg J, Surmann H (2007) 6D \u00a8\nSLAM\u20143D mapping outdoor environments: Research articles. J\nField Robot 24(8-9):699\u2013722\nO\u00dfwald S, Hornung A, Bennewitz M (2012) Improved proposals for\nhighly accurate localization using range and vision data. In: Proc. of\nthe IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS)\nPathak K, Birk A, Poppinga J, Schwertfeger S (2007) 3D forward sensor modeling and application to occupancy grid based sensor fusion.\nIn: Proc. of the IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS)\nPayeur P, Hebert P, Laurendeau D, Gosselin C (1997) Probabilistic octree modeling of a 3-d dynamic environment. In: Proc. of the IEEE\nInt. Conf. on Robotics & Automation (ICRA)\nPfaff P, Triebel R, Stachniss C, Lamon P, Burgard W, Siegwart\nR (2007) Towards mapping of cities. In: Proc. of the IEEE\nInt. Conf. on Robotics & Automation (ICRA), Rome, Italy\nRoth-Tabak Y, Jain R (1989) Building an environment model using\ndepth information. Computer 22(6):85\u201390\nRyde J, Hu H (2010) 3D mapping with multi-resolution occupied voxel\nlists. Autonomous Robots 28(2):169\u2013185\nSchnabel R, Klein R (2006) Octree-based point-cloud compression. In:\nSymposium on Point-Based Graphics 2006, Eurographics\nShade R, Newman P (2011) Choosing where to go: Complete 3D exploration with stereo. In: Proc. of the IEEE Int. Conf. on Robotics\n& Automation (ICRA)\nSibley G, Mei C, Reid I, Newman P (2009) Adaptive relative bundle\nadjustment. In: Proc. of Robotics: Science and Systems (RSS)\nSmith M, Baldwin I, Churchill W, Paul R, Newman P (2009) The\nnew college vision and laser data set. International Journal for\nRobotics Research (IJRR) 28(5):595\u2013599, DOI http://dx.doi.org/10.\n1177/0278364909103911\nStoyanov T, Magnusson M, Andreasson H, Lilienthal AJ (2010) Path\nplanning in 3d environments using the normal distributions transform. In: Proc. of the IEEE/RSJ Int. Conf. on Intelligent Robots and\nSystems (IROS)\nSturm J, Engelhard N, Endres F, Burgard W, Cremers D (2012) A\n\n\n\nbenchmark for the evaluation of RGB-D slam systems. In: Proc. of\nthe IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS),\nhttp://cvpr.in.tum.de/data/datasets/rgbd-dataset/download\nSurmann H, Nuchter A, Hertzberg J (2003) An autonomous mobile \u00a8\nrobot with a 3d laser range finder for 3d exploration and digitalization of indoor environments. Robotics and Autonomous Systems\n45(3):181\u2013198\nTriebel R, Pfaff P, Burgard W (2006) Multi-level surface maps for outdoor terrain mapping and loop closing. In: Proc. of the IEEE/RSJ\nInt. Conf. on Intelligent Robots and Systems (IROS)\nWeise T, Wismer T, Leibe B, Van Gool L (2009) In-hand scanning with\nonline loop closure. In: ICCV Workshops\nWhelan T, Kaess M, Fallon M, Johannsson H, Leonard J, McDonald\nJ (2012) Kintinuous: Spatially extended KinectFusion. Tech. rep.,\nURL http://hdl.handle.net/1721.1/71756\nWilhelms J, Van Gelder A (1992) Octrees for faster isosurface generation. ACM Trans Graph 11(3):201\u2013227\nWurm KM, Hornung A, Bennewitz M, Stachniss C, Burgard W (2010)\nOctoMap: A probabilistic, flexible, and compact 3D map representation for robotic systems. In: Proc. of the ICRA 2010 Workshop on\nBest Practice in 3D Perception and Modeling for Mobile Manipulation\nWurm KM, Hennes D, Holz D, Rusu RB, Stachniss C, Konolige K,\nBurgard W (2011) Hierarchies of octrees for efficient 3d mapping.\nIn: Proc. of the IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS), San Francisco, CA, USA\nYguel M, Aycard O, Laugier C (2007a) Update policy of dense maps:\nEfficient algorithms and sparse representation. In: Field and Service\nRobotics, Results of the Int. Conf., FSR 2007, vol 42, pp 23\u201333\nYguel M, Keat CTM, Braillon C, Laugier C, Aycard O (2007b) Dense\nmapping for range sensors: Efficient algorithms and sparse representations. In: Proceedings of Robotics: Science and Systems\n\n\n"
  },
  {
    "id": "spawn_entity/5waystospeedupgazebo.txt",
    "content": "[ ![](https://assets-global.website-\nfiles.com/5e7b3ab65e9f113eadf770b4/5eba355ac3a6603c1730472c_nav%20bar%20BCR%20Logo.png)\n](/)\n\n[ BLOG ](/blog) CONTACT US\n\n#  5 Ways to Speedup Gazebo Simulations\n\n[ Leander D'Souza  ](https://www.linkedin.com/in/lsd)\n\nJuly 22, 2023\n\nRead time: 7 mins\n\n![LinkedIn Share](https://assets-global.website-\nfiles.com/5e7b3ab65e9f113eadf770b4/63fee6764dc16b62ab28a7c2_linkedinshare.png)\n![Twitter share icon](https://assets-global.website-\nfiles.com/5e7b3ab65e9f113eadf770b4/63fee44ee101659b03501b2c_twittershareicon.png)\n\nAs you may know, we at Black Coffee Robotics love Gazebo and [ writ\n](https://blackcoffeerobotics.com/blog/migration-from-gazebo-classic-to-\nignition-with-ros-2) e [ quite ](https://blackcoffeerobotics.com/blog/ros-\nplugin-to-control-actors-in-gazebo-simulation) [ frequently\n](https://blackcoffeerobotics.com/blog/simulations-for-mobile-robots) [ about\nit ](https://blackcoffeerobotics.com/blog/gazebo-projection-of-occupancy-maps)\n. We\u00e2\u0080\u0099ve completed many varied and complex robotics projects in the past, and\nthe starting point for most of these projects was a gazebo simulation. We\u00e2\u0080\u0099ve\nsuccessfully simulated drones, boats, robot arms, and even fleets of 100+ AMRs\nin Gazebo.\n\nOne recurring challenge that we faced was Gazebo being slow and\ncomputationally heavy. Running your robot in a slow simulation environment has\na lot of downsides. These include the following issues:\n\n  1. Some time-sensitive control algorithms don\u00e2\u0080\u0099t work correctly or give an unstable result in a low real-time factor. \n  2. Difficulty in scaling to multiple robots (in case of fleets of robots) or more complex environmental features. \n  3. Difficulty in development with low-powered laptops. \n  4. Less visually appealing simulations due to frame rate drop. \n\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/64b52731e72d81d58780be86_1*ZlzeU62e5-A8yrVbFYYuOg.gif)\n\nGet ready to speed up your simulations in Gazebo.\n\nOver time we have come up with many optimizations to speed up Gazebo to solve\nthese problems.\n\n  1. Downscaling meshes \n  2. Hardware Acceleration in Docker \n  3. Efficient Spawning and Deletion of Models \n  4. Reducing Lighting Sources and Disabling Shadows \n  5. Other Optimizations \n\n##  Downscaling Meshes\n\nA standard practice of creating URDFs for robots is creating CAD files in\nsoftware like [ SolidWorks ](https://www.solidworks.com/) or [ Fusion360\n](https://www.autodesk.com/campaigns/education/fusion-360) and using their\nrespective [ URDF converters\n](https://wiki.ros.org/sw_urdf_exporter/Tutorials/Export%20an%20Assembly) . In\naddition, people import design meshes from popular free model libraries such\nas [ 3dWarehouse ](https://3dwarehouse.sketchup.com/?hl=en) and [ GrabCAD\n](https://grabcad.com/) .\n\nThese meshes imported have a very high face count and are not optimised for\nlaunch in Gazebo. The more complex mesh you spawn in Gazebo, the greater the\ncomputational time needed to determine potential collisions and rendering.\nTherefore, it is always good practice to downscale any mesh you import into\nthe simulator.\n\nTo provide context, [ Blender ](https://www.blender.org/) is an open-source 3D\ncreation suite with various modelling, animation, rendering, video editing,\nand more tools.\n\nWe use the [ Decimate Modifier function\n](https://docs.blender.org/manual/en/latest/modeling/modifiers/generate/decimate.html)\nto downscale meshes provided by the said suite to reduce the number of faces\nin the robotic meshes. There are mainly three types of methods by which you\ncan Decimate or modify.\n\nOut of the three subparts, the ideal method for our use case is the [ Collapse\n](https://docs.blender.org/manual/en/latest/modeling/modifiers/generate/decimate.html#collapse)\nfunction, which reduces meshes depending upon a ratio.\n\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/64b5273153f53e9be8777a79_1*t4kkXgSgV_dzAvGo9WKDzw.png)\n\nDecimate Modifier function in Blender indicating the three methods\n\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/64b52731f419e782ea8e7d10_1*6jnZV7heHPE1ANTWjyDVPg.gif)\n\nGradually downsizing the model using Collapse\n\nA simplistic model was chosen to downscale for a more pronounced effect;\nhowever, in reality, robot meshes and design meshes have a lot of faces to\nbegin with.\n\nThe order of magnitude of these faces is in the range of millions. Hence it\nresults in virtually no change in appearance after reducing the model ratio\nsignificantly. Depending upon your mesh size, this method can boost your\nsimulation substantially.\n\nHowever, as shown in the above demonstration, there is a slight tradeoff in\ncollision checking. In addition, if your algorithm depends on accurately\ndetermining the contours of the said object in question, then it is a good\nidea not to reduce the Collapse ratio significantly.\n\n##  Hardware Acceleration in Docker\n\nSince we work on varying ROS and ROS2 distros simultaneously, we do all our\ndevelopment in Docker. If you plan on running Gazebo or even Rviz in Docker,\nGPU support is essential to get the best results. ROS has a nice tutorial for\n[ hardware acceleration\n](https://wiki.ros.org/docker/Tutorials/Hardware%20Acceleration) for dockers.\nParaphrasing the important parts:\n\n**For Nvidia systems:**\n\n  * Configure [ Nvidia Container Toolkit ](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/k8s/containers/container-toolkit) with your Docker from the following documentation [ page ](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#setting-up-nvidia-container-toolkit) . \n  * Add the following environment variables to your Dockerfile on build: \n\n> # nvidia-container-runtimeENV NVIDIA_VISIBLE_DEVICES \\  \n>  ${NVIDIA_VISIBLE_DEVICES:-all}  \n>  ENV NVIDIA_DRIVER_CAPABILITIES \\  \n>  ${NVIDIA_DRIVER_CAPABILITIES:+$NVIDIA_DRIVER_CAPABILITIES,}graphics\n\n  * Finally, configure your container to use Nvidia GPU Drivers: \n\n> docker run -it --privileged --net=host \\  \n>  \\--name test_image_container \\  \n>  \\--env=\"QT_X11_NO_MITSHM=1\" \u00c2 \\  \n>  \\--env=\"DISPLAY\" \u00c2 \\  \n>  \\--runtime=nvidia \\  \n>  test_image:latest\n\n**For Intel systems:**\n\n  * Install the following drivers in your Dockerfile: \n\n> apt-get -y install libgl1-mesa-glx libgl1-mesa-dri\n\n  * Finally, configure your container to use Intel GPU Drivers: \n\n> docker run -it --privileged --net=host \\ \u00c2 \u00c2  \n>  \\--name test_image_container \\  \n>  \\--env=\"QT_X11_NO_MITSHM=1\" \u00c2 \\  \n>  \\--env=\"DISPLAY\" \u00c2 \\  \n>  \\--volume=/tmp/.X11-unix:/tmp/.X11-unix \\  \n>  \\--device=/dev/dri:/dev/dri \\  \n>  test_image:latest\n\nThis dramatically improves the simulation by achieving much higher rendering\nframe rates, increases Gazebo\u00e2\u0080\u0099s real-time factor and reduces CPU load.\n\n##  Efficient Spawning and Deletion of Models\n\nA simplistic way to spawn and delete models is to use the [ SpawnModel\n](https://docs.ros.org/en/noetic/api/gazebo_msgs/html/srv/SpawnModel.html) and\n[ DeleteModel\n](https://docs.ros.org/en/noetic/api/gazebo_msgs/html/srv/DeleteModel.html)\nservices provided by Gazebo ROS API.\n\nAs you can see below, there is a slight delay in spawning these gazebo models.\nThis is the same case while deleting the models as well.\n\nThis seems like little, but when cascaded between hundreds of obstacles, this\nwill significantly impede the loading time of your simulation as well as the\nlogical aspect of it.\n\nTo efficiently tackle this issue, we use the [ WorldPlugin\n](https://classic.gazebosim.org/tutorials?tut=plugins_world&cat=write_plugin)\nprovided by Gazebo. This removes the cooldown when you spam the ros service to\nspawn or delete models. This is because the plugin provides access to all the\nmodels in the scene and gives us a more direct API to the system. As a result,\nwe can instantly generate and delete all models with ease.\n\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/64b5286fcbe1d79cfdece5d1_output_1_.gif)\n\nComparison of two spanning methods\n\n##  Reducing Lighting Sources and Disabling Shadows\n\nAn abundance of lighting sources in simulation is a significant cause for\nlowering the real-time factor in Gazebo.\n\nMake sure to use minimal light sources as long as your perception algorithms\nperform optimally. Only proceed to add sources of directional light if you\ncannot modify the default Sun model\u00e2\u0080\u0099s range and attenuation parameters to\nachieve your end cause.\n\nThe performance of vision-based algorithms such as image segmentation using\nDeep Learning Models or Visual SLAM depends on the amount of light in the\nenvironment, so this method will not be very useful in those cases. If your\nuse case does not cover vision-based methods of approach, then the above\nsolution may prove helpful.\n\nDisabling shadows also boosts the rendering FPS, especially when launching the\nsimulation in CPU-only modes.  \nTo disable shadows, modify the scene attributes as follows:\n\n> <scene>  \n>  <shadows>0</shadows>  \n>  <grid>false</grid>  \n>  <origin_visual>false</origin_visual>  \n>  </scene>\n\nIn addition, you can further limit aesthetic features in your simulation by\nremoving the origin visual and embedded grid in the default world provided.\nThis tip will trade off a bit of aesthetics for performance, so you should\nskip this while recording your next viral demo video.\n\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/64b527317cecc42ec57edbd0_1*-aSvjT7QKVM31_xyjSYVKg.png)\n\nBefore and After: Disabling Shadows, embedded grid and origin visuals\n\n##  Other Optimizations\n\nThese are very minimal steps and good practices that can be applied to your\nGazebo world.\n\n###  Setting the initial pose of your camera\n\nOn every launch, it is tedious to match the Gazebo Camera to face the model\nyou are working on in the Simulation.\n\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/64b5273153f53e9be8777a75_1*9QBE4bvQZVRYQ5fgCKcLtA.gif)\n\nAdjusting time to get the camera facing the model\n\nTo correct this, we save the gazebo camera pose in the world file to save\npanning and zooming time.\n\n> <gui>  \n>  <camera name=\"gzclient_camera\"><pose>1.53 0 2.25 0 0.64\n> -3.1414</pose></camera>  \n>  </gui>\n\nThese are obtained by expanding the GUI section of the left World Tab and\nnoting down the camera pose values.\n\n###  Choosing the right hardware specifications to emulate\n\nWhether you are trying to mimic an AMR, AGV, or a Robotic Arm, it is\nimperative to determine which hardware properties of a real-life sensor you\nwant to emulate in Gazebo. The true bottleneck arises in simulating cameras,\npointclouds, and laser scans.\n\n####  **For Cameras and PointCloud Sensors**\n\n  * Reduction of max clipping distance \n  * Reducing update rate \n  * Limiting the horizontal and vertical field of view \n  * Downsizing the resolution of the output image (only for cameras) \n\n####  **For LiDAR sensors**\n\n  * Reducing maximum range \n  * Reducing update rate \n  * Adjusting angular resolution (ideally set to 1\u00c2\u00b0) \n  * Set the sample size as a multiple of your maximum range (ideally lower, the better for the Simulation).   \n\\- For instance, if your maximum angular range is 360\u00c2\u00b0, set the sample size\nto be a factor of 360, say 720 + 1 (to account for zero index) samples.\n\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/64b52731a94b48cb24d5a228_1*8bIyxSg8ycEY1sSkDhc0gQ.png)\n\nDownscale from 361 to 91 samples of maximum angular range.\n\nThere\u00e2\u0080\u0099s an obvious tradeoff with this method because it deviates the\nsimulation from real robots, and the behaviour of certain perception\nalgorithms can degrade many of the sensors it relies upon are low resolution.\n\n##  Conclusion\n\nThe methods mentioned here can only be applied for some use cases, as most\noptimizations are weighed against sensor accuracy and aesthetic design. So,\nchoose the methods here that match your use case.\n\nIn addition, several other controllable levers in the Gazebo ecosystem can\nimprove performance. However, such changes can be specific to the simulated\nrobotic system. For example, improving the performance of a robot arm while\nmaintaining the necessary physics update would be different from simulating a\n3D LiDAR in an outdoor scene.\n\nIf your work involves developing large or intricate simulations and your\nsystem needs a performance boost \u00e2\u0080\u0094 [ reach out to us\n](https://blackcoffeerobotics.com/#contact) !\n\n\u00e2\u0080\u008d\n\n**Read more**\n\n[ ROS MoveIt Servo with Kinova Arm  Read time 5 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/65cc9efae3f6ef644b5e32a3_kinova_sim.jpg)\n](/blog/ros-moveit-servo-with-kinova-arm)\n\n[ Unit Tests for Robotics Software: Quality over Quantity  Read time: 5 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/6571c648f6a21b27d239fb73_path_follower%20\\(1\\).jpg)\n](/blog/unit-tests-for-robotics-software-quality-over-quantity)\n\n[ 5 Ways to Speedup Gazebo Simulations  Read time: 7 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/64b52af1de8dcc67e648ed8f_sim_speed_thumb.jpg)\n](/blog/5-ways-to-speedup-gazebo-simulations)\n\n[ Migration from Gazebo Classic to Ignition with ROS\u00c2 2  Read time 4 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/649d7e725c2b81b728090ea3_image.png)\n](/blog/migration-from-gazebo-classic-to-ignition-with-ros-2)\n\n[ Webots with ROS: Simulation Overview  Read time 4 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/6481d2dec9c02d08e0b8454f_webots_mapping.png)\n](/blog/webots-with-ros-simulation-overview)\n\n[ ROS plugin to control Actors in Gazebo Simulation  Read time 4 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/642ead64f8ce14006b1b18ae_actor_gazebo_ros.jpg)\n](/blog/ros-plugin-to-control-actors-in-gazebo-simulation)\n\n[ How to become a robotics software engineer  Read time 5 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/641982ff80f7ef2c61002d68_zubin_arm_robot.jpeg)\n](/blog/how-to-become-a-robotics-software-engineer)\n\n[ 4 challenges in robotics product development  Read time 4 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/640c35aa3ecaf8c09c320117_rpd_cover_2.jpg)\n](/blog/4-challenges-in-robotics-product-development)\n\n[ Localization for Warehouse Autonomous Robots  Read time 6 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/6403a4a2a2b653579951dab3_warehouse_cov.gif)\n](/blog/localization-for-warehouse-autonomous-robots)\n\n[ Unity and ROS: Keeping it real  Read time 4 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/6403a2147ad4e057dfba6e2f_unityorch-0.png)\n](/blog/unity-and-ros-keeping-it-real)\n\n[ ROS1 robots in a ROS2 world  Read time 3 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/6403989d7d01f7212c247a19_ros12bridge.png)\n](/blog/ros1-robots-in-a-ros2-world)\n\n[ Our DevOps pipeline for a heterogeneous fleet of robots  Read time 4 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/640377df8a898d9b070ce13a_devopsmedium2.png)\n](/blog/our-devops-pipeline-for-a-heterogeneous-fleet-of-robots)\n\n[ Robot software: Beyond algorithms  Read time 5 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/640375087d01f73442215172_devops.png)\n](/blog/robot-software-beyond-algorithms)\n\n[ Gazebo: Projection of Occupancy Maps  Read time 5 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/64036b3f6fa970bc6e2d51e7_gzcover.png)\n](/blog/gazebo-projection-of-occupancy-maps)\n\n[ Simulations for mobile robots  Read time 5 mins  ![](https://assets-\nglobal.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/64035b16422e3a2855bb5668_anim-opt.gif)\n](/blog/simulations-for-mobile-robots)\n\n[ GPS based Localization for Self-Driving Robots  Read time 6 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/64033f2c5361e52d693b7c6f_gps_localization.png)\n](/blog/gps-based-localization-for-self-driving-robots)\n\n[ ROS and ROS2 Navigation Stacks: A performance review  Read time 7 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/63f90f613fc93f95c74a965a_ros1ros2nav.png)\n](/blog/ros-and-ros2-navigation-stacks-a-performance-review)\n\n[ ROS: Why What and How.  Read time 5 mins  ![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/63f633f92da6c307d732a5db_ros1logo.png)\n](/blog/ros-why-what-and-how)\n\n[ ROS: Core\u00c2 concepts  Read time 7 mins  ![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/63f633f92da6c307d732a5db_ros1logo.png)\n](/blog/ros-core-concepts)\n\n[ Robotics Product Development: Pitfalls you need to know  Read time 5 mins\n![](https://assets-global.website-\nfiles.com/63f4a8519ea24e0d8fb02a3d/63f90c056e2483866c71b685_rpdp.png)\n](/blog/robotics-product-development-learning)\n\n##  Contact Us\n\n##  Get in touch. Let us know how we can help.\n\n![contact@blackcoffeerobotics.com](https://assets-global.website-\nfiles.com/5e7b3ab65e9f113eadf770b4/5e7b549cf803a25889973e2d_email.png)\n\n[ contact@blackcoffeerobotics.com ](mailto:contact@blackcoffeerobotics.com)\n\n[ ![Twitter Link](https://assets-global.website-\nfiles.com/5e7b3ab65e9f113eadf770b4/60a00125f9cc8f85844407ba_Twitter%20social%20icons%20-%20rounded%20square%20-%20blue.png)\n](https://twitter.com/bcrllp) [ ![LinkendIn Link](https://assets-\nglobal.website-\nfiles.com/5e7b3ab65e9f113eadf770b4/640975263d2118947636e711_linkedinicon.png)\n](http://www.linkedin.com/company/blackcoffeerobotics)\n\n![location pin](https://assets-global.website-\nfiles.com/5e7b3ab65e9f113eadf770b4/5e7b549e46049e7283219cfe_location-pin.png)\n\n14, Raghava Enclave, Transport Road, Secunderabad, Hyderabad (500009)\n\n[ Careers ](/careers)\n\n| Copyright \u00c2\u00a9 2023 Black Coffee Robotics\n\n"
  },
  {
    "id": "setupbash/whydoesros2installse.txt",
    "content": "First time here? Check out the FAQ!\n\n  \nROS Resources: [ Documentation ](http://wiki.ros.org/) | [ Support\n](http://wiki.ros.org/Support) | [ Discussion Forum\n](http://discourse.ros.org/) | [ Index ](http://index.ros.org/) | [ Service\nStatus ](http://status.ros.org/) | [ ros @ Robotics Stack Exchange\n](https://robotics.stackexchange.com/questions/tagged/ros)  \n---  \n  \n_Attention:_ Answers.ros.org is deprecated as of August the 11th, 2023. Please\nvisit [ robotics.stackexchange.com ](http://robotics.stackexchange.com) to ask\na new question. This site will remain online in read-only mode during the\ntransition and into the foreseeable future. Selected questions and answers\nhave been migrated, and redirects have been put in place to direct users to\nthe corresponding questions on Robotics Stack Exchange. Additional details are\n[ available here ](https://discourse.ros.org/t/ros-and-gazebo-answers-\nmigration-to-robotics-stack-exchange-process/31494) .\n\n[ Hi there! Please sign in ](/account/signin/?next=/question/389464/why-does-\nros2-installsetupbash-source-ros1-and-ros2/) [ help ](/help/ \"help\")\n\n[ ![ROS Answers logo](/m/ros/media/images/logoros.png?v=28) ](/questions/)\n\n[ tags ](/tags/) [ users ](/users/) [ badges ](/badges/)\n\nThe site is read-only. Please transition to use Robotics Stack Exchange\n\n[ __ ](/questions/) |\n\n[ ALL ](/questions/scope:all/sort:activity-desc/page:1/) [ UNANSWERED\n](/questions/scope:unanswered/sort:answers-asc/page:1/)\n\n|\n\n|  [ Ask Your Question ](/questions/ask/)  \n---|---|---|---  \n  \n1\n\n#\n\nWhy Does ROS2 install/setup.bash Source ROS1 and ROS2\n\nedit\n\n  * [ ros2 ](/questions/scope:all/sort:activity-desc/tags:ros2/page:1/)\n\n  * [ setup.bash ](/questions/scope:all/sort:activity-desc/tags:setup.bash/page:1/)\n\n[ **asked 2021-10-26 22:24:57 -0500  ** ](/questions/389464/revisions/)\n\n[ ![jmadd gravatar image](/m/default/media/images/nophoto.png?v=27)\n](/users/5269/jmadd/)\n\n[ jmadd ](/users/5269/jmadd/)  \n11  \u25cf  2  \u25cf  2  \u25cf  4\n\nI have installed ROS1 **noetic** and ROS2 **foxy** on my system. I switch\nbetween them by commenting out the sourcing of either in my .bashrc file as\nfollows:\n\n    \n    \n    # ROS 1 Sourcing\n    # source opt/ros/noetic/setup.bash\n    # source ~/ros1_ws/devel/setup.bash\n    # source ~/catkin_ws/devel/setup.bash\n    \n    # ROS 2 Sourcing\n    source /opt/ros/foxy/setup.bash\n    source ~/ros2_ws/install/setup.bash\n    source /usr/share/colcon_argcomplete/hook/colcon-argcomplete.bash\n    \n\nI noticed however that even with ROS 1 sourcing commented out, it was being\nsourced as indicated by the following message every time I opened a terminal:\n\n    \n    \n    ROS_DISTRO was set to 'foxy' before. Please make sure that the environment does not mix paths from different distributions.\n    ROS_DISTRO was set to 'noetic' before. Please make sure that the environment does not mix paths from different distributions.\n    \n\nI traced the problem down to the ` install/setup.bash ` file in my ROS2\nworkspace which I source in .bashrc. It contains the following:\n\n    \n    \n    # source chained prefixes\n    # setting COLCON_CURRENT_PREFIX avoids determining the prefix in the sourced script\n    COLCON_CURRENT_PREFIX=\"/opt/ros/noetic\"\n    _colcon_prefix_chain_bash_source_script \"$COLCON_CURRENT_PREFIX/local_setup.bash\"\n    # setting COLCON_CURRENT_PREFIX avoids determining the prefix in the sourced script\n    COLCON_CURRENT_PREFIX=\"/home/ros-god/ros1_ws/devel\"\n    _colcon_prefix_chain_bash_source_script \"$COLCON_CURRENT_PREFIX/local_setup.bash\"\n    # setting COLCON_CURRENT_PREFIX avoids determining the prefix in the sourced script\n    COLCON_CURRENT_PREFIX=\"/opt/ros/foxy\"\n    _colcon_prefix_chain_bash_source_script \"$COLCON_CURRENT_PREFIX/local_setup.bash\"\n    \n    # source this prefix\n    # setting COLCON_CURRENT_PREFIX avoids determining the prefix in the sourced script\n    COLCON_CURRENT_PREFIX=\"$(builtin cd \"`dirname \"${BASH_SOURCE[0]}\"`\" > /dev/null && pwd)\"\n    _colcon_prefix_chain_bash_source_script \"$COLCON_CURRENT_PREFIX/local_setup.bash\"\n    \n    unset COLCON_CURRENT_PREFIX\n    unset _colcon_prefix_chain_bash_source_script\n    \n\nAs you can see, it is sourcing noetic and then sourcing foxy. Why? Did I set\nsomething up incorrectly? I confirmed that I can comment out the line where it\nsources **noetic** and I get exactly the behavior I want but I am not\ncomfortable with a solution that has me modifying an auto-generated file.\n\nAny help is greatly appreciated!!!\n\n[ edit ](/questions/389464/edit/) [ retag ](/s/questions/389464/retag/) flag\noffensive  [ close ](/questions/389464/close/) merge  delete\n\n##  Comments\n\n1\n\nI suspect that both ROS 1 and ROS 2 are being sourced because of the [\nros1_bridge ](https://github.com/ros2/ros1_bridge) .\n\nHow did you install ROS 2 Foxy?\n\n[ ![jacobperron gravatar\nimage](/upfiles/avatars/jacobperron/resized/16/avatar.jpeg)\n](/users/26373/jacobperron/) [ jacobperron ](/users/26373/jacobperron/) (\n2021-11-01 17:24:49 -0500  )  edit\n\nadd a comment\n\n##  1  Answer\n\nSort by \u00bb  [ oldest  ](/question/389464/why-does-ros2-installsetupbash-source-\nros1-and-ros2/?sort=oldest#sort-top) [ newest  ](/question/389464/why-does-\nros2-installsetupbash-source-ros1-and-ros2/?sort=latest#sort-top) [ most voted\n](/question/389464/why-does-ros2-installsetupbash-source-ros1-and-\nros2/?sort=votes#sort-top)\n\n0\n\n[ **answered 2021-11-03 04:15:13 -0500  ** ](/answers/389914/revisions/)\n\n[ ![rodrigo55 gravatar\nimage](/upfiles/avatars/rodrigo55/resized/32/Screenshot%20from%202020-03-30%2015-03-17.png)\n](/users/53015/rodrigo55/)\n\n[ rodrigo55 ](/users/53015/rodrigo55/)  \n156  \u25cf  2  \u25cf  9  \u25cf  8\n\nIf you have both distributions already installed correctly, you can just\ncreate a new workspace and that will only source foxy.\n\nI don't know why your ` setup.bash ` file in your ` ros2_ws ` has references\nto noetic, it was probably done while following a tutorial on sourcing two\ndistributions in one workspace?\n\nAnyway, you can just do\n\n    \n    \n    mkdir -p ~/new_ros2_ws/src\n    cd ~/new_ros2_ws\n    colcon build\n    \n\nIf you then look at the ` setup.bash ` from this new workspace, it won't have\nnoetic sourced, and you can add this one to your ` bashrc ` .\n\nIf you want an in depth explanation you can check out this video I made: [\nhttps://www.youtube.com/watch?v=TIMJ-...\n](https://www.youtube.com/watch?v=TIMJ-WL_lGU)\n\n[ edit ](/s/answers/389914/edit/) flag offensive  delete  [ link\n](/question/389464/why-does-ros2-installsetupbash-source-ros1-and-\nros2/?answer=389914#post-id-389914 \"permanent link\") more\n\n  *   * \n\n##  Comments\n\nThis will only work if the OP hasn't actually already added an auto- ` source\n` of both ` setup.bash ` files to his shell configuration.\n\nWhich could be _why_ he is in the situation he's currently in.\n\n[ ![gvdhoorn gravatar image](/upfiles/avatars/gvdhoorn/resized/16/4550046.png)\n](/users/5184/gvdhoorn/) [ gvdhoorn ](/users/5184/gvdhoorn/) (  2021-11-03\n04:24:11 -0500  )  edit\n\nadd a comment\n\n##  Question Tools\n\nFollow\n\n1 follower\n\n[ subscribe to rss feed ](/feeds/question/389464/ \"subscribe to the rss feed\")\n\n##  Stats\n\nAsked: ** 2021-10-26 22:24:57 -0500  **\n\nSeen: **2,101 times**\n\nLast updated: **Nov 03 '21**\n\n##  Related questions\n\n[ Create Dockerfile for ros2 package : ament_cmake error\n](/question/319610/create-dockerfile-for-ros2-package-ament_cmake-error/)\n\n[ ROS2 nodes launched with systemd aren't discovered\n](/question/389577/ros2-nodes-launched-with-systemd-arent-discovered/)\n\n[ Getting the rclcpp::Duration in microseconds ](/question/399382/getting-the-\nrclcppduration-in-microseconds/)\n\n[ how to debug a ros2 python launch file ](/question/412294/how-to-debug-a-\nros2-python-launch-file/)\n\n[ Can we use MQTT in ROS2? [closed] ](/question/369262/can-we-use-mqtt-in-\nros2/)\n\n[ Unable to build sim_ros2_interface for CoppeliaSim\n](/question/409032/unable-to-build-sim_ros2_interface-for-coppeliasim/)\n\n[ Multiple Micro-Ros MCUs over the same serial ](/question/385747/multiple-\nmicro-ros-mcus-over-the-same-serial/)\n\n[ Why there is no timestamp field in sensor_msgs ? ](/question/338345/why-\nthere-is-no-timestamp-field-in-sensor_msgs/)\n\n[ Min and max value with ROS2 Parameter ](/question/311922/min-and-max-value-\nwith-ros2-parameter/)\n\n[ what is the use of --symlink-install in ROS2 colcon build?\n](/question/371822/what-is-the-use-of-symlink-install-in-ros2-colcon-build/)\n\n[ ![cc-by-sa](/m/default/media/images/cc-by-sa.png?v=28)\n](http://creativecommons.org/licenses/by-sa/3.0/legalcode) ROS Answers is\nlicensed under Creative Commons Attribution 3.0 Content on this site is\nlicensed under a [ Creative Commons Attribution Share Alike 3.0\n](http://creativecommons.org/licenses/by-sa/3.0/legalcode) license.\n\n[ about ](/about/) |  [ faq ](/faq/) |  [ help ](/help/ \"help\") |  [ privacy\npolicy ](/privacy/) |  [ terms of service ](/terms/)\n\n[ Powered by Askbot version 0.10.2 ](http://askbot.com)\n\nPlease note: ROS Answers requires javascript to work properly, please enable\njavascript in your browser, [ here is how\n](https://www.google.com/support/bin/answer.py?answer=23852)\n\n[ ![ gravatar image]() ]() [ ]() (  2024-04-18 17:31:33 -0500  )  edit\n\n[ none ](/questions/scope:all/sort:activity-desc/tags:none/page:1/) \u00d7\n\n  *[\n              2021-10-26 22:24:57 -0500\n             ]: 2021-10-26 22:24:57 -0500\n  *[\n             2021-11-01 17:24:49 -0500\n            ]: 2021-11-01 17:24:49 -0500\n  *[\n              2021-11-03 04:15:13 -0500\n             ]: 2021-11-03 04:15:13 -0500\n  *[\n             2021-11-03 04:24:11 -0500\n            ]: 2021-11-03 04:24:11 -0500\n  *[\n        2021-10-26 22:24:57 -0500\n       ]: 2021-10-26 22:24:57 -0500\n  *[\n        2024-04-18 17:31:33 -0500\n       ]: 2024-04-18 17:31:33 -0500\n\n"
  },
  {
    "id": "spawn_gui/gazebomaincc.txt",
    "content": "/*\n * Copyright (C) 2012 Open Source Robotics Foundation\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n*/\n#ifndef _WIN32\n#include <sys/wait.h>\n#include <unistd.h>\n#include <signal.h>\n#include <sys/types.h>\n#else\n#include <process.hpp>\n#include <signal.h>\n#endif\n#include \"gazebo/common/Console.hh\"\n#include \"gazebo/Server.hh\"\n#include \"gazebo/gui/GuiIface.hh\"\n/////////////////////////////////////////////////\nvoid help()\n{\n  std::cerr << \"gazebo -- Run the Gazebo server and GUI.\\n\\n\";\n  std::cerr << \"`gazebo` [options] <world_file>\\n\\n\";\n  std::cerr << \"Gazebo server runs simulation and handles commandline \"\n    << \"options, starts a Master, runs World update and sensor generation \"\n    << \"loops. This also starts the Gazebo GUI client in a separate \"\n    << \"process.\\n\\n\";\n  std::cerr << \"Options:\\n\"\n  << \"  -v [ --version ]              Output version information.\\n\"\n  << \"  --verbose                     Increase the messages written to the \"\n\n\n\n  <<                                  \"terminal.\\n\"\n  << \"  -h [ --help ]                 Produce this help message.\\n\"\n  << \"  -u [ --pause ]                Start the server in a paused state.\\n\"\n  << \"  -e [ --physics ] arg          Specify a physics engine \"\n  << \"(ode|bullet|dart|simbody).\\n\"\n  << \"  -p [ --play ] arg             Play a log file.\\n\"\n  << \"  -r [ --record ]               Record state data.\\n\"\n  << \"  --record_encoding arg (=zlib) Compression encoding format for log \"\n  << \"data \\n\"\n  << \"                                (zlib|bz2|txt).\\n\"\n  << \"  --record_path arg             Absolute path in which to store \"\n  << \"state data.\\n\"\n  << \"  --record_period arg (=-1)     Recording period (seconds).\\n\"\n  << \"  --record_filter arg           Recording filter (supports wildcard and \"\n  << \"regular expression).\\n\"\n  << \"  --record_resources           Recording with model meshes and \"\n  << \"materials.\\n\"\n  << \"  --seed arg                    Start with a given random number seed.\\n\"\n  << \"  --iters arg                   Number of iterations to simulate.\\n\"\n  << \"  --minimal_comms               Reduce the TCP/IP traffic output by \"\n  <<                                  \"gazebo.\\n\"\n  << \"  -g [ --gui-plugin ] arg       Load a System plugin (deprecated)\\n\"\n  << \"  --gui-client-plugin arg       Load a GUI plugin.\\n\"\n  << \"  -s [ --server-plugin ] arg    Load a server plugin.\\n\"\n  << \"  -o [ --profile ] arg          Physics preset profile name from the \"\n  << \"options in\\n\"\n  << \"                                the world file.\\n\"\n  << \"  --lockstep                    Lockstep simulation so sensor update \"\n  <<                                  \"rates are respected.\\n\"\n  << \"\\n\";\n}\n#ifndef _WIN32\nbool sig_killed = false;\nint status1, status2;\n// pid of server process\npid_t pid1;\n// pid of client process\npid_t pid2;\nbool killed1 = false;\nbool killed2 = false;\n\n\n\n/// \\brief Try to kill a single process.\n/// \\param[in] _pid Process ID.\n/// \\param[in] _name Process name.\n/// \\param[in] _waittime Total time to wait in seconds.\n/// \\param[in,out] _killed Set to true if process was successfully killed.\n/// \\param[in,out] _status Store status information for that process.\nstatic void kill_one_process(const int _pid, const std::string &_name,\n                             const double _waittime, bool &_killed,\n                             int &_status)\n{\n  kill(_pid, SIGINT);\n  double sleepSecs = 0.001;\n  // Wait some time and if not dead, escalate to SIGKILL\n  for (unsigned int i = 0; i < (unsigned int)(_waittime / sleepSecs); ++i)\n  {\n    if (_killed)\n    {\n      break;\n    }\n    else\n    {\n      int p = waitpid(_pid, &_status, WNOHANG);\n      if (p == _pid)\n      {\n        _killed = true;\n        break;\n      }\n    }\n    // Sleep briefly\n    gazebo::common::Time::Sleep(gazebo::common::Time(sleepSecs));\n  }\n  if (!_killed)\n  {\n    std::cerr << \"escalating to SIGKILL on \" << _name << std::endl;\n    kill(_pid, SIGKILL);\n  }\n}\n/////////////////////////////////////////////////\nvoid sig_handler(int /*signo*/)\n{\n\n\n\n  sig_killed = true;\n  kill_one_process(pid2, \"client\", 5.0, killed2, status2);\n  kill_one_process(pid1, \"server\", 5.0, killed1, status1);\n}\n/////////////////////////////////////////////////\nint main(int _argc, char **_argv)\n{\n  if (_argc >= 2 &&\n      (strcmp(_argv[1], \"-h\") == 0 || strcmp(_argv[1], \"--help\") == 0))\n  {\n    help();\n    return 0;\n  }\n  struct sigaction sigact;\n  sigact.sa_flags = 0;\n  sigact.sa_handler = sig_handler;\n  if (sigemptyset(&sigact.sa_mask) != 0)\n    std::cerr << \"sigemptyset failed while setting up for SIGINT\" << std::endl;\n  if (sigaction(SIGINT, &sigact, NULL))\n  {\n    std::cerr << \"Stopping. Unable to catch SIGINT.\\n\"\n              << \" Please visit http://gazebosim.org/support.html for help.\\n\";\n    return 0;\n  }\n  // The following was added in\n  // https://osrf-migration.github.io/gazebo-gh-pages/#!/osrf/gazebo/pull-requests/2923,\n  // but it is causing shutdown issues when gazebo is used with ros.\n  // if (sigaction(SIGTERM, &sigact, NULL))\n  // {\n  //   std::cerr << \"Stopping. Unable to catch SIGTERM.\\n\";\n  //   return 0;\n  // }\n  pid1 = fork();\n  char **argvServer = new char*[_argc+1];\n  char **argvClient = new char*[_argc+1];\n  argvServer[0] = const_cast<char*>(\"gzserver\");\n  argvClient[0] = const_cast<char*>(\"gzclient\");\n  for (int i = 1; i < _argc; ++i)\n  {\n    argvServer[i] = _argv[i];\n\n\n\n    argvClient[i] = _argv[i];\n  }\n  argvServer[_argc] = static_cast<char*>(NULL);\n  argvClient[_argc] = static_cast<char*>(NULL);\n  // Need to check the return of wait function (8 lines below) to know\n  // what should be returned by the process\n  int returnValue = 0;\n  if (pid1)\n  {\n    pid2 = fork();\n    if (pid2)\n    {\n      int child_exit_status;\n      pid_t dead_child = wait(&child_exit_status);\n      // WIFEXITED will return zero if the process finished not reaching\n      // return or exit calls.\n      // WEXITSTATUS will check the value of the return function, not being\n      // zero means problems.\n      if ((WIFEXITED(child_exit_status)   == 0) ||\n          (WEXITSTATUS(child_exit_status) != 0))\n        returnValue = -1;\n      else\n        returnValue = 0;\n      if (dead_child == pid1)\n        killed1 = true;\n      else if (dead_child == pid2)\n        killed2 = true;\n      // one of the children died\n      if (!sig_killed)\n        sig_handler(SIGINT);\n    }\n    else\n    {\n      // remove client from foreground process group\n      setpgid(0, 0);\n      execvp(argvClient[0], argvClient);\n    }\n  }\n  else\n  {\n\n\n\n    // remove server from foreground process group\n    setpgid(0, 0);\n    execvp(argvServer[0], argvServer);\n  }\n  delete[] argvServer;\n  delete[] argvClient;\n  return returnValue;\n}\n#else\nstd::atomic<bool> g_shouldExit = false;\nvoid sig_handler(int /*signo*/)\n{\n  g_shouldExit = true;\n}\nint main(int _argc, char **_argv)\n{\n  if (_argc >= 2 &&\n      (strcmp(_argv[1], \"-h\") == 0 || strcmp(_argv[1], \"--help\") == 0)) {\n    help();\n    return 0;\n  }\n  signal(SIGINT, sig_handler);\n  std::vector<std::string> argvServer;\n  std::vector<std::string> argvClient;\n  argvServer.push_back(\"gzserver\");\n  argvClient.push_back(\"gzclient\");\n  for (int i = 1; i < _argc; ++i)\n  {\n    argvServer.push_back(std::string(_argv[i]));\n    argvClient.push_back(std::string(_argv[i]));\n  }\n  // Start server\n  TinyProcessLib::Process server(argvServer);\n  // Start client\n  TinyProcessLib::Process client(argvClient);\n  // Wait\n  bool serverClosed = false;\n  bool clientClosed = false;\n  int serverExitCode = 0;\n  int clientExitCode = 0;\n\n\n\n  while (!g_shouldExit)\n  {\n    std::this_thread::sleep_for(std::chrono::milliseconds(20));\n    // Check if server and gui are still open, if they are closed\n    // close this process as well\n    serverClosed = server.try_get_exit_status(serverExitCode);\n    clientClosed = client.try_get_exit_status(clientExitCode);\n    if (serverClosed || clientClosed)\n    {\n      g_shouldExit = true;\n    }\n  }\n  // Cleanup\n  serverClosed = server.try_get_exit_status(serverExitCode);\n  if (!serverClosed)\n  {\n    server.kill();\n  }\n  clientClosed = client.try_get_exit_status(clientExitCode);\n  if (!clientClosed)\n  {\n    client.kill();\n  }\n  // Get exit status\n  serverExitCode = server.get_exit_status();\n  clientExitCode = client.get_exit_status();\n  int exitCode = 0;\n  if (serverExitCode != 0 || clientExitCode != 0)\n  {\n    exitCode = 1;\n  }\n  return exitCode;\n}\n#endif\n\n\n"
  },
  {
    "id": "realtime_control/28872.txt",
    "content": "[ The Construct ROS Community ](/)\n\n#  [ How to solve this ros2_control error? [ros2_control_node-1] what():\nAccording to the loaded plugin descriptions the class\nackermann_steering_controller/AckermannSteeringController with base class type\nhardware_interface::SystemInterface does not exist ](/t/how-to-solve-this-\nros2-control-error-ros2-control-node-1-what-according-to-the-loaded-plugin-\ndescriptions-the-class-ackermann-steering-controller-\nackermannsteeringcontroller-with-base-class-type-hardware-interface-\nsysteminterface-does-not-exist/28872)\n\n[ External Requests  ](/c/external-requests/50)\n\n[ 077bei004.aarjan  ](https://get-help.theconstruct.ai/u/077bei004.aarjan)\nFebruary 12, 2024, 5:39pm  1\n\nHello!\n\nI have been working on making a real hardware robot(car) with ackermann\nsteering with front steering and rear wheels for driving. I have managed to\nload my car on rviz2. I used ros2_controllers/ackermann_steering_controller\npackage for ros2_control for driving the car.\n\nThe launch files are written with reference from ros2_control documentation.\nThe documentation also contains the demo of ros2_control of different types of\nrobot, unfortunately there is no ros2_control_demo for robot with ackermann\nsteering controller.\n\nHowever I configured the ros2_controller/ackermann_steering_controller in my\nproject but it didnt work as expected and threw some errors at last of this\npost.\n\nEven with all of the ros2_control dependencies installed, the controller\nmanager seems to not be working. Every form on this same problem seems to be\nunsolved for people using the Humble version. Here are the logs and setup\n(sorry for the long post):\n\nParameters file for ackermann_steering_controller is written with reference of\nackermann_steering_controller and steering_controller_library from\nros2_controllers documentation.\n\n**Launch file for viewing the car only:**\n\n    \n    \n    from launch import LaunchDescription\n    from launch.actions import DeclareLaunchArgument\n    from launch.conditions import IfCondition from launch.substitutions import Command, FindExecutable, LaunchConfiguration, PathJoinSubstitution\n    from launch_ros.actions import Node\n    from launch_ros.substitutions import FindPackageShare\n    def generate_launch_description():\n    # Declare arguments\n    declared_arguments = []\n    declared_arguments.append(\n        DeclareLaunchArgument(\n            \"description_package\",\n            default_value=\"car_gazebo\",\n            description=\"Description package with robot URDF/xacro files. Usually the argument \\\n        is not set, it enables use of a custom description.\",\n        )\n    )\n    \n       declared_arguments.append(\n        DeclareLaunchArgument(\n            \"gui\",\n            default_value=\"true\",\n            description=\"Start Rviz2 and Joint State Publisher gui automatically \\\n        with this launch file.\",\n        )\n    )\n    \n       # Initialize Arguments\n    gui = LaunchConfiguration(\"gui\")\n    \n       # Get URDF via xacro\n    robot_description_content = Command(\n        [\n            PathJoinSubstitution([FindExecutable(name=\"xacro\")]),\n            \" \",\n            PathJoinSubstitution(\n                [\n                    FindPackageShare(\"car_gazebo\"),\n                    \"urdf\",\n                    \"car.urdf.xacro\",\n                ]\n            ),\n        ]\n    )\n    robot_description = {\"robot_description\": robot_description_content}\n    \n       joint_state_publisher_node = Node(\n        package=\"joint_state_publisher_gui\",\n        executable=\"joint_state_publisher_gui\",\n        condition=IfCondition(gui),\n    )\n    robot_state_publisher_node = Node(\n        package=\"robot_state_publisher\",\n        executable=\"robot_state_publisher\",\n        output=\"both\",\n        parameters=[robot_description],\n    )\n    rviz_node = Node(\n        package=\"rviz2\",\n        executable=\"rviz2\",\n        name=\"rviz2\",\n        output=\"log\",\n        condition=IfCondition(gui),\n    )\n    \n       nodes = [\n        joint_state_publisher_node,\n        robot_state_publisher_node,\n        rviz_node,\n    ]\n    \n       return LaunchDescription(declared_arguments + nodes)\n    \n\n**Launch file for running the car in real with ros2_control_node and\ncontroller_manager**\n\n    \n    \n    def generate_launch_description():\n    # Declare arguments\n    declared_arguments = []\n    declared_arguments.append(\n        DeclareLaunchArgument(\n            \"gui\",\n            default_value=\"true\",\n            description=\"Start RViz2 automatically with this launch file.\",\n        )\n    )\n    \n       # Initialize Arguments\n    gui = LaunchConfiguration(\"gui\")\n    \n       # Get URDF via xacro\n    robot_description_content = Command(\n        [\n            PathJoinSubstitution([FindExecutable(name=\"xacro\")]),\n            \" \",\n            PathJoinSubstitution(\n                [\n                    FindPackageShare(\"car_gazebo\"),\n                    \"urdf\",\n                    \"car.urdf.xacro\",\n                ]\n            ),\n        ]\n    )\n    \n       robot_description = {\"robot_description\": robot_description_content}\n    \n       robot_controllers = PathJoinSubstitution(\n        [\n            FindPackageShare(\"car_gazebo\"),\n            \"config\",\n            \"ackermann_steering_controller.yaml\",\n        ]\n    )\n    \n       # rviz_config_file = PathJoinSubstitution(\n    #     [FindPackageShare(\"car_gazebo\"), \"rrbot/rviz\", \"rrbot.rviz\"]\n    # )\n    \n       control_node = Node(\n        package=\"controller_manager\",\n        executable=\"ros2_control_node\",\n        parameters=[robot_description, robot_controllers],\n        output=\"both\",\n    )\n    \n       robot_state_pub_node = Node(\n        package=\"robot_state_publisher\",\n        executable=\"robot_state_publisher\",\n        output=\"both\",\n        parameters=[robot_description],\n    )\n    \n       rviz_node = Node(\n        package=\"rviz2\",\n        executable=\"rviz2\",\n        name=\"rviz2\",\n        output=\"log\",\n        condition=IfCondition(gui),\n    )\n    \n       joint_state_broadcaster_spawner = Node(\n        package=\"controller_manager\",\n        executable=\"spawner\",\n        arguments=[\"joint_state_broadcaster\",\n                   \"--controller-manager\", \"/controller_manager\"],\n    )\n    \n       robot_controller_spawner = Node(\n        package=\"controller_manager\",\n        executable=\"spawner\",\n        arguments=[\"ackermann_steering_base_controller\",\n                   \"--controller-manager\", \"/controller_manager\"],\n    )\n    \n       # Delay rviz start after `joint_state_broadcaster`\n    delay_rviz_after_joint_state_broadcaster_spawner = RegisterEventHandler(\n        event_handler=OnProcessExit(\n            target_action=joint_state_broadcaster_spawner,\n            on_exit=[rviz_node],\n        )\n    )\n    \n       # Delay start of robot_controller after `joint_state_broadcaster`\n    delay_robot_controller_spawner_after_joint_state_broadcaster_spawner = RegisterEventHandler(\n        event_handler=OnProcessExit(\n            target_action=joint_state_broadcaster_spawner,\n            on_exit=[robot_controller_spawner],\n        )\n    )\n    \n       nodes = [\n        control_node,\n        robot_state_pub_node,\n        joint_state_broadcaster_spawner,\n        delay_rviz_after_joint_state_broadcaster_spawner,\n        delay_robot_controller_spawner_after_joint_state_broadcaster_spawner,\n    ]\n    \n       return LaunchDescription(declared_arguments+nodes)\n    \n\n**Here is the parameters file for the ackermann_steering_controller package**\n\n    \n    \n    controller_manager:\n      ros__parameters:\n        update_rate: 30\n    \n        joint_state_broadcaster:\n          type: joint_state_broadcaster/JointStateBroadcaster\n    \n        ackermann_steering_base_controller:\n          type: ackermann_steering_controller/AckermannSteeringController\n    \n    ackermann_steering_base_controller:\n      ros__parameters:\n    \n        reference_timeout: 2.0\n        front_steering: true\n    \n        rear_wheels_names: [rear_left_wheel_joint, rear_right_wheel_joint]\n        front_wheels_names: [left_steering_joint, right_steering_joint]\n    \n        open_loop: false \n        velocity_rolling_window_size: 10\n    \n        publish_rate: 50.0\n        odom_frame_id: odom\n        base_frame_id: base_link\n    \n        enable_odom_tf: true\n    \n        twist_covariance_diagonal: [0.0, 7.0, 14.0, 21.0, 28.0, 35.0]\n        pose_covariance_diagonal: [0.0, 7.0, 14.0, 21.0, 28.0, 35.0]\n    \n        position_feedback: false\n        use_stamped_vel: false\n        \n        wheelbase: 0.46\n        front_wheel_track: 1.8\n        rear_wheel_track: 1.8\n        front_wheels_radius: 0.115\n        rear_wheels_radius: 0.115\n    \n\n**Here is CMakeLists.txt raw file**\n\n    \n    \n    cmake_minimum_required(VERSION 3.8)\n    \n    if(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\n      add_compile_options(-Wall -Wextra -Wpedantic)\n    endif()\n    \n    # find dependencies\n    find_package(ament_cmake REQUIRED)\n    # uncomment the following section in order to fill in\n    # further dependencies manually.\n    # find_package(<dependency> REQUIRED)\n    \n    \n    if(BUILD_TESTING)\n    find_package(ament_lint_auto REQUIRED)\n    # the following line skips the linter which checks for copyrights\n    # comment the line when a copyright and license is added to all source files\n    set(ament_cmake_copyright_FOUND TRUE)\n    # the following line skips cpplint (only works in a git repo)\n    # comment the line when this package is in a git repo and when\n    # a copyright and license is added to all source files\n    set(ament_cmake_cpplint_FOUND TRUE)\n    ament_lint_auto_find_test_dependencies()\n    endif()\n    \n    install(\n      DIRECTORY launch rviz config worlds transforms src urdf\n      DESTINATION share/${PROJECT_NAME}\n    )\n    \n    ament_package()\n    \n\n**Here is the ros2_control linked with hardware linked directly as specified\nin urdf of car.**\n\n    \n    \n    <ros2_control name=\"ackermann_ros2_control\" type=\"system\">\n        <hardware>\n          <plugin>ackermann_steering_controller/AckermannSteeringController</plugin>\n        </hardware>\n        <joint name=\"rear_left_wheel_joint\">\n            <command_interface name=\"velocity\" />\n            <state_interface name=\"position\" />\n            <state_interface name=\"velocity\" />\n        </joint>\n        <joint name=\"rear_right_wheel_joint\">\n            <command_interface name=\"velocity\" />\n            <state_interface name=\"position\" />\n            <state_interface name=\"velocity\" />\n        </joint>\n        <joint name=\"left_steering_joint\">\n            <command_interface name=\"position\" />\n            <state_interface name=\"position\" />\n            <state_interface name=\"velocity\" />\n        </joint>\n        <joint name=\"right_steering_joint\">\n            <command_interface name=\"position\" />\n            <state_interface name=\"position\" />\n            <state_interface name=\"velocity\" />\n        </joint>\n    </ros2_control>\n    \n\n**THIS IS THE ERORR!!!**\n\n    \n    \n    colcon build --symlink-install --allow-overriding ackermann_steering_controller ; source install/setup.bash ; ros2 launch car_gazebo car_bringup.launch.py \n    [1.045s] WARNING:colcon.colcon_ros.prefix_path.ament:The path '/home/aarjan/minor_ros/install/ackermann_drive_controller' in the environment variable AMENT_PREFIX_PATH doesn't exist\n    [1.045s] WARNING:colcon.colcon_ros.prefix_path.catkin:The path '/home/aarjan/minor_ros/install/ackermann_drive_controller' in the environment variable CMAKE_PREFIX_PATH doesn't exist\n    \n    Starting >>> ackermann_steering_controller\n    Starting >>> car_body\n    Starting >>> pubsub                                                                       \n    Finished <<< car_body [0.88s]                                                                                              \n    Finished <<< ackermann_steering_controller [1.08s]                                              \n    Starting >>> car_gazebo\n    Finished <<< car_gazebo [0.24s]                                              \n    Finished <<< pubsub [1.60s]   \n    \n    Summary: 4 packages finished [2.60s]\n    [INFO] [launch]: All log files can be found below /home/aarjan/.ros/log/2024-02-12-21-58-28-865613-robotics-25902\n    [INFO] [launch]: Default logging verbosity is set to INFO\n    [INFO] [ros2_control_node-1]: process started with pid [25905]\n    [INFO] [robot_state_publisher-2]: process started with pid [25907]\n    [INFO] [spawner-3]: process started with pid [25909]\n    [ros2_control_node-1] [WARN] [1707754409.129160634] [controller_manager]: [Deprecated] Passing the robot description parameter directly to the control_manager node is deprecated. Use '~/robot_description' topic from 'robot_state_publisher' instead.\n    \n    [ros2_control_node-1] [INFO] [1707754409.129328123] [resource_manager]: Loading hardware 'ackermann_ros2_control' \n    [ros2_control_node-1] terminate called after throwing an instance of 'pluginlib::LibraryLoadException'\n    [ros2_control_node-1]   what():  According to the loaded plugin descriptions the class ackermann_steering_controller/AckermannSteeringController with base class type hardware_interface::SystemInterface does not exist. Declared types are  fake_components/GenericSystem mock_components/GenericSystem test_hardware_components/TestSystemCommandModes test_hardware_components/TestTwoJointSystem test_system test_unitilizable_system turtlebot3_manipulation_hardware/TurtleBot3ManipulationSystemHardware\n    \n    [ros2_control_node-1] Stack trace (most recent call last):\n    [ros2_control_node-1] #16   Object \"\", at 0xffffffffffffffff, in \n    [ros2_control_node-1] #15   Object \"/opt/ros/humble/lib/controller_manager/ros2_control_node\", at 0x55fb7f788d84, in \n    [robot_state_publisher-2] [INFO] [1707754409.131011613] [robot_state_publisher]: got segment base_footprint\n    [robot_state_publisher-2] [INFO] [1707754409.131083738] [robot_state_publisher]: got segment base_link\n    [robot_state_publisher-2] [INFO] [1707754409.131088347] [robot_state_publisher]: got segment chassis\n    [robot_state_publisher-2] [INFO] [1707754409.131091102] [robot_state_publisher]: got segment front_left_wheel\n    [robot_state_publisher-2] [INFO] [1707754409.131093672] [robot_state_publisher]: got segment front_right_wheel\n    [robot_state_publisher-2] [INFO] [1707754409.131095965] [robot_state_publisher]: got segment left_steering_link\n    [robot_state_publisher-2] [INFO] [1707754409.131098241] [robot_state_publisher]: got segment rear_left_wheel\n    [robot_state_publisher-2] [INFO] [1707754409.131100390] [robot_state_publisher]: got segment rear_right_wheel\n    [robot_state_publisher-2] [INFO] [1707754409.131102542] [robot_state_publisher]: got segment right_steering_link\n    \n    [ros2_control_node-1] #14   Source \"../csu/libc-start.c\", line 392, in __libc_start_main_impl [0x7fcd9d629e3f]\n    [ros2_control_node-1] #13   Source \"../sysdeps/nptl/libc_start_call_main.h\", line 58, in __libc_start_call_main [0x7fcd9d629d8f]\n    [ros2_control_node-1] #12   Object \"/opt/ros/humble/lib/controller_manager/ros2_control_node\", at 0x55fb7f78889e, in \n    [ros2_control_node-1] #11   Object \"/opt/ros/humble/lib/libcontroller_manager.so\", at 0x7fcd9e0b5719, in controller_manager::ControllerManager::ControllerManager(std::shared_ptr<rclcpp::Executor>, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, rclcpp::NodeOptions const&)\n    [ros2_control_node-1] #10   Object \"/opt/ros/humble/lib/libcontroller_manager.so\", at 0x7fcd9e0b0e04, in controller_manager::ControllerManager::init_resource_manager(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)\n    [ros2_control_node-1] #9    Object \"/opt/ros/humble/lib/libhardware_interface.so\", at 0x7fcd9dd18d9d, in hardware_interface::ResourceManager::load_urdf(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool)\n    [ros2_control_node-1] #8    Object \"/opt/ros/humble/lib/libhardware_interface.so\", at 0x7fcd9dd171ce, in \n    [ros2_control_node-1] #7    Object \"/opt/ros/humble/lib/libhardware_interface.so\", at 0x7fcd9dcf832a, in \n    [ros2_control_node-1] #6    Object \"/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.30\", at 0x7fcd9daae4d7, in __cxa_throw\n    [ros2_control_node-1] #5    Object \"/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.30\", at 0x7fcd9daae276, in std::terminate()\n    [ros2_control_node-1] #4    Object \"/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.30\", at 0x7fcd9daae20b, in \n    [ros2_control_node-1] #3    Object \"/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.30\", at 0x7fcd9daa2b9d, in \n    [ros2_control_node-1] #2    Source \"./stdlib/abort.c\", line 79, in abort [0x7fcd9d6287f2]\n    [ros2_control_node-1] #1    Source \"../sysdeps/posix/raise.c\", line 26, in raise [0x7fcd9d642475]\n    [ros2_control_node-1] #0  | Source \"./nptl/pthread_kill.c\", line 89, in __pthread_kill_internal\n    [ros2_control_node-1]     | Source \"./nptl/pthread_kill.c\", line 78, in __pthread_kill_implementation\n    [ros2_control_node-1]       Source \"./nptl/pthread_kill.c\", line 44, in __pthread_kill [0x7fcd9d6969fc]\n    [ros2_control_node-1] Aborted (Signal sent by tkill() 25905 1000)\n    \n    [ERROR] [ros2_control_node-1]: process has died [pid 25905, exit code -6, cmd '/opt/ros/humble/lib/controller_manager/ros2_control_node --ros-args --params-file /tmp/launch_params_8qnwt2ax --params-file /home/aarjan/minor_ros/install/car_gazebo/share/car_gazebo/config/ackermann_steering_controller.yaml'].\n    [spawner-3] [INFO] [1707754411.348236298] [spawner_joint_state_broadcaster]: Waiting for '/controller_manager' node to exist\n    [spawner-3] [INFO] [1707754413.365302157] [spawner_joint_state_broadcaster]: Waiting for '/controller_manager' node to exist\n    [spawner-3] [INFO] [1707754415.384160723] [spawner_joint_state_broadcaster]: Waiting for '/controller_manager' node to exist\n    [spawner-3] [INFO] [1707754417.401642295] [spawner_joint_state_broadcaster]: Waiting for '/controller_manager' node to exist\n    [spawner-3] [ERROR] [1707754419.422091681] [spawner_joint_state_broadcaster]: Controller manager not available\n    [ERROR] [spawner-3]: process has died [pid 25909, exit code 1, cmd '/opt/ros/humble/lib/controller_manager/spawner joint_state_broadcaster --controller-manager /controller_manager --ros-args'].\n    [INFO] [spawner-4]: process started with pid [26024]\n    [INFO] [rviz2-5]: process started with pid [26026]\n    [rviz2-5] [INFO] [1707754419.880410912] [rviz2]: Stereo is NOT SUPPORTED\n    [rviz2-5] [INFO] [1707754419.880543949] [rviz2]: OpenGl version: 4.6 (GLSL 4.6)\n    [rviz2-5] [INFO] [1707754419.895533589] [rviz2]: Stereo is NOT SUPPORTED\n    \n    [rviz2-5] [WARN] [1707754419.957731402] [rcl.logging_rosout]: Publisher already registered for provided node name. If this is due to multiple nodes with the same name then all logs for that logger name will go out over the existing publisher. As soon as any node with that name is destructed it will unregister the publisher, preventing any further logs for that name from being published on the rosout topic.\n    [rviz2-5] [WARN] [1707754419.960753279] [rcl.logging_rosout]: Publisher already registered for provided node name. If this is due to multiple nodes with the same name then all logs for that logger name will go out over the existing publisher. As soon as any node with that name is destructed it will unregister the publisher, preventing any further logs for that name from being published on the rosout topic.\n    [spawner-4] [INFO] [1707754421.811967419] [spawner_ackermann_steering_base_controller]: Waiting for '/controller_manager' node to exist\n    [spawner-4] [INFO] [1707754423.832159604] [spawner_ackermann_steering_base_controller]: Waiting for '/controller_manager' node to exist\n    [spawner-4] [INFO] [1707754425.852644375] [spawner_ackermann_steering_base_controller]: Waiting for '/controller_manager' node to exist\n    [spawner-4] [INFO] [1707754427.872454754] [spawner_ackermann_steering_base_controller]: Waiting for '/controller_manager' node to exist\n    [spawner-4] [ERROR] [1707754429.893425903] [spawner_ackermann_steering_base_controller]: Controller manager not available\n    [ERROR] [spawner-4]: process has died [pid 26024, exit code 1, cmd '/opt/ros/humble/lib/controller_manager/spawner ackermann_steering_base_controller --controller-manager /controller_manager --ros-args'].\n    \n\n**This is the code from\nackermann_steering_controller/src/ackermann_steering_controller.cpp Maybe the\nproblem is causing due to**\n\n    \n    \n    #include \"pluginlib/class_list_macros.hpp\"\n    \n    // <controller_name_namespace>::<ControllerName>\n    // second the base class, controller_interface::ControllerInterface.\n    PLUGINLIB_EXPORT_CLASS(\n        ackermann_steering_controller::AckermannSteeringController,\n        controller_interface::ChainableControllerInterface)\n    \n\n**means that ackermann_steering_controller is exported with base class type as\ncontroller_interface::ChainableControllerInterface but ros2_control_node is\nexpecting it to be of base class type as\nhardware_interface::SystemInterface.**\n\nHow can I solve this, DO I modify the code in package file or do some other\nthings?\n\nCould you please help me tackling this error or have some solution that might\nhelp me\u2026\n\n**Thank You!**\n\n[ system  ](https://get-help.theconstruct.ai/u/system) Closed  February 22,\n2024, 5:40pm  2\n\nThis topic was automatically closed 10 days after the last reply. New replies\nare no longer allowed.\n\n  * [ Home ](/)\n  * [ Categories ](/categories)\n  * [ FAQ/Guidelines ](/guidelines)\n  * [ Terms of Service ](http://www.theconstructsim.com/terms_and_conditions/)\n  * [ Privacy Policy ](http://www.theconstructsim.com/privacy_policy/)\n\nPowered by [ Discourse ](https://www.discourse.org) , best viewed with\nJavaScript enabled\n\n"
  },
  {
    "id": "launch_moveit/ros2launchmoveitreso.txt",
    "content": "First time here? Check out the FAQ!\n\n  \nROS Resources: [ Documentation ](http://wiki.ros.org/) | [ Support\n](http://wiki.ros.org/Support) | [ Discussion Forum\n](http://discourse.ros.org/) | [ Index ](http://index.ros.org/) | [ Service\nStatus ](http://status.ros.org/) | [ ros @ Robotics Stack Exchange\n](https://robotics.stackexchange.com/questions/tagged/ros)  \n---  \n  \n_Attention:_ Answers.ros.org is deprecated as of August the 11th, 2023. Please\nvisit [ robotics.stackexchange.com ](http://robotics.stackexchange.com) to ask\na new question. This site will remain online in read-only mode during the\ntransition and into the foreseeable future. Selected questions and answers\nhave been migrated, and redirects have been put in place to direct users to\nthe corresponding questions on Robotics Stack Exchange. Additional details are\n[ available here ](https://discourse.ros.org/t/ros-and-gazebo-answers-\nmigration-to-robotics-stack-exchange-process/31494) .\n\n[ Hi there! Please sign in\n](/account/signin/?next=/question/394756/ros2-launch-\nmoveit_resources_fanuc_moveit_config-demolaunch/) [ help ](/help/ \"help\")\n\n[ ![ROS Answers logo](/m/ros/media/images/logoros.png?v=28) ](/questions/)\n\n[ tags ](/tags/) [ users ](/users/) [ badges ](/badges/)\n\nThe site is read-only. Please transition to use Robotics Stack Exchange\n\n[ __ ](/questions/) |\n\n[ ALL ](/questions/scope:all/sort:activity-desc/page:1/) [ UNANSWERED\n](/questions/scope:unanswered/sort:answers-asc/page:1/)\n\n|\n\n|  [ Ask Your Question ](/questions/ask/)  \n---|---|---|---  \n  \n1\n\n#\n\nros2 launch moveit_resources_fanuc_moveit_config demo.launch\n\nedit\n\n  * [ ros2_foxy ](/questions/scope:all/sort:activity-desc/tags:ros2_foxy/page:1/)\n\n  * [ demo.launch_moveit ](/questions/scope:all/sort:activity-desc/tags:demo.launch_moveit/page:1/)\n\n  * [ fanuc_ros ](/questions/scope:all/sort:activity-desc/tags:fanuc_ros/page:1/)\n\n  * [ foxy ](/questions/scope:all/sort:activity-desc/tags:foxy/page:1/)\n\n  * [ MoveIt2 ](/questions/scope:all/sort:activity-desc/tags:MoveIt2/page:1/)\n\n  * [ moveit2_tutorial ](/questions/scope:all/sort:activity-desc/tags:moveit2_tutorial/page:1/)\n\n[ **asked 2022-01-21 04:24:06 -0500  ** ](/questions/394756/revisions/)\n\n[ ![Manoj gravatar image](/m/default/media/images/nophoto.png?v=28)\n](/users/94358/manoj/)\n\n[ Manoj ](/users/94358/manoj/)  \n11  \u25cf  1  \u25cf  2  \u25cf  2\n\n[ **updated 2022-01-21 12:01:32 -0500  ** ](/questions/394756/revisions/)\n\n[ ![osilva gravatar image](/upfiles/avatars/osilva/resized/32/RG-logo.jpg)\n](/users/84086/osilva/)\n\n[ osilva ](/users/84086/osilva/) ![flag of\nCanada](/m/default/media/images/flags/ca.gif?v=28)  \n1650  \u25cf  3  \u25cf  172  \u25cf  19  [ https://github.com/rob...\n](https://github.com/robogeekcanada \"osilva's website is\nhttps://github.com/robogeekcanada\")\n\nHi, I am using moveit2 on ros2 foxy.\n\nI am trying to configure my robot URDF file for the moveit2 ROS foxy and run\nmy robot on ` moveit2 ` . I generated URDF file using Solid works. As there is\nno setup assistant for the moveit2 ROS foxy, I configured my URDF file using\nmoveit1 noetic. And added that file to the moveit2 foxy workspace. And i\nchanged the ` Cmakefile ` and ` package.xml ` file with reference to the `\nfanuc_moveit_config ` . And my robot URDF package is exactly similar to the `\nfanuc_moveit_config ` .\n\nMy robot URDF file is building properly and and I am able to see my robot urdf\nconfig and ` moveit_resources_fanuc_moveit_ config ` packages in launch\npackages. But when i see the launch files in that particular packages, I am\nunable to launch the ` demo.launch ` file both the packages. And I am able to\nsee only the ` .xml ` files in the launch files list of the both packages.\n\nPlease guide me how to launch the ` moveit_resources_fanuc_moveit_config\ndemo.launch ` file. And share me any data relating how to modify the urdf\nconfig file generated by ROS1 to ROS2.\n\n[ edit ](/questions/394756/edit/) [ retag ](/s/questions/394756/retag/) flag\noffensive  [ close ](/questions/394756/close/) merge  delete\n\nadd a comment\n\n##  1  Answer\n\nSort by \u00bb  [ oldest  ](/question/394756/ros2-launch-\nmoveit_resources_fanuc_moveit_config-demolaunch/?sort=oldest#sort-top) [\nnewest  ](/question/394756/ros2-launch-moveit_resources_fanuc_moveit_config-\ndemolaunch/?sort=latest#sort-top) [ most voted\n](/question/394756/ros2-launch-moveit_resources_fanuc_moveit_config-\ndemolaunch/?sort=votes#sort-top)\n\n1\n\n[ **answered 2022-01-21 16:49:44 -0500  ** ](/answers/394792/revisions/)\n\n[ ![cst0 gravatar image](/m/default/media/images/nophoto.png?v=28)\n](/users/92869/cst0/)\n\n[ cst0 ](/users/92869/cst0/)  \n119  \u25cf  17  \u25cf  7\n\n[ **updated 2022-01-24 09:15:34 -0500  ** ](/answers/394792/revisions/)\n\nThis appears to be a ROS1 package. To launch the ` demo.launch ` file in the `\nmoveit_resources_fanuc_moveit_config ` package, run:\n\n` roslaunch moveit_resources_fanuc_moveit_config demo.launch `\n\nMake sure that you have:\n\n  * Installed the package, looks like you'll need to do that by building from source: clone [ this repo ](https://github.com/ros-planning/moveit_resources/tree/master/fanuc_moveit_config) into the ` src/ ` of your catkin workspace and then build (more info [ here ](http://wiki.ros.org/ROS/Tutorials/BuildingPackages) ) \n\n  * Sourced the workspace (more info [ here ](http://wiki.ros.org/ROS/Tutorials/InstallingandConfiguringROSEnvironment) ) \n\nHowever, I would point out that (per the source repository): \"Use ROS-\nIndustrial's upstream files if you actually want to work with the robot!\". So,\nyou may not be using this package properly.\n\n* * *\n\nFor ROS 2, the command is ` ros2 launch <package_name> <launch_file_name> `\n(see [ here ](https://docs.ros.org/en/foxy/Tutorials/Launch/Creating-Launch-\nFiles.html) ), so your command would be:\n\n` ros2 launch moveit_resources_fanuc_moveit_config demo.launch `\n\n[ edit ](/s/answers/394792/edit/) flag offensive  delete  [ link\n](/question/394756/ros2-launch-moveit_resources_fanuc_moveit_config-\ndemolaunch/?answer=394792#post-id-394792 \"permanent link\") more\n\n  *   * \n\n##  Comments\n\nHi, Thanks for response. As I informed in my query, I am using ROS2 foxy\nmoveit2. you can find the Ros2 moveit repo [ https://github.com/ros-\nplanning/movei... ](https://github.com/ros-\nplanning/moveit_resources/tree/ros2)\n\nAs i mentioned the packages are building in colcon workspace, but at the time\nof launching, its only showing the .xml files only. And as you can see that\nthe cmakefile file in that repo link above is also contains ROS2 commands.\n\nSo please guide me how can launch that in the ROS2 foxy.\n\nOr else please share me link how to convert and run the configuration file\ngenerated by using the ROS1 setup assistant in ROS2.\n\n[ ![Manoj gravatar image](/m/default/media/images/nophoto.png?v=28)\n](/users/94358/manoj/) [ Manoj ](/users/94358/manoj/) (  2022-01-24 00:42:35\n-0500  )  edit\n\n[ @Manoj ](/users/94358/manoj/) : perhaps you could help [ @cst0\n](/users/92869/cst0/) by explaining what you really want to do.\n\nAre you trying to control a real Fanuc robot with MoveIt 2. Or some other\nrobot?\n\n[ ![gvdhoorn gravatar image](/upfiles/avatars/gvdhoorn/resized/16/4550046.png)\n](/users/5184/gvdhoorn/) [ gvdhoorn ](/users/5184/gvdhoorn/) (  2022-01-24\n03:05:36 -0500  )  edit\n\n[ @cst0 ](/users/92869/cst0/) , [ @gvdhoorn ](/users/5184/gvdhoorn/) Please\nTell me how to launch the moveit_resources_fanuc_moveit_config demo.launch\nfile in the ROS2 Foxy Moveit2. I just want to visually see the fanuc Robot in\nrviz. it will be helpful if you tell me how to launch the demo.launch file\nexisting in the moveit_resources_fanuc_moveit_config package in the ROS2 Foxy.\n\n[ ![Manoj gravatar image](/m/default/media/images/nophoto.png?v=28)\n](/users/94358/manoj/) [ Manoj ](/users/94358/manoj/) (  2022-01-24 04:32:17\n-0500  )  edit\n\nI've updated my answer to answer that, but I think the source of the confusion\nis that running a launchfile is pretty well-documented, so it's not totally\nclear what specific issue you may be having here. Is there any reason this\nlaunch file doesn't seem to be working for you?\n\n[ ![cst0 gravatar image](/m/default/media/images/nophoto.png?v=28)\n](/users/92869/cst0/) [ cst0 ](/users/92869/cst0/) (  2022-01-24 09:17:42\n-0500  )  edit\n\nadd a comment\n\n##  Question Tools\n\nFollow\n\n[ subscribe to rss feed ](/feeds/question/394756/ \"subscribe to the rss feed\")\n\n##  Stats\n\nAsked: ** 2022-01-21 04:24:06 -0500  **\n\nSeen: **444 times**\n\nLast updated: **Jan 24 '22**\n\n##  Related questions\n\n[ is it possible to read an RC control by arduino and pass to ros2?\n](/question/398136/is-it-possible-to-read-an-rc-control-by-arduino-and-pass-\nto-ros2/)\n\n[ MoveIt planned path visualisation ](/question/411230/moveit-planned-path-\nvisualisation/)\n\n[ ROS2 Foxy install on Big Sur failing, any ideas?\n](/question/380221/ros2-foxy-install-on-big-sur-failing-any-ideas/)\n\n[ Does ROS development fall under the systems programming category?\n](/question/392331/does-ros-development-fall-under-the-systems-programming-\ncategory/)\n\n[ ros2 foxy install jetson nano fails qt_gui_cpp ](/question/399928/ros2-foxy-\ninstall-jetson-nano-fails-qt_gui_cpp/)\n\n[ camera_info_manager with ROS2 ](/question/411344/camera_info_manager-with-\nros2/)\n\n[ moveit2_tutorials: Cannot locate rosdep definition for\n[moveit_hybrid_planning] ](/question/400245/moveit2_tutorials-cannot-locate-\nrosdep-definition-for-moveit_hybrid_planning/)\n\n[ MoveIt2 tutorial error Pick and Place ](/question/407851/moveit2-tutorial-\nerror-pick-and-place/)\n\n[ Best way to integrate ndarray into ros2 [closed] ](/question/398470/best-\nway-to-integrate-ndarray-into-ros2/)\n\n[ How to troubleshoot Rviz2 not receiving map from cartographer?\n](/question/388322/how-to-troubleshoot-rviz2-not-receiving-map-from-\ncartographer/)\n\n[ ![cc-by-sa](/m/default/media/images/cc-by-sa.png?v=28)\n](http://creativecommons.org/licenses/by-sa/3.0/legalcode) ROS Answers is\nlicensed under Creative Commons Attribution 3.0 Content on this site is\nlicensed under a [ Creative Commons Attribution Share Alike 3.0\n](http://creativecommons.org/licenses/by-sa/3.0/legalcode) license.\n\n[ about ](/about/) |  [ faq ](/faq/) |  [ help ](/help/ \"help\") |  [ privacy\npolicy ](/privacy/) |  [ terms of service ](/terms/)\n\n[ Powered by Askbot version 0.10.2 ](http://askbot.com)\n\nPlease note: ROS Answers requires javascript to work properly, please enable\njavascript in your browser, [ here is how\n](https://www.google.com/support/bin/answer.py?answer=23852)\n\n[ ![ gravatar image]() ]() [ ]() (  2024-04-14 11:50:37 -0500  )  edit\n\n[ none ](/questions/scope:all/sort:activity-desc/tags:none/page:1/) \u00d7\n\n  *[\n              2022-01-21 04:24:06 -0500\n             ]: 2022-01-21 04:24:06 -0500\n  *[\n              2022-01-21 12:01:32 -0500\n             ]: 2022-01-21 12:01:32 -0500\n  *[\n              2022-01-21 16:49:44 -0500\n             ]: 2022-01-21 16:49:44 -0500\n  *[\n              2022-01-24 09:15:34 -0500\n             ]: 2022-01-24 09:15:34 -0500\n  *[\n             2022-01-24 00:42:35 -0500\n            ]: 2022-01-24 00:42:35 -0500\n  *[\n             2022-01-24 03:05:36 -0500\n            ]: 2022-01-24 03:05:36 -0500\n  *[\n             2022-01-24 04:32:17 -0500\n            ]: 2022-01-24 04:32:17 -0500\n  *[\n             2022-01-24 09:17:42 -0500\n            ]: 2022-01-24 09:17:42 -0500\n  *[\n        2022-01-21 04:24:06 -0500\n       ]: 2022-01-21 04:24:06 -0500\n  *[\n        2024-04-14 11:50:37 -0500\n       ]: 2024-04-14 11:50:37 -0500\n\n"
  },
  {
    "id": "gazebo_detach/tutorialstutsetveloc.txt",
    "content": "Toggle navigation  [\n![gazebo](/assets/masthead-0bd44817978df8069f427d8ca1657998789065a2b242edfd1a3d8ab4a329dd4c.png)\n](/)\n\n  * [ Tutorials ](/tutorials)\n  * [ Download ](/download)\n  * [ Blog ](/blog.html)\n  * [ Media ](/media)\n  * [ Projects ](/projects)\n\n__\n\n** WARNING ** : This documentation is for Gazebo-classic, which has been\nsuperseded by Gazebo. [ Click here to see the documentation for the latest\nGazebo release ](https://gazebosim.org/docs)\n\n[ Back ](/tutorials?cat=)\n\n#  Setting Velocity on Joints and Links\n\n[ Edit\n](https://github.com/osrf/gazebo_tutorials/blob/master/set_velocity/tutorial_7.md)\nVersion: 7.0\n\n* * *\n\n####  Table of Contents\n\n#  Setting Velocity on Links And Joints\n\nThis tutorial will describe how to programatically set velocities on Joints\nand Links in Gazebo 7. This is a common task done in a custom [ plugin\n](tutorials?cat=plugins) .\n\n#  Examples\n\n[ Downloaded an example plugin here\n](http://github.com/osrf/gazebo_tutorials/raw/master/set_velocity/examples/set_vel_plugin/)\n. Follow these steps to build and run the plugin.\n\n    \n    \n    cd Downloads/set_vel_plugin/\n    mkdir build\n    cd build\n    cmake ..\n    make\n    GAZEBO_PLUGIN_PATH=. gazebo --pause --verbose ../set_velocity.world\n    \n\nFinally unpause the world to see everything move. All of the methods used to\nset velocity are explained below.\n\n#  Methods\n\nThere are three methods to set velocity:\n\n  1. Set Instantaneous Velocity \n  2. Configure a joint motor (ODE only) \n  3. Create a PID controller \n\n###  Set Velocity Instantaneously\n\n**Advantages**\n\n  * Supported on all physics engines \n  * Simple, only one function call \n  * Object moves at target velocity right away \n\n**Disadvantages**\n\n  * Object doesn't \"feel\" a force accellerating it \n\nAll physics engines used by gazebo support setting an instananeous velocity.\nObjects move at the target speed without any forces or torques being applied.\nThis means calls to [ ` Joint::GetForceTorque() ` ](http://osrf-\ndistributions.s3.amazonaws.com/gazebo/api/7.1.0/classgazebo_1_1physics_1_1Joint.html#a85f6b25f1d0d6451a84875c18c57535d)\n, [ ` Link::GetWorldForce() ` ](http://osrf-\ndistributions.s3.amazonaws.com/gazebo/api/7.1.0/classgazebo_1_1physics_1_1Link.html#ab6d63e2c37c0273d1f8fd820d208f894)\nand [ ` Link::GetWorldTorque() ` ](http://osrf-\ndistributions.s3.amazonaws.com/gazebo/api/7.1.0/classgazebo_1_1physics_1_1Link.html#ab4f3ec4a752b81b69198055b525cc026)\nwill not show any additional forces or torques when using this method.\n\nThe object is not constrained to the velocity permanently. Forces or torques\nmay change the speed of the object after the velocity is set. It must be set\nevery time step to keep the object at a constant velocity forever.\n\n###  Set Velocity With Joint Motors\n\n**Advantages**\n\n  * Can reach target velocity in a single update \n  * Object feels the force that accellerates it \n  * The exact required force is used, no under or overshooting the target velocity \n\n**Disadvantages**\n\n  * ODE only (default physics engine used by gazebo) \n  * When using to set a link's velocity all other degrees of freedom are locked \n\nJoints motors can be used to reach a velocity by applying the exact required\nforce to a joint. Gazebo only supports this method when using the ODE physics\nengine (the default engine). It relies on the [ ODE Joint Motor feature\n](https://www.ode-\nwiki.org/wiki/index.php?title=Manual:_Joint_Types_and_Functions#Stops_and_motor_parameters)\n.\n\n###  Setting Velocity Using PID Controllers\n\n**Advantages**\n\n  * Supported on all physics engines \n  * Object feels the force that accellerates it \n  * Does not need to lock other degrees of freedom \n\n**Disadvantages**\n\n  * PID gains need to be tuned per object \n  * Can under shoot or over shoot the target velocity \n  * It takes multiple updates to reach the target velocity \n\nAnother method of setting velocity is to use a [ PID controller\n](https://en.wikipedia.org/wiki/PID_controller) to apply forces and torques.\nIt works on all physics engines, but requires tuning constants specifically\nfor the object being moved. Unlike the joint motor method, the other degrees\nof freedom are not locked while the forces are being applied.\n\nIn general the velocity cannot be achieved instantaneously with a PID\ncontroller. It must exist and be active for multiple updates to achive the\ntarget velocity.\n\n#  Setting Velocity on Joints\n\nThis section will show how to use the three methods to set velocity on a\njoint.\n\n![](https://github.com/osrf/gazebo_tutorials/raw/master/set_velocity/pictures/set_joint_velocity.gif)\n\n> **Note** Not all joints can be commanded to move at target velocity.\n> Revolute, revolute2, prismatic, screw, and universal joints can be set.\n> Ball, gearbox, and fixed joints cannot be set using any method described\n> below. However, while a gearbox joint velocity cannot be set, the parent or\n> child joint can be set if it is one of the supported joint types.\n\n###  Set Joint Velocity Instantaneously\n\nVelocity on joints can be set instantaneously using [ ` Joint::SetVelocity() `\n](http://osrf-\ndistributions.s3.amazonaws.com/gazebo/api/7.1.0/classgazebo_1_1physics_1_1Joint.html#ae32987acf99308e4aca7f2c399f3e731)\n. The velocity is achieved by moving the child link. Notice at first the top\nlink (child) on the gray (leftmost) joint moves while the bottom link is\nstationary. The momentum of the top link causes the whole gray object to move\nwhen the joint limit is hit.\n\n    \n    \n              this->model->GetJoint(\"gray_joint\")->SetVelocity(0, 1.0);\n    \n\nIt takes two parameters: axis, and velocity. The axis parameter is an index,\nand it may be 0 or 1. Zero means the first axis on the joint, and one means\nthe second if applicable.\n\nType  |  Number of Axes  \n---|---  \nprismatic  |  1  \nrevolute  |  1  \nrevolute2  |  2  \nscrew  |  1  \nuniversal  |  2  \n  \nThe second parameter is the velocity. It is meters per second for prismatic\njoints, and radians per second for all others.\n\n###  Set Joint Velocity Using Joint Motors\n\nConfiguring a joint motor is done using [ ` Joint::SetParam() ` ](http://osrf-\ndistributions.s3.amazonaws.com/gazebo/api/7.1.0/classgazebo_1_1physics_1_1Joint.html#a48402b4fa13b0209246396c0d726d914)\n.\n\n    \n    \n              this->model->GetJoint(\"orange_joint\")->SetParam(\"fmax\", 0, 100.0);\n              this->model->GetJoint(\"orange_joint\")->SetParam(\"vel\", 0, 1.0);\n    \n\nIt accepts three parameters: key, axis, and value. The key parameter is a\nstring that names the parameter to be changed. The axis parameter is an index\nthat may be 0 or 1.\n\n> **Note** The value parameter must have exactly the right type. Joint motors\n> require setting ` double ` parameters. This call will work `\n> joint->SetParam('fmax', 0, 0.0) ` while this will have a runtime error `\n> joint->SetParam('fmax', 0, 0) ` .\n\nSetting up a joint motor requires requires two calls. The first call sets the\nkey ` vel ` to the velocity the joint should travel at. It is meters per\nsecond for prismatic joints and radians per second for all others. The other\ncall sets the key ` fmax ` . It is the maximum force or torque a joint motor\nmay apply during a time step. Set it larger than the force required to be at\nthe target velocity at the next time step. Set it smaller to apply a force\nover many time steps until the velocity is reached. Stop applying force by\nsetting ` fmax ` back to zero.\n\n###  Set Joint Velocity Using PID controllers\n\nA [ PID controller ](https://en.wikipedia.org/wiki/PID_controller) can be used\nto apply forces on the joint axes. The class [ ` physics::JointController `\n](http://osrf-\ndistributions.s3.amazonaws.com/gazebo/api/dev/classgazebo_1_1physics_1_1JointController.html)\ncan manager the PID controllers for you.\n\n    \n    \n              this->jointController.reset(new physics::JointController(\n                    this->model));\n              this->jointController->AddJoint(model->GetJoint(\"purple_joint\"));\n              std::string name = model->GetJoint(\"purple_joint\")->GetScopedName();\n              this->jointController->SetVelocityPID(name, common::PID(100, 0, 0));\n              this->jointController->SetVelocityTarget(name, 1.0);\n    \n\nThe controller gains must be configured for each object being moved. The\nvelocity target is meters per second for prismatic joints, and radians per\nsecond for all others. [ ` JointController::Update() ` ](http://osrf-\ndistributions.s3.amazonaws.com/gazebo/api/dev/classgazebo_1_1physics_1_1JointController.html#aec0783b5a136e042adcc47bae4fe5291)\nmust be called every time step to apply forces\n\n    \n    \n              this->jointController->Update();\n    \n\n#  Setting Velocity on Links\n\nThis section will show how to use the three methods to set velocity on a link.\n\n![](https://github.com/osrf/gazebo_tutorials/raw/master/set_velocity/pictures/set_link_velocity.gif)\n\n###  Set Link Velocity Instantaneously\n\n    \n    \n              // Link velocity instantaneously without applying forces\n              model->GetLink(\"white_link_0\")->SetLinearVel({0, 1, 0});\n              model->GetLink(\"white_link_1\")->SetLinearVel({0, 1, 0});\n              model->GetLink(\"white_link_1\")->SetAngularVel({1, 0, 0});\n              model->GetLink(\"white_link_2\")->SetAngularVel({1, 0, 0});\n    \n\nLinear velocity on links can be set with [ ` Link::SetLinearVel() `\n](http://osrf-\ndistributions.s3.amazonaws.com/gazebo/api/7.1.0/classgazebo_1_1physics_1_1Link.html#a110267b99cacd79cd377ca8619956645)\n. Angular velocity on links can be set with [ ` Link::SetAngularVel() `\n](http://osrf-\ndistributions.s3.amazonaws.com/gazebo/api/7.1.0/classgazebo_1_1physics_1_1Link.html#a996d99f2897ebca28979b24b7f23faa1)\n. Both accept a [ three dimensional vector ](http://osrf-\ndistributions.s3.amazonaws.com/gazebo/api/7.1.0/classgazebo_1_1math_1_1Vector3.html)\nwith the target linear velocity. The velocity must be expressed in the world\nframe in meters per second or radians per second.\n\n###  Set Link Velocity Using Joint Motors\n\nJoint motors can be used to move links by creating a joint connecting the link\nto the world. It is critical that the joints are created when the velocity is\nto be applied, and deleted afterwards.\n\nLinear velocity can be set by creating a prismatic joint between the world and\nthe link to be moved. Then a joint moter can be configured as described above.\nThe link will not rotate or move off the prismatic joint axis until the joint\nis detached.\n\n    \n    \n            // create prismatic joint with the world as a parent\n            physics::ModelPtr model = _link->GetModel();\n            physics::WorldPtr world = physics::get_world(\"default\");\n            physics::PhysicsEnginePtr engine = world->GetPhysicsEngine();\n            this->joint = engine->CreateJoint(\"prismatic\");\n            this->joint->SetName(model->GetName() + \"__perfect_lin_joint__\");\n            physics::LinkPtr worldLink = boost::dynamic_pointer_cast<physics::Link>(\n                world->GetByName(\"world\"));\n            math::Pose jointOrigin;\n            this->joint->Load(worldLink, _link, jointOrigin);\n            this->joint->Init();\n            double magnitude = _vel.GetLength();\n            this->joint->SetAxis(0, _vel.Normalize());\n            this->joint->SetParam(\"fmax\", 0, _maxForce);\n            this->joint->SetParam(\"vel\", 0, magnitude);\n    \n\nAngular velocity can be set by creating a revolute joint between the world and\nthe link to be moved. The link will only be able to rotate about the revolute\njoint axis until the joint is detached.\n\n    \n    \n            // create revolute joint with the world as a parent\n            physics::ModelPtr model = _link->GetModel();\n            physics::WorldPtr world = physics::get_world(\"default\");\n            physics::PhysicsEnginePtr engine = world->GetPhysicsEngine();\n            this->joint = engine->CreateJoint(\"revolute\");\n            this->joint->SetName(model->GetName() + \"__perfect_ang_joint__\");\n            physics::LinkPtr worldLink =\n              boost::dynamic_pointer_cast<physics::Link>(world->GetByName(\"world\"));\n            math::Pose jointOrigin;\n            this->joint->Load(worldLink, _link, jointOrigin);\n            this->joint->Init();\n            double magnitude = _vel.GetLength();\n            this->joint->SetAxis(0, _vel.Normalize());\n            this->joint->SetParam(\"fmax\", 0, _maxTorque);\n            this->joint->SetParam(\"vel\", 0, magnitude);\n    \n\nControlling both linear and angular velocity at the same time requires an\nadditional link. The link should be programmatically created with the same\norigin as the link whose velocity is to be set. Create a prismatic joint with\nthe world as the parent and the phantom link as the child. Then create a\nrevolute joint with the phantom link as the parent and the link to be moved as\nthe child. Finally create joint motors on both joints to reach the target\nvelocity.\n\n    \n    \n            // Create a phantom link\n            this->phantomLink = model->CreateLink(\"__perfect_phantom_link__\");\n            sdf::ElementPtr config(new sdf::Element);\n            config->Copy(_link->GetSDF()->Clone());\n            config->GetAttribute(\"name\")->Set(\"__perfect_phantom_link__\");\n            // Remove visuals/collisions/inertials\n            while (config->HasElement(\"visual\"))\n            {\n              config->RemoveChild(config->GetElement(\"visual\"));\n            }\n            while (config->HasElement(\"collision\"))\n            {\n              config->RemoveChild(config->GetElement(\"collision\"));\n            }\n            while (config->HasElement(\"inertial\"))\n            {\n              config->RemoveChild(config->GetElement(\"inertial\"));\n            }\n            this->phantomLink->Load(config);\n            this->phantomLink->Init();\n    \n            // create prismatic joint with parent \"world\" and child phantomLink\n            this->prismaticJoint = engine->CreateJoint(\"prismatic\");\n            this->prismaticJoint->SetName(\n                model->GetName() + \"__perfect_vel_lin_joint__\");\n            physics::LinkPtr worldLink = boost::dynamic_pointer_cast<physics::Link>(\n                world->GetByName(\"world\"));\n            math::Pose prismaticJointOrigin;\n            this->prismaticJoint->Load(worldLink, this->phantomLink,\n                prismaticJointOrigin);\n            this->prismaticJoint->Init();\n            double linearMagnitude = _linearVel.GetLength();\n            this->prismaticJoint->SetAxis(0, _linearVel.Normalize());\n            this->prismaticJoint->SetParam(\"fmax\", 0, _maxForce);\n            this->prismaticJoint->SetParam(\"vel\", 0, linearMagnitude);\n    \n            // create revolute joint with parent phantomLink and child _link\n            this->revoluteJoint = engine->CreateJoint(\"revolute\");\n            this->revoluteJoint->SetName(\n                model->GetName() + \"__perfect_vel_ang_joint__\");\n            math::Pose revoluteJointOrigin;\n            this->revoluteJoint->Load(this->phantomLink, _link,\n                revoluteJointOrigin);\n            this->revoluteJoint->Init();\n            double angularMagnitude = _angularVel.GetLength();\n            this->revoluteJoint->SetAxis(0, _angularVel.Normalize());\n            this->revoluteJoint->SetParam(\"fmax\", 0, _maxTorque);\n            this->revoluteJoint->SetParam(\"vel\", 0, angularMagnitude);\n    \n\n###  Set Link Velocity Using PID controllers\n\nA [ PID controller ](http://osrf-\ndistributions.s3.amazonaws.com/gazebo/api/7.1.0/classgazebo_1_1common_1_1PID.html)\ncan be used to set a velocity by appling forces or torques. This requires\ntuning constants for each object whose velocity is to be set.\n\n    \n    \n          // Hard coded gains. Tune these for your own application!\n          double linear_p = 100.0;\n          double linear_i = 0.0;\n          double linear_d = 0.0;\n          double linear_imax = 123456789.0;\n          double angular_p = 100.0;\n          double angular_i = 0.0;\n          double angular_d = 0.0;\n          double angular_imax = 123456789.0;\n    \n\nEach degree of freedom (x, y, z, roll, pitch, yaw) must have it's own PID\ncontroller. Fewer controllers can be used if it is permissable for the link to\nmove freely on some degrees of freedom. For example, setting a translational\nvelocity while allowing the object to rotate requries only 3 PID controllers:\nx, y, z.\n\n    \n    \n          // Add a PID controller for each DoF\n          for (int i = 0; i < 3; i++)\n          {\n            common::PID controller_translation(linear_p, linear_i, linear_d,\n                linear_imax, -linear_imax, _maxForce, -_maxForce);\n            common::PID controller_rotation(angular_p, angular_i, angular_d,\n                angular_imax, -angular_imax, _maxTorque, -_maxTorque);\n            this->controllers.push_back(controller_translation);\n            this->controllers.push_back(controller_rotation);\n          }\n    \n\nEvery physics update the error between the actual velocity and the target\nvelocity needs to be given to the controller.\n\n    \n    \n          // Calculate the error between actual and target velocity\n          math::Vector3 curLinearVel = this->link->GetWorldLinearVel();\n          math::Vector3 curAngularVel = this->link->GetWorldAngularVel();\n          math::Vector3 linearError = curLinearVel - this->targetLinearVel;\n          math::Vector3 angularError = curAngularVel - this->targetAngularVel;\n    \n          // Get forces to apply from controllers\n          math::Vector3 worldForce;\n          math::Vector3 worldTorque;\n          worldForce.x = this->controllers[0].Update(linearError.x, dt);\n          worldTorque.x = this->controllers[1].Update(angularError.x, dt);\n          worldForce.y = this->controllers[2].Update(linearError.y, dt);\n          worldTorque.y = this->controllers[3].Update(angularError.y, dt);\n          worldForce.z = this->controllers[4].Update(linearError.z, dt);\n          worldTorque.z = this->controllers[5].Update(angularError.z, dt);\n    \n\nThe controllers will output forces and torques that should be applied to the\nlink to correct for the current error.\n\n    \n    \n          // Add those forces to the body\n          this->link->AddForce(worldForce);\n          this->link->AddTorque(worldTorque);\n    \n\nThe object will move at the desired velocity. The amount of velocity error\ndepends on the PID gains chosen. Tune these until you get acceptable\nperformance.\n\n\u00a92014 Open Source Robotics Foundation\n\nGazebo is open-source licensed under [ Apache 2.0\n](http://www.apache.org/licenses/LICENSE-2.0.html)\n\n[ ![Google+](/assets/google_gray-\ncc34826f560f99c7a9b7db88cd5f2db4d28fd4b3afcfa4b897435c51e3b25518.png)\n](//plus.google.com/u/0/115981436296571800301?prsrc=3) [\n![YouTube](/assets/youtube_gray-978838444154eb6aa5e4aa38489f66d10e40361dd06a3814411c211cba013752.png)\n](https://www.youtube.com/channel/UCJyqf9XJpDoM9XnpAwW6WxA) [\n![YouTube](/assets/twitter_gray-8e9dfe74c6cab12171992a40add9a65e5bba92ac93063a4ac0eeba58c77e774a.png)\n](https://twitter.com/GazeboSim)\n\n"
  },
  {
    "id": "teleopanel/panelplugintutorialh.txt",
    "content": "#  TeleopPanel  \u00c2\u00b6\n\n##  Overview  \u00c2\u00b6\n\nThis tutorial shows how to write a simple Panel plugin for RViz.\n\nA _panel_ in RViz is a GUI widget which can be docked in the main window or\nfloating. It does not show properties in the \u201cDisplays\u201d panel like a _Display_\n, but it could show things in the 3D scene.\n\nA panel can be a useful place to put a bunch of application-specific GUI\nelements. You could put start and stop buttons for your robot, or other\ncommand or control inputs.\n\nRViz has a built-in tool to send a goal pose to a path planner, but it does\nnot have a native way to send velocity commands directly to a robot base\ncontroller. That is what this tutorial shows, a subclass of rviz::Panel which\nlets you send velocity commands right to your robot.\n\nThe source code for this tutorial is in the rviz_plugin_tutorials package. You\ncan check out the source directly or (if you use Ubuntu) you can just apt-get\ninstall the pre-compiled Debian package like so:\n\n    \n    \n    sudo apt-get install ros-hydro-visualization-tutorials\n    \n\nHere is what RViz looks like with the new \u201cTeleop\u201d panel showing on the left:\n\n![_images/teleop_in_rviz.png](_images/teleop_in_rviz.png)\n\n##  The Plugin Code  \u00c2\u00b6\n\nThe code for TeleopPanel is in these files: [ src/teleop_panel.h\n](https://github.com/ros-visualization/visualization_tutorials/tree/groovy-\ndevel/rviz_plugin_tutorials/src/teleop_panel.h) , [ src/teleop_panel.cpp\n](https://github.com/ros-visualization/visualization_tutorials/tree/groovy-\ndevel/rviz_plugin_tutorials/src/teleop_panel.cpp) , [ src/drive_widget.h\n](https://github.com/ros-visualization/visualization_tutorials/tree/groovy-\ndevel/rviz_plugin_tutorials/src/drive_widget.h) , and [ src/drive_widget.cpp\n](https://github.com/ros-visualization/visualization_tutorials/tree/groovy-\ndevel/rviz_plugin_tutorials/src/drive_widget.cpp) .\n\n###  teleop_panel.h  \u00c2\u00b6\n\nThe full text of teleop_panel.h is here: [ src/teleop_panel.h\n](https://github.com/ros-visualization/visualization_tutorials/tree/groovy-\ndevel/rviz_plugin_tutorials/src/teleop_panel.h)\n\nHere we declare our new subclass of rviz::Panel. Every panel which can be\nadded via the Panels/Add_New_Panel menu is a subclass of rviz::Panel.\n\nTeleopPanel will show a text-entry field to set the output topic and a 2D\ncontrol area. The 2D control area is implemented by the DriveWidget class, and\nis described there.\n\n    \n    \n    class TeleopPanel: public rviz::Panel\n    {\n    \n\nThis class uses Qt slots and is a subclass of QObject, so it needs the\nQ_OBJECT macro.\n\n    \n    \n    Q_OBJECT\n    public:\n    \n\nQWidget subclass constructors usually take a parent widget parameter (which\nusually defaults to 0). At the same time, pluginlib::ClassLoader creates\ninstances by calling the default constructor (with no arguments). Taking the\nparameter and giving a default of 0 lets the default constructor work and also\nlets someone using the class for something else to pass in a parent widget as\nthey normally would with Qt.\n\n    \n    \n    TeleopPanel( QWidget* parent = 0 );\n    \n\nNow we declare overrides of rviz::Panel functions for saving and loading data\nfrom the config file. Here the data is the topic name.\n\n    \n    \n    virtual void load( const rviz::Config& config );\n    virtual void save( rviz::Config config ) const;\n    \n\nNext come a couple of public Qt slots.\n\n    \n    \n    public Q_SLOTS:\n    \n\nThe control area, DriveWidget, sends its output to a Qt signal for ease of re-\nuse, so here we declare a Qt slot to receive it.\n\n    \n    \n    void setVel( float linear_velocity_, float angular_velocity_ );\n    \n\nIn this example setTopic() does not get connected to any signal (it is called\ndirectly), but it is easy to define it as a public slot instead of a private\nfunction in case it would be useful to some other user.\n\n    \n    \n    void setTopic( const QString& topic );\n    \n\nHere we declare some internal slots.\n\n    \n    \n    protected Q_SLOTS:\n    \n\nsendvel() publishes the current velocity values to a ROS topic. Internally\nthis is connected to a timer which calls it 10 times per second.\n\n    \n    \n    void sendVel();\n    \n\nupdateTopic() reads the topic name from the QLineEdit and calls setTopic()\nwith the result.\n\n    \n    \n    void updateTopic();\n    \n\nThen we finish up with protected member variables.\n\n    \n    \n    protected:\n    \n\nThe control-area widget which turns mouse events into command velocities.\n\n    \n    \n    DriveWidget* drive_widget_;\n    \n\nOne-line text editor for entering the outgoing ROS topic name.\n\n    \n    \n    QLineEdit* output_topic_editor_;\n    \n\nThe current name of the output topic.\n\n    \n    \n    QString output_topic_;\n    \n\nThe ROS publisher for the command velocity.\n\n    \n    \n    ros::Publisher velocity_publisher_;\n    \n\nThe ROS node handle.\n\n    \n    \n    ros::NodeHandle nh_;\n    \n\nThe latest velocity values from the drive widget.\n\n    \n    \n    float linear_velocity_;\n    float angular_velocity_;\n    \n\n###  teleop_panel.cpp  \u00c2\u00b6\n\nThe full text of teleop_panel.cpp is here: [ src/teleop_panel.cpp\n](https://github.com/ros-visualization/visualization_tutorials/tree/groovy-\ndevel/rviz_plugin_tutorials/src/teleop_panel.cpp)\n\nHere is the implementation of the TeleopPanel class. TeleopPanel has these\nresponsibilities:\n\n  * Act as a container for GUI elements DriveWidget and QLineEdit. \n  * Publish command velocities 10 times per second (whether 0 or not). \n  * Saving and restoring internal state from a config file. \n\nWe start with the constructor, doing the standard Qt thing of passing the\noptional _parent_ argument on to the superclass constructor, and also zero-ing\nthe velocities we will be publishing.\n\n    \n    \n    TeleopPanel::TeleopPanel( QWidget* parent )\n      : rviz::Panel( parent )\n      , linear_velocity_( 0 )\n      , angular_velocity_( 0 )\n    {\n    \n\nNext we lay out the \u201coutput topic\u201d text entry field using a QLabel and a\nQLineEdit in a QHBoxLayout.\n\n    \n    \n    QHBoxLayout* topic_layout = new QHBoxLayout;\n    topic_layout->addWidget( new QLabel( \"Output Topic:\" ));\n    output_topic_editor_ = new QLineEdit;\n    topic_layout->addWidget( output_topic_editor_ );\n    \n\nThen create the control widget.\n\n    \n    \n    drive_widget_ = new DriveWidget;\n    \n\nLay out the topic field above the control widget.\n\n    \n    \n    QVBoxLayout* layout = new QVBoxLayout;\n    layout->addLayout( topic_layout );\n    layout->addWidget( drive_widget_ );\n    setLayout( layout );\n    \n\nCreate a timer for sending the output. Motor controllers want to be reassured\nfrequently that they are doing the right thing, so we keep re-sending\nvelocities even when they aren\u2019t changing.\n\nHere we take advantage of QObject\u2019s memory management behavior: since \u201cthis\u201d\nis passed to the new QTimer as its parent, the QTimer is deleted by the\nQObject destructor when this TeleopPanel object is destroyed. Therefore we\ndon\u2019t need to keep a pointer to the timer.\n\n    \n    \n    QTimer* output_timer = new QTimer( this );\n    \n\nNext we make signal/slot connections.\n\n    \n    \n    connect( drive_widget_, SIGNAL( outputVelocity( float, float )), this, SLOT( setVel( float, float )));\n    connect( output_topic_editor_, SIGNAL( editingFinished() ), this, SLOT( updateTopic() ));\n    connect( output_timer, SIGNAL( timeout() ), this, SLOT( sendVel() ));\n    \n\nStart the timer.\n\n    \n    \n    output_timer->start( 100 );\n    \n\nMake the control widget start disabled, since we don\u2019t start with an output\ntopic.\n\n    \n    \n      drive_widget_->setEnabled( false );\n    }\n    \n\nsetVel() is connected to the DriveWidget\u2019s output, which is sent whenever it\nchanges due to a mouse event. This just records the values it is given. The\ndata doesn\u2019t actually get sent until the next timer callback.\n\n    \n    \n    void TeleopPanel::setVel( float lin, float ang )\n    {\n      linear_velocity_ = lin;\n      angular_velocity_ = ang;\n    }\n    \n\nRead the topic name from the QLineEdit and call setTopic() with the results.\nThis is connected to QLineEdit::editingFinished() which fires when the user\npresses Enter or Tab or otherwise moves focus away.\n\n    \n    \n    void TeleopPanel::updateTopic()\n    {\n      setTopic( output_topic_editor_->text() );\n    }\n    \n\nSet the topic name we are publishing to.\n\n    \n    \n    void TeleopPanel::setTopic( const QString& new_topic )\n    {\n    \n\nOnly take action if the name has changed.\n\n    \n    \n    if( new_topic != output_topic_ )\n    {\n      output_topic_ = new_topic;\n    \n\nIf the topic is the empty string, don\u2019t publish anything.\n\n    \n    \n    if( output_topic_ == \"\" )\n    {\n      velocity_publisher_.shutdown();\n    }\n    else\n    {\n    \n\nThe old ` velocity_publisher_  ` is destroyed by this assignment, and thus the\nold topic advertisement is removed. The call to nh_advertise() says we want to\npublish data on the new topic name.\n\n    \n    \n      velocity_publisher_ = nh_.advertise<geometry_msgs::Twist>( output_topic_.toStdString(), 1 );\n    }\n    \n\nrviz::Panel defines the configChanged() signal. Emitting it tells RViz that\nsomething in this panel has changed that will affect a saved config file.\nUltimately this signal can cause QWidget::setWindowModified(true) to be called\non the top-level rviz::VisualizationFrame, which causes a little asterisk\n(\u201c*\u201d) to show in the window\u2019s title bar indicating unsaved changes.\n\n    \n    \n      Q_EMIT configChanged();\n    }\n    \n\nGray out the control widget when the output topic is empty.\n\n    \n    \n      drive_widget_->setEnabled( output_topic_ != \"\" );\n    }\n    \n\nPublish the control velocities if ROS is not shutting down and the publisher\nis ready with a valid topic name.\n\n    \n    \n    void TeleopPanel::sendVel()\n    {\n      if( ros::ok() && velocity_publisher_ )\n      {\n        geometry_msgs::Twist msg;\n        msg.linear.x = linear_velocity_;\n        msg.linear.y = 0;\n        msg.linear.z = 0;\n        msg.angular.x = 0;\n        msg.angular.y = 0;\n        msg.angular.z = angular_velocity_;\n        velocity_publisher_.publish( msg );\n      }\n    }\n    \n\nSave all configuration data from this panel to the given Config object. It is\nimportant here that you call save() on the parent class so the class id and\npanel name get saved.\n\n    \n    \n    void TeleopPanel::save( rviz::Config config ) const\n    {\n      rviz::Panel::save( config );\n      config.mapSetValue( \"Topic\", output_topic_ );\n    }\n    \n\nLoad all configuration data for this panel from the given Config object.\n\n    \n    \n    void TeleopPanel::load( const rviz::Config& config )\n    {\n      rviz::Panel::load( config );\n      QString topic;\n      if( config.mapGetString( \"Topic\", &topic ))\n      {\n        output_topic_editor_->setText( topic );\n        updateTopic();\n      }\n    }\n    \n    } // end namespace rviz_plugin_tutorials\n    \n\nTell pluginlib about this class. Every class which should be loadable by\npluginlib::ClassLoader must have these two lines compiled in its .cpp file,\noutside of any namespace scope.\n\n    \n    \n    #include <pluginlib/class_list_macros.h>\n    PLUGINLIB_EXPORT_CLASS(rviz_plugin_tutorials::TeleopPanel,rviz::Panel )\n    \n\n###  drive_widget.h  \u00c2\u00b6\n\nThe full text of drive_widget.h is here: [ src/drive_widget.h\n](https://github.com/ros-visualization/visualization_tutorials/tree/groovy-\ndevel/rviz_plugin_tutorials/src/drive_widget.h)\n\nDriveWidget implements a control which translates mouse Y values into linear\nvelocities and mouse X values into angular velocities.\n\nFor maximum reusability, this class is only responsible for user interaction\nand display inside its widget. It does not make any ROS or RViz calls. It\ncommunicates its data to the outside just via Qt signals.\n\n    \n    \n    class DriveWidget: public QWidget\n    {\n    Q_OBJECT\n    public:\n    \n\nThis class is not instantiated by pluginlib::ClassLoader, so the constructor\nhas no restrictions.\n\n    \n    \n    DriveWidget( QWidget* parent = 0 );\n    \n\nWe override QWidget::paintEvent() to do custom painting.\n\n    \n    \n    virtual void paintEvent( QPaintEvent* event );\n    \n\nWe override the mouse events and leaveEvent() to keep track of what the mouse\nis doing.\n\n    \n    \n    virtual void mouseMoveEvent( QMouseEvent* event );\n    virtual void mousePressEvent( QMouseEvent* event );\n    virtual void mouseReleaseEvent( QMouseEvent* event );\n    virtual void leaveEvent( QEvent* event );\n    \n\nOverride sizeHint() to give the layout managers some idea of a good size for\nthis.\n\n    \n    \n    virtual QSize sizeHint() const { return QSize( 150, 150 ); }\n    \n\nWe emit outputVelocity() whenever it changes.\n\n    \n    \n    Q_SIGNALS:\n      void outputVelocity( float linear, float angular );\n    \n\nmouseMoveEvent() and mousePressEvent() need the same math to figure the\nvelocities, so I put that in here.\n\n    \n    \n    protected:\n      void sendVelocitiesFromMouse( int x, int y, int width, int height );\n    \n\nA function to emit zero velocity.\n\n    \n    \n    void stop();\n    \n\nFinally the member variables:\n\n    \n    \n      float linear_velocity_; // In m/s\n      float angular_velocity_; // In radians/s\n      float linear_scale_; // In m/s\n      float angular_scale_; // In radians/s\n    };\n    \n\n###  drive_widget.cpp  \u00c2\u00b6\n\nThe full text of drive_widget.cpp is here: [ src/drive_widget.cpp\n](https://github.com/ros-visualization/visualization_tutorials/tree/groovy-\ndevel/rviz_plugin_tutorials/src/drive_widget.cpp)\n\nThe DriveWidget constructor does the normal Qt thing of passing the parent\nwidget to the superclass constructor, then initializing the member variables.\n\n    \n    \n    DriveWidget::DriveWidget( QWidget* parent )\n      : QWidget( parent )\n      , linear_velocity_( 0 )\n      , angular_velocity_( 0 )\n      , linear_scale_( 10 )\n      , angular_scale_( 2 )\n    {\n    }\n    \n\nThis paintEvent() is complex because of the drawing of the two arc-arrows\nrepresenting wheel motion. It is not particularly relevant to learning how to\nmake an RViz plugin, so I will kind of skim it.\n\n    \n    \n    void DriveWidget::paintEvent( QPaintEvent* event )\n    {\n    \n\nThe background color and crosshair lines are drawn differently depending on\nwhether this widget is enabled or not. This gives a nice visual indication of\nwhether the control is \u201clive\u201d.\n\n    \n    \n    QColor background;\n    QColor crosshair;\n    if( isEnabled() )\n    {\n      background = Qt::white;\n      crosshair = Qt::black;\n    }\n    else\n    {\n      background = Qt::lightGray;\n      crosshair = Qt::darkGray;\n    }\n    \n\nThe main visual is a square, centered in the widget\u2019s area. Here we compute\nthe size of the square and the horizontal and vertical offsets of it.\n\n    \n    \n    int w = width();\n    int h = height();\n    int size = (( w > h ) ? h : w) - 1;\n    int hpad = ( w - size ) / 2;\n    int vpad = ( h - size ) / 2;\n    \n    QPainter painter( this );\n    painter.setBrush( background );\n    painter.setPen( crosshair );\n    \n\nDraw the background square.\n\n    \n    \n    painter.drawRect( QRect( hpad, vpad, size, size ));\n    \n\nDraw a cross-hair inside the square.\n\n    \n    \n    painter.drawLine( hpad, height() / 2, hpad + size, height() / 2 );\n    painter.drawLine( width() / 2, vpad, width() / 2, vpad + size );\n    \n\nIf the widget is enabled and the velocities are not zero, draw some sweet\ngreen arrows showing possible paths that the wheels of a diff-drive robot\nwould take if it stayed at these velocities.\n\n    \n    \n    if( isEnabled() && (angular_velocity_ != 0 || linear_velocity_ != 0 ))\n    {\n      QPen arrow;\n      arrow.setWidth( size/20 );\n      arrow.setColor( Qt::green );\n      arrow.setCapStyle( Qt::RoundCap );\n      arrow.setJoinStyle( Qt::RoundJoin );\n      painter.setPen( arrow );\n    \n\nThis code steps along a central arc defined by the linear and angular\nvelocites. At each step, it computes where the left and right wheels would be\nand collects the resulting points in the left_track and right_track arrays.\n\n    \n    \n    const int step_count = 100;\n    QPointF left_track[ step_count ];\n    QPointF right_track[ step_count ];\n    \n    float half_track_width = size/4.0;\n    \n    float cx = w/2;\n    float cy = h/2;\n    left_track[ 0 ].setX( cx - half_track_width );\n    left_track[ 0 ].setY( cy );\n    right_track[ 0 ].setX( cx + half_track_width );\n    right_track[ 0 ].setY( cy );\n    float angle = M_PI/2;\n    float delta_angle = angular_velocity_ / step_count;\n    float step_dist = linear_velocity_ * size/2 / linear_scale_ / step_count;\n    for( int step = 1; step < step_count; step++ )\n    {\n      angle += delta_angle / 2;\n      float next_cx = cx + step_dist * cosf( angle );\n      float next_cy = cy - step_dist * sinf( angle );\n      angle += delta_angle / 2;\n    \n      left_track[ step ].setX( next_cx + half_track_width * cosf( angle + M_PI/2 ));\n      left_track[ step ].setY( next_cy - half_track_width * sinf( angle + M_PI/2 ));\n      right_track[ step ].setX( next_cx + half_track_width * cosf( angle - M_PI/2 ));\n      right_track[ step ].setY( next_cy - half_track_width * sinf( angle - M_PI/2 ));\n    \n      cx = next_cx;\n      cy = next_cy;\n    }\n    \n\nNow the track arrays are filled, so stroke each with a fat green line.\n\n    \n    \n    painter.drawPolyline( left_track, step_count );\n    painter.drawPolyline( right_track, step_count );\n    \n\nHere we decide which direction each arrowhead will point (forward or\nbackward). This works by comparing the arc length travelled by the center in\none step (step_dist) with the arc length travelled by the wheel\n(half_track_width * delta_angle).\n\n    \n    \n    int left_arrow_dir = (-step_dist + half_track_width * delta_angle > 0);\n    int right_arrow_dir = (-step_dist - half_track_width * delta_angle > 0);\n    \n\nUse MiterJoin for the arrowheads so we get a nice sharp point.\n\n    \n    \n    arrow.setJoinStyle( Qt::MiterJoin );\n    painter.setPen( arrow );\n    \n\nCompute and draw polylines for each arrowhead. This code could probably be\nmore elegant.\n\n    \n    \n        float head_len = size / 8.0;\n        QPointF arrow_head[ 3 ];\n        float x, y;\n        if( fabsf( -step_dist + half_track_width * delta_angle ) > .01 )\n        {\n          x = left_track[ step_count - 1 ].x();\n          y = left_track[ step_count - 1 ].y();\n          arrow_head[ 0 ].setX( x + head_len * cosf( angle + 3*M_PI/4 + left_arrow_dir * M_PI ));\n          arrow_head[ 0 ].setY( y - head_len * sinf( angle + 3*M_PI/4 + left_arrow_dir * M_PI ));\n          arrow_head[ 1 ].setX( x );\n          arrow_head[ 1 ].setY( y );\n          arrow_head[ 2 ].setX( x + head_len * cosf( angle - 3*M_PI/4 + left_arrow_dir * M_PI ));\n          arrow_head[ 2 ].setY( y - head_len * sinf( angle - 3*M_PI/4 + left_arrow_dir * M_PI ));\n          painter.drawPolyline( arrow_head, 3 );\n        }\n        if( fabsf( -step_dist - half_track_width * delta_angle ) > .01 )\n        {\n          x = right_track[ step_count - 1 ].x();\n          y = right_track[ step_count - 1 ].y();\n          arrow_head[ 0 ].setX( x + head_len * cosf( angle + 3*M_PI/4 + right_arrow_dir * M_PI ));\n          arrow_head[ 0 ].setY( y - head_len * sinf( angle + 3*M_PI/4 + right_arrow_dir * M_PI ));\n          arrow_head[ 1 ].setX( x );\n          arrow_head[ 1 ].setY( y );\n          arrow_head[ 2 ].setX( x + head_len * cosf( angle - 3*M_PI/4 + right_arrow_dir * M_PI ));\n          arrow_head[ 2 ].setY( y - head_len * sinf( angle - 3*M_PI/4 + right_arrow_dir * M_PI ));\n          painter.drawPolyline( arrow_head, 3 );\n        }\n      }\n    }\n    \n\nEvery mouse move event received here sends a velocity because Qt only sends us\nmouse move events if there was previously a mouse-press event while in the\nwidget.\n\n    \n    \n    void DriveWidget::mouseMoveEvent( QMouseEvent* event )\n    {\n      sendVelocitiesFromMouse( event->x(), event->y(), width(), height() );\n    }\n    \n\nMouse-press events should send the velocities too, of course.\n\n    \n    \n    void DriveWidget::mousePressEvent( QMouseEvent* event )\n    {\n      sendVelocitiesFromMouse( event->x(), event->y(), width(), height() );\n    }\n    \n\nWhen the mouse leaves the widget but the button is still held down, we don\u2019t\nget the leaveEvent() because the mouse is \u201cgrabbed\u201d (by default from Qt).\nHowever, when the mouse drags out of the widget and then other buttons are\npressed (or possibly other window-manager things happen), we will get a\nleaveEvent() but not a mouseReleaseEvent(). Without catching this event you\ncan have a robot stuck \u201con\u201d without the user controlling it.\n\n    \n    \n    void DriveWidget::leaveEvent( QEvent* event )\n    {\n      stop();\n    }\n    \n\nThe ordinary way to stop: let go of the mouse button.\n\n    \n    \n    void DriveWidget::mouseReleaseEvent( QMouseEvent* event )\n    {\n      stop();\n    }\n    \n\nCompute and emit linear and angular velocities based on Y and X mouse\npositions relative to the central square.\n\n    \n    \n    void DriveWidget::sendVelocitiesFromMouse( int x, int y, int width, int height )\n    {\n      int size = (( width > height ) ? height : width );\n      int hpad = ( width - size ) / 2;\n      int vpad = ( height - size ) / 2;\n    \n      linear_velocity_ = (1.0 - float( y - vpad ) / float( size / 2 )) * linear_scale_;\n      angular_velocity_ = (1.0 - float( x - hpad ) / float( size / 2 )) * angular_scale_;\n      Q_EMIT outputVelocity( linear_velocity_, angular_velocity_ );\n    \n\nupdate() is a QWidget function which schedules this widget to be repainted the\nnext time through the main event loop. We need this because the velocities\nhave just changed, so the arrows need to be redrawn to match.\n\n    \n    \n      update();\n    }\n    \n\nHow to stop: emit velocities of 0!\n\n    \n    \n    void DriveWidget::stop()\n    {\n      linear_velocity_ = 0;\n      angular_velocity_ = 0;\n      Q_EMIT outputVelocity( linear_velocity_, angular_velocity_ );\n      update();\n    }\n    \n\n##  Building the Plugin  \u00c2\u00b6\n\nTo build the plugin, just do the normal \u201crosmake\u201d thing:\n\n    \n    \n    rosmake rviz_plugin_tutorials\n    \n\n##  Exporting the Plugin  \u00c2\u00b6\n\nFor the plugin to be found and understood by other ROS packages (in this case,\nrviz), it needs a \u201cplugin_description.xml\u201d file. This file can be named\nanything you like, as it is specified in the plugin package\u2019s \u201cpackage.xml\u201d\nfile like so:\n\n    \n    \n    <export>\n        <rviz plugin=\"${prefix}/plugin_description.xml\"/>\n    </export>\n    \n\nThe contents of plugin_description.xml then look like this:\n\n    \n    \n    <library path=\"lib/librviz_plugin_tutorials\">\n      <class name=\"rviz_plugin_tutorials/Teleop\"\n             type=\"rviz_plugin_tutorials::TeleopPanel\"\n             base_class_type=\"rviz::Panel\">\n        <description>\n          A panel widget allowing simple diff-drive style robot base control.\n        </description>\n      </class>\n      <class name=\"rviz_plugin_tutorials/Imu\"\n             type=\"rviz_plugin_tutorials::ImuDisplay\"\n             base_class_type=\"rviz::Display\">\n        <description>\n          Displays direction and scale of accelerations from sensor_msgs/Imu messages.\n        </description>\n        <message_type>sensor_msgs/Imu</message_type>\n      </class>\n      <class name=\"rviz_plugin_tutorials/PlantFlag\"\n             type=\"rviz_plugin_tutorials::PlantFlagTool\"\n             base_class_type=\"rviz::Tool\">\n        <description>\n          Tool for planting flags on the ground plane in rviz.\n        </description>\n      </class>\n    </library>\n    \n\nThe first line says that the compiled library lives in\nlib/librviz_plugin_tutorials (the \u201d.so\u201d ending is appended by pluginlib\naccording to the OS). This path is relative to the top directory of the\npackage:\n\n    \n    \n    <library path=\"lib/librviz_plugin_tutorials\">\n    \n\nThe next section is a ` class  ` entry describing the TeleopPanel:\n\n    \n    \n    <class name=\"rviz_plugin_tutorials/Teleop\"\n           type=\"rviz_plugin_tutorials::TeleopPanel\"\n           base_class_type=\"rviz::Panel\">\n      <description>\n        A panel widget allowing simple diff-drive style robot base control.\n      </description>\n    </class>\n    \n\nThis specifies the name, type, base class, and description of the class. The\n_name_ field must be a combination of the first two strings given to the `\nPLUGINLIB_DECLARE_CLASS()  ` macro in the source file. It must be the\n\u201cpackage\u201d name, a \u201c/\u201d slash, then the \u201cdisplay name\u201d for the class. The\n\u201cdisplay name\u201d is the name used for the class in the user interface.\n\nThe _type_ entry must be the fully-qualified class name, including any\nnamespace(s) it is inside.\n\nThe _base_class_type_ is usually one of ` rviz::Panel  ` , ` rviz::Display  `\n, ` rviz::Tool  ` , or ` rviz::ViewController  ` .\n\nThe _description_ subsection is a simple text description of the class, which\nis shown in the class-chooser dialog and in the Displays panel help area. This\nsection can contain HTML, including hyperlinks, but the markup must be escaped\nto avoid being interpreted as XML markup. For example a link tag might look\nlike: ` &lt;a  href=\"my-web-page.html\"&gt;  ` .\n\nDisplay plugins can have multiple _message_type_ tags, which are used by RViz\nwhen you add a Display by selecting it\u2019s topic first.\n\n##  Trying It Out  \u00c2\u00b6\n\nOnce your RViz plugin is compiled and exported, simply run rviz normally:\n\n    \n    \n    rosrun rviz rviz\n    \n\nand rviz will use pluginlib to find all the plugins exported to it.\n\nAdd a Teleop panel by opening the \u201cPanels\u201d menu and then \u201cAdd New Panel\u201d\nwithin that. This should bring up a Panel class chooser dialog with \u201cTeleop\u201d\nin it (here it is \u201crviz_plugin_tutorials\u201d):\n\n![_images/teleop_plugin.png](_images/teleop_plugin.png)\n\nIf \u201cTeleop\u201d is not in your list of Panel types, look through RViz\u2019s console\noutput for error messages relating to plugin loading. Some common problems\nare:\n\n  * not having a plugin_description.xml file, \n  * not exporting it in the manifest.xml file, or \n  * not properly referencing the library file (like librviz_plugin_tutorials.so) from plugin_description.xml. \n\nOnce you\u2019ve added the Teleop panel to RViz, you just need to enter a topic\nname to publish the geometry_msgs/Twist command velocities on. Once a non-\nempty string has been entered in the \u201cOutput Topic\u201d field, the control square\narea should light up and accept mouse events. Holding the mouse button down in\nthe control area sends a linear velocity based on the Y position of the mouse\nrelative to the center and an angular velocity based on the X position of the\nmouse relative to the center.\n\n##  Next Steps  \u00c2\u00b6\n\nThis Teleop panel might be useful as it is, since it already sends out command\nvelocities appropriate for a diff-drive robot. However, there are a few things\nwhich might make it more useful:\n\n  * Adjustable scaling of the linear and angular velocities. \n  * Enforced maxima for the velocities. \n  * An adjustable robot width parameter, so that the curved arrows accurately show the arc a robot would traverse. \n  * A \u201cstrafe\u201d mode (maybe when holding down the Shift key) for robots like the PR2 with (more) holonomic drive ability. \n\n###  [ Table Of Contents ](index.html)\n\n  * TeleopPanel \n    * Overview \n    * The Plugin Code \n      * teleop_panel.h \n      * teleop_panel.cpp \n      * drive_widget.h \n      * drive_widget.cpp \n    * Building the Plugin \n    * Exporting the Plugin \n    * Trying It Out \n    * Next Steps \n\n###  Related Topics\n\n  * [ Documentation overview ](index.html)\n\n###  This Page\n\n  * [ Show Source ](_sources/panel_plugin_tutorial.txt)\n\n###  Quick search\n\nEnter search terms or a module, class or function name.\n\n\u00a92012, Willow Garage, Inc. | Powered by [ Sphinx 1.3.6 ](http://sphinx-\ndoc.org/) & [ Alabaster 0.7.7 ](https://github.com/bitprophet/alabaster) | [\nPage source ](_sources/panel_plugin_tutorial.txt)\n\n"
  },
  {
    "id": "move_group_interface/movegroupinterface8h.txt",
    "content": "  * [ Main Page  ](index.html)\n  * [ Related Pages  ](pages.html)\n  * [ Namespaces  ](namespaces.html)\n  * [ Classes  ](annotated.html)\n  * [ Files  ](files.html)\n\n  * [ File List  ](files.html)\n  * [ File Members  ](globals.html)\n\n  * [ move_group_interface ](dir_86133b455f0071bfbc47e5fc4156271f.html)\n  * [ include ](dir_3d22a3d18732584a197af2401e43fb95.html)\n  * [ moveit ](dir_72c55768156a02b8ccde1113e4a6e412.html)\n  * [ move_group_interface ](dir_fb80dfd8cc6e1dfc2d52978768ba8b2e.html)\n\nmove_group_interface.h\n\n[ Go to the documentation of this file. ](move__group__interface_8h.html)\n\n1  /*********************************************************************\n\n2  * Software License Agreement (BSD License)\n\n3  *\n\n4  * Copyright (c) 2014, SRI International\n\n5  * Copyright (c) 2012, Willow Garage, Inc.\n\n6  * All rights reserved.\n\n7  *\n\n8  * Redistribution and use in source and binary forms, with or without\n\n9  * modification, are permitted provided that the following conditions\n\n10  * are met:\n\n11  *\n\n12  * * Redistributions of source code must retain the above copyright\n\n13  * notice, this list of conditions and the following disclaimer.\n\n14  * * Redistributions in binary form must reproduce the above\n\n15  * copyright notice, this list of conditions and the following\n\n16  * disclaimer in the documentation and/or other materials provided\n\n17  * with the distribution.\n\n18  * * Neither the name of Willow Garage nor the names of its\n\n19  * contributors may be used to endorse or promote products derived\n\n20  * from this software without specific prior written permission.\n\n21  *\n\n22  * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\n23  * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n\n24  * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n\n25  * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE\n\n26  * COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n\n27  * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n\n28  * BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n\n29  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n\n30  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n\n31  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN\n\n32  * ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n\n33  * POSSIBILITY OF SUCH DAMAGE.\n\n34  *********************************************************************/\n\n35\n\n36  /* Author: Ioan Sucan, Sachin Chitta */\n\n37\n\n38  #ifndef MOVEIT_MOVE_GROUP_INTERFACE_MOVE_GROUP_INTERFACE_\n\n39  #define MOVEIT_MOVE_GROUP_INTERFACE_MOVE_GROUP_INTERFACE_\n\n40\n\n41  #include < [ moveit/macros/class_forward.h\n](../../../api/moveit_core/html/class__forward_8h.html) >\n\n42  #include < [ moveit/macros/deprecation.h\n](../../../api/moveit_core/html/deprecation_8h.html) >\n\n43  #include < [ moveit/robot_state/robot_state.h\n](../../../api/moveit_core/html/robot__state_8h.html) >\n\n44  #include <moveit_msgs/RobotTrajectory.h>\n\n45  #include <moveit_msgs/RobotState.h>\n\n46  #include <moveit_msgs/PlannerInterfaceDescription.h>\n\n47  #include <moveit_msgs/Constraints.h>\n\n48  #include <moveit_msgs/Grasp.h>\n\n49  #include <moveit_msgs/PlaceLocation.h>\n\n50  #include <moveit_msgs/MotionPlanRequest.h>\n\n51  #include <moveit_msgs/MoveGroupAction.h>\n\n52  #include <geometry_msgs/PoseStamped.h>\n\n53  #include < [ actionlib/client/simple_action_client.h\n](../../../api/actionlib/html/simple__action__client_8h.html) >\n\n54  #include <boost/shared_ptr.hpp>\n\n55  #include < [ tf/tf.h ](../../../api/tf/html/c++/tf_8h.html) >\n\n56\n\n57  namespace  [ moveit ](namespacemoveit.html)\n\n58  {\n\n60  namespace  [ planning_interface\n](../../../api/moveit_core/html/namespaceplanning__interface.html)\n\n61  {\n\n[ 62 ](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html) class  [\nMoveItErrorCode ](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html)\n:  public  moveit_msgs::MoveItErrorCodes\n\n63  {\n\n64  public  :\n\n[ 65\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#af155da6133976a737823585a12b6aaf6)\n[ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#af155da6133976a737823585a12b6aaf6)\n()\n\n66  {\n\n67  val = 0;\n\n68  }\n\n[ 69\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#a1a3910a9fc60cb15ce5eec4a0444c60a)\n[ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#a1a3910a9fc60cb15ce5eec4a0444c60a)\n(  int  code)\n\n70  {\n\n71  val = code;\n\n72  }\n\n[ 73\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#adeb720f484d065de44084139fcc54401)\n[ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#adeb720f484d065de44084139fcc54401)\n(  const  moveit_msgs::MoveItErrorCodes& code)\n\n74  {\n\n75  val = code.val;\n\n76  }\n\n[ 77\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#ac6b141036599f1675ee8b4079adc36c5)\nexplicit  operator  bool()  const\n\n78  {\n\n79  return  val == moveit_msgs::MoveItErrorCodes::SUCCESS;\n\n80  }\n\n[ 81\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#ad7c12c18bec22efc4271b565950a3803)\nbool  [ operator==\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#ad7c12c18bec22efc4271b565950a3803)\n(  const  int  c)  const\n\n82  {\n\n83  return  val == c;\n\n84  }\n\n[ 85\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#a8abfea59c8baf37e4a649a09c0483f59)\nbool  [ operator!=\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#a8abfea59c8baf37e4a649a09c0483f59)\n(  const  int  c)  const\n\n86  {\n\n87  return  val != c;\n\n88  }\n\n89  };\n\n90\n\n91  [ MOVEIT_CLASS_FORWARD\n](namespacemoveit_1_1planning__interface.html#a6e3731ab08afb210c97f7d8400ccb8b6)\n( [ MoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html) );\n\n92\n\n[ 98 ](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html) class  [\nMoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html)\n\n99  {\n\n100  public  :\n\n[ 102\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html#a11613e2bc76eb2b956d7c6eb9357139d)\nstatic  const  std::string [ ROBOT_DESCRIPTION\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html#a11613e2bc76eb2b956d7c6eb9357139d)\n;\n\n103\n\n[ 105\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html)\nstruct  [ Options\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html)\n\n106  {\n\n[ 107\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html#acd2d919de7135c86cb0127ec3cd82ee6)\n[ Options\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html#acd2d919de7135c86cb0127ec3cd82ee6)\n(  const  std::string& group_name,  const  std::string& desc =\nROBOT_DESCRIPTION,\n\n108  const  [ ros::NodeHandle\n](../../../api/roscpp/html/structros_1_1NodeHandle_1_1no__validate.html) &\nnode_handle = [ ros::NodeHandle\n](../../../api/roscpp/html/structros_1_1NodeHandle_1_1no__validate.html) ())\n\n109  : group_name_(group_name), robot_description_( [ desc\n](../../../api/moveit_kinematics/html/namespacecreate__ikfast__moveit__plugin.html#acea37eb824dcaa53b6a91f548ee1b5f7)\n), node_handle_(node_handle)\n\n110  {\n\n111  }\n\n112\n\n[ 114\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html#a2cf3354acfc47c1708dd511be0bca347)\nstd::string [ group_name_\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html#a2cf3354acfc47c1708dd511be0bca347)\n;\n\n115\n\n[ 117\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html#a6d808c8691c7bb9f96ea7c586046b439)\nstd::string [ robot_description_\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html#a6d808c8691c7bb9f96ea7c586046b439)\n;\n\n118\n\n[ 120\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html#a2e72f8b0daa9a9f7067648c9eca24b15)\nrobot_model::RobotModelConstPtr [ robot_model_\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html#a2e72f8b0daa9a9f7067648c9eca24b15)\n;\n\n121\n\n[ 122\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html#a4d5aa2c0acde1db173173f4878ee3e27)\n[ ros::NodeHandle\n](../../../api/roscpp/html/structros_1_1NodeHandle_1_1no__validate.html) [\nnode_handle_\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html#a4d5aa2c0acde1db173173f4878ee3e27)\n;\n\n123  };\n\n124\n\n125  [ MOVEIT_STRUCT_FORWARD\n](../../../api/moveit_core/html/namespacecollision__detection.html#a1cb8da8467ea8e22af94de00c401e975)\n( [ Plan\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html) );\n\n126\n\n[ 128\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html)\nstruct  [ Plan\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html)\n\n129  {\n\n[ 131\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html#ac9333762e84a22da5879866413dec8c6)\nmoveit_msgs::RobotState [ start_state_\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html#ac9333762e84a22da5879866413dec8c6)\n;\n\n132\n\n[ 134\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html#af974e387daa3c09c4e19f29657a2b7cb)\nmoveit_msgs::RobotTrajectory [ trajectory_\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html#af974e387daa3c09c4e19f29657a2b7cb)\n;\n\n135\n\n[ 137\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html#ab479de7a2494a40891cc7baf51a202a8)\ndouble  [ planning_time_\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html#ab479de7a2494a40891cc7baf51a202a8)\n;\n\n138  };\n\n139\n\n149  [ MoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html) (  const  [\nOptions\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html) &\nopt,\n\n150  const  [ boost::shared_ptr<tf::Transformer>\n](../../../api/roscpp_traits/html/classboost_1_1shared__ptr.html) & [ tf\n](../../../api/eigen_conversions/html/namespacetf.html) = [\nboost::shared_ptr<tf::Transformer>\n](../../../api/roscpp_traits/html/classboost_1_1shared__ptr.html) (),\n\n151  const  [ ros::WallDuration\n](../../../api/rostime/html/classros_1_1WallDuration.html) & wait_for_servers\n= [ ros::WallDuration\n](../../../api/rostime/html/classros_1_1WallDuration.html) ());\n\n152  [ MOVEIT_DEPRECATED\n](namespacemoveit_1_1planning__interface.html#a706399608538b81b2936e34817260537)\n[ MoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html) (  const  [\nOptions\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html) &\nopt,  const  [ boost::shared_ptr<tf::Transformer>\n](../../../api/roscpp_traits/html/classboost_1_1shared__ptr.html) & [ tf\n](../../../api/eigen_conversions/html/namespacetf.html) ,\n\n153  const  [ ros::Duration\n](../../../api/rostime/html/classros_1_1Duration.html) & wait_for_servers);\n\n154\n\n161  [ MoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html) (  const\nstd::string& [ group\n](namespacemovegroup__interface.html#abd91430536f622d99cd24987c32c6d55) ,\n\n162  const  [ boost::shared_ptr<tf::Transformer>\n](../../../api/roscpp_traits/html/classboost_1_1shared__ptr.html) & [ tf\n](../../../api/eigen_conversions/html/namespacetf.html) = [\nboost::shared_ptr<tf::Transformer>\n](../../../api/roscpp_traits/html/classboost_1_1shared__ptr.html) (),\n\n163  const  [ ros::WallDuration\n](../../../api/rostime/html/classros_1_1WallDuration.html) & wait_for_servers\n= [ ros::WallDuration\n](../../../api/rostime/html/classros_1_1WallDuration.html) ());\n\n164  [ MOVEIT_DEPRECATED\n](namespacemoveit_1_1planning__interface.html#a706399608538b81b2936e34817260537)\n[ MoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html) (  const\nstd::string& group,  const  [ boost::shared_ptr<tf::Transformer>\n](../../../api/roscpp_traits/html/classboost_1_1shared__ptr.html) & [ tf\n](../../../api/eigen_conversions/html/namespacetf.html) ,\n\n165  const  [ ros::Duration\n](../../../api/rostime/html/classros_1_1Duration.html) & wait_for_servers);\n\n166\n\n167  ~ [ MoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html) ();\n\n168\n\n174  [ MoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html) (  const  [\nMoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html) &) =  delete\n;\n\n175  [ MoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html) & operator=(\nconst  [ MoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html) &) =  delete\n;\n\n176\n\n177  [ MoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html) ( [\nMoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html) && other);\n\n178  [ MoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html) & operator=(\n[ MoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html) && other);\n\n179\n\n181  const  std::string& [ getName\n](../../../api/rosconsole/html/namespaceros_1_1console_1_1impl.html#a99d74e1500c0ebb7f3f3fb98ae77037f)\n()  const  ;\n\n182\n\n185  const  std::vector<std::string> getNamedTargets();\n\n186\n\n188  robot_model::RobotModelConstPtr getRobotModel()  const  ;\n\n189\n\n191  const  [ ros::NodeHandle\n](../../../api/roscpp/html/structros_1_1NodeHandle_1_1no__validate.html) &\ngetNodeHandle()  const  ;\n\n192\n\n194  const  std::string& getPlanningFrame()  const  ;\n\n195\n\n197  const  std::vector<std::string>& getJointNames();\n\n198\n\n200  const  std::vector<std::string>& getLinkNames();\n\n201\n\n203  std::map<std::string, double> getNamedTargetValues(  const  std::string&\nname);\n\n204\n\n206  const  std::vector<std::string>& getActiveJoints()  const  ;\n\n207\n\n209  const  std::vector<std::string>& getJoints()  const  ;\n\n210\n\n213  unsigned  int  getVariableCount()  const  ;\n\n214\n\n216  bool  getInterfaceDescription(moveit_msgs::PlannerInterfaceDescription&\ndesc);\n\n217\n\n219  std::map<std::string, std::string> getPlannerParams(  const  std::string&\nplanner_id,  const  std::string& group =  \"\"  );\n\n220\n\n222  void  setPlannerParams(  const  std::string& planner_id,  const\nstd::string& group,\n\n223  const  std::map<std::string, std::string>& params,  bool  bReplace =\nfalse  );\n\n224\n\n226  std::string getDefaultPlannerId(  const  std::string& group =  \"\"  )\nconst  ;\n\n227\n\n229  void  setPlannerId(  const  std::string& planner_id);\n\n230\n\n232  const  std::string& getPlannerId()  const  ;\n\n233\n\n235  void  setPlanningTime(  double  seconds);\n\n236\n\n239  void  setNumPlanningAttempts(  unsigned  int  num_planning_attempts);\n\n240\n\n246  void  setMaxVelocityScalingFactor(  double  max_velocity_scaling_factor);\n\n247\n\n253  void  setMaxAccelerationScalingFactor(  double\nmax_acceleration_scaling_factor);\n\n254\n\n256  double  getPlanningTime()  const  ;\n\n257\n\n260  double  getGoalJointTolerance()  const  ;\n\n261\n\n264  double  getGoalPositionTolerance()  const  ;\n\n265\n\n268  double  getGoalOrientationTolerance()  const  ;\n\n269\n\n276  void  setGoalTolerance(  double  tolerance);\n\n277\n\n280  void  setGoalJointTolerance(  double  tolerance);\n\n281\n\n283  void  setGoalPositionTolerance(  double  tolerance);\n\n284\n\n286  void  setGoalOrientationTolerance(  double  tolerance);\n\n287\n\n292  void  setWorkspace(  double  minx,  double  miny,  double  minz,  double\nmaxx,  double  maxy,  double  maxz);\n\n293\n\n296  void  setStartState(  const  moveit_msgs::RobotState& start_state);\n\n297\n\n300  void  setStartState(  const  robot_state::RobotState& start_state);\n\n301\n\n303  void  setStartStateToCurrentState();\n\n304\n\n307  void  setSupportSurfaceName(  const  std::string& name);\n\n308\n\n339  bool  setJointValueTarget(  const  std::vector<double>&\ngroup_variable_values);\n\n340\n\n356  bool  setJointValueTarget(  const  std::map<std::string, double>&\nvariable_values);\n\n357\n\n367  bool  setJointValueTarget(  const  robot_state::RobotState& robot_state);\n\n368\n\n380  bool  setJointValueTarget(  const  std::string& joint_name,  const\nstd::vector<double>& values);\n\n381\n\n393  bool  setJointValueTarget(  const  std::string& joint_name,  double\nvalue);\n\n394\n\n405  bool  setJointValueTarget(  const  sensor_msgs::JointState& state);\n\n406\n\n418  bool  setJointValueTarget(  const  geometry_msgs::Pose& eef_pose,  const\nstd::string& end_effector_link =  \"\"  );\n\n419\n\n431  bool  setJointValueTarget(  const  geometry_msgs::PoseStamped& eef_pose,\nconst  std::string& end_effector_link =  \"\"  );\n\n432\n\n444  bool  setJointValueTarget(  const  Eigen::Affine3d& eef_pose,  const\nstd::string& end_effector_link =  \"\"  );\n\n445\n\n456  bool  setApproximateJointValueTarget(  const  geometry_msgs::Pose&\neef_pose,  const  std::string& end_effector_link =  \"\"  );\n\n457\n\n468  bool  setApproximateJointValueTarget(  const  geometry_msgs::PoseStamped&\neef_pose,\n\n469  const  std::string& end_effector_link =  \"\"  );\n\n470\n\n481  bool  setApproximateJointValueTarget(  const  Eigen::Affine3d& eef_pose,\nconst  std::string& end_effector_link =  \"\"  );\n\n482\n\n487  void  setRandomTarget();\n\n488\n\n491  bool  setNamedTarget(  const  std::string& name);\n\n492\n\n494  const  robot_state::RobotState& getJointValueTarget()  const  ;\n\n495\n\n517  bool  setPositionTarget(  double  x,  double  y,  double  z,  const\nstd::string& end_effector_link =  \"\"  );\n\n518\n\n526  bool  setRPYTarget(  double  roll,  double  pitch,  double  yaw,  const\nstd::string& end_effector_link =  \"\"  );\n\n527\n\n536  bool  setOrientationTarget(  double  x,  double  y,  double  z,  double\nw,  const  std::string& end_effector_link =  \"\"  );\n\n537\n\n545  bool  setPoseTarget(  const  Eigen::Affine3d& end_effector_pose,  const\nstd::string& end_effector_link =  \"\"  );\n\n546\n\n554  bool  setPoseTarget(  const  geometry_msgs::Pose& target,  const\nstd::string& end_effector_link =  \"\"  );\n\n555\n\n563  bool  setPoseTarget(  const  geometry_msgs::PoseStamped& target,  const\nstd::string& end_effector_link =  \"\"  );\n\n564\n\n583  bool  setPoseTargets(  const  [ EigenSTL::vector_Affine3d\n](../../../api/eigen_stl_containers/html/namespaceEigenSTL.html#a14f080ffb504c39aeeafc3e1c7590801)\n& end_effector_pose,  const  std::string& end_effector_link =  \"\"  );\n\n584\n\n603  bool  setPoseTargets(  const  std::vector<geometry_msgs::Pose>& target,\nconst  std::string& end_effector_link =  \"\"  );\n\n604\n\n623  bool  setPoseTargets(  const  std::vector<geometry_msgs::PoseStamped>&\ntarget,  const  std::string& end_effector_link =  \"\"  );\n\n624\n\n626  void  setPoseReferenceFrame(  const  std::string& pose_reference_frame);\n\n627\n\n631  bool  setEndEffectorLink(  const  std::string& end_effector_link);\n\n632\n\n635  bool  setEndEffector(  const  std::string& eef_name);\n\n636\n\n638  void  clearPoseTarget(  const  std::string& end_effector_link =  \"\"  );\n\n639\n\n641  void  clearPoseTargets();\n\n642\n\n649  const  geometry_msgs::PoseStamped& getPoseTarget(  const  std::string&\nend_effector_link =  \"\"  )  const  ;\n\n650\n\n656  const  std::vector<geometry_msgs::PoseStamped>& getPoseTargets(  const\nstd::string& end_effector_link =  \"\"  )  const  ;\n\n657\n\n663  const  std::string& getEndEffectorLink()  const  ;\n\n664\n\n670  const  std::string& getEndEffector()  const  ;\n\n671\n\n674  const  std::string& getPoseReferenceFrame()  const  ;\n\n675\n\n686  [ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html) asyncMove();\n\n687\n\n691  [ actionlib::SimpleActionClient<moveit_msgs::MoveGroupAction>\n](../../../api/actionlib/html/classactionlib_1_1SimpleActionClient.html) &\ngetMoveGroupClient()  const  ;\n\n692\n\n697  [ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html) move();\n\n698\n\n702  [ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html) plan( [ Plan\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html) &\nplan);\n\n703\n\n705  [ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html) asyncExecute(\nconst  [ Plan\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html) &\nplan);\n\n706\n\n708  [ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html) [ execute\n](../../../api/roscpp/html/namespaceros_1_1master.html#a6148ee923ef1602d2093daff82573043)\n(  const  [ Plan\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html) &\nplan);\n\n709\n\n719  double  computeCartesianPath(  const  std::vector<geometry_msgs::Pose>&\nwaypoints,  double  eef_step,  double  jump_threshold,\n\n720  moveit_msgs::RobotTrajectory& trajectory,  bool  avoid_collisions =  true\n,\n\n721  moveit_msgs::MoveItErrorCodes* error_code = NULL);\n\n722\n\n735  double  computeCartesianPath(  const  std::vector<geometry_msgs::Pose>&\nwaypoints,  double  eef_step,  double  jump_threshold,\n\n736  moveit_msgs::RobotTrajectory& trajectory,\n\n737  const  moveit_msgs::Constraints& path_constraints,  bool\navoid_collisions =  true  ,\n\n738  moveit_msgs::MoveItErrorCodes* error_code = NULL);\n\n739\n\n741  void  stop();\n\n742\n\n745  void  allowLooking(  bool  flag);\n\n746\n\n748  void  allowReplanning(  bool  flag);\n\n749\n\n752  void  constructMotionPlanRequest(moveit_msgs::MotionPlanRequest&\nrequest);\n\n753\n\n764  [ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html) pick(  const\nstd::string& object  ,  bool  plan_only =  false  );\n\n765\n\n767  [ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html) pick(  const\nstd::string& object  ,  const  moveit_msgs::Grasp& grasp,  bool  plan_only =\nfalse  );\n\n768\n\n772  [ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html) pick(  const\nstd::string& object  ,  const  std::vector<moveit_msgs::Grasp>& grasps,\n\n773  bool  plan_only =  false  );\n\n774\n\n778  [ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html)\nplanGraspsAndPick(  const  std::string& object  =  \"\"  ,  bool  plan_only =\nfalse  );\n\n779\n\n783  [ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html)\nplanGraspsAndPick(  const  moveit_msgs::CollisionObject& object  ,  bool\nplan_only =  false  );\n\n784\n\n786  [ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html) place(  const\nstd::string& object  ,  bool  plan_only =  false  );\n\n787\n\n789  [ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html) place(  const\nstd::string& object  ,  const  std::vector<moveit_msgs::PlaceLocation>&\nlocations,\n\n790  bool  plan_only =  false  );\n\n791\n\n793  [ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html) place(  const\nstd::string& object  ,  const  std::vector<geometry_msgs::PoseStamped>& poses,\n\n794  bool  plan_only =  false  );\n\n795\n\n797  [ MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html) place(  const\nstd::string& object  ,  const  geometry_msgs::PoseStamped& pose,  bool\nplan_only =  false  );\n\n798\n\n805  bool  [ attachObject ](demo_8cpp.html#a7b9e3632e33ade1fb91f781cf2a349b8)\n(  const  std::string& object  ,  const  std::string& link =  \"\"  );\n\n806\n\n815  bool  [ attachObject ](demo_8cpp.html#a7b9e3632e33ade1fb91f781cf2a349b8)\n(  const  std::string& object  ,  const  std::string& link,  const\nstd::vector<std::string>& touch_links);\n\n816\n\n822  bool  detachObject(  const  std::string& name =  \"\"  );\n\n823\n\n836  bool  startStateMonitor(  double  wait = 1.0);\n\n837\n\n839  std::vector<double> getCurrentJointValues();\n\n840\n\n842  robot_state::RobotStatePtr getCurrentState(  double  wait = 1);\n\n843\n\n847  geometry_msgs::PoseStamped getCurrentPose(  const  std::string&\nend_effector_link =  \"\"  );\n\n848\n\n852  std::vector<double> getCurrentRPY(  const  std::string& end_effector_link\n=  \"\"  );\n\n853\n\n855  std::vector<double> getRandomJointValues();\n\n856\n\n860  geometry_msgs::PoseStamped getRandomPose(  const  std::string&\nend_effector_link =  \"\"  );\n\n861\n\n873  void  rememberJointValues(  const  std::string& name);\n\n874\n\n879  void  rememberJointValues(  const  std::string& name,  const\nstd::vector<double>& values);\n\n880\n\n[ 882\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html#a7da7361401c0810970a6b69105c5ee01)\nconst  std::map<std::string, std::vector<double> >& [ getRememberedJointValues\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html#a7da7361401c0810970a6b69105c5ee01)\n()  const\n\n883  {\n\n884  return  remembered_joint_values_;\n\n885  }\n\n886\n\n888  void  forgetJointValues(  const  std::string& [ name\n](../../../api/eigenpy/html/namespacecompile.html#a46be63463291fe312cb52b5643ad6c3a)\n);\n\n889\n\n898  void  setConstraintsDatabase(  const  std::string& host,  unsigned  int\nport);\n\n899\n\n901  std::vector<std::string> getKnownConstraints()  const  ;\n\n902\n\n906  moveit_msgs::Constraints getPathConstraints()  const  ;\n\n907\n\n911  bool  setPathConstraints(  const  std::string& constraint);\n\n912\n\n916  void  setPathConstraints(  const  moveit_msgs::Constraints& constraint);\n\n917\n\n920  void  clearPathConstraints();\n\n921\n\n922  moveit_msgs::TrajectoryConstraints getTrajectoryConstraints()  const  ;\n\n923  void  setTrajectoryConstraints(  const\nmoveit_msgs::TrajectoryConstraints& constraint);\n\n924  void  clearTrajectoryConstraints();\n\n925\n\n928  private  :\n\n[ 929\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html#a1dbc2672b6abc380e425b06e1d282c88)\nstd::map<std::string, std::vector<double> > [ remembered_joint_values_\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html#a1dbc2672b6abc380e425b06e1d282c88)\n;\n\n[ 930\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html#a64ddb8064073c6e9ed50b0a448362052)\nclass  [ MoveGroupInterfaceImpl\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1MoveGroupInterfaceImpl.html)\n;\n\n931  [ MoveGroupInterfaceImpl\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1MoveGroupInterfaceImpl.html)\n* [ impl_\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html#a64ddb8064073c6e9ed50b0a448362052)\n;\n\n932  };\n\n933  }\n\n934  }\n\n935\n\n936  #endif\n\n[ moveit::planning_interface::MoveItErrorCode::MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#adeb720f484d065de44084139fcc54401)\n\nMoveItErrorCode(const moveit_msgs::MoveItErrorCodes &code)\n\n**Definition:** [ move_group_interface.h:73\n](move__group__interface_8h_source.html#l00073)\n\n[ moveit::planning_interface::MoveGroupInterface::MoveGroupInterfaceImpl\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1MoveGroupInterfaceImpl.html)\n\n**Definition:** [ move_group_interface.cpp:91\n](move__group__interface_8cpp_source.html#l00091)\n\n[ moveit::planning_interface::MoveGroupInterface::getRememberedJointValues\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html#a7da7361401c0810970a6b69105c5ee01)\n\nconst std::map< std::string, std::vector< double > > &\ngetRememberedJointValues() const\n\nGet the currently remembered map of names to joint values.\n\n**Definition:** [ move_group_interface.h:882\n](move__group__interface_8h_source.html#l00882)\n\n[ moveit::planning_interface::MoveGroupInterface::Plan::trajectory_\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html#af974e387daa3c09c4e19f29657a2b7cb)\n\nmoveit_msgs::RobotTrajectory trajectory_\n\nThe trajectory of the robot (may not contain joints that are the same as for\nthe start_state_) ...\n\n**Definition:** [ move_group_interface.h:134\n](move__group__interface_8h_source.html#l00134)\n\n[ ros::NodeHandle\n](../../../api/roscpp/html/structros_1_1NodeHandle_1_1no__validate.html)\n\n[ moveit::planning_interface::MoveGroupInterface::ROBOT_DESCRIPTION\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html#a11613e2bc76eb2b956d7c6eb9357139d)\n\nstatic const std::string ROBOT_DESCRIPTION\n\nDefault ROS parameter name from where to read the robot&#39;s URDF. Set to\n&#39;robot_description&#39;.\n\n**Definition:** [ move_group_interface.h:102\n](move__group__interface_8h_source.html#l00102)\n\n[ deprecation.h ](../../../api/moveit_core/html/deprecation_8h.html)\n\n[ moveit::planning_interface::MoveItErrorCode::MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#af155da6133976a737823585a12b6aaf6)\n\nMoveItErrorCode()\n\n**Definition:** [ move_group_interface.h:65\n](move__group__interface_8h_source.html#l00065)\n\n[ desc\n](../../../api/moveit_kinematics/html/namespacecreate__ikfast__moveit__plugin.html#acea37eb824dcaa53b6a91f548ee1b5f7)\n\ndesc\n\n[ EigenSTL::vector_Affine3d\n](../../../api/eigen_stl_containers/html/namespaceEigenSTL.html#a14f080ffb504c39aeeafc3e1c7590801)\n\nstd::vector< Eigen::Affine3d, Eigen::aligned_allocator< Eigen::Affine3d > >\nvector_Affine3d\n\n[ moveit::planning_interface::MOVEIT_DEPRECATED\n](namespacemoveit_1_1planning__interface.html#a706399608538b81b2936e34817260537)\n\nmoveit::planning_interface::MoveGroup MOVEIT_DEPRECATED\n\n[ moveit::planning_interface::MoveItErrorCode::operator==\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#ad7c12c18bec22efc4271b565950a3803)\n\nbool operator==(const int c) const\n\n**Definition:** [ move_group_interface.h:81\n](move__group__interface_8h_source.html#l00081)\n\n[ attachObject ](demo_8cpp.html#a7b9e3632e33ade1fb91f781cf2a349b8)\n\nvoid attachObject(void)\n\n**Definition:** [ demo.cpp:104 ](demo_8cpp_source.html#l00104)\n\n[ moveit::planning_interface::MoveGroupInterface::remembered_joint_values_\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html#a1dbc2672b6abc380e425b06e1d282c88)\n\nstd::map< std::string, std::vector< double > > remembered_joint_values_\n\n**Definition:** [ move_group_interface.h:929\n](move__group__interface_8h_source.html#l00929)\n\n[ getName\n](../../../api/rosconsole/html/namespaceros_1_1console_1_1impl.html#a99d74e1500c0ebb7f3f3fb98ae77037f)\n\nstd::string getName(void *handle)\n\n[ name\n](../../../api/eigenpy/html/namespacecompile.html#a46be63463291fe312cb52b5643ad6c3a)\n\nname\n\n[ ros::WallDuration ](../../../api/rostime/html/classros_1_1WallDuration.html)\n\n[ tf ](../../../api/eigen_conversions/html/namespacetf.html)\n\n[ class_forward.h ](../../../api/moveit_core/html/class__forward_8h.html)\n\n[ moveit::planning_interface::MoveGroupInterface::Options\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html)\n\nSpecification of options to use when constructing the MoveGroupInterface\nclass.\n\n**Definition:** [ move_group_interface.h:105\n](move__group__interface_8h_source.html#l00105)\n\n[ moveit::planning_interface::MoveGroupInterface::Options::robot_description_\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html#a6d808c8691c7bb9f96ea7c586046b439)\n\nstd::string robot_description_\n\nThe robot description parameter name (if different from default)\n\n**Definition:** [ move_group_interface.h:117\n](move__group__interface_8h_source.html#l00117)\n\n[ boost::shared_ptr< tf::Transformer >\n](../../../api/roscpp_traits/html/classboost_1_1shared__ptr.html)\n\n[ movegroup_interface.group\n](namespacemovegroup__interface.html#abd91430536f622d99cd24987c32c6d55)\n\ngroup\n\n**Definition:** [ movegroup_interface.py:5\n](movegroup__interface_8py_source.html#l00005)\n\n[ moveit::planning_interface::MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html)\n\n**Definition:** [ move_group_interface.h:62\n](move__group__interface_8h_source.html#l00062)\n\n[ MOVEIT_STRUCT_FORWARD\n](../../../api/moveit_core/html/namespacecollision__detection.html#a1cb8da8467ea8e22af94de00c401e975)\n\nMOVEIT_STRUCT_FORWARD(CollisionGeometryData)\n\n[ moveit::planning_interface::MoveItErrorCode::operator!=\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#a8abfea59c8baf37e4a649a09c0483f59)\n\nbool operator!=(const int c) const\n\n**Definition:** [ move_group_interface.h:85\n](move__group__interface_8h_source.html#l00085)\n\n[ execute\n](../../../api/roscpp/html/namespaceros_1_1master.html#a6148ee923ef1602d2093daff82573043)\n\nROSCPP_DECL bool execute(const std::string &method, const XmlRpc::XmlRpcValue\n&request, XmlRpc::XmlRpcValue &response, XmlRpc::XmlRpcValue &payload, bool\nwait_for_master)\n\n[ actionlib::SimpleActionClient\n](../../../api/actionlib/html/classactionlib_1_1SimpleActionClient.html)\n\n[ moveit::planning_interface::MoveGroupInterface::Options::Options\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html#acd2d919de7135c86cb0127ec3cd82ee6)\n\nOptions(const std::string &group_name, const std::string\n&desc=ROBOT_DESCRIPTION, const ros::NodeHandle &node_handle=ros::NodeHandle())\n\n**Definition:** [ move_group_interface.h:107\n](move__group__interface_8h_source.html#l00107)\n\n[ moveit::planning_interface::MoveGroupInterface::impl_\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html#a64ddb8064073c6e9ed50b0a448362052)\n\nMoveGroupInterfaceImpl * impl_\n\n**Definition:** [ move_group_interface.h:930\n](move__group__interface_8h_source.html#l00930)\n\n[ robot_state.h ](../../../api/moveit_core/html/robot__state_8h.html)\n\n[ moveit::planning_interface::MoveGroupInterface\n](classmoveit_1_1planning__interface_1_1MoveGroupInterface.html)\n\nClient class to conveniently use the ROS interfaces provided by the move_group\nnode.\n\n**Definition:** [ move_group_interface.h:98\n](move__group__interface_8h_source.html#l00098)\n\n[ moveit::planning_interface::MoveGroupInterface::Options::robot_model_\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html#a2e72f8b0daa9a9f7067648c9eca24b15)\n\nrobot_model::RobotModelConstPtr robot_model_\n\nOptionally, an instance of the RobotModel to use can be also specified.\n\n**Definition:** [ move_group_interface.h:120\n](move__group__interface_8h_source.html#l00120)\n\n[ moveit::planning_interface::MoveGroupInterface::Plan::start_state_\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html#ac9333762e84a22da5879866413dec8c6)\n\nmoveit_msgs::RobotState start_state_\n\nThe full starting state used for planning.\n\n**Definition:** [ move_group_interface.h:131\n](move__group__interface_8h_source.html#l00131)\n\n[ ros::Duration ](../../../api/rostime/html/classros_1_1Duration.html)\n\n[ planning_interface\n](../../../api/moveit_core/html/namespaceplanning__interface.html)\n\n[ moveit::planning_interface::MoveItErrorCode::MoveItErrorCode\n](classmoveit_1_1planning__interface_1_1MoveItErrorCode.html#a1a3910a9fc60cb15ce5eec4a0444c60a)\n\nMoveItErrorCode(int code)\n\n**Definition:** [ move_group_interface.h:69\n](move__group__interface_8h_source.html#l00069)\n\n[ moveit ](namespacemoveit.html)\n\n[ moveit::planning_interface::MoveGroupInterface::Options::group_name_\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html#a2cf3354acfc47c1708dd511be0bca347)\n\nstd::string group_name_\n\nThe group to construct the class instance for.\n\n**Definition:** [ move_group_interface.h:114\n](move__group__interface_8h_source.html#l00114)\n\n[ moveit::planning_interface::MoveGroupInterface::Plan::planning_time_\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html#ab479de7a2494a40891cc7baf51a202a8)\n\ndouble planning_time_\n\nThe amount of time it took to generate the plan.\n\n**Definition:** [ move_group_interface.h:137\n](move__group__interface_8h_source.html#l00137)\n\n[ moveit::planning_interface::MoveGroupInterface::Plan\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Plan.html)\n\nThe representation of a motion plan (as ROS messasges)\n\n**Definition:** [ move_group_interface.h:128\n](move__group__interface_8h_source.html#l00128)\n\n[ moveit::planning_interface::MoveGroupInterface::Options::node_handle_\n](structmoveit_1_1planning__interface_1_1MoveGroupInterface_1_1Options.html#a4d5aa2c0acde1db173173f4878ee3e27)\n\nros::NodeHandle node_handle_\n\n**Definition:** [ move_group_interface.h:122\n](move__group__interface_8h_source.html#l00122)\n\n[ simple_action_client.h\n](../../../api/actionlib/html/simple__action__client_8h.html)\n\n[ tf.h ](../../../api/tf/html/c++/tf_8h.html)\n\n[ moveit::planning_interface::MOVEIT_CLASS_FORWARD\n](namespacemoveit_1_1planning__interface.html#a6e3731ab08afb210c97f7d8400ccb8b6)\n\nMOVEIT_CLASS_FORWARD(MoveGroupInterface)\n\n  \n\n* * *\n\n[ planning_interface ](http://wiki.ros.org/planning_interface)  \nAuthor(s): Ioan Sucan  autogenerated on Sun Oct 18 2020 13:18:50\n\n"
  },
  {
    "id": "ros2_camera/video.txt",
    "content": "[\n![Logo](https://cdn.sanity.io/images/s18ewfw4/production/3534345dbdb3bbf9ec698e5024d0c4f72eeb30f5-149x20.svg)\n](https://www.stereolabs.com)\n\n  * [ Documentation ](https://www.stereolabs.com/docs/)\n  * [ Samples ](https://www.stereolabs.com/docs/samples/)\n  * [ API Reference ](https://www.stereolabs.com/docs/api/)\n  * [ Support ](https://support.stereolabs.com/hc/en-us/)\n  * [ Downloads ](https://www.stereolabs.com/developers/release/)\n\n[ ](https://github.com/stereolabs/zed-sdk \"GitHub\")\n\n  * Video with RVIZ2 \n  * Video subscribing in C++ \n\n[ Docs Home  ](https://www.stereolabs.com/docs/)\n\n  * Getting Started \n  * [ Get Started With ZED  ](https://www.stereolabs.com/docs/get-started-with-zed/)\n  * [ Get Started With ZED X  ](https://www.stereolabs.com/docs/get-started-with-zed-x/) [ Setup for ZED Box Orin NX ](https://www.stereolabs.com/docs/get-started-with-zed-x/zed-box-orin-nx-setup/) [ Setup for AGX Orin / Xavier ](https://www.stereolabs.com/docs/get-started-with-zed-x/jetson-agx-devkit-setup/) [ Setup for Xavier NX DevKits ](https://www.stereolabs.com/docs/get-started-with-zed-x/jetson-xavier-nx-devkit-setup/) [ Setup for Orin Nano / NX DevKits ](https://www.stereolabs.com/docs/get-started-with-zed-x/jetson-orin-devkit-setup/) [ Developing with ZED X on a PC ](https://www.stereolabs.com/docs/get-started-with-zed-x/zed-x-dev-on-pc/) [ Troubleshooting ](https://www.stereolabs.com/docs/get-started-with-zed-x/troubleshooting/) [ Advanced Topics ](https://www.stereolabs.com/docs/get-started-with-zed-x/advanced-topics/)\n  * [ Get Started With ZED X One  ](https://www.stereolabs.com/docs/get-started-with-zed-x-one/) [ Setting up the ZED X One Monocular ](https://www.stereolabs.com/docs/get-started-with-zed-x-one/zed-x-one-mono/) [ Setting up the ZED X One Stereo ](https://www.stereolabs.com/docs/get-started-with-zed-x-one/zed-x-one-stereo/) [ Developing with ZED X One Stereo on a PC ](https://www.stereolabs.com/docs/get-started-with-zed-x-one/zed-x-dev-on-pc/) [ Troubleshooting ](https://www.stereolabs.com/docs/get-started-with-zed-x-one/troubleshooting/) [ Advanced Topics ](https://www.stereolabs.com/docs/get-started-with-zed-x-one/advanced-topics/)\n  * [ Get Started With ZED Box  ](https://www.stereolabs.com/docs/get-started-with-zed-box/)\n  * [ Get Started With ZED Box Orin  ](https://www.stereolabs.com/docs/get-started-with-zed-box-orin-nx/) [ Installation ](https://www.stereolabs.com/docs/get-started-with-zed-box-orin-nx/installation/) [ Reset ](https://www.stereolabs.com/docs/get-started-with-zed-box-orin-nx/reset-update/) [ Using GMSL ](https://www.stereolabs.com/docs/get-started-with-zed-box-orin-nx/gmsl/) [ Using GNSS ](https://www.stereolabs.com/docs/get-started-with-zed-box-orin-nx/gnss/) [ Troubleshooting ](https://www.stereolabs.com/docs/get-started-with-zed-box-orin-nx/troubleshooting/)\n  * [ Installation  ](https://www.stereolabs.com/docs/installation/) [ Install on Windows ](https://www.stereolabs.com/docs/installation/windows/) [ Install on Linux ](https://www.stereolabs.com/docs/installation/linux/) [ Install on NVIDIA\u00ae Jetson ](https://www.stereolabs.com/docs/installation/jetson/) [ Docker ](https://www.stereolabs.com/docs/installation/docker/) [ Recommended Specifications ](https://www.stereolabs.com/docs/installation/specifications/)\n  * [ C++ Development  ](https://www.stereolabs.com/docs/app-development/cpp/) [ Building on Windows ](https://www.stereolabs.com/docs/app-development/cpp/windows/) [ Building on Linux and NVIDIA\u00ae Jetson ](https://www.stereolabs.com/docs/app-development/cpp/linux/)\n  * [ Python Development  ](https://www.stereolabs.com/docs/app-development/python/install/) [ Run a Python Application ](https://www.stereolabs.com/docs/app-development/python/run/) [ Python Virtual Environment ](https://www.stereolabs.com/docs/app-development/python/virtual_env/)\n  * [ C# Development  ](https://www.stereolabs.com/docs/app-development/csharp/use/)\n  * [ C Development  ](https://www.stereolabs.com/docs/app-development/c/install/) [ Run a C Application ](https://www.stereolabs.com/docs/app-development/c/run/)\n  * SDK Overview \n  * [ Camera  ](https://www.stereolabs.com/docs/video/) [ Camera Controls ](https://www.stereolabs.com/docs/video/camera-controls/) [ Camera Calibration ](https://www.stereolabs.com/docs/video/camera-calibration/) [ Video Recording ](https://www.stereolabs.com/docs/video/recording/) [ Local Streaming ](https://www.stereolabs.com/docs/video/streaming/) [ Multi-Camera ](https://www.stereolabs.com/docs/video/multi-camera/) [ Using the API ](https://www.stereolabs.com/docs/video/using-video/)\n  * [ Sensors  ](https://www.stereolabs.com/docs/sensors/) [ IMU ](https://www.stereolabs.com/docs/sensors/imu/) [ Magnetometer ](https://www.stereolabs.com/docs/sensors/magnetometer/) [ Barometer ](https://www.stereolabs.com/docs/sensors/barometer/) [ Temperature Sensors ](https://www.stereolabs.com/docs/sensors/temperature/) [ Time Synchronization ](https://www.stereolabs.com/docs/sensors/time-synchronization/) [ Using the API ](https://www.stereolabs.com/docs/sensors/using-sensors/)\n  * [ Depth Sensing  ](https://www.stereolabs.com/docs/depth-sensing/) [ Depth Settings ](https://www.stereolabs.com/docs/depth-sensing/depth-settings/) [ Confidence Filtering ](https://www.stereolabs.com/docs/depth-sensing/confidence-filtering/) [ Using the API ](https://www.stereolabs.com/docs/depth-sensing/using-depth/)\n  * [ Positional Tracking  ](https://www.stereolabs.com/docs/positional-tracking/) [ Relocalization ](https://www.stereolabs.com/docs/positional-tracking/area-memory/) [ Coordinate Frames ](https://www.stereolabs.com/docs/positional-tracking/coordinate-frames/) [ Use Cases ](https://www.stereolabs.com/docs/positional-tracking/use-cases/) [ Using the API ](https://www.stereolabs.com/docs/positional-tracking/using-tracking/)\n  * [ Global Localization  ](https://www.stereolabs.com/docs/global-localization/) [ Setting up GNSS / RTK ](https://www.stereolabs.com/docs/global-localization/using-gnss-linux/)\n  * [ Spatial Mapping  ](https://www.stereolabs.com/docs/spatial-mapping/) [ Using the API ](https://www.stereolabs.com/docs/spatial-mapping/using-mapping/) [ Plane Detection ](https://www.stereolabs.com/docs/spatial-mapping/plane-detection/)\n  * [ Object Detection  ](https://www.stereolabs.com/docs/object-detection/) [ Using the API ](https://www.stereolabs.com/docs/object-detection/using-object-detection/) [ Custom Detector ](https://www.stereolabs.com/docs/object-detection/custom-od/)\n  * [ Body Tracking  ](https://www.stereolabs.com/docs/body-tracking/) [ Using the API ](https://www.stereolabs.com/docs/body-tracking/using-body-tracking/)\n  * [ Fusion  ](https://www.stereolabs.com/docs/fusion/overview/) [ ZED360 ](https://www.stereolabs.com/docs/fusion/zed360/)\n  * Code Samples \n  * [ Tutorials  ](https://www.stereolabs.com/docs/tutorials/) [ Tutorial - Hello ZED ](https://www.stereolabs.com/docs/tutorials/hello-zed/) [ Tutorial - Image Capture ](https://www.stereolabs.com/docs/tutorials/image-capture/) [ Tutorial - Depth Perception ](https://www.stereolabs.com/docs/tutorials/depth-sensing/) [ Tutorial - Camera Tracking ](https://www.stereolabs.com/docs/tutorials/positional-tracking/) [ Tutorial - Spatial Mapping ](https://www.stereolabs.com/docs/tutorials/spatial-mapping/) [ Tutorial - Object Detection ](https://www.stereolabs.com/docs/tutorials/3d-object-detection/) [ Tutorial - Using Sensors ](https://www.stereolabs.com/docs/tutorials/using-sensors/) [ Tutorial - Body Tracking ](https://www.stereolabs.com/docs/tutorials/body-tracking/)\n  * [ Samples  ](https://www.stereolabs.com/docs/samples/)\n  * Integrations \n  * [ Overview  ](https://www.stereolabs.com/docs/integrations/)\n  * [ ROS  ](https://www.stereolabs.com/docs/ros/) [ ZED Node ](https://www.stereolabs.com/docs/ros/zed-node/) [ ZED Nodelets ](https://www.stereolabs.com/docs/ros/zed-nodelets/) [ Data Display with Rviz ](https://www.stereolabs.com/docs/ros/rviz/) [ Video Capture ](https://www.stereolabs.com/docs/ros/video/) [ Depth Perception ](https://www.stereolabs.com/docs/ros/depth-sensing/) [ Positional Tracking ](https://www.stereolabs.com/docs/ros/positional-tracking/) [ Plane Detection ](https://www.stereolabs.com/docs/ros/plane_detection/) [ Object Detection ](https://www.stereolabs.com/docs/ros/object-detection/) [ Getting Sensor Data ](https://www.stereolabs.com/docs/ros/sensor-data/)\n  * [ ROS 2  ](https://www.stereolabs.com/docs/ros2/) [ ZED Node ](https://www.stereolabs.com/docs/ros2/zed-node/) [ Data Display with Rviz2 ](https://www.stereolabs.com/docs/ros2/rviz2/) [ Video Capture ](https://www.stereolabs.com/docs/ros2/video/) [ Depth Perception ](https://www.stereolabs.com/docs/ros2/depth-sensing/) [ Positional Tracking ](https://www.stereolabs.com/docs/ros2/positional-tracking/) [ Geo Tracking ](https://www.stereolabs.com/docs/ros2/geo-tracking/) [ Plane Detection ](https://www.stereolabs.com/docs/ros2/plane-detection/) [ Object Detection ](https://www.stereolabs.com/docs/ros2/object-detection/) [ Body Tracking ](https://www.stereolabs.com/docs/ros2/body-tracking/) [ Region of Interest ](https://www.stereolabs.com/docs/ros2/region-of-interest/) [ Custom messages ](https://www.stereolabs.com/docs/ros2/custom-msgs/) [ Composition ](https://www.stereolabs.com/docs/ros2/ros2-composition/) [ Robot Integration ](https://www.stereolabs.com/docs/ros2/ros2-robot-integration/)\n  * [ Isaac Sim  ](https://www.stereolabs.com/docs/isaac-sim/) [ Getting started with Isaac Sim ](https://www.stereolabs.com/docs/isaac-sim/isaac_sim/) [ Setting up ZED in Isaac Sim ](https://www.stereolabs.com/docs/isaac-sim/setting_up_zed_isaac_sim/) [ Using ZED with ROS 2 and Isaac Sim ](https://www.stereolabs.com/docs/isaac-sim/ros2_integration/)\n  * [ OpenCV  ](https://www.stereolabs.com/docs/opencv/) [ Python Interface ](https://www.stereolabs.com/docs/opencv/python/) [ OpenCV Calibration ](https://www.stereolabs.com/docs/opencv/calibration/)\n  * [ PyTorch  ](https://www.stereolabs.com/docs/pytorch/)\n  * [ YOLO  ](https://www.stereolabs.com/docs/yolo/) [ YOLO_python ](https://www.stereolabs.com/docs/yolo/python/)\n  * [ Docker  ](https://www.stereolabs.com/docs/docker/) [ Install Guide on Linux ](https://www.stereolabs.com/docs/docker/install-guide-linux/) [ Install Guide on NVIDIA\u00ae Jetson ](https://www.stereolabs.com/docs/docker/install-guide-jetson/) [ Creating a Docker Image ](https://www.stereolabs.com/docs/docker/creating-your-image/) [ Orchestrate containers ](https://www.stereolabs.com/docs/docker/orchestration/) [ Using OpenCV ](https://www.stereolabs.com/docs/docker/using-opencv/) [ Create an OpenCV image ](https://www.stereolabs.com/docs/docker/configure-opencv-dockerfile/) [ Using ROS/2 ](https://www.stereolabs.com/docs/docker/using-ros/) [ Create a ROS image ](https://www.stereolabs.com/docs/docker/configure-ros-dockerfile/) [ Create a ROS 2 image ](https://www.stereolabs.com/docs/docker/configure-ros2-dockerfile/) [ Building Images for NVIDIA\u00ae Jetson ](https://www.stereolabs.com/docs/docker/building-arm-container-on-x86/)\n  * [ Unity  ](https://www.stereolabs.com/docs/unity/) [ Key Concepts & Scripts ](https://www.stereolabs.com/docs/unity/basic-concepts/) [ Building Applications ](https://www.stereolabs.com/docs/unity/building-applications-with-zed/) [ AR Video Passthrough ](https://www.stereolabs.com/docs/unity/video-passthrough/) [ Build Your First AR/MR App ](https://www.stereolabs.com/docs/unity/creating-mixed-reality-app/) [ Body Tracking ](https://www.stereolabs.com/docs/unity/body-tracking/) [ Spatial Mapping ](https://www.stereolabs.com/docs/unity/spatial-mapping-unity/) [ Mixed Reality Capture ](https://www.stereolabs.com/docs/unity/mixed-reality-capture/) [ Object Detection ](https://www.stereolabs.com/docs/unity/object-detection/) [ Lighting and Shadows ](https://www.stereolabs.com/docs/unity/lighting/) [ Motion Controllers in AR ](https://www.stereolabs.com/docs/unity/motion-controllers-passthrough/) [ Object Placement ](https://www.stereolabs.com/docs/unity/object-placement/) [ Using OpenCV in Unity ](https://www.stereolabs.com/docs/unity/using-opencv-with-unity/) [ Green Screen VR Capture ](https://www.stereolabs.com/docs/unity/green-screen-vr/) [ Sample scenes ](https://www.stereolabs.com/docs/unity/samples/)\n  * [ Unreal Engine 5  ](https://www.stereolabs.com/docs/ue5/) [ Configuring your Project ](https://www.stereolabs.com/docs/ue5/configuring-your-project/) [ Body Tracking ](https://www.stereolabs.com/docs/ue5/body-tracking/) [ Camera Tracking ](https://www.stereolabs.com/docs/ue5/camera-tracking/) [ AR/MR ](https://www.stereolabs.com/docs/ue5/ar_mr_app/) [ Spatial Mapping ](https://www.stereolabs.com/docs/ue5/spatial-mapping/) [ Object Detection ](https://www.stereolabs.com/docs/ue5/object-detection/) [ Background Subtraction ](https://www.stereolabs.com/docs/ue5/background-subtraction/)\n  * [ Live Link  ](https://www.stereolabs.com/docs/livelink/)\n    * [ Live Link for UE5  arrow  ](https://www.stereolabs.com/docs/livelink/livelink-ue5/) [ Animating New Avatars ](https://www.stereolabs.com/docs/livelink/animate-new-avatar/) [ Building ZED Live Link ](https://www.stereolabs.com/docs/livelink/building-the-plugin/)\n[ Live Link for Unity ](https://www.stereolabs.com/docs/livelink/livelink-\nunity/)\n\n  * [ GStreamer  ](https://www.stereolabs.com/docs/gstreamer/) [ Camera Source ](https://www.stereolabs.com/docs/gstreamer/zed-camera-source/) [ Metadata ](https://www.stereolabs.com/docs/gstreamer/zed-metadata/) [ Demuxer ](https://www.stereolabs.com/docs/gstreamer/zed-demux/) [ Sensors CSV Sink ](https://www.stereolabs.com/docs/gstreamer/zed-data-csv-sink/) [ Object Detection Overlay ](https://www.stereolabs.com/docs/gstreamer/zed-od-overlay/) [ Data muxer ](https://www.stereolabs.com/docs/gstreamer/zed-datamux/) [ RTSP Server ](https://www.stereolabs.com/docs/gstreamer/rtsp-server/)\n  * [ Matlab  ](https://www.stereolabs.com/docs/matlab/)\n  * [ OpenNI2  ](https://www.stereolabs.com/docs/openni2/)\n\n#  Adding Video Capture in ROS 2\n\n##  Video with RVIZ2  #\n\nIn this tutorial, you will learn how to configure your own RVIZ2 session to\nsee only the video data that you require.\n\nTo visualize the video stream published by the ZED node, you can use two\ndifferent plugins:\n\n  * ` Camera ` : Displays an image from a camera, with the visualized world rendered behind it \n  * ` Image ` : Displays an image from a topic of type ` sensor_msgs/Image `\n\n###  Camera  #\n\nThe ` Camera ` plugin allows you to visualize an image from a topic of type `\nsensor_msgs/Image ` . It acts as if the source of the image is placed on its\nvirtual frame and renders all virtual objects in front of it.\n\n![](https://docs.stereolabs.com/ros2/images/rviz2_camera.png)\n\nKey parameters:\n\n  * ` Topic ` : Selects the image topic to visualize from the list of available images in the combo box \n  * ` Depth ` : The depth of the incoming message queue \n  * ` History policy ` : Set the QoS history policy. ` Keep Last ` is suggested for performance and compatibility \n  * ` Reliability Policy ` : Set the QoS reliability policy. ` Best Effort ` is suggested for performances, ` Reliable ` is used for compatibility \n  * ` Durability Policy ` : Set the QoS durability policy. ` Volatile ` is suggested for compatibility \n\nBy expanding ` Visibility ` , you can select/deselect what will be visible in\nthe ` camera view ` . Only active plugins can be selected.\n\n###  Image  #\n\nThe ` Image ` plugin allows you to visualize an image from a topic of type `\nsensor_msgs/Image ` .\n\n![](https://docs.stereolabs.com/ros2/images/rviz2_image.png)\n\nKey parameters:\n\n  * ` Topic ` : Selects the image topic to visualize from the list of available images in the combo box \n  * ` Depth ` : The depth of the incoming message queue \n  * ` History policy ` : Set the QoS history policy. ` Keep Last ` is suggested for performance and compatibility \n  * ` Reliability Policy ` : Set the QoS reliability policy. ` Best Effort ` is suggested for performances, ` Reliable ` is used for compatibility \n  * ` Durability Policy ` : Set the QoS durability policy. ` Volatile ` is suggested for compatibility \n\n##  Video subscribing in C++  #\n\nIn this tutorial, you will learn how to write a simple C++ node that\nsubscribes to messages of type ` sensor_msgs/Image ` . This lets you retrieve\nthe Left and Right rectified images published by the ZED node.\n\n###  Introduction  #\n\nOpen a new console and use this command to connect the camera to the ROS 2\nnetwork:\n\n    \n    \n    ros2 launch zed_display_rviz2 display_zed_cam.launch.py camera_model:=<camera model>\n    \n\n> **Note** : the old launch command ` $ ros2 launch zed_display_rviz2\n> display_<camera model>.launch.py ` is now obsolete and will be removed in a\n> future release of the wrapper.\n\nThe ZED node will start to publish image data in the network only if there is\nanother node that subscribes to the relative topic.\n\n###  Running the tutorial  #\n\nIf you properly followed the [ ROS 2 Examples Installation Guide\n](https://github.com/stereolabs/zed-ros2-examples#build-the-package) , the\nexecutable of this tutorial has been compiled and you can run the subscriber\nnode using this command:\n\n    \n    \n    $ ros2 run stereolabs_zed_tutorial_video stereolabs_zed_tutorial_video\n    \n\nThe tutorial node subscribes generic ` left_image ` and ` right_image `\ntopics, so a remapping is required to connect to the correct topics published\nby the ZED node:\n\nZED:\n\n    \n    \n    $ ros2 run zed_tutorial_video zed_tutorial_video --ros-args -r left_image:=/zed/zed_node/left/image_rect_color -r right_image:=/zed/zed_node/right/image_rect_color\n    \n\nIf the ZED node is running and a camera is connected or you have loaded an SVO\nfile, you will receive the following stream of messages confirming that you\nhave correctly subscribed to the ZED image topics:\n\n    \n    \n    [INFO] [zed_video_tutorial]: Left  Rectified image received from ZED\tSize: 1280x720 - Timestamp: 1602576933.791896880 sec \n    [INFO] [zed_video_tutorial]: Right Rectified image received from ZED\tSize: 1280x720 - Timestamp: 1602576933.891931106 sec \n    [INFO] [zed_video_tutorial]: Left  Rectified image received from ZED\tSize: 1280x720 - Timestamp: 1602576934.91928857 sec \n    [INFO] [zed_video_tutorial]: Right Rectified image received from ZED\tSize: 1280x720 - Timestamp: 1602576934.91928857 sec \n    [INFO] [zed_video_tutorial]: Left  Rectified image received from ZED\tSize: 1280x720 - Timestamp: 1602576934.191911460 sec \n    [INFO] [zed_video_tutorial]: Right Rectified image received from ZED\tSize: 1280x720 - Timestamp: 1602576934.191911460 sec\n    \n    [...]\n    \n\n###  The code  #\n\nThe source code of the subscriber node [ zed_video_sub_tutorial.cpp\n](https://github.com/stereolabs/zed-\nros2-examples/tree/master/tutorials/zed_video_tutorial/src) :\n\n    \n    \n    #include <rclcpp/rclcpp.hpp>\n    #include <rclcpp/qos.hpp>\n    #include <sensor_msgs/msg/image.hpp>\n    \n    rclcpp::Node::SharedPtr g_node = nullptr;\n    \n    /**\n     * Subscriber callbacks. The argument of the callback is a constant pointer to the received message\n     */\n    \n    \n    void imageRightRectifiedCallback(const sensor_msgs::msg::Image::SharedPtr msg) {\n        RCLCPP_INFO(g_node->get_logger(),\n                    \"Right Rectified image received from ZED\\tSize: %dx%d - Timestamp: %u.%u sec \",\n                    msg->width, msg->height,\n                    msg->header.stamp.sec,msg->header.stamp.nanosec);\n    }\n    \n    void imageLeftRectifiedCallback(const sensor_msgs::msg::Image::SharedPtr msg) {\n        RCLCPP_INFO(g_node->get_logger(),\n                    \"Left  Rectified image received from ZED\\tSize: %dx%d - Timestamp: %u.%u sec \",\n                    msg->width, msg->height,\n                    msg->header.stamp.sec,msg->header.stamp.nanosec);\n    }\n    \n    int main(int argc, char* argv[]) {\n        rclcpp::init(argc, argv);\n    \n        // Create the node\n        g_node = rclcpp::Node::make_shared(\"zed_video_tutorial\");\n    \n        /* Note: it is very important to use a QOS profile for the subscriber that is compatible\n         * with the QOS profile of the publisher.\n         * The ZED component node uses a default QoS profile with reliability set as \"RELIABLE\"\n         * and durability set as \"VOLATILE\".\n         * To be able to receive the subscribed topic the subscriber must use compatible\n         * parameters.\n         */\n    \n        // https://github.com/ros2/ros2/wiki/About-Quality-of-Service-Settings\n    \n        rclcpp::QoS video_qos(10);\n        video_qos.keep_last(10);\n        video_qos.best_effort();\n        video_qos.durability_volatile();\n    \n        // Create right image subscriber\n        auto right_sub = g_node->create_subscription<sensor_msgs::msg::Image>(\n                    \"right_image\", video_qos, imageRightRectifiedCallback );\n    \n        // Create left image subscriber\n        auto left_sub = g_node->create_subscription<sensor_msgs::msg::Image>\n                (\"left_image\", video_qos, imageLeftRectifiedCallback );\n    \n        // Let the node run\n        rclcpp::spin(g_node);\n    \n        // Shutdown when the node is stopped using Ctrl+C\n        rclcpp::shutdown();\n    \n        return 0;\n    }\n    \n\n###  The code explained  #\n\nThe following is a brief explanation of the source code above:\n\n    \n    \n    void imageRightRectifiedCallback(const sensor_msgs::msg::Image::SharedPtr msg) {\n        RCLCPP_INFO(g_node->get_logger(),\n                    \"Right Rectified image received from ZED\\tSize: %dx%d - Timestamp: %u.%u sec \",\n                    msg->width, msg->height,\n                    msg->header.stamp.sec,msg->header.stamp.nanosec);\n    }\n    \n    void imageLeftRectifiedCallback(const sensor_msgs::msg::Image::SharedPtr msg) {\n        RCLCPP_INFO(g_node->get_logger(),\n                    \"Left  Rectified image received from ZED\\tSize: %dx%d - Timestamp: %u.%u sec \",\n                    msg->width, msg->height,\n                    msg->header.stamp.sec,msg->header.stamp.nanosec);\n    }\n    \n\nThese callbacks are executed when the subscriber node receives a message of\ntype ` sensor_msgs/Image ` that matches the subscribed topic. The parameter of\nthe callback is a ` std::shared_ptr ` to the received message. This means you\ndon\u2019t have to worry about memory management. The callback code is very simple\nand demonstrates how to access the fields in a message; in this case, the `\nheight ` and ` width ` of the image and the topic timestamp.\n\nThe ` main ` function is divided in two main parts:\n\nNode declaration:\n\n    \n    \n        rclcpp::init(argc, argv);\n    \n        // Create the node\n        g_node = rclcpp::Node::make_shared(\"zed_video_tutorial\");\n    \n\nFirst, the ROS 2 environment is initialized with the ` rclcpp::init ` command.\nThen, the ` zed_video_tutorial ` node is created and a shared pointer ` g_node\n` to it is initialized.\n\nThe most important lesson of the above code is how the subscribers are\ndefined:\n\n    \n    \n        rclcpp::QoS video_qos(10);\n        video_qos.keep_last(10);\n        video_qos.best_effort();\n        video_qos.durability_volatile();\n    \n        // Create right image subscriber\n        auto right_sub = g_node->create_subscription<sensor_msgs::msg::Image>(\n                    \"right_image\", video_qos, imageRightRectifiedCallback );\n    \n        // Create left image subscriber\n        auto left_sub = g_node->create_subscription<sensor_msgs::msg::Image>(\n                    \"left_image\", video_qos, imageLeftRectifiedCallback );\n    \n\nThe two ` auto ` variables ` right_sub ` and ` left_sub ` are two `\nrclcpp::Subscription ` objects.\n\nA ` rclcpp::Subscription ` is a ROS object that listens to the network and\nwaits for its own topic message to be available. When a message is received,\nit executes the callback assigned to it.\n\nWe declared two subscribers: one for the left rectified image and one for the\nright rectified image.\n\n  * The subscriber to the ` right_image ` topic calls the ` imageRightRectCallback ` function when it receives a message of type ` sensor_msgs/Image ` that matches that topic \n  * The subscriber to the ` left_image ` topic calls the ` imageLeftRectCallback ` function when it receives a message of type ` sensor_msgs/Image ` that matches that topic \n\nIt is important that the two subscriptions use a QOS profile compatible with\nthe QOS profile of the publisher of the topics.\n\nIn this case, the QOS profile is configured to keep the last received 10\nmessages with \u201cbest effort\u201d reliability and \u201cvolatile\u201d durability. This\nconfiguration is highly compatible with many possible publisher\nconfigurations.\n\nFor more information about QoS compatibility, refer to the [ ZED node guide\n](https://www.stereolabs.com/docs/ros2/zed-node/#published-topics)\n\n> **Note** : The code of this tutorial instantiates a ` rclcpp::Node ` without\n> **subclassing** it. This was the typical usage model in the original **ROS,\n> but unfortunately, this style of coding is not compatible with composing\n> multiple nodes into a single process. Thus, it is no longer the recommended\n> style for ROS 2. Please refer to the \u201c [ Depth sensing\n> ](https://www.stereolabs.com/docs/ros2/depth-sensing/#depth-subscribing-\n> in-c) \u201d tutorial for C++ tutorials written with a coding style more targeted\n> to ROS 2.\n\n###  Conclusion  #\n\nThe full source code of this tutorial is available on GitHub in the [\nzed_video_tutorial ](https://github.com/stereolabs/zed-\nros2-examples/tree/master/tutorials/zed_video_tutorial) sub-package.\n\nAlong with the node source code are the ` package.xml ` and ` CMakeLists.txt `\nfiles that complete the tutorial package.\n\nCopyright \u00a9 2024 Stereolabs Inc.\n\n[ ](https://github.com/stereolabs \"GitHub\") [\n](https://www.linkedin.com/company/stereolabs \"LinkedIn\") [\n](https://twitter.com/stereolabs3d \"X \\(Twitter\\)\") [\n](https://www.youtube.com/Stereolabs3d \"YouTube\")\n\n  * Video with RVIZ2 \n  * Video subscribing in C++ \n\n"
  },
  {
    "id": "crazy_file_add_variable/pythonapi.txt",
    "content": "[ ![Bitcraze logo](/images/nav/navLogo.png) ](/)\n\n[ __ ](https://github.com/bitcraze) [ __ ](https://fosstodon.org/@bitcraze) [\n__ ](https://twitter.com/bitcraze_se) [ __ ](https://instagram.com/bitcraze) [\n__ ](https://www.linkedin.com/company/bitcraze-ab/) [ __\n](https://www.facebook.com/bitcraze) [ __ ](/feed/)\n\nSearch for:  __\n\n  * [ Blog ](/blog/ \"Blog\")\n  * Products \n    * [ Crazyflie 2.1 ](/products/crazyflie-2-1/ \"Crazyflie 2.1\")\n    * [ Crazyflie Bolt 1.1 ](/products/crazyflie-bolt-1-1/ \"Crazyflie Bolt 1.1\")\n    * [ Crazyradio PA ](/products/crazyradio-pa/ \"Crazyradio PA\")\n    * [ Crazyradio 2.0 ](/products/crazyradio-2-0/ \"Crazyradio 2.0\")\n    * [ Debug adapter kit ](/products/debug-adapter-kit/ \"Debug adapter kit\")\n    * [ Battery charger ](/products/battery-chg-500mA/ \"Battery charger\")\n    * [ Propellers 47-17 ](/products/propellers-47-17/ \"Propellers 47-17\")\n    * * * *\n\n    * [ AI deck 1.1 ](/products/ai-deck/ \"AI deck 1.1\")\n    * [ LED-ring deck ](/products/led-ring-deck/ \"LED-ring deck\")\n    * [ Qi 1.2 charger deck ](/products/qi-1_2-charger-deck/ \"Qi 1.2 charger deck\")\n    * [ Buzzer deck ](/products/buzzer-deck/ \"Buzzer deck\")\n    * [ BigQuad deck ](/products/bigquad-deck/ \"BigQuad deck\")\n    * [ Micro SD card deck ](/products/micro-sd-card-deck/ \"Micro SD card deck\")\n    * [ Prototyping deck ](/products/prototyping-deck/ \"Prototyping deck\")\n    * [ Breakout deck ](/products/breakout-deck/ \"Breakout deck\")\n    * [ Z-ranger deck v2 ](/products/z-ranger-deck-v2/ \"Z-ranger deck v2\")\n    * [ Flow deck v2 ](/products/flow-deck-v2/ \"Flow deck v2\")\n    * [ Multi-ranger deck ](/products/multi-ranger-deck/ \"Multi-ranger deck\")\n    * [ Active marker deck ](/products/active-marker-deck/ \"Active marker deck\")\n    * [ Motion capture marker deck ](/products/motion-capture-marker-deck/ \"Motion capture marker deck\")\n    * * * *\n\n    * [ Positioning Systems Overview ](/documentation/system/positioning/ \"Positioning Systems Overview\")\n    * [ Loco Positioning deck ](/products/loco-positioning-deck/ \"Loco Positioning deck\")\n    * [ Loco Positioning node ](/products/loco-positioning-node/ \"Loco Positioning node\")\n    * [ Lighthouse positioning deck ](/products/lighthouse-positioning-deck/ \"Lighthouse positioning deck\")\n    * * * *\n\n    * [ Old products ](/products/old-products/ \"Old products\")\n  * Buy \n    * [ Buy online __ ](https://store.bitcraze.io/ \"Buy online\")\n    * [ Local retailers ](/buy/local-retailers/ \"Local retailers\")\n    * [ Buyers guide ](/buy/buyers-guide/ \"Buyers guide\")\n  * Support \n    * [ Getting help ](/support/getting-help/ \"Getting help\")\n    * [ Discussions __ ](https://discussions.bitcraze.io \"Discussions\")\n    * [ Downloads & Install ](/support/downloads/ \"Downloads & Install\")\n    * [ FAQ ](/support/f-a-q/ \"FAQ\")\n    * [ Troubleshooting ](/support/troubleshooting/ \"Troubleshooting\")\n  * Documentation \n    * [ Start here ](/documentation/start/ \"Start here\")\n    * [ Tutorials ](/documentation/tutorials/ \"Tutorials\")\n    * [ System overview ](/documentation/system/ \"System overview\")\n    * [ Repository overview ](/documentation/repository/ \"Repository overview\")\n    * [ Developer meetings ](/documentation/meetings/ \"Developer meetings\")\n    * [ Video gallery ](/documentation/video-gallery/ \"Video gallery\")\n  * Development \n    * [ Development overview ](/development/development-overview/ \"Development overview\")\n    * [ Contribute ](/development/contribute/ \"Contribute\")\n    * [ GitHub __ ](https://github.com/bitcraze \"GitHub\")\n    * [ Discussions __ ](https://discussions.bitcraze.io \"Discussions\")\n    * [ Early access ](/development/early-access/ \"Early access\")\n    * [ External projects ](/development/external-projects/ \"External projects\")\n  * About \n    * [ Bitcraze ](/about/bitcraze/ \"Bitcraze\")\n    * [ Team ](/about/team/ \"Team\")\n    * [ Press ](/about/press/ \"Press\")\n    * [ Product cycle ](/about/product-cycle/ \"Product cycle\")\n    * [ Thesis ](/about/thesis/ \"Thesis\")\n    * [ Jobs ](/about/jobs/ \"Jobs\")\n    * [ Contact ](/about/contact/ \"Contact\")\n    * [ Feedback ](/about/feedback/ \"Feedback\")\n    * [ Events ](/about/events/ \"Events\")\n    * [ Credits ](/about/credits/ \"Credits\")\n\n#  The Crazyflie Python API explanation\n\n[ Home ](/) / Documentation / [ Repository overview\n](/documentation/repository/) / crazyflie-lib-python / [ master\n](/documentation/repository/crazyflie-lib-python/master/) / [ User guides\n](/documentation/repository/crazyflie-lib-python/master/user-guides/) / The\nCrazyflie Python API explanation\n\nVersion:  [  master  , [ 0.1.25.1 ](/documentation/repository/crazyflie-lib-\npython/0.1.25.1/) , [ 0.1.24 ](/documentation/repository/crazyflie-lib-\npython/0.1.24/) , [ 0.1.23 ](/documentation/repository/crazyflie-lib-\npython/0.1.23/) , [ 0.1.22 ](/documentation/repository/crazyflie-lib-\npython/0.1.22/) , [ 0.1.21 ](/documentation/repository/crazyflie-lib-\npython/0.1.21/) , [ 0.1.20.1 ](/documentation/repository/crazyflie-lib-\npython/0.1.20.1/) , [ 0.1.19 ](/documentation/repository/crazyflie-lib-\npython/0.1.19/) ]\n\n  * [ Home ](/documentation/repository/crazyflie-lib-python/master/ \"Home\")\n  * [ installation ](/documentation/repository/crazyflie-lib-python/master/installation/ \"installation\")\n    * [ Installation ](/documentation/repository/crazyflie-lib-python/master/installation/install/ \"Installation\")\n    * [ USB permissions ](/documentation/repository/crazyflie-lib-python/master/installation/usb_permissions/ \"USB permissions\")\n  * [ User guides ](/documentation/repository/crazyflie-lib-python/master/user-guides/ \"User guides\")\n    * [ Step-by-Step: Connecting, logging and parameters ](/documentation/repository/crazyflie-lib-python/master/user-guides/sbs_connect_log_param/ \"Step-by-Step: Connecting, logging and parameters\")\n    * [ Step-by-Step: Motion Commander ](/documentation/repository/crazyflie-lib-python/master/user-guides/sbs_motion_commander/ \"Step-by-Step: Motion Commander\")\n    * [ Step-by-Step: Swarm Interface ](/documentation/repository/crazyflie-lib-python/master/user-guides/sbs_swarm_interface/ \"Step-by-Step: Swarm Interface\")\n    * [ The Crazyflie Python API explanation ](/documentation/repository/crazyflie-lib-python/master/user-guides/python_api/ \"The Crazyflie Python API explanation\")\n  * [ Functional Areas ](/documentation/repository/crazyflie-lib-python/master/functional-areas/ \"Functional Areas\")\n    * [ Python Crazyradio Library ](/documentation/repository/crazyflie-lib-python/master/functional-areas/crazyradio_lib/ \"Python Crazyradio Library\")\n  * [ Development ](/documentation/repository/crazyflie-lib-python/master/development/ \"Development\")\n    * [ Debugging CRTP using Wireshark ](/documentation/repository/crazyflie-lib-python/master/development/wireshark/ \"Debugging CRTP using Wireshark\")\n    * [ Reset EEPROM ](/documentation/repository/crazyflie-lib-python/master/development/eeprom/ \"Reset EEPROM\")\n    * [ UART communication ](/documentation/repository/crazyflie-lib-python/master/development/uart_communication/ \"UART communication\")\n    * [ Using Matlab with the Crazyflie API ](/documentation/repository/crazyflie-lib-python/master/development/matlab/ \"Using Matlab with the Crazyflie API\")\n  * [ Auto-generated API Documentation ](/documentation/repository/crazyflie-lib-python/master/api/ \"Auto-generated API Documentation\")\n    * [ API reference for CFLib ](/documentation/repository/crazyflie-lib-python/master/api/cflib/ \"API reference for CFLib\")\n\nIn order to easily use and control the Crazyflie there's a library made in\nPython that gives high-level functions and hides the details. This page\ncontains generic information about how to use this library and the API that it\nimplements.\n\nIf you are interested in more details look in the PyDoc in the code or:\n\n  * Communication protocol for [ logging ](/documentation/repository/crazyflie-firmware/master/functional-areas/crtp/crtp_log/) or [ parameters ](/documentation/repository/crazyflie-firmware/master/functional-areas/crtp/crtp_parameters/)\n  * [ Automated documentation for Python API ](/documentation/repository/crazyflie-lib-python/master/api/cflib/)\n  * Examples: See the [ example folder of the repository ](https://github.com/bitcraze/crazyflie-lib-python/tree/master/examples) . \n\n##  Structure of the library\n\nThe library is asynchronous and based on callbacks for events. Functions like\n` open_link ` will return immediately, and the callback ` connected ` will be\ncalled when the link is opened. The library doesn't contain any threads or\nlocks that will keep the application running, it's up to the application that\nis using the library to do this.\n\nThere are a few synchronous wrappers for selected classes that create a\nsynchronous API by wrapping the asynchronous classes, see the  Synchronous API\nsection\n\n###  Uniform Resource Identifier (URI)\n\nAll communication links are identified using an URI built up of the following:\nInterfaceType://InterfaceId/InterfaceChannel/InterfaceSpeed\n\nCurrently we have _radio_ , _serial_ , _usb_ , _debug_ , _udp_ interfaces.\nHere are some examples:\n\n  * _radio://0/10/2M_ : Radio interface, USB dongle number 0, radio channel 10 and radio speed 2 Mbit/s: radio://0/10/2M \n  * _debug://0/1_ : Debug interface, id 0, channel 1 \n  * _usb://0_ : USB cable to microusb port, id 0 \n  * _serial://ttyAMA0_ : Serial port, id ttyAMA0 \n  * _tcp://aideck-AABBCCDD.local:5000_ : TCP network connection, Name: aideck-AABBCCDD.local, port 5000 \n\n###  Variables and logging\n\nThe library supports setting up logging configurations that are used for\nlogging variables from the firmware. Each log configuration contains a number\nof variables that should be logged as well as a time period (in ms) of how\noften the data should be sent back to the host. Once the log configuration is\nadded to the firmware the firmware will automatically send back the data at\nevery period. These configurations are used in the following way:\n\n  * Connect to the Crazyflie (log configurations needs a TOC to work) \n  * Create a log configuration that contains a number of variables to log and a period at which they should be logged \n  * Add the log configuration. This will also validate that the log configuration is sane (i.e uses a supported period and all variables are in the TOC) \n  * After checking that the configuration is valid, set up callbacks for the data in your application and start the log configuration \n  * Each time the firmware sends data back to the host, the callback will be called with a time-stamp and the data \n\nThere's are few limitations that need to be taken into account:\n\n  * The maximum length for a log packet is 26 bytes. This, for for example, allows to log 6 floats and one uint16_t (6*4 + 2 bytes) in a single packet. \n  * The minimum period of a for a log configuration is multiples of 10ms \n\n###  Parameters\n\nThe library supports reading and writing parameters at run-time to the\nfirmware. This is intended to be used for data that is not continuously\nchanged by the firmware, like setting regulation parameters and reading out if\nthe power-on self-tests passed. Parameters should only be changed in the\nfirmware when being set from the host (cfclient or a cflib script) or during\nstart-up.\n\nThe library doesn't continuously update the parameter values, this should only\nbe done once after connecting. After each write to a parameter the firmware\nwill send back the updated value and this will be forwarded to callbacks\nregistered for reading this parameter.\n\nThe parameters should be used in the following way:\n\n  * Register parameter updated callbacks at any time in your application \n  * Connect to your Crazyflie (this will download the parameter TOC) \n  * Request updates for all the parameters \n  * The library will call all the callbacks registered \n  * The host can now write parameters that will be forwarded to the firmware \n  * For each write all the callbacks registered for this parameter will be called back \n\nThere is an exception for experimental support to change the parameter from\nwithin [ firmware\u00e2\u0080\u0099s app layer ](/documentation/repository/crazyflie-\nfirmware/master/userguides/app_layer/#internal-log-and-param-system) . However\ndo mind that this functionality is not according to the design of the\nparameters framework so that the host might not be updated correctly on the\nparameter change.\n\n###  Variable and parameter names\n\nAll names of parameters and log variables use the same structure: ` group.name\n` .\n\nThe group should be used to bundle together logical groups, like everything\nthat deals with the stabilizer should be in the group ` stabilizer ` .\n\nThere's a limit of 28 chars in total and here are some examples:\n\n  * stabilizer.roll \n  * stabilizer.pitch \n  * pm.vbat \n  * imu_tests.MPU6050 \n  * pid_attitide.pitch_kd \n\n##  Utilities\n\n###  Callbacks\n\nAll callbacks are handled using the ` Caller ` class that contains the\nfollowing methods:\n\n    \n    \n        add_callback(cb)\n            \"\"\" Register cb as a new callback. Will not register duplicates. \"\"\"\n    \n        remove_callback(cb)\n            \"\"\" Un-register cb from the callbacks \"\"\"\n    \n        call(*args)\n            \"\"\" Call the callbacks registered with the arguments args \"\"\"\n    \n\n##  Initiating the link drivers\n\nBefore the library can be used the link drivers have to he initialized. This\nwill search for available drivers and instantiate them.\n\n    \n    \n        init_drivers()\n           \"\"\" Search for and initialize link drivers.\"\"\"\n    \n\n###  Serial driver\n\nThe serial driver is disabled by default and has to be enabled to be used.\nEnable it in the call to ` init_drivers() ` .\n\n    \n    \n        init_drivers(enable_serial_driver=True)\n    \n\n##  Connection- and link-callbacks\n\nOperations on the link and connection will return immediately and will call\nthe following callbacks when events occur:\n\n    \n    \n        # Called on disconnect, no matter the reason\n        disconnected = Caller()\n        # Called on unintentional disconnect only\n        connection_lost = Caller()\n        # Called when the first packet in a new link is received\n        link_established = Caller()\n        # Called when the user requests a connection\n        connection_requested = Caller()\n        # Called when the link is established and the TOCs (that are not cached)\n        # have been downloaded\n        connected = Caller()\n        # Called when the the link is established and all data, including parameters have been downloaded\n        fully_connected = Caller()\n        # Called if establishing of the link fails (i.e times out)\n        connection_failed = Caller()\n        # Called for every packet received\n        packet_received = Caller()\n        # Called for every packet sent\n        packet_sent = Caller()\n        # Called when the link driver updates the link quality measurement\n        link_quality_updated = Caller()\n    \n\nTo register for callbacks the following is used:\n\n    \n    \n        crazyflie = Crazyflie()\n        crazyflie.connected.add_callback(crazyflie_connected)\n    \n\n##  Finding a Crazyflie and connecting\n\nThe first thing to do is to find a Crazyflie quadcopter that we can connect\nto. This is done by queuing the library that will scan all the available\ninterfaces (currently the debug and radio interface).\n\n    \n    \n        cflib.crtp.init_drivers()\n        available = cflib.crtp.scan_interfaces()\n        for i in available:\n            print \"Interface with URI [%s] found and name/comment [%s]\" % (i[0], i[1])\n    \n\nOpening and closing a communication link is done by using the Crazyflie\nobject:\n\n    \n    \n        crazyflie = Crazyflie()\n        crazyflie.connected.add_callback(crazyflie_connected)\n        crazyflie.open_link(\"radio://0/10/2M\")\n    \n\nThen you can use the following to close the link again:\n\n    \n    \n        crazyflie.close_link()\n    \n\n##  Sending control setpoints with the commander framework\n\nThe control setpoints are not implemented as parameters, instead they have a\nspecial API.\n\n###  Attitude Setpoints\n\n    \n    \n        def send_setpoint(self, roll, pitch, yawrate, thrust):\n    \n\nTo send a new control set-point use the following:\n\n    \n    \n        roll    = 0.0\n        pitch   = 0.0\n        yawrate = 0\n        thrust  = 10001\n        crazyflie.commander.send_setpoint(roll, pitch, yawrate, thrust)\n    \n\nThrust is an integer value ranging from 10001 (next to no power) to 60000\n(full power). It corresponds to the mean thrust that will be applied to the\nmotors. There is a battery compensation algorithm applied to make the thrust\nmostly independent of battery voltage. Roll/pitch are in degree and yawrate is\nin degree/seconds.\n\nThis command will set the attitude controller setpoint for the next 500ms.\nAfter 500ms without next setpoint, the Crazyflie will apply a setpoint with\nthe same thrust but with roll/pitch/yawrate = 0, this will make the Crazyflie\nstop accelerating. After 2 seconds without new setpoint the Crazyflie will cut\npower from the motors.\n\nNote that this command implements a motor lock mechanism that is intended to\navoid flyaway when connecting a gamepad. You must send one command with thrust\n= 0 in order to unlock the command. This unlock procedure needs to be repeated\nif the watchdog described above kicks-in.\n\n###  Other commander setpoints sending\n\nIf your Crazyflie has a positioning system (Loco, flowdeck, MoCap,\nLighthouse), you can also send velocity or position setpoints, like for\ninstance:\n\n    \n    \n    send_hover_setpoint(self, vx, vy, yawrate, zdistance)\n    \n\nCheck out the [ automated API documentation\n](/documentation/repository/crazyflie-lib-\npython/master/api/cflib/crazyflie/commander/) for the Crazyflie cflib\u00e2\u0080\u0099s\ncommander framework to find out what other functions you can use.\n\n##  Parameters\n\nThe parameter framework is used to read and set parameters. This functionality\nshould be used when:\n\n  * The parameter is not changed by the Crazyflie but by the client \n  * The parameter is not read periodically \n\nIf this is not the case then the logging framework should be used instead.\n\nTo set a parameter you must be connected to the Crazyflie. A parameter is set\nusing:\n\n    \n    \n        param_name = \"group.name\"\n        param_value = 3\n        crazyflie.param.set_value(param_name, param_value)\n    \n\nThe parameter reading is done using callbacks. When a parameter is updated\nfrom the host (using the code above) the parameter will be read back by the\nlibrary and this will trigger the callbacks. Parameter callbacks can be added\nat any time (you don't have to be connected to a Crazyflie).\n\n    \n    \n        add_update_callback(group, name=None, cb=None)\n            \"\"\"\n            Add a callback for a specific parameter name or group. If name is not specified then\n            all parameters in the group will trigger the callback. This callback will be executed\n            when a new value is read from the Crazyflie.\n            \"\"\"\n    \n        request_param_update(complete_name)\n            \"\"\" Request an update of the value for the supplied parameter. \"\"\"\n    \n        set_value(complete_name, value)\n            \"\"\" Set the value for the supplied parameter. \"\"\"\n    \n\nHere's an example of how to use the calls.\n\n    \n    \n        crazyflie.param.add_update_callback(group=\"group\", name=\"name\", param_updated_callback)\n    \n        def param_updated_callback(name, value):\n            print \"%s has value %d\" % (name, value)\n    \n\nIt is also possible to get the current value of a parameter (when connected)\nwithout using a callback\n\n    \n    \n        value = get_value(complete_name)\n    \n\n> **Note 1** If you call ` set_value() ` and then directly call ` get_value()\n> ` for a parameter, you might not read back the new value, but get the old\n> one instead. The process is asynchronous and ` get_value() ` will not return\n> the new value until the parameter value has propagated to the Crazyflie and\n> back. Use the callback method if you need to be certain that you get the\n> correct value after an update.\n\n> **Note 2** : ` get_value() ` and ` set_value() ` can not be called from\n> callbacks until the Crazyflie is fully connected. Most notably they can not\n> be called from the ` connected ` callback as the parameter values have not\n> been downloaded yet. Use the ` fully_connected ` callback to make sure the\n> system is ready for parameter use. It is OK to call ` get_value() ` and `\n> set_value() ` from the ` fully_connected ` callback.\n\n##  Logging\n\nThe logging framework is used to enable the \"automatic\" sending of variable\nvalues at specified intervals to the client. This functionality should be used\nwhen:\n\n  * The variable is changed by the Crazyflie and not by the client \n  * The variable is updated at high rate and you want to read the value periodically \n\nIf this is not the case then the parameter framework should be used instead.\n\nThe API to create and get information from LogConfig:\n\n    \n    \n        # Called when new logging data arrives\n        data_received_cb = Caller()\n        # Called when there's an error\n        error_cb = Caller()\n        # Called when the log configuration is confirmed to be started\n        started_cb = Caller()\n        # Called when the log configuration is confirmed to be added\n        added_cb = Caller()\n    \n        add_variable(name, fetch_as=None)\n            \"\"\"Add a new variable to the configuration.\n    \n            name - Full name of the variable in the form group.name\n            fetch_as - String representation of the type the variable should be\n                       fetched as (i.e uint8_t, float, FP16, etc)\n    \n            If no fetch_as type is supplied, then the stored type will be used\n            (i.e the type of the fetched variable is the same as it's stored in the\n            Crazyflie).\"\"\"\n    \n        start()\n            \"\"\"Start the logging for this entry\"\"\"\n    \n        stop()\n            \"\"\"Stop the logging for this entry\"\"\"\n    \n        delete()\n            \"\"\"Delete this entry in the Crazyflie\"\"\"\n    \n\nThe API for the log in the Crazyflie:\n\n    \n    \n        add_config(logconf)\n            \"\"\"Add a log configuration to the logging framework.\n    \n            When doing this the contents of the log configuration will be validated\n            and listeners for new log configurations will be notified. When\n            validating the configuration the variables are checked against the TOC\n            to see that they actually exist. If they don't then the configuration\n            cannot be used. Since a valid TOC is required, a Crazyflie has to be\n            connected when calling this method, otherwise it will fail.\"\"\"\n    \n\nTo create a logging configuration the following can be used:\n\n    \n    \n        logconf = LogConfig(name=\"Logging\", period_in_ms=100)\n        logconf.add_variable(\"group1.name1\", \"float\")\n        logconf.add_variable(\"group1.name2\", \"uint8_t\")\n        logconf.add_variable(\"group2.name1\", \"int16_t\")\n    \n\nThe datatype is the transferred datatype, it will be converted from internal\ntype to transferred type before transfers:\n\n  * float \n  * uint8_t and int8_t \n  * uint16_t and int16_t \n  * uint32_t and int32_t \n  * FP16: 16bit version of floating point, allows to pack more variables in one packet at the expense of precision. \n\nThe logging cannot be started until your are connected to a Crazyflie:\n\n    \n    \n        # Callback called when the connection is established to the Crazyflie\n        def connected(link_uri):\n            crazyflie.log.add_config(logconf)\n    \n            if logconf.valid:\n                logconf.data_received_cb.add_callback(data_received_callback)\n                logconf.error_cb.add_callback(logging_error)\n                logconf.start()\n            else:\n                print \"One or more of the variables in the configuration was not found in log TOC. No logging will be possible.\"\n    \n        def data_received_callback(timestamp, data, logconf):\n            print \"[%d][%s]: %s\" % (timestamp, logconf.name, data)\n    \n        def logging_error(logconf, msg):\n            print \"Error when logging %s\" % logconf.name\n    \n\nThe values of log variables are transferred from the Crazyflie using CRTP\npackets, where all variables belonging to one logging configuration are\ntransferred in the same packet. A CRTP packet has a maximum data size of 30\nbytes, which sets an upper limit to the number of variables that can be used\nin one logging configuration. If the desired log variables do not fit in one\nlogging configuration, a second configuration may be added.\n\n    \n    \n        crazyflie.log.add_config([logconf1, logconfig2])\n    \n\n##  Synchronous API\n\nThe synchronous classes are wrappers around the asynchronous API, where the\nasynchronous calls/callbacks are replaced with blocking calls. The synchronous\nAPI does not provide the full flexibility of the asynchronous API, but is\nuseful when writing small scripts, for logging for instance.\n\nThe synchronous API uses the python Context manager concept, that is the `\nwith ` keyword. A resource is allocated when entering a ` with ` section and\nautomatically released when exiting it, for instance a connection or take\noff/landing of a Crazyflie.\n\n###  SyncCrazyflie\n\nThe ` SyncCrazyflie ` class wraps a Crazyflie instance and mainly simplifies\nconnect/disconnect.\n\nBasic usage\n\n    \n    \n        with SyncCrazyflie(uri) as scf:\n            # A Crazyflie instance is created and is now connected. If the connection fails,\n            # an exception is raised.\n    \n            # The underlying crazyflie object can be accessed through the cf member\n            scf.cf.param.set_value('kalman.resetEstimation', '1')\n    \n            # Do useful stuff\n            # When leaving the \"with\" section, the connection is automatically closed\n    \n\nIf some special properties are required for the underlying Crazyflie object, a\nCrazyflie instance can be passed in to the ` SyncCrazyflie ` instance.\n\n    \n    \n        my_cf = Crazyflie(rw_cache='./cache')\n        with SyncCrazyflie(uri, cf=my_cf) as scf:\n            # The my_cf is now connected\n            # Do useful stuff\n            # When leaving the \"with\" section, the connection is automatically closed\n    \n\n###  SyncLogger\n\nThe ` SyncLogger ` class wraps setting up, as well as starting/stopping\nlogging. It works both for Crazyflie and ` SyncCrazyflie ` instances. To get\nthe log values, iterate the instance.\n\n    \n    \n        # Connect to a Crazyflie\n        with SyncCrazyflie(uri) as scf:\n            # Create a log configuration\n            log_conf = LogConfig(name='myConf', period_in_ms=200)\n            log_conf.add_variable('stateEstimateZ.vx', 'int16_t')\n    \n            # Start logging\n            with SyncLogger(scf, log_conf) as logger:\n                # Iterate the logger to get the values\n                count = 0\n                for log_entry in logger:\n                    print(log_entry)\n                    # Do useful stuff\n                    count += 1\n                    if (count > 10):\n                        # The logging will continue until you exit the loop\n                        break\n                # When leaving this \"with\" section, the logging is automatically stopped\n            # When leaving this \"with\" section, the connection is automatically closed\n    \n\n###  MotionCommander\n\nThe ` MotionCommander ` class is intended to simplify basic autonomous flight,\nwhere the motion control is done from the host computer. The Crazyflie takes\noff and makes when entering the \u00e2\u0080\u009cwith\u00e2\u0080\u009d section, and lands when exiting. It\nhas functions for basic movements that are blocking until the motion is\nfinished.\n\nThe ` MotionCommander ` is using velocity set points and does not have a\nglobal coordinate system, all positions are relative. It is mainly intended to\nbe used with a Flow deck.\n\n    \n    \n        with SyncCrazyflie(URI) as scf:\n            # We take off when the commander is created\n            with MotionCommander(scf) as mc:\n                # Move one meter forward\n                mc.forward(1)\n                # Move one meter back\n                mc.back(1)\n                # The Crazyflie lands when leaving this \"with\" section\n            # When leaving this \"with\" section, the connection is automatically closed\n    \n\n###  PositionHlCommander\n\nThe ` PositionHlCommander ` is intended to simplify basic autonomous flight,\nwhere all the high level commands exist inside the Crazyflie firmware. The\nCrazyflie takes off when entering the \u00e2\u0080\u009cwith\u00e2\u0080\u009d section, and lands when\nexiting. It has functions for basic movements that are blocking until the\nmotion is finished.\n\nThe ` PositionHlCommander ` uses the high level commander in the Crazyflie and\nis based on a global coordinate system and absolute positions. It is intended\nto be used with a positioning system such as Loco, the lighthouse or a mocap\nsystem.\n\n    \n    \n        with SyncCrazyflie(URI) as scf:\n            with PositionHlCommander(scf, controller=PositionHlCommander.CONTROLLER_PID) as pc:\n                # Go to the coordinate (0, 0, 1)\n                pc.go_to(0.0, 0.0, 1.0)\n                # The Crazyflie lands when leaving this \"with\" section\n            # When leaving this \"with\" section, the connection is automatically closed\n    \n\n#  Footer Menu\n\n  * Top \n  * [ Home ](/ \"Home\")\n  * [ Research ](/portals/research/ \"Research\")\n  * [ Education ](/portals/education/ \"Education\")\n  * [ Development ](/portals/development/ \"Development\")\n  * [ DIY ](/portals/diy/ \"DIY\")\n  * [ License ](/license/ \"License\")\n  * [ Cookie Policy ](/cookies/ \"Cookie Policy\")\n  * [ Privacy Policy ](/privacy-policy/ \"Privacy Policy\")\n  * [ Sign up for newsletter ](/signup/ \"Signup for newsletter\")\n  * [ Feedback ](/about/feedback/ \"feedback\")\n\n[ __ Improve this page ](https://github.com/bitcraze/crazyflie-lib-\npython/edit/master/docs/user-guides/python_api.md)\n\n\u00a9 2023 [ Bitcraze AB ](/) [ ![Bitcraze logo](/images/footerLogo.png) ](/)\n\n"
  },
  {
    "id": "srvmsg/Posemsg.txt",
    "content": "# A representation of pose in free space, composed of position and orientation.\nPoint position\nQuaternion orientation\n\n\n"
  },
  {
    "id": "vscode_gazebo/debuggingros2gazebop.txt",
    "content": "[ Open in app\n](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F14de44d58cc9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&source=---two_column_layout_nav----------------------------------)\n\nSign up\n\n[ Sign in\n](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40arshad.mehmood%2Fdebugging-\nros2-gazebo-plugins-with-vscode-14de44d58cc9&source=post_page---\ntwo_column_layout_nav-----------------------global_nav-----------)\n\n[ ](/?source=---two_column_layout_nav----------------------------------)\n\n[ Write\n](/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-\nstory&source=---two_column_layout_nav-----------------------\nnew_post_topnav-----------)\n\n[ ](/search?source=---two_column_layout_nav----------------------------------)\n\nSign up\n\n[ Sign in\n](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40arshad.mehmood%2Fdebugging-\nros2-gazebo-plugins-with-vscode-14de44d58cc9&source=post_page---\ntwo_column_layout_nav-----------------------global_nav-----------)\n\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\n\n#  Debugging ROS2 Gazebo Plugins With VSCode\n\n[ ![Arshad\nMehmood](https://miro.medium.com/v2/da:true/resize:fill:88:88/0*4RqKG46Pf3yDD_4A)\n](/@arshad.mehmood?source=post_page-----\n14de44d58cc9--------------------------------)\n\n[ Arshad Mehmood ](/@arshad.mehmood?source=post_page-----\n14de44d58cc9--------------------------------)\n\n\u00b7\n\n[ Follow\n](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcd9e995731f3&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40arshad.mehmood%2Fdebugging-\nros2-gazebo-plugins-with-\nvscode-14de44d58cc9&user=Arshad+Mehmood&userId=cd9e995731f3&source=post_page-\ncd9e995731f3----14de44d58cc9---------------------post_header-----------)\n\n5 min read\n\n\u00b7\n\nNov 21, 2022\n\n[\n](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F14de44d58cc9&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40arshad.mehmood%2Fdebugging-\nros2-gazebo-plugins-with-\nvscode-14de44d58cc9&user=Arshad+Mehmood&userId=cd9e995731f3&source=-----14de44d58cc9\n---------------------clap_footer-----------)\n\n\\--\n\n[\n](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F14de44d58cc9&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40arshad.mehmood%2Fdebugging-\nros2-gazebo-plugins-with-vscode-14de44d58cc9&source=-----14de44d58cc9\n---------------------bookmark_footer-----------)\n\nListen\n\nShare\n\nWhen working with Gazebo Simulation, there could be a need to debug it\u2019s\nplugins and ROS2 code to root cause issues and bugs. This article is a\ntutorial on setting up interactive debugging gazebo plugins using Microsoft\nVSCode. ROS2 Foxy used but the method can be used with any ROS version.\n\nAssumptions:\n\n  * Familiarity with MS VSCode. \n  * Familiarity with gdb and it\u2019s usage. \n  * Plugin source code availability and it\u2019s building with debug symbols. See [ this reference tutorial ](http://gazebosim.org/tutorials?tut=install_from_source) . \n\nGazebo runs in a client and server process. All the physics logic is carried\nout by service process named gzserver. It also host plugins dynamic libraries.\nThe client (gzclient) is the front end counter part and responsible for\nrendering physics state on the screen using 3D libraries. This separations\nallows to run gzclient and gzserver on separate machines thus get better\nresults for actual simulation and not effected by 3D rendering. The gzserver\nis alone enough to run off display simulation.\n\ngazebo command is basically wrapper executable to run gzserver and gzclient\nprocesses.\n\n[ https://classic.gazebosim.org/tutorials?tut=architecture&cat=get_started\n](https://classic.gazebosim.org/tutorials?tut=architecture&cat=get_started)\n\n#  **Gazebo Plugin Types**\n\nHere is brief intro of gazebo plugins.\n\n    \n    \n    enum PluginType  \n    {  \n    /// \\brief A World plugin  \n    WORLD_PLUGIN,  \n    /// \\brief A Model plugin  \n    MODEL_PLUGIN,  \n    /// \\brief A Sensor plugin  \n    SENSOR_PLUGIN,  \n    /// \\brief A System plugin  \n    SYSTEM_PLUGIN,  \n    /// \\brief A Visual plugin  \n    VISUAL_PLUGIN,  \n    /// \\brief A GUI plugin  \n    GUI_PLUGIN  \n    };\n\nWorld plugins are declared and loaded via world file. Model plugin life time\ndepends on Model existing in a world. Sensor plugins are to simulate camera\nand often associated with model. System plugins are loaded by the gzserver at\nprocess start even before any world or model is created.\n\n#  Compiling Plugin with Debug Symbols\n\nInteractive debugging requires debug symbols to be included in the binary as\nwell as with minimal optimizations. Too much compiler optimization effect\ndebugger\u2019s ability to relate code with instructions. Best scenario for\ndebugging would be to build binaries with -O0 flag (no optimization). -g flag\ninstructs compiler to embed debug symbol into the executable.\n\nColcon command for building ROS2 package with debug symbols and minimal\noptimization.\n\n    \n    \n    colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE= **Debug**\n\nCMAKE_BUILD_TYPE options. Can use any of the bold options.\n\n    \n    \n    1. Release: `-O3 -DNDEBUG`  \n    2. **Debug** : `-O0 -g`  \n    3. **RelWithDebInfo** : `-O2 -g -DNDEBUG`  \n    4. MinSizeRel: `-Os -DNDEBUG`\n\nBest config for debugging will be Debug or RelWithDebInfo. Though -O0 may\ncause some performance degradation depending on code sensitivity. In rare\ncases, building code without optimization may hide the bugs related to\nsynchronization.\n\n#  **Setting up VSCode for plugin debugging**\n\nCreate a launch.json file in .vscode directory inside workspace. This can be\ndone directly from command prompt or via VSCode GUI.\n\nReplace any existing contents with below snippet.\n\n**launch.json file**\n\n    \n    \n    {  \n        \"version\": \"0.2.0\",  \n        \"configurations\": [  \n        {  \n            \"name\": \"(gdb) Attach\",  \n            \"type\": \"cppdbg\",  \n            \"request\": \"attach\",  \n            \"processId\": \"${input:GetPID}\",  \n            \"program\"  : \"${input:GetPath}\",  \n            \"MIMode\": \"gdb\",  \n            \"sudo\": true,  \n            \"setupCommands\": [  \n                {  \n                    \"description\": \"Enable pretty-printing for gdb\",  \n                    \"text\": \"-enable-pretty-printing\",  \n                    \"ignoreFailures\": true  \n                },  \n                {  \n                    \"description\":  \"Set Disassembly Flavor to Intel\",  \n                    \"text\": \"-gdb-set disassembly-flavor intel\",  \n                    \"ignoreFailures\": true  \n                }  \n            ]  \n        }  \n        ],  \n        \"inputs\": [  \n            {  \n              \"id\": \"GetPID\",  \n              \"type\": \"command\",  \n              \"command\": \"shellCommand.execute\",  \n              \"args\": {  \n                \"command\": \"pgrep gzserver\",  \n                \"description\": \"Select your target PID\",  \n                \"useFirstResult\": true,  \n              }  \n            },  \n            {  \n                \"id\": \"GetPath\",  \n                \"type\": \"command\",  \n                \"command\": \"shellCommand.execute\",  \n                \"args\": {  \n                  \"command\": \"readlink /proc/$(pgrep gzserver)/exe\",  \n                  \"description\": \"Select your target PID\",  \n                  \"useFirstResult\": true,  \n                }  \n              }  \n        ]  \n    }\n\nGetPID will return pid of gzserver process. GetPath is to get executable path.\npid and path both are needed by launch.json to attach gdb with running\nprocess. (e.g gzserver)\n\n#  Debugging plugins\n\nA typical scenario would be to start simulation and then attach VSCode\ndebugger to gzserver process. The code to be inspect get called after the\nprocess is attached (e.g spawn_entity). This is a straight forward scenario\nwith below steps to follow. This method can be used for debugging any function\ncode either one time or repeated calls. e.g Load(), Update()\n\nSteps:\n\n  * Start gazebo \n  * Set break point on desired plugin function \n  * Attach to gzserver via vscode launch.json file \n  * Import model containing plugin reference into gazebo via spawn_entity.py script. \n  * Breakpoint should get hit once the function is called. \n  * Continue with Watch and other debugging steps \n\n**spawn_entity command**\n\n    \n    \n    ros2 run gazebo_ros spawn_entity.py -file <path>/model.sdf -entity robot  -x 0.0 -y 0.0 -z 0.0\n\nStarting a debug session in VSCode\n\n#  **Scenario 2**\n\n##  Debugging plugin startup code loaded with gzserver\n\nThere are situations when the problematic code is in the initialization calls\nand cause crash or passes to quickly even before debugger given chance to\nattach. In this situation, either can run gazebo under gdb or put a temporary\ndelay via sleep in startup routines to cause plugin to wait for debugger to\nattach. This wait can end either using a variable value set or using a temp\nfile check.\n\nRunning gzserver under gdb. A crash will get trapped by gdb (e.g assert, a\nreal crash). Debugging can continue from there.\n\n    \n    \n    ros2 launch gazebo_ros gzserver.launch.py gdb:=true\n\nThere are situations when the plugin is loaded with gzserver and there is a\nneed to debug plugin startup code.\n\n  * Command line arguments (e.g -s option for system plugins). \n  * Referenced inside .world file \n  * Model is spawned within launch file \n\nA work around for this scenario would be to force plugin to wait for debugger\nto attach before proceeding. This can be achieved by introducing a while wait\nloop at start of Load() or Constructor() calls.\n\nThere could be multiple ways to wait. Here two of them are listed.\n\nWait loop can wait on a file on local system. After ros2 launch, the gzserver\nwill be blocked by the plugin due to below loop. This will give the\nopportunity to attach VS Code to gzserver and wait for symbols to get loaded,\nset a breakpoint on desired location and then create the file via \u2018touch\n/tmp/go\u2019 command to proceed. Assuming DEBUG_ON preprocessor flag is set to 1.\n\nUsing file creation:\n\n    \n    \n    #include <sys/stat.h>  \n    ...  \n    ...  \n    #if DEBUG_ON  \n    struct stat buffer;  \n    while (stat (\"/tmp/go\", &buffer) != 0) {  \n          sleep(1);  // sleep for 1 seconds.  can replace with usleep        \n    }  \n    #endif\n    \n    \n    touch /tmp/go\n\nAnother way to achieve same behavior is using a variable. In this case, set a\nbreakpoint on sleep statement. Once the VSCode is attached to gzserver, this\nbreakpoint will get hit. Change the i value to something other than 0 causing\nwhile loop to exit. Assuming real target breakpoint is already set which will\nget hit after the while loop is done.\n\nUsing variable update:\n\n    \n    \n    #if DEBUG_ON  \n      int i = 0;  \n      while (i == 0) {  \n          sleep(1);  // sleep for 1 seconds.  can replace with usleep        \n      }  \n    #endif\n\nVSCode offers all standard debugger GUI features including Watch and Variable\nwindow, Call Stack and Breakpoint set/remove options.\n\nVSCode in a debugging session (breakpoint hit)\n\n**References:**\n\n[ https://code.visualstudio.com/docs/editor/debugging\n](https://code.visualstudio.com/docs/editor/debugging)\n\n[ https://code.visualstudio.com/docs/introvideos/debugging\n](https://code.visualstudio.com/docs/introvideos/debugging)\n\n[\n](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F14de44d58cc9&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40arshad.mehmood%2Fdebugging-\nros2-gazebo-plugins-with-\nvscode-14de44d58cc9&user=Arshad+Mehmood&userId=cd9e995731f3&source=-----14de44d58cc9\n---------------------clap_footer-----------)\n\n\\--\n\n[\n](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F14de44d58cc9&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40arshad.mehmood%2Fdebugging-\nros2-gazebo-plugins-with-\nvscode-14de44d58cc9&user=Arshad+Mehmood&userId=cd9e995731f3&source=-----14de44d58cc9\n---------------------clap_footer-----------)\n\n\\--\n\n[\n](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F14de44d58cc9&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40arshad.mehmood%2Fdebugging-\nros2-gazebo-plugins-with-\nvscode-14de44d58cc9&source=--------------------------bookmark_footer-----------)\n\n[ ![Arshad\nMehmood](https://miro.medium.com/v2/da:true/resize:fill:144:144/0*4RqKG46Pf3yDD_4A)\n](/@arshad.mehmood?source=post_page-----\n14de44d58cc9--------------------------------)\n\nFollow\n\n[\n](/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7f34dd30531c&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40arshad.mehmood%2Fdebugging-\nros2-gazebo-plugins-with-\nvscode-14de44d58cc9&newsletterV3=cd9e995731f3&newsletterV3Id=7f34dd30531c&user=Arshad+Mehmood&userId=cd9e995731f3&source=-----14de44d58cc9\n---------------------subscribe_user-----------)\n\n[\n\n##  Written by  Arshad Mehmood\n\n](/@arshad.mehmood?source=post_page-----\n14de44d58cc9--------------------------------)\n\n[ 69 Followers ](/@arshad.mehmood/followers?source=post_page-----\n14de44d58cc9--------------------------------)\n\nAs the technical lead at Intel Corporation, my work orbits around the\nintriguing world of Robotics and Artificial Intelligence.\n\nFollow\n\n[\n](/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7f34dd30531c&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40arshad.mehmood%2Fdebugging-\nros2-gazebo-plugins-with-\nvscode-14de44d58cc9&newsletterV3=cd9e995731f3&newsletterV3Id=7f34dd30531c&user=Arshad+Mehmood&userId=cd9e995731f3&source=-----14de44d58cc9\n---------------------subscribe_user-----------)\n\n[\n\nHelp\n\n](https://help.medium.com/hc/en-us?source=post_page-----\n14de44d58cc9--------------------------------)\n\n[\n\nStatus\n\n](https://medium.statuspage.io/?source=post_page-----\n14de44d58cc9--------------------------------)\n\n[\n\nAbout\n\n](/about?autoplay=1&source=post_page-----\n14de44d58cc9--------------------------------)\n\n[\n\nCareers\n\n](/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----\n14de44d58cc9--------------------------------)\n\n[\n\nBlog\n\n](https://blog.medium.com/?source=post_page-----\n14de44d58cc9--------------------------------)\n\n[\n\nPrivacy\n\n](https://policy.medium.com/medium-privacy-\npolicy-f03bf92035c9?source=post_page-----\n14de44d58cc9--------------------------------)\n\n[\n\nTerms\n\n](https://policy.medium.com/medium-terms-of-\nservice-9db0094a1e0f?source=post_page-----\n14de44d58cc9--------------------------------)\n\n[\n\nText to speech\n\n](https://speechify.com/medium?source=post_page-----\n14de44d58cc9--------------------------------)\n\n[\n\nTeams\n\n](/business?source=post_page-----14de44d58cc9--------------------------------)\n\n"
  },
  {
    "id": "rosparam/rosparampy.txt",
    "content": "#!/usr/bin/env python\n# Software License Agreement (BSD License)\n#\n# Copyright (c) 2008, Willow Garage, Inc.\n# All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions\n# are met:\n#\n#  * Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n#  * Redistributions in binary form must reproduce the above\n#    copyright notice, this list of conditions and the following\n#    disclaimer in the documentation and/or other materials provided\n#    with the distribution.\n#  * Neither the name of Willow Garage, Inc. nor the names of its\n#    contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n# \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n# FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE\n# COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN\n# ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n#\n# Revision $Id: rosparam 1641 2008-07-28 21:39:33Z sfkwc $\n\n\"\"\"\nImplementation of the rosparam as well as a library for modifying the\nstate of the ROS Parameter Server using YAML files.\n\"\"\"\n\nNAME = 'rosparam'\n\n## namespace key. Use of this in a YAML document specifies the\n## namespace of all the params.  NOTE: phasing out most use of this\n## key. It's still useful in corner cases, but most of its\n## functionality can be achieved with command-line arguments.\nNS = '_ns'\n\nimport base64\nimport math\nimport os\nimport re\nimport sys\nimport socket\nimport traceback\nimport xmlrpclib\n\nfrom optparse import OptionParser\n\nimport yaml\n\nfrom roslib.names import ns_join, get_ros_namespace, make_caller_id, make_global_ns, GLOBALNS\nfrom roslib.scriptutil import get_param_server, script_resolve_name\n\nclass ROSParamException(Exception):\n    \"\"\"\n    rosparam base exception type\n    \"\"\"\n    pass\nclass ROSParamIOException(ROSParamException):\n    \"\"\"\n    Exception for communication-based (i/o) errors.\n    \"\"\"\n    pass\n\n# pyyaml customizations for binary and angle data\n\ndef represent_xml_binary(loader, data):\n    \"\"\"\n    Adds a pyyaml serializer to handle xmlrpclib.Binary objects\n    \"\"\"\n    data = base64.b64encode(data.data)\n    return loader.represent_scalar(u'tag:yaml.org,2002:binary', data, style='|')\n\ndef construct_yaml_binary(loader, node):\n    \"\"\"\n    Overrides pyaml's constructor for binary data. Wraps binary data in\n    xmlrpclib.Binary container instead of straight string\n    representation.\n    \"\"\"\n    return xmlrpclib.Binary(loader.construct_yaml_binary(node))\n        \n# register the (de)serializers with pyyaml\nyaml.add_representer(xmlrpclib.Binary,represent_xml_binary)\nyaml.add_constructor(u'tag:yaml.org,2002:binary', construct_yaml_binary)\n\ndef construct_angle_radians(loader, node):\n    \"\"\"\n    python-yaml utility for converting rad(num) into float value\n    \"\"\"\n    value = loader.construct_scalar(node).strip()\n    exprvalue = value.replace('pi', 'math.pi')\n    if exprvalue.startswith(\"rad(\"):\n        exprvalue = exprvalue[4:-1]\n    try:\n        return float(eval(exprvalue))\n    except SyntaxError, e:\n        raise ROSParamException(\"invalid radian expression: %s\"%value)\n\ndef construct_angle_degrees(loader, node):\n    \"\"\"\n    python-yaml utility for converting deg(num) into float value\n    \"\"\"\n    value = loader.construct_scalar(node)\n    exprvalue = value\n    if exprvalue.startswith(\"deg(\"):\n        exprvalue = exprvalue.strip()[4:-1]\n    try:\n        return float(exprvalue) * math.pi / 180.0\n    except ValueError:\n        raise ROSParamException(\"invalid degree value: %s\"%value)\n\n\n# utilities\n\ndef _succeed(args):\n    \"\"\"\n    Utility routine for checking ROS XMLRPC API call\n    @return: value field from ROS xmlrpc call\n    @rtype: XmlRpcLegalValue\n    @raise ROSParamException: if call to ROS xmlrpc API did not succeed\n    \"\"\"\n    code, msg, val = args\n    if code != 1:\n        raise ROSParamException(msg)\n    return val\n\ndef _get_caller_id():\n    \"\"\"\n    @return: caller ID for rosparam ROS client calls\n    @rtype: str\n    \"\"\"\n    return make_caller_id('rosparam-%s'%os.getpid())\n\ndef print_params(params, ns):\n    \"\"\"\n    Print contents of param dictionary to screen\n    \"\"\"\n    if type(params) == dict:\n        for k, v in params.iteritems():\n            if type(v) == dict:\n                print_params(v, ns_join(ns, k))\n            else:\n                print \"%s=%s\"%(ns_join(ns, k), v)\n    else:\n        print params\n    \n# yaml processing\n\ndef load_file(filename, default_namespace=None, verbose=False):\n    \"\"\"\n    Load the YAML document from the specified file\n    \n    @param filename: name of filename\n    @type  filename: str\n    @param default_namespace: namespace to load filename into\n    @type  default_namespace: str\n    @return [(dict, str)...]: list of parameter dictionary and\n    corresponding namespaces for each YAML document in the file\n    @raise ROSParamException: if unable to load contents of filename\n    \"\"\"\n    if not os.path.isfile(filename):\n        raise ROSParamException(\"file [%s] does not exist\"%filename)\n    if verbose:\n        print \"reading parameters from [%s]\"%filename\n    f = open(filename, 'r')\n    try:\n        return load_str(f.read(), filename, default_namespace=default_namespace, verbose=verbose)\n    finally:\n        f.close()\n        \ndef load_str(str, filename, default_namespace=None, verbose=False):\n    \"\"\"\n    Load the YAML document as a string\n    \n    @param filename: name of filename, only used for debugging    \n    @type  filename: str\n    @param default_namespace: namespace to load filename into\n    @type  default_namespace: str\n    @param str: YAML text\n    @type  str: str\n    @return: list of parameter dictionary and\n        corresponding namespaces for each YAML document in the file\n    @rtype: [(dict, str)...]\n    \"\"\"\n    paramlist = []\n    default_namespace = default_namespace or get_ros_namespace()\n    for doc in yaml.load_all(str):\n        if NS in doc:\n            ns = ns_join(default_namespace, doc.get(NS, None))\n            if verbose:\n                print \"reading parameters into namespace [%s]\"%ns\n            del doc[NS]\n        else:\n            ns = default_namespace\n        paramlist.append((doc, ns))\n    return paramlist\n\n\n# DUMP/GET\n\ndef get_param(param):\n    \"\"\"\n    Download a parameter from Parameter Server\n\n    @param param: parameter name to retrieve from parameter\n        server. If param is a parameter namespace, entire parameter\n        subtree will be downloaded.\n    @type  param: str\n    \"\"\"\n    try:\n        return _succeed(get_param_server().getParam(_get_caller_id(), param))\n    except socket.error:\n        raise ROSParamIOException(\"Unable to communicate with master!\")\n    \n# #698\ndef _pretty_print(value, indent=''):\n    \"\"\"\n    Pretty print get value\n    @param value: value to print\n    @param indent: indent level, used for recursive calls\n    @type  indent: str\n    \"\"\"\n    keys = value.keys()\n    keys.sort()\n    for k in keys:\n        v = value[k]\n        if type(v) == dict:\n            print \"%s%s:\"%(indent, k)\n            _pretty_print(v, indent+'  ')\n        elif type(v) == str:\n            if '\\n' in v:\n                print indent+'%s: |'%k\n                for l in v.split('\\n'):\n                    print indent+'  '+l\n            else:\n                print \"%s%s: %s\"%(indent, k, v)\n        else:\n            dump = yaml.dump(v)\n            # #1617\n            # newer versions of python-yaml append the '...' document end\n            # syntax.  as YAML functions fine w/o it, and as it is\n            # confusing to users who are just getting a single scalar, we\n            # strip it\n            if dump.endswith('\\n...\\n'):\n                dump = dump[:-4]\n            \n            sys.stdout.write(\"%s%s: %s\"%(indent, k, dump))\n            \ndef _rosparam_cmd_get_param(param, pretty=False, verbose=False):\n    \"\"\"\n    Download a parameter tree and print to screen\n    @param param: parameter name to retrieve from Parameter\n        Server. If param is a parameter namespace, entire parameter\n        subtree will be downloaded.\n    @type  param: str\n    \"\"\"\n    # yaml.dump has a \\n at the end, so use stdout.write instead of print\n    if verbose:\n        print \"getting parameter [%s]\"%param\n    val = get_param(param)\n    if pretty and type(val) in [dict, str]:\n        if type(val) == dict:\n            _pretty_print(val)\n        else:\n            if '\\n' in val:\n                print '|'\n                for l in val.split('\\n'):\n                    print '  '+l\n            else:\n                print val\n    else:\n        dump = yaml.dump(val)\n        # #1617\n        # newer versions of python-yaml append the '...' document end\n        # syntax.  as YAML functions fine w/o it, and as it is\n        # confusing to users who are just getting a single scalar, we\n        # strip it\n        if dump.endswith('\\n...\\n'):\n            dump = dump[:-5]\n\n        sys.stdout.write(dump)\n\ndef dump_params(filename, param, verbose=False):\n    \"\"\"\n    Download a parameter tree from the Parameter Server and store in a yaml file\n    @param filename: name of file to save YAML representation\n    @type  filename: str\n    @param param: name of parameter/namespace to dump\n    @type  param: str\n    @param verbose: print verbose output for debugging\n    @type  verbose: bool\n    \"\"\"\n    tree = get_param(param)\n    if verbose:\n        print_params(tree, param)\n    f = open(filename, 'w')\n    try:\n        yaml.dump(tree, f)\n    finally:\n        f.close()\n\n\ndef delete_param(param, verbose=False):\n    \"\"\"\n    Delete a parameter from the Parameter Server\n    @param param: parameter name\n    @type  param: str\n    @param verbose: print verbose output for debugging\n    @type  verbose: bool\n    \"\"\"\n    try:\n        if param == GLOBALNS:\n            # not allowed to delete the root of the tree as it must always\n            # have a value. the equivalent command is setting the root to an\n            # empty dictionary\n            _succeed(get_param_server().setParam(_get_caller_id(), GLOBALNS, {})) \n            if verbose:\n                print \"deleted ENTIRE parameter server\"\n        else:\n            _succeed(get_param_server().deleteParam(_get_caller_id(), param))\n            if verbose:\n                print \"deleted parameter [%s]\"%param\n    except socket.error:\n        raise ROSParamIOException(\"Unable to communicate with master!\")\n    \n# LOAD/SET\n\ndef set_param_raw(param, value, verbose=False):\n    \"\"\"\n    Set param on the Parameter Server. Unlike L{set_param()}, this\n    takes in a Python value to set instead of YAML.\n    \n    @param param: parameter name\n    @type  param: str\n    @param value XmlRpcLegalValue: value to upload\n    @type  value: XmlRpcLegalValue\n    \"\"\"\n    if type(value) == dict:\n        # #1098 changing dictionary behavior to be an update, rather\n        # than replace behavior.\n        for k, v in value.iteritems():\n            # dictionary keys must be non-unicode strings\n            if isinstance(k, str):\n                set_param_raw(ns_join(param, k), v, verbose=verbose)\n            else:\n                raise ROSParamException(\"YAML dictionaries must have string keys. Invalid dictionary is:\\n%s\"%value)\n    else:\n        if type(value) == long:\n            if value > sys.maxint:\n                raise ROSParamException(\"Overflow: Parameter Server integers must be 32-bit signed integers:\\n\\t-%s <= value <= %s\"%(sys.maxint-1, sys.maxint))\n            \n        try:\n            _succeed(get_param_server().setParam(_get_caller_id(), param, value))\n        except socket.error:\n            raise ROSParamIOException(\"Unable to communicate with master!\")\n        if verbose:\n            print \"set parameter [%s] to [%s]\"%(param, value)\n\ndef set_param(param, value, verbose=False):\n    \"\"\"\n    Set param on the ROS parameter server using a YAML value.\n    \n    @param param: parameter name\n    @type  param: str\n    @param value: yaml-encoded value\n    @type  value: str\n    \"\"\"\n    set_param_raw(param, yaml.load(value), verbose=verbose)\n\ndef upload_params(ns, values, verbose=False):\n    \"\"\"\n    Upload params to the Parameter Server\n    @param values: key/value dictionary, where keys are parameter names and values are parameter values\n    @type  values: dict\n    @param ns: namespace to load parameters into        \n    @type  ns: str\n    \"\"\"\n    if ns == '/' and not type(values) == dict:\n        raise ROSParamException(\"global / can only be set to a dictionary\")\n    if verbose:\n        print_params(values, ns)\n    set_param_raw(ns, values)\n\n\n# LIST\n\ndef list_params(ns):\n    \"\"\"\n    Get list of parameters in ns\n    @param ns: namespace to match\n    @type  ns: str\n    \"\"\"\n    try:\n        ns = make_global_ns(ns)\n        names = _succeed(get_param_server().getParamNames(_get_caller_id()))\n        names.sort()\n        return [n for n in names if n.startswith(ns)]\n    except socket.error:\n        raise ROSParamIOException(\"Unable to communicate with master!\")\n\n# COMMAND-LINE PARSING\n    \ndef _rosparam_cmd_get_dump(cmd, argv):\n    \"\"\"\n    Process command line for rosparam get/dump, e.g.::\n      rosparam get param\n      rosparam dump file.yaml [namespace]\n    @param cmd: command ('get' or 'dump')\n    @type  cmd: str\n    @param argv: command-line args\n    @type  argv: str    \n    \n    \"\"\"\n    # get and dump are equivalent functionality, just different arguments\n    if cmd == 'dump':\n        parser = OptionParser(usage=\"usage: %prog dump [options] file [namespace]\", prog=NAME)\n    elif cmd == 'get':\n        parser = OptionParser(usage=\"usage: %prog get [options] parameter\", prog=NAME)        \n        parser.add_option(\"-p\", dest=\"pretty\", default=False,\n                          action=\"store_true\", help=\"pretty print. WARNING: not YAML-safe\")\n\n    parser.add_option(\"-v\", dest=\"verbose\", default=False,\n                      action=\"store_true\", help=\"turn on verbose output\")\n    options, args = parser.parse_args(argv[2:])\n\n    arg = None\n    ns = ''\n    \n    if len(args) == 0:\n        if cmd == 'dump':\n            parser.error(\"invalid arguments. Please specify a file name\")\n        elif cmd == 'get':\n            parser.error(\"invalid arguments. Please specify a parameter name\")\n    elif len(args) == 1:\n        arg = args[0]\n    elif len(args) == 2 and cmd == 'dump':\n        arg = args[0]\n        ns = args[1]\n    else:\n        parser.error(\"too many arguments\")\n\n    if cmd == 'get':\n        _rosparam_cmd_get_param(script_resolve_name(NAME, arg), pretty=options.pretty, verbose=options.verbose)\n    else:\n        if options.verbose:\n            print \"dumping namespace [%s] to file [%s]\"%(ns, arg)\n        dump_params(arg, script_resolve_name(NAME, ns), verbose=options.verbose)\n\ndef _set_optparse_neg_args(parser, argv):\n    # we don't use optparse to parse actual arguments, just options,\n    # due to the fact that optparse doesn't handle negative numbers as\n    # arguments. This parsing is complicated by the fact that we still\n    # need to respect argument-bearing options like --textfile.\n    args = []\n    optparse_args = []\n    skip = False\n    for s in argv[2:]:\n        if s.startswith('-'):\n            if s in ['-t', '--textfile', '-b', '--binfile']:\n                skip = True\n                optparse_args.append(s)\n            elif skip:\n                parser.error(\"-t and --textfile options require an argument\")\n            elif len(s) > 1 and ord(s[1]) >= ord('0') and ord(s[1]) <= ord('9'):\n                args.append(s)\n            else:\n                optparse_args.append(s)\n        else:\n            if skip:\n                skip = False\n                optparse_args.append(s)                \n            else:\n                args.append(s)\n    options, _ = parser.parse_args(optparse_args)\n    return options, args\n\n# TODO: break this into separate routines, has gotten too ugly to multiplex\ndef _rosparam_cmd_set_load(cmd, argv):\n    \"\"\"\n    Process command line for rosparam set/load, e.g.::\n      rosparam load file.yaml [namespace]\n      rosparam set param value\n    @param cmd: command name\n    @type  cmd: str\n    @param argv: command-line args\n    @type  argv: str    \n    \"\"\"\n    if cmd == 'load':\n        parser = OptionParser(usage=\"usage: %prog load [options] file [namespace]\", prog=NAME)\n    elif cmd == 'set':\n        parser = OptionParser(usage=\"usage: %prog set [options] parameter value\", prog=NAME)\n        parser.add_option(\"-t\", \"--textfile\", dest=\"text_file\", default=None,\n                          metavar=\"TEXT_FILE\", help=\"set parameters to contents of text file\")\n        parser.add_option(\"-b\", \"--binfile\", dest=\"bin_file\", default=None,\n                          metavar=\"BINARY_FILE\", help=\"set parameters to contents of binary file\")\n\n    parser.add_option(\"-v\", dest=\"verbose\", default=False,\n                      action=\"store_true\", help=\"turn on verbose output\")\n    options, args = _set_optparse_neg_args(parser, argv)\n    if cmd == 'set':\n        if options.text_file and options.bin_file:\n            parser.error(\"you may only specify one of --textfile or --binfile\")\n\n    arg2 = None\n    if len(args) == 0:\n        if cmd == 'load':\n            parser.error(\"invalid arguments. Please specify a file name\")\n        elif cmd == 'set':\n            parser.error(\"invalid arguments. Please specify a parameter name\")\n    elif len(args) == 1:\n        arg = args[0]\n        if cmd == 'set' and not (options.text_file or options.bin_file):\n            parser.error(\"invalid arguments. Please specify a parameter value\")\n    elif len(args) == 2:\n        arg = args[0]\n        arg2 = args[1]\n    else:\n        parser.error(\"too many arguments\")\n\n    if cmd == 'set':\n        name = script_resolve_name(NAME, arg)\n        # #2647\n        if options.text_file:\n            if not os.path.isfile(options.text_file):\n                parser.error(\"file '%s' does not exist\"%(options.text_file))\n            with open(options.text_file) as f:\n                arg2 = f.read()\n            set_param_raw(name, arg2, verbose=options.verbose) \n        elif options.bin_file:\n            import xmlrpclib\n            with open(options.bin_file, 'rb') as f:\n                arg2 = xmlrpclib.Binary(f.read())\n            set_param_raw(name, arg2, verbose=options.verbose)                \n        else:\n            # #2237: the empty string is really hard to specify on the\n            # command-line due to bash quoting rules. We cheat here and\n            # let an empty Python string be an empty YAML string (instead\n            # of YAML null, which has no meaning to the Parameter Server\n            # anyway).\n            if arg2 == '':\n                arg2 = '!!str'\n            set_param(name, arg2, verbose=options.verbose)\n    else:\n        paramlist = load_file(arg, default_namespace=script_resolve_name(NAME, arg2), verbose=options.verbose)\n        for params,ns in paramlist:\n            upload_params(ns, params, verbose=options.verbose)\n\ndef _rosparam_cmd_list(argv):\n    \"\"\"\n    Process command line for rosparam set/load, e.g.::\n      rosparam load file.yaml [namespace]\n      rosparam set param value\n    @param argv: command-line args\n    @type  argv: str\n    \"\"\"\n    parser = OptionParser(usage=\"usage: %prog list [namespace]\", prog=NAME)\n    options, args = parser.parse_args(argv[2:])\n\n    ns = GLOBALNS\n    if len(args) == 1:\n        ns = script_resolve_name(NAME, args[0])\n    elif len(args) == 2:\n        parser.error(\"too many arguments\")\n\n    print '\\n'.join(list_params(ns))\n\n\ndef _rosparam_cmd_delete(argv):\n    \"\"\"\n    Process command line for rosparam delete, e.g.::\n      rosparam delete param \n    @param cmd: command name\n    @type  cmd: str\n    @param argv: command-line args\n    @type  argv: str\n    \"\"\"\n    parser = OptionParser(usage=\"usage: %prog delete [options] parameter\", prog=NAME)\n    parser.add_option(\"-v\", dest=\"verbose\", default=False,\n                      action=\"store_true\", help=\"turn on verbose output\")\n    options, args = parser.parse_args(argv[2:])\n\n    arg2 = None\n    if len(args) == 0:\n        parser.error(\"invalid arguments. Please specify a parameter name\")\n    elif len(args) == 1:\n        arg = args[0]\n    else:\n        parser.error(\"too many arguments\")\n\n    delete_param(script_resolve_name(NAME, arg), verbose=options.verbose)\n\ndef _fullusage():\n    \"\"\"\n    Prints rosparam usage\n    \"\"\"\n    print \"\"\"rosparam is a command-line tool for getting, setting, and deleting parameters from the ROS Parameter Server.\n\nCommands:\n\\trosparam set\\tset parameter\n\\trosparam get\\tget parameter\n\\trosparam load\\tload parameters from file\n\\trosparam dump\\tdump parameters to file\n\\trosparam delete\\tdelete parameter\n\\trosparam list\\tlist parameter names\n\"\"\"\n    sys.exit(0)\n\ndef yamlmain(argv=None):\n    \"\"\"\n    Command-line main routine. Loads in one or more input files\n    \n    @param argv: command-line arguments or None to use sys.argv\n    @type  argv: [str]\n    \"\"\"\n    if argv is None:\n        argv = sys.argv\n    if len(argv) == 1:\n        _fullusage()\n    try:\n        command = argv[1]\n        if command in ['get', 'dump']:\n            _rosparam_cmd_get_dump(command, argv)\n        elif command in ['set', 'load']:\n            _rosparam_cmd_set_load(command, argv)\n        elif command in ['delete']:\n            _rosparam_cmd_delete(argv)\n        elif command == 'list':\n            _rosparam_cmd_list(argv)\n        else:\n            _fullusage()\n    except ROSParamException, e:\n        print >> sys.stderr, \"ERROR: \"+str(e)\n        sys.exit(1)\n\n# YAML configuration. Doxygen does not like these being higher up in the code\n\nyaml.add_constructor(u'!radians', construct_angle_radians)\nyaml.add_constructor(u'!degrees', construct_angle_degrees)\n\n# allow both !degrees 180, !radians 2*pi\npattern = re.compile(r'^deg\\([^\\)]*\\)$')\nyaml.add_implicit_resolver(u'!degrees', pattern, first=\"deg(\")\npattern = re.compile(r'^rad\\([^\\)]*\\)$')\nyaml.add_implicit_resolver(u'!radians', pattern, first=\"rad(\")"
  },
  {
    "id": "detachable_joint/detachablejointshtml.txt",
    "content": "[ ![](https://gazebosim.org/assets/doxygen/gazebo_logo.svg) ](index.html)\n\n#  Gazebo Sim\n\n##  API Reference\n\n8.3.0\n\n[ _insert_drive_file_ Tutorials ](tutorials.html) _library_books_ Classes\n_toc_ Namespaces  [ _insert_drive_file_ Files ](files.html) [ _launch_ Gazebo\nWebsite ](http://gazebosim.org)\n\n  * [ Index ](classes.html)\n  * [ List ](annotated.html)\n  * [ Hierarchy ](hierarchy.html)\n  * [ Members: All ](functions.html)\n  * [ Members: Functions ](functions_func.html)\n  * [ Members: Variables ](functions_vars.html)\n  * [ Members: Typedefs ](functions_type.html)\n  * [ Members: Enumerations ](functions_enum.html)\n  * [ Members: Enumerator ](functions_eval.html)\n\n  * [ List ](namespaces.html)\n  * [ Members ](namespacemembers.html)\n  * [ Functions ](namespacemembers_func.html)\n  * [ Typedefs ](namespacemembers_type.html)\n  * [ Variables ](namespacemembers_vars.html)\n  * [ Enumerations ](namespacemembers_enum.html)\n  * [ Enumerator ](namespacemembers_eval.html)\n\nDetachable Joints\n\nThe ` DetachableJoint ` system allows two models to start off rigidly attached\nand then detach during simulation by publishing to a topic. The system\ninternally uses a fixed joint between two links, each belonging to two\nseparate models. Because the system uses joints to connect models, the\nresulting kinematic topology has to be a tree, i.e., kinematic loops are not\ncurrently supported. This affects the choice of the parent link, and\ntherefore, the parent model, which is the model that contains the `\nDetachableJoint ` system. Once detached, the joint can be re-attached by\npublishing to a topic. When reattaching, the child model will be attached to\nthe parent model at its current pose/configuration. To achieve reattachment at\na specific pose, the child model can be positioned accordingly through a\nset_pose service call prior to reattaching the joint.\n\nFor example, [ detachable_joint.sdf ](https://github.com/gazebosim/gz-\nsim/blob/ign-gazebo2/examples/worlds/detachable_joint.sdf) demonstrates a four\nwheel vehicle that holds three objects that are later detached from the\nvehicle. As seen in this example, the parent model is the vehicle. The\nkinematic topology is the following.\n\nworld---vehicle_blue---B1\n\n\\\n\n\\---B2\n\n\\\n\n\\---B3\n\nIf the objects were each parent models, instead, there would be multiple\nkinematic loops, as shown below.\n\nworld---B1---vehicle_blue\n\n\\ / /\n\n\\---B2 /\n\n\\ /\n\n\\---B3\n\nDue to a limitation in the implementation of this system, if detached models\nneed to collide with a parent model or other detached models that have the\nsame parent, the parent model needs to have ` <self_collide> ` set to true.\nHowever, due to an issue in DART, the default physics engine, it is important\nthat none of the parent or child models be in collision in their initial\n(attached) state. Furthermore, it is important to note that reattaching a\nchild model is not currently supported while the child model and parent model\nare in contact. Therefore, it is imperative to ensure that there is no\ncollision between the child and parent model when attempting to perform the\nreattachment process.\n\nThe system has the following parameters:\n\n  * ` <parent_link> ` : Name of the link in the model containing this system that will be used as the parent link in the detachable joint. \n  * ` <child_model> ` : The name of the model containing the child link in the detachable joint. \n  * ` <child_model_link> ` : Name of the link in the ` <child_model> ` that will be used as the child link in the detachable joint. \n  * ` topic ` (optional): Topic name to be used for detaching connections. Using <detach_topic> is preferred. If empty, a default topic will be created with a pattern ` /model/<model_name>/detachable_joint/detach ` . \n  * ` detach_topic ` (optional): Topic name to be used for detaching connections. If empty, a default topic will be created with a pattern ` /model/<model_name>/detachable_joint/detach ` . If multiple detachable plugin is used in one model, ` detach_topic ` is REQUIRED to detach child models individually. \n  * ` attach_topic ` (optional): Topic name to be used for re-attaching connections. If empty, a default topic will be created with a pattern ` /model/<model_name>/detachable_joint/attach ` . If multiple detachable plugin is used in one model, ` attach_topic ` is REQUIRED to attach child models individually. \n  * ` output_topic ` (optional): Topic name to be used for publishing the state of the detachment. If empty, a default topic will be created with a pattern ` /model/<child_model_name>/detachable_joint/state ` . If multiple detachable plugin is used in one model, ` output_topic ` is REQUIRED to publish child models state individually. \n\n"
  },
  {
    "id": "costmap_subscript/indexhtml.txt",
    "content": "[ Navigation 2 ![Logo](../_static/nav2_logo.png) ](../index.html)\n\nlatest\n\n  * [ Getting Started ](../getting_started/index.html)\n    * [ Installation ](../getting_started/index.html#installation)\n    * [ Running the Example ](../getting_started/index.html#running-the-example)\n    * [ Navigating ](../getting_started/index.html#navigating)\n  * [ Development Guides ](../development_guides/index.html)\n    * [ Build and Install ](../development_guides/build_docs/index.html)\n      * [ Install ](../development_guides/build_docs/index.html#install)\n      * [ Build ](../development_guides/build_docs/index.html#build)\n        * [ Released Distribution Binaries ](../development_guides/build_docs/index.html#released-distribution-binaries)\n        * [ Rolling Development Source ](../development_guides/build_docs/index.html#rolling-development-source)\n        * [ Docker Container Images ](../development_guides/build_docs/index.html#docker-container-images)\n      * [ Generate Doxygen ](../development_guides/build_docs/index.html#generate-doxygen)\n      * [ Help ](../development_guides/build_docs/index.html#help)\n        * [ Build Troubleshooting Guide ](../development_guides/build_docs/build_troubleshooting_guide.html)\n    * [ Dev Containers ](../development_guides/devcontainer_docs/index.html)\n      * [ Dev Container Guide ](../development_guides/devcontainer_docs/devcontainer_guide.html)\n        * [ Creating Dev Containers ](../development_guides/devcontainer_docs/devcontainer_guide.html#creating-dev-containers)\n        * [ Using Dev Containers ](../development_guides/devcontainer_docs/devcontainer_guide.html#using-dev-containers)\n      * [ What, Why, How? ](../development_guides/devcontainer_docs/index.html#what-why-how)\n        * [ What is a Dev Container? ](../development_guides/devcontainer_docs/index.html#what-is-a-dev-container)\n        * [ Why use a Dev Container? ](../development_guides/devcontainer_docs/index.html#why-use-a-dev-container)\n        * [ How do Dev Containers work? ](../development_guides/devcontainer_docs/index.html#how-do-dev-containers-work)\n      * [ Prerequisites ](../development_guides/devcontainer_docs/index.html#prerequisites)\n      * [ Getting started ](../development_guides/devcontainer_docs/index.html#getting-started)\n      * [ Security ](../development_guides/devcontainer_docs/index.html#security)\n    * [ Getting Involved ](../development_guides/involvement_docs/index.html)\n      * [ Getting Involved ](../development_guides/involvement_docs/index.html#id1)\n      * [ Process ](../development_guides/involvement_docs/index.html#process)\n      * [ Licensing ](../development_guides/involvement_docs/index.html#licensing)\n      * [ Developer Certification of Origin (DCO) ](../development_guides/involvement_docs/index.html#developer-certification-of-origin-dco)\n  * Navigation Concepts \n    * ROS 2 \n      * Action Server \n      * Lifecycle Nodes and Bond \n    * Behavior Trees \n    * Navigation Servers \n      * Planner, Controller, Smoother and Recovery Servers \n      * Planners \n      * Controllers \n      * Behaviors \n      * Smoothers \n      * Waypoint Following \n    * State Estimation \n      * Standards \n      * Global Positioning: Localization and SLAM \n      * Odometry \n    * Environmental Representation \n      * Costmaps and Layers \n      * Costmap Filters \n      * Other Forms \n    * Nav2 Academic Overview \n  * [ First-Time Robot Setup Guide ](../setup_guides/index.html)\n    * [ Setting Up Transformations ](../setup_guides/transformation/setup_transforms.html)\n      * [ Transforms Introduction ](../setup_guides/transformation/setup_transforms.html#transforms-introduction)\n      * [ Static Transform Publisher Demo ](../setup_guides/transformation/setup_transforms.html#static-transform-publisher-demo)\n      * [ Transforms in Navigation2 ](../setup_guides/transformation/setup_transforms.html#transforms-in-navigation2)\n      * [ Conclusion ](../setup_guides/transformation/setup_transforms.html#conclusion)\n    * [ Setting Up The URDF ](../setup_guides/urdf/setup_urdf.html)\n      * [ URDF and the Robot State Publisher ](../setup_guides/urdf/setup_urdf.html#urdf-and-the-robot-state-publisher)\n      * [ Setting Up the Environment ](../setup_guides/urdf/setup_urdf.html#setting-up-the-environment)\n      * [ Writing the URDF ](../setup_guides/urdf/setup_urdf.html#writing-the-urdf)\n      * [ Build and Launch ](../setup_guides/urdf/setup_urdf.html#build-and-launch)\n      * [ Visualization using RVIZ ](../setup_guides/urdf/setup_urdf.html#visualization-using-rviz)\n      * [ Adding Physical Properties ](../setup_guides/urdf/setup_urdf.html#adding-physical-properties)\n      * [ Conclusion ](../setup_guides/urdf/setup_urdf.html#conclusion)\n    * [ Setting Up Odometry ](../setup_guides/odom/setup_odom.html)\n      * [ Odometry Introduction ](../setup_guides/odom/setup_odom.html#odometry-introduction)\n      * [ Setting Up Odometry on your Robot ](../setup_guides/odom/setup_odom.html#setting-up-odometry-on-your-robot)\n      * [ Simulating an Odometry System using Gazebo ](../setup_guides/odom/setup_odom.html#simulating-an-odometry-system-using-gazebo)\n        * [ Setup and Prerequisites ](../setup_guides/odom/setup_odom.html#setup-and-prerequisites)\n        * [ Adding Gazebo Plugins to a URDF ](../setup_guides/odom/setup_odom.html#adding-gazebo-plugins-to-a-urdf)\n        * [ Launch and Build Files ](../setup_guides/odom/setup_odom.html#launch-and-build-files)\n        * [ Build, Run and Verification ](../setup_guides/odom/setup_odom.html#build-run-and-verification)\n      * [ Robot Localization Demo ](../setup_guides/odom/setup_odom.html#robot-localization-demo)\n        * [ Configuring Robot Localization ](../setup_guides/odom/setup_odom.html#configuring-robot-localization)\n        * [ Launch and Build Files ](../setup_guides/odom/setup_odom.html#id3)\n        * [ Build, Run and Verification ](../setup_guides/odom/setup_odom.html#id4)\n      * [ Conclusion ](../setup_guides/odom/setup_odom.html#conclusion)\n    * [ Setting Up Sensors ](../setup_guides/sensors/setup_sensors.html)\n      * [ Sensor Introduction ](../setup_guides/sensors/setup_sensors.html#sensor-introduction)\n        * [ Common Sensor Messages ](../setup_guides/sensors/setup_sensors.html#common-sensor-messages)\n      * [ Simulating Sensors using Gazebo ](../setup_guides/sensors/setup_sensors.html#simulating-sensors-using-gazebo)\n        * [ Adding Gazebo Plugins to a URDF ](../setup_guides/sensors/setup_sensors.html#adding-gazebo-plugins-to-a-urdf)\n        * [ Launch and Build Files ](../setup_guides/sensors/setup_sensors.html#launch-and-build-files)\n        * [ Build, Run and Verification ](../setup_guides/sensors/setup_sensors.html#build-run-and-verification)\n      * [ Mapping and Localization ](../setup_guides/sensors/setup_sensors.html#mapping-and-localization)\n      * [ Costmap 2D ](../setup_guides/sensors/setup_sensors.html#costmap-2d)\n        * [ Configuring nav2_costmap_2d ](../setup_guides/sensors/setup_sensors.html#configuring-nav2-costmap-2d)\n        * [ Build, Run and Verification ](../setup_guides/sensors/setup_sensors.html#id2)\n      * [ Conclusion ](../setup_guides/sensors/setup_sensors.html#conclusion)\n    * [ Setting Up the Robot\u2019s Footprint ](../setup_guides/footprint/setup_footprint.html)\n      * [ Footprint Introduction ](../setup_guides/footprint/setup_footprint.html#footprint-introduction)\n      * [ Configuring the Robot\u2019s Footprint ](../setup_guides/footprint/setup_footprint.html#configuring-the-robot-s-footprint)\n      * [ Build, Run and Verification ](../setup_guides/footprint/setup_footprint.html#build-run-and-verification)\n      * [ Visualizing Footprint in RViz ](../setup_guides/footprint/setup_footprint.html#visualizing-footprint-in-rviz)\n      * [ Conclusion ](../setup_guides/footprint/setup_footprint.html#conclusion)\n    * [ Setting Up Navigation Plugins ](../setup_guides/algorithm/select_algorithm.html)\n      * [ Planner and Controller Servers ](../setup_guides/algorithm/select_algorithm.html#planner-and-controller-servers)\n      * [ Selecting the Algorithm Plugins ](../setup_guides/algorithm/select_algorithm.html#selecting-the-algorithm-plugins)\n        * [ Planner Server ](../setup_guides/algorithm/select_algorithm.html#planner-server)\n        * [ Controller Server ](../setup_guides/algorithm/select_algorithm.html#controller-server)\n      * [ Conclusion ](../setup_guides/algorithm/select_algorithm.html#conclusion)\n  * [ General Tutorials ](../tutorials/index.html)\n    * [ Navigating with a Physical Turtlebot 3 ](../tutorials/docs/navigation2_on_real_turtlebot3.html)\n      * [ Overview ](../tutorials/docs/navigation2_on_real_turtlebot3.html#overview)\n      * [ Requirements ](../tutorials/docs/navigation2_on_real_turtlebot3.html#requirements)\n      * [ Tutorial Steps ](../tutorials/docs/navigation2_on_real_turtlebot3.html#tutorial-steps)\n        * [ 0- Setup Your Enviroment Variables ](../tutorials/docs/navigation2_on_real_turtlebot3.html#setup-your-enviroment-variables)\n        * [ 1- Launch Turtlebot 3 ](../tutorials/docs/navigation2_on_real_turtlebot3.html#launch-turtlebot-3)\n        * [ 2- Launch Nav2 ](../tutorials/docs/navigation2_on_real_turtlebot3.html#launch-nav2)\n        * [ 3- Launch RVIZ ](../tutorials/docs/navigation2_on_real_turtlebot3.html#launch-rviz)\n        * [ 4- Initialize the Location of Turtlebot 3 ](../tutorials/docs/navigation2_on_real_turtlebot3.html#initialize-the-location-of-turtlebot-3)\n        * [ 5- Send a Goal Pose ](../tutorials/docs/navigation2_on_real_turtlebot3.html#send-a-goal-pose)\n    * [ (SLAM) Navigating While Mapping ](../tutorials/docs/navigation2_with_slam.html)\n      * [ Overview ](../tutorials/docs/navigation2_with_slam.html#overview)\n      * [ Requirements ](../tutorials/docs/navigation2_with_slam.html#requirements)\n      * [ Tutorial Steps ](../tutorials/docs/navigation2_with_slam.html#tutorial-steps)\n        * [ 0- Launch Robot Interfaces ](../tutorials/docs/navigation2_with_slam.html#launch-robot-interfaces)\n        * [ 1- Launch Navigation2 ](../tutorials/docs/navigation2_with_slam.html#launch-navigation2)\n        * [ 2- Launch SLAM ](../tutorials/docs/navigation2_with_slam.html#launch-slam)\n        * [ 3- Working with SLAM ](../tutorials/docs/navigation2_with_slam.html#working-with-slam)\n        * [ 4- Getting Started Simplification ](../tutorials/docs/navigation2_with_slam.html#getting-started-simplification)\n    * [ (STVL) Using an External Costmap Plugin ](../tutorials/docs/navigation2_with_stvl.html)\n      * [ Overview ](../tutorials/docs/navigation2_with_stvl.html#overview)\n      * [ Costmap2D and STVL ](../tutorials/docs/navigation2_with_stvl.html#costmap2d-and-stvl)\n      * [ Tutorial Steps ](../tutorials/docs/navigation2_with_stvl.html#tutorial-steps)\n        * [ 0- Setup ](../tutorials/docs/navigation2_with_stvl.html#setup)\n        * [ 1- Install STVL ](../tutorials/docs/navigation2_with_stvl.html#install-stvl)\n        * [ 1- Modify Navigation2 Parameter ](../tutorials/docs/navigation2_with_stvl.html#modify-navigation2-parameter)\n        * [ 2- Launch Navigation2 ](../tutorials/docs/navigation2_with_stvl.html#launch-navigation2)\n        * [ 3- RVIZ ](../tutorials/docs/navigation2_with_stvl.html#rviz)\n    * [ Groot - Interacting with Behavior Trees ](../tutorials/docs/using_groot.html)\n      * [ Overview ](../tutorials/docs/using_groot.html#overview)\n      * [ Visualize Behavior Trees ](../tutorials/docs/using_groot.html#visualize-behavior-trees)\n      * [ Edit Behavior Trees ](../tutorials/docs/using_groot.html#edit-behavior-trees)\n      * [ Adding A Custom Node ](../tutorials/docs/using_groot.html#adding-a-custom-node)\n    * [ Camera Calibration ](../tutorials/docs/camera_calibration.html)\n      * [ Overview ](../tutorials/docs/camera_calibration.html#overview)\n      * [ Requirements ](../tutorials/docs/camera_calibration.html#requirements)\n      * [ Tutorial Steps ](../tutorials/docs/camera_calibration.html#tutorial-steps)\n    * [ Get Backtrace in ROS 2 / Nav2 ](../tutorials/docs/get_backtrace.html)\n      * [ Overview ](../tutorials/docs/get_backtrace.html#overview)\n      * [ Preliminaries ](../tutorials/docs/get_backtrace.html#preliminaries)\n      * [ From a Node ](../tutorials/docs/get_backtrace.html#from-a-node)\n      * [ From a Launch File ](../tutorials/docs/get_backtrace.html#from-a-launch-file)\n      * [ From Large Project ](../tutorials/docs/get_backtrace.html#from-large-project)\n      * [ From Nav2 Bringup ](../tutorials/docs/get_backtrace.html#from-nav2-bringup)\n      * [ Automatic backtrace on crash ](../tutorials/docs/get_backtrace.html#automatic-backtrace-on-crash)\n    * [ Profiling in ROS 2 / Nav2 ](../tutorials/docs/get_profile.html)\n      * [ Overview ](../tutorials/docs/get_profile.html#overview)\n      * [ Preliminaries ](../tutorials/docs/get_profile.html#preliminaries)\n      * [ Profile from a Node ](../tutorials/docs/get_profile.html#profile-from-a-node)\n      * [ Profile from a Launch File ](../tutorials/docs/get_profile.html#profile-from-a-launch-file)\n      * [ From Nav2 Bringup ](../tutorials/docs/get_profile.html#from-nav2-bringup)\n      * [ Interpreting Results ](../tutorials/docs/get_profile.html#interpreting-results)\n    * [ Dynamic Object Following ](../tutorials/docs/navigation2_dynamic_point_following.html)\n      * [ Overview ](../tutorials/docs/navigation2_dynamic_point_following.html#overview)\n      * [ Tutorial Steps ](../tutorials/docs/navigation2_dynamic_point_following.html#tutorial-steps)\n        * [ 0- Create the Behavior Tree ](../tutorials/docs/navigation2_dynamic_point_following.html#create-the-behavior-tree)\n        * [ 1- Setup Rviz clicked point ](../tutorials/docs/navigation2_dynamic_point_following.html#setup-rviz-clicked-point)\n        * [ 2- Run Dynamic Object Following in Nav2 Simulation ](../tutorials/docs/navigation2_dynamic_point_following.html#run-dynamic-object-following-in-nav2-simulation)\n    * [ Navigating with Keepout Zones ](../tutorials/docs/navigation2_with_keepout_filter.html)\n      * [ Overview ](../tutorials/docs/navigation2_with_keepout_filter.html#overview)\n      * [ Requirements ](../tutorials/docs/navigation2_with_keepout_filter.html#requirements)\n      * [ Tutorial Steps ](../tutorials/docs/navigation2_with_keepout_filter.html#tutorial-steps)\n        * [ 1\\. Prepare filter mask ](../tutorials/docs/navigation2_with_keepout_filter.html#prepare-filter-mask)\n        * [ 2\\. Configure Costmap Filter Info Publisher Server ](../tutorials/docs/navigation2_with_keepout_filter.html#configure-costmap-filter-info-publisher-server)\n        * [ 3\\. Enable Keepout Filter ](../tutorials/docs/navigation2_with_keepout_filter.html#enable-keepout-filter)\n        * [ 4\\. Run Nav2 stack ](../tutorials/docs/navigation2_with_keepout_filter.html#run-nav2-stack)\n    * [ Navigating with Speed Limits ](../tutorials/docs/navigation2_with_speed_filter.html)\n      * [ Overview ](../tutorials/docs/navigation2_with_speed_filter.html#overview)\n      * [ Requirements ](../tutorials/docs/navigation2_with_speed_filter.html#requirements)\n      * [ Tutorial Steps ](../tutorials/docs/navigation2_with_speed_filter.html#tutorial-steps)\n        * [ 1\\. Prepare filter mask ](../tutorials/docs/navigation2_with_speed_filter.html#prepare-filter-mask)\n        * [ 2\\. Configure Costmap Filter Info Publisher Server ](../tutorials/docs/navigation2_with_speed_filter.html#configure-costmap-filter-info-publisher-server)\n        * [ 3\\. Enable Speed Filter ](../tutorials/docs/navigation2_with_speed_filter.html#enable-speed-filter)\n        * [ 4\\. Run Nav2 stack ](../tutorials/docs/navigation2_with_speed_filter.html#run-nav2-stack)\n    * [ Using Rotation Shim Controller ](../tutorials/docs/using_shim_controller.html)\n      * [ Overview ](../tutorials/docs/using_shim_controller.html#overview)\n      * [ What is the Rotation Shim Controller? ](../tutorials/docs/using_shim_controller.html#what-is-the-rotation-shim-controller)\n      * [ Configuring Rotation Shim Controller ](../tutorials/docs/using_shim_controller.html#configuring-rotation-shim-controller)\n      * [ Configuring Primary Controller ](../tutorials/docs/using_shim_controller.html#configuring-primary-controller)\n      * [ Demo Execution ](../tutorials/docs/using_shim_controller.html#demo-execution)\n    * [ Adding a Smoother to a BT ](../tutorials/docs/adding_smoother.html)\n      * [ Overview ](../tutorials/docs/adding_smoother.html#overview)\n      * [ Requirements ](../tutorials/docs/adding_smoother.html#requirements)\n      * [ Tutorial Steps ](../tutorials/docs/adding_smoother.html#tutorial-steps)\n        * [ 0- Familiarization with the Smoother BT Node ](../tutorials/docs/adding_smoother.html#familiarization-with-the-smoother-bt-node)\n        * [ 1- Specifying a Smoother Plugin ](../tutorials/docs/adding_smoother.html#specifying-a-smoother-plugin)\n        * [ 2- Modifying your BT XML ](../tutorials/docs/adding_smoother.html#modifying-your-bt-xml)\n    * [ Using Collision Monitor ](../tutorials/docs/using_collision_monitor.html)\n      * [ Overview ](../tutorials/docs/using_collision_monitor.html#overview)\n      * [ Requirements ](../tutorials/docs/using_collision_monitor.html#requirements)\n      * [ Configuring Collision Monitor ](../tutorials/docs/using_collision_monitor.html#configuring-collision-monitor)\n      * [ Preparing Nav2 stack ](../tutorials/docs/using_collision_monitor.html#preparing-nav2-stack)\n      * [ Demo Execution ](../tutorials/docs/using_collision_monitor.html#demo-execution)\n    * [ Adding a New Nav2 Task Server ](../tutorials/docs/adding_a_nav2_task_server.html)\n      * [ Lifecycle Nodes ](../tutorials/docs/adding_a_nav2_task_server.html#lifecycle-nodes)\n      * [ Composition ](../tutorials/docs/adding_a_nav2_task_server.html#composition)\n      * [ Error codes ](../tutorials/docs/adding_a_nav2_task_server.html#error-codes)\n      * [ Conclusion ](../tutorials/docs/adding_a_nav2_task_server.html#conclusion)\n    * [ Filtering of Noise-Induced Obstacles ](../tutorials/docs/filtering_of_noise-induced_obstacles.html)\n      * [ Overview ](../tutorials/docs/filtering_of_noise-induced_obstacles.html#overview)\n      * [ Requirements ](../tutorials/docs/filtering_of_noise-induced_obstacles.html#requirements)\n      * [ Tutorial Steps ](../tutorials/docs/filtering_of_noise-induced_obstacles.html#tutorial-steps)\n        * [ 1\\. Enable Denoise Layer ](../tutorials/docs/filtering_of_noise-induced_obstacles.html#enable-denoise-layer)\n        * [ 2\\. Run Nav2 stack ](../tutorials/docs/filtering_of_noise-induced_obstacles.html#run-nav2-stack)\n      * [ How it works ](../tutorials/docs/filtering_of_noise-induced_obstacles.html#how-it-works)\n  * [ Plugin Tutorials ](../plugin_tutorials/index.html)\n    * [ Writing a New Costmap2D Plugin ](../plugin_tutorials/docs/writing_new_costmap2d_plugin.html)\n      * [ Overview ](../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#overview)\n      * [ Requirements ](../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#requirements)\n      * [ Tutorial Steps ](../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#tutorial-steps)\n        * [ 1- Write a new Costmap2D plugin ](../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#write-a-new-costmap2d-plugin)\n        * [ 2- Export and make GradientLayer plugin ](../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#export-and-make-gradientlayer-plugin)\n        * [ 3- Enable the plugin in Costmap2D ](../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#enable-the-plugin-in-costmap2d)\n        * [ 4- Run GradientLayer plugin ](../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#run-gradientlayer-plugin)\n    * [ Writing a New Planner Plugin ](../plugin_tutorials/docs/writing_new_nav2planner_plugin.html)\n      * [ Overview ](../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#overview)\n      * [ Requirements ](../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#requirements)\n      * [ Tutorial Steps ](../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#tutorial-steps)\n        * [ 1- Creating a new Planner Plugin ](../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#creating-a-new-planner-plugin)\n        * [ 2- Exporting the planner plugin ](../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#exporting-the-planner-plugin)\n        * [ 3- Pass the plugin name through params file ](../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#pass-the-plugin-name-through-params-file)\n        * [ 4- Run StraightLine plugin ](../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#run-straightline-plugin)\n    * [ Writing a New Controller Plugin ](../plugin_tutorials/docs/writing_new_nav2controller_plugin.html)\n      * [ Overview ](../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#overview)\n      * [ Requirements ](../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#requirements)\n      * [ Tutorial Steps ](../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#tutorial-steps)\n        * [ 1- Create a new Controller Plugin ](../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#create-a-new-controller-plugin)\n        * [ 2- Exporting the controller plugin ](../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#exporting-the-controller-plugin)\n        * [ 3- Pass the plugin name through the params file ](../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#pass-the-plugin-name-through-the-params-file)\n        * [ 4- Run Pure Pursuit Controller plugin ](../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#run-pure-pursuit-controller-plugin)\n    * [ Writing a New Behavior Tree Plugin ](../plugin_tutorials/docs/writing_new_bt_plugin.html)\n      * [ Overview ](../plugin_tutorials/docs/writing_new_bt_plugin.html#overview)\n      * [ Requirements ](../plugin_tutorials/docs/writing_new_bt_plugin.html#requirements)\n      * [ Tutorial Steps ](../plugin_tutorials/docs/writing_new_bt_plugin.html#tutorial-steps)\n        * [ 1- Creating a new BT Plugin ](../plugin_tutorials/docs/writing_new_bt_plugin.html#creating-a-new-bt-plugin)\n        * [ 2- Exporting the planner plugin ](../plugin_tutorials/docs/writing_new_bt_plugin.html#exporting-the-planner-plugin)\n        * [ 3- Add plugin library name to config ](../plugin_tutorials/docs/writing_new_bt_plugin.html#add-plugin-library-name-to-config)\n        * [ 4- Run Your Custom plugin ](../plugin_tutorials/docs/writing_new_bt_plugin.html#run-your-custom-plugin)\n    * [ Writing a New Behavior Plugin ](../plugin_tutorials/docs/writing_new_behavior_plugin.html)\n      * [ Overview ](../plugin_tutorials/docs/writing_new_behavior_plugin.html#overview)\n      * [ Requirements ](../plugin_tutorials/docs/writing_new_behavior_plugin.html#requirements)\n      * [ Tutorial Steps ](../plugin_tutorials/docs/writing_new_behavior_plugin.html#tutorial-steps)\n        * [ 1- Creating a new Behavior Plugin ](../plugin_tutorials/docs/writing_new_behavior_plugin.html#creating-a-new-behavior-plugin)\n        * [ 2- Exporting the Behavior Plugin ](../plugin_tutorials/docs/writing_new_behavior_plugin.html#exporting-the-behavior-plugin)\n        * [ 3- Pass the plugin name through params file ](../plugin_tutorials/docs/writing_new_behavior_plugin.html#pass-the-plugin-name-through-params-file)\n        * [ 4- Run Behavior Plugin ](../plugin_tutorials/docs/writing_new_behavior_plugin.html#run-behavior-plugin)\n    * [ Writing a New Navigator Plugin ](../plugin_tutorials/docs/writing_new_navigator_plugin.html)\n      * [ Overview ](../plugin_tutorials/docs/writing_new_navigator_plugin.html#overview)\n      * [ Requirements ](../plugin_tutorials/docs/writing_new_navigator_plugin.html#requirements)\n      * [ Tutorial Steps ](../plugin_tutorials/docs/writing_new_navigator_plugin.html#tutorial-steps)\n        * [ 1- Create a new Navigator Plugin ](../plugin_tutorials/docs/writing_new_navigator_plugin.html#create-a-new-navigator-plugin)\n        * [ 2- Exporting the navigator plugin ](../plugin_tutorials/docs/writing_new_navigator_plugin.html#exporting-the-navigator-plugin)\n        * [ 3- Pass the plugin name through the params file ](../plugin_tutorials/docs/writing_new_navigator_plugin.html#pass-the-plugin-name-through-the-params-file)\n        * [ 4- Run plugin ](../plugin_tutorials/docs/writing_new_navigator_plugin.html#run-plugin)\n  * [ Configuration Guide ](../configuration/index.html)\n    * [ Behavior-Tree Navigator ](../configuration/packages/configuring-bt-navigator.html)\n      * [ Parameters ](../configuration/packages/configuring-bt-navigator.html#parameters)\n      * [ Example ](../configuration/packages/configuring-bt-navigator.html#example)\n    * [ Behavior Tree XML Nodes ](../configuration/packages/configuring-bt-xml.html)\n      * [ Action Plugins ](../configuration/packages/configuring-bt-xml.html#action-plugins)\n        * [ Wait ](../configuration/packages/bt-plugins/actions/Wait.html)\n        * [ Spin ](../configuration/packages/bt-plugins/actions/Spin.html)\n        * [ BackUp ](../configuration/packages/bt-plugins/actions/BackUp.html)\n        * [ DriveOnHeading ](../configuration/packages/bt-plugins/actions/DriveOnHeading.html)\n        * [ AssistedTeleop ](../configuration/packages/bt-plugins/actions/AssistedTeleop.html)\n        * [ ComputePathToPose ](../configuration/packages/bt-plugins/actions/ComputePathToPose.html)\n        * [ FollowPath ](../configuration/packages/bt-plugins/actions/FollowPath.html)\n        * [ NavigateToPose ](../configuration/packages/bt-plugins/actions/NavigateToPose.html)\n        * [ ClearEntireCostmap ](../configuration/packages/bt-plugins/actions/ClearEntireCostmap.html)\n        * [ ClearCostmapExceptRegion ](../configuration/packages/bt-plugins/actions/ClearCostmapExceptRegion.html)\n        * [ ClearCostmapAroundRobot ](../configuration/packages/bt-plugins/actions/ClearCostmapAroundRobot.html)\n        * [ ReinitializeGlobalLocalization ](../configuration/packages/bt-plugins/actions/ReinitializeGlobalLocalization.html)\n        * [ TruncatePath ](../configuration/packages/bt-plugins/actions/TruncatePath.html)\n        * [ TruncatePathLocal ](../configuration/packages/bt-plugins/actions/TruncatePathLocal.html)\n        * [ PlannerSelector ](../configuration/packages/bt-plugins/actions/PlannerSelector.html)\n        * [ ControllerSelector ](../configuration/packages/bt-plugins/actions/ControllerSelector.html)\n        * [ SmootherSelector ](../configuration/packages/bt-plugins/actions/SmootherSelector.html)\n        * [ GoalCheckerSelector ](../configuration/packages/bt-plugins/actions/GoalCheckerSelector.html)\n        * [ NavigateThroughPoses ](../configuration/packages/bt-plugins/actions/NavigateThroughPoses.html)\n        * [ ComputePathThroughPoses ](../configuration/packages/bt-plugins/actions/ComputePathThroughPoses.html)\n        * [ RemovePassedGoals ](../configuration/packages/bt-plugins/actions/RemovePassedGoals.html)\n        * [ CancelControl ](../configuration/packages/bt-plugins/actions/CancelControl.html)\n        * [ CancelBackUp ](../configuration/packages/bt-plugins/actions/CancelBackUp.html)\n        * [ CancelSpin ](../configuration/packages/bt-plugins/actions/CancelSpin.html)\n        * [ CancelWait ](../configuration/packages/bt-plugins/actions/CancelWait.html)\n        * [ CancelDriveOnHeading ](../configuration/packages/bt-plugins/actions/CancelDriveOnHeading.html)\n        * [ CancelAssistedTeleop ](../configuration/packages/bt-plugins/actions/CancelAssistedTeleop.html)\n        * [ SmoothPath ](../configuration/packages/bt-plugins/actions/Smooth.html)\n      * [ Condition Plugins ](../configuration/packages/configuring-bt-xml.html#condition-plugins)\n        * [ GoalReached ](../configuration/packages/bt-plugins/conditions/GoalReached.html)\n        * [ TransformAvailable ](../configuration/packages/bt-plugins/conditions/TransformAvailable.html)\n        * [ DistanceTraveled ](../configuration/packages/bt-plugins/conditions/DistanceTraveled.html)\n        * [ GoalUpdated ](../configuration/packages/bt-plugins/conditions/GoalUpdated.html)\n        * [ GloballyUpdatedGoal ](../configuration/packages/bt-plugins/conditions/GloballyUpdatedGoal.html)\n        * [ InitialPoseReceived ](../configuration/packages/bt-plugins/conditions/InitialPoseReceived.html)\n        * [ IsStuck ](../configuration/packages/bt-plugins/conditions/IsStuck.html)\n        * [ TimeExpired ](../configuration/packages/bt-plugins/conditions/TimeExpired.html)\n        * [ IsBatteryLow ](../configuration/packages/bt-plugins/conditions/IsBatteryLow.html)\n        * [ IsPathValid ](../configuration/packages/bt-plugins/conditions/IsPathValid.html)\n        * [ PathExpiringTimer ](../configuration/packages/bt-plugins/conditions/PathExpiringTimer.html)\n        * [ AreErrorCodesPresent ](../configuration/packages/bt-plugins/conditions/AreErrorCodesPresent.html)\n        * [ WouldAControllerRecoveryHelp ](../configuration/packages/bt-plugins/conditions/WouldAControllerRecoveryHelp.html)\n        * [ WouldAPlannerRecoveryHelp ](../configuration/packages/bt-plugins/conditions/WouldAPlannerRecoveryHelp.html)\n        * [ WouldASmootherRecoveryHelp ](../configuration/packages/bt-plugins/conditions/WouldASmootherRecoveryHelp.html)\n        * [ IsBatteryCharging ](../configuration/packages/bt-plugins/conditions/IsBatteryCharging.html)\n      * [ Control Plugins ](../configuration/packages/configuring-bt-xml.html#control-plugins)\n        * [ PipelineSequence ](../configuration/packages/bt-plugins/controls/PipelineSequence.html)\n        * [ RoundRobin ](../configuration/packages/bt-plugins/controls/RoundRobin.html)\n        * [ RecoveryNode ](../configuration/packages/bt-plugins/controls/RecoveryNode.html)\n      * [ Decorator Plugins ](../configuration/packages/configuring-bt-xml.html#decorator-plugins)\n        * [ RateController ](../configuration/packages/bt-plugins/decorators/RateController.html)\n        * [ DistanceController ](../configuration/packages/bt-plugins/decorators/DistanceController.html)\n        * [ SpeedController ](../configuration/packages/bt-plugins/decorators/SpeedController.html)\n        * [ GoalUpdater ](../configuration/packages/bt-plugins/decorators/GoalUpdater.html)\n        * [ PathLongerOnApproach ](../configuration/packages/bt-plugins/decorators/PathLongerOnApproach.html)\n        * [ SingleTrigger ](../configuration/packages/bt-plugins/decorators/SingleTrigger.html)\n      * [ Example ](../configuration/packages/configuring-bt-xml.html#example)\n    * [ Costmap 2D ](../configuration/packages/configuring-costmaps.html)\n      * [ Costmap2D ROS Parameters ](../configuration/packages/configuring-costmaps.html#costmap2d-ros-parameters)\n      * [ Default Plugins ](../configuration/packages/configuring-costmaps.html#default-plugins)\n      * [ Plugin Parameters ](../configuration/packages/configuring-costmaps.html#plugin-parameters)\n        * [ Static Layer Parameters ](../configuration/packages/costmap-plugins/static.html)\n        * [ Inflation Layer Parameters ](../configuration/packages/costmap-plugins/inflation.html)\n        * [ Obstacle Layer Parameters ](../configuration/packages/costmap-plugins/obstacle.html)\n        * [ Voxel Layer Parameters ](../configuration/packages/costmap-plugins/voxel.html)\n        * [ Range Sensor Parameters ](../configuration/packages/costmap-plugins/range.html)\n        * [ Denoise Layer Parameters ](../configuration/packages/costmap-plugins/denoise.html)\n      * [ Costmap Filters Parameters ](../configuration/packages/configuring-costmaps.html#costmap-filters-parameters)\n        * [ Keepout Filter Parameters ](../configuration/packages/costmap-plugins/keepout_filter.html)\n        * [ Speed Filter Parameters ](../configuration/packages/costmap-plugins/speed_filter.html)\n        * [ Binary Filter Parameters ](../configuration/packages/costmap-plugins/binary_filter.html)\n      * [ Example ](../configuration/packages/configuring-costmaps.html#example)\n    * [ Lifecycle Manager ](../configuration/packages/configuring-lifecycle.html)\n      * [ Parameters ](../configuration/packages/configuring-lifecycle.html#parameters)\n      * [ Example ](../configuration/packages/configuring-lifecycle.html#example)\n    * [ Planner Server ](../configuration/packages/configuring-planner-server.html)\n      * [ Parameters ](../configuration/packages/configuring-planner-server.html#parameters)\n      * [ Default Plugins ](../configuration/packages/configuring-planner-server.html#default-plugins)\n      * [ Example ](../configuration/packages/configuring-planner-server.html#example)\n    * [ NavFn Planner ](../configuration/packages/configuring-navfn.html)\n      * [ Parameters ](../configuration/packages/configuring-navfn.html#parameters)\n      * [ Example ](../configuration/packages/configuring-navfn.html#example)\n    * [ Smac Planner ](../configuration/packages/configuring-smac-planner.html)\n      * [ Provided Plugins ](../configuration/packages/configuring-smac-planner.html#provided-plugins)\n        * [ Smac 2D Planner ](../configuration/packages/smac/configuring-smac-2d.html)\n        * [ Smac Hybrid-A* Planner ](../configuration/packages/smac/configuring-smac-hybrid.html)\n        * [ Smac State Lattice Planner ](../configuration/packages/smac/configuring-smac-lattice.html)\n      * [ Description ](../configuration/packages/configuring-smac-planner.html#description)\n    * [ Theta Star Planner ](../configuration/packages/configuring-thetastar.html)\n      * [ Parameters ](../configuration/packages/configuring-thetastar.html#parameters)\n      * [ Example ](../configuration/packages/configuring-thetastar.html#example)\n    * [ Controller Server ](../configuration/packages/configuring-controller-server.html)\n      * [ Parameters ](../configuration/packages/configuring-controller-server.html#parameters)\n      * [ Provided Plugins ](../configuration/packages/configuring-controller-server.html#provided-plugins)\n        * [ SimpleProgressChecker ](../configuration/packages/nav2_controller-plugins/simple_progress_checker.html)\n        * [ PoseProgressChecker ](../configuration/packages/nav2_controller-plugins/pose_progress_checker.html)\n        * [ SimpleGoalChecker ](../configuration/packages/nav2_controller-plugins/simple_goal_checker.html)\n        * [ StoppedGoalChecker ](../configuration/packages/nav2_controller-plugins/stopped_goal_checker.html)\n      * [ Default Plugins ](../configuration/packages/configuring-controller-server.html#default-plugins)\n      * [ Example ](../configuration/packages/configuring-controller-server.html#example)\n    * [ DWB Controller ](../configuration/packages/configuring-dwb-controller.html)\n      * [ Controller ](../configuration/packages/configuring-dwb-controller.html#controller)\n        * [ DWB Controller ](../configuration/packages/dwb-params/controller.html)\n        * [ XYTheta Iterator ](../configuration/packages/dwb-params/iterator.html)\n        * [ Kinematic Parameters ](../configuration/packages/dwb-params/kinematic.html)\n        * [ Publisher ](../configuration/packages/dwb-params/visualization.html)\n      * [ Plugins ](../configuration/packages/configuring-dwb-controller.html#plugins)\n        * [ LimitedAccelGenerator ](../configuration/packages/dwb-plugins/limited_accel_generator.html)\n        * [ StandardTrajectoryGenerator ](../configuration/packages/dwb-plugins/standard_traj_generator.html)\n      * [ Trajectory Critics ](../configuration/packages/configuring-dwb-controller.html#trajectory-critics)\n        * [ BaseObstacleCritic ](../configuration/packages/trajectory_critics/base_obstacle.html)\n        * [ GoalAlignCritic ](../configuration/packages/trajectory_critics/goal_align.html)\n        * [ GoalDistCritic ](../configuration/packages/trajectory_critics/goal_dist.html)\n        * [ ObstacleFootprintCritic ](../configuration/packages/trajectory_critics/obstacle_footprint.html)\n        * [ OscillationCritic ](../configuration/packages/trajectory_critics/oscillation.html)\n        * [ PathAlignCritic ](../configuration/packages/trajectory_critics/path_align.html)\n        * [ PathDistCritic ](../configuration/packages/trajectory_critics/path_dist.html)\n        * [ PreferForwardCritic ](../configuration/packages/trajectory_critics/prefer_forward.html)\n        * [ RotateToGoalCritic ](../configuration/packages/trajectory_critics/rotate_to_goal.html)\n        * [ TwirlingCritic ](../configuration/packages/trajectory_critics/twirling.html)\n      * [ Example ](../configuration/packages/configuring-dwb-controller.html#example)\n    * [ Regulated Pure Pursuit ](../configuration/packages/configuring-regulated-pp.html)\n      * [ Regulated Pure Pursuit Parameters ](../configuration/packages/configuring-regulated-pp.html#regulated-pure-pursuit-parameters)\n      * [ Example ](../configuration/packages/configuring-regulated-pp.html#example)\n    * [ Model Predictive Path Integral Controller ](../configuration/packages/configuring-mppic.html)\n      * [ MPPI Parameters ](../configuration/packages/configuring-mppic.html#mppi-parameters)\n        * [ Trajectory Visualization ](../configuration/packages/configuring-mppic.html#trajectory-visualization)\n        * [ Path Handler ](../configuration/packages/configuring-mppic.html#path-handler)\n        * [ Ackermann Motion Model ](../configuration/packages/configuring-mppic.html#ackermann-motion-model)\n        * [ Constraint Critic ](../configuration/packages/configuring-mppic.html#constraint-critic)\n        * [ Goal Angle Critic ](../configuration/packages/configuring-mppic.html#goal-angle-critic)\n        * [ Goal Critic ](../configuration/packages/configuring-mppic.html#goal-critic)\n        * [ Obstacles Critic ](../configuration/packages/configuring-mppic.html#obstacles-critic)\n        * [ Path Align Critic ](../configuration/packages/configuring-mppic.html#path-align-critic)\n        * [ Path Angle Critic ](../configuration/packages/configuring-mppic.html#path-angle-critic)\n        * [ Path Follow Critic ](../configuration/packages/configuring-mppic.html#path-follow-critic)\n        * [ Prefer Forward Critic ](../configuration/packages/configuring-mppic.html#prefer-forward-critic)\n        * [ Twirling Critic ](../configuration/packages/configuring-mppic.html#twirling-critic)\n      * [ Example ](../configuration/packages/configuring-mppic.html#example)\n      * [ Notes to Users ](../configuration/packages/configuring-mppic.html#notes-to-users)\n        * [ General Words of Wisdom ](../configuration/packages/configuring-mppic.html#general-words-of-wisdom)\n        * [ Prediction Horizon, Costmap Sizing, and Offsets ](../configuration/packages/configuring-mppic.html#prediction-horizon-costmap-sizing-and-offsets)\n        * [ Obstacle, Inflation Layer, and Path Following ](../configuration/packages/configuring-mppic.html#obstacle-inflation-layer-and-path-following)\n    * [ Rotation Shim Controller ](../configuration/packages/configuring-rotation-shim-controller.html)\n      * [ Rotation Shim Controller Parameters ](../configuration/packages/configuring-rotation-shim-controller.html#rotation-shim-controller-parameters)\n      * [ Example ](../configuration/packages/configuring-rotation-shim-controller.html#example)\n    * [ Map Server / Saver ](../configuration/packages/configuring-map-server.html)\n      * [ Map Saver Parameters ](../configuration/packages/configuring-map-server.html#map-saver-parameters)\n      * [ Map Server Parameters ](../configuration/packages/configuring-map-server.html#map-server-parameters)\n      * [ Costmap Filter Info Server Parameters ](../configuration/packages/configuring-map-server.html#costmap-filter-info-server-parameters)\n      * [ Example ](../configuration/packages/configuring-map-server.html#example)\n    * [ AMCL ](../configuration/packages/configuring-amcl.html)\n      * [ Parameters ](../configuration/packages/configuring-amcl.html#parameters)\n      * [ Example ](../configuration/packages/configuring-amcl.html#example)\n    * [ Behavior Server ](../configuration/packages/configuring-behavior-server.html)\n      * [ Behavior Server Parameters ](../configuration/packages/configuring-behavior-server.html#behavior-server-parameters)\n      * [ Default Plugins ](../configuration/packages/configuring-behavior-server.html#default-plugins)\n      * [ Spin Behavior Parameters ](../configuration/packages/configuring-behavior-server.html#spin-behavior-parameters)\n      * [ BackUp Behavior Parameters ](../configuration/packages/configuring-behavior-server.html#backup-behavior-parameters)\n      * [ DriveOnHeading Behavior Parameters ](../configuration/packages/configuring-behavior-server.html#driveonheading-behavior-parameters)\n      * [ AssistedTeleop Behavior Parameters ](../configuration/packages/configuring-behavior-server.html#assistedteleop-behavior-parameters)\n      * [ Example ](../configuration/packages/configuring-behavior-server.html#example)\n    * [ Smoother Server ](../configuration/packages/configuring-smoother-server.html)\n      * [ Smoother Server Parameters ](../configuration/packages/configuring-smoother-server.html#smoother-server-parameters)\n      * [ Example ](../configuration/packages/configuring-smoother-server.html#example)\n    * [ Simple Smoother ](../configuration/packages/configuring-simple-smoother.html)\n      * [ Simple Smoother Parameters ](../configuration/packages/configuring-simple-smoother.html#simple-smoother-parameters)\n      * [ Example ](../configuration/packages/configuring-simple-smoother.html#example)\n    * [ Savitzky-Golay Smoother ](../configuration/packages/configuring-savitzky-golay-smoother.html)\n      * [ Savitzky-Golay Smoother Parameters ](../configuration/packages/configuring-savitzky-golay-smoother.html#savitzky-golay-smoother-parameters)\n      * [ Example ](../configuration/packages/configuring-savitzky-golay-smoother.html#example)\n    * [ Constrained smoother ](../configuration/packages/configuring-constrained-smoother.html)\n      * [ Smoother Server Parameters ](../configuration/packages/configuring-constrained-smoother.html#smoother-server-parameters)\n      * [ Example ](../configuration/packages/configuring-constrained-smoother.html#example)\n    * [ Velocity Smoother ](../configuration/packages/configuring-velocity-smoother.html)\n      * [ Velocity Smoother Parameters ](../configuration/packages/configuring-velocity-smoother.html#velocity-smoother-parameters)\n      * [ Example ](../configuration/packages/configuring-velocity-smoother.html#example)\n    * [ Collision Monitor ](../configuration/packages/configuring-collision-monitor.html)\n      * [ Features ](../configuration/packages/configuring-collision-monitor.html#features)\n      * [ Parameters ](../configuration/packages/configuring-collision-monitor.html#parameters)\n        * [ Polygons parameters ](../configuration/packages/configuring-collision-monitor.html#polygons-parameters)\n        * [ Observation sources parameters ](../configuration/packages/configuring-collision-monitor.html#observation-sources-parameters)\n      * [ Example ](../configuration/packages/configuring-collision-monitor.html#example)\n    * [ Waypoint Follower ](../configuration/packages/configuring-waypoint-follower.html)\n      * [ Parameters ](../configuration/packages/configuring-waypoint-follower.html#parameters)\n      * [ Provided Plugins ](../configuration/packages/configuring-waypoint-follower.html#provided-plugins)\n        * [ WaitAtWaypoint ](../configuration/packages/nav2_waypoint_follower-plugins/wait_at_waypoint.html)\n        * [ PhotoAtWaypoint ](../configuration/packages/nav2_waypoint_follower-plugins/photo_at_waypoint.html)\n        * [ InputAtWaypoint ](../configuration/packages/nav2_waypoint_follower-plugins/input_at_waypoint.html)\n      * [ Default Plugin ](../configuration/packages/configuring-waypoint-follower.html#default-plugin)\n      * [ Example ](../configuration/packages/configuring-waypoint-follower.html#example)\n  * [ Tuning Guide ](../tuning/index.html)\n    * [ Inflation Potential Fields ](../tuning/index.html#inflation-potential-fields)\n    * [ Robot Footprint vs Radius ](../tuning/index.html#robot-footprint-vs-radius)\n    * [ Rotate in Place Behavior ](../tuning/index.html#rotate-in-place-behavior)\n    * [ Planner Plugin Selection ](../tuning/index.html#planner-plugin-selection)\n    * [ Controller Plugin Selection ](../tuning/index.html#controller-plugin-selection)\n    * [ Caching Obstacle Heuristic in Smac Planners ](../tuning/index.html#caching-obstacle-heuristic-in-smac-planners)\n    * [ Nav2 Launch Options ](../tuning/index.html#nav2-launch-options)\n    * [ Other Pages We\u2019d Love To Offer ](../tuning/index.html#other-pages-we-d-love-to-offer)\n  * [ Nav2 Behavior Trees ](../behavior_trees/index.html)\n    * [ Introduction To Nav2 Specific Nodes ](../behavior_trees/overview/nav2_specific_nodes.html)\n      * [ Action Nodes ](../behavior_trees/overview/nav2_specific_nodes.html#action-nodes)\n      * [ Condition Nodes ](../behavior_trees/overview/nav2_specific_nodes.html#condition-nodes)\n      * [ Decorator Nodes ](../behavior_trees/overview/nav2_specific_nodes.html#decorator-nodes)\n      * [ Control: PipelineSequence ](../behavior_trees/overview/nav2_specific_nodes.html#control-pipelinesequence)\n      * [ Control: Recovery ](../behavior_trees/overview/nav2_specific_nodes.html#control-recovery)\n      * [ Control: RoundRobin ](../behavior_trees/overview/nav2_specific_nodes.html#control-roundrobin)\n    * [ Detailed Behavior Tree Walkthrough ](../behavior_trees/overview/detailed_behavior_tree_walkthrough.html)\n      * [ Overview ](../behavior_trees/overview/detailed_behavior_tree_walkthrough.html#overview)\n      * [ Prerequisites ](../behavior_trees/overview/detailed_behavior_tree_walkthrough.html#prerequisites)\n      * [ Navigate To Pose With Replanning and Recovery ](../behavior_trees/overview/detailed_behavior_tree_walkthrough.html#navigate-to-pose-with-replanning-and-recovery)\n      * [ Navigation Subtree ](../behavior_trees/overview/detailed_behavior_tree_walkthrough.html#navigation-subtree)\n      * [ Recovery Subtree ](../behavior_trees/overview/detailed_behavior_tree_walkthrough.html#recovery-subtree)\n    * [ Navigate To Pose ](../behavior_trees/trees/nav_to_pose_recovery.html)\n    * [ Navigate Through Poses ](../behavior_trees/trees/nav_through_poses_recovery.html)\n    * [ Navigate To Pose and Pause Near Goal-Obstacle ](../behavior_trees/trees/nav_to_pose_and_pause_near_goal_obstacle.html)\n    * [ Navigate To Pose With Consistent Replanning And If Path Becomes Invalid ](../behavior_trees/trees/nav_to_pose_with_consistent_replanning_and_if_path_becomes_invalid.html)\n    * [ Follow Dynamic Point ](../behavior_trees/trees/follow_point.html)\n    * [ Odometry Calibration ](../behavior_trees/trees/odometry_calibration.html)\n  * [ Navigation Plugins ](../plugins/index.html)\n    * [ Behavior-Tree Navigators ](../plugins/index.html#behavior-tree-navigators)\n    * [ Costmap Layers ](../plugins/index.html#costmap-layers)\n    * [ Costmap Filters ](../plugins/index.html#costmap-filters)\n    * [ Controllers ](../plugins/index.html#controllers)\n    * [ Planners ](../plugins/index.html#planners)\n    * [ Smoothers ](../plugins/index.html#smoothers)\n    * [ Behaviors ](../plugins/index.html#behaviors)\n    * [ Waypoint Task Executors ](../plugins/index.html#waypoint-task-executors)\n    * [ Goal Checkers ](../plugins/index.html#goal-checkers)\n    * [ Progress Checkers ](../plugins/index.html#progress-checkers)\n    * [ Behavior Tree Nodes ](../plugins/index.html#behavior-tree-nodes)\n  * [ Migration Guides ](../migration/index.html)\n    * [ Dashing to Eloquent ](../migration/Dashing.html)\n      * [ New Packages ](../migration/Dashing.html#new-packages)\n      * [ New Plugins ](../migration/Dashing.html#new-plugins)\n      * [ Navigation2 Architectural Changes ](../migration/Dashing.html#navigation2-architectural-changes)\n    * [ Eloquent to Foxy ](../migration/Eloquent.html)\n      * [ General ](../migration/Eloquent.html#general)\n      * [ Server Updates ](../migration/Eloquent.html#server-updates)\n      * [ New Plugins ](../migration/Eloquent.html#new-plugins)\n      * [ Map Server Re-Work ](../migration/Eloquent.html#map-server-re-work)\n      * [ New Particle Filter Messages ](../migration/Eloquent.html#new-particle-filter-messages)\n      * [ Selection of Behavior Tree in each navigation action ](../migration/Eloquent.html#selection-of-behavior-tree-in-each-navigation-action)\n      * [ FollowPoint Capability ](../migration/Eloquent.html#followpoint-capability)\n      * [ New Costmap Layer ](../migration/Eloquent.html#new-costmap-layer)\n    * [ Foxy to Galactic ](../migration/Foxy.html)\n      * [ NavigateToPose Action Feedback updates ](../migration/Foxy.html#navigatetopose-action-feedback-updates)\n      * [ NavigateToPose BT-node Interface Changes ](../migration/Foxy.html#navigatetopose-bt-node-interface-changes)\n      * [ NavigateThroughPoses and ComputePathThroughPoses Actions Added ](../migration/Foxy.html#navigatethroughposes-and-computepaththroughposes-actions-added)\n      * [ ComputePathToPose BT-node Interface Changes ](../migration/Foxy.html#computepathtopose-bt-node-interface-changes)\n      * [ ComputePathToPose Action Interface Changes ](../migration/Foxy.html#computepathtopose-action-interface-changes)\n      * [ BackUp BT-node Interface Changes ](../migration/Foxy.html#backup-bt-node-interface-changes)\n      * [ BackUp Recovery Interface Changes ](../migration/Foxy.html#backup-recovery-interface-changes)\n      * [ Nav2 Controllers and Goal Checker Plugin Interface Changes ](../migration/Foxy.html#nav2-controllers-and-goal-checker-plugin-interface-changes)\n      * [ FollowPath goal_checker_id attribute ](../migration/Foxy.html#followpath-goal-checker-id-attribute)\n      * [ Groot Support ](../migration/Foxy.html#groot-support)\n      * [ New Plugins ](../migration/Foxy.html#new-plugins)\n      * [ Costmap Filters ](../migration/Foxy.html#costmap-filters)\n      * [ SmacPlanner ](../migration/Foxy.html#smacplanner)\n      * [ ThetaStarPlanner ](../migration/Foxy.html#thetastarplanner)\n      * [ RegulatedPurePursuitController ](../migration/Foxy.html#regulatedpurepursuitcontroller)\n      * [ Costmap2D ` current_  ` Usage ](../migration/Foxy.html#costmap2d-current-usage)\n      * [ Standard time units in parameters ](../migration/Foxy.html#standard-time-units-in-parameters)\n      * [ Ray Tracing Parameters ](../migration/Foxy.html#ray-tracing-parameters)\n      * [ Obstacle Marking Parameters ](../migration/Foxy.html#obstacle-marking-parameters)\n      * [ Recovery Action Changes ](../migration/Foxy.html#recovery-action-changes)\n      * [ Default Behavior Tree Changes ](../migration/Foxy.html#default-behavior-tree-changes)\n      * [ NavFn Planner Parameters ](../migration/Foxy.html#navfn-planner-parameters)\n      * [ New ClearCostmapExceptRegion and ClearCostmapAroundRobot BT-nodes ](../migration/Foxy.html#new-clearcostmapexceptregion-and-clearcostmaparoundrobot-bt-nodes)\n      * [ New Behavior Tree Nodes ](../migration/Foxy.html#new-behavior-tree-nodes)\n      * [ sensor_msgs/PointCloud to sensor_msgs/PointCloud2 Change ](../migration/Foxy.html#sensor-msgs-pointcloud-to-sensor-msgs-pointcloud2-change)\n      * [ ControllerServer New Parameter failure_tolerance ](../migration/Foxy.html#controllerserver-new-parameter-failure-tolerance)\n      * [ Removed BT XML Launch Configurations ](../migration/Foxy.html#removed-bt-xml-launch-configurations)\n      * [ Nav2 RViz Panel Action Feedback Information ](../migration/Foxy.html#nav2-rviz-panel-action-feedback-information)\n    * [ Galactic to Humble ](../migration/Galactic.html)\n      * [ Major improvements to Smac Planners ](../migration/Galactic.html#major-improvements-to-smac-planners)\n      * [ Simple (Python) Commander ](../migration/Galactic.html#simple-python-commander)\n      * [ Reduce Nodes and Executors ](../migration/Galactic.html#reduce-nodes-and-executors)\n      * [ API Change for nav2_core ](../migration/Galactic.html#api-change-for-nav2-core)\n      * [ Extending the BtServiceNode to process Service-Results ](../migration/Galactic.html#extending-the-btservicenode-to-process-service-results)\n      * [ Including new Rotation Shim Controller Plugin ](../migration/Galactic.html#including-new-rotation-shim-controller-plugin)\n      * [ Spawning the robot in Gazebo ](../migration/Galactic.html#spawning-the-robot-in-gazebo)\n      * [ Recovery Behavior Timeout ](../migration/Galactic.html#recovery-behavior-timeout)\n      * [ New parameter ` use_final_approach_orientation  ` for the 3 2D planners ](../migration/Galactic.html#new-parameter-use-final-approach-orientation-for-the-3-2d-planners)\n      * [ SmacPlanner2D and Theta*: fix goal orientation being ignored ](../migration/Galactic.html#smacplanner2d-and-theta-fix-goal-orientation-being-ignored)\n      * [ SmacPlanner2D, NavFn and Theta*: fix small path corner cases ](../migration/Galactic.html#smacplanner2d-navfn-and-theta-fix-small-path-corner-cases)\n      * [ Change and fix behavior of dynamic parameter change detection ](../migration/Galactic.html#change-and-fix-behavior-of-dynamic-parameter-change-detection)\n      * [ Dynamic Parameters ](../migration/Galactic.html#dynamic-parameters)\n      * [ BT Action Nodes Exception Changes ](../migration/Galactic.html#bt-action-nodes-exception-changes)\n      * [ BT Navigator Groot Multiple Navigators ](../migration/Galactic.html#bt-navigator-groot-multiple-navigators)\n      * [ Removed Kinematic Limiting in RPP ](../migration/Galactic.html#removed-kinematic-limiting-in-rpp)\n      * [ Added Smoother Task Server ](../migration/Galactic.html#added-smoother-task-server)\n      * [ Removed Use Approach Velocity Scaling Param in RPP ](../migration/Galactic.html#removed-use-approach-velocity-scaling-param-in-rpp)\n      * [ Refactored AMCL motion models as plugins ](../migration/Galactic.html#refactored-amcl-motion-models-as-plugins)\n      * [ Dropping Support for Live Groot Monitoring of Nav2 ](../migration/Galactic.html#dropping-support-for-live-groot-monitoring-of-nav2)\n      * [ Replanning Only if Path is Invalid ](../migration/Galactic.html#replanning-only-if-path-is-invalid)\n      * [ Fix CostmapLayer clearArea invert param logic ](../migration/Galactic.html#fix-costmaplayer-cleararea-invert-param-logic)\n      * [ Dynamic Composition ](../migration/Galactic.html#dynamic-composition)\n      * [ BT Cancel Node ](../migration/Galactic.html#bt-cancel-node)\n      * [ BT PathLongerOnApproach Node ](../migration/Galactic.html#bt-pathlongeronapproach-node)\n      * [ BT TruncatePathLocal Node ](../migration/Galactic.html#bt-truncatepathlocal-node)\n      * [ Constrained Smoother ](../migration/Galactic.html#constrained-smoother)\n      * [ Replanning at a Constant Rate and if the Path is Invalid ](../migration/Galactic.html#replanning-at-a-constant-rate-and-if-the-path-is-invalid)\n      * [ Euclidean Distance 2D ](../migration/Galactic.html#euclidean-distance-2d)\n      * [ Recovery To Behavior ](../migration/Galactic.html#recovery-to-behavior)\n      * [ Respawn Support in Launch and Lifecycle Manager ](../migration/Galactic.html#respawn-support-in-launch-and-lifecycle-manager)\n      * [ New Nav2 Velocity Smoother ](../migration/Galactic.html#new-nav2-velocity-smoother)\n      * [ Goal Checker API Changed ](../migration/Galactic.html#goal-checker-api-changed)\n      * [ Added Assisted Teleop ](../migration/Galactic.html#added-assisted-teleop)\n    * [ Humble to Iron ](../migration/Humble.html)\n      * [ New Behavior-Tree Navigator Plugins ](../migration/Humble.html#new-behavior-tree-navigator-plugins)\n      * [ Added Collision Monitor ](../migration/Humble.html#added-collision-monitor)\n      * [ Removed use_sim_time from yaml ](../migration/Humble.html#removed-use-sim-time-from-yaml)\n      * [ Run-time Speed up of Smac Planner ](../migration/Humble.html#run-time-speed-up-of-smac-planner)\n      * [ Recursive Refinement of Smac and Simple Smoothers ](../migration/Humble.html#recursive-refinement-of-smac-and-simple-smoothers)\n      * [ Simple Commander Python API ](../migration/Humble.html#simple-commander-python-api)\n      * [ Smac Planner Start Pose Included in Path ](../migration/Humble.html#smac-planner-start-pose-included-in-path)\n      * [ Parameterizable Collision Checking in RPP ](../migration/Humble.html#parameterizable-collision-checking-in-rpp)\n      * [ Expanded Planner Benchmark Tests ](../migration/Humble.html#expanded-planner-benchmark-tests)\n      * [ Smac Planner Path Tolerances ](../migration/Humble.html#smac-planner-path-tolerances)\n      * [ costmap_2d_node default constructor ](../migration/Humble.html#costmap-2d-node-default-constructor)\n      * [ Feedback for Navigation Failures ](../migration/Humble.html#feedback-for-navigation-failures)\n      * [ Costmap Filters ](../migration/Humble.html#costmap-filters)\n      * [ Savitzky-Golay Smoother ](../migration/Humble.html#savitzky-golay-smoother)\n      * [ Changes to Map yaml file path for map_server node in Launch ](../migration/Humble.html#changes-to-map-yaml-file-path-for-map-server-node-in-launch)\n      * [ SmootherSelector BT Node ](../migration/Humble.html#smootherselector-bt-node)\n      * [ Publish Costmap Layers ](../migration/Humble.html#publish-costmap-layers)\n      * [ Give Behavior Server Access to Both Costmaps ](../migration/Humble.html#give-behavior-server-access-to-both-costmaps)\n      * [ New Model Predictive Path Integral Controller ](../migration/Humble.html#new-model-predictive-path-integral-controller)\n      * [ Behavior Tree Uses Error Codes ](../migration/Humble.html#behavior-tree-uses-error-codes)\n      * [ Load, Save and Loop Waypoints from the Nav2 Panel in RViz ](../migration/Humble.html#load-save-and-loop-waypoints-from-the-nav2-panel-in-rviz)\n      * [ DWB Forward vs Reverse Pruning ](../migration/Humble.html#dwb-forward-vs-reverse-pruning)\n      * [ More stable regulation on curves for long lookahead distances ](../migration/Humble.html#more-stable-regulation-on-curves-for-long-lookahead-distances)\n      * [ Publish Collision Monitor State ](../migration/Humble.html#publish-collision-monitor-state)\n      * [ Renamed ROS-parameter in Collision Monitor ](../migration/Humble.html#renamed-ros-parameter-in-collision-monitor)\n      * [ New safety behavior model \u201climit\u201d in Collision Monitor ](../migration/Humble.html#new-safety-behavior-model-limit-in-collision-monitor)\n      * [ Velocity smoother applies deceleration when timeout ](../migration/Humble.html#velocity-smoother-applies-deceleration-when-timeout)\n      * [ PoseProgressChecker plugin ](../migration/Humble.html#poseprogresschecker-plugin)\n      * [ Allow multiple goal checkers and change parameter progress_checker_plugin(s) name and type ](../migration/Humble.html#allow-multiple-goal-checkers-and-change-parameter-progress-checker-plugin-s-name-and-type)\n      * [ IsBatteryChargingCondition BT Node ](../migration/Humble.html#isbatterychargingcondition-bt-node)\n      * [ Behavior Server Error Codes ](../migration/Humble.html#behavior-server-error-codes)\n      * [ New Denoise Costmap Layer Plugin ](../migration/Humble.html#new-denoise-costmap-layer-plugin)\n      * [ SmacPlannerHybrid viz_expansions parameter ](../migration/Humble.html#smacplannerhybrid-viz-expansions-parameter)\n  * [ Simple Commander API ](../commander_api/index.html)\n    * [ Overview ](../commander_api/index.html#overview)\n    * [ Commander API ](../commander_api/index.html#id1)\n    * [ Costmap API ](../commander_api/index.html#costmap-api)\n    * [ Footprint Collision Checker API ](../commander_api/index.html#footprint-collision-checker-api)\n    * [ Examples and Demos ](../commander_api/index.html#examples-and-demos)\n  * [ Roadmaps ](../roadmap/roadmap.html)\n    * [ Iron Roadmap ](../roadmap/roadmap.html#iron-roadmap)\n    * [ Humble Roadmap ](../roadmap/roadmap.html#humble-roadmap)\n  * [ About and Contact ](../about/index.html)\n    * [ Related Projects ](../about/related_projects.html)\n    * [ ROS to ROS 2 Navigation ](../about/ros1_comparison.html)\n    * [ About ](../about/index.html#id1)\n    * [ Contact ](../about/index.html#contact)\n  * [ Robots Using ](../about/robots.html)\n\n__ [ Navigation 2 ](../index.html)\n\n[ Edit ](https://github.com/ros-planning/navigation.ros.org)\n\n  * [ ](../index.html)\n  * Navigation Concepts \n  * \n\n* * *\n\n#  Navigation Concepts  \u00b6\n\nThis page is to help familiarize new robotists to the concepts of mobile robot\nnavigation, in particular, with the concepts required to appreciating and\nworking with this project.\n\n##  ROS 2  \u00b6\n\nROS 2 is the core middleware used for Nav2. If you are unfamilar with this,\nplease visit [ the ROS 2 documentation ](https://docs.ros.org/en/rolling/)\nbefore continuing.\n\n###  Action Server  \u00b6\n\nJust as in ROS, action servers are a common way to control long running tasks\nlike navigation. This stack makes more extensive use of actions, and in some\ncases, without an easy topic interface. It is more important to understand\naction servers as a developer in ROS 2. Some simple CLI examples can be found\nin the [ ROS 2 documentation\n](https://docs.ros.org/en/rolling/Tutorials/Understanding-ROS2-Actions.html) .\n\nAction servers are similar to a canonical service server. A client will\nrequest some task to be completed, except, this task may take a long time. An\nexample would be moving the shovel up from a bulldozer or ask a robot to\ntravel 10 meters to the right.\n\nIn this situation, action servers and clients allow us to call a long-running\ntask in another process or thread and return a future to its result. It is\npermissible at this point to block until the action is complete, however, you\nmay want to occasionally check if the action is complete and continue to\nprocess work in the client thread. Since it is long-running, action servers\nwill also provide feedback to their clients. This feedback can be anything and\nis defined in the ROS ` .action  ` along with the request and result types. In\nthe bulldozer example, a request may be an angle, a feedback may be the angle\nremaining to be moved, and the result is a success or fail boolean with the\nend angle. In the navigation example, a request may be a position, a feedback\nmay be the time its been navigating for and the distance to the goal, and the\nresult a boolean for success.\n\nFeedback and results can be gathered synchronously by registering callbacks\nwith the action client. They may also be gathered by asychronously requesting\ninformation from the shared future objects. Both require spinning the client\nnode to process callback groups.\n\nAction servers are used in this stack to communicate with the highest level BT\nnavigator through a ` NavigateToPose  ` action message. They are also used for\nthe BT navigator to communicate with the subsequent smaller action servers to\ncompute plans, control efforts, and recoveries. Each will have their own\nunique ` .action  ` type in ` nav2_msgs  ` for interacting with the servers.\n\n###  Lifecycle Nodes and Bond  \u00b6\n\nLifecycle (or Managed, more correctly) nodes are unique to ROS 2. More\ninformation can be [ found here\n](https://design.ros2.org/articles/node_lifecycle.html) . They are nodes that\ncontain state machine transitions for bringup and teardown of ROS 2 servers.\nThis helps in determinstic behavior of ROS systems in startup and shutdown. It\nalso helps users structure their programs in reasonable ways for commercial\nuses and debugging.\n\nWhen a node is started, it is in the unconfigured state, only processing the\nnode\u2019s constructor which should **not** contain any ROS networking setup or\nparameter reading. By the launch system, or the supplied lifecycle manager,\nthe nodes need to be transitioned to inactive by configuring. After, it is\npossible to activate the node by transitioning through the activating stage.\n\nThis state will allow the node to process information and be fully setup to\nrun. The configuration stage, triggering the ` on_configure()  ` method, will\nsetup all parameters, ROS networking interfaces, and for safety systems, all\ndynamically allocated memory. The activation stage, triggering the `\non_activate()  ` method, will active the ROS networking interfaces and set any\nstates in the program to start processing information.\n\nTo shutdown, we transition into deactivating, cleaning up, shutting down and\nend in the finalized state. The networking interfaces are deactivated and stop\nprocessing, deallocate memory, exit cleanly, in those stages, respectively.\n\nThe lifecycle node framework is used extensively through out this project and\nall servers utilize it. It is best convention for all ROS systems to use\nlifecycle nodes if it is possible.\n\nWithin Nav2, we use a wrapper of LifecycleNodes, ` nav2_util  LifecycleNode  `\n. This wrapper wraps much of the complexities of LifecycleNodes for typical\napplications. It also includes a ` bond  ` connection for the lifecycle\nmanager to ensure that after a server transitions up, it also remains active.\nIf a server crashes, it lets the lifecycle manager know and transition down\nthe system to prevent a critical failure. See [ Eloquent to Foxy\n](../migration/Eloquent.html#eloquent-migration) for details.\n\n##  Behavior Trees  \u00b6\n\nBehavior trees (BT) are becoming increasingly common in complex robotics\ntasks. They are a tree structure of tasks to be completed. It creates a more\nscalable and human-understandable framework for defining multi-step or many\nstate applications. This is opposed to a finite state machine (FSM) which may\nhave dozens of states and hundreds of transitions. An example would be a\nsoccer playing robot. Embedding the logic of soccer game play into a FSM would\nbe challenging and error prone with many possible states and rules.\nAdditionally, modeling choices like to shoot at the goal from the left, right,\nor center, is particularly unclear. With a BT, basic primitives like \u201ckick\u201d\n\u201cwalk\u201d \u201cgo to ball\u201d can be created and reused for many behaviors. More\ninformation can be found [ in this book ](https://arxiv.org/abs/1709.00084) .\nI **strongly** recommend reading chapters 1-3 to get a good understanding of\nthe nomenclature and workflow. It should only take about 30 minutes.\n\nBehavior Trees provide a formal structure for navigation logic which can be\nboth used to create complex systems but also be verifiable and validated as\nprovenly correct using advanced tools. Having the application logic\ncentralized in the behavior tree and with independent task servers (which only\ncommunicate data over the tree) allows for formal analysis.\n\nFor this project, we use [ BehaviorTree CPP V3\n](https://www.behaviortree.dev/) as the behavior tree library. We create node\nplugins which can be constructed into a tree, inside the ` BT  Navigator  ` .\nThe node plugins are loaded into the BT and when the XML file of the tree is\nparsed, the registered names are associated. At this point, we can march\nthrough the behavior tree to navigate.\n\nOne reason this library is used is its ability to load subtrees. This means\nthat the Nav2 behavior tree can be loaded into another higher-level BT to use\nthis project as node plugin. An example would be in soccer play, using the\nNav2 behavior tree as the \u201cgo to ball\u201d node with a ball detection as part of a\nlarger task. Additionally, we supply a ` NavigateToPoseAction  ` plugin (among\nothers) for BT so the Nav2 stack can be called from a client application\nthrough the usual action interface.\n\nOther systems could be used to design complex autonomous behavior, namely\nHierarchical FSMs (HFSM). Behavior Trees were selected due to popularity\nacross the robotics and related industries and by largely user demand.\nHowever, due to the independent task server nature of Nav2, it is not\ndifficult to offer a ` nav2_hfsm_navigator  ` package in the future, pending\ninterest and contribution.\n\n##  Navigation Servers  \u00b6\n\nPlanners and controllers are at the heart of a navigation task. Recoveries are\nused to get the robot out of a bad situation or attempt to deal with various\nforms of issues to make the system fault-tolerant. Smoothers can be used for\nadditional quality improvements of the planned path. In this section, the\ngeneral concepts around them and their uses in this project are analyzed.\n\n###  Planner, Controller, Smoother and Recovery Servers  \u00b6\n\nFour of the action servers in this project are the planner, behavior, smoother\nand controller servers.\n\nThese action servers are used to host a map of algorithm plugins to complete\nvarious tasks. They also host the environmental representation used by the\nalgorithm plugins to compute their outputs.\n\nThe planner, smoother and controller servers will be configured at runtime\nwith the names (aliases) and types of algorithms to use. These types are the\npluginlib names that have been registered and the names are the aliases for\nthe task. An example would be the DWB controller used with name ` FollowPath\n` , as it follows a reference path. In this case, then all parameters for DWB\nwould be placed in that namespace, e.g. ` FollowPath.<param> ` .\n\nThese three servers then expose an action interface corresponding to its task.\nWhen the behavior tree ticks the corresponding BT node, it will call the\naction server to process its task. The action server callback inside the\nserver will call the chosen algorithm by its name (e.g. ` FollowPath  ` ) that\nmaps to a specific algorithm. This allows a user to abstract the algorithm\nused in the behavior tree to classes of algorithms. For instance, you can have\n` N  ` plugin controllers to follow paths, dock with charger, avoid dynamic\nobstacles, or interface with a tool. Having all of these plugins in the same\nserver allows the user to make use of a single environmental representation\nobject, which is costly to duplicate.\n\nFor the behavior server, each of the behaviors also contains their own name,\nhowever, each plugin will also expose its own special action server. This is\ndone because of the wide variety of behavior actions that may be created\ncannot have a single simple interface to share. The behavior server also\ncontains a costmap subscriber to the local costmap, receiving real-time\nupdates from the controller server, to compute its tasks. We do this to avoid\nhaving multiple instances of the local costmap which are computationally\nexpensive to duplicate.\n\nAlternatively, since the BT nodes are trivial plugins calling an action, new\nBT nodes can be created to call other action servers with other action types.\nIt is advisable to use the provided servers if possible at all times. If, due\nto the plugin or action interfaces, a new server is needed, that can be\nsustained with the framework. The new server should use the new type and\nplugin interface, similar to the provided servers. A new BT node plugin will\nneed to be created to call the new action server \u2013 however no forking or\nmodification is required in the Nav2 repo itself by making extensive use of\nservers and plugins.\n\nIf you find that you require a new interface to the pluginlib definition or\naction type, please file a ticket and see if we can rectify that in the same\ninterfaces.\n\n###  Planners  \u00b6\n\nThe task of a planner is to compute a path to complete some objective\nfunction. The path can also be known as a route, depending on the nomenclature\nand algorithm selected. Two canonical examples are computing a plan to a goal\n(e.g. from current position to a goal) or complete coverage (e.g. plan to\ncover all free space). The planner will have access to a global environmental\nrepresentation and sensor data buffered into it. Planners can be written to:\n\n  * Compute shortest path \n\n  * Compute complete coverage path \n\n  * Compute paths along sparse or predefined routes \n\nThe general task in Nav2 for the planner is to compute a valid, and\npotentially optimal, path from the current pose to a goal pose. However, many\nclasses of plans and routes exist which are supported.\n\n###  Controllers  \u00b6\n\nControllers, also known as local planners in ROS 1, are the way we follow the\nglobally computed path or complete a local task. The controller will have\naccess to a local environment representation to attempt to compute feasible\ncontrol efforts for the base to follow. Many controller will project the robot\nforward in space and compute a locally feasible path at each update iteration.\nControllers can be written to:\n\n  * Follow a path \n\n  * Dock with a charging station using detectors in the odometric frame \n\n  * Board an elevator \n\n  * Interface with a tool \n\nThe general task in Nav2 for a controller is to compute a valid control effort\nto follow the global plan. However, many classes of controllers and local\nplanners exist. It is the goal of this project that all controller algorithms\ncan be plugins in this server for common research and industrial tasks.\n\n###  Behaviors  \u00b6\n\nRecovery behaviors are a mainstay of fault-tolerant systems. The goal of\nrecoveries are to deal with unknown or failure conditions of the system and\nautonomously handle them. Examples may include faults in the perception system\nresulting in the environmental representation being full of fake obstacles.\nThe clear costmap recovery would then be triggered to allow the robot to move.\n\nAnother example would be if the robot was stuck due to dynamic obstacles or\npoor control. Backing up or spinning in place, if permissible, allow the robot\nto move from a poor location into free space it may navigate successfully.\n\nFinally, in the case of a total failure, a recovery may be implemented to call\nan operators attention for help. This can be done with email, SMS, Slack,\nMatrix, etc.\n\nIt is important to note that the behavior server can hold any behavior to\nshare access to expensive resources like costmaps or TF buffers, not just\nrecovery behaviors. Each may have their own API.\n\n###  Smoothers  \u00b6\n\nAs criteria for optimality of the path searched by a planner are usually\nreduced compared to reality, additional path refinement is often beneficial.\nSmoothers have been introduced for this purpose, typically responsible for\nreducing path raggedness and smoothing abrupt rotations, but also for\nincreasing distance from obstacles and high-cost areas as the smoothers have\naccess to a global environmental representation.\n\nUse of a separate smoother over one that is included as a part of a planner is\nadvantageous when combining different planners with different smoothers or\nwhen a specific control over smoothing is required, e.g. smoothing ony a\nspecific part of the path.\n\nThe general task in Nav2 for a smoother is to receive a path and return its\nimproved version. However, different input paths, criteria of the improvements\nand methods of acquiring them exist, creating space for multitude of smoothers\nthat can be registered in this server.\n\n###  Waypoint Following  \u00b6\n\nWaypoint following is a basic feature of a navigation system. It tells our\nsystem how to use navigation to get to multiple destinations.\n\nThe ` nav2_waypoint_follower  ` contains a waypoint following program with a\nplugin interface for specific task executors. This is useful if you need to go\nto a given location and complete a specific task like take a picture, pick up\na box, or wait for user input. It is a nice demo application for how to use\nNav2 in a sample application.\n\nHowever, it could be used for more than just a sample application. There are 2\nschools of thoughts for fleet managers / dispatchers. \\- Dumb robot; smart\ncentralized dispatcher \\- Smart robot; dumb centralized dispatcher\n\nIn the first, the ` nav2_waypoint_follower  ` is fully sufficient to create a\nproduction-grade on-robot solution. Since the autonomy system / dispatcher is\ntaking into account things like the robot\u2019s pose, battery level, current task,\nand more when assigning tasks, the application on the robot just needs to\nworry about the task at hand and not the other complexities of the system\ncomplete the requested task. In this situation, you should think of a request\nto the waypoint follower as 1 unit of work (e.g. 1 pick in a warehouse, 1\nsecurity patrole loop, 1 aisle, etc) to do a task and then return to the\ndispatcher for the next task or request to recharge. In this school of\nthought, the waypoint following application is just one step above navigation\nand below the system autonomy application.\n\nIn the second, the ` nav2_waypoint_follower  ` is a nice sample application /\nproof of concept, but you really need your waypoint following / autonomy\nsystem on the robot to carry more weight in making a robust solution. In this\ncase, you should use the ` nav2_behavior_tree  ` package to create a custom\napplication-level behavior tree using navigation to complete the task. This\ncan include subtrees like checking for the charge status mid-task for\nreturning to dock or handling more than 1 unit of work in a more complex task.\nSoon, there will be a ` nav2_bt_waypoint_follower  ` (name subject to\nadjustment) that will allow you to create this application more easily. In\nthis school of thought, the waypoint following application is more closely\ntied to the system autonomy, or in many cases, is the system autonomy.\n\nNeither is better than the other, it highly depends on the tasks your robot(s)\nare completing, in what type of environment, and with what cloud resources\navailable. Often this distinction is very clear for a given business case.\n\n##  State Estimation  \u00b6\n\nWithin the navigation project, there are 2 major transformations that need to\nbe provided, according to community standards. The ` map  ` to ` odom  `\ntransform is provided by a positioning system (localization, mapping, SLAM)\nand ` odom  ` to ` base_link  ` by an odometry system.\n\nNote\n\nThere is **no** requirement on using a LIDAR on your robot to use the\nnavigation system. There is no requirement to use lidar-based collision\navoidance, localization, or slam. However, we do provide instructions and\nsupport tried and true implementations of these things using lidars. You can\nbe equally as successful using a vision or depth based positioning system and\nusing other sensors for collision avoidance. The only requirement is that you\nfollow the standards below with your choice of implementation.\n\n###  Standards  \u00b6\n\n[ REP 105 ](https://www.ros.org/reps/rep-0105.html) defines the frames and\nconventions required for navigation and the larger ROS ecosystem. These\nconventions should be followed at all times to make use of the rich\npositioning, odometry, and slam projects available in the community.\n\nIn a nutshell, REP-105 says that you must, at minimum, build a TF tree that\ncontains a full ` map  ` -> ` odom  ` -> ` base_link  ` -> ` [sensor  frames]\n` for your robot. TF2 are the time-variant transformation library in ROS 2 we\nuse to represent and obtain time synchronized transformations. It is the job\nof the global positioning system (GPS, SLAM, Motion Capture) to, at minimum,\nprovide the ` map  ` -> ` odom  ` transformation. It is then the role of the\nodometry system to provide the ` odom  ` -> ` base_link  ` transformation. The\nremainder of the transformations relative to ` base_link  ` should be static\nand defined in your [ URDF ](http://wiki.ros.org/urdf) .\n\n###  Global Positioning: Localization and SLAM  \u00b6\n\nIt is the job of the global positioning system (GPS, SLAM, Motion Capture) to,\nat minimum, provide the ` map  ` -> ` odom  ` transformation. We provide `\namcl  ` which is an Adaptive Monte-Carlo Localization technique based on a\nparticle filter for localization of a static map. We also provide SLAM Toolbox\nas the default SLAM algorithm for use to position and generate a static map.\n\nThese methods may also produce other output including position topics, maps,\nor other metadata, but they must provide that transformation to be valid.\nMultiple positioning methods can be fused together using robot localization,\ndiscussed more below.\n\n###  Odometry  \u00b6\n\nIt is the role of the odometry system to provide the ` odom  ` -> ` base_link\n` transformation. Odometry can come from many sources including LIDAR, RADAR,\nwheel encoders, VIO, and IMUs. The goal of the odometry is to provide a smooth\nand continuous local frame based on robot motion. The global positioning\nsystem will update the transformation relative to the global frame to account\nfor the odometric drift.\n\n[ Robot Localization ](https://github.com/cra-ros-pkg/robot_localization/) is\ntypically used for this fusion. It will take in ` N  ` sensors of various\ntypes and provide a continuous and smooth odometry to TF and to a topic. A\ntypical mobile robotics setup may have odometry from wheel encoders, IMUs, and\nvision fused in this manor.\n\nThe smooth output can be used then for dead-reckoning for precise motion and\nupdating the position of the robot accurately between global position updates.\n\n##  Environmental Representation  \u00b6\n\nThe environmental representation is the way the robot perceives its\nenvironment. It also acts as the central localization for various algorithms\nand data sources to combine their information into a single space. This space\nis then used by the controllers, planners, and recoveries to compute their\ntasks safely and efficiently.\n\n###  Costmaps and Layers  \u00b6\n\nThe current environmental representation is a costmap. A costmap is a regular\n2D grid of cells containing a cost from unknown, free, occupied, or inflated\ncost. This costmap is then searched to compute a global plan or sampled to\ncompute local control efforts.\n\nVarious costmap layers are implemented as pluginlib plugins to buffer\ninformation into the costmap. This includes information from LIDAR, RADAR,\nsonar, depth, images, etc. It may be wise to process sensor data before\ninputting it into the costmap layer, but that is up to the developer.\n\nCostmap layers can be created to detect and track obstacles in the scene for\ncollision avoidance using camera or depth sensors. Additionally, layers can be\ncreated to algorithmically change the underlying costmap based on some rule or\nheuristic. Finally, they may be used to buffer live data into the 2D or 3D\nworld for binary obstacle marking.\n\n###  Costmap Filters  \u00b6\n\nImagine, you\u2019re annotating a map file (or any image file) in order to have a\nspecific action occur based on the location in the annotated map. Examples of\nmarking/annotating might be keep out zones to avoid planning inside, or have\npixels belong to maximum speeds in marked areas. This annotated map is called\n\u201cfilter mask\u201d. Just like a mask overlaid on a surface, it can or cannot be\nsame size, pose and scale as a main map. The main goal of filter mask - is to\nprovide an ability of marking areas on maps with some additional features or\nbehavioral changes.\n\nCostmap filters - is costmap layer based approach of applying spatial-\ndependent behavioral changes annotated in filter masks, into Nav2 stack.\nCostmap filters are implemented as costmap plugins. These plugins are called\n\u201cfilters\u201d as they are filtering a costmap by spatial annotations marked on\nfilter masks. In order to make a filtered costmap and change robot\u2019s behavior\nin annotated areas, filter plugin reads the data came from filter mask. This\ndata is being linearly transformed into feature map in a filter space. Having\nthis transformed feature map along with a map/costmap, any sensors data and\ncurrent robot coordinates filters can update underlying costmap and change\nbehavior of the robot depending on where it is. For example, the following\nfunctionality could be made by using of costmap filters:\n\n  * Keep-out/safety zones where robots will never enter. \n\n  * Speed restriction areas. Maximum speed of robots going inside those areas will be limited. \n\n  * Preferred lanes for robots moving in industrial environments and warehouses. \n\n###  Other Forms  \u00b6\n\nVarious other forms of environmental representations exist. These include:\n\n  * gradient maps, which are similar to costmaps but represent surface gradients to check traversibility over \n\n  * 3D costmaps, which represent the space in 3D, but then also requires 3D planning and collision checking \n\n  * Mesh maps, which are similar to gradient maps but with surface meshes at many angles \n\n  * \u201cVector space\u201d, taking in sensor information and using machine learning to detect individual items and locations to track rather than buffering discrete points. \n\n##  Nav2 Academic Overview  \u00b6\n\n#\n\n* * *\n\n\u00a9 Copyright 2020.\n\n"
  },
  {
    "id": "planner_selector/configuringbtxmlhtml.txt",
    "content": "[ Nav2 ![Logo](../../_static/nav2_logo_powered.png) ](../../index.html)\n\nlatest\n\n  * [ Getting Started ](../../getting_started/index.html)\n    * [ Installation ](../../getting_started/index.html#installation)\n    * [ Running the Example ](../../getting_started/index.html#running-the-example)\n    * [ Navigating ](../../getting_started/index.html#navigating)\n  * [ Development Guides ](../../development_guides/index.html)\n    * [ Build and Install ](../../development_guides/build_docs/index.html)\n      * [ Install ](../../development_guides/build_docs/index.html#install)\n      * [ Build ](../../development_guides/build_docs/index.html#build)\n        * [ Released Distribution Binaries ](../../development_guides/build_docs/index.html#released-distribution-binaries)\n        * [ Rolling Development Source ](../../development_guides/build_docs/index.html#rolling-development-source)\n        * [ Docker Container Images ](../../development_guides/build_docs/index.html#docker-container-images)\n      * [ Generate Doxygen ](../../development_guides/build_docs/index.html#generate-doxygen)\n      * [ Help ](../../development_guides/build_docs/index.html#help)\n        * [ Build Troubleshooting Guide ](../../development_guides/build_docs/build_troubleshooting_guide.html)\n    * [ Dev Containers ](../../development_guides/devcontainer_docs/index.html)\n      * [ Dev Container Guide ](../../development_guides/devcontainer_docs/devcontainer_guide.html)\n        * [ Creating Dev Containers ](../../development_guides/devcontainer_docs/devcontainer_guide.html#creating-dev-containers)\n        * [ Using Dev Containers ](../../development_guides/devcontainer_docs/devcontainer_guide.html#using-dev-containers)\n      * [ What, Why, How? ](../../development_guides/devcontainer_docs/index.html#what-why-how)\n        * [ What is a Dev Container? ](../../development_guides/devcontainer_docs/index.html#what-is-a-dev-container)\n        * [ Why use a Dev Container? ](../../development_guides/devcontainer_docs/index.html#why-use-a-dev-container)\n        * [ How do Dev Containers work? ](../../development_guides/devcontainer_docs/index.html#how-do-dev-containers-work)\n      * [ Prerequisites ](../../development_guides/devcontainer_docs/index.html#prerequisites)\n      * [ Getting started ](../../development_guides/devcontainer_docs/index.html#getting-started)\n      * [ Security ](../../development_guides/devcontainer_docs/index.html#security)\n    * [ Getting Involved ](../../development_guides/involvement_docs/index.html)\n      * [ Getting Involved ](../../development_guides/involvement_docs/index.html#id1)\n      * [ Process ](../../development_guides/involvement_docs/index.html#process)\n      * [ Licensing ](../../development_guides/involvement_docs/index.html#licensing)\n      * [ Developer Certification of Origin (DCO) ](../../development_guides/involvement_docs/index.html#developer-certification-of-origin-dco)\n  * [ Navigation Concepts ](../../concepts/index.html)\n    * [ ROS 2 ](../../concepts/index.html#ros-2)\n      * [ Action Server ](../../concepts/index.html#action-server)\n      * [ Lifecycle Nodes and Bond ](../../concepts/index.html#lifecycle-nodes-and-bond)\n    * [ Behavior Trees ](../../concepts/index.html#behavior-trees)\n    * [ Navigation Servers ](../../concepts/index.html#navigation-servers)\n      * [ Planner, Controller, Smoother and Recovery Servers ](../../concepts/index.html#planner-controller-smoother-and-recovery-servers)\n      * [ Planners ](../../concepts/index.html#planners)\n      * [ Controllers ](../../concepts/index.html#controllers)\n      * [ Behaviors ](../../concepts/index.html#behaviors)\n      * [ Smoothers ](../../concepts/index.html#smoothers)\n      * [ Robot Footprints ](../../concepts/index.html#robot-footprints)\n      * [ Waypoint Following ](../../concepts/index.html#waypoint-following)\n    * [ State Estimation ](../../concepts/index.html#state-estimation)\n      * [ Standards ](../../concepts/index.html#standards)\n      * [ Global Positioning: Localization and SLAM ](../../concepts/index.html#global-positioning-localization-and-slam)\n      * [ Odometry ](../../concepts/index.html#odometry)\n    * [ Environmental Representation ](../../concepts/index.html#environmental-representation)\n      * [ Costmaps and Layers ](../../concepts/index.html#costmaps-and-layers)\n      * [ Costmap Filters ](../../concepts/index.html#costmap-filters)\n      * [ Other Forms ](../../concepts/index.html#other-forms)\n    * [ Nav2 Academic Overview ](../../concepts/index.html#nav2-academic-overview)\n  * [ First-Time Robot Setup Guide ](../../setup_guides/index.html)\n    * [ Setting Up Transformations ](../../setup_guides/transformation/setup_transforms.html)\n      * [ Transforms Introduction ](../../setup_guides/transformation/setup_transforms.html#transforms-introduction)\n      * [ Static Transform Publisher Demo ](../../setup_guides/transformation/setup_transforms.html#static-transform-publisher-demo)\n      * [ Transforms in Navigation2 ](../../setup_guides/transformation/setup_transforms.html#transforms-in-navigation2)\n      * [ Conclusion ](../../setup_guides/transformation/setup_transforms.html#conclusion)\n    * [ Setting Up The URDF ](../../setup_guides/urdf/setup_urdf.html)\n      * [ URDF and the Robot State Publisher ](../../setup_guides/urdf/setup_urdf.html#urdf-and-the-robot-state-publisher)\n      * [ Setting Up the Environment ](../../setup_guides/urdf/setup_urdf.html#setting-up-the-environment)\n      * [ Writing the URDF ](../../setup_guides/urdf/setup_urdf.html#writing-the-urdf)\n      * [ Build and Launch ](../../setup_guides/urdf/setup_urdf.html#build-and-launch)\n      * [ Visualization using RVIZ ](../../setup_guides/urdf/setup_urdf.html#visualization-using-rviz)\n      * [ Adding Physical Properties ](../../setup_guides/urdf/setup_urdf.html#adding-physical-properties)\n      * [ Conclusion ](../../setup_guides/urdf/setup_urdf.html#conclusion)\n    * [ Setting Up Odometry ](../../setup_guides/odom/setup_odom.html)\n      * [ Odometry Introduction ](../../setup_guides/odom/setup_odom.html#odometry-introduction)\n      * [ Setting Up Odometry on your Robot ](../../setup_guides/odom/setup_odom.html#setting-up-odometry-on-your-robot)\n      * [ Simulating an Odometry System using Gazebo ](../../setup_guides/odom/setup_odom.html#simulating-an-odometry-system-using-gazebo)\n        * [ Setup and Prerequisites ](../../setup_guides/odom/setup_odom.html#setup-and-prerequisites)\n        * [ Adding Gazebo Plugins to a URDF ](../../setup_guides/odom/setup_odom.html#adding-gazebo-plugins-to-a-urdf)\n        * [ Launch and Build Files ](../../setup_guides/odom/setup_odom.html#launch-and-build-files)\n        * [ Build, Run and Verification ](../../setup_guides/odom/setup_odom.html#build-run-and-verification)\n      * [ Robot Localization Demo ](../../setup_guides/odom/setup_odom.html#robot-localization-demo)\n        * [ Configuring Robot Localization ](../../setup_guides/odom/setup_odom.html#configuring-robot-localization)\n        * [ Launch and Build Files ](../../setup_guides/odom/setup_odom.html#id3)\n        * [ Build, Run and Verification ](../../setup_guides/odom/setup_odom.html#id4)\n      * [ Conclusion ](../../setup_guides/odom/setup_odom.html#conclusion)\n    * [ Setting Up Sensors ](../../setup_guides/sensors/setup_sensors.html)\n      * [ Sensor Introduction ](../../setup_guides/sensors/setup_sensors.html#sensor-introduction)\n        * [ Common Sensor Messages ](../../setup_guides/sensors/setup_sensors.html#common-sensor-messages)\n      * [ Simulating Sensors using Gazebo ](../../setup_guides/sensors/setup_sensors.html#simulating-sensors-using-gazebo)\n        * [ Adding Gazebo Plugins to a URDF ](../../setup_guides/sensors/setup_sensors.html#adding-gazebo-plugins-to-a-urdf)\n        * [ Launch and Build Files ](../../setup_guides/sensors/setup_sensors.html#launch-and-build-files)\n        * [ Build, Run and Verification ](../../setup_guides/sensors/setup_sensors.html#build-run-and-verification)\n      * [ Mapping and Localization ](../../setup_guides/sensors/setup_sensors.html#mapping-and-localization)\n      * [ Costmap 2D ](../../setup_guides/sensors/setup_sensors.html#costmap-2d)\n        * [ Configuring nav2_costmap_2d ](../../setup_guides/sensors/setup_sensors.html#configuring-nav2-costmap-2d)\n        * [ Build, Run and Verification ](../../setup_guides/sensors/setup_sensors.html#id2)\n      * [ Conclusion ](../../setup_guides/sensors/setup_sensors.html#conclusion)\n    * [ Setting Up the Robot\u2019s Footprint ](../../setup_guides/footprint/setup_footprint.html)\n      * [ Footprint Introduction ](../../setup_guides/footprint/setup_footprint.html#footprint-introduction)\n      * [ Configuring the Robot\u2019s Footprint ](../../setup_guides/footprint/setup_footprint.html#configuring-the-robot-s-footprint)\n      * [ Build, Run and Verification ](../../setup_guides/footprint/setup_footprint.html#build-run-and-verification)\n      * [ Visualizing Footprint in RViz ](../../setup_guides/footprint/setup_footprint.html#visualizing-footprint-in-rviz)\n      * [ Conclusion ](../../setup_guides/footprint/setup_footprint.html#conclusion)\n    * [ Setting Up Navigation Plugins ](../../setup_guides/algorithm/select_algorithm.html)\n      * [ Planner and Controller Servers ](../../setup_guides/algorithm/select_algorithm.html#planner-and-controller-servers)\n      * [ Selecting the Algorithm Plugins ](../../setup_guides/algorithm/select_algorithm.html#selecting-the-algorithm-plugins)\n        * [ Planner Server ](../../setup_guides/algorithm/select_algorithm.html#planner-server)\n        * [ Controller Server ](../../setup_guides/algorithm/select_algorithm.html#controller-server)\n      * [ Conclusion ](../../setup_guides/algorithm/select_algorithm.html#conclusion)\n  * [ Robots Using ](../../about/robots.html)\n  * [ General Tutorials ](../../tutorials/index.html)\n    * [ Navigating with a Physical Turtlebot 3 ](../../tutorials/docs/navigation2_on_real_turtlebot3.html)\n      * [ Overview ](../../tutorials/docs/navigation2_on_real_turtlebot3.html#overview)\n      * [ Requirements ](../../tutorials/docs/navigation2_on_real_turtlebot3.html#requirements)\n      * [ Tutorial Steps ](../../tutorials/docs/navigation2_on_real_turtlebot3.html#tutorial-steps)\n        * [ 0- Setup Your Enviroment Variables ](../../tutorials/docs/navigation2_on_real_turtlebot3.html#setup-your-enviroment-variables)\n        * [ 1- Launch Turtlebot 3 ](../../tutorials/docs/navigation2_on_real_turtlebot3.html#launch-turtlebot-3)\n        * [ 2- Launch Nav2 ](../../tutorials/docs/navigation2_on_real_turtlebot3.html#launch-nav2)\n        * [ 3- Launch RVIZ ](../../tutorials/docs/navigation2_on_real_turtlebot3.html#launch-rviz)\n        * [ 4- Initialize the Location of Turtlebot 3 ](../../tutorials/docs/navigation2_on_real_turtlebot3.html#initialize-the-location-of-turtlebot-3)\n        * [ 5- Send a Goal Pose ](../../tutorials/docs/navigation2_on_real_turtlebot3.html#send-a-goal-pose)\n    * [ (SLAM) Navigating While Mapping ](../../tutorials/docs/navigation2_with_slam.html)\n      * [ Overview ](../../tutorials/docs/navigation2_with_slam.html#overview)\n      * [ Requirements ](../../tutorials/docs/navigation2_with_slam.html#requirements)\n      * [ Tutorial Steps ](../../tutorials/docs/navigation2_with_slam.html#tutorial-steps)\n        * [ 0- Launch Robot Interfaces ](../../tutorials/docs/navigation2_with_slam.html#launch-robot-interfaces)\n        * [ 1- Launch Navigation2 ](../../tutorials/docs/navigation2_with_slam.html#launch-navigation2)\n        * [ 2- Launch SLAM ](../../tutorials/docs/navigation2_with_slam.html#launch-slam)\n        * [ 3- Working with SLAM ](../../tutorials/docs/navigation2_with_slam.html#working-with-slam)\n        * [ 4- Getting Started Simplification ](../../tutorials/docs/navigation2_with_slam.html#getting-started-simplification)\n    * [ (STVL) Using an External Costmap Plugin ](../../tutorials/docs/navigation2_with_stvl.html)\n      * [ Overview ](../../tutorials/docs/navigation2_with_stvl.html#overview)\n      * [ Costmap2D and STVL ](../../tutorials/docs/navigation2_with_stvl.html#costmap2d-and-stvl)\n      * [ Tutorial Steps ](../../tutorials/docs/navigation2_with_stvl.html#tutorial-steps)\n        * [ 0- Setup ](../../tutorials/docs/navigation2_with_stvl.html#setup)\n        * [ 1- Install STVL ](../../tutorials/docs/navigation2_with_stvl.html#install-stvl)\n        * [ 1- Modify Navigation2 Parameter ](../../tutorials/docs/navigation2_with_stvl.html#modify-navigation2-parameter)\n        * [ 2- Launch Navigation2 ](../../tutorials/docs/navigation2_with_stvl.html#launch-navigation2)\n        * [ 3- RVIZ ](../../tutorials/docs/navigation2_with_stvl.html#rviz)\n    * [ Navigating Using GPS Localization ](../../tutorials/docs/navigation2_with_gps.html)\n      * [ Overview ](../../tutorials/docs/navigation2_with_gps.html#overview)\n      * [ Requirements ](../../tutorials/docs/navigation2_with_gps.html#requirements)\n      * [ GPS Localization Overview ](../../tutorials/docs/navigation2_with_gps.html#gps-localization-overview)\n      * [ Tutorial Steps ](../../tutorials/docs/navigation2_with_gps.html#tutorial-steps)\n        * [ 0- Setup Gazebo World ](../../tutorials/docs/navigation2_with_gps.html#setup-gazebo-world)\n        * [ 1- Setup GPS Localization system ](../../tutorials/docs/navigation2_with_gps.html#setup-gps-localization-system)\n        * [ 2- Setup Navigation system ](../../tutorials/docs/navigation2_with_gps.html#setup-navigation-system)\n        * [ 3- Interactive GPS Waypoint Follower ](../../tutorials/docs/navigation2_with_gps.html#interactive-gps-waypoint-follower)\n        * [ 4- Logged GPS Waypoint Follower & Waypoint Logging ](../../tutorials/docs/navigation2_with_gps.html#logged-gps-waypoint-follower-waypoint-logging)\n      * [ Conclusion ](../../tutorials/docs/navigation2_with_gps.html#conclusion)\n    * [ Groot - Interacting with Behavior Trees ](../../tutorials/docs/using_groot.html)\n      * [ Overview ](../../tutorials/docs/using_groot.html#overview)\n      * [ Visualize Behavior Trees ](../../tutorials/docs/using_groot.html#visualize-behavior-trees)\n      * [ Edit Behavior Trees ](../../tutorials/docs/using_groot.html#edit-behavior-trees)\n      * [ Adding A Custom Node ](../../tutorials/docs/using_groot.html#adding-a-custom-node)\n    * [ Using VIO to Augment Robot Odometry ](../../tutorials/docs/integrating_vio.html)\n      * [ Overview ](../../tutorials/docs/integrating_vio.html#overview)\n      * [ Setting Up the ZED X Camera ](../../tutorials/docs/integrating_vio.html#setting-up-the-zed-x-camera)\n      * [ Setting Up ZED ROS ](../../tutorials/docs/integrating_vio.html#setting-up-zed-ros)\n      * [ Fusing VIO Into Local State Estimate ](../../tutorials/docs/integrating_vio.html#fusing-vio-into-local-state-estimate)\n        * [ Fusing VSLAM Into Global State Estimate ](../../tutorials/docs/integrating_vio.html#fusing-vslam-into-global-state-estimate)\n      * [ Testing it Out! ](../../tutorials/docs/integrating_vio.html#testing-it-out)\n    * [ Dynamic Object Following ](../../tutorials/docs/navigation2_dynamic_point_following.html)\n      * [ Overview ](../../tutorials/docs/navigation2_dynamic_point_following.html#overview)\n      * [ Tutorial Steps ](../../tutorials/docs/navigation2_dynamic_point_following.html#tutorial-steps)\n        * [ 0- Create the Behavior Tree ](../../tutorials/docs/navigation2_dynamic_point_following.html#create-the-behavior-tree)\n        * [ 1- Setup Rviz clicked point ](../../tutorials/docs/navigation2_dynamic_point_following.html#setup-rviz-clicked-point)\n        * [ 2- Run Dynamic Object Following in Nav2 Simulation ](../../tutorials/docs/navigation2_dynamic_point_following.html#run-dynamic-object-following-in-nav2-simulation)\n    * [ Navigating with Keepout Zones ](../../tutorials/docs/navigation2_with_keepout_filter.html)\n      * [ Overview ](../../tutorials/docs/navigation2_with_keepout_filter.html#overview)\n      * [ Requirements ](../../tutorials/docs/navigation2_with_keepout_filter.html#requirements)\n      * [ Tutorial Steps ](../../tutorials/docs/navigation2_with_keepout_filter.html#tutorial-steps)\n        * [ 1\\. Prepare filter mask ](../../tutorials/docs/navigation2_with_keepout_filter.html#prepare-filter-mask)\n        * [ 2\\. Configure Costmap Filter Info Publisher Server ](../../tutorials/docs/navigation2_with_keepout_filter.html#configure-costmap-filter-info-publisher-server)\n        * [ 3\\. Enable Keepout Filter ](../../tutorials/docs/navigation2_with_keepout_filter.html#enable-keepout-filter)\n        * [ 4\\. Run Nav2 stack ](../../tutorials/docs/navigation2_with_keepout_filter.html#run-nav2-stack)\n    * [ Navigating with Speed Limits ](../../tutorials/docs/navigation2_with_speed_filter.html)\n      * [ Overview ](../../tutorials/docs/navigation2_with_speed_filter.html#overview)\n      * [ Requirements ](../../tutorials/docs/navigation2_with_speed_filter.html#requirements)\n      * [ Tutorial Steps ](../../tutorials/docs/navigation2_with_speed_filter.html#tutorial-steps)\n        * [ 1\\. Prepare filter mask ](../../tutorials/docs/navigation2_with_speed_filter.html#prepare-filter-mask)\n        * [ 2\\. Configure Costmap Filter Info Publisher Server ](../../tutorials/docs/navigation2_with_speed_filter.html#configure-costmap-filter-info-publisher-server)\n        * [ 3\\. Enable Speed Filter ](../../tutorials/docs/navigation2_with_speed_filter.html#enable-speed-filter)\n        * [ 4\\. Run Nav2 stack ](../../tutorials/docs/navigation2_with_speed_filter.html#run-nav2-stack)\n    * [ Using Rotation Shim Controller ](../../tutorials/docs/using_shim_controller.html)\n      * [ Overview ](../../tutorials/docs/using_shim_controller.html#overview)\n      * [ What is the Rotation Shim Controller? ](../../tutorials/docs/using_shim_controller.html#what-is-the-rotation-shim-controller)\n      * [ Configuring Rotation Shim Controller ](../../tutorials/docs/using_shim_controller.html#configuring-rotation-shim-controller)\n      * [ Configuring Primary Controller ](../../tutorials/docs/using_shim_controller.html#configuring-primary-controller)\n      * [ Demo Execution ](../../tutorials/docs/using_shim_controller.html#demo-execution)\n    * [ Adding a Smoother to a BT ](../../tutorials/docs/adding_smoother.html)\n      * [ Overview ](../../tutorials/docs/adding_smoother.html#overview)\n      * [ Requirements ](../../tutorials/docs/adding_smoother.html#requirements)\n      * [ Tutorial Steps ](../../tutorials/docs/adding_smoother.html#tutorial-steps)\n        * [ 0- Familiarization with the Smoother BT Node ](../../tutorials/docs/adding_smoother.html#familiarization-with-the-smoother-bt-node)\n        * [ 1- Specifying a Smoother Plugin ](../../tutorials/docs/adding_smoother.html#specifying-a-smoother-plugin)\n        * [ 2- Modifying your BT XML ](../../tutorials/docs/adding_smoother.html#modifying-your-bt-xml)\n    * [ Using Collision Monitor ](../../tutorials/docs/using_collision_monitor.html)\n      * [ Overview ](../../tutorials/docs/using_collision_monitor.html#overview)\n      * [ Requirements ](../../tutorials/docs/using_collision_monitor.html#requirements)\n      * [ Configuring Collision Monitor ](../../tutorials/docs/using_collision_monitor.html#configuring-collision-monitor)\n      * [ Configuring Collision Monitor with VelocityPolygon ](../../tutorials/docs/using_collision_monitor.html#configuring-collision-monitor-with-velocitypolygon)\n      * [ Preparing Nav2 stack ](../../tutorials/docs/using_collision_monitor.html#preparing-nav2-stack)\n      * [ Demo Execution ](../../tutorials/docs/using_collision_monitor.html#demo-execution)\n    * [ Adding a New Nav2 Task Server ](../../tutorials/docs/adding_a_nav2_task_server.html)\n      * [ Lifecycle Nodes ](../../tutorials/docs/adding_a_nav2_task_server.html#lifecycle-nodes)\n      * [ Composition ](../../tutorials/docs/adding_a_nav2_task_server.html#composition)\n      * [ Error codes ](../../tutorials/docs/adding_a_nav2_task_server.html#error-codes)\n      * [ Conclusion ](../../tutorials/docs/adding_a_nav2_task_server.html#conclusion)\n    * [ Filtering of Noise-Induced Obstacles ](../../tutorials/docs/filtering_of_noise-induced_obstacles.html)\n      * [ Overview ](../../tutorials/docs/filtering_of_noise-induced_obstacles.html#overview)\n      * [ Requirements ](../../tutorials/docs/filtering_of_noise-induced_obstacles.html#requirements)\n      * [ Tutorial Steps ](../../tutorials/docs/filtering_of_noise-induced_obstacles.html#tutorial-steps)\n        * [ 1\\. Enable Denoise Layer ](../../tutorials/docs/filtering_of_noise-induced_obstacles.html#enable-denoise-layer)\n        * [ 2\\. Run Nav2 stack ](../../tutorials/docs/filtering_of_noise-induced_obstacles.html#run-nav2-stack)\n      * [ How it works ](../../tutorials/docs/filtering_of_noise-induced_obstacles.html#how-it-works)\n    * [ Camera Calibration ](../../tutorials/docs/camera_calibration.html)\n      * [ Overview ](../../tutorials/docs/camera_calibration.html#overview)\n      * [ Requirements ](../../tutorials/docs/camera_calibration.html#requirements)\n      * [ Tutorial Steps ](../../tutorials/docs/camera_calibration.html#tutorial-steps)\n    * [ Get Backtrace in ROS 2 / Nav2 ](../../tutorials/docs/get_backtrace.html)\n      * [ Overview ](../../tutorials/docs/get_backtrace.html#overview)\n      * [ Preliminaries ](../../tutorials/docs/get_backtrace.html#preliminaries)\n      * [ From a Node ](../../tutorials/docs/get_backtrace.html#from-a-node)\n      * [ From a Launch File ](../../tutorials/docs/get_backtrace.html#from-a-launch-file)\n      * [ From Large Project ](../../tutorials/docs/get_backtrace.html#from-large-project)\n      * [ From Nav2 Bringup ](../../tutorials/docs/get_backtrace.html#from-nav2-bringup)\n      * [ Automatic backtrace on crash ](../../tutorials/docs/get_backtrace.html#automatic-backtrace-on-crash)\n    * [ Profiling in ROS 2 / Nav2 ](../../tutorials/docs/get_profile.html)\n      * [ Overview ](../../tutorials/docs/get_profile.html#overview)\n      * [ Preliminaries ](../../tutorials/docs/get_profile.html#preliminaries)\n      * [ Profile from a Node ](../../tutorials/docs/get_profile.html#profile-from-a-node)\n      * [ Profile from a Launch File ](../../tutorials/docs/get_profile.html#profile-from-a-launch-file)\n      * [ From Nav2 Bringup ](../../tutorials/docs/get_profile.html#from-nav2-bringup)\n      * [ Interpreting Results ](../../tutorials/docs/get_profile.html#interpreting-results)\n    * [ Docker for Development: Zero to Hero ](../../tutorials/docs/docker_dev.html)\n      * [ Overview ](../../tutorials/docs/docker_dev.html#overview)\n      * [ Preliminaries ](../../tutorials/docs/docker_dev.html#preliminaries)\n      * [ Important Docker Commands ](../../tutorials/docs/docker_dev.html#important-docker-commands)\n      * [ Exploring Your First Container ](../../tutorials/docs/docker_dev.html#exploring-your-first-container)\n      * [ Understanding ROS Docker Images ](../../tutorials/docs/docker_dev.html#understanding-ros-docker-images)\n      * [ For Docker-Based Development ](../../tutorials/docs/docker_dev.html#for-docker-based-development)\n        * [ Building a Development Image ](../../tutorials/docs/docker_dev.html#building-a-development-image)\n        * [ Visualizations from Docker ](../../tutorials/docs/docker_dev.html#visualizations-from-docker)\n      * [ For Docker-Based Deployment ](../../tutorials/docs/docker_dev.html#for-docker-based-deployment)\n      * [ Conclusion ](../../tutorials/docs/docker_dev.html#conclusion)\n      * [ Appendix ](../../tutorials/docs/docker_dev.html#appendix)\n        * [ Nav2 Development Image ](../../tutorials/docs/docker_dev.html#nav2-development-image)\n        * [ Nav2 Deployment Image ](../../tutorials/docs/docker_dev.html#nav2-deployment-image)\n  * [ Plugin Tutorials ](../../plugin_tutorials/index.html)\n    * [ Writing a New Costmap2D Plugin ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html)\n      * [ Overview ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#overview)\n      * [ Requirements ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#requirements)\n      * [ Tutorial Steps ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#tutorial-steps)\n        * [ 1- Write a new Costmap2D plugin ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#write-a-new-costmap2d-plugin)\n        * [ 2- Export and make GradientLayer plugin ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#export-and-make-gradientlayer-plugin)\n        * [ 3- Enable the plugin in Costmap2D ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#enable-the-plugin-in-costmap2d)\n        * [ 4- Run GradientLayer plugin ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#run-gradientlayer-plugin)\n    * [ Writing a New Planner Plugin ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html)\n      * [ Overview ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#overview)\n      * [ Requirements ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#requirements)\n      * [ Tutorial Steps ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#tutorial-steps)\n        * [ 1- Creating a new Planner Plugin ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#creating-a-new-planner-plugin)\n        * [ 2- Exporting the planner plugin ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#exporting-the-planner-plugin)\n        * [ 3- Pass the plugin name through params file ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#pass-the-plugin-name-through-params-file)\n        * [ 4- Run StraightLine plugin ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#run-straightline-plugin)\n    * [ Writing a New Controller Plugin ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html)\n      * [ Overview ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#overview)\n      * [ Requirements ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#requirements)\n      * [ Tutorial Steps ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#tutorial-steps)\n        * [ 1- Create a new Controller Plugin ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#create-a-new-controller-plugin)\n        * [ 2- Exporting the controller plugin ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#exporting-the-controller-plugin)\n        * [ 3- Pass the plugin name through the params file ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#pass-the-plugin-name-through-the-params-file)\n        * [ 4- Run Pure Pursuit Controller plugin ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#run-pure-pursuit-controller-plugin)\n    * [ Writing a New Behavior Tree Plugin ](../../plugin_tutorials/docs/writing_new_bt_plugin.html)\n      * [ Overview ](../../plugin_tutorials/docs/writing_new_bt_plugin.html#overview)\n      * [ Requirements ](../../plugin_tutorials/docs/writing_new_bt_plugin.html#requirements)\n      * [ Tutorial Steps ](../../plugin_tutorials/docs/writing_new_bt_plugin.html#tutorial-steps)\n        * [ 1- Creating a new BT Plugin ](../../plugin_tutorials/docs/writing_new_bt_plugin.html#creating-a-new-bt-plugin)\n        * [ 2- Exporting the planner plugin ](../../plugin_tutorials/docs/writing_new_bt_plugin.html#exporting-the-planner-plugin)\n        * [ 3- Add plugin library name to config ](../../plugin_tutorials/docs/writing_new_bt_plugin.html#add-plugin-library-name-to-config)\n        * [ 4- Run Your Custom plugin ](../../plugin_tutorials/docs/writing_new_bt_plugin.html#run-your-custom-plugin)\n    * [ Writing a New Behavior Plugin ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html)\n      * [ Overview ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html#overview)\n      * [ Requirements ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html#requirements)\n      * [ Tutorial Steps ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html#tutorial-steps)\n        * [ 1- Creating a new Behavior Plugin ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html#creating-a-new-behavior-plugin)\n        * [ 2- Exporting the Behavior Plugin ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html#exporting-the-behavior-plugin)\n        * [ 3- Pass the plugin name through params file ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html#pass-the-plugin-name-through-params-file)\n        * [ 4- Run Behavior Plugin ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html#run-behavior-plugin)\n    * [ Writing a New Navigator Plugin ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html)\n      * [ Overview ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html#overview)\n      * [ Requirements ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html#requirements)\n      * [ Tutorial Steps ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html#tutorial-steps)\n        * [ 1- Create a new Navigator Plugin ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html#create-a-new-navigator-plugin)\n        * [ 2- Exporting the navigator plugin ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html#exporting-the-navigator-plugin)\n        * [ 3- Pass the plugin name through the params file ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html#pass-the-plugin-name-through-the-params-file)\n        * [ 4- Run plugin ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html#run-plugin)\n  * [ Configuration Guide ](../index.html)\n    * [ Behavior-Tree Navigator ](configuring-bt-navigator.html)\n      * [ Parameters ](configuring-bt-navigator.html#parameters)\n      * [ Example ](configuring-bt-navigator.html#example)\n    * Behavior Tree XML Nodes \n      * Action Plugins \n        * [ Wait ](bt-plugins/actions/Wait.html)\n        * [ Spin ](bt-plugins/actions/Spin.html)\n        * [ BackUp ](bt-plugins/actions/BackUp.html)\n        * [ DriveOnHeading ](bt-plugins/actions/DriveOnHeading.html)\n        * [ AssistedTeleop ](bt-plugins/actions/AssistedTeleop.html)\n        * [ ComputePathToPose ](bt-plugins/actions/ComputePathToPose.html)\n        * [ FollowPath ](bt-plugins/actions/FollowPath.html)\n        * [ NavigateToPose ](bt-plugins/actions/NavigateToPose.html)\n        * [ ClearEntireCostmap ](bt-plugins/actions/ClearEntireCostmap.html)\n        * [ ClearCostmapExceptRegion ](bt-plugins/actions/ClearCostmapExceptRegion.html)\n        * [ ClearCostmapAroundRobot ](bt-plugins/actions/ClearCostmapAroundRobot.html)\n        * [ ReinitializeGlobalLocalization ](bt-plugins/actions/ReinitializeGlobalLocalization.html)\n        * [ TruncatePath ](bt-plugins/actions/TruncatePath.html)\n        * [ TruncatePathLocal ](bt-plugins/actions/TruncatePathLocal.html)\n        * [ PlannerSelector ](bt-plugins/actions/PlannerSelector.html)\n        * [ ControllerSelector ](bt-plugins/actions/ControllerSelector.html)\n        * [ SmootherSelector ](bt-plugins/actions/SmootherSelector.html)\n        * [ GoalCheckerSelector ](bt-plugins/actions/GoalCheckerSelector.html)\n        * [ ProgressCheckerSelector ](bt-plugins/actions/ProgressCheckerSelector.html)\n        * [ NavigateThroughPoses ](bt-plugins/actions/NavigateThroughPoses.html)\n        * [ ComputePathThroughPoses ](bt-plugins/actions/ComputePathThroughPoses.html)\n        * [ ComputeCoveragePath ](bt-plugins/actions/ComputeCoveragePath.html)\n        * [ CancelCoverage ](bt-plugins/actions/CancelCoverage.html)\n        * [ RemovePassedGoals ](bt-plugins/actions/RemovePassedGoals.html)\n        * [ CancelControl ](bt-plugins/actions/CancelControl.html)\n        * [ CancelBackUp ](bt-plugins/actions/CancelBackUp.html)\n        * [ CancelSpin ](bt-plugins/actions/CancelSpin.html)\n        * [ CancelWait ](bt-plugins/actions/CancelWait.html)\n        * [ CancelDriveOnHeading ](bt-plugins/actions/CancelDriveOnHeading.html)\n        * [ CancelAssistedTeleop ](bt-plugins/actions/CancelAssistedTeleop.html)\n        * [ SmoothPath ](bt-plugins/actions/Smooth.html)\n      * Condition Plugins \n        * [ GoalReached ](bt-plugins/conditions/GoalReached.html)\n        * [ TransformAvailable ](bt-plugins/conditions/TransformAvailable.html)\n        * [ DistanceTraveled ](bt-plugins/conditions/DistanceTraveled.html)\n        * [ GoalUpdated ](bt-plugins/conditions/GoalUpdated.html)\n        * [ GloballyUpdatedGoal ](bt-plugins/conditions/GloballyUpdatedGoal.html)\n        * [ InitialPoseReceived ](bt-plugins/conditions/InitialPoseReceived.html)\n        * [ IsStuck ](bt-plugins/conditions/IsStuck.html)\n        * [ TimeExpired ](bt-plugins/conditions/TimeExpired.html)\n        * [ IsBatteryLow ](bt-plugins/conditions/IsBatteryLow.html)\n        * [ IsPathValid ](bt-plugins/conditions/IsPathValid.html)\n        * [ PathExpiringTimer ](bt-plugins/conditions/PathExpiringTimer.html)\n        * [ AreErrorCodesPresent ](bt-plugins/conditions/AreErrorCodesPresent.html)\n        * [ WouldAControllerRecoveryHelp ](bt-plugins/conditions/WouldAControllerRecoveryHelp.html)\n        * [ WouldAPlannerRecoveryHelp ](bt-plugins/conditions/WouldAPlannerRecoveryHelp.html)\n        * [ WouldASmootherRecoveryHelp ](bt-plugins/conditions/WouldASmootherRecoveryHelp.html)\n        * [ IsBatteryCharging ](bt-plugins/conditions/IsBatteryCharging.html)\n      * Control Plugins \n        * [ PipelineSequence ](bt-plugins/controls/PipelineSequence.html)\n        * [ RoundRobin ](bt-plugins/controls/RoundRobin.html)\n        * [ RecoveryNode ](bt-plugins/controls/RecoveryNode.html)\n      * Decorator Plugins \n        * [ RateController ](bt-plugins/decorators/RateController.html)\n        * [ DistanceController ](bt-plugins/decorators/DistanceController.html)\n        * [ SpeedController ](bt-plugins/decorators/SpeedController.html)\n        * [ GoalUpdater ](bt-plugins/decorators/GoalUpdater.html)\n        * [ PathLongerOnApproach ](bt-plugins/decorators/PathLongerOnApproach.html)\n        * [ SingleTrigger ](bt-plugins/decorators/SingleTrigger.html)\n      * Example \n    * [ Costmap 2D ](configuring-costmaps.html)\n      * [ Costmap2D ROS Parameters ](configuring-costmaps.html#costmap2d-ros-parameters)\n      * [ Default Plugins ](configuring-costmaps.html#default-plugins)\n      * [ Plugin Parameters ](configuring-costmaps.html#plugin-parameters)\n        * [ Static Layer Parameters ](costmap-plugins/static.html)\n        * [ Inflation Layer Parameters ](costmap-plugins/inflation.html)\n        * [ Obstacle Layer Parameters ](costmap-plugins/obstacle.html)\n        * [ Voxel Layer Parameters ](costmap-plugins/voxel.html)\n        * [ Range Sensor Parameters ](costmap-plugins/range.html)\n        * [ Denoise Layer Parameters ](costmap-plugins/denoise.html)\n      * [ Costmap Filters Parameters ](configuring-costmaps.html#costmap-filters-parameters)\n        * [ Keepout Filter Parameters ](costmap-plugins/keepout_filter.html)\n        * [ Speed Filter Parameters ](costmap-plugins/speed_filter.html)\n        * [ Binary Filter Parameters ](costmap-plugins/binary_filter.html)\n      * [ Example ](configuring-costmaps.html#example)\n    * [ Lifecycle Manager ](configuring-lifecycle.html)\n      * [ Parameters ](configuring-lifecycle.html#parameters)\n      * [ Example ](configuring-lifecycle.html#example)\n    * [ Planner Server ](configuring-planner-server.html)\n      * [ Parameters ](configuring-planner-server.html#parameters)\n      * [ Default Plugins ](configuring-planner-server.html#default-plugins)\n      * [ Example ](configuring-planner-server.html#example)\n    * [ Coverage Server ](configuring-coverage-server.html)\n      * [ Parameters ](configuring-coverage-server.html#parameters)\n      * [ Example ](configuring-coverage-server.html#example)\n    * [ NavFn Planner ](configuring-navfn.html)\n      * [ Parameters ](configuring-navfn.html#parameters)\n      * [ Example ](configuring-navfn.html#example)\n    * [ Smac Planner ](configuring-smac-planner.html)\n      * [ Provided Plugins ](configuring-smac-planner.html#provided-plugins)\n        * [ Smac 2D Planner ](smac/configuring-smac-2d.html)\n        * [ Smac Hybrid-A* Planner ](smac/configuring-smac-hybrid.html)\n        * [ Smac State Lattice Planner ](smac/configuring-smac-lattice.html)\n      * [ Description ](configuring-smac-planner.html#description)\n    * [ Theta Star Planner ](configuring-thetastar.html)\n      * [ Parameters ](configuring-thetastar.html#parameters)\n      * [ Example ](configuring-thetastar.html#example)\n    * [ Controller Server ](configuring-controller-server.html)\n      * [ Parameters ](configuring-controller-server.html#parameters)\n      * [ Provided Plugins ](configuring-controller-server.html#provided-plugins)\n        * [ SimpleProgressChecker ](nav2_controller-plugins/simple_progress_checker.html)\n        * [ PoseProgressChecker ](nav2_controller-plugins/pose_progress_checker.html)\n        * [ SimpleGoalChecker ](nav2_controller-plugins/simple_goal_checker.html)\n        * [ StoppedGoalChecker ](nav2_controller-plugins/stopped_goal_checker.html)\n      * [ Default Plugins ](configuring-controller-server.html#default-plugins)\n      * [ Example ](configuring-controller-server.html#example)\n    * [ DWB Controller ](configuring-dwb-controller.html)\n      * [ Controller ](configuring-dwb-controller.html#controller)\n        * [ DWB Controller ](dwb-params/controller.html)\n        * [ XYTheta Iterator ](dwb-params/iterator.html)\n        * [ Kinematic Parameters ](dwb-params/kinematic.html)\n        * [ Publisher ](dwb-params/visualization.html)\n      * [ Plugins ](configuring-dwb-controller.html#plugins)\n        * [ LimitedAccelGenerator ](dwb-plugins/limited_accel_generator.html)\n        * [ StandardTrajectoryGenerator ](dwb-plugins/standard_traj_generator.html)\n      * [ Trajectory Critics ](configuring-dwb-controller.html#trajectory-critics)\n        * [ BaseObstacleCritic ](trajectory_critics/base_obstacle.html)\n        * [ GoalAlignCritic ](trajectory_critics/goal_align.html)\n        * [ GoalDistCritic ](trajectory_critics/goal_dist.html)\n        * [ ObstacleFootprintCritic ](trajectory_critics/obstacle_footprint.html)\n        * [ OscillationCritic ](trajectory_critics/oscillation.html)\n        * [ PathAlignCritic ](trajectory_critics/path_align.html)\n        * [ PathDistCritic ](trajectory_critics/path_dist.html)\n        * [ PreferForwardCritic ](trajectory_critics/prefer_forward.html)\n        * [ RotateToGoalCritic ](trajectory_critics/rotate_to_goal.html)\n        * [ TwirlingCritic ](trajectory_critics/twirling.html)\n      * [ Example ](configuring-dwb-controller.html#example)\n    * [ Regulated Pure Pursuit ](configuring-regulated-pp.html)\n      * [ Regulated Pure Pursuit Parameters ](configuring-regulated-pp.html#regulated-pure-pursuit-parameters)\n      * [ Example ](configuring-regulated-pp.html#example)\n    * [ Model Predictive Path Integral Controller ](configuring-mppic.html)\n      * [ MPPI Parameters ](configuring-mppic.html#mppi-parameters)\n        * [ Trajectory Visualization ](configuring-mppic.html#trajectory-visualization)\n        * [ Path Handler ](configuring-mppic.html#path-handler)\n        * [ Ackermann Motion Model ](configuring-mppic.html#ackermann-motion-model)\n        * [ Constraint Critic ](configuring-mppic.html#constraint-critic)\n        * [ Goal Angle Critic ](configuring-mppic.html#goal-angle-critic)\n        * [ Goal Critic ](configuring-mppic.html#goal-critic)\n        * [ Obstacles Critic ](configuring-mppic.html#obstacles-critic)\n        * [ Cost Critic ](configuring-mppic.html#cost-critic)\n        * [ Path Align Critic ](configuring-mppic.html#path-align-critic)\n        * [ Path Angle Critic ](configuring-mppic.html#path-angle-critic)\n        * [ Path Follow Critic ](configuring-mppic.html#path-follow-critic)\n        * [ Prefer Forward Critic ](configuring-mppic.html#prefer-forward-critic)\n        * [ Twirling Critic ](configuring-mppic.html#twirling-critic)\n        * [ Velocity Deadband Critic ](configuring-mppic.html#velocity-deadband-critic)\n      * [ Example ](configuring-mppic.html#example)\n      * [ Notes to Users ](configuring-mppic.html#notes-to-users)\n        * [ General Words of Wisdom ](configuring-mppic.html#general-words-of-wisdom)\n        * [ Prediction Horizon, Costmap Sizing, and Offsets ](configuring-mppic.html#prediction-horizon-costmap-sizing-and-offsets)\n        * [ Obstacle, Inflation Layer, and Path Following ](configuring-mppic.html#obstacle-inflation-layer-and-path-following)\n    * [ Rotation Shim Controller ](configuring-rotation-shim-controller.html)\n      * [ Rotation Shim Controller Parameters ](configuring-rotation-shim-controller.html#rotation-shim-controller-parameters)\n      * [ Example ](configuring-rotation-shim-controller.html#example)\n    * [ Graceful Controller ](configuring-graceful-motion-controller.html)\n      * [ Graceful Controller Parameters ](configuring-graceful-motion-controller.html#graceful-controller-parameters)\n      * [ Example ](configuring-graceful-motion-controller.html#example)\n    * [ Map Server / Saver ](configuring-map-server.html)\n      * [ Map Saver Parameters ](configuring-map-server.html#map-saver-parameters)\n      * [ Map Server Parameters ](configuring-map-server.html#map-server-parameters)\n      * [ Costmap Filter Info Server Parameters ](configuring-map-server.html#costmap-filter-info-server-parameters)\n      * [ Example ](configuring-map-server.html#example)\n    * [ AMCL ](configuring-amcl.html)\n      * [ Parameters ](configuring-amcl.html#parameters)\n      * [ Example ](configuring-amcl.html#example)\n    * [ Behavior Server ](configuring-behavior-server.html)\n      * [ Behavior Server Parameters ](configuring-behavior-server.html#behavior-server-parameters)\n      * [ Default Plugins ](configuring-behavior-server.html#default-plugins)\n      * [ Spin Behavior Parameters ](configuring-behavior-server.html#spin-behavior-parameters)\n      * [ BackUp Behavior Parameters ](configuring-behavior-server.html#backup-behavior-parameters)\n      * [ DriveOnHeading Behavior Parameters ](configuring-behavior-server.html#driveonheading-behavior-parameters)\n      * [ AssistedTeleop Behavior Parameters ](configuring-behavior-server.html#assistedteleop-behavior-parameters)\n      * [ Example ](configuring-behavior-server.html#example)\n    * [ Smoother Server ](configuring-smoother-server.html)\n      * [ Smoother Server Parameters ](configuring-smoother-server.html#smoother-server-parameters)\n      * [ Example ](configuring-smoother-server.html#example)\n    * [ Simple Smoother ](configuring-simple-smoother.html)\n      * [ Simple Smoother Parameters ](configuring-simple-smoother.html#simple-smoother-parameters)\n      * [ Example ](configuring-simple-smoother.html#example)\n    * [ Savitzky-Golay Smoother ](configuring-savitzky-golay-smoother.html)\n      * [ Savitzky-Golay Smoother Parameters ](configuring-savitzky-golay-smoother.html#savitzky-golay-smoother-parameters)\n      * [ Example ](configuring-savitzky-golay-smoother.html#example)\n    * [ Constrained smoother ](configuring-constrained-smoother.html)\n      * [ Smoother Server Parameters ](configuring-constrained-smoother.html#smoother-server-parameters)\n      * [ Example ](configuring-constrained-smoother.html#example)\n    * [ Velocity Smoother ](configuring-velocity-smoother.html)\n      * [ Velocity Smoother Parameters ](configuring-velocity-smoother.html#velocity-smoother-parameters)\n      * [ Example ](configuring-velocity-smoother.html#example)\n    * [ Collision Monitor ](configuring-collision-monitor.html)\n      * [ Provided Nodes ](configuring-collision-monitor.html#provided-nodes)\n        * [ Collision Monitor Node ](collision_monitor/configuring-collision-monitor-node.html)\n        * [ Collision Detector Node ](collision_monitor/configuring-collision-detector-node.html)\n    * [ Waypoint Follower ](configuring-waypoint-follower.html)\n      * [ Parameters ](configuring-waypoint-follower.html#parameters)\n      * [ Provided Plugins ](configuring-waypoint-follower.html#provided-plugins)\n        * [ WaitAtWaypoint ](nav2_waypoint_follower-plugins/wait_at_waypoint.html)\n        * [ PhotoAtWaypoint ](nav2_waypoint_follower-plugins/photo_at_waypoint.html)\n        * [ InputAtWaypoint ](nav2_waypoint_follower-plugins/input_at_waypoint.html)\n      * [ Default Plugin ](configuring-waypoint-follower.html#default-plugin)\n      * [ Example ](configuring-waypoint-follower.html#example)\n  * [ Tuning Guide ](../../tuning/index.html)\n    * [ Inflation Potential Fields ](../../tuning/index.html#inflation-potential-fields)\n    * [ Robot Footprint vs Radius ](../../tuning/index.html#robot-footprint-vs-radius)\n    * [ Rotate in Place Behavior ](../../tuning/index.html#rotate-in-place-behavior)\n    * [ Planner Plugin Selection ](../../tuning/index.html#planner-plugin-selection)\n    * [ Controller Plugin Selection ](../../tuning/index.html#controller-plugin-selection)\n    * [ Caching Obstacle Heuristic in Smac Planners ](../../tuning/index.html#caching-obstacle-heuristic-in-smac-planners)\n    * [ Costmap2D Plugins ](../../tuning/index.html#costmap2d-plugins)\n    * [ Nav2 Launch Options ](../../tuning/index.html#nav2-launch-options)\n    * [ Other Pages We\u2019d Love To Offer ](../../tuning/index.html#other-pages-we-d-love-to-offer)\n  * [ Nav2 Behavior Trees ](../../behavior_trees/index.html)\n    * [ Introduction To Nav2 Specific Nodes ](../../behavior_trees/overview/nav2_specific_nodes.html)\n      * [ Action Nodes ](../../behavior_trees/overview/nav2_specific_nodes.html#action-nodes)\n      * [ Condition Nodes ](../../behavior_trees/overview/nav2_specific_nodes.html#condition-nodes)\n      * [ Decorator Nodes ](../../behavior_trees/overview/nav2_specific_nodes.html#decorator-nodes)\n      * [ Control: PipelineSequence ](../../behavior_trees/overview/nav2_specific_nodes.html#control-pipelinesequence)\n      * [ Control: Recovery ](../../behavior_trees/overview/nav2_specific_nodes.html#control-recovery)\n      * [ Control: RoundRobin ](../../behavior_trees/overview/nav2_specific_nodes.html#control-roundrobin)\n    * [ Detailed Behavior Tree Walkthrough ](../../behavior_trees/overview/detailed_behavior_tree_walkthrough.html)\n      * [ Overview ](../../behavior_trees/overview/detailed_behavior_tree_walkthrough.html#overview)\n      * [ Prerequisites ](../../behavior_trees/overview/detailed_behavior_tree_walkthrough.html#prerequisites)\n      * [ Navigate To Pose With Replanning and Recovery ](../../behavior_trees/overview/detailed_behavior_tree_walkthrough.html#navigate-to-pose-with-replanning-and-recovery)\n      * [ Navigation Subtree ](../../behavior_trees/overview/detailed_behavior_tree_walkthrough.html#navigation-subtree)\n      * [ Recovery Subtree ](../../behavior_trees/overview/detailed_behavior_tree_walkthrough.html#recovery-subtree)\n    * [ Navigate To Pose ](../../behavior_trees/trees/nav_to_pose_recovery.html)\n    * [ Navigate Through Poses ](../../behavior_trees/trees/nav_through_poses_recovery.html)\n    * [ Navigate To Pose and Pause Near Goal-Obstacle ](../../behavior_trees/trees/nav_to_pose_and_pause_near_goal_obstacle.html)\n    * [ Navigate To Pose With Consistent Replanning And If Path Becomes Invalid ](../../behavior_trees/trees/nav_to_pose_with_consistent_replanning_and_if_path_becomes_invalid.html)\n    * [ Follow Dynamic Point ](../../behavior_trees/trees/follow_point.html)\n    * [ Odometry Calibration ](../../behavior_trees/trees/odometry_calibration.html)\n  * [ Navigation Plugins ](../../plugins/index.html)\n    * [ Behavior-Tree Navigators ](../../plugins/index.html#behavior-tree-navigators)\n    * [ Costmap Layers ](../../plugins/index.html#costmap-layers)\n    * [ Costmap Filters ](../../plugins/index.html#costmap-filters)\n    * [ Controllers ](../../plugins/index.html#controllers)\n    * [ Planners ](../../plugins/index.html#planners)\n    * [ Smoothers ](../../plugins/index.html#smoothers)\n    * [ Behaviors ](../../plugins/index.html#behaviors)\n    * [ Waypoint Task Executors ](../../plugins/index.html#waypoint-task-executors)\n    * [ Goal Checkers ](../../plugins/index.html#goal-checkers)\n    * [ Progress Checkers ](../../plugins/index.html#progress-checkers)\n    * [ Behavior Tree Nodes ](../../plugins/index.html#behavior-tree-nodes)\n  * [ Migration Guides ](../../migration/index.html)\n    * [ Dashing to Eloquent ](../../migration/Dashing.html)\n      * [ New Packages ](../../migration/Dashing.html#new-packages)\n      * [ New Plugins ](../../migration/Dashing.html#new-plugins)\n      * [ Navigation2 Architectural Changes ](../../migration/Dashing.html#navigation2-architectural-changes)\n    * [ Eloquent to Foxy ](../../migration/Eloquent.html)\n      * [ General ](../../migration/Eloquent.html#general)\n      * [ Server Updates ](../../migration/Eloquent.html#server-updates)\n      * [ New Plugins ](../../migration/Eloquent.html#new-plugins)\n      * [ Map Server Re-Work ](../../migration/Eloquent.html#map-server-re-work)\n      * [ New Particle Filter Messages ](../../migration/Eloquent.html#new-particle-filter-messages)\n      * [ Selection of Behavior Tree in each navigation action ](../../migration/Eloquent.html#selection-of-behavior-tree-in-each-navigation-action)\n      * [ FollowPoint Capability ](../../migration/Eloquent.html#followpoint-capability)\n      * [ New Costmap Layer ](../../migration/Eloquent.html#new-costmap-layer)\n    * [ Foxy to Galactic ](../../migration/Foxy.html)\n      * [ NavigateToPose Action Feedback updates ](../../migration/Foxy.html#navigatetopose-action-feedback-updates)\n      * [ NavigateToPose BT-node Interface Changes ](../../migration/Foxy.html#navigatetopose-bt-node-interface-changes)\n      * [ NavigateThroughPoses and ComputePathThroughPoses Actions Added ](../../migration/Foxy.html#navigatethroughposes-and-computepaththroughposes-actions-added)\n      * [ ComputePathToPose BT-node Interface Changes ](../../migration/Foxy.html#computepathtopose-bt-node-interface-changes)\n      * [ ComputePathToPose Action Interface Changes ](../../migration/Foxy.html#computepathtopose-action-interface-changes)\n      * [ BackUp BT-node Interface Changes ](../../migration/Foxy.html#backup-bt-node-interface-changes)\n      * [ BackUp Recovery Interface Changes ](../../migration/Foxy.html#backup-recovery-interface-changes)\n      * [ Nav2 Controllers and Goal Checker Plugin Interface Changes ](../../migration/Foxy.html#nav2-controllers-and-goal-checker-plugin-interface-changes)\n      * [ FollowPath goal_checker_id attribute ](../../migration/Foxy.html#followpath-goal-checker-id-attribute)\n      * [ Groot Support ](../../migration/Foxy.html#groot-support)\n      * [ New Plugins ](../../migration/Foxy.html#new-plugins)\n      * [ Costmap Filters ](../../migration/Foxy.html#costmap-filters)\n      * [ SmacPlanner ](../../migration/Foxy.html#smacplanner)\n      * [ ThetaStarPlanner ](../../migration/Foxy.html#thetastarplanner)\n      * [ RegulatedPurePursuitController ](../../migration/Foxy.html#regulatedpurepursuitcontroller)\n      * [ Costmap2D ` current_  ` Usage ](../../migration/Foxy.html#costmap2d-current-usage)\n      * [ Standard time units in parameters ](../../migration/Foxy.html#standard-time-units-in-parameters)\n      * [ Ray Tracing Parameters ](../../migration/Foxy.html#ray-tracing-parameters)\n      * [ Obstacle Marking Parameters ](../../migration/Foxy.html#obstacle-marking-parameters)\n      * [ Recovery Action Changes ](../../migration/Foxy.html#recovery-action-changes)\n      * [ Default Behavior Tree Changes ](../../migration/Foxy.html#default-behavior-tree-changes)\n      * [ NavFn Planner Parameters ](../../migration/Foxy.html#navfn-planner-parameters)\n      * [ New ClearCostmapExceptRegion and ClearCostmapAroundRobot BT-nodes ](../../migration/Foxy.html#new-clearcostmapexceptregion-and-clearcostmaparoundrobot-bt-nodes)\n      * [ New Behavior Tree Nodes ](../../migration/Foxy.html#new-behavior-tree-nodes)\n      * [ sensor_msgs/PointCloud to sensor_msgs/PointCloud2 Change ](../../migration/Foxy.html#sensor-msgs-pointcloud-to-sensor-msgs-pointcloud2-change)\n      * [ ControllerServer New Parameter failure_tolerance ](../../migration/Foxy.html#controllerserver-new-parameter-failure-tolerance)\n      * [ Removed BT XML Launch Configurations ](../../migration/Foxy.html#removed-bt-xml-launch-configurations)\n      * [ Nav2 RViz Panel Action Feedback Information ](../../migration/Foxy.html#nav2-rviz-panel-action-feedback-information)\n    * [ Galactic to Humble ](../../migration/Galactic.html)\n      * [ Major improvements to Smac Planners ](../../migration/Galactic.html#major-improvements-to-smac-planners)\n      * [ Simple (Python) Commander ](../../migration/Galactic.html#simple-python-commander)\n      * [ Reduce Nodes and Executors ](../../migration/Galactic.html#reduce-nodes-and-executors)\n      * [ API Change for nav2_core ](../../migration/Galactic.html#api-change-for-nav2-core)\n      * [ Extending the BtServiceNode to process Service-Results ](../../migration/Galactic.html#extending-the-btservicenode-to-process-service-results)\n      * [ Including new Rotation Shim Controller Plugin ](../../migration/Galactic.html#including-new-rotation-shim-controller-plugin)\n      * [ Spawning the robot in Gazebo ](../../migration/Galactic.html#spawning-the-robot-in-gazebo)\n      * [ Recovery Behavior Timeout ](../../migration/Galactic.html#recovery-behavior-timeout)\n      * [ New parameter ` use_final_approach_orientation  ` for the 3 2D planners ](../../migration/Galactic.html#new-parameter-use-final-approach-orientation-for-the-3-2d-planners)\n      * [ SmacPlanner2D and Theta*: fix goal orientation being ignored ](../../migration/Galactic.html#smacplanner2d-and-theta-fix-goal-orientation-being-ignored)\n      * [ SmacPlanner2D, NavFn and Theta*: fix small path corner cases ](../../migration/Galactic.html#smacplanner2d-navfn-and-theta-fix-small-path-corner-cases)\n      * [ Change and fix behavior of dynamic parameter change detection ](../../migration/Galactic.html#change-and-fix-behavior-of-dynamic-parameter-change-detection)\n      * [ Dynamic Parameters ](../../migration/Galactic.html#dynamic-parameters)\n      * [ BT Action Nodes Exception Changes ](../../migration/Galactic.html#bt-action-nodes-exception-changes)\n      * [ BT Navigator Groot Multiple Navigators ](../../migration/Galactic.html#bt-navigator-groot-multiple-navigators)\n      * [ Removed Kinematic Limiting in RPP ](../../migration/Galactic.html#removed-kinematic-limiting-in-rpp)\n      * [ Added Smoother Task Server ](../../migration/Galactic.html#added-smoother-task-server)\n      * [ Removed Use Approach Velocity Scaling Param in RPP ](../../migration/Galactic.html#removed-use-approach-velocity-scaling-param-in-rpp)\n      * [ Refactored AMCL motion models as plugins ](../../migration/Galactic.html#refactored-amcl-motion-models-as-plugins)\n      * [ Dropping Support for Live Groot Monitoring of Nav2 ](../../migration/Galactic.html#dropping-support-for-live-groot-monitoring-of-nav2)\n      * [ Replanning Only if Path is Invalid ](../../migration/Galactic.html#replanning-only-if-path-is-invalid)\n      * [ Fix CostmapLayer clearArea invert param logic ](../../migration/Galactic.html#fix-costmaplayer-cleararea-invert-param-logic)\n      * [ Dynamic Composition ](../../migration/Galactic.html#dynamic-composition)\n      * [ BT Cancel Node ](../../migration/Galactic.html#bt-cancel-node)\n      * [ BT PathLongerOnApproach Node ](../../migration/Galactic.html#bt-pathlongeronapproach-node)\n      * [ BT TruncatePathLocal Node ](../../migration/Galactic.html#bt-truncatepathlocal-node)\n      * [ Constrained Smoother ](../../migration/Galactic.html#constrained-smoother)\n      * [ Replanning at a Constant Rate and if the Path is Invalid ](../../migration/Galactic.html#replanning-at-a-constant-rate-and-if-the-path-is-invalid)\n      * [ Euclidean Distance 2D ](../../migration/Galactic.html#euclidean-distance-2d)\n      * [ Recovery To Behavior ](../../migration/Galactic.html#recovery-to-behavior)\n      * [ Respawn Support in Launch and Lifecycle Manager ](../../migration/Galactic.html#respawn-support-in-launch-and-lifecycle-manager)\n      * [ New Nav2 Velocity Smoother ](../../migration/Galactic.html#new-nav2-velocity-smoother)\n      * [ Goal Checker API Changed ](../../migration/Galactic.html#goal-checker-api-changed)\n      * [ Added Assisted Teleop ](../../migration/Galactic.html#added-assisted-teleop)\n    * [ Humble to Iron ](../../migration/Humble.html)\n      * [ New Behavior-Tree Navigator Plugins ](../../migration/Humble.html#new-behavior-tree-navigator-plugins)\n      * [ Added Collision Monitor ](../../migration/Humble.html#added-collision-monitor)\n      * [ Removed use_sim_time from yaml ](../../migration/Humble.html#removed-use-sim-time-from-yaml)\n      * [ Run-time Speed up of Smac Planner ](../../migration/Humble.html#run-time-speed-up-of-smac-planner)\n      * [ Recursive Refinement of Smac and Simple Smoothers ](../../migration/Humble.html#recursive-refinement-of-smac-and-simple-smoothers)\n      * [ Simple Commander Python API ](../../migration/Humble.html#simple-commander-python-api)\n      * [ Smac Planner Start Pose Included in Path ](../../migration/Humble.html#smac-planner-start-pose-included-in-path)\n      * [ Parameterizable Collision Checking in RPP ](../../migration/Humble.html#parameterizable-collision-checking-in-rpp)\n      * [ Expanded Planner Benchmark Tests ](../../migration/Humble.html#expanded-planner-benchmark-tests)\n      * [ Smac Planner Path Tolerances ](../../migration/Humble.html#smac-planner-path-tolerances)\n      * [ costmap_2d_node default constructor ](../../migration/Humble.html#costmap-2d-node-default-constructor)\n      * [ Feedback for Navigation Failures ](../../migration/Humble.html#feedback-for-navigation-failures)\n      * [ Costmap Filters ](../../migration/Humble.html#costmap-filters)\n      * [ Savitzky-Golay Smoother ](../../migration/Humble.html#savitzky-golay-smoother)\n      * [ Changes to Map yaml file path for map_server node in Launch ](../../migration/Humble.html#changes-to-map-yaml-file-path-for-map-server-node-in-launch)\n      * [ SmootherSelector BT Node ](../../migration/Humble.html#smootherselector-bt-node)\n      * [ Publish Costmap Layers ](../../migration/Humble.html#publish-costmap-layers)\n      * [ Give Behavior Server Access to Both Costmaps ](../../migration/Humble.html#give-behavior-server-access-to-both-costmaps)\n      * [ New Model Predictive Path Integral Controller ](../../migration/Humble.html#new-model-predictive-path-integral-controller)\n      * [ Behavior Tree Uses Error Codes ](../../migration/Humble.html#behavior-tree-uses-error-codes)\n      * [ Load, Save and Loop Waypoints from the Nav2 Panel in RViz ](../../migration/Humble.html#load-save-and-loop-waypoints-from-the-nav2-panel-in-rviz)\n      * [ DWB Forward vs Reverse Pruning ](../../migration/Humble.html#dwb-forward-vs-reverse-pruning)\n      * [ More stable regulation on curves for long lookahead distances ](../../migration/Humble.html#more-stable-regulation-on-curves-for-long-lookahead-distances)\n      * [ Publish Collision Monitor State ](../../migration/Humble.html#publish-collision-monitor-state)\n      * [ Renamed ROS-parameter in Collision Monitor ](../../migration/Humble.html#renamed-ros-parameter-in-collision-monitor)\n      * [ New safety behavior model \u201climit\u201d in Collision Monitor ](../../migration/Humble.html#new-safety-behavior-model-limit-in-collision-monitor)\n      * [ Velocity smoother applies deceleration when timeout ](../../migration/Humble.html#velocity-smoother-applies-deceleration-when-timeout)\n      * [ PoseProgressChecker plugin ](../../migration/Humble.html#poseprogresschecker-plugin)\n      * [ Allow multiple goal checkers and change parameter progress_checker_plugin(s) name and type ](../../migration/Humble.html#allow-multiple-goal-checkers-and-change-parameter-progress-checker-plugin-s-name-and-type)\n      * [ IsBatteryChargingCondition BT Node ](../../migration/Humble.html#isbatterychargingcondition-bt-node)\n      * [ Behavior Server Error Codes ](../../migration/Humble.html#behavior-server-error-codes)\n      * [ New Denoise Costmap Layer Plugin ](../../migration/Humble.html#new-denoise-costmap-layer-plugin)\n      * [ SmacPlannerHybrid viz_expansions parameter ](../../migration/Humble.html#smacplannerhybrid-viz-expansions-parameter)\n    * [ Iron to Jazzy ](../../migration/Iron.html)\n      * [ Added TwistStamped Option for Commands ](../../migration/Iron.html#added-twiststamped-option-for-commands)\n      * [ Add VelocityPolygon in Collision Monitor ](../../migration/Iron.html#add-velocitypolygon-in-collision-monitor)\n      * [ Change polygon points parameter format in Collision Monitor ](../../migration/Iron.html#change-polygon-points-parameter-format-in-collision-monitor)\n      * [ Introduction of Soft-Real Time Action Servers ](../../migration/Iron.html#introduction-of-soft-real-time-action-servers)\n      * [ ` opennav_coverage  ` Project ](../../migration/Iron.html#opennav-coverage-project)\n      * [ Introduce a new Multi-Robot Bringup Launch ](../../migration/Iron.html#introduce-a-new-multi-robot-bringup-launch)\n      * [ New option for the Voxel and Obstacle Layers ](../../migration/Iron.html#new-option-for-the-voxel-and-obstacle-layers)\n      * [ use_interpolation RPP Parameter Depreciated ](../../migration/Iron.html#use-interpolation-rpp-parameter-depreciated)\n      * [ Changes to MPPI Goal Critic ](../../migration/Iron.html#changes-to-mppi-goal-critic)\n      * [ Changes to MPPI Path Angle Critic ](../../migration/Iron.html#changes-to-mppi-path-angle-critic)\n      * [ Changes to MPPI Path Handling For Directionality ](../../migration/Iron.html#changes-to-mppi-path-handling-for-directionality)\n      * [ Addition of new MPPI Cost Critic ](../../migration/Iron.html#addition-of-new-mppi-cost-critic)\n      * [ MPPI Acceleration ](../../migration/Iron.html#mppi-acceleration)\n      * [ Move Error Code Enumerations ](../../migration/Iron.html#move-error-code-enumerations)\n      * [ Substitution in parameter file ](../../migration/Iron.html#substitution-in-parameter-file)\n      * [ Allow Behavior Server Plugins to Access The Action Result ](../../migration/Iron.html#allow-behavior-server-plugins-to-access-the-action-result)\n      * [ Smac Planner Debug Param Name Change ](../../migration/Iron.html#smac-planner-debug-param-name-change)\n      * [ Smac Planner On Approach to Goal Shortcutting Solutions ](../../migration/Iron.html#smac-planner-on-approach-to-goal-shortcutting-solutions)\n      * [ Added GPS Waypoint Follower Server ](../../migration/Iron.html#added-gps-waypoint-follower-server)\n      * [ Smac Planner Hybrid-A* New Features ](../../migration/Iron.html#smac-planner-hybrid-a-new-features)\n      * [ New node in nav2_collision_monitor: Collision Detector ](../../migration/Iron.html#new-node-in-nav2-collision-monitor-collision-detector)\n      * [ Dynamic enabling/disabling of sources/polygons in Collision Monitor/Detector ](../../migration/Iron.html#dynamic-enabling-disabling-of-sources-polygons-in-collision-monitor-detector)\n      * [ Expose action server\u2019s result timeout ](../../migration/Iron.html#expose-action-server-s-result-timeout)\n      * [ RewrittenYaml could add new parameters to YAMLs ](../../migration/Iron.html#rewrittenyaml-could-add-new-parameters-to-yamls)\n      * [ Simple Commander API Allows Multi-Robot Namespacing ](../../migration/Iron.html#simple-commander-api-allows-multi-robot-namespacing)\n      * [ Change duration type in wait_action node ](../../migration/Iron.html#change-duration-type-in-wait-action-node)\n      * [ The costmap activation fails when required transforms are not available ](../../migration/Iron.html#the-costmap-activation-fails-when-required-transforms-are-not-available)\n      * [ Subtrees Obtain Shared Resources ](../../migration/Iron.html#subtrees-obtain-shared-resources)\n      * [ Collision Monitor: added watchdog mechanism based on ` source_timeout  ` parameter with default blocking behavior ](../../migration/Iron.html#collision-monitor-added-watchdog-mechanism-based-on-source-timeout-parameter-with-default-blocking-behavior)\n      * [ BtActionServer: use native library haltTree() ](../../migration/Iron.html#btactionserver-use-native-library-halttree)\n      * [ Global Frame Removed from 2 BT Nodes ](../../migration/Iron.html#global-frame-removed-from-2-bt-nodes)\n      * [ Introduction of ` CostmapUpdate.msg  ` ](../../migration/Iron.html#introduction-of-costmapupdate-msg)\n      * [ Full Stack Uses Node Clocks ](../../migration/Iron.html#full-stack-uses-node-clocks)\n      * [ New Graceful Motion Controller ](../../migration/Iron.html#new-graceful-motion-controller)\n      * [ Plugin Libraries in BT Navigator Only Includes Custom Nodes ](../../migration/Iron.html#plugin-libraries-in-bt-navigator-only-includes-custom-nodes)\n      * [ New RViz Plugin for selecting Planners, Controllers, Goal Checkers, Progress Checkers and Smoothers ](../../migration/Iron.html#new-rviz-plugin-for-selecting-planners-controllers-goal-checkers-progress-checkers-and-smoothers)\n      * [ RPP new optional ` interpolate_curvature_after_goal  ` behavior and fix conflict between ` use_rotate_to_heading  ` and ` allow_reversing  ` ](../../migration/Iron.html#rpp-new-optional-interpolate-curvature-after-goal-behavior-and-fix-conflict-between-use-rotate-to-heading-and-allow-reversing)\n      * [ Cancel Checker Interface For GlobalPlanner ](../../migration/Iron.html#cancel-checker-interface-for-globalplanner)\n      * [ New BtActionServer/BtNavigator parameter ](../../migration/Iron.html#new-btactionserver-btnavigator-parameter)\n      * [ New collision monitor parameter ](../../migration/Iron.html#new-collision-monitor-parameter)\n      * [ New graceful cancellation API for Controllers ](../../migration/Iron.html#new-graceful-cancellation-api-for-controllers)\n      * [ Standardization of Plugin Naming with Double Colons (::) ](../../migration/Iron.html#standardization-of-plugin-naming-with-double-colons)\n      * [ Collision monitor: dynamic radius for circle type polygons ](../../migration/Iron.html#collision-monitor-dynamic-radius-for-circle-type-polygons)\n  * [ Simple Commander API ](../../commander_api/index.html)\n    * [ Overview ](../../commander_api/index.html#overview)\n    * [ Commander API ](../../commander_api/index.html#id1)\n    * [ Costmap API ](../../commander_api/index.html#costmap-api)\n    * [ Footprint Collision Checker API ](../../commander_api/index.html#footprint-collision-checker-api)\n    * [ Examples and Demos ](../../commander_api/index.html#examples-and-demos)\n  * [ Roadmaps ](../../roadmap/roadmap.html)\n    * [ Jazzy Roadmap ](../../roadmap/roadmap.html#jazzy-roadmap)\n    * [ Iron Roadmap ](../../roadmap/roadmap.html#iron-roadmap)\n    * [ Humble Roadmap ](../../roadmap/roadmap.html#humble-roadmap)\n  * [ About and Contact ](../../about/index.html)\n    * [ Related Projects ](../../about/related_projects.html)\n    * [ About ](../../about/index.html#id1)\n    * [ Contact ](../../about/index.html#contact)\n\n__ [ Nav2 ](../../index.html)\n\n[ Edit ](https://github.com/ros-planning/navigation.ros.org)\n\n  * [ ](../../index.html)\n  * [ Configuration Guide ](../index.html)\n  * Behavior Tree XML Nodes \n  * \n\n* * *\n\n#  Behavior Tree XML Nodes  \u00b6\n\nThe [ nav2_behavior_tree ](https://github.com/ros-\nplanning/navigation2/tree/main/nav2_behavior_tree) package provides several\nnavigation-specific nodes that are pre-registered and can be included in\nBehavior Trees.\n\nCheck this [ introduction ](https://www.behaviortree.dev/bt_basics/) to learn\nhow behavior trees work and the difference between actions, conditions,\ncontrols and decorators.\n\nConsider checking out the [ Groot - Interacting with Behavior Trees\n](../../tutorials/docs/using_groot.html#groot-introduction) tutorial for using\nGroot to visualize and modify behavior trees.\n\n##  Action Plugins  \u00b6\n\n  * [ Wait ](bt-plugins/actions/Wait.html)\n  * [ Spin ](bt-plugins/actions/Spin.html)\n  * [ BackUp ](bt-plugins/actions/BackUp.html)\n  * [ DriveOnHeading ](bt-plugins/actions/DriveOnHeading.html)\n  * [ AssistedTeleop ](bt-plugins/actions/AssistedTeleop.html)\n  * [ ComputePathToPose ](bt-plugins/actions/ComputePathToPose.html)\n  * [ FollowPath ](bt-plugins/actions/FollowPath.html)\n  * [ NavigateToPose ](bt-plugins/actions/NavigateToPose.html)\n  * [ ClearEntireCostmap ](bt-plugins/actions/ClearEntireCostmap.html)\n  * [ ClearCostmapExceptRegion ](bt-plugins/actions/ClearCostmapExceptRegion.html)\n  * [ ClearCostmapAroundRobot ](bt-plugins/actions/ClearCostmapAroundRobot.html)\n  * [ ReinitializeGlobalLocalization ](bt-plugins/actions/ReinitializeGlobalLocalization.html)\n  * [ TruncatePath ](bt-plugins/actions/TruncatePath.html)\n  * [ TruncatePathLocal ](bt-plugins/actions/TruncatePathLocal.html)\n  * [ PlannerSelector ](bt-plugins/actions/PlannerSelector.html)\n  * [ ControllerSelector ](bt-plugins/actions/ControllerSelector.html)\n  * [ SmootherSelector ](bt-plugins/actions/SmootherSelector.html)\n  * [ GoalCheckerSelector ](bt-plugins/actions/GoalCheckerSelector.html)\n  * [ ProgressCheckerSelector ](bt-plugins/actions/ProgressCheckerSelector.html)\n  * [ NavigateThroughPoses ](bt-plugins/actions/NavigateThroughPoses.html)\n  * [ ComputePathThroughPoses ](bt-plugins/actions/ComputePathThroughPoses.html)\n  * [ ComputeCoveragePath ](bt-plugins/actions/ComputeCoveragePath.html)\n  * [ CancelCoverage ](bt-plugins/actions/CancelCoverage.html)\n  * [ RemovePassedGoals ](bt-plugins/actions/RemovePassedGoals.html)\n  * [ CancelControl ](bt-plugins/actions/CancelControl.html)\n  * [ CancelBackUp ](bt-plugins/actions/CancelBackUp.html)\n  * [ CancelSpin ](bt-plugins/actions/CancelSpin.html)\n  * [ CancelWait ](bt-plugins/actions/CancelWait.html)\n  * [ CancelDriveOnHeading ](bt-plugins/actions/CancelDriveOnHeading.html)\n  * [ CancelAssistedTeleop ](bt-plugins/actions/CancelAssistedTeleop.html)\n  * [ SmoothPath ](bt-plugins/actions/Smooth.html)\n\n##  Condition Plugins  \u00b6\n\n  * [ GoalReached ](bt-plugins/conditions/GoalReached.html)\n  * [ TransformAvailable ](bt-plugins/conditions/TransformAvailable.html)\n  * [ DistanceTraveled ](bt-plugins/conditions/DistanceTraveled.html)\n  * [ GoalUpdated ](bt-plugins/conditions/GoalUpdated.html)\n  * [ GloballyUpdatedGoal ](bt-plugins/conditions/GloballyUpdatedGoal.html)\n  * [ InitialPoseReceived ](bt-plugins/conditions/InitialPoseReceived.html)\n  * [ IsStuck ](bt-plugins/conditions/IsStuck.html)\n  * [ TimeExpired ](bt-plugins/conditions/TimeExpired.html)\n  * [ IsBatteryLow ](bt-plugins/conditions/IsBatteryLow.html)\n  * [ IsPathValid ](bt-plugins/conditions/IsPathValid.html)\n  * [ PathExpiringTimer ](bt-plugins/conditions/PathExpiringTimer.html)\n  * [ AreErrorCodesPresent ](bt-plugins/conditions/AreErrorCodesPresent.html)\n  * [ WouldAControllerRecoveryHelp ](bt-plugins/conditions/WouldAControllerRecoveryHelp.html)\n  * [ WouldAPlannerRecoveryHelp ](bt-plugins/conditions/WouldAPlannerRecoveryHelp.html)\n  * [ WouldASmootherRecoveryHelp ](bt-plugins/conditions/WouldASmootherRecoveryHelp.html)\n  * [ IsBatteryCharging ](bt-plugins/conditions/IsBatteryCharging.html)\n\n##  Control Plugins  \u00b6\n\n  * [ PipelineSequence ](bt-plugins/controls/PipelineSequence.html)\n  * [ RoundRobin ](bt-plugins/controls/RoundRobin.html)\n  * [ RecoveryNode ](bt-plugins/controls/RecoveryNode.html)\n\n##  Decorator Plugins  \u00b6\n\n  * [ RateController ](bt-plugins/decorators/RateController.html)\n  * [ DistanceController ](bt-plugins/decorators/DistanceController.html)\n  * [ SpeedController ](bt-plugins/decorators/SpeedController.html)\n  * [ GoalUpdater ](bt-plugins/decorators/GoalUpdater.html)\n  * [ PathLongerOnApproach ](bt-plugins/decorators/PathLongerOnApproach.html)\n  * [ SingleTrigger ](bt-plugins/decorators/SingleTrigger.html)\n\n##  Example  \u00b6\n\nThis Behavior Tree replans the global path periodically at 1 Hz and it also\nhas recovery actions.\n\n    \n    \n    <root main_tree_to_execute=\"MainTree\">\n      <BehaviorTree ID=\"MainTree\">\n        <RecoveryNode number_of_retries=\"6\" name=\"NavigateRecovery\">\n          <PipelineSequence name=\"NavigateWithReplanning\">\n            <RateController hz=\"1.0\">\n              <RecoveryNode number_of_retries=\"1\" name=\"ComputePathToPose\">\n                <ComputePathToPose goal=\"{goal}\" path=\"{path}\" planner_id=\"GridBased\"/>\n                <ReactiveFallback name=\"ComputePathToPoseRecoveryFallback\">\n                  <GoalUpdated/>\n                  <ClearEntireCostmap name=\"ClearGlobalCostmap-Context\" service_name=\"global_costmap/clear_entirely_global_costmap\"/>\n                </ReactiveFallback>\n              </RecoveryNode>\n            </RateController>\n            <RecoveryNode number_of_retries=\"1\" name=\"FollowPath\">\n              <FollowPath path=\"{path}\" controller_id=\"FollowPath\"/>\n              <ReactiveFallback name=\"FollowPathRecoveryFallback\">\n                <GoalUpdated/>\n                <ClearEntireCostmap name=\"ClearLocalCostmap-Context\" service_name=\"local_costmap/clear_entirely_local_costmap\"/>\n              </ReactiveFallback>\n            </RecoveryNode>\n          </PipelineSequence>\n          <ReactiveFallback name=\"RecoveryFallback\">\n            <GoalUpdated/>\n            <RoundRobin name=\"RecoveryActions\">\n              <Sequence name=\"ClearingActions\">\n                <ClearEntireCostmap name=\"ClearLocalCostmap-Subtree\" service_name=\"local_costmap/clear_entirely_local_costmap\"/>\n                <ClearEntireCostmap name=\"ClearGlobalCostmap-Subtree\" service_name=\"global_costmap/clear_entirely_global_costmap\"/>\n              </Sequence>\n              <Spin spin_dist=\"1.57\"/>\n              <Wait wait_duration=\"5\"/>\n              <BackUp backup_dist=\"0.15\" backup_speed=\"0.025\"/>\n            </RoundRobin>\n          </ReactiveFallback>\n        </RecoveryNode>\n      </BehaviorTree>\n    </root>\n    \n\n* * *\n\n\u00a9 Copyright 2023.\n\n"
  },
  {
    "id": "galactic/Releaseshtml.txt",
    "content": "[ ROS 2 Documentation: Rolling ![Logo](_static/rolling-small.png)\n](index.html)\n  * [ Installation ](Installation.html)\n    * [ Ubuntu (Debian packages) ](Installation/Ubuntu-Install-Debians.html)\n    * [ Windows (binary) ](Installation/Windows-Install-Binary.html)\n    * [ RHEL (RPM packages) ](Installation/RHEL-Install-RPMs.html)\n    * [ Alternatives ](Installation/Alternatives.html)\n      * [ Ubuntu (source) ](Installation/Alternatives/Ubuntu-Development-Setup.html)\n      * [ Ubuntu (binary) ](Installation/Alternatives/Ubuntu-Install-Binary.html)\n      * [ Windows (source) ](Installation/Alternatives/Windows-Development-Setup.html)\n      * [ RHEL (source) ](Installation/Alternatives/RHEL-Development-Setup.html)\n      * [ RHEL (binary) ](Installation/Alternatives/RHEL-Install-Binary.html)\n      * [ macOS (source) ](Installation/Alternatives/macOS-Development-Setup.html)\n      * [ Latest development (source) ](Installation/Alternatives/Latest-Development-Setup.html)\n    * [ Maintain source checkout ](Installation/Maintaining-a-Source-Checkout.html)\n    * [ Testing with pre-release binaries ](Installation/Testing.html)\n    * [ DDS implementations ](Installation/DDS-Implementations.html)\n      * [ Connext security plugins ](Installation/DDS-Implementations/Install-Connext-Security-Plugins.html)\n      * [ RTI Connext DDS ](Installation/DDS-Implementations/Install-Connext-University-Eval.html)\n      * [ Eclipse Cyclone DDS ](Installation/DDS-Implementations/Working-with-Eclipse-CycloneDDS.html)\n      * [ GurumNetworks GurumDDS ](Installation/DDS-Implementations/Working-with-GurumNetworks-GurumDDS.html)\n      * [ eProsima Fast DDS ](Installation/DDS-Implementations/Working-with-eProsima-Fast-DDS.html)\n  * Distributions \n    * [ Iron Irwini ( ` iron  ` ) ](Releases/Release-Iron-Irwini.html)\n      * [ Iron Irwini Changelog ](Releases/Iron-Irwini-Complete-Changelog.html)\n    * [ Humble Hawksbill ( ` humble  ` ) ](Releases/Release-Humble-Hawksbill.html)\n      * [ Humble Hawksbill changelog ](Releases/Humble-Hawksbill-Complete-Changelog.html)\n    * [ Rolling Ridley ( ` rolling  ` ) ](Releases/Release-Rolling-Ridley.html)\n    * [ Development Distribution ](Releases/Development.html)\n      * [ Jazzy Jalisco ( ` jazzy  ` ) ](Releases/Release-Jazzy-Jalisco.html)\n    * [ End-of-Life Distributions ](Releases/End-of-Life.html)\n      * [ Galactic Geochelone ( ` galactic  ` ) ](Releases/Release-Galactic-Geochelone.html)\n        * [ Galactic Geochelone changelog ](Releases/Galactic-Geochelone-Complete-Changelog.html)\n      * [ Foxy Fitzroy ( ` foxy  ` ) ](Releases/Release-Foxy-Fitzroy.html)\n      * [ Eloquent Elusor ( ` eloquent  ` ) ](Releases/Release-Eloquent-Elusor.html)\n      * [ Dashing Diademata ( ` dashing  ` ) ](Releases/Release-Dashing-Diademata.html)\n      * [ Crystal Clemmys ( ` crystal  ` ) ](Releases/Release-Crystal-Clemmys.html)\n      * [ Bouncy Bolson ( ` bouncy  ` ) ](Releases/Release-Bouncy-Bolson.html)\n      * [ Ardent Apalone ( ` ardent  ` ) ](Releases/Release-Ardent-Apalone.html)\n      * [ Beta 3 ( ` r2b3  ` ) ](Releases/Beta3-Overview.html)\n\n\n\n      * [ Beta 2 ( ` r2b2  ` ) ](Releases/Beta2-Overview.html)\n      * [ Beta 1 ( ` Asphalt  ` ) ](Releases/Beta1-Overview.html)\n      * [ Alphas ](Releases/Alpha-Overview.html)\n    * [ Development process for a release ](Releases/Release-Process.html)\n  * [ Tutorials ](Tutorials.html)\n    * [ Beginner: CLI tools ](Tutorials/Beginner-CLI-Tools.html)\n      * [ Configuring environment ](Tutorials/Beginner-CLI-Tools/Configuring-ROS2-Environment.html)\n      * [ Using ` turtlesim  ` , ` ros2  ` , and ` rqt  ` ](Tutorials/Beginner-CLI-Tools/Introducing-Turtlesim/Introducing-Turtlesim.html)\n      * [ Understanding nodes ](Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Nodes/Understanding-ROS2-Nodes.html)\n      * [ Understanding topics ](Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Topics/Understanding-ROS2-Topics.html)\n      * [ Understanding services ](Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Services/Understanding-ROS2-Services.html)\n      * [ Understanding parameters ](Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Parameters/Understanding-ROS2-Parameters.html)\n      * [ Understanding actions ](Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Actions/Understanding-ROS2-Actions.html)\n      * [ Using ` rqt_console  ` to view logs ](Tutorials/Beginner-CLI-Tools/Using-Rqt-Console/Using-Rqt-Console.html)\n      * [ Launching nodes ](Tutorials/Beginner-CLI-Tools/Launching-Multiple-Nodes/Launching-Multiple-Nodes.html)\n      * [ Recording and playing back data ](Tutorials/Beginner-CLI-Tools/Recording-And-Playing-Back-Data/Recording-And-Playing-Back-Data.html)\n    * [ Beginner: Client libraries ](Tutorials/Beginner-Client-Libraries.html)\n      * [ Using ` colcon  ` to build packages ](Tutorials/Beginner-Client-Libraries/Colcon-Tutorial.html)\n      * [ Creating a workspace ](Tutorials/Beginner-Client-Libraries/Creating-A-Workspace/Creating-A-Workspace.html)\n      * [ Creating a package ](Tutorials/Beginner-Client-Libraries/Creating-Your-First-ROS2-Package.html)\n      * [ Writing a simple publisher and subscriber (C++) ](Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Publisher-And-Subscriber.html)\n      * [ Writing a simple publisher and subscriber (Python) ](Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html)\n      * [ Writing a simple service and client (C++) ](Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Service-And-Client.html)\n      * [ Writing a simple service and client (Python) ](Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Service-And-Client.html)\n      * [ Creating custom msg and srv files ](Tutorials/Beginner-Client-Libraries/Custom-ROS2-Interfaces.html)\n      * [ Implementing custom interfaces ](Tutorials/Beginner-Client-Libraries/Single-Package-Define-And-Use-Interface.html)\n      * [ Using parameters in a class (C++) ](Tutorials/Beginner-Client-Libraries/Using-Parameters-In-A-Class-CPP.html)\n      * [ Using parameters in a class (Python) ](Tutorials/Beginner-Client-Libraries/Using-Parameters-In-A-Class-Python.html)\n      * [ Using ` ros2doctor  ` to identify issues ](Tutorials/Beginner-Client-Libraries/Getting-Started-With-Ros2doctor.html)\n      * [ Creating and using plugins (C++) ](Tutorials/Beginner-Client-Libraries/Pluginlib.html)\n    * [ Intermediate ](Tutorials/Intermediate.html)\n      * [ Managing Dependencies with rosdep ](Tutorials/Intermediate/Rosdep.html)\n      * [ Creating an action ](Tutorials/Intermediate/Creating-an-Action.html)\n      * [ Writing an action server and client (C++) ](Tutorials/Intermediate/Writing-an-Action-Server-Client/Cpp.html)\n      * [ Writing an action server and client (Python) ](Tutorials/Intermediate/Writing-an-Action-Server-Client/Py.html)\n      * [ Writing a Composable Node (C++) ](Tutorials/Intermediate/Writing-a-Composable-Node.html)\n      * [ Composing multiple nodes in a single process ](Tutorials/Intermediate/Composition.html)\n      * [ Monitoring for parameter changes (C++) ](Tutorials/Intermediate/Monitoring-For-Parameter-Changes-CPP.html)\n      * [ Monitoring for parameter changes (Python) ](Tutorials/Intermediate/Monitoring-For-Parameter-Changes-Python.html)\n      * [ Launch ](Tutorials/Intermediate/Launch/Launch-Main.html)\n\n\n\n        * [ Creating a launch file ](Tutorials/Intermediate/Launch/Creating-Launch-Files.html)\n        * [ Integrating launch files into ROS 2 packages ](Tutorials/Intermediate/Launch/Launch-system.html)\n        * [ Using substitutions ](Tutorials/Intermediate/Launch/Using-Substitutions.html)\n        * [ Using event handlers ](Tutorials/Intermediate/Launch/Using-Event-Handlers.html)\n        * [ Managing large projects ](Tutorials/Intermediate/Launch/Using-ROS2-Launch-For-Large-Projects.html)\n      * [ ` tf2  ` ](Tutorials/Intermediate/Tf2/Tf2-Main.html)\n        * [ Introducing ` tf2  ` ](Tutorials/Intermediate/Tf2/Introduction-To-Tf2.html)\n        * [ Writing a static broadcaster (Python) ](Tutorials/Intermediate/Tf2/Writing-A-Tf2-Static-Broadcaster-Py.html)\n        * [ Writing a static broadcaster (C++) ](Tutorials/Intermediate/Tf2/Writing-A-Tf2-Static-Broadcaster-Cpp.html)\n        * [ Writing a broadcaster (Python) ](Tutorials/Intermediate/Tf2/Writing-A-Tf2-Broadcaster-Py.html)\n        * [ Writing a broadcaster (C++) ](Tutorials/Intermediate/Tf2/Writing-A-Tf2-Broadcaster-Cpp.html)\n        * [ Writing a listener (Python) ](Tutorials/Intermediate/Tf2/Writing-A-Tf2-Listener-Py.html)\n        * [ Writing a listener (C++) ](Tutorials/Intermediate/Tf2/Writing-A-Tf2-Listener-Cpp.html)\n        * [ Adding a frame (Python) ](Tutorials/Intermediate/Tf2/Adding-A-Frame-Py.html)\n        * [ Adding a frame (C++) ](Tutorials/Intermediate/Tf2/Adding-A-Frame-Cpp.html)\n        * [ Using time (Python) ](Tutorials/Intermediate/Tf2/Learning-About-Tf2-And-Time-Py.html)\n        * [ Using time (C++) ](Tutorials/Intermediate/Tf2/Learning-About-Tf2-And-Time-Cpp.html)\n        * [ Traveling in time (Python) ](Tutorials/Intermediate/Tf2/Time-Travel-With-Tf2-Py.html)\n        * [ Traveling in time (C++) ](Tutorials/Intermediate/Tf2/Time-Travel-With-Tf2-Cpp.html)\n        * [ Debugging ](Tutorials/Intermediate/Tf2/Debugging-Tf2-Problems.html)\n        * [ Quaternion fundamentals ](Tutorials/Intermediate/Tf2/Quaternion-Fundamentals.html)\n        * [ Using stamped datatypes with ` tf2_ros::MessageFilter  ` ](Tutorials/Intermediate/Tf2/Using-Stamped-Datatypes-With-Tf2-Ros-MessageFilter.html)\n      * [ Testing ](Tutorials/Intermediate/Testing/Testing-Main.html)\n        * [ Running Tests in ROS 2 from the Command Line ](Tutorials/Intermediate/Testing/CLI.html)\n        * [ Writing Basic Tests with C++ with GTest ](Tutorials/Intermediate/Testing/Cpp.html)\n        * [ Writing Basic Tests with Python ](Tutorials/Intermediate/Testing/Python.html)\n      * [ URDF ](Tutorials/Intermediate/URDF/URDF-Main.html)\n        * [ Building a visual robot model from scratch ](Tutorials/Intermediate/URDF/Building-a-Visual-Robot-Model-with-URDF-from-Scratch.html)\n        * [ Building a movable robot model ](Tutorials/Intermediate/URDF/Building-a-Movable-Robot-Model-with-URDF.html)\n        * [ Adding physical and collision properties ](Tutorials/Intermediate/URDF/Adding-Physical-and-Collision-Properties-to-a-URDF-Model.html)\n        * [ Using Xacro to clean up your code ](Tutorials/Intermediate/URDF/Using-Xacro-to-Clean-Up-a-URDF-File.html)\n        * [ Using URDF with ` robot_state_publisher  ` ](Tutorials/Intermediate/URDF/Using-URDF-with-Robot-State-Publisher.html)\n        * [ Generating an URDF File ](Tutorials/Intermediate/URDF/Exporting-an-URDF-File.html)\n      * [ RViz ](Tutorials/Intermediate/RViz/RViz-Main.html)\n        * [ RViz User Guide ](Tutorials/Intermediate/RViz/RViz-User-Guide/RViz-User-Guide.html)\n        * [ Building a Custom RViz Display ](Tutorials/Intermediate/RViz/RViz-Custom-Display/RViz-Custom-Display.html)\n    * [ Advanced ](Tutorials/Advanced.html)\n      * [ Enabling topic statistics (C++) ](Tutorials/Advanced/Topic-Statistics-Tutorial/Topic-Statistics-Tutorial.html)\n      * [ Using Fast DDS Discovery Server as discovery protocol [community-contributed] ](Tutorials/Advanced/Discovery-Server/Discovery-Server.html)\n      * [ Implementing a custom memory allocator ](Tutorials/Advanced/Allocator-Template-Tutorial.html)\n\n\n\n      * [ Unlocking the potential of Fast DDS middleware [community-contributed] ](Tutorials/Advanced/FastDDS-Configuration.html)\n      * [ Improved Dynamic Discovery ](Tutorials/Advanced/Improved-Dynamic-Discovery.html)\n      * [ Recording a bag from a node (C++) ](Tutorials/Advanced/Recording-A-Bag-From-Your-Own-Node-CPP.html)\n      * [ Recording a bag from a node (Python) ](Tutorials/Advanced/Recording-A-Bag-From-Your-Own-Node-Py.html)\n      * [ Reading from a bag file (C++) ](Tutorials/Advanced/Reading-From-A-Bag-File-CPP.html)\n      * [ How to use ros2_tracing to trace and analyze an application ](Tutorials/Advanced/ROS2-Tracing-Trace-and-Analyze.html)\n      * [ Simulators ](Tutorials/Advanced/Simulators/Simulation-Main.html)\n        * [ Webots ](Tutorials/Advanced/Simulators/Webots/Simulation-Webots.html)\n          * [ Installation (Ubuntu) ](Tutorials/Advanced/Simulators/Webots/Installation-Ubuntu.html)\n          * [ Installation (Windows) ](Tutorials/Advanced/Simulators/Webots/Installation-Windows.html)\n          * [ Installation (macOS) ](Tutorials/Advanced/Simulators/Webots/Installation-MacOS.html)\n          * [ Setting up a robot simulation (Basic) ](Tutorials/Advanced/Simulators/Webots/Setting-Up-Simulation-Webots-Basic.html)\n          * [ Setting up a robot simulation (Advanced) ](Tutorials/Advanced/Simulators/Webots/Setting-Up-Simulation-Webots-Advanced.html)\n          * [ Setting up a Reset Handler ](Tutorials/Advanced/Simulators/Webots/Simulation-Reset-Handler.html)\n          * [ The Ros2Supervisor Node ](Tutorials/Advanced/Simulators/Webots/Simulation-Supervisor.html)\n        * [ Gazebo ](Tutorials/Advanced/Simulators/Gazebo/Simulation-Gazebo.html)\n          * [ Setting up a robot simulation (Gazebo) ](Tutorials/Advanced/Simulators/Gazebo/Gazebo.html)\n      * [ Security ](Tutorials/Advanced/Security/Security-Main.html)\n        * [ Setting up security ](Tutorials/Advanced/Security/Introducing-ros2-security.html)\n        * [ Understanding the security keystore ](Tutorials/Advanced/Security/The-Keystore.html)\n        * [ Ensuring security across machines ](Tutorials/Advanced/Security/Security-on-Two.html)\n        * [ Examining network traffic ](Tutorials/Advanced/Security/Examine-Traffic.html)\n        * [ Setting access controls ](Tutorials/Advanced/Security/Access-Controls.html)\n        * [ Deployment Guidelines ](Tutorials/Advanced/Security/Deployment-Guidelines.html)\n    * [ Demos ](Tutorials/Demos.html)\n      * [ Using quality-of-service settings for lossy networks ](Tutorials/Demos/Quality-of-Service.html)\n      * [ Managing nodes with managed lifecycles ](Tutorials/Demos/Managed-Nodes.html)\n      * [ Setting up efficient intra-process communication ](Tutorials/Demos/Intra-Process-Communication.html)\n      * [ Recording and playing back data with ` rosbag  ` using the ROS 1 bridge ](Tutorials/Demos/Rosbag-with-ROS1-Bridge.html)\n      * [ Understanding real-time programming ](Tutorials/Demos/Real-Time-Programming.html)\n      * [ Experimenting with a dummy robot ](Tutorials/Demos/dummy-robot-demo.html)\n      * [ Logging ](Tutorials/Demos/Logging-and-logger-configuration.html)\n      * [ Creating a content filtering subscription ](Tutorials/Demos/Content-Filtering-Subscription.html)\n      * [ Configure service introspection ](Tutorials/Demos/Service-Introspection.html)\n    * [ Miscellaneous ](Tutorials/Miscellaneous.html)\n      * [ Deploying on IBM Cloud Kubernetes [community-contributed] ](Tutorials/Miscellaneous/Deploying-ROS-2-on-IBM-Cloud.html)\n      * [ Using Eclipse Oxygen with ` rviz2  ` [community-contributed] ](Tutorials/Miscellaneous/Eclipse-Oxygen-with-ROS-2-and-rviz2.html)\n      * [ Building a real-time Linux kernel [community-contributed] ](Tutorials/Miscellaneous/Building-Realtime-rt_preempt-kernel-for-ROS-2.html)\n      * [ Building a package with Eclipse 2021-06 ](Tutorials/Miscellaneous/Building-ROS2-Package-with-eclipse-2021-06.html)\n  * [ How-to Guides ](How-To-Guides.html)\n\n\n\n    * [ Installation troubleshooting ](How-To-Guides/Installation-Troubleshooting.html)\n    * [ Developing a ROS 2 package ](How-To-Guides/Developing-a-ROS-2-Package.html)\n    * [ Documenting a ROS 2 package ](How-To-Guides/Documenting-a-ROS-2-Package.html)\n    * [ ament_cmake user documentation ](How-To-Guides/Ament-CMake-Documentation.html)\n    * [ ament_cmake_python user documentation ](How-To-Guides/Ament-CMake-Python-Documentation.html)\n    * [ Migrating from ROS 1 to ROS 2 ](How-To-Guides/Migrating-from-ROS1.html)\n      * [ Migrating Packages ](How-To-Guides/Migrating-from-ROS1/Migrating-Packages.html)\n      * [ Migrating Interfaces ](How-To-Guides/Migrating-from-ROS1/Migrating-Interfaces.html)\n      * [ Migrating C++ Packages ](How-To-Guides/Migrating-from-ROS1/Migrating-CPP-Packages.html)\n      * [ Migrating Python Packages ](How-To-Guides/Migrating-from-ROS1/Migrating-Python-Packages.html)\n      * [ Migrating Launch Files ](How-To-Guides/Migrating-from-ROS1/Migrating-Launch-Files.html)\n      * [ Migrating Parameters ](How-To-Guides/Migrating-from-ROS1/Migrating-Parameters.html)\n      * [ Migrating Scripts ](How-To-Guides/Migrating-from-ROS1/Migrating-Scripts.html)\n    * [ Using Python, XML, and YAML for ROS 2 Launch Files ](How-To-Guides/Launch-file-different-formats.html)\n    * [ Using ROS 2 launch to launch composable nodes ](How-To-Guides/Launching-composable-nodes.html)\n    * [ Passing ROS arguments to nodes via the command-line ](How-To-Guides/Node-arguments.html)\n    * [ Synchronous vs. asynchronous service clients ](How-To-Guides/Sync-Vs-Async.html)\n    * [ DDS tuning information ](How-To-Guides/DDS-tuning.html)\n    * [ rosbag2: Overriding QoS Policies ](How-To-Guides/Overriding-QoS-Policies-For-Recording-And-Playback.html)\n    * [ Working with multiple ROS 2 middleware implementations ](How-To-Guides/Working-with-multiple-RMW-implementations.html)\n    * [ Cross-compilation ](How-To-Guides/Cross-compilation.html)\n    * [ Releasing a Package ](How-To-Guides/Releasing/Releasing-a-Package.html)\n      * [ First Time Release ](How-To-Guides/Releasing/First-Time-Release.html)\n      * [ Subsequent Releases ](How-To-Guides/Releasing/Subsequent-Releases.html)\n      * [ Release Team / Repository ](How-To-Guides/Releasing/Release-Team-Repository.html)\n      * [ Release Track ](How-To-Guides/Releasing/Release-Track.html)\n    * [ Using Python Packages with ROS 2 ](How-To-Guides/Using-Python-Packages.html)\n    * [ Porting RQt plugins to Windows ](How-To-Guides/RQt-Port-Plugin-Windows.html)\n    * [ Running ROS 2 nodes in Docker [community-contributed] ](How-To-Guides/Run-2-nodes-in-single-or-separate-docker-containers.html)\n    * [ Visualizing ROS 2 data with Foxglove Studio ](How-To-Guides/Visualizing-ROS-2-Data-With-Foxglove-Studio.html)\n    * [ ROS 2 Package Maintainer Guide ](How-To-Guides/Package-maintainer-guide.html)\n    * [ Building a custom Debian package ](How-To-Guides/Building-a-Custom-Debian-Package.html)\n    * [ Building ROS 2 with tracing ](How-To-Guides/Building-ROS-2-with-Tracing.html)\n    * [ Topics vs Services vs Actions ](How-To-Guides/Topics-Services-Actions.html)\n    * [ Using variants ](How-To-Guides/Using-Variants.html)\n    * [ Using the ` ros2  param  ` command-line tool ](How-To-Guides/Using-ros2-param.html)\n    * [ Using ` ros1_bridge  ` with upstream ROS on Ubuntu 22.04 ](How-To-Guides/Using-ros1_bridge-Jammy-upstream.html)\n    * [ Configure Zero Copy Loaned Messages ](How-To-Guides/Configure-ZeroCopy-loaned-messages.html)\n    * [ ROS 2 on Raspberry Pi ](How-To-Guides/Installing-on-Raspberry-Pi.html)\n    * [ Using Callback Groups ](How-To-Guides/Using-callback-groups.html)\n\n\n\n    * [ IDEs and Debugging [community-contributed] ](How-To-Guides/ROS-2-IDEs.html)\n    * [ Setup ROS 2 with VSCode and Docker [community-contributed] ](How-To-Guides/Setup-ROS-2-with-VSCode-and-Docker-Container.html)\n    * [ Using Custom Rosdistro Version ](How-To-Guides/Using-Custom-Rosdistro.html)\n    * [ Building RQt from source ](How-To-Guides/RQt-Source-Install.html)\n      * [ Building RQt from source on macOS ](How-To-Guides/RQt-Source-Install-MacOS.html)\n      * [ Building RQt from source on Windows 10 ](How-To-Guides/RQt-Source-Install-Windows10.html)\n  * [ Concepts ](Concepts.html)\n    * [ Basic Concepts ](Concepts/Basic.html)\n      * [ Nodes ](Concepts/Basic/About-Nodes.html)\n      * [ Discovery ](Concepts/Basic/About-Discovery.html)\n      * [ Interfaces ](Concepts/Basic/About-Interfaces.html)\n      * [ Topics ](Concepts/Basic/About-Topics.html)\n      * [ Services ](Concepts/Basic/About-Services.html)\n      * [ Actions ](Concepts/Basic/About-Actions.html)\n      * [ Parameters ](Concepts/Basic/About-Parameters.html)\n      * [ Introspection with command line tools ](Concepts/Basic/About-Command-Line-Tools.html)\n      * [ Launch ](Concepts/Basic/About-Launch.html)\n      * [ Client libraries ](Concepts/Basic/About-Client-Libraries.html)\n    * [ Intermediate Concepts ](Concepts/Intermediate.html)\n      * [ The ROS_DOMAIN_ID ](Concepts/Intermediate/About-Domain-ID.html)\n      * [ Different ROS 2 middleware vendors ](Concepts/Intermediate/About-Different-Middleware-Vendors.html)\n      * [ Logging and logger configuration ](Concepts/Intermediate/About-Logging.html)\n      * [ Quality of Service settings ](Concepts/Intermediate/About-Quality-of-Service-Settings.html)\n      * [ Executors ](Concepts/Intermediate/About-Executors.html)\n      * [ Topic statistics ](Concepts/Intermediate/About-Topic-Statistics.html)\n      * [ Overview and usage of RQt ](Concepts/Intermediate/About-RQt.html)\n      * [ Composition ](Concepts/Intermediate/About-Composition.html)\n      * [ Cross-compilation ](Concepts/Intermediate/About-Cross-Compilation.html)\n      * [ ROS 2 Security ](Concepts/Intermediate/About-Security.html)\n      * [ Tf2 ](Concepts/Intermediate/About-Tf2.html)\n    * [ Advanced Concepts ](Concepts/Advanced.html)\n      * [ The build system ](Concepts/Advanced/About-Build-System.html)\n      * [ Internal ROS 2 interfaces ](Concepts/Advanced/About-Internal-Interfaces.html)\n      * [ ROS 2 middleware implementations ](Concepts/Advanced/About-Middleware-Implementations.html)\n  * [ Contact ](Contact.html)\n  * [ The ROS 2 Project ](The-ROS2-Project.html)\n    * [ Contributing ](The-ROS2-Project/Contributing.html)\n      * [ ROS 2 developer guide ](The-ROS2-Project/Contributing/Developer-Guide.html)\n      * [ Code style and language versions ](The-ROS2-Project/Contributing/Code-Style-Language-Versions.html)\n      * [ Quality guide: ensuring code quality ](The-ROS2-Project/Contributing/Quality-Guide.html)\n\n\n\n      * [ ROS Build Farms ](The-ROS2-Project/Contributing/Build-Farms.html)\n      * [ Windows Tips and Tricks ](The-ROS2-Project/Contributing/Windows-Tips-and-Tricks.html)\n      * [ Contributing to ROS 2 Documentation ](The-ROS2-Project/Contributing/Contributing-To-ROS-2-Documentation.html)\n    * [ Features Status ](The-ROS2-Project/Features.html)\n    * [ Feature Ideas ](The-ROS2-Project/Feature-Ideas.html)\n    * [ Roadmap ](The-ROS2-Project/Roadmap.html)\n    * [ ROSCon Talks ](The-ROS2-Project/ROSCon-Content.html)\n    * [ Project Governance ](The-ROS2-Project/Governance.html)\n      * [ ROS 2 Technical Steering Committee Charter ](The-ROS2-Project/Governance/ROS2-TSC-Charter.html)\n      * [ ROS 2 TSC applicant intake process ](The-ROS2-Project/Governance/ROS2-TSC-Intake-process.html)\n      * [ About Working Groups ](The-ROS2-Project/Governance/Working-Groups.html)\n      * [ How to Start a Community Working Group ](The-ROS2-Project/Governance/How-To-Start-A-Community-Working-Group.html)\n    * [ Marketing ](The-ROS2-Project/Marketing.html)\n    * [ Metrics ](The-ROS2-Project/Metrics.html)\n  * [ API Documentation ](API-Docs.html)\n  * [ Related Projects ](Related-Projects.html)\n    * [ Intel ROS 2 Projects ](Related-Projects/Intel-ROS2-Projects.html)\n    * [ NVIDIA ROS 2 Projects ](Related-Projects/Nvidia-ROS2-Projects.html)\n  * [ Glossary ](Glossary.html)\n  * [ Citations ](Citations.html)\n__ [ ROS 2 Documentation: Rolling ](index.html)\n  * [ ](index.html)\n  * Distributions \n  * [ Edit on GitHub ](https://github.com/ros2/ros2_documentation/blob/rolling/source/Releases.rst)\n* * *\n**You're reading the documentation for a development version. For the latest\nreleased version, please have a look at[ Iron ](../iron/Releases.html) . **\n#  Distributions  \u00ef\u0083\u0081\n##  What is a Distribution?  \u00ef\u0083\u0081\nA ROS distribution is a versioned set of ROS packages. These are akin to Linux\ndistributions (e.g. Ubuntu). The purpose of the ROS distributions is to let\ndevelopers work against a relatively stable codebase until they are ready to\nroll everything forward. Therefore once a distribution is released, we try to\nlimit changes to bug fixes and non-breaking improvements for the core packages\n(every thing under ros-desktop-full). That generally applies to the whole\ncommunity, but for \u00e2\u0080\u009chigher\u00e2\u0080\u009d level packages, the rules are less strict, and\nso it falls to the maintainers of a given package to avoid breaking changes.\n##  List of Distributions  \u00ef\u0083\u0081\nBelow is a list of current and historic ROS 2 distributions. Rows in the table\nmarked in green are the currently supported distributions.\n\n\n\nDistro\n|\nRelease date\n|\nLogo\n|\nEOL date  \n  \n---|---|---|---  \n  \n[ Iron Irwini  ](Releases/Release-Iron-Irwini.html)\n|\nMay 23rd, 2023\n|\n![Iron logo](_images/iron-small.png)\n|\nNovember 2024  \n  \n[ Humble Hawksbill  ](Releases/Release-Humble-Hawksbill.html)\n|\nMay 23rd, 2022\n|\n![Humble logo](_images/humble-small.png)\n|\nMay 2027  \n  \n[ Galactic Geochelone  ](Releases/Release-Galactic-Geochelone.html)\n|\nMay 23rd, 2021\n|\n![Galactic logo](_images/galactic-small.png)\n|\nDecember 9th, 2022  \n  \n[ Foxy Fitzroy  ](Releases/Release-Foxy-Fitzroy.html)\n|\nJune 5th, 2020\n|\n![Foxy logo](_images/foxy-small.png)\n|\n\n\n\nJune 20th, 2023  \n  \n[ Eloquent Elusor  ](Releases/Release-Eloquent-Elusor.html)\n|\nNovember 22nd, 2019\n|\n![Eloquent logo](_images/eloquent-small.png)\n|\nNovember 2020  \n  \n[ Dashing Diademata  ](Releases/Release-Dashing-Diademata.html)\n|\nMay 31st, 2019\n|\n![Dashing logo](_images/dashing-small.png)\n|\nMay 2021  \n  \n[ Crystal Clemmys  ](Releases/Release-Crystal-Clemmys.html)\n|\nDecember 14th, 2018\n|\n![Crystal logo](_images/crystal-small.png)\n|\nDecember 2019  \n  \n[ Bouncy Bolson  ](Releases/Release-Bouncy-Bolson.html)\n|\nJuly 2nd, 2018\n|\n![Bouncy logo](_images/bouncy-small.png)\n|\nJuly 2019  \n  \n[ Ardent Apalone  ](Releases/Release-Ardent-Apalone.html)\n|\nDecember 8th, 2017\n|\n![Ardent logo](_images/ardent-small.png)\n|\n\n\n\nDecember 2018  \n  \n[ beta3  ](Releases/Beta3-Overview.html)\n|\nSeptember 13th, 2017\n|  |\nDecember 2017  \n  \n[ beta2  ](Releases/Beta2-Overview.html)\n|\nJuly 5th, 2017\n|  |\nSeptember 2017  \n  \n[ beta1  ](Releases/Beta1-Overview.html)\n|\nDecember 19th, 2016\n|  |\nJul 2017  \n  \n[ alpha1 - alpha8  ](Releases/Alpha-Overview.html)\n|\nAugust 31th, 2015\n|  |\nDecember 2016  \n  \n##  Future Distributions  \u00ef\u0083\u0081\nFor details on upcoming features see the [ roadmap  ](The-\nROS2-Project/Roadmap.html) .\nThere is a new ROS 2 distribution released yearly on May 23rd ( [ World Turtle\nDay ](https://www.worldturtleday.org/) ).\nDistro\n|\nRelease date\n|\nLogo\n|\nEOL date  \n  \n---|---|---|---  \n\n\n\n  \n[ Jazzy Jalisco  ](Releases/Release-Jazzy-Jalisco.html)\n|\nMay 2024\n|\nTBD\n|\nMay 2029  \n  \n##  Rolling Distribution  \u00ef\u0083\u0081\n[ ROS 2 Rolling Ridley  ](Releases/Release-Rolling-Ridley.html) is the rolling\ndevelopment distribution of ROS 2. It is described in [ REP 2002\n](https://www.ros.org/reps/rep-2002.html) and was first introduced in June\n2020.\nThe Rolling distribution of ROS 2 serves two purposes:\n  1. it is a staging area for future stable distributions of ROS 2, and \n  2. it is a collection of the most recent development releases. \nAs the name implies, Rolling is continuously updated and **can have in-place\nupdates that include breaking changes** . We recommend that most people use\nthe most recent stable distribution instead (see  List of Distributions  ).\nPackages released into the Rolling distribution will be automatically released\ninto future stable distributions of ROS 2. [ Releasing a ROS 2 package  ](How-\nTo-Guides/Releasing/Releasing-a-Package.html) into the Rolling distribution\nfollows the same procedures as all other ROS 2 distributions.\n[ Previous ](Installation/DDS-Implementations/Working-with-eProsima-Fast-\nDDS.html \"eProsima Fast DDS\") [ Next  ](Releases/Release-Iron-Irwini.html\n\"Iron Irwini \\(iron\\)\")\n* * *\n\u00a9 Copyright 2024, Open Robotics.\nBuilt with [ Sphinx ](https://www.sphinx-doc.org/) using a [ theme\n](https://github.com/readthedocs/sphinx_rtd_theme) provided by [ Read the Docs\n](https://readthedocs.org) .\nOther Versions  v: rolling\nReleases\n     [ Iron (latest) ](../iron/Releases.html)\n     [ Humble ](../humble/Releases.html)\n     [ Galactic (EOL) ](../galactic/Releases.html)\n     [ Foxy (EOL) ](../foxy/Releases.html)\n     [ Eloquent (EOL) ](../eloquent/Releases.html)\n     [ Dashing (EOL) ](../dashing/Releases.html)\n\n\n\n     [ Crystal (EOL) ](../crystal/Releases.html)\nIn Development\n     [ Rolling ](Releases.html)\n\n\n"
  },
  {
    "id": "takeoff_rotation/transformationshtml.txt",
    "content": "###  Navigation\n  * [ index ](genindex.html \"General Index\")\n  * [ modules ](py-modindex.html \"Python Module Index\") | \n  * [ previous ](tf_python.html \"tf \\(Python\\)\") | \n  * [ tf 0.1.0 documentation ](index.html) \u00bb \n#  transformations  \u00c2\u00b6\nHomogeneous Transformation Matrices and Quaternions.\nA library for calculating 4x4 matrices for translating, rotating, reflecting,\nscaling, shearing, projecting, orthogonalizing, and superimposing arrays of 3D\nhomogeneous coordinates as well as for converting between rotation matrices,\nEuler angles, and quaternions. Also includes an Arcball control object and\nfunctions to decompose transformation matrices.\nAuthors:  |  [ Christoph Gohlke ](http://www.lfd.uci.edu/~gohlke/) ,\nLaboratory for Fluorescence Dynamics, University of California, Irvine  \n---|---  \nVersion:  |  20090418  \n  \n##  Requirements  \u00c2\u00b6\n  * [ Python 2.6 ](http://www.python.org)\n  * [ Numpy 1.3 ](http://numpy.scipy.org)\n  * [ transformations.c 20090418 ](http://www.lfd.uci.edu/~gohlke/) (optional implementation of some functions in C) \n##  Notes  \u00c2\u00b6\nMatrices (M) can be inverted using numpy.linalg.inv(M), concatenated using\nnumpy.dot(M0, M1), or used to transform homogeneous coordinates (v) using\nnumpy.dot(M, v) for shape (4, *) \u201cpoint of arrays\u201d, respectively numpy.dot(v,\nM.T) for shape (*, 4) \u201carray of points\u201d.\nCalculations are carried out with numpy.float64 precision.\nThis Python implementation is not optimized for speed.\nVector, point, quaternion, and matrix function arguments are expected to be\n\u201carray like\u201d, i.e. tuple, list, or numpy arrays.\nReturn types are numpy arrays unless specified otherwise.\nAngles are in radians unless specified otherwise.\nQuaternions ix+jy+kz+w are represented as [x, y, z, w].\nUse the transpose of transformation matrices for OpenGL glMultMatrixd().\nA triple of Euler angles can be applied/interpreted in 24 ways, which can be\nspecified using a 4 character string or encoded 4-tuple:\n> _Axes 4-string_ : e.g. \u2018sxyz\u2019 or \u2018ryxy\u2019\n>\n>   * first character : rotations are applied to \u2018s\u2019tatic or \u2018r\u2019otating frame\n>   * remaining characters : successive rotation axis \u2018x\u2019, \u2018y\u2019, or \u2018z\u2019\n\n\n\n>\n>\n> _Axes 4-tuple_ : e.g. (0, 0, 0, 0) or (1, 1, 1, 1)\n>\n>   * inner axis: code of axis (\u2018x\u2019:0, \u2018y\u2019:1, \u2018z\u2019:2) of rightmost matrix.\n>   * parity : even (0) if inner axis \u2018x\u2019 is followed by \u2018y\u2019, \u2018y\u2019 is followed\n> by \u2018z\u2019, or \u2018z\u2019 is followed by \u2018x\u2019. Otherwise odd (1).\n>   * repetition : first and last axis are same (1) or different (0).\n>   * frame : rotations are applied to static (0) or rotating (1) frame.\n>\n##  References  \u00c2\u00b6\n  1. Matrices and transformations. Ronald Goldman. In \u201cGraphics Gems I\u201d, pp 472-475. Morgan Kaufmann, 1990. \n  2. More matrices and transformations: shear and pseudo-perspective. Ronald Goldman. In \u201cGraphics Gems II\u201d, pp 320-323. Morgan Kaufmann, 1991. \n  3. Decomposing a matrix into simple transformations. Spencer Thomas. In \u201cGraphics Gems II\u201d, pp 320-323. Morgan Kaufmann, 1991. \n  4. Recovering the data from the transformation matrix. Ronald Goldman. In \u201cGraphics Gems II\u201d, pp 324-331. Morgan Kaufmann, 1991. \n  5. Euler angle conversion. Ken Shoemake. In \u201cGraphics Gems IV\u201d, pp 222-229. Morgan Kaufmann, 1994. \n  6. Arcball rotation control. Ken Shoemake. In \u201cGraphics Gems IV\u201d, pp 175-192. Morgan Kaufmann, 1994. \n  7. Representing attitude: Euler angles, unit quaternions, and rotation vectors. James Diebel. 2006. \n  8. A discussion of the solution for the best rotation to relate two sets of vectors. W Kabsch. Acta Cryst. 1978. A34, 827-828. \n  9. Closed-form solution of absolute orientation using unit quaternions. BKP Horn. J Opt Soc Am A. 1987. 4(4), 629-642. \n  10. Quaternions. Ken Shoemake. [ http://www.sfu.ca/~jwa3/cmpt461/files/quatut.pdf ](http://www.sfu.ca/~jwa3/cmpt461/files/quatut.pdf)\n  11. From quaternion to matrix and back. JMP van Waveren. 2005. [ http://www.intel.com/cd/ids/developer/asmo-na/eng/293748.htm ](http://www.intel.com/cd/ids/developer/asmo-na/eng/293748.htm)\n  12. Uniform random rotations. Ken Shoemake. In \u201cGraphics Gems III\u201d, pp 124-132. Morgan Kaufmann, 1992. \n##  Examples  \u00c2\u00b6\n    \n    \n    >>> alpha, beta, gamma = 0.123, -1.234, 2.345\n    >>> origin, xaxis, yaxis, zaxis = (0, 0, 0), (1, 0, 0), (0, 1, 0), (0, 0, 1)\n    >>> I = identity_matrix()\n    >>> Rx = rotation_matrix(alpha, xaxis)\n    >>> Ry = rotation_matrix(beta, yaxis)\n    >>> Rz = rotation_matrix(gamma, zaxis)\n    >>> R = concatenate_matrices(Rx, Ry, Rz)\n    >>> euler = euler_from_matrix(R, 'rxyz')\n    >>> numpy.allclose([alpha, beta, gamma], euler)\n    True\n    >>> Re = euler_matrix(alpha, beta, gamma, 'rxyz')\n    >>> is_same_transform(R, Re)\n    True\n    >>> al, be, ga = euler_from_matrix(Re, 'rxyz')\n\n\n\n    >>> is_same_transform(Re, euler_matrix(al, be, ga, 'rxyz'))\n    True\n    >>> qx = quaternion_about_axis(alpha, xaxis)\n    >>> qy = quaternion_about_axis(beta, yaxis)\n    >>> qz = quaternion_about_axis(gamma, zaxis)\n    >>> q = quaternion_multiply(qx, qy)\n    >>> q = quaternion_multiply(q, qz)\n    >>> Rq = quaternion_matrix(q)\n    >>> is_same_transform(R, Rq)\n    True\n    >>> S = scale_matrix(1.23, origin)\n    >>> T = translation_matrix((1, 2, 3))\n    >>> Z = shear_matrix(beta, xaxis, origin, zaxis)\n    >>> R = random_rotation_matrix(numpy.random.rand(3))\n    >>> M = concatenate_matrices(T, R, Z, S)\n    >>> scale, shear, angles, trans, persp = decompose_matrix(M)\n    >>> numpy.allclose(scale, 1.23)\n    True\n    >>> numpy.allclose(trans, (1, 2, 3))\n    True\n    >>> numpy.allclose(shear, (0, math.tan(beta), 0))\n    True\n    >>> is_same_transform(R, euler_matrix(axes='sxyz', *angles))\n    True\n    >>> M1 = compose_matrix(scale, shear, angles, trans, persp)\n    >>> is_same_transform(M, M1)\n    True\n    \n_class_ ` tf.transformations. ` ` Arcball ` (  _initial=None_ )  \u00c2\u00b6\n    \nVirtual Trackball Control.\n    \n    \n    >>> ball = Arcball()\n    >>> ball = Arcball(initial=numpy.identity(4))\n    >>> ball.place([320, 320], 320)\n    >>> ball.down([500, 250])\n    >>> ball.drag([475, 275])\n    >>> R = ball.matrix()\n    >>> numpy.allclose(numpy.sum(R), 3.90583455)\n\n\n\n    True\n    >>> ball = Arcball(initial=[0, 0, 0, 1])\n    >>> ball.place([320, 320], 320)\n    >>> ball.setaxes([1,1,0], [-1, 1, 0])\n    >>> ball.setconstrain(True)\n    >>> ball.down([400, 200])\n    >>> ball.drag([200, 400])\n    >>> R = ball.matrix()\n    >>> numpy.allclose(numpy.sum(R), 0.2055924)\n    True\n    >>> ball.next()\n    \n` down ` (  _point_ )  \u00c2\u00b6\n    \nSet initial cursor window coordinates and pick constrain-axis.\n` drag ` (  _point_ )  \u00c2\u00b6\n    \nUpdate current cursor window coordinates.\n` getconstrain ` (  )  \u00c2\u00b6\n    \nReturn state of constrain to axis mode.\n` matrix ` (  )  \u00c2\u00b6\n    \nReturn homogeneous rotation matrix.\n` next ` (  _acceleration=0.0_ )  \u00c2\u00b6\n    \nContinue rotation in direction of last drag.\n` place ` (  _center_ , _radius_ )  \u00c2\u00b6\n    \nPlace Arcball, e.g. when window size changes.\ncenter  :  sequence[2]\n     Window coordinates of trackball center. \nradius  :  float\n     Radius of trackball in window coordinates. \n` setaxes ` (  _*axes_ )  \u00c2\u00b6\n    \nSet axes to constrain rotations.\n` setconstrain ` (  _constrain_ )  \u00c2\u00b6\n    \nSet state of constrain to axis mode.\n\n\n\n` tf.transformations. ` ` arcball_constrain_to_axis ` (  _point_ , _axis_ )\n\u00c2\u00b6\n    \nReturn sphere point perpendicular to axis.\n` tf.transformations. ` ` arcball_map_to_sphere ` (  _point_ , _center_ ,\n_radius_ )  \u00c2\u00b6\n    \nReturn unit sphere coordinates from window coordinates.\n` tf.transformations. ` ` arcball_nearest_axis ` (  _point_ , _axes_ )  \u00c2\u00b6\n    \nReturn axis, which arc is nearest to point.\n` tf.transformations. ` ` clip_matrix ` (  _left_ , _right_ , _bottom_ , _top_\n, _near_ , _far_ , _perspective=False_ )  \u00c2\u00b6\n    \nReturn matrix to obtain normalized device coordinates from frustrum.\nThe frustrum bounds are axis-aligned along x (left, right), y (bottom, top)\nand z (near, far).\nNormalized device coordinates are in range [-1, 1] if coordinates are inside\nthe frustrum.\nIf perspective is True the frustrum is a truncated pyramid with the\nperspective point at origin and direction along z axis, otherwise an\northographic canonical view volume (a box).\nHomogeneous coordinates transformed by the perspective clip matrix need to be\ndehomogenized (devided by w coordinate).\n    \n    \n    >>> frustrum = numpy.random.rand(6)\n    >>> frustrum[1] += frustrum[0]\n    >>> frustrum[3] += frustrum[2]\n    >>> frustrum[5] += frustrum[4]\n    >>> M = clip_matrix(*frustrum, perspective=False)\n    >>> numpy.dot(M, [frustrum[0], frustrum[2], frustrum[4], 1.0])\n    array([-1., -1., -1.,  1.])\n    >>> numpy.dot(M, [frustrum[1], frustrum[3], frustrum[5], 1.0])\n    array([ 1.,  1.,  1.,  1.])\n    >>> M = clip_matrix(*frustrum, perspective=True)\n    >>> v = numpy.dot(M, [frustrum[0], frustrum[2], frustrum[4], 1.0])\n    >>> v / v[3]\n    array([-1., -1., -1.,  1.])\n    >>> v = numpy.dot(M, [frustrum[1], frustrum[3], frustrum[4], 1.0])\n\n\n\n    >>> v / v[3]\n    array([ 1.,  1., -1.,  1.])\n    \n` tf.transformations. ` ` compose_matrix ` (  _scale=None_ , _shear=None_ ,\n_angles=None_ , _translate=None_ , _perspective=None_ )  \u00c2\u00b6\n    \nReturn transformation matrix from sequence of transformations.\nThis is the inverse of the decompose_matrix function.\nSequence of transformations:\n     scale : vector of 3 scaling factors shear : list of shear factors for x-y, x-z, y-z axes angles : list of Euler angles about static x, y, z axes translate : translation vector along x, y, z axes perspective : perspective partition of matrix \n    \n    \n    >>> scale = numpy.random.random(3) - 0.5\n    >>> shear = numpy.random.random(3) - 0.5\n    >>> angles = (numpy.random.random(3) - 0.5) * (2*math.pi)\n    >>> trans = numpy.random.random(3) - 0.5\n    >>> persp = numpy.random.random(4) - 0.5\n    >>> M0 = compose_matrix(scale, shear, angles, trans, persp)\n    >>> result = decompose_matrix(M0)\n    >>> M1 = compose_matrix(*result)\n    >>> is_same_transform(M0, M1)\n    True\n    \n` tf.transformations. ` ` concatenate_matrices ` (  _*matrices_ )  \u00c2\u00b6\n    \nReturn concatenation of series of transformation matrices.\n    \n    \n    >>> M = numpy.random.rand(16).reshape((4, 4)) - 0.5\n    >>> numpy.allclose(M, concatenate_matrices(M))\n    True\n    >>> numpy.allclose(numpy.dot(M, M.T), concatenate_matrices(M, M.T))\n    True\n    \n` tf.transformations. ` ` decompose_matrix ` (  _matrix_ )  \u00c2\u00b6\n    \nReturn sequence of transformations from transformation matrix.\nmatrix  :  array_like\n     Non-degenerative homogeneous transformation matrix \nReturn tuple of:\n\n\n\n     scale : vector of 3 scaling factors shear : list of shear factors for x-y, x-z, y-z axes angles : list of Euler angles about static x, y, z axes translate : translation vector along x, y, z axes perspective : perspective partition of matrix \nRaise ValueError if matrix is of wrong type or degenerative.\n    \n    \n    >>> T0 = translation_matrix((1, 2, 3))\n    >>> scale, shear, angles, trans, persp = decompose_matrix(T0)\n    >>> T1 = translation_matrix(trans)\n    >>> numpy.allclose(T0, T1)\n    True\n    >>> S = scale_matrix(0.123)\n    >>> scale, shear, angles, trans, persp = decompose_matrix(S)\n    >>> scale[0]\n    0.123\n    >>> R0 = euler_matrix(1, 2, 3)\n    >>> scale, shear, angles, trans, persp = decompose_matrix(R0)\n    >>> R1 = euler_matrix(*angles)\n    >>> numpy.allclose(R0, R1)\n    True\n    \n` tf.transformations. ` ` euler_from_matrix ` (  _matrix_ , _axes='sxyz'_ )\n\u00c2\u00b6\n    \nReturn Euler angles from rotation matrix for specified axis sequence.\naxes : One of 24 axis sequences as string or encoded tuple\nNote that many Euler angle triplets can describe one matrix.\n    \n    \n    >>> R0 = euler_matrix(1, 2, 3, 'syxz')\n    >>> al, be, ga = euler_from_matrix(R0, 'syxz')\n    >>> R1 = euler_matrix(al, be, ga, 'syxz')\n    >>> numpy.allclose(R0, R1)\n    True\n    >>> angles = (4.0*math.pi) * (numpy.random.random(3) - 0.5)\n    >>> for axes in _AXES2TUPLE.keys():\n    ...    R0 = euler_matrix(axes=axes, *angles)\n    ...    R1 = euler_matrix(axes=axes, *euler_from_matrix(R0, axes))\n    ...    if not numpy.allclose(R0, R1): print axes, \"failed\"\n    \n` tf.transformations. ` ` euler_from_quaternion ` (  _quaternion_ ,\n_axes='sxyz'_ )  \u00c2\u00b6\n\n\n\n    \nReturn Euler angles from quaternion for specified axis sequence.\n    \n    \n    >>> angles = euler_from_quaternion([0.06146124, 0, 0, 0.99810947])\n    >>> numpy.allclose(angles, [0.123, 0, 0])\n    True\n    \n` tf.transformations. ` ` euler_matrix ` (  _ai_ , _aj_ , _ak_ , _axes='sxyz'_\n)  \u00c2\u00b6\n    \nReturn homogeneous rotation matrix from Euler angles and axis sequence.\nai, aj, ak : Euler\u2019s roll, pitch and yaw angles axes : One of 24 axis\nsequences as string or encoded tuple\n    \n    \n    >>> R = euler_matrix(1, 2, 3, 'syxz')\n    >>> numpy.allclose(numpy.sum(R[0]), -1.34786452)\n    True\n    >>> R = euler_matrix(1, 2, 3, (0, 1, 0, 1))\n    >>> numpy.allclose(numpy.sum(R[0]), -0.383436184)\n    True\n    >>> ai, aj, ak = (4.0*math.pi) * (numpy.random.random(3) - 0.5)\n    >>> for axes in _AXES2TUPLE.keys():\n    ...    R = euler_matrix(ai, aj, ak, axes)\n    >>> for axes in _TUPLE2AXES.keys():\n    ...    R = euler_matrix(ai, aj, ak, axes)\n    \n` tf.transformations. ` ` identity_matrix ` (  )  \u00c2\u00b6\n    \nReturn 4x4 identity/unit matrix.\n    \n    \n    >>> I = identity_matrix()\n    >>> numpy.allclose(I, numpy.dot(I, I))\n    True\n    >>> numpy.sum(I), numpy.trace(I)\n    (4.0, 4.0)\n    >>> numpy.allclose(I, numpy.identity(4, dtype=numpy.float64))\n    True\n\n\n\n    \n` tf.transformations. ` ` inverse_matrix ` (  _matrix_ )  \u00c2\u00b6\n    \nReturn inverse of square transformation matrix.\n    \n    \n    >>> M0 = random_rotation_matrix()\n    >>> M1 = inverse_matrix(M0.T)\n    >>> numpy.allclose(M1, numpy.linalg.inv(M0.T))\n    True\n    >>> for size in range(1, 7):\n    ...     M0 = numpy.random.rand(size, size)\n    ...     M1 = inverse_matrix(M0)\n    ...     if not numpy.allclose(M1, numpy.linalg.inv(M0)): print size\n    \n` tf.transformations. ` ` is_same_transform ` (  _matrix0_ , _matrix1_ )  \u00c2\u00b6\n    \nReturn True if two matrices perform same transformation.\n    \n    \n    >>> is_same_transform(numpy.identity(4), numpy.identity(4))\n    True\n    >>> is_same_transform(numpy.identity(4), random_rotation_matrix())\n    False\n    \n` tf.transformations. ` ` orthogonalization_matrix ` (  _lengths_ , _angles_ )\n\u00c2\u00b6\n    \nReturn orthogonalization matrix for crystallographic cell coordinates.\nAngles are expected in degrees.\nThe de-orthogonalization matrix is the inverse.\n    \n    \n    >>> O = orthogonalization_matrix((10., 10., 10.), (90., 90., 90.))\n    >>> numpy.allclose(O[:3, :3], numpy.identity(3, float) * 10)\n    True\n    >>> O = orthogonalization_matrix([9.8, 12.0, 15.5], [87.2, 80.7, 69.7])\n    >>> numpy.allclose(numpy.sum(O), 43.063229)\n    True\n    \n\n\n\n` tf.transformations. ` ` projection_from_matrix ` (  _matrix_ ,\n_pseudo=False_ )  \u00c2\u00b6\n    \nReturn projection plane and perspective point from projection matrix.\nReturn values are same as arguments for projection_matrix function: point,\nnormal, direction, perspective, and pseudo.\n    \n    \n    >>> point = numpy.random.random(3) - 0.5\n    >>> normal = numpy.random.random(3) - 0.5\n    >>> direct = numpy.random.random(3) - 0.5\n    >>> persp = numpy.random.random(3) - 0.5\n    >>> P0 = projection_matrix(point, normal)\n    >>> result = projection_from_matrix(P0)\n    >>> P1 = projection_matrix(*result)\n    >>> is_same_transform(P0, P1)\n    True\n    >>> P0 = projection_matrix(point, normal, direct)\n    >>> result = projection_from_matrix(P0)\n    >>> P1 = projection_matrix(*result)\n    >>> is_same_transform(P0, P1)\n    True\n    >>> P0 = projection_matrix(point, normal, perspective=persp, pseudo=False)\n    >>> result = projection_from_matrix(P0, pseudo=False)\n    >>> P1 = projection_matrix(*result)\n    >>> is_same_transform(P0, P1)\n    True\n    >>> P0 = projection_matrix(point, normal, perspective=persp, pseudo=True)\n    >>> result = projection_from_matrix(P0, pseudo=True)\n    >>> P1 = projection_matrix(*result)\n    >>> is_same_transform(P0, P1)\n    True\n    \n` tf.transformations. ` ` projection_matrix ` (  _point_ , _normal_ ,\n_direction=None_ , _perspective=None_ , _pseudo=False_ )  \u00c2\u00b6\n    \nReturn matrix to project onto plane defined by point and normal.\nUsing either perspective point, projection direction, or none of both.\nIf pseudo is True, perspective projections will preserve relative depth such\nthat Perspective = dot(Orthogonal, PseudoPerspective).\n\n\n\n    \n    \n    >>> P = projection_matrix((0, 0, 0), (1, 0, 0))\n    >>> numpy.allclose(P[1:, 1:], numpy.identity(4)[1:, 1:])\n    True\n    >>> point = numpy.random.random(3) - 0.5\n    >>> normal = numpy.random.random(3) - 0.5\n    >>> direct = numpy.random.random(3) - 0.5\n    >>> persp = numpy.random.random(3) - 0.5\n    >>> P0 = projection_matrix(point, normal)\n    >>> P1 = projection_matrix(point, normal, direction=direct)\n    >>> P2 = projection_matrix(point, normal, perspective=persp)\n    >>> P3 = projection_matrix(point, normal, perspective=persp, pseudo=True)\n    >>> is_same_transform(P2, numpy.dot(P0, P3))\n    True\n    >>> P = projection_matrix((3, 0, 0), (1, 1, 0), (1, 0, 0))\n    >>> v0 = (numpy.random.rand(4, 5) - 0.5) * 20.0\n    >>> v0[3] = 1.0\n    >>> v1 = numpy.dot(P, v0)\n    >>> numpy.allclose(v1[1], v0[1])\n    True\n    >>> numpy.allclose(v1[0], 3.0-v1[1])\n    True\n    \n` tf.transformations. ` ` quaternion_about_axis ` (  _angle_ , _axis_ )  \u00c2\u00b6\n    \nReturn quaternion for rotation about axis.\n    \n    \n    >>> q = quaternion_about_axis(0.123, (1, 0, 0))\n    >>> numpy.allclose(q, [0.06146124, 0, 0, 0.99810947])\n    True\n    \n` tf.transformations. ` ` quaternion_conjugate ` (  _quaternion_ )  \u00c2\u00b6\n    \nReturn conjugate of quaternion.\n    \n    \n    >>> q0 = random_quaternion()\n    >>> q1 = quaternion_conjugate(q0)\n\n\n\n    >>> q1[3] == q0[3] and all(q1[:3] == -q0[:3])\n    True\n    \n` tf.transformations. ` ` quaternion_from_euler ` (  _ai_ , _aj_ , _ak_ ,\n_axes='sxyz'_ )  \u00c2\u00b6\n    \nReturn quaternion from Euler angles and axis sequence.\nai, aj, ak : Euler\u2019s roll, pitch and yaw angles axes : One of 24 axis\nsequences as string or encoded tuple\n    \n    \n    >>> q = quaternion_from_euler(1, 2, 3, 'ryxz')\n    >>> numpy.allclose(q, [0.310622, -0.718287, 0.444435, 0.435953])\n    True\n    \n` tf.transformations. ` ` quaternion_from_matrix ` (  _matrix_ )  \u00c2\u00b6\n    \nReturn quaternion from rotation matrix.\n    \n    \n    >>> R = rotation_matrix(0.123, (1, 2, 3))\n    >>> q = quaternion_from_matrix(R)\n    >>> numpy.allclose(q, [0.0164262, 0.0328524, 0.0492786, 0.9981095])\n    True\n    \n` tf.transformations. ` ` quaternion_inverse ` (  _quaternion_ )  \u00c2\u00b6\n    \nReturn inverse of quaternion.\n    \n    \n    >>> q0 = random_quaternion()\n    >>> q1 = quaternion_inverse(q0)\n    >>> numpy.allclose(quaternion_multiply(q0, q1), [0, 0, 0, 1])\n    True\n    \n` tf.transformations. ` ` quaternion_matrix ` (  _quaternion_ )  \u00c2\u00b6\n    \nReturn homogeneous rotation matrix from quaternion.\n    \n    \n\n\n\n    >>> R = quaternion_matrix([0.06146124, 0, 0, 0.99810947])\n    >>> numpy.allclose(R, rotation_matrix(0.123, (1, 0, 0)))\n    True\n    \n` tf.transformations. ` ` quaternion_multiply ` (  _quaternion1_ ,\n_quaternion0_ )  \u00c2\u00b6\n    \nReturn multiplication of two quaternions.\n    \n    \n    >>> q = quaternion_multiply([1, -2, 3, 4], [-5, 6, 7, 8])\n    >>> numpy.allclose(q, [-44, -14, 48, 28])\n    True\n    \n` tf.transformations. ` ` quaternion_slerp ` (  _quat0_ , _quat1_ , _fraction_\n, _spin=0_ , _shortestpath=True_ )  \u00c2\u00b6\n    \nReturn spherical linear interpolation between two quaternions.\n    \n    \n    >>> q0 = random_quaternion()\n    >>> q1 = random_quaternion()\n    >>> q = quaternion_slerp(q0, q1, 0.0)\n    >>> numpy.allclose(q, q0)\n    True\n    >>> q = quaternion_slerp(q0, q1, 1.0, 1)\n    >>> numpy.allclose(q, q1)\n    True\n    >>> q = quaternion_slerp(q0, q1, 0.5)\n    >>> angle = math.acos(numpy.dot(q0, q))\n    >>> numpy.allclose(2.0, math.acos(numpy.dot(q0, q1)) / angle) or         numpy.allclose(2.0, math.acos(-numpy.dot(q0, q1)) / angle)\n    True\n    \n` tf.transformations. ` ` random_quaternion ` (  _rand=None_ )  \u00c2\u00b6\n    \nReturn uniform random unit quaternion.\nrand: array like or None\n     Three independent random variables that are uniformly distributed between 0 and 1. \n    \n    \n\n\n\n    >>> q = random_quaternion()\n    >>> numpy.allclose(1.0, vector_norm(q))\n    True\n    >>> q = random_quaternion(numpy.random.random(3))\n    >>> q.shape\n    (4,)\n    \n` tf.transformations. ` ` random_rotation_matrix ` (  _rand=None_ )  \u00c2\u00b6\n    \nReturn uniform random rotation matrix.\nrnd: array like\n     Three independent random variables that are uniformly distributed between 0 and 1 for each returned quaternion. \n    \n    \n    >>> R = random_rotation_matrix()\n    >>> numpy.allclose(numpy.dot(R.T, R), numpy.identity(4))\n    True\n    \n` tf.transformations. ` ` random_vector ` (  _size_ )  \u00c2\u00b6\n    \nReturn array of random doubles in the half-open interval [0.0, 1.0).\n    \n    \n    >>> v = random_vector(10000)\n    >>> numpy.all(v >= 0.0) and numpy.all(v < 1.0)\n    True\n    >>> v0 = random_vector(10)\n    >>> v1 = random_vector(10)\n    >>> numpy.any(v0 == v1)\n    False\n    \n` tf.transformations. ` ` reflection_from_matrix ` (  _matrix_ )  \u00c2\u00b6\n    \nReturn mirror plane point and normal vector from reflection matrix.\n    \n    \n    >>> v0 = numpy.random.random(3) - 0.5\n    >>> v1 = numpy.random.random(3) - 0.5\n    >>> M0 = reflection_matrix(v0, v1)\n    >>> point, normal = reflection_from_matrix(M0)\n\n\n\n    >>> M1 = reflection_matrix(point, normal)\n    >>> is_same_transform(M0, M1)\n    True\n    \n` tf.transformations. ` ` reflection_matrix ` (  _point_ , _normal_ )  \u00c2\u00b6\n    \nReturn matrix to mirror at plane defined by point and normal vector.\n    \n    \n    >>> v0 = numpy.random.random(4) - 0.5\n    >>> v0[3] = 1.0\n    >>> v1 = numpy.random.random(3) - 0.5\n    >>> R = reflection_matrix(v0, v1)\n    >>> numpy.allclose(2., numpy.trace(R))\n    True\n    >>> numpy.allclose(v0, numpy.dot(R, v0))\n    True\n    >>> v2 = v0.copy()\n    >>> v2[:3] += v1\n    >>> v3 = v0.copy()\n    >>> v2[:3] -= v1\n    >>> numpy.allclose(v2, numpy.dot(R, v3))\n    True\n    \n` tf.transformations. ` ` rotation_from_matrix ` (  _matrix_ )  \u00c2\u00b6\n    \nReturn rotation angle and axis from rotation matrix.\n    \n    \n    >>> angle = (random.random() - 0.5) * (2*math.pi)\n    >>> direc = numpy.random.random(3) - 0.5\n    >>> point = numpy.random.random(3) - 0.5\n    >>> R0 = rotation_matrix(angle, direc, point)\n    >>> angle, direc, point = rotation_from_matrix(R0)\n    >>> R1 = rotation_matrix(angle, direc, point)\n    >>> is_same_transform(R0, R1)\n    True\n    \n` tf.transformations. ` ` rotation_matrix ` (  _angle_ , _direction_ ,\n_point=None_ )  \u00c2\u00b6\n\n\n\n    \nReturn matrix to rotate about axis defined by point and direction.\n    \n    \n    >>> angle = (random.random() - 0.5) * (2*math.pi)\n    >>> direc = numpy.random.random(3) - 0.5\n    >>> point = numpy.random.random(3) - 0.5\n    >>> R0 = rotation_matrix(angle, direc, point)\n    >>> R1 = rotation_matrix(angle-2*math.pi, direc, point)\n    >>> is_same_transform(R0, R1)\n    True\n    >>> R0 = rotation_matrix(angle, direc, point)\n    >>> R1 = rotation_matrix(-angle, -direc, point)\n    >>> is_same_transform(R0, R1)\n    True\n    >>> I = numpy.identity(4, numpy.float64)\n    >>> numpy.allclose(I, rotation_matrix(math.pi*2, direc))\n    True\n    >>> numpy.allclose(2., numpy.trace(rotation_matrix(math.pi/2,\n    ...                                                direc, point)))\n    True\n    \n` tf.transformations. ` ` scale_from_matrix ` (  _matrix_ )  \u00c2\u00b6\n    \nReturn scaling factor, origin and direction from scaling matrix.\n    \n    \n    >>> factor = random.random() * 10 - 5\n    >>> origin = numpy.random.random(3) - 0.5\n    >>> direct = numpy.random.random(3) - 0.5\n    >>> S0 = scale_matrix(factor, origin)\n    >>> factor, origin, direction = scale_from_matrix(S0)\n    >>> S1 = scale_matrix(factor, origin, direction)\n    >>> is_same_transform(S0, S1)\n    True\n    >>> S0 = scale_matrix(factor, origin, direct)\n    >>> factor, origin, direction = scale_from_matrix(S0)\n    >>> S1 = scale_matrix(factor, origin, direction)\n    >>> is_same_transform(S0, S1)\n    True\n\n\n\n    \n` tf.transformations. ` ` scale_matrix ` (  _factor_ , _origin=None_ ,\n_direction=None_ )  \u00c2\u00b6\n    \nReturn matrix to scale by factor around origin in direction.\nUse factor -1 for point symmetry.\n    \n    \n    >>> v = (numpy.random.rand(4, 5) - 0.5) * 20.0\n    >>> v[3] = 1.0\n    >>> S = scale_matrix(-1.234)\n    >>> numpy.allclose(numpy.dot(S, v)[:3], -1.234*v[:3])\n    True\n    >>> factor = random.random() * 10 - 5\n    >>> origin = numpy.random.random(3) - 0.5\n    >>> direct = numpy.random.random(3) - 0.5\n    >>> S = scale_matrix(factor, origin)\n    >>> S = scale_matrix(factor, origin, direct)\n    \n` tf.transformations. ` ` shear_from_matrix ` (  _matrix_ )  \u00c2\u00b6\n    \nReturn shear angle, direction and plane from shear matrix.\n    \n    \n    >>> angle = (random.random() - 0.5) * 4*math.pi\n    >>> direct = numpy.random.random(3) - 0.5\n    >>> point = numpy.random.random(3) - 0.5\n    >>> normal = numpy.cross(direct, numpy.random.random(3))\n    >>> S0 = shear_matrix(angle, direct, point, normal)\n    >>> angle, direct, point, normal = shear_from_matrix(S0)\n    >>> S1 = shear_matrix(angle, direct, point, normal)\n    >>> is_same_transform(S0, S1)\n    True\n    \n` tf.transformations. ` ` shear_matrix ` (  _angle_ , _direction_ , _point_ ,\n_normal_ )  \u00c2\u00b6\n    \nReturn matrix to shear by angle along direction vector on shear plane.\nThe shear plane is defined by a point and normal vector. The direction vector\nmust be orthogonal to the plane\u2019s normal vector.\n\n\n\nA point P is transformed by the shear matrix into P\u201d such that the vector P-P\u201d\nis parallel to the direction vector and its extent is given by the angle of\nP-P\u2019-P\u201d, where P\u2019 is the orthogonal projection of P onto the shear plane.\n    \n    \n    >>> angle = (random.random() - 0.5) * 4*math.pi\n    >>> direct = numpy.random.random(3) - 0.5\n    >>> point = numpy.random.random(3) - 0.5\n    >>> normal = numpy.cross(direct, numpy.random.random(3))\n    >>> S = shear_matrix(angle, direct, point, normal)\n    >>> numpy.allclose(1.0, numpy.linalg.det(S))\n    True\n    \n` tf.transformations. ` ` superimposition_matrix ` (  _v0_ , _v1_ ,\n_scaling=False_ , _usesvd=True_ )  \u00c2\u00b6\n    \nReturn matrix to transform given vector set into second vector set.\nv0 and v1 are shape (3, *) or (4, *) arrays of at least 3 vectors.\nIf usesvd is True, the weighted sum of squared deviations (RMSD) is minimized\naccording to the algorithm by W. Kabsch [8]. Otherwise the quaternion based\nalgorithm by B. Horn [9] is used (slower when using this Python\nimplementation).\nThe returned matrix performs rotation, translation and uniform scaling (if\nspecified).\n    \n    \n    >>> v0 = numpy.random.rand(3, 10)\n    >>> M = superimposition_matrix(v0, v0)\n    >>> numpy.allclose(M, numpy.identity(4))\n    True\n    >>> R = random_rotation_matrix(numpy.random.random(3))\n    >>> v0 = ((1,0,0), (0,1,0), (0,0,1), (1,1,1))\n    >>> v1 = numpy.dot(R, v0)\n    >>> M = superimposition_matrix(v0, v1)\n    >>> numpy.allclose(v1, numpy.dot(M, v0))\n    True\n    >>> v0 = (numpy.random.rand(4, 100) - 0.5) * 20.0\n    >>> v0[3] = 1.0\n    >>> v1 = numpy.dot(R, v0)\n    >>> M = superimposition_matrix(v0, v1)\n\n\n\n    >>> numpy.allclose(v1, numpy.dot(M, v0))\n    True\n    >>> S = scale_matrix(random.random())\n    >>> T = translation_matrix(numpy.random.random(3)-0.5)\n    >>> M = concatenate_matrices(T, R, S)\n    >>> v1 = numpy.dot(M, v0)\n    >>> v0[:3] += numpy.random.normal(0.0, 1e-9, 300).reshape(3, -1)\n    >>> M = superimposition_matrix(v0, v1, scaling=True)\n    >>> numpy.allclose(v1, numpy.dot(M, v0))\n    True\n    >>> M = superimposition_matrix(v0, v1, scaling=True, usesvd=False)\n    >>> numpy.allclose(v1, numpy.dot(M, v0))\n    True\n    >>> v = numpy.empty((4, 100, 3), dtype=numpy.float64)\n    >>> v[:, :, 0] = v0\n    >>> M = superimposition_matrix(v0, v1, scaling=True, usesvd=False)\n    >>> numpy.allclose(v1, numpy.dot(M, v[:, :, 0]))\n    True\n    \n` tf.transformations. ` ` translation_from_matrix ` (  _matrix_ )  \u00c2\u00b6\n    \nReturn translation vector from translation matrix.\n    \n    \n    >>> v0 = numpy.random.random(3) - 0.5\n    >>> v1 = translation_from_matrix(translation_matrix(v0))\n    >>> numpy.allclose(v0, v1)\n    True\n    \n` tf.transformations. ` ` translation_matrix ` (  _direction_ )  \u00c2\u00b6\n    \nReturn matrix to translate by direction vector.\n    \n    \n    >>> v = numpy.random.random(3) - 0.5\n    >>> numpy.allclose(v, translation_matrix(v)[:3, 3])\n    True\n    \n` tf.transformations. ` ` unit_vector ` (  _data_ , _axis=None_ , _out=None_ )\n\u00c2\u00b6\n\n\n\n    \nReturn ndarray normalized by length, i.e. eucledian norm, along axis.\n    \n    \n    >>> v0 = numpy.random.random(3)\n    >>> v1 = unit_vector(v0)\n    >>> numpy.allclose(v1, v0 / numpy.linalg.norm(v0))\n    True\n    >>> v0 = numpy.random.rand(5, 4, 3)\n    >>> v1 = unit_vector(v0, axis=-1)\n    >>> v2 = v0 / numpy.expand_dims(numpy.sqrt(numpy.sum(v0*v0, axis=2)), 2)\n    >>> numpy.allclose(v1, v2)\n    True\n    >>> v1 = unit_vector(v0, axis=1)\n    >>> v2 = v0 / numpy.expand_dims(numpy.sqrt(numpy.sum(v0*v0, axis=1)), 1)\n    >>> numpy.allclose(v1, v2)\n    True\n    >>> v1 = numpy.empty((5, 4, 3), dtype=numpy.float64)\n    >>> unit_vector(v0, axis=1, out=v1)\n    >>> numpy.allclose(v1, v2)\n    True\n    >>> list(unit_vector([]))\n    []\n    >>> list(unit_vector([1.0]))\n    [1.0]\n    \n` tf.transformations. ` ` vector_norm ` (  _data_ , _axis=None_ , _out=None_ )\n\u00c2\u00b6\n    \nReturn length, i.e. eucledian norm, of ndarray along axis.\n    \n    \n    >>> v = numpy.random.random(3)\n    >>> n = vector_norm(v)\n    >>> numpy.allclose(n, numpy.linalg.norm(v))\n    True\n    >>> v = numpy.random.rand(6, 5, 3)\n    >>> n = vector_norm(v, axis=-1)\n    >>> numpy.allclose(n, numpy.sqrt(numpy.sum(v*v, axis=2)))\n    True\n\n\n\n    >>> n = vector_norm(v, axis=1)\n    >>> numpy.allclose(n, numpy.sqrt(numpy.sum(v*v, axis=1)))\n    True\n    >>> v = numpy.random.rand(5, 4, 3)\n    >>> n = numpy.empty((5, 3), dtype=numpy.float64)\n    >>> vector_norm(v, axis=1, out=n)\n    >>> numpy.allclose(n, numpy.sqrt(numpy.sum(v*v, axis=1)))\n    True\n    >>> vector_norm([])\n    0.0\n    >>> vector_norm([1.0])\n    1.0\n    \n###  [ Table Of Contents ](index.html)\n  * transformations \n    * Requirements \n    * Notes \n    * References \n    * Examples \n####  Previous topic\n[ tf (Python) ](tf_python.html \"previous chapter\")\n###  This Page\n  * [ Show Source ](_sources/transformations.txt)\n###  Quick search\nEnter search terms or a module, class or function name.\n###  Navigation\n  * [ index ](genindex.html \"General Index\")\n  * [ modules ](py-modindex.html \"Python Module Index\") | \n  * [ previous ](tf_python.html \"tf \\(Python\\)\") | \n  * [ tf 0.1.0 documentation ](index.html) \u00bb \n\u00a9 Copyright 2009, Willow Garage, Inc.. Created using [ Sphinx ](http://sphinx-\ndoc.org/) 1.2.2.\n\n\n"
  },
  {
    "id": "nav2bringup/navigationlaunchpy.txt",
    "content": "# Copyright (c) 2018 Intel Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\n\nfrom ament_index_python.packages import get_package_share_directory\n\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, GroupAction, SetEnvironmentVariable\nfrom launch.conditions import IfCondition\nfrom launch.substitutions import LaunchConfiguration, PythonExpression\nfrom launch_ros.actions import LoadComposableNodes, SetParameter\nfrom launch_ros.actions import Node\nfrom launch_ros.descriptions import ComposableNode, ParameterFile\nfrom nav2_common.launch import RewrittenYaml\n\n\ndef generate_launch_description():\n    # Get the launch directory\n    bringup_dir = get_package_share_directory('nav2_bringup')\n\n    namespace = LaunchConfiguration('namespace')\n    use_sim_time = LaunchConfiguration('use_sim_time')\n    autostart = LaunchConfiguration('autostart')\n    params_file = LaunchConfiguration('params_file')\n    use_composition = LaunchConfiguration('use_composition')\n    container_name = LaunchConfiguration('container_name')\n    container_name_full = (namespace, '/', container_name)\n    use_respawn = LaunchConfiguration('use_respawn')\n    log_level = LaunchConfiguration('log_level')\n\n    lifecycle_nodes = [\n        'controller_server',\n        'smoother_server',\n        'planner_server',\n        'behavior_server',\n        'velocity_smoother',\n        'collision_monitor',\n        'bt_navigator',\n        'waypoint_follower',\n    ]\n\n    # Map fully qualified names to relative ones so the node's namespace can be prepended.\n    # In case of the transforms (tf), currently, there doesn't seem to be a better alternative\n    # https://github.com/ros/geometry2/issues/32\n    # https://github.com/ros/robot_state_publisher/pull/30\n    # TODO(orduno) Substitute with `PushNodeRemapping`\n    #              https://github.com/ros2/launch_ros/issues/56\n    remappings = [('/tf', 'tf'), ('/tf_static', 'tf_static')]\n\n    # Create our own temporary YAML files that include substitutions\n    param_substitutions = {'autostart': autostart}\n\n    configured_params = ParameterFile(\n        RewrittenYaml(\n            source_file=params_file,\n            root_key=namespace,\n            param_rewrites=param_substitutions,\n            convert_types=True,\n        ),\n        allow_substs=True,\n    )\n\n    stdout_linebuf_envvar = SetEnvironmentVariable(\n        'RCUTILS_LOGGING_BUFFERED_STREAM', '1'\n    )\n\n    declare_namespace_cmd = DeclareLaunchArgument(\n        'namespace', default_value='', description='Top-level namespace'\n    )\n\n    declare_use_sim_time_cmd = DeclareLaunchArgument(\n        'use_sim_time',\n        default_value='false',\n        description='Use simulation (Gazebo) clock if true',\n    )\n\n    declare_params_file_cmd = DeclareLaunchArgument(\n        'params_file',\n        default_value=os.path.join(bringup_dir, 'params', 'nav2_params.yaml'),\n        description='Full path to the ROS2 parameters file to use for all launched nodes',\n    )\n\n    declare_autostart_cmd = DeclareLaunchArgument(\n        'autostart',\n        default_value='true',\n        description='Automatically startup the nav2 stack',\n    )\n\n    declare_use_composition_cmd = DeclareLaunchArgument(\n        'use_composition',\n        default_value='False',\n        description='Use composed bringup if True',\n    )\n\n    declare_container_name_cmd = DeclareLaunchArgument(\n        'container_name',\n        default_value='nav2_container',\n        description='the name of conatiner that nodes will load in if use composition',\n    )\n\n    declare_use_respawn_cmd = DeclareLaunchArgument(\n        'use_respawn',\n        default_value='False',\n        description='Whether to respawn if a node crashes. Applied when composition is disabled.',\n    )\n\n    declare_log_level_cmd = DeclareLaunchArgument(\n        'log_level', default_value='info', description='log level'\n    )\n\n    load_nodes = GroupAction(\n        condition=IfCondition(PythonExpression(['not ', use_composition])),\n        actions=[\n            SetParameter('use_sim_time', use_sim_time),\n            Node(\n                package='nav2_controller',\n                executable='controller_server',\n                output='screen',\n                respawn=use_respawn,\n                respawn_delay=2.0,\n                parameters=[configured_params],\n                arguments=['--ros-args', '--log-level', log_level],\n                remappings=remappings + [('cmd_vel', 'cmd_vel_nav')],\n            ),\n            Node(\n                package='nav2_smoother',\n                executable='smoother_server',\n                name='smoother_server',\n                output='screen',\n                respawn=use_respawn,\n                respawn_delay=2.0,\n                parameters=[configured_params],\n                arguments=['--ros-args', '--log-level', log_level],\n                remappings=remappings,\n            ),\n            Node(\n                package='nav2_planner',\n                executable='planner_server',\n                name='planner_server',\n                output='screen',\n                respawn=use_respawn,\n                respawn_delay=2.0,\n                parameters=[configured_params],\n                arguments=['--ros-args', '--log-level', log_level],\n                remappings=remappings,\n            ),\n            Node(\n                package='nav2_behaviors',\n                executable='behavior_server',\n                name='behavior_server',\n                output='screen',\n                respawn=use_respawn,\n                respawn_delay=2.0,\n                parameters=[configured_params],\n                arguments=['--ros-args', '--log-level', log_level],\n                remappings=remappings + [('cmd_vel', 'cmd_vel_nav')],\n            ),\n            Node(\n                package='nav2_bt_navigator',\n                executable='bt_navigator',\n                name='bt_navigator',\n                output='screen',\n                respawn=use_respawn,\n                respawn_delay=2.0,\n                parameters=[configured_params],\n                arguments=['--ros-args', '--log-level', log_level],\n                remappings=remappings,\n            ),\n            Node(\n                package='nav2_waypoint_follower',\n                executable='waypoint_follower',\n                name='waypoint_follower',\n                output='screen',\n                respawn=use_respawn,\n                respawn_delay=2.0,\n                parameters=[configured_params],\n                arguments=['--ros-args', '--log-level', log_level],\n                remappings=remappings,\n            ),\n            Node(\n                package='nav2_velocity_smoother',\n                executable='velocity_smoother',\n                name='velocity_smoother',\n                output='screen',\n                respawn=use_respawn,\n                respawn_delay=2.0,\n                parameters=[configured_params],\n                arguments=['--ros-args', '--log-level', log_level],\n                remappings=remappings\n                + [('cmd_vel', 'cmd_vel_nav')],\n            ),\n            Node(\n                package='nav2_collision_monitor',\n                executable='collision_monitor',\n                name='collision_monitor',\n                output='screen',\n                respawn=use_respawn,\n                respawn_delay=2.0,\n                parameters=[configured_params],\n                arguments=['--ros-args', '--log-level', log_level],\n                remappings=remappings,\n            ),\n            Node(\n                package='nav2_lifecycle_manager',\n                executable='lifecycle_manager',\n                name='lifecycle_manager_navigation',\n                output='screen',\n                arguments=['--ros-args', '--log-level', log_level],\n                parameters=[{'autostart': autostart}, {'node_names': lifecycle_nodes}],\n            ),\n        ],\n    )\n\n    load_composable_nodes = GroupAction(\n        condition=IfCondition(use_composition),\n        actions=[\n            SetParameter('use_sim_time', use_sim_time),\n            LoadComposableNodes(\n                target_container=container_name_full,\n                composable_node_descriptions=[\n                    ComposableNode(\n                        package='nav2_controller',\n                        plugin='nav2_controller::ControllerServer',\n                        name='controller_server',\n                        parameters=[configured_params],\n                        remappings=remappings + [('cmd_vel', 'cmd_vel_nav')],\n                    ),\n                    ComposableNode(\n                        package='nav2_smoother',\n                        plugin='nav2_smoother::SmootherServer',\n                        name='smoother_server',\n                        parameters=[configured_params],\n                        remappings=remappings,\n                    ),\n                    ComposableNode(\n                        package='nav2_planner',\n                        plugin='nav2_planner::PlannerServer',\n                        name='planner_server',\n                        parameters=[configured_params],\n                        remappings=remappings,\n                    ),\n                    ComposableNode(\n                        package='nav2_behaviors',\n                        plugin='behavior_server::BehaviorServer',\n                        name='behavior_server',\n                        parameters=[configured_params],\n                        remappings=remappings + [('cmd_vel', 'cmd_vel_nav')],\n                    ),\n                    ComposableNode(\n                        package='nav2_bt_navigator',\n                        plugin='nav2_bt_navigator::BtNavigator',\n                        name='bt_navigator',\n                        parameters=[configured_params],\n                        remappings=remappings,\n                    ),\n                    ComposableNode(\n                        package='nav2_waypoint_follower',\n                        plugin='nav2_waypoint_follower::WaypointFollower',\n                        name='waypoint_follower',\n                        parameters=[configured_params],\n                        remappings=remappings,\n                    ),\n                    ComposableNode(\n                        package='nav2_velocity_smoother',\n                        plugin='nav2_velocity_smoother::VelocitySmoother',\n                        name='velocity_smoother',\n                        parameters=[configured_params],\n                        remappings=remappings\n                        + [('cmd_vel', 'cmd_vel_nav')],\n                    ),\n                    ComposableNode(\n                        package='nav2_collision_monitor',\n                        plugin='nav2_collision_monitor::CollisionMonitor',\n                        name='collision_monitor',\n                        parameters=[configured_params],\n                        remappings=remappings,\n                    ),\n                    ComposableNode(\n                        package='nav2_lifecycle_manager',\n                        plugin='nav2_lifecycle_manager::LifecycleManager',\n                        name='lifecycle_manager_navigation',\n                        parameters=[\n                            {'autostart': autostart, 'node_names': lifecycle_nodes}\n                        ],\n                    ),\n                ],\n            ),\n        ],\n    )\n\n    # Create the launch description and populate\n    ld = LaunchDescription()\n\n    # Set environment variables\n    ld.add_action(stdout_linebuf_envvar)\n\n    # Declare the launch options\n    ld.add_action(declare_namespace_cmd)\n    ld.add_action(declare_use_sim_time_cmd)\n    ld.add_action(declare_params_file_cmd)\n    ld.add_action(declare_autostart_cmd)\n    ld.add_action(declare_use_composition_cmd)\n    ld.add_action(declare_container_name_cmd)\n    ld.add_action(declare_use_respawn_cmd)\n    ld.add_action(declare_log_level_cmd)\n    # Add the actions to launch all of the navigation nodes\n    ld.add_action(load_nodes)\n    ld.add_action(load_composable_nodes)\n\n    return ld"
  },
  {
    "id": "setupbash/environmenthtmlworks.txt",
    "content": "[ ![Logo](../_static/colcon.svg) ](../index.html)\n\nreleased\n\nUser Documentation\n\n  * [ Installation ](../user/installation.html)\n  * [ Quick start ](../user/quick-start.html)\n  * [ Configuration ](../user/configuration.html)\n  * [ How to ](../user/how-to.html)\n  * [ What is a Workspace? ](../user/what-is-a-workspace.html)\n  * [ Log Files ](../user/log-files.html)\n  * [ Isolated vs Merged Workspaces ](../user/isolated-vs-merged-workspaces.html)\n  * [ Using Multiple Workspaces ](../user/using-multiple-workspaces.html)\n  * [ Overriding Packages ](../user/overriding-packages.html)\n\nReference\n\n  * [ ` build  ` \\- Build Packages ](../reference/verb/build.html)\n  * [ ` edit  ` \\- Edit File ](../reference/verb/edit.html)\n  * [ ` graph  ` \\- Visualize Dependencies ](../reference/verb/graph.html)\n  * [ ` info  ` \\- Show Package Information ](../reference/verb/info.html)\n  * [ ` list  ` \\- List Packages ](../reference/verb/list.html)\n  * [ ` metadata  ` \\- Manage metadata ](../reference/verb/metadata.html)\n  * [ ` mixin  ` \\- Manage mixins ](../reference/verb/mixin.html)\n  * [ ` test  ` \\- Test Packages ](../reference/verb/test.html)\n  * [ ` test-result  ` \\- Summarize Test Results ](../reference/verb/test-result.html)\n  * [ Global arguments ](../reference/global-arguments.html)\n  * [ Executor arguments ](../reference/executor-arguments.html)\n  * [ Event handler arguments ](../reference/event-handler-arguments.html)\n  * [ Discovery arguments ](../reference/discovery-arguments.html)\n  * [ Package selection arguments ](../reference/package-selection-arguments.html)\n  * [ Mixin arguments ](../reference/mixin-arguments.html)\n\nDeveloper Documentation\n\n  * [ Design ](design.html)\n  * [ Bootstrap from source ](bootstrap.html)\n  * Environment setup \n    * Entry points \n      * Package-level \n      * Workspace-level \n    * Different shells \n      * Primary shells \n      * Non-primary / additional shells \n    * Avoid duplicate entries \n      * .dsv files \n    * Implementation \n    * Tracing \n  * [ Program flow ](program-flow.html)\n  * [ Extension points ](extension-point.html)\n  * [ Contributions ](contribution.html)\n  * [ Make Releases ](release.html)\n  * [ Changelog ](changelog.html)\n\nMigrate from other build tools\n\n  * [ ament_tools ](../migration/ament_tools.html)\n  * [ catkin_make_isolated ](../migration/catkin_make_isolated.html)\n  * [ catkin_tools ](../migration/catkin_tools.html)\n\n__ [ colcon ](../index.html)\n\n  * [ Docs ](../index.html) \u00bb \n  * Environment setup \n  * [ Edit on GitHub ](https://github.com/colcon/colcon.readthedocs.org/blob/released/developer/environment.rst)\n\n* * *\n\n#  Environment setup  \u00c2\u00b6\n\nUsing a package after it has been built or building a package on top of its\ndependencies might require updating environment variables. For the former, the\nbest option for the user is to have a script perform the environment update\nfor ease of use. In the latter case, automating the process is necessary to\nbuild packages in topological order without user interaction. E.g. if a\npackage installs an executable which should be invocable by name, the\ndirectory containing the executable needs to be part of the ` PATH  `\nenvironment variable.\n\n##  Entry points  \u00c2\u00b6\n\nTo update environment variables:\n\n  * On non-Windows platforms a shell script needs to be ` source  ` -ed (e.g. ` .sh  ` , ` .bash  ` , ` .zsh  ` ) \n  * On Windows a shell script needs to be ` call  ` -ed (e.g. ` .bat  ` , ` .ps1  ` ) \n\nNote\n\nExecutables are unable to change the environment of the current shell.\nTherefore this needs to be done from a shell script.\n\n###  Package-level  \u00c2\u00b6\n\nNote\n\nEach package installs its files under its install prefix. This corresponds to\n` install/<package_name> ` except when ` colcon  build  --merge-install  ` is\nused. In that case, the install prefix is ` install/  ` .\n\nFor each built package ` colcon  ` generates a set of package-level scripts\n(one for each supported shell type): ` share/<package_name>/package.<ext> ` .\nThese script files update the environment with information specific to this\npackage.\n\n` colcon  ` supports multiple different approaches to update environment\nvariables:\n\n  * A heuristic checking the installed files for known file types or known destinations. A few of the supported heuristics: \n    * An executable under ` bin  ` adds that directory to the ` PATH  `\n    * An existing Python library directory adds that directory to the ` PYTHONPATH  `\n    * A file ending in ` -config.cmake  ` or ` Config.cmake  ` adds the directory to the ` CMAKE_PREFIX_PATH  ` (provided by ` colcon-cmake  ` ) \n    * A file starting with ` Find  ` and ending in ` .cmake  ` adds the directory to the ` CMAKE_MODULE_PATH  ` (provided by ` colcon-cmake  ` ) \n    * A shared library adds the directory to one of the following environment variables (depending on the platform): ` LD_LIBRARY_PATH  ` , ` DYLD_LIBRARY_PATH  ` , ` PATH  ` (provided by ` colcon-library-path  ` ) \n    * A file ending in ` .pc  ` in a directory ` lib/pkgconfig  ` adds the directory to the ` PKG_CONFIG_PATH  ` (provided by ` colcon-pkg-config  ` ) \n  * Specific package types providing their own scripts to setup the package specific environment. E.g. ` ament_cmake  ` packages (supported by ` colcon-ros  ` ) provide a file named ` share/<package_name>/local_setup.<ext> ` . \n\n###  Workspace-level  \u00c2\u00b6\n\nIn the root of the install prefix path, ` colcon  ` generates two kinds of\nscripts:\n\n  * ` local_setup.<ext> ` : updates the environment with information from all packages installed under this prefix path. Since package-level scripts rely on information from their dependencies the package-level scripts must be invoked in topological order. In order to determine the topological order of all packages under the prefix path, ` colcon  ` stores all run dependencies of a package in a file named ` share/colcon-core/packages/<package_name> ` . \n  * ` setup.<ext> ` : first invokes the ` local_setup.<ext> ` files from all parent prefix paths and then invokes the sibling ` local_setup.<ext> ` file. \n\n##  Different shells  \u00c2\u00b6\n\nEach shell has a potentially different syntax and supports a different set of\nfeatures. Some environment changes like extending the ` PATH  ` are applicable\nto all shells while others like providing completion functionality are only\napplicable to some. If one shell (e.g. ` bash  ` ) provides a superset of\nfunctionality and syntax of another shell (e.g. ` sh  ` ) the logic of the `\n.sh  ` scripts doesn\u00e2\u0080\u0099t have to be duplicated for ` bash  ` but can be\ninvoked from the package-level setup files. The latter shell is called a\n_primary shell_ .\n\n###  Primary shells  \u00c2\u00b6\n\nAll environment changes necessary to use a package should be expressed in\nscript with the extension of a primary shell. Primary shell extensions are:\n\n  * ` .sh  ` : plain shell \n  * ` .bat  ` : Windows cmd \n  * ` .ps1  ` : PowerShell \n\n###  Non-primary / additional shells  \u00c2\u00b6\n\nOther shells which are able to invoke primary shell scripts within their\ncontext commonly don\u00e2\u0080\u0099t duplicate their content and logic. Instead they first\ninvoke the primary shell script and then add additional logic to provide\nspecific functionalities like completion.\n\n##  Avoid duplicate entries  \u00c2\u00b6\n\nSeveral environment variables store multiple values separated by a delimiter.\nCommonly, duplicate values are not useful and only increase length and\ndecrease readability. Therefore, shell scripts try to avoid adding duplicate\nvalues where applicable.\n\nWith the number of values in such an environment variable the cost to check if\na given value is already in the collection increases. This significantly\naffects the time it takes to ` source  ` / ` call  ` the workspace-level setup\nfile since for each attempt to update an environment variable the collection\nneeds to be split and each existing value compared to the to-be-added value.\n\nTherefore ` colcon  ` provides an alternative way to update the environment.\n\n###  .dsv files  \u00c2\u00b6\n\nSince shell scripts can contain arbitrary logic it is opaque from the outside\nhow they affect the environment. That makes it impossible to optimize their\nexecution.\n\nMost scripts perform one of the following common operations:\n\n  * Set an environment variable to a value. \n  * Add a value to an environment variable (using a platform specific delimiter) if the value is not already in the collection. \n  * Source / call another script file. \n\nA ` .dsv  ` file contains the descriptive information about the intended\nenvironment change (instead of shell specific logic). The content of such a\nfile uses a semicolon as the delimiter and contains a single line. The first\nvalue is the ` type  ` of the operation followed by a variable number of\narguments specific to the operation.\n\nThe following list enumerates the supported types and their arguments:\n\n  * ` prepend-non-duplicate;<name>;<value> ` : Prepend a value ` <value> ` to an environment variable ` <name> ` (using a platform specific delimiter) if the value is not already in the collection. The value is considered to be a path. If the value is not an absolute path the prefix path of the ` .dsv  ` file is prepended to the value. An empty value therefore represents the prefix path. \n  * ` prepend-non-duplicate-if-exists;<name>;<value> ` : Same as ` prepend-non-duplicate  ` but only if the path described by the value exists. \n  * ` set;<name>;<value> ` : Set an environment variable ` <name> ` to a value ` <value> ` . If the value is an existing relative path in the install prefix the install prefix is prepended to the value. Otherwise the value is used as is. \n  * ` set-if-unset;<name>;<value> ` : Same as ` set  ` but only if the environment variable is not yet set (or empty). \n  * ` source;<path> ` : Source / call another script file ` <path> ` . If the value is not an absolute path the prefix path of the ` .dsv  ` file is prepended. \n\n##  Implementation  \u00c2\u00b6\n\nImplementing the logic to determine the topological order of packages in every\nprimary shell would be a lot of effort and (depending on the shell)\ncumbersome. Also parsing and interpreting ` .dsv  ` files would likely not be\nmuch faster than invoking the native scripts.\n\nTherefore both parts are implemented in a Python script located in the root of\nthe install prefix: ` _local_setup_util_<ext>.py  ` . The Python script itself\ncan\u00e2\u0080\u0099t change the environment. However, it is able to efficiently interpret\nthe operations described by the ` .dsv  ` files and generate the shell\nspecific commands necessary to update the environment. The Python file is\ntemplated with information specific to the primary shell it\u00e2\u0080\u0099s used from,\nhence the ` <ext> ` in the filename.\n\n##  Tracing  \u00c2\u00b6\n\nWhen sourcing / calling a workspace-level setup file the number of evaluated\nscripts and / or interpreted ` .dsv  ` files can be significant. To debug what\nfiles are being considered in which order and what environment changes are\nbeing performed you can prepend the invocation with ` COLCON_TRACE=1  ` . As a\nresult each recursively invoked script as well as every generated command will\nbe printed to the terminal.\n\n[ Next  ](program-flow.html \"Program flow\") [ Previous ](bootstrap.html\n\"Bootstrap from source\")\n\n* * *\n\n\u00a9 Copyright 2018, Dirk Thomas, licensed under the Creative Commons Attribution\n4.0  Revision ` 4c590dab ` .\n\nBuilt with [ Sphinx ](http://sphinx-doc.org/) using a [ theme\n](https://github.com/rtfd/sphinx_rtd_theme) provided by [ Read the Docs\n](https://readthedocs.org) .\n\nRead the Docs  v: released\n\nVersions\n\n     [ released ](/en/released/)\n     [ main ](/en/main/)\n\nDownloads\n\n     [ pdf ](//colcon.readthedocs.io/_/downloads/en/released/pdf/)\n     [ html ](//colcon.readthedocs.io/_/downloads/en/released/htmlzip/)\n     [ epub ](//colcon.readthedocs.io/_/downloads/en/released/epub/)\n\nOn Read the Docs\n\n     [ Project Home ](//readthedocs.org/projects/colcon/?fromdocs=colcon)\n     [ Builds ](//readthedocs.org/builds/colcon/?fromdocs=colcon)\n\n* * *\n\nFree document hosting provided by [ Read the Docs\n](http://www.readthedocs.org) .\n\n"
  },
  {
    "id": "visual_marker/29106.txt",
    "content": "[ ![](https://github.com/Dronecode/dronecode-wordpress-\ntheme/raw/master/dronecode-salient-\nchild/images/dronecode_top_bar_logo_full.png) ](https://www.dronecode.org/)\n\n[ ![](https://github.com/Dronecode/dronecode-wordpress-\ntheme/raw/master/dronecode-salient-\nchild/images/dronecode_top_bar_logo_small.png) ](https://www.dronecode.org/)\n\n[ Dronecode ](https://www.dronecode.org/)\n\n[ PX4 ](http://px4.io/)\n\n[ QGroundControl ](http://qgroundcontrol.com/)\n\n[ QGC ](http://qgroundcontrol.com/)\n\n[ MAVSDK ](http://mavsdk.mavlink.io)\n\n[ MAVLink ](https://mavlink.io/en/)\n\n[ Documentation ](https://www.dronecode.org/documentation/)\n\n[ Docs ](https://www.dronecode.org/documentation/)\n\n[ Support ](http://discuss.px4.io/)\n\n[ Help ](http://discuss.px4.io/)\n\n[ Discussion Forum for PX4, Pixhawk, QGroundControl, MAVSDK, MAVLink ](/)\n\n#  [ Simulate aruco markers in gazebo with MavSDK ](/t/simulate-aruco-markers-\nin-gazebo-with-mavsdk/29106)\n\n[ MAVSDK  ](/c/mavsdk/19)\n\n[ blank-supportgis  ](https://discuss.px4.io/u/blank-supportgis) September 21,\n2022, 4:22pm  1\n\nI\u2019m trying to do precision landing using a downward facing camera and aruco\nmarkers.  \nI\u2019m currently doing my simulations in SITL (according to [ this tutorial\n](https://docs.px4.io/main/en/simulation/gazebo.html) ) by manually holding\nthe copter over the marker and trying to follow the movements of the simulated\ndrone. It looks about as silly as it sounds\u2026\n\nI\u2019d like to use Gazebo to simulate this, e.g. by adding a simple camera to the\nIris drone and a marker at the bottom. However, there are 2 problems:\n\n  * I have no experience in Gazebo or ROS. \n  * I\u2019m not developing in ROS at all, I\u2019m developing in Python, using OpenCV to read the images and MavSDK to talk to the drone. \n\nIs there a simple description or tutorial on how to extend the [ Gazebo\nsimulations ](https://docs.px4.io/main/en/simulation/gazebo.html) with a\nsimple downward facing camera that externally acts as a USB camera.\n\n[ mwbb  ](https://discuss.px4.io/u/mwbb) September 22, 2022, 5:32am  2\n\nHey,  \nYou can use Typhoon H480 which already has a camera and add your aruco marker\nintro your Gazebo world. But you may need to play around a bit to make the\nworld changes in Gazebo.\n\n[ docs.px4.io ](https://docs.px4.io/main/en/simulation/gazebo.html#running-\nthe-simulation)\n\n###  [ Gazebo Simulation | PX4 User Guide\n](https://docs.px4.io/main/en/simulation/gazebo.html#running-the-simulation)\n\nPX4 is the Professional Autopilot. Developed by world-class developers from\nindustry and academia, and supported by an active world wide community, it\npowers all kinds of vehicles from racing and cargo drones through to ground\nvehicles and...\n\n[ blank-supportgis  ](https://discuss.px4.io/u/blank-supportgis) September 23,\n2022, 1:16pm  3\n\nThanks, that would be an idea for the camera problem, I\u2019ll give that a try.\nUnfortunately, it still leaves one problem.  \nThe Typhoon has a gimbal camera that corrects any swaying of the drone, but\nmost downward cameras for object recognition are fixed (so is mine). When the\ndrone tilts or rolls, the camera center moves and the detected distance to the\nmarker changes, though the drone hasn\u2019t moved. You can correct that by getting\nthe roll and tilt angles of the drone, turning them into rotation matrices and\nrotate the camera frame back into the drone body frame, which points straight\ntowards earth. However, this important effect cannot be simulated here.\n\n[ Mzahana  ](https://discuss.px4.io/u/Mzahana) September 24, 2022, 2:00pm  4\n\nThis is a project I did in the past, and it might be useful in your case.\n\n![](https://github.githubassets.com/favicons/favicon.svg) [ GitHub\n](https://github.com/mzahana/mavros_apriltag_tracking)\n\n![](https://opengraph.githubassets.com/9267fb623ef98aaa890941a2ef768535d32ac7e14d8395efa15970ddb0087063/mzahana/mavros_apriltag_tracking)\n\n###  [ GitHub - mzahana/mavros_apriltag_tracking: This package implements\nmethods to... ](https://github.com/mzahana/mavros_apriltag_tracking)\n\nThis package implements methods to enable a PX4-powered multi-rotor to track a\nmoving vehicle. - GitHub - mzahana/mavros_apriltag_tracking: This package\nimplements methods to enable a PX4-powered m...\n\n1 Like\n\n  * [ Home ](/)\n  * [ Categories ](/categories)\n  * [ FAQ/Guidelines ](/guidelines)\n  * [ Terms of Service ](/tos)\n  * [ Privacy Policy ](/privacy)\n\nPowered by [ Discourse ](https://www.discourse.org) , best viewed with\nJavaScript enabled\n\n"
  },
  {
    "id": "coordinate_frame/readyforros6tf.txt",
    "content": "[ ![Articulated Robotics](/assets/images/logo3.png) ](/)\n\n  * [ __ ](https://www.youtube.com/c/ArticulatedRobotics)\n  * [ __ ](https://www.facebook.com/ArticulatedRobotics/)\n  * [ __ ](https://twitter.com/articulatedrobo/)\n  * [ __ ](https://www.linkedin.com/company/articulated-robotics/)\n  * [ __ ](https://github.com/joshnewans/)\n  * [ Blog ](/index.html)\n  * [ Community ](https://discourse.articulatedrobotics.xyz/)\n  * [ About ](/about)\n  * [ Support Us! ](/support)\n\n![Articulated Robotics](/assets/images/logo2.png)\n\nShare\n\n  * [ __ ](https://twitter.com/intent/tweet?text=Getting Ready for ROS Part 6: The Transform System \\(TF\\)&url=https://articulatedrobotics.xyz/ready-for-ros-6-tf/)\n  * [ __ ](https://facebook.com/sharer.php?u=https://articulatedrobotics.xyz/ready-for-ros-6-tf/)\n  * [ __ ](https://www.linkedin.com/shareArticle?mini=true&url=https://articulatedrobotics.xyz/ready-for-ros-6-tf/)\n\n  * \n\n![Josh Newans](/assets/images/logo3.png)\n\n[ Josh Newans ](https://articulatedrobotics.xyz/) [ Follow\n](https://www.facebook.com/ArticulatedRobotics/)  \nCreator of Articulated Robotics.\n\n#  Getting Ready for ROS Part 6: The Transform System (TF)\n\n  \n\n##  Why are Transforms so important?\n\nCoordinate transformations (or transforms) play a huge role in the mathematics\nof robotics. They are a a mathematical tool to take points or measurements\nthat are represented from one point of view, and represent them in a different\npoint of view that is more useful. Without using transformations, we would\nneed to perform the calculations with trigonometry, which quickly becomes very\ncomplex with larger problems, and especially in 3D.\n\n> This tutorial is all about how ROS makes using transformations simple. If\n> you\u2019re particularly interested in the more complex and interesting\n> underlying mathematics, I\u2019ve written (most of) a series of tutorials on\n> them, available _here_ .\n\nShown below are two examples of robotic systems where transformations are\nhelpful. In the first, two mobile robots are exploring and one has found an\nobject of interest. How will the other robot know how to get to it? In the\nsecond, a mounted camera has spotted a target and a manipulator needs to move\nthe gripper over to it. How do we know the correct motion from the gripper to\nthe target?\n\n![TF Scene 1](/media/assets/posts/ready-for-ros/tf_scene_1.png)\n\nTo solve these problems, we need to first assign coordinate systems, or\n_frames_ to appropriate components of our system. Next, we would need to\ndefine _transforms_ between the frames. A transform tells us the translations\nand rotations required to turn one frame into a different frame, and can be\neasily reversed to go the other way.\n\n![TF Scene 2](/media/assets/posts/ready-for-ros/tf_scene_2.png)\n\nIf we have a system where every frame is defined by its relationship to one\n(and only one) other frame, this will create a _tree structure_ , and we will\nbe able to convert a known point in one frame to any other frame in the tree.\n\nFiguring out all the mathematics and code behind this can be quite tricky, so\nROS provides us with a whole subsystem just to make working with transforms\neasier. In this tutorial we\u2019ll learn how to set up a transform tree for some\nexample cases.\n\n##  Transforms in ROS\n\nROS provides a system called ` tf2 ` (TransForm version 2) to handle these\ntransformations for us. Any node can use the ` tf2 ` libraries to _broadcast_\na transform from one frame to another. As mentioned above, these transforms\nwill need to form a tree structure, where each frame is defined by one (and\nonly one) transform from another frame, but can have any number of frames\ndependent on it. The picture below shows a portion of a tree that we\u2019ll be\nexploring later. In this tree, ` base ` and ` camera ` are defined relative to\n` world ` , and ` l3 ` is defined relative to ` base ` .\n\n![TF tree small](/media/assets/posts/ready-for-ros/tf_frames_small.png)\n\nAny node can also use the ` tf2 ` libraries to _listen_ for transforms, and\nthen use the transforms to convert points from any frame to any other frame,\nas long as they are connected in the tree.\n\nWhen a node broadcasts a particular transform, it can either be _static_\n(doesn\u2019t change over time), or _dynamic_ (may change over time, but doesn\u2019t\nhave to). The reason for this distinction is that robust systems will need to\nknow if their information is out of date, and can flag an error if the\nbroadcaster hasn\u2019t updated a dynamic transform for some time. Static\ntransforms, on the other hand, can be broadcast once and are assumed to be\ncorrect until a new one is broadcast.\n\nUnderneath, the ` tf2 ` libraries are still using topics ( ` /tf ` and `\n/tf_static ` ) to handle all this communication, but because we don\u2019t actually\npublish to the topic ourselves, we call it broadcasting and listening instead\nof publishing and subscribing.\n\n![TF topics](/media/assets/posts/ready-for-ros/tf_topics.png)\n\nIf we\u2019re writing our own nodes, we can code them to broadcast whatever\ntransforms we like, but most of us starting out aren\u2019t ready to write custom\nnodes or calculate transforms. To help with this, ROS comes with some built-in\nnodes that perform some common broadcasting tasks.\n\n##  Broadcasting Single Frames\n\nThe first way is to manually broadcast them using ` static_transform_publisher\n` . As you might guess, this tool can\u2019t broadcast dynamic transforms, only\nstatic ones. That might seem a bit useless, but it\u2019s very helpful for learning\ntransforms, doing quick tests, and acting as the \u201cglue\u201d in a bigger system\n(e.g. if two different nodes expect a frame to have different names, or be in\nslightly different spots).\n\nThe command below will broadcast a static transform, with the translations and\nrotations provided, from ` parent_frame ` to ` child_frame ` . Note that the\nrotations are in radians, and are processed after the translations, in order,\nwith respect to the local coordinate system.\n\n    \n    \n    1\n    \n\n|\n\n    \n    \n    ros2 run tf2_ros static_transform_publisher x y z yaw pitch roll parent_frame child_frame\n      \n  \n---|---  \n`\n\nAs an example, we might want to have a frame ` robot_1 ` that is across and up\nfrom a ` world ` frame, at a 45\u00b0 (0.785 rad) angle. To do that we\u2019d use the\nfollowing command:\n\n    \n    \n    1\n    \n\n|\n\n    \n    \n    ros2 run tf2_ros static_transform_publisher 2 1 0 0.785 0 0 world robot_1\n      \n  \n---|---  \n`\n\n![TF Sidecar](/media/assets/posts/ready-for-ros/tf_sidecar.png)\n\nLet\u2019s pretend we have a second robot that always sits to the right of our\nfirst one (like a sidecar). Using a second terminal, we can create another\nstatic transform using the command below to create a new frame, ` robot_2 `\nthat sits 1m in the positive x direction of ` robot_1 ` .\n\n    \n    \n    1\n    \n\n|\n\n    \n    \n    ros2 run tf2_ros static_transform_publisher 1 0 0 0 0 0 robot_1 robot_2\n      \n  \n---|---  \n`\n\nTo check if these worked, we\u2019ll use the ROS visualisation tool, RViz.\n\n##  Viewing Frames and Transforms in RVIZ\n\nIn ROS 2, RViz (the ROS visualisation tool) is called ` rviz2 ` , and is in a\npackage with the same name. So we just need to run:\n\n    \n    \n    1\n    \n\n|\n\n    \n    \n    ros2 run rviz2 rviz2\n      \n  \n---|---  \n`\n\n> Note, you can just run ` rviz2 ` directly as a shortcut, rather than using `\n> ros2 run ` .\n\nRViz can display all kinds of different data. To display TF data, we click the\n\u201cAdd\u201d button in the bottom-left corner, and select \u201cTF\u201d.\n\n![Adding TF to Visualisation](/media/assets/posts/ready-for-\nros/tf_screenshot_rviz_add.png)\n\nOur transforms won\u2019t appear just yet, because we haven\u2019t told RViz which frame\nto use as a reference (it defaults to ` map ` , which doesn\u2019t exist right\nnow). Up in the top-left corner we can select ` world ` as our fixed frame.\n\n![Fixing reference frame](/media/assets/posts/ready-for-\nros/tf_screenshot_fix_frame.png)\n\nThe \u201cGlobal Status\u201d should become healthy and our two frames should appear,\nwith a line between them to indicate the transform.\n\n> Note that RViz represents the transform as an arrow from child to parent,\n> rather than parent to child as in the introduction and in ` view_frames `\n> below.\n\nWe can configure the data displayed in RViz using the left panel. For example,\nwe can open up the settings for the TF visualisation and enable displaying\nframe names.\n\n![Static TF Visualisation](/media/assets/posts/ready-for-\nros/tf_screenshot_static_1.png)\n\nIf we go back to our first terminal, and rerun the command with a larger\nrotation of 90\u00b0 (1.57 rad), we should see in RViz that the first robot\u2019s\nmarker rotates, and the second robot moves too because its frame is defined\nrelative to the first robot.\n\n    \n    \n    1\n    \n\n|\n\n    \n    \n    ros2 run tf2_ros static_transform_publisher 2 1 0 1.57 0 0 world robot_1\n      \n  \n---|---  \n`\n\n![Static TF second rotation](/media/assets/posts/ready-for-\nros/tf_screenshot_static_2.png)\n\nIt\u2019s good to play around with this and get a feel for how transforms work. Try\nchanging the fixed frame (top-left) to be one of the robots instead of ` world\n` , adjusting the frames to new positions and rotations, or adding some new\nones.\n\nWe need to make sure to stop all the ` static_transform_publishers ` and close\nRViz before we move to the next part, otherwise they will interfere.\n\n##  Broadcasting a Moving Robot\n\nWe\u2019ve learnt some cool tricks so far, but we\u2019re still stuck publishing static\nframes. We want our robot to move! Before we tackle this we need to install a\ncouple of extra packages:\n\n    \n    \n    1\n    \n\n|\n\n    \n    \n    sudo apt install ros-foxy-xacro ros-foxy-joint-state-publisher-gui\n      \n  \n---|---  \n`\n\nThe first step in doing this is to make sure we have a URDF file for our\nrobot. This is a kind of configuration file where we can specify all sorts of\nphysical characteristics of the robot\u2019s components, such as their size, shape,\ncolour, and more. There are many tutorials available for writing URDF files,\nbut for now we can use [ this example file\n](https://gist.github.com/joshnewans/69cb8a049fb4606b0a6bdecd6933164e) which\nis for a manipulator similar to the one from the introduction.\n\n![TF Gripper Again](/media/assets/posts/ready-for-ros/tf_gripper_again.png)\n\nIn URDF, a robot is made up of a series of rigid components called _links_ ,\nand the links are joined together in a parent-child tree structure, where the\nrelationships between different links are called _joints_ . Seem familiar?\n\n![URDF TF comparison](/media/assets/posts/ready-for-ros/urdf_tf.png)\n\nIt\u2019s not too hard to see how the link/joint pattern is very similar to the\nframe/transform pattern. Because they are so tightly related, there is a ROS\nnode called ` robot_state_publisher ` which can take in a URDF file and\nautomatically broadcast all the transforms from it. It will also publish the\nfull contents of the URDF file to the topic ` /robot_description ` so that any\nother nodes that need it can all use the same file.\n\nIn the URDF file each joint can be defined as \u201cfixed\u201d, or one of a variety of\nmovable types (e.g. continuous spinning, limited rotation, linear sliding).\nFor the joints that are fixed, ` robot_state_publisher ` can just publish a\nstatic transform, but for the ones that move it needs an external value (e.g\nan angle or distance) to calculate the dynamic transform for that point in\ntime. To get these values, it subscribes to a topic called ` /joint_states ` ,\nwhich will contain ` JointState ` messages. These messages can contain\ninformation about the position, velocity, or effort of a joint (but for now we\nwill only use position).\n\n![Robot State Publisher Diagram](/media/assets/posts/ready-for-ros/rsp.png)\n\nSuddenly our job got a whole lot easier! Instead of having to broadcast whole\ntransforms, all we need to do is publish ` JointState ` messages. Normally,\nthis data will come from actuator feedback sensors on the robot such as\nencoders or potentiometers (and in a simulation environment those can be\nsimulated). For now, we will just fake the joint states using a tool called `\njoint_state_publisher_gui ` . This node will look at the ` /robot_description\n` topic published by ` robot_state_publisher ` , find any joints that can be\nmoved, and display a slider for them. It reads the values from these sliders,\nand publishes them to ` /joint_states ` .\n\n![Joint State Publishers Diagram](/media/assets/posts/ready-for-\nros/joint_states.png)\n\nLet\u2019s have a go at running all this.\n\nFirst we\u2019ll run ` robot_state_publisher ` , which can be a bit confusing when\ndoing it for the first time as passing in the URDF file in is a bit tricky.\nThe URDF is taken on the parameter ` robot_description ` , so the command will\nlook something like:\n\n    \n    \n    1\n    \n\n|\n\n    \n    \n    ros2 run robot_state_publisher robot_state_publisher --ros-args -p robot_description:=(something here)\n      \n  \n---|---  \n`\n\nYou might expect the ` robot_description ` parameter to be a path to a URDF\nfile, but it actually expects the full _content_ of the URDF file to be passed\nin at the command line. To achieve this we need to use the ` xacro ` software\non the URDF to preprocess it, run that inside a subshell ( ` $(...) ` ), and\nenclose it in quotes ( ` \"...\" ` ) so that the spaces don\u2019t break everything.\nSo our run command will look more like:\n\n    \n    \n    1\n    \n\n|\n\n    \n    \n    ros2 run robot_state_publisher robot_state_publisher --ros-args -p robot_description:=\"$(xacro path/to/my/xacro/file.urdf.xacro)\"\n      \n  \n---|---  \n`\n\n> Note, because it is such a pain to run ` robot_state_publisher ` this way,\n> it is generally easiest to create a launch file to do it for us. An example\n> one is available [ here\n> ](https://gist.github.com/joshnewans/d0e7992dba50923a7628110d740050ea) .\n\nThen, to publish the joint states, we can run\n\n    \n    \n    1\n    \n\n|\n\n    \n    \n    ros2 run joint_state_publisher_gui joint_state_publisher_gui\n      \n  \n---|---  \n`\n\nFinally, we can launch RViz again, add the TF visualisation, and see our\nframes move as we adjust the sliders. We can also add a \u201cRobotModel\u201d\nvisualisation in RViz. Use the options to select ` /robot_description ` as the\ntopic, and a visual representation of the links should appear.\n\n![Displaying robot in RViz](/media/assets/posts/ready-for-\nros/tf_joints_moving.gif)\n\n> Note, For the case of a mobile platform, things will get a bit more\n> complicated. ` robot_state_publisher ` can broadcast all the transforms\n> within the robot, but you\u2019ll need other nodes to publish transforms such as\n> the robot\u2019s location within the environment. There are existing nodes to\n> handle this kind of thing, but they\u2019ll be covered in later tutorials.\n\n##  Under the hood\n\nHopefully the above example worked, but sometimes when we\u2019re working with\ntransforms things aren\u2019t working properly and we need to figure out why.\n\nAs mentioned earlier, the transform data is published across two topics, ` /tf\n` and ` /tf_static ` . We can try to listen to these topics directly using `\nros2 topic echo ` , but that can sometimes be tricky to interpret. To help,\nROS comes with a tool (do we need to install ` tf2_tools ` ?) called `\nview_frames ` that lets us visualise the transform tree, along with\ninformation about how it is being broadcast.\n\n> Note, in ROS 1 there was a useful tool called ` rqt_tf_tree ` which did\n> exactly this but with less hassle. At time of writing, however, this hasn\u2019t\n> been ported to ROS 2, and so we have to use ` view_frames ` instead.\n\nThe ` view_frames ` tool is actually a Python script which listens to the\ntransforms for a few seconds, then generates a file called ` frames.pdf ` (and\nalso ` frames.gv ` ) in whatever directory the terminal was in when the script\nwas executed (for a fresh terminal this will be your home directory).\n\nThe script is part of the ` tf2_tools ` package, so all we need to do is run:\n\n    \n    \n    1\n    \n\n|\n\n    \n    \n    ros2 run tf2_tools view_frames.py\n      \n  \n---|---  \n`\n\nIf we take a look at the resulting file (either opening in a file browser, or\nfrom the terminal with ` atril frames.pdf ` ), we can see the tree visualised.\nNote that the arrows here are reversed compared to RViz (and are the same as\nin the introduction). We won\u2019t worry too much about the rest of the\ninformation displayed for now.\n\n> If you\u2019re not familiar with it, the big numbers starting with \u201c16314\u2026\u2026\u201d are\n> times, represented in \u201cUnix Time\u201d which is commonly used in Linux systems,\n> and so in robotic platforms. For more info on Unix Time (a.k.a Epoch Time)\n> check out the [ Epoch Converter ](https://www.epochconverter.com/) . When\n> running simulations, Gazebo will generate its own time source, and the\n> numbers will be in seconds since Gazebo was started.\n\n![Viewing TF tree structure](/media/assets/posts/ready-for-ros/tf_frames.png)\n\n##  Conclusion\n\nThe ROS transform system is a powerful tool and we\u2019ve only just scratched the\nsurface of how we can use it. The details of how we use TF will depend on many\nfactors such as whether our robot is mobile, or a manipulator (or a mobile\nmanipulator), and whether we are running simulations or on physical hardware.\nIn future tutorials we\u2019ll look more closely at how TF can be used for\nparticular projects.\n\nNext up, [ we\u2019ll see how to write our own URDF files ](/ready-for-ros-7-urdf/)\n.\n\n24 Sep 2021\n\n  * [ ros ](/categories#ros)\n\n[ \u00ab Getting Ready for ROS Part 5: Making your First Package\n](https://articulatedrobotics.xyz/ready-for-ros-5-packages/) [ Getting Ready\nfor ROS Part 7: Describing a robot with URDF \u00bb\n](https://articulatedrobotics.xyz/ready-for-ros-7-urdf/)\n\n##  Explore  \u2192\n\n[ transformations (5) ](/categories#transformations) [ linear (1)\n](/categories#linear) [ coordinate (4) ](/categories#coordinate) [ 2d (1)\n](/categories#2d) [ transforms (1) ](/categories#transforms) [ rotations (1)\n](/categories#rotations) [ posts (1) ](/categories#posts) [ ros (23)\n](/categories#ros)\n\nCopyright \u00a9 2023 Articulated Robotics\n\n[ Mediumish Jekyll Theme ](https://www.wowthemes.net/mediumish-free-jekyll-\ntemplate/) by WowThemes.net\n\n"
  },
  {
    "id": "image_callback/AboutExecutorshtml.txt",
    "content": "[ ROS 2 Documentation: Foxy ![Logo](../_static/foxy-small.png)\n](../index.html)\n\n  * [ Installation ](../Installation.html)\n    * [ Ubuntu (Debian) ](../Installation/Ubuntu-Install-Debians.html)\n    * [ Windows (binary) ](../Installation/Windows-Install-Binary.html)\n    * [ Alternatives ](../Installation/Alternatives.html)\n      * [ Ubuntu (source) ](../Installation/Alternatives/Ubuntu-Development-Setup.html)\n      * [ Ubuntu (binary) ](../Installation/Alternatives/Ubuntu-Install-Binary.html)\n      * [ Windows (source) ](../Installation/Alternatives/Windows-Development-Setup.html)\n      * [ macOS (source) ](../Installation/Alternatives/macOS-Development-Setup.html)\n      * [ macOS (binary) ](../Installation/Alternatives/macOS-Install-Binary.html)\n      * [ Fedora (source) ](../Installation/Alternatives/Fedora-Development-Setup.html)\n      * [ Latest development (source) ](../Installation/Alternatives/Latest-Development-Setup.html)\n    * [ Maintain source checkout ](../Installation/Maintaining-a-Source-Checkout.html)\n    * [ Testing with pre-release binaries ](../Installation/Testing.html)\n    * [ DDS implementations ](../Installation/DDS-Implementations.html)\n      * [ Connext security plugins ](../Installation/DDS-Implementations/Install-Connext-Security-Plugins.html)\n      * [ RTI Connext DDS ](../Installation/DDS-Implementations/Install-Connext-University-Eval.html)\n      * [ Eclipse Cyclone DDS ](../Installation/DDS-Implementations/Working-with-Eclipse-CycloneDDS.html)\n      * [ GurumNetworks GurumDDS ](../Installation/DDS-Implementations/Working-with-GurumNetworks-GurumDDS.html)\n      * [ eProsima Fast DDS ](../Installation/DDS-Implementations/Working-with-eProsima-Fast-DDS.html)\n  * [ Distributions ](../Releases.html)\n    * [ Iron Irwini ( ` iron  ` ) ](../Releases/Release-Iron-Irwini.html)\n      * [ Iron Irwini Changelog ](../Releases/Iron-Irwini-Complete-Changelog.html)\n    * [ Humble Hawksbill ( ` humble  ` ) ](../Releases/Release-Humble-Hawksbill.html)\n      * [ Humble Hawksbill changelog ](../Releases/Humble-Hawksbill-Complete-Changelog.html)\n    * [ Rolling Ridley ( ` rolling  ` ) ](../Releases/Release-Rolling-Ridley.html)\n    * [ Development Distribution ](../Releases/Development.html)\n      * [ Jazzy Jalisco (codename \u00e2\u0080\u0098jazzy\u00e2\u0080\u0099; May, 2024) ](../Releases/Release-Jazzy-Jalisco.html)\n    * [ End-of-Life Distributions ](../Releases/End-of-Life.html)\n      * [ Galactic Geochelone ( ` galactic  ` ) ](../Releases/Release-Galactic-Geochelone.html)\n        * [ Galactic Geochelone changelog ](../Releases/Galactic-Geochelone-Complete-Changelog.html)\n      * [ Foxy Fitzroy ( ` foxy  ` ) ](../Releases/Release-Foxy-Fitzroy.html)\n      * [ Eloquent Elusor ( ` eloquent  ` ) ](../Releases/Release-Eloquent-Elusor.html)\n      * [ Dashing Diademata ( ` dashing  ` ) ](../Releases/Release-Dashing-Diademata.html)\n      * [ Crystal Clemmys ( ` crystal  ` ) ](../Releases/Release-Crystal-Clemmys.html)\n      * [ Bouncy Bolson ( ` bouncy  ` ) ](../Releases/Release-Bouncy-Bolson.html)\n      * [ Ardent Apalone ( ` ardent  ` ) ](../Releases/Release-Ardent-Apalone.html)\n      * [ Beta 3 ( ` r2b3  ` ) ](../Releases/Beta3-Overview.html)\n      * [ Beta 2 ( ` r2b2  ` ) ](../Releases/Beta2-Overview.html)\n      * [ Beta 1 ( ` Asphalt  ` ) ](../Releases/Beta1-Overview.html)\n      * [ Alphas ](../Releases/Alpha-Overview.html)\n    * [ Development process for a release ](../Releases/Release-Process.html)\n  * [ Tutorials ](../Tutorials.html)\n    * [ Beginner: CLI tools ](../Tutorials/Beginner-CLI-Tools.html)\n      * [ Configuring environment ](../Tutorials/Beginner-CLI-Tools/Configuring-ROS2-Environment.html)\n      * [ Using ` turtlesim  ` , ` ros2  ` , and ` rqt  ` ](../Tutorials/Beginner-CLI-Tools/Introducing-Turtlesim/Introducing-Turtlesim.html)\n      * [ Understanding nodes ](../Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Nodes/Understanding-ROS2-Nodes.html)\n      * [ Understanding topics ](../Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Topics/Understanding-ROS2-Topics.html)\n      * [ Understanding services ](../Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Services/Understanding-ROS2-Services.html)\n      * [ Understanding parameters ](../Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Parameters/Understanding-ROS2-Parameters.html)\n      * [ Understanding actions ](../Tutorials/Beginner-CLI-Tools/Understanding-ROS2-Actions/Understanding-ROS2-Actions.html)\n      * [ Using ` rqt_console  ` to view logs ](../Tutorials/Beginner-CLI-Tools/Using-Rqt-Console/Using-Rqt-Console.html)\n      * [ Launching nodes ](../Tutorials/Beginner-CLI-Tools/Launching-Multiple-Nodes/Launching-Multiple-Nodes.html)\n      * [ Recording and playing back data ](../Tutorials/Beginner-CLI-Tools/Recording-And-Playing-Back-Data/Recording-And-Playing-Back-Data.html)\n    * [ Beginner: Client libraries ](../Tutorials/Beginner-Client-Libraries.html)\n      * [ Using ` colcon  ` to build packages ](../Tutorials/Beginner-Client-Libraries/Colcon-Tutorial.html)\n      * [ Creating a workspace ](../Tutorials/Beginner-Client-Libraries/Creating-A-Workspace/Creating-A-Workspace.html)\n      * [ Creating a package ](../Tutorials/Beginner-Client-Libraries/Creating-Your-First-ROS2-Package.html)\n      * [ Writing a simple publisher and subscriber (C++) ](../Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Publisher-And-Subscriber.html)\n      * [ Writing a simple publisher and subscriber (Python) ](../Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html)\n      * [ Writing a simple service and client (C++) ](../Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Service-And-Client.html)\n      * [ Writing a simple service and client (Python) ](../Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Service-And-Client.html)\n      * [ Creating custom msg and srv files ](../Tutorials/Beginner-Client-Libraries/Custom-ROS2-Interfaces.html)\n      * [ Implementing custom interfaces ](../Tutorials/Beginner-Client-Libraries/Single-Package-Define-And-Use-Interface.html)\n      * [ Using parameters in a class (C++) ](../Tutorials/Beginner-Client-Libraries/Using-Parameters-In-A-Class-CPP.html)\n      * [ Using parameters in a class (Python) ](../Tutorials/Beginner-Client-Libraries/Using-Parameters-In-A-Class-Python.html)\n      * [ Using ` ros2doctor  ` to identify issues ](../Tutorials/Beginner-Client-Libraries/Getting-Started-With-Ros2doctor.html)\n      * [ Creating and using plugins (C++) ](../Tutorials/Beginner-Client-Libraries/Pluginlib.html)\n    * [ Intermediate ](../Tutorials/Intermediate.html)\n      * [ Managing Dependencies with rosdep ](../Tutorials/Intermediate/Rosdep.html)\n      * [ Creating an action ](../Tutorials/Intermediate/Creating-an-Action.html)\n      * [ Writing an action server and client (C++) ](../Tutorials/Intermediate/Writing-an-Action-Server-Client/Cpp.html)\n      * [ Writing an action server and client (Python) ](../Tutorials/Intermediate/Writing-an-Action-Server-Client/Py.html)\n      * [ Composing multiple nodes in a single process ](../Tutorials/Intermediate/Composition.html)\n      * [ Launch ](../Tutorials/Intermediate/Launch/Launch-Main.html)\n        * [ Creating a launch file ](../Tutorials/Intermediate/Launch/Creating-Launch-Files.html)\n        * [ Integrating launch files into ROS 2 packages ](../Tutorials/Intermediate/Launch/Launch-system.html)\n        * [ Using substitutions ](../Tutorials/Intermediate/Launch/Using-Substitutions.html)\n        * [ Using event handlers ](../Tutorials/Intermediate/Launch/Using-Event-Handlers.html)\n        * [ Managing large projects ](../Tutorials/Intermediate/Launch/Using-ROS2-Launch-For-Large-Projects.html)\n      * [ ` tf2  ` ](../Tutorials/Intermediate/Tf2/Tf2-Main.html)\n        * [ Introducing ` tf2  ` ](../Tutorials/Intermediate/Tf2/Introduction-To-Tf2.html)\n        * [ Writing a static broadcaster (Python) ](../Tutorials/Intermediate/Tf2/Writing-A-Tf2-Static-Broadcaster-Py.html)\n        * [ Writing a static broadcaster (C++) ](../Tutorials/Intermediate/Tf2/Writing-A-Tf2-Static-Broadcaster-Cpp.html)\n        * [ Writing a broadcaster (Python) ](../Tutorials/Intermediate/Tf2/Writing-A-Tf2-Broadcaster-Py.html)\n        * [ Writing a broadcaster (C++) ](../Tutorials/Intermediate/Tf2/Writing-A-Tf2-Broadcaster-Cpp.html)\n        * [ Writing a listener (Python) ](../Tutorials/Intermediate/Tf2/Writing-A-Tf2-Listener-Py.html)\n        * [ Writing a listener (C++) ](../Tutorials/Intermediate/Tf2/Writing-A-Tf2-Listener-Cpp.html)\n        * [ Adding a frame (Python) ](../Tutorials/Intermediate/Tf2/Adding-A-Frame-Py.html)\n        * [ Adding a frame (C++) ](../Tutorials/Intermediate/Tf2/Adding-A-Frame-Cpp.html)\n        * [ Using time (Python) ](../Tutorials/Intermediate/Tf2/Learning-About-Tf2-And-Time-Py.html)\n        * [ Using time (C++) ](../Tutorials/Intermediate/Tf2/Learning-About-Tf2-And-Time-Cpp.html)\n        * [ Traveling in time (Python) ](../Tutorials/Intermediate/Tf2/Time-Travel-With-Tf2-Py.html)\n        * [ Traveling in time (C++) ](../Tutorials/Intermediate/Tf2/Time-Travel-With-Tf2-Cpp.html)\n        * [ Debugging ](../Tutorials/Intermediate/Tf2/Debugging-Tf2-Problems.html)\n        * [ Quaternion fundamentals ](../Tutorials/Intermediate/Tf2/Quaternion-Fundamentals.html)\n        * [ Using stamped datatypes with ` tf2_ros::MessageFilter  ` ](../Tutorials/Intermediate/Tf2/Using-Stamped-Datatypes-With-Tf2-Ros-MessageFilter.html)\n      * [ Testing ](../Tutorials/Intermediate/Testing/Testing-Main.html)\n        * [ Running Tests in ROS 2 from the Command Line ](../Tutorials/Intermediate/Testing/CLI.html)\n        * [ Writing Basic Tests with C++ with GTest ](../Tutorials/Intermediate/Testing/Cpp.html)\n        * [ Writing Basic Tests with Python ](../Tutorials/Intermediate/Testing/Python.html)\n      * [ URDF ](../Tutorials/Intermediate/URDF/URDF-Main.html)\n        * [ Building a visual robot model from scratch ](../Tutorials/Intermediate/URDF/Building-a-Visual-Robot-Model-with-URDF-from-Scratch.html)\n        * [ Building a movable robot model ](../Tutorials/Intermediate/URDF/Building-a-Movable-Robot-Model-with-URDF.html)\n        * [ Adding physical and collision properties ](../Tutorials/Intermediate/URDF/Adding-Physical-and-Collision-Properties-to-a-URDF-Model.html)\n        * [ Using Xacro to clean up your code ](../Tutorials/Intermediate/URDF/Using-Xacro-to-Clean-Up-a-URDF-File.html)\n        * [ Using URDF with ` robot_state_publisher  ` ](../Tutorials/Intermediate/URDF/Using-URDF-with-Robot-State-Publisher.html)\n    * [ Advanced ](../Tutorials/Advanced.html)\n      * [ Enabling topic statistics (C++) ](../Tutorials/Advanced/Topic-Statistics-Tutorial/Topic-Statistics-Tutorial.html)\n      * [ Using Fast DDS Discovery Server as discovery protocol [community-contributed] ](../Tutorials/Advanced/Discovery-Server/Discovery-Server.html)\n      * [ Implementing a custom memory allocator ](../Tutorials/Advanced/Allocator-Template-Tutorial.html)\n      * [ Recording a bag from a node (C++) ](../Tutorials/Advanced/Recording-A-Bag-From-Your-Own-Node-CPP.html)\n      * [ Simulators ](../Tutorials/Advanced/Simulators/Simulation-Main.html)\n        * [ Webots ](../Tutorials/Advanced/Simulators/Webots/Simulation-Webots.html)\n          * [ Installation (Ubuntu) ](../Tutorials/Advanced/Simulators/Webots/Installation-Ubuntu.html)\n          * [ Installation (Windows) ](../Tutorials/Advanced/Simulators/Webots/Installation-Windows.html)\n          * [ Installation (macOS) ](../Tutorials/Advanced/Simulators/Webots/Installation-MacOS.html)\n          * [ Setting up a robot simulation (Basic) ](../Tutorials/Advanced/Simulators/Webots/Setting-Up-Simulation-Webots-Basic.html)\n          * [ Setting up a robot simulation (Advanced) ](../Tutorials/Advanced/Simulators/Webots/Setting-Up-Simulation-Webots-Advanced.html)\n        * [ Ignition ](../Tutorials/Advanced/Simulators/Ignition/Simulation-Ignition.html)\n          * [ Setting up a robot simulation (Ignition Gazebo) ](../Tutorials/Advanced/Simulators/Ignition/Ignition.html)\n    * [ Demos ](../Tutorials/Demos.html)\n      * [ Using quality-of-service settings for lossy networks ](../Tutorials/Demos/Quality-of-Service.html)\n      * [ Managing nodes with managed lifecycles ](../Tutorials/Demos/Managed-Nodes.html)\n      * [ Setting up efficient intra-process communication ](../Tutorials/Demos/Intra-Process-Communication.html)\n      * [ Recording and playing back data with ` rosbag  ` using the ROS 1 bridge ](../Tutorials/Demos/Rosbag-with-ROS1-Bridge.html)\n      * [ Understanding real-time programming ](../Tutorials/Demos/Real-Time-Programming.html)\n      * [ Experimenting with a dummy robot ](../Tutorials/Demos/dummy-robot-demo.html)\n      * [ Logging ](../Tutorials/Demos/Logging-and-logger-configuration.html)\n    * [ Miscellaneous ](../Tutorials/Miscellaneous.html)\n      * [ Packaging your ROS 2 application as a snap [community-contributed] ](../Tutorials/Miscellaneous/Packaging-your-ROS-2-application-as-a-snap.html)\n      * [ Deploying on IBM Cloud Kubernetes [community-contributed] ](../Tutorials/Miscellaneous/Deploying-ROS-2-on-IBM-Cloud.html)\n      * [ Using Eclipse Oxygen with ` rviz2  ` [community-contributed] ](../Tutorials/Miscellaneous/Eclipse-Oxygen-with-ROS-2-and-rviz2.html)\n      * [ Building a real-time Linux kernel [community-contributed] ](../Tutorials/Miscellaneous/Building-Realtime-rt_preempt-kernel-for-ROS-2.html)\n      * [ Building a package with Eclipse 2021-06 ](../Tutorials/Miscellaneous/Building-ROS2-Package-with-eclipse-2021-06.html)\n  * [ How-to Guides ](../How-To-Guides.html)\n    * [ Installation troubleshooting ](../How-To-Guides/Installation-Troubleshooting.html)\n    * [ Developing a ROS 2 package ](../How-To-Guides/Developing-a-ROS-2-Package.html)\n    * [ ament_cmake user documentation ](../How-To-Guides/Ament-CMake-Documentation.html)\n    * [ ament_cmake_python user documentation ](../How-To-Guides/Ament-CMake-Python-Documentation.html)\n    * [ Migrating launch files from ROS 1 to ROS 2 ](../How-To-Guides/Launch-files-migration-guide.html)\n    * [ Using Python, XML, and YAML for ROS 2 Launch Files ](../How-To-Guides/Launch-file-different-formats.html)\n    * [ Using ROS 2 launch to launch composable nodes ](../How-To-Guides/Launching-composable-nodes.html)\n    * [ Migrating YAML parameter files from ROS 1 to ROS 2 ](../How-To-Guides/Parameters-YAML-files-migration-guide.html)\n    * [ Passing ROS arguments to nodes via the command-line ](../How-To-Guides/Node-arguments.html)\n    * [ Synchronous vs. asynchronous service clients ](../How-To-Guides/Sync-Vs-Async.html)\n    * [ DDS tuning information ](../How-To-Guides/DDS-tuning.html)\n    * [ rosbag2: Overriding QoS Policies ](../How-To-Guides/Overriding-QoS-Policies-For-Recording-And-Playback.html)\n    * [ Working with multiple ROS 2 middleware implementations ](../How-To-Guides/Working-with-multiple-RMW-implementations.html)\n    * [ Cross-compilation ](../How-To-Guides/Cross-compilation.html)\n    * [ Releasing a Package ](../How-To-Guides/Releasing/Releasing-a-Package.html)\n      * [ First Time Release ](../How-To-Guides/Releasing/First-Time-Release.html)\n      * [ Subsequent Releases ](../How-To-Guides/Releasing/Subsequent-Releases.html)\n      * [ Release Team / Repository ](../How-To-Guides/Releasing/Release-Team-Repository.html)\n      * [ Release Track ](../How-To-Guides/Releasing/Release-Track.html)\n    * [ Using Python Packages with ROS 2 ](../How-To-Guides/Using-Python-Packages.html)\n    * [ Porting RQt plugins to Windows ](../How-To-Guides/RQt-Port-Plugin-Windows.html)\n    * [ Running ROS 2 nodes in Docker [community-contributed] ](../How-To-Guides/Run-2-nodes-in-single-or-separate-docker-containers.html)\n    * [ Visualizing ROS 2 data with Foxglove Studio ](../How-To-Guides/Visualizing-ROS-2-Data-With-Foxglove-Studio.html)\n    * [ ROS 2 Package Maintainer Guide ](../How-To-Guides/Package-maintainer-guide.html)\n    * [ Building a custom Debian package ](../How-To-Guides/Building-a-Custom-Debian-Package.html)\n    * [ Building ROS 2 with tracing instrumentation ](../How-To-Guides/Building-ROS-2-with-Tracing-Instrumentation.html)\n    * [ Topics vs Services vs Actions ](../How-To-Guides/Topics-Services-Actions.html)\n    * [ Using variants ](../How-To-Guides/Using-Variants.html)\n    * [ Using the ` ros2  param  ` command-line tool ](../How-To-Guides/Using-ros2-param.html)\n    * [ ROS 2 on Raspberry Pi ](../How-To-Guides/Installing-on-Raspberry-Pi.html)\n    * [ Using Callback Groups ](../How-To-Guides/Using-callback-groups.html)\n    * [ Setup ROS 2 with VSCode and Docker [community-contributed] ](../How-To-Guides/Setup-ROS-2-with-VSCode-and-Docker-Container.html)\n    * [ Building RQt from source ](../How-To-Guides/RQt-Source-Install.html)\n      * [ Building RQt from source on macOS ](../How-To-Guides/RQt-Source-Install-MacOS.html)\n      * [ Building RQt from source on Windows 10 ](../How-To-Guides/RQt-Source-Install-Windows10.html)\n  * [ Concepts ](../Concepts.html)\n    * [ The ROS_DOMAIN_ID ](About-Domain-ID.html)\n    * [ About different ROS 2 DDS/RTPS vendors ](About-Different-Middleware-Vendors.html)\n    * [ About logging and logger configuration ](About-Logging.html)\n    * [ About Quality of Service settings ](About-Quality-of-Service-Settings.html)\n    * [ About ROS 2 client libraries ](About-ROS-2-Client-Libraries.html)\n    * [ About ROS 2 interfaces ](About-ROS-Interfaces.html)\n    * [ About parameters in ROS 2 ](About-ROS-2-Parameters.html)\n    * Executors \n    * [ About topic statistics ](About-Topic-Statistics.html)\n    * [ Introspection with command line tools ](About-Command-Line-Tools.html)\n    * [ Overview and usage of RQt ](About-RQt.html)\n    * [ About Composition ](About-Composition.html)\n    * [ On the mixing of ament and catkin (catment) ](About-Catment.html)\n    * [ About Cross-compilation ](About-Cross-Compilation.html)\n    * [ About tf2 ](About-Tf2.html)\n    * [ About the build system ](About-Build-System.html)\n    * [ About internal ROS 2 interfaces ](About-Internal-Interfaces.html)\n    * [ About ROS 2 middleware implementations ](About-Middleware-Implementations.html)\n    * [ About ROS 2 client libraries ](About-ROS-2-Client-Libraries.html)\n  * [ Contact ](../Contact.html)\n  * [ The ROS 2 Project ](../The-ROS2-Project.html)\n    * [ Contributing ](../The-ROS2-Project/Contributing.html)\n      * [ ROS 2 developer guide ](../The-ROS2-Project/Contributing/Developer-Guide.html)\n      * [ Code style and language versions ](../The-ROS2-Project/Contributing/Code-Style-Language-Versions.html)\n      * [ Quality guide: ensuring code quality ](../The-ROS2-Project/Contributing/Quality-Guide.html)\n      * [ Migration guide from ROS 1 ](../The-ROS2-Project/Contributing/Migration-Guide.html)\n        * [ Python migration guide from ROS 1 ](../The-ROS2-Project/Contributing/Migration-Guide-Python.html)\n      * [ ROS Build Farms ](../The-ROS2-Project/Contributing/Build-Farms.html)\n      * [ Windows Tips and Tricks ](../The-ROS2-Project/Contributing/Windows-Tips-and-Tricks.html)\n      * [ Contributing to ROS 2 Documentation ](../The-ROS2-Project/Contributing/Contributing-To-ROS-2-Documentation.html)\n    * [ Features Status ](../The-ROS2-Project/Features.html)\n    * [ Feature Ideas ](../The-ROS2-Project/Feature-Ideas.html)\n    * [ Roadmap ](../The-ROS2-Project/Roadmap.html)\n    * [ ROSCon Talks ](../The-ROS2-Project/ROSCon-Content.html)\n    * [ Project Governance ](../The-ROS2-Project/Governance.html)\n      * [ ROS 2 Technical Steering Committee Charter ](../The-ROS2-Project/Governance/ROS2-TSC-Charter.html)\n      * [ ROS 2 TSC applicant intake process ](../The-ROS2-Project/Governance/ROS2-TSC-Intake-process.html)\n      * [ How to Start a Community Working Group ](../The-ROS2-Project/Governance/How-To-Start-A-Community-Working-Group.html)\n    * [ Marketing ](../The-ROS2-Project/Marketing.html)\n  * [ Related Projects ](../Related-Projects.html)\n    * [ Intel ROS 2 Projects ](../Related-Projects/Intel-ROS2-Projects.html)\n    * [ NVIDIA ROS 2 Projects ](../Related-Projects/Nvidia-ROS2-Projects.html)\n  * [ Glossary ](../Glossary.html)\n  * [ Citations ](../Citations.html)\n\n__ [ ROS 2 Documentation: Foxy ](../index.html)\n\n  * [ ](../index.html)\n  * [ Concepts ](../Concepts.html)\n  * Executors \n  * [ Edit on GitHub ](https://github.com/ros2/ros2_documentation/blob/foxy/source/Concepts/About-Executors.rst)\n\n* * *\n\n**You're reading the documentation for a version of ROS 2 that has reached its\nEOL (end-of-life), and is no longer officially supported. If you want up-to-\ndate information, please have a look at[ Iron ](../../iron/index.html) . **\n\n#  Executors  \u00ef\u0083\u0081\n\nTable of Contents\n\n  * Overview \n\n  * Basic use \n\n  * Types of Executors \n\n  * Callback groups \n\n  * Scheduling semantics \n\n  * Outlook \n\n  * Further information \n\n##  Overview  \u00ef\u0083\u0081\n\nExecution management in ROS 2 is explicated by the concept of Executors. An\nExecutor uses one or more threads of the underlying operating system to invoke\nthe callbacks of subscriptions, timers, service servers, action servers, etc.\non incoming messages and events. The explicit Executor class (in [\nexecutor.hpp\n](https://github.com/ros2/rclcpp/blob/foxy/rclcpp/include/rclcpp/executor.hpp)\nin rclcpp, in [ executors.py\n](https://github.com/ros2/rclpy/blob/foxy/rclpy/rclpy/executors.py) in rclpy,\nor in [ executor.h\n](https://github.com/ros2/rclc/blob/master/rclc/include/rclc/executor.h) in\nrclc) provides more control over execution management than the spin mechanism\nin ROS 1, although the basic API is very similar.\n\nIn the following, we focus on the C++ Client Library _rclcpp_ .\n\n##  Basic use  \u00ef\u0083\u0081\n\nIn the simplest case, the main thread is used for processing the incoming\nmessages and events of a Node by calling ` rclcpp::spin(..)  ` as follows:\n\n    \n    \n    int main(int argc, char* argv[])\n    {\n       // Some initialization.\n       rclcpp::init(argc, argv);\n       ...\n    \n       // Instantiate a node.\n       rclcpp::Node::SharedPtr node = ...\n    \n       // Run the executor.\n       rclcpp::spin(node);\n    \n       // Shutdown and exit.\n       ...\n       return 0;\n    }\n    \n\nThe call to ` spin(node)  ` basically expands to an instantiation and\ninvocation of the Single-Threaded Executor, which is the simplest Executor:\n\n    \n    \n    rclcpp::executors::SingleThreadedExecutor executor;\n    executor.add_node(node);\n    executor.spin();\n    \n\nBy invoking ` spin()  ` of the Executor instance, the current thread starts\nquerying the rcl and middleware layers for incoming messages and other events\nand calls the corresponding callback functions until the node shuts down. In\norder not to counteract the QoS settings of the middleware, an incoming\nmessage is not stored in a queue on the Client Library layer but kept in the\nmiddleware until it is taken for processing by a callback function. (This is a\ncrucial difference to ROS 1.) A _wait set_ is used to inform the Executor\nabout available messages on the middleware layer, with one binary flag per\nqueue. The _wait set_ is also used to detect when timers expire.\n\n![../_images/executors_basic_principle.png](../_images/executors_basic_principle.png)\n\nThe Single-Threaded Executor is also used by the container process for [\ncomponents  ](About-Composition.html) , i.e. in all cases where nodes are\ncreated and executed without an explicit main function.\n\n##  Types of Executors  \u00ef\u0083\u0081\n\nCurrently, rclcpp provides three Executor types, derived from a shared parent\nclass:\n\n![digraph Flatland {\n\n   Executor -> SingleThreadedExecutor \\[dir = back, arrowtail = empty\\];\n\n   Executor -> MultiThreadedExecutor \\[dir = back, arrowtail = empty\\];\n\n   Executor -> StaticSingleThreadedExecutor \\[dir = back, arrowtail = empty\\];\n\n   Executor  \\[shape=polygon,sides=4\\];\n\n   SingleThreadedExecutor  \\[shape=polygon,sides=4\\];\n\n   MultiThreadedExecutor  \\[shape=polygon,sides=4\\];\n\n   StaticSingleThreadedExecutor  \\[shape=polygon,sides=4\\];\n\n   }](../_images/graphviz-c1160194dae16051e00be2abef23d0fce5e7c347.png)\n\nThe _Multi-Threaded Executor_ creates a configurable number of threads to\nallow for processing multiple messages or events in parallel. The _Static\nSingle-Threaded Executor_ optimizes the runtime costs for scanning the\nstructure of a node in terms of subscriptions, timers, service servers, action\nservers, etc. It performs this scan only once when the node is added, while\nthe other two executors regularly scan for such changes. Therefore, the Static\nSingle-Threaded Executor should be used only with nodes that create all\nsubscriptions, timers, etc. during initialization.\n\nAll three executors can be used with multiple nodes by calling ` add_node(..)\n` for each node.\n\n    \n    \n    rclcpp::Node::SharedPtr node1 = ...\n    rclcpp::Node::SharedPtr node2 = ...\n    rclcpp::Node::SharedPtr node3 = ...\n    \n    rclcpp::executors::StaticSingleThreadedExecutor executor;\n    executor.add_node(node1);\n    executor.add_node(node2);\n    executor.add_node(node3);\n    executor.spin();\n    \n\nIn the above example, the one thread of a Static Single-Threaded Executor is\nused to serve three nodes together. In case of a Multi-Threaded Executor, the\nactual parallelism depends on the callback groups.\n\n##  Callback groups  \u00ef\u0083\u0081\n\nROS 2 allows organizing the callbacks of a node in groups. In rclcpp, such a\n_callback group_ can be created by the ` create_callback_group  ` function of\nthe Node class. In rclpy, the same is done by calling the constructor of the\nspecific callback group type. The callback group must be stored throughout\nexecution of the node (eg. as a class member), or otherwise the executor\nwon\u00e2\u0080\u0099t be able to trigger the callbacks. Then, this callback group can be\nspecified when creating a subscription, timer, etc. - for example by the\nsubscription options:\n\nC++  Python\n\n    \n    \n    my_callback_group = create_callback_group(rclcpp::CallbackGroupType::MutuallyExclusive);\n    \n    rclcpp::SubscriptionOptions options;\n    options.callback_group = my_callback_group;\n    \n    my_subscription = create_subscription<Int32>(\"/topic\", rclcpp::SensorDataQoS(),\n                                                 callback, options);\n    \n    \n    \n    my_callback_group = MutuallyExclusiveCallbackGroup()\n    my_subscription = self.create_subscription(Int32, \"/topic\", self.callback, qos_profile=1,\n                                               callback_group=my_callback_group)\n    \n\nAll subscriptions, timers, etc. that are created without the indication of a\ncallback group are assigned to the _default callback group_ . The default\ncallback group can be queried via `\nNodeBaseInterface::get_default_callback_group()  ` in rclcpp and by `\nNode.default_callback_group  ` in rclpy.\n\nThere are two types of callback groups, where the type has to be specified at\ninstantiation time:\n\n  * _Mutually exclusive:_ Callbacks of this group must not be executed in parallel. \n\n  * _Reentrant:_ Callbacks of this group may be executed in parallel. \n\nCallbacks of different callback groups may always be executed in parallel. The\nMulti-Threaded Executor uses its threads as a pool to process as many\ncallbacks as possible in parallel according to these conditions. For tips on\nhow to use callback groups efficiently, see [ Using Callback Groups  ](../How-\nTo-Guides/Using-callback-groups.html) .\n\nSince Galactic, the interface of the Executor base class in rclcpp has been\nrefined by a new function ` add_callback_group(..)  ` . This allows\ndistributing callback groups to different Executors. By configuring the\nunderlying threads using the operating system scheduler, specific callbacks\ncan be prioritized over other callbacks. For example, the subscriptions and\ntimers of a control loop can be prioritized over all other subscriptions and\nstandard services of a node. The [ examples_rclcpp_cbg_executor package\n](https://github.com/ros2/examples/tree/foxy/rclcpp/executors/cbg_executor)\nprovides a demo of this mechanism.\n\n##  Scheduling semantics  \u00ef\u0083\u0081\n\nIf the processing time of the callbacks is shorter than the period with which\nmessages and events occur, the Executor basically processes them in FIFO\norder. However, if the processing time of some callbacks is longer, messages\nand events will be queued on the lower layers of the stack. The wait set\nmechanism reports only very little information about these queues to the\nExecutor. In detail, it only reports whether there are any messages for a\ncertain topic or not. The Executor uses this information to process the\nmessages (including services and actions) in a round-robin fashion - but not\nin FIFO order. The following flow diagram visualizes this scheduling\nsemantics.\n\n![../_images/executors_scheduling_semantics.png](../_images/executors_scheduling_semantics.png)\n\nThis semantics was first described in a [ paper by Casini et al. at ECRTS 2019\n](https://drops.dagstuhl.de/opus/volltexte/2019/10743/pdf/LIPIcs-\nECRTS-2019-6.pdf) . (Note: The paper also explains that timer events are\nprioritized over all other messages. [ This prioritization was removed in\nEloquent. ](https://github.com/ros2/rclcpp/pull/841) )\n\n##  Outlook  \u00ef\u0083\u0081\n\nWhile the three Executors of rclcpp work well for most applications, there are\nsome issues that make them not suitable for real-time applications, which\nrequire well-defined execution times, determinism, and custom control over the\nexecution order. Here is a summary of some of these issues:\n\n  1. Complex and mixed scheduling semantics. Ideally you want well defined scheduling semantics to perform a formal timing analysis. \n\n  2. Callbacks may suffer from priority inversion. Higher priority callbacks may be blocked by lower priority callbacks. \n\n  3. No explicit control over the callbacks execution order. \n\n  4. No built-in control over triggering for specific topics. \n\nAdditionally, the executor overhead in terms of CPU and memory usage is\nconsiderable. The Static Single-Threaded Executor reduces this overhead\ngreatly but it might not be enough for some applications.\n\nThese issues have been partially addressed by the following developments:\n\n  * [ rclcpp WaitSet ](https://github.com/ros2/rclcpp/blob/foxy/rclcpp/include/rclcpp/wait_set.hpp) : The ` WaitSet  ` class of rclcpp allows waiting directly on subscriptions, timers, service servers, action servers, etc. instead of using an Executor. It can be used to implement deterministic, user-defined processing sequences, possibly processing multiple messages from different subscriptions together. The [ examples_rclcpp_wait_set package ](https://github.com/ros2/examples/tree/foxy/rclcpp/wait_set) provides several examples for the use of this user-level wait set mechanism. \n\n  * [ rclc Executor ](https://github.com/ros2/rclc/blob/master/rclc/include/rclc/executor.h) : This Executor from the C Client Library _rclc_ , developed for micro-ROS, gives the user fine-grained control over the execution order of callbacks and allows for custom trigger conditions to activate callbacks. Furthermore, it implements ideas of the Logical Execution Time (LET) semantics. \n\n##  Further information  \u00ef\u0083\u0081\n\n  * Michael P\u00c3\u00b6hnl et al.: [ \u00e2\u0080\u009cROS 2 Executor: How to make it efficient, real-time and deterministic?\u00e2\u0080\u009d ](https://www.apex.ai/roscon-21) . Workshop at ROS World 2021. Virtual event. 19 October 2021. \n\n  * Ralph Lange: [ \u00e2\u0080\u009cAdvanced Execution Management with ROS 2\u00e2\u0080\u009d ](https://www.youtube.com/watch?v=Sz-nllmtcc8&t=109s) . ROS Industrial Conference. Virtual event. 16 December 2020. \n\n  * Daniel Casini, Tobias Blass, Ingo L\u00c3\u00bctkebohle, and Bj\u00c3\u00b6rn Brandenburg: [ \u00e2\u0080\u009cResponse-Time Analysis of ROS\u00c2 2 Processing Chains under Reservation-Based Scheduling\u00e2\u0080\u009d ](https://drops.dagstuhl.de/opus/volltexte/2019/10743/pdf/LIPIcs-ECRTS-2019-6.pdf) , Proc. of 31st ECRTS 2019, Stuttgart, Germany, July 2019. \n\n[ Previous ](About-ROS-2-Parameters.html \"About parameters in ROS 2\") [ Next\n](About-Topic-Statistics.html \"About topic statistics\")\n\n* * *\n\n\u00a9 Copyright 2024, Open Robotics.\n\nBuilt with [ Sphinx ](https://www.sphinx-doc.org/) using a [ theme\n](https://github.com/readthedocs/sphinx_rtd_theme) provided by [ Read the Docs\n](https://readthedocs.org) .\n\nOther Versions  v: foxy\n\nReleases\n\n     [ Iron (latest) ](../../iron/index.html)\n     [ Humble ](../../humble/index.html)\n     [ Galactic (EOL) ](../../galactic/Concepts/About-Executors.html)\n     [ Foxy (EOL) ](About-Executors.html)\n     [ Eloquent (EOL) ](../../eloquent/index.html)\n     [ Dashing (EOL) ](../../dashing/index.html)\n     [ Crystal (EOL) ](../../crystal/index.html)\n\nIn Development\n\n     [ Rolling ](../../rolling/index.html)\n\n"
  },
  {
    "id": "nav2bringup/nav2bringup.txt",
    "content": "  \nROS Resources: [ Documentation ](http://docs.ros.org/) | [ Support\n](http://wiki.ros.org/Support) | [ Discussion Forum\n](http://discourse.ros.org/) | [ Service Status ](http://status.ros.org/) | [\nros @ Robotics Stack Exchange\n](https://robotics.stackexchange.com/questions/tagged/ros)  \n---  \n  \n[ ROS Index ](/)\n\n  * [ About ](/about)\n  * Index \n    * [ Package List ](/packages/page/1/time/)\n    * [ Repository List ](/repos/page/1/time/)\n    *     * [ Nodes ](/srvs/)\n    * [ Messages ](/msgs/)\n    * [ Services ](/srvs/)\n    * [ Plugins ](/srvs/)\n    *     * [ System Dependencies ](/deps/)\n  * [ Contribute ](/contribute)\n  * [ Stats ](/stats)\n\n[ ](https://lunrjs.com/guides/searching.html \"Help to Search\")\n\n  1. [ Home ](/)\n  2. [ Packages ](/packages)\n  3. nav2_bringup \n\nhumble  iron  rolling  noetic\n\nOlder\n\n  * ardent \n  * bouncy \n  * crystal \n  * eloquent \n  * dashing \n  * galactic \n  * foxy \n  * lunar \n  * jade \n  * indigo \n  * hydro \n  * kinetic \n  * melodic \n\n![](/assets/package.png) |\n\n###  [ nav2_bringup ](/p/nav2_bringup) package from [ navigation2\n](/r/navigation2/github-ros-planning-navigation2) repo\n\n[ nav2_amcl ](/p/nav2_amcl/github-ros-planning-navigation2) [\nnav2_behavior_tree ](/p/nav2_behavior_tree/github-ros-planning-navigation2) [\nnav2_behaviors ](/p/nav2_behaviors/github-ros-planning-navigation2)\nnav2_bringup  [ nav2_bt_navigator ](/p/nav2_bt_navigator/github-ros-planning-\nnavigation2) [ nav2_collision_monitor ](/p/nav2_collision_monitor/github-ros-\nplanning-navigation2) [ nav2_common ](/p/nav2_common/github-ros-planning-\nnavigation2) [ nav2_constrained_smoother\n](/p/nav2_constrained_smoother/github-ros-planning-navigation2) [\nnav2_controller ](/p/nav2_controller/github-ros-planning-navigation2) [\nnav2_core ](/p/nav2_core/github-ros-planning-navigation2) [ nav2_costmap_2d\n](/p/nav2_costmap_2d/github-ros-planning-navigation2) [ costmap_queue\n](/p/costmap_queue/github-ros-planning-navigation2) [ dwb_core\n](/p/dwb_core/github-ros-planning-navigation2) [ dwb_critics\n](/p/dwb_critics/github-ros-planning-navigation2) [ dwb_msgs\n](/p/dwb_msgs/github-ros-planning-navigation2) [ dwb_plugins\n](/p/dwb_plugins/github-ros-planning-navigation2) [ nav2_dwb_controller\n](/p/nav2_dwb_controller/github-ros-planning-navigation2) [ nav_2d_msgs\n](/p/nav_2d_msgs/github-ros-planning-navigation2) [ nav_2d_utils\n](/p/nav_2d_utils/github-ros-planning-navigation2) [ nav2_graceful_controller\n](/p/nav2_graceful_controller/github-ros-planning-navigation2) [\nnav2_lifecycle_manager ](/p/nav2_lifecycle_manager/github-ros-planning-\nnavigation2) [ nav2_map_server ](/p/nav2_map_server/github-ros-planning-\nnavigation2) [ nav2_mppi_controller ](/p/nav2_mppi_controller/github-ros-\nplanning-navigation2) [ nav2_msgs ](/p/nav2_msgs/github-ros-planning-\nnavigation2) [ nav2_navfn_planner ](/p/nav2_navfn_planner/github-ros-planning-\nnavigation2) [ nav2_planner ](/p/nav2_planner/github-ros-planning-navigation2)\n[ nav2_regulated_pure_pursuit_controller\n](/p/nav2_regulated_pure_pursuit_controller/github-ros-planning-navigation2) [\nnav2_rotation_shim_controller ](/p/nav2_rotation_shim_controller/github-ros-\nplanning-navigation2) [ nav2_rviz_plugins ](/p/nav2_rviz_plugins/github-ros-\nplanning-navigation2) [ nav2_simple_commander\n](/p/nav2_simple_commander/github-ros-planning-navigation2) [\nnav2_smac_planner ](/p/nav2_smac_planner/github-ros-planning-navigation2) [\nnav2_smoother ](/p/nav2_smoother/github-ros-planning-navigation2) [\nnav2_system_tests ](/p/nav2_system_tests/github-ros-planning-navigation2) [\nnav2_theta_star_planner ](/p/nav2_theta_star_planner/github-ros-planning-\nnavigation2) [ nav2_util ](/p/nav2_util/github-ros-planning-navigation2) [\nnav2_velocity_smoother ](/p/nav2_velocity_smoother/github-ros-planning-\nnavigation2) [ nav2_voxel_grid ](/p/nav2_voxel_grid/github-ros-planning-\nnavigation2) [ nav2_waypoint_follower ](/p/nav2_waypoint_follower/github-ros-\nplanning-navigation2) [ navigation2 ](/p/navigation2/github-ros-planning-\nnavigation2)  \n---|---  \n  \ngithub-ros-planning-navigation2\n\n  * [ github-paulbovbel-nav2_platform ](/p/nav2_bringup/github-paulbovbel-nav2_platform)\n  * [ github-ros-planning-navigation2 ](/p/nav2_bringup/github-ros-planning-navigation2)\n\n  \n  \n---  \n  \n[  \nAPI Docs ](http://docs.ros.org/en/humble/p/nav2_bringup \"View API\ndocumentation on docs.ros.org\") [  \nBrowse Code ](https://github.com/ros-\nplanning/navigation2/tree/humble/nav2_bringup \"View source code on\nrepository\")\n\n  * Overview \n  * 0  Assets \n  * 11  Dependencies \n  * 0  Tutorials \n  * 0  Q & A \n\n####  Package Summary\n\n**Tags** |  _No category tags._  \n---|---  \n**Version** |  1.1.14  \n**License** |  Apache-2.0  \n**Build type** |  AMENT_CMAKE  \n**Use** |  RECOMMENDED  \n  \n###  Repository Summary\n\n**Checkout URI** |  [ https://github.com/ros-planning/navigation2.git\n](https://github.com/ros-planning/navigation2.git)  \n---|---  \n**VCS Type** |  git  \n**VCS Version** |  humble  \n**Last Updated**  \n  \n2024-04-04  |  **Dev Status** |  DEVELOPED  \n**CI status** |  No Continuous Integration  \n**Released** |  RELEASED  \n**Tags** |  _No category tags._  \n**Contributing** |  [ Help Wanted (  0  ) ](/r/navigation2/#humble-contribute-\nlists-help-wanted)  \n[ Good First Issues (  0  ) ](/r/navigation2/#humble-contribute-lists-good-\nfirst-issue)  \n[ Pull Requests to Review (  0  ) ](/r/navigation2/#humble-contribute-lists-\npull-requests)  \n  \n###  Package Description\n\nBringup scripts and configurations for the Nav2 stack\n\n####  Additional Links\n\n_No additional links._\n\n####  Maintainers\n\n  * Michael Jeronimo \n  * Steve Macenski \n  * Carlos Orduno \n\n####  Authors\n\n_No additional authors._\n\n[ nav2_bringup/README.md ](https://github.com/ros-\nplanning/navigation2/tree/humble/nav2_bringup/README.md \"Open in git\nrepository\")\n\n#  nav2_bringup\n\nThe ` nav2_bringup ` package is an example bringup system for Nav2\napplications.\n\nThis is a very flexible example for nav2 bringup that can be modified for\ndifferent maps/robots/hardware/worlds/etc. It is our expectation for an\napplication specific robot system that you're mirroring ` nav2_bringup `\npackage and modifying it for your specific maps/robots/bringup needs. This is\nan applied and working demonstration for the default system bringup with many\noptions that can be easily modified.\n\nUsual robot stacks will have a ` <robot_name>_nav ` package with\nconfig/bringup files and this is that for the general case to base a specific\nrobot system off of.\n\nDynamically composed bringup (based on [ ROS2 Composition\n](https://docs.ros.org/en/galactic/Tutorials/Composition.html) ) is optional\nfor users. It can be used to compose all Nav2 nodes in a single process\ninstead of launching these nodes separately, which is useful for embedded\nsystems users that need to make optimizations due to harsh resource\nconstraints. Dynamically composed bringup is used by default, but can be\ndisabled by using the launch argument ` use_composition:=False ` .\n\n  * Some discussions about performance improvement of composed bringup could be found here: [ https://discourse.ros.org/t/nav2-composition/22175 ](https://discourse.ros.org/t/nav2-composition/22175) . \n\nTo use, please see the Nav2 [ Getting Started Page\n](https://navigation.ros.org/getting_started/index.html) on our documentation\nwebsite. Additional [ tutorials will help you\n](https://navigation.ros.org/tutorials/index.html) go from an initial setup in\nsimulation to testing on a hardware robot, using SLAM, and more.\n\nNote: * gazebo should be started with both libgazebo_ros_init.so and\nlibgazebo_ros_factory.so to work correctly. * spawn_entity node could not\nremap /tf and /tf_static to tf and tf_static in the launch file yet, used only\nfor multi-robot situations. Instead it should be done as remapping argument\n/tf:=tf  /tf_static:=tf_static  under ros2 tag in each plugin which publishs\ntransforms in the SDF file. It is essential to differentiate the tf's of the\ndifferent robot.\n\n##  Launch\n\n###  Multi-robot Simulation\n\nThis is how to launch multi-robot simulation with simple command line. Please\nsee the Nav2 documentation for further augments.\n\n####  Cloned\n\nThis allows to bring up multiple robots, cloning a single robot N times at\ndifferent positions in the map. The parameter are loaded from `\nnav2_multirobot_params_all.yaml ` file by default. The multiple robots that\nconsists of name and initial pose in YAML format will be set on the command-\nline. The format for each robot is ` robot_name={x: 0.0, y: 0.0, yaw: 0.0,\nroll: 0.0, pitch: 0.0, yaw: 0.0} ` .\n\nPlease refer to below examples.\n\n    \n    \n    ros2 launch nav2_bringup cloned_multi_tb3_simulation_launch.py robots:=\"robot1={x: 1.0, y: 1.0, yaw: 1.5707}; robot2={x: 1.0, y: 1.0, yaw: 1.5707}\"\n    \n    \n\n####  Unique\n\nThere are two robots including name and intitial pose are hard-coded in the\nlaunch script. Two separated unique robots are required params file ( `\nnav2_multirobot_params_1.yaml ` , ` nav2_multirobot_params_2.yaml ` ) for each\nrobot to bring up.\n\nIf you want to bringup more than two robots, you should modify the `\nunique_multi_tb3_simulation_launch.py ` script.\n\n    \n    \n    ros2 launch nav2_bringup unique_multi_tb3_simulation_launch.py\n    \n    \n\nCHANGELOG\n\n###  Wiki Tutorials\n\n_See[ ROS Wiki Tutorials ](http://wiki.ros.org/nav2_bringup/Tutorials) for\nmore details. _\n\n###  Source Tutorials\n\n_Not currently indexed._\n\n###  Package Dependencies\n\nDeps  |  |  Name  |  [ ](/p/nav2_common#humble-deps) |  [ 1\n](/packages/nav2_common) |  [ nav2_common ](/p/nav2_common#humble)  \n---|---|---  \n[ ](/p/navigation2#humble-deps) |  [ 1 ](/packages/navigation2) |  [\nnavigation2 ](/p/navigation2#humble)  \n[ ](/p/launch_ros#humble-deps) |  [ 2 ](/packages/launch_ros) |  [ launch_ros\n](/p/launch_ros#humble)  \n[ ](/p/ament_cmake#humble-deps) |  [ 1 ](/packages/ament_cmake) |  [\nament_cmake ](/p/ament_cmake#humble)  \n[ ](/p/slam_toolbox#humble-deps) |  [ 1 ](/packages/slam_toolbox) |  [\nslam_toolbox ](/p/slam_toolbox#humble)  \n[ ](/p/ament_lint_common#humble-deps) |  [ 1 ](/packages/ament_lint_common) |\n[ ament_lint_common ](/p/ament_lint_common#humble)  \n[ ](/p/ament_lint_auto#humble-deps) |  [ 1 ](/packages/ament_lint_auto) |  [\nament_lint_auto ](/p/ament_lint_auto#humble)  \n[ ](/p/ament_cmake_gtest#humble-deps) |  [ 1 ](/packages/ament_cmake_gtest) |\n[ ament_cmake_gtest ](/p/ament_cmake_gtest#humble)  \n[ ](/p/ament_cmake_pytest#humble-deps) |  [ 1 ](/packages/ament_cmake_pytest)\n|  [ ament_cmake_pytest ](/p/ament_cmake_pytest#humble)  \n[ ](/p/launch#humble-deps) |  [ 1 ](/packages/launch) |  [ launch\n](/p/launch#humble)  \n[ ](/p/launch_testing#humble-deps) |  [ 1 ](/packages/launch_testing) |  [\nlaunch_testing ](/p/launch_testing#humble)  \n  \n###  System Dependencies\n\n_No direct system dependencies._\n\n###  Dependant Packages\n\nName  |  Repo  |  Deps  |  [ rtabmap_demos ](/p/rtabmap_demos/github-introlab-\nrtabmap_ros#humble) |  [ github-introlab-rtabmap_ros ](/r/rtabmap_ros/github-\nintrolab-rtabmap_ros) |  [ ](/p/rtabmap_demos/github-introlab-\nrtabmap_ros#humble-deps)  \n---|---|---  \n[ turtlebot3_navigation2 ](/p/turtlebot3_navigation2/github-ROBOTIS-GIT-\nturtlebot3#humble) |  [ github-ROBOTIS-GIT-turtlebot3 ](/r/turtlebot3/github-\nROBOTIS-GIT-turtlebot3) |  [ ](/p/turtlebot3_navigation2/github-ROBOTIS-GIT-\nturtlebot3#humble-deps)  \n[ nav2_system_tests ](/p/nav2_system_tests/github-ros-planning-\nnavigation2#humble) |  [ github-ros-planning-navigation2\n](/r/navigation2/github-ros-planning-navigation2) |  [\n](/p/nav2_system_tests/github-ros-planning-navigation2#humble-deps)  \n[ pmb2_2dnav ](/p/pmb2_2dnav/github-pal-robotics-pmb2_navigation#humble) |  [\ngithub-pal-robotics-pmb2_navigation ](/r/pmb2_navigation/github-pal-robotics-\npmb2_navigation) |  [ ](/p/pmb2_2dnav/github-pal-robotics-\npmb2_navigation#humble-deps)  \n[ raspimouse_navigation ](/p/raspimouse_navigation/github-rt-net-\nraspimouse_slam_navigation_ros2#humble) |  [ github-rt-net-\nraspimouse_slam_navigation_ros2 ](/r/raspimouse_slam_navigation_ros2/github-\nrt-net-raspimouse_slam_navigation_ros2) |  [\n](/p/raspimouse_navigation/github-rt-net-\nraspimouse_slam_navigation_ros2#humble-deps)  \n[ sm_dance_bot ](/p/sm_dance_bot/github-robosoft-ai-SMACC2#humble) |  [\ngithub-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-ai-SMACC2) |  [\n](/p/sm_dance_bot/github-robosoft-ai-SMACC2#humble-deps)  \n[ sm_dance_bot_warehouse ](/p/sm_dance_bot_warehouse/github-robosoft-ai-\nSMACC2#humble) |  [ github-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-ai-\nSMACC2) |  [ ](/p/sm_dance_bot_warehouse/github-robosoft-ai-SMACC2#humble-\ndeps)  \n[ sm_dance_bot_warehouse_2 ](/p/sm_dance_bot_warehouse_2/github-robosoft-ai-\nSMACC2#humble) |  [ github-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-ai-\nSMACC2) |  [ ](/p/sm_dance_bot_warehouse_2/github-robosoft-ai-SMACC2#humble-\ndeps)  \n[ sm_dance_bot_warehouse_3 ](/p/sm_dance_bot_warehouse_3/github-robosoft-ai-\nSMACC2#humble) |  [ github-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-ai-\nSMACC2) |  [ ](/p/sm_dance_bot_warehouse_3/github-robosoft-ai-SMACC2#humble-\ndeps)  \n[ sm_dance_bot_warehouse_4 ](/p/sm_dance_bot_warehouse_4/github-robosoft-ai-\nSMACC2#humble) |  [ github-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-ai-\nSMACC2) |  [ ](/p/sm_dance_bot_warehouse_4/github-robosoft-ai-SMACC2#humble-\ndeps)  \n[ sm_dancebot_artgallery_ue ](/p/sm_dancebot_artgallery_ue/github-robosoft-ai-\nSMACC2#humble) |  [ github-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-ai-\nSMACC2) |  [ ](/p/sm_dancebot_artgallery_ue/github-robosoft-ai-SMACC2#humble-\ndeps)  \n[ sm_dancebot_mine_ue ](/p/sm_dancebot_mine_ue/github-robosoft-ai-\nSMACC2#humble) |  [ github-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-ai-\nSMACC2) |  [ ](/p/sm_dancebot_mine_ue/github-robosoft-ai-SMACC2#humble-deps)  \n[ sm_dancebot_office_ue ](/p/sm_dancebot_office_ue/github-robosoft-ai-\nSMACC2#humble) |  [ github-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-ai-\nSMACC2) |  [ ](/p/sm_dancebot_office_ue/github-robosoft-ai-SMACC2#humble-deps)  \n[ sm_dancebot_ue ](/p/sm_dancebot_ue/github-robosoft-ai-SMACC2#humble) |  [\ngithub-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-ai-SMACC2) |  [\n](/p/sm_dancebot_ue/github-robosoft-ai-SMACC2#humble-deps)  \n[ turtlebot4_navigation ](/p/turtlebot4_navigation/github-turtlebot-\nturtlebot4#humble) |  [ github-turtlebot-turtlebot4 ](/r/turtlebot4/github-\nturtlebot-turtlebot4) |  [ ](/p/turtlebot4_navigation/github-turtlebot-\nturtlebot4#humble-deps)  \n[ andino_navigation ](/p/andino_navigation/github-Ekumen-OS-andino#humble) |\n[ github-Ekumen-OS-andino ](/r/andino/github-Ekumen-OS-andino) |  [\n](/p/andino_navigation/github-Ekumen-OS-andino#humble-deps)  \n[ clearpath_nav2_demos ](/p/clearpath_nav2_demos/github-clearpathrobotics-\nclearpath_nav2_demos#humble) |  [ github-clearpathrobotics-\nclearpath_nav2_demos ](/r/clearpath_nav2_demos/github-clearpathrobotics-\nclearpath_nav2_demos) |  [ ](/p/clearpath_nav2_demos/github-clearpathrobotics-\nclearpath_nav2_demos#humble-deps)  \n[ omni_base_2dnav ](/p/omni_base_2dnav/github-pal-robotics-\nomni_base_navigation#humble) |  [ github-pal-robotics-omni_base_navigation\n](/r/omni_base_navigation/github-pal-robotics-omni_base_navigation) |  [\n](/p/omni_base_2dnav/github-pal-robotics-omni_base_navigation#humble-deps)  \n[ pal_navigation_cfg_bringup ](/p/pal_navigation_cfg_bringup/github-pal-\nrobotics-pal_navigation_cfg_public#humble) |  [ github-pal-robotics-\npal_navigation_cfg_public ](/r/pal_navigation_cfg_public/github-pal-robotics-\npal_navigation_cfg_public) |  [ ](/p/pal_navigation_cfg_bringup/github-pal-\nrobotics-pal_navigation_cfg_public#humble-deps)  \n[ tiago_2dnav ](/p/tiago_2dnav/github-pal-robotics-tiago_navigation#humble) |\n[ github-pal-robotics-tiago_navigation ](/r/tiago_navigation/github-pal-\nrobotics-tiago_navigation) |  [ ](/p/tiago_2dnav/github-pal-robotics-\ntiago_navigation#humble-deps)  \n  \n###  Launch files\n\n_No launch files found_\n\n###  Messages\n\n_No message files found._\n\n###  Services\n\n_No service files found_\n\n###  Plugins\n\n_No plugins found._\n\n###  Recent questions tagged ` nav2_bringup ` at **[ Robotics Stack Exchange\n](https://robotics.stackexchange.com/) **\n\nNo questions yet, you can ask one [ here\n](https://robotics.stackexchange.com/questions/tagged/nav2_bringup+humble) .\n\nFailed to get question list, you can ticket an issue [ here\n](https://github.com/ros-infrastructure/rosindex/issues/new)\n\n[ API Docs ](http://docs.ros.org/en/humble/p/nav2_bringup \"View API\ndocumentation on docs.ros.org\") [ Browse Code ](https://github.com/ros-\nplanning/navigation2/tree/humble/nav2_bringup \"View source code on\nrepository\")\n\n![](/assets/package.png) |\n\n###  [ nav2_bringup ](/p/nav2_bringup) package from [ navigation2\n](/r/navigation2/github-ros-planning-navigation2) repo\n\n[ nav2_amcl ](/p/nav2_amcl/github-ros-planning-navigation2) [\nnav2_behavior_tree ](/p/nav2_behavior_tree/github-ros-planning-navigation2) [\nnav2_behaviors ](/p/nav2_behaviors/github-ros-planning-navigation2)\nnav2_bringup  [ nav2_bt_navigator ](/p/nav2_bt_navigator/github-ros-planning-\nnavigation2) [ nav2_collision_monitor ](/p/nav2_collision_monitor/github-ros-\nplanning-navigation2) [ nav2_common ](/p/nav2_common/github-ros-planning-\nnavigation2) [ nav2_constrained_smoother\n](/p/nav2_constrained_smoother/github-ros-planning-navigation2) [\nnav2_controller ](/p/nav2_controller/github-ros-planning-navigation2) [\nnav2_core ](/p/nav2_core/github-ros-planning-navigation2) [ nav2_costmap_2d\n](/p/nav2_costmap_2d/github-ros-planning-navigation2) [ costmap_queue\n](/p/costmap_queue/github-ros-planning-navigation2) [ dwb_core\n](/p/dwb_core/github-ros-planning-navigation2) [ dwb_critics\n](/p/dwb_critics/github-ros-planning-navigation2) [ dwb_msgs\n](/p/dwb_msgs/github-ros-planning-navigation2) [ dwb_plugins\n](/p/dwb_plugins/github-ros-planning-navigation2) [ nav2_dwb_controller\n](/p/nav2_dwb_controller/github-ros-planning-navigation2) [ nav_2d_msgs\n](/p/nav_2d_msgs/github-ros-planning-navigation2) [ nav_2d_utils\n](/p/nav_2d_utils/github-ros-planning-navigation2) [ nav2_lifecycle_manager\n](/p/nav2_lifecycle_manager/github-ros-planning-navigation2) [ nav2_map_server\n](/p/nav2_map_server/github-ros-planning-navigation2) [ nav2_mppi_controller\n](/p/nav2_mppi_controller/github-ros-planning-navigation2) [ nav2_msgs\n](/p/nav2_msgs/github-ros-planning-navigation2) [ nav2_navfn_planner\n](/p/nav2_navfn_planner/github-ros-planning-navigation2) [ nav2_planner\n](/p/nav2_planner/github-ros-planning-navigation2) [\nnav2_regulated_pure_pursuit_controller\n](/p/nav2_regulated_pure_pursuit_controller/github-ros-planning-navigation2) [\nnav2_rotation_shim_controller ](/p/nav2_rotation_shim_controller/github-ros-\nplanning-navigation2) [ nav2_rviz_plugins ](/p/nav2_rviz_plugins/github-ros-\nplanning-navigation2) [ nav2_simple_commander\n](/p/nav2_simple_commander/github-ros-planning-navigation2) [\nnav2_smac_planner ](/p/nav2_smac_planner/github-ros-planning-navigation2) [\nnav2_smoother ](/p/nav2_smoother/github-ros-planning-navigation2) [\nnav2_system_tests ](/p/nav2_system_tests/github-ros-planning-navigation2) [\nnav2_theta_star_planner ](/p/nav2_theta_star_planner/github-ros-planning-\nnavigation2) [ nav2_util ](/p/nav2_util/github-ros-planning-navigation2) [\nnav2_velocity_smoother ](/p/nav2_velocity_smoother/github-ros-planning-\nnavigation2) [ nav2_voxel_grid ](/p/nav2_voxel_grid/github-ros-planning-\nnavigation2) [ nav2_waypoint_follower ](/p/nav2_waypoint_follower/github-ros-\nplanning-navigation2) [ navigation2 ](/p/navigation2/github-ros-planning-\nnavigation2)  \n---|---  \n  \ngithub-ros-planning-navigation2\n\n  * [ github-paulbovbel-nav2_platform ](/p/nav2_bringup/github-paulbovbel-nav2_platform)\n  * [ github-ros-planning-navigation2 ](/p/nav2_bringup/github-ros-planning-navigation2)\n\n  \n  \n---  \n  \n[  \nAPI Docs ](http://docs.ros.org/en/iron/p/nav2_bringup \"View API documentation\non docs.ros.org\") [  \nBrowse Code ](https://github.com/ros-\nplanning/navigation2/tree/iron/nav2_bringup \"View source code on repository\")\n\n  * Overview \n  * 0  Assets \n  * 12  Dependencies \n  * 0  Tutorials \n  * 0  Q & A \n\n####  Package Summary\n\n**Tags** |  _No category tags._  \n---|---  \n**Version** |  1.2.7  \n**License** |  Apache-2.0  \n**Build type** |  AMENT_CMAKE  \n**Use** |  RECOMMENDED  \n  \n###  Repository Summary\n\n**Checkout URI** |  [ https://github.com/ros-planning/navigation2.git\n](https://github.com/ros-planning/navigation2.git)  \n---|---  \n**VCS Type** |  git  \n**VCS Version** |  iron  \n**Last Updated**  \n  \n2024-04-04  |  **Dev Status** |  DEVELOPED  \n**CI status** |  No Continuous Integration  \n**Released** |  RELEASED  \n**Tags** |  _No category tags._  \n**Contributing** |  [ Help Wanted (  0  ) ](/r/navigation2/#iron-contribute-\nlists-help-wanted)  \n[ Good First Issues (  0  ) ](/r/navigation2/#iron-contribute-lists-good-\nfirst-issue)  \n[ Pull Requests to Review (  0  ) ](/r/navigation2/#iron-contribute-lists-\npull-requests)  \n  \n###  Package Description\n\nBringup scripts and configurations for the Nav2 stack\n\n####  Additional Links\n\n_No additional links._\n\n####  Maintainers\n\n  * Michael Jeronimo \n  * Steve Macenski \n  * Carlos Orduno \n\n####  Authors\n\n_No additional authors._\n\n[ nav2_bringup/README.md ](https://github.com/ros-\nplanning/navigation2/tree/iron/nav2_bringup/README.md \"Open in git\nrepository\")\n\n#  nav2_bringup\n\nThe ` nav2_bringup ` package is an example bringup system for Nav2\napplications.\n\nThis is a very flexible example for nav2 bringup that can be modified for\ndifferent maps/robots/hardware/worlds/etc. It is our expectation for an\napplication specific robot system that you're mirroring ` nav2_bringup `\npackage and modifying it for your specific maps/robots/bringup needs. This is\nan applied and working demonstration for the default system bringup with many\noptions that can be easily modified.\n\nUsual robot stacks will have a ` <robot_name>_nav ` package with\nconfig/bringup files and this is that for the general case to base a specific\nrobot system off of.\n\nDynamically composed bringup (based on [ ROS2 Composition\n](https://docs.ros.org/en/galactic/Tutorials/Composition.html) ) is optional\nfor users. It can be used to compose all Nav2 nodes in a single process\ninstead of launching these nodes separately, which is useful for embedded\nsystems users that need to make optimizations due to harsh resource\nconstraints. Dynamically composed bringup is used by default, but can be\ndisabled by using the launch argument ` use_composition:=False ` .\n\n  * Some discussions about performance improvement of composed bringup could be found here: [ https://discourse.ros.org/t/nav2-composition/22175 ](https://discourse.ros.org/t/nav2-composition/22175) . \n\nTo use, please see the Nav2 [ Getting Started Page\n](https://navigation.ros.org/getting_started/index.html) on our documentation\nwebsite. Additional [ tutorials will help you\n](https://navigation.ros.org/tutorials/index.html) go from an initial setup in\nsimulation to testing on a hardware robot, using SLAM, and more.\n\nNote: * gazebo should be started with both libgazebo_ros_init.so and\nlibgazebo_ros_factory.so to work correctly. * spawn_entity node could not\nremap /tf and /tf_static to tf and tf_static in the launch file yet, used only\nfor multi-robot situations. Instead it should be done as remapping argument\n/tf:=tf  /tf_static:=tf_static  under ros2 tag in each plugin which publishs\ntransforms in the SDF file. It is essential to differentiate the tf's of the\ndifferent robot.\n\n##  Launch\n\n###  Multi-robot Simulation\n\nThis is how to launch multi-robot simulation with simple command line. Please\nsee the Nav2 documentation for further augments.\n\n####  Cloned\n\nThis allows to bring up multiple robots, cloning a single robot N times at\ndifferent positions in the map. The parameter are loaded from `\nnav2_multirobot_params_all.yaml ` file by default. The multiple robots that\nconsists of name and initial pose in YAML format will be set on the command-\nline. The format for each robot is ` robot_name={x: 0.0, y: 0.0, yaw: 0.0,\nroll: 0.0, pitch: 0.0, yaw: 0.0} ` .\n\nPlease refer to below examples.\n\n    \n    \n    ros2 launch nav2_bringup cloned_multi_tb3_simulation_launch.py robots:=\"robot1={x: 1.0, y: 1.0, yaw: 1.5707}; robot2={x: 1.0, y: 1.0, yaw: 1.5707}\"\n    \n    \n\n####  Unique\n\nThere are two robots including name and intitial pose are hard-coded in the\nlaunch script. Two separated unique robots are required params file ( `\nnav2_multirobot_params_1.yaml ` , ` nav2_multirobot_params_2.yaml ` ) for each\nrobot to bring up.\n\nIf you want to bringup more than two robots, you should modify the `\nunique_multi_tb3_simulation_launch.py ` script.\n\n    \n    \n    ros2 launch nav2_bringup unique_multi_tb3_simulation_launch.py\n    \n    \n\nCHANGELOG\n\n###  Wiki Tutorials\n\n_See[ ROS Wiki Tutorials ](http://wiki.ros.org/nav2_bringup/Tutorials) for\nmore details. _\n\n###  Source Tutorials\n\n_Not currently indexed._\n\n###  Package Dependencies\n\nDeps  |  |  Name  |  [ ](/p/nav2_common#iron-deps) |  [ 1\n](/packages/nav2_common) |  [ nav2_common ](/p/nav2_common#iron)  \n---|---|---  \n[ ](/p/navigation2#iron-deps) |  [ 1 ](/packages/navigation2) |  [ navigation2\n](/p/navigation2#iron)  \n[ ](/p/launch_ros#iron-deps) |  [ 2 ](/packages/launch_ros) |  [ launch_ros\n](/p/launch_ros#iron)  \n[ ](/p/ament_cmake#iron-deps) |  [ 1 ](/packages/ament_cmake) |  [ ament_cmake\n](/p/ament_cmake#iron)  \n[ ](/p/slam_toolbox#iron-deps) |  [ 1 ](/packages/slam_toolbox) |  [\nslam_toolbox ](/p/slam_toolbox#iron)  \n[ ](/p/turtlebot3_gazebo#iron-deps) |  [ 1 ](/packages/turtlebot3_gazebo) |  [\nturtlebot3_gazebo ](/p/turtlebot3_gazebo#iron)  \n[ ](/p/ament_lint_common#iron-deps) |  [ 1 ](/packages/ament_lint_common) |  [\nament_lint_common ](/p/ament_lint_common#iron)  \n[ ](/p/ament_lint_auto#iron-deps) |  [ 1 ](/packages/ament_lint_auto) |  [\nament_lint_auto ](/p/ament_lint_auto#iron)  \n[ ](/p/ament_cmake_gtest#iron-deps) |  [ 1 ](/packages/ament_cmake_gtest) |  [\nament_cmake_gtest ](/p/ament_cmake_gtest#iron)  \n[ ](/p/ament_cmake_pytest#iron-deps) |  [ 1 ](/packages/ament_cmake_pytest) |\n[ ament_cmake_pytest ](/p/ament_cmake_pytest#iron)  \n[ ](/p/launch#iron-deps) |  [ 1 ](/packages/launch) |  [ launch\n](/p/launch#iron)  \n[ ](/p/launch_testing#iron-deps) |  [ 1 ](/packages/launch_testing) |  [\nlaunch_testing ](/p/launch_testing#iron)  \n  \n###  System Dependencies\n\n_No direct system dependencies._\n\n###  Dependant Packages\n\nName  |  Repo  |  Deps  |  [ rtabmap_demos ](/p/rtabmap_demos/github-introlab-\nrtabmap_ros#iron) |  [ github-introlab-rtabmap_ros ](/r/rtabmap_ros/github-\nintrolab-rtabmap_ros) |  [ ](/p/rtabmap_demos/github-introlab-\nrtabmap_ros#iron-deps)  \n---|---|---  \n[ nav2_system_tests ](/p/nav2_system_tests/github-ros-planning-\nnavigation2#iron) |  [ github-ros-planning-navigation2\n](/r/navigation2/github-ros-planning-navigation2) |  [\n](/p/nav2_system_tests/github-ros-planning-navigation2#iron-deps)  \n[ sm_dance_bot ](/p/sm_dance_bot/github-robosoft-ai-SMACC2#iron) |  [ github-\nrobosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-ai-SMACC2) |  [\n](/p/sm_dance_bot/github-robosoft-ai-SMACC2#iron-deps)  \n[ sm_dance_bot_strikes_back ](/p/sm_dance_bot_strikes_back/github-robosoft-ai-\nSMACC2#iron) |  [ github-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-ai-\nSMACC2) |  [ ](/p/sm_dance_bot_strikes_back/github-robosoft-ai-SMACC2#iron-\ndeps)  \n[ sm_dance_bot_warehouse ](/p/sm_dance_bot_warehouse/github-robosoft-ai-\nSMACC2#iron) |  [ github-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-ai-\nSMACC2) |  [ ](/p/sm_dance_bot_warehouse/github-robosoft-ai-SMACC2#iron-deps)  \n[ sm_dance_bot_warehouse_2 ](/p/sm_dance_bot_warehouse_2/github-robosoft-ai-\nSMACC2#iron) |  [ github-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-ai-\nSMACC2) |  [ ](/p/sm_dance_bot_warehouse_2/github-robosoft-ai-SMACC2#iron-\ndeps)  \n[ sm_dance_bot_warehouse_3 ](/p/sm_dance_bot_warehouse_3/github-robosoft-ai-\nSMACC2#iron) |  [ github-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-ai-\nSMACC2) |  [ ](/p/sm_dance_bot_warehouse_3/github-robosoft-ai-SMACC2#iron-\ndeps)  \n  \n###  Launch files\n\n_No launch files found_\n\n###  Messages\n\n_No message files found._\n\n###  Services\n\n_No service files found_\n\n###  Plugins\n\n_No plugins found._\n\n###  Recent questions tagged ` nav2_bringup ` at **[ Robotics Stack Exchange\n](https://robotics.stackexchange.com/) **\n\nNo questions yet, you can ask one [ here\n](https://robotics.stackexchange.com/questions/tagged/nav2_bringup+iron) .\n\nFailed to get question list, you can ticket an issue [ here\n](https://github.com/ros-infrastructure/rosindex/issues/new)\n\n[ API Docs ](http://docs.ros.org/en/iron/p/nav2_bringup \"View API\ndocumentation on docs.ros.org\") [ Browse Code ](https://github.com/ros-\nplanning/navigation2/tree/iron/nav2_bringup \"View source code on repository\")\n\nNo version for distro **rolling** . Known supported distros are highlighted in\nthe buttons above.\n\nNo version for distro **noetic** . Known supported distros are highlighted in\nthe buttons above.\n\nNo version for distro **ardent** . Known supported distros are highlighted in\nthe buttons above.\n\nNo version for distro **bouncy** . Known supported distros are highlighted in\nthe buttons above.\n\n![](/assets/package.png) |\n\n###  [ nav2_bringup ](/p/nav2_bringup) package from [ navigation2\n](/r/navigation2/github-ros-planning-navigation2) repo\n\n[ nav2_amcl ](/p/nav2_amcl/github-ros-planning-navigation2) nav2_bringup  [\nnav2_bt_navigator ](/p/nav2_bt_navigator/github-ros-planning-navigation2) [\nnav2_common ](/p/nav2_common/github-ros-planning-navigation2) [\nnav2_costmap_2d ](/p/nav2_costmap_2d/github-ros-planning-navigation2) [\ncostmap_queue ](/p/costmap_queue/github-ros-planning-navigation2) [\ndwb_controller ](/p/dwb_controller/github-ros-planning-navigation2) [ dwb_core\n](/p/dwb_core/github-ros-planning-navigation2) [ dwb_critics\n](/p/dwb_critics/github-ros-planning-navigation2) [ dwb_msgs\n](/p/dwb_msgs/github-ros-planning-navigation2) [ dwb_plugins\n](/p/dwb_plugins/github-ros-planning-navigation2) [ nav2_dwb_controller\n](/p/nav2_dwb_controller/github-ros-planning-navigation2) [ nav_2d_msgs\n](/p/nav_2d_msgs/github-ros-planning-navigation2) [ nav_2d_utils\n](/p/nav_2d_utils/github-ros-planning-navigation2) [ nav2_dynamic_params\n](/p/nav2_dynamic_params/github-ros-planning-navigation2) [ nav2_map_server\n](/p/nav2_map_server/github-ros-planning-navigation2) [ nav2_mission_executor\n](/p/nav2_mission_executor/github-ros-planning-navigation2) [\nnav2_motion_primitives ](/p/nav2_motion_primitives/github-ros-planning-\nnavigation2) [ nav2_msgs ](/p/nav2_msgs/github-ros-planning-navigation2) [\nnav2_navfn_planner ](/p/nav2_navfn_planner/github-ros-planning-navigation2) [\nnav2_robot ](/p/nav2_robot/github-ros-planning-navigation2) [\nnav2_simple_navigator ](/p/nav2_simple_navigator/github-ros-planning-\nnavigation2) [ nav2_system_tests ](/p/nav2_system_tests/github-ros-planning-\nnavigation2) [ nav2_tasks ](/p/nav2_tasks/github-ros-planning-navigation2) [\nnav2_util ](/p/nav2_util/github-ros-planning-navigation2) [ nav2_voxel_grid\n](/p/nav2_voxel_grid/github-ros-planning-navigation2) [ nav2_world_model\n](/p/nav2_world_model/github-ros-planning-navigation2) [ navigation2\n](/p/navigation2/github-ros-planning-navigation2)  \n---|---  \n  \ngithub-ros-planning-navigation2\n\n  * [ github-paulbovbel-nav2_platform ](/p/nav2_bringup/github-paulbovbel-nav2_platform)\n  * [ github-ros-planning-navigation2 ](/p/nav2_bringup/github-ros-planning-navigation2)\n\n  \n  \n---  \n  \n[  \nAPI Docs ](http://docs.ros.org/en/crystal/p/nav2_bringup \"View API\ndocumentation on docs.ros.org\") [  \nBrowse Code ](https://github.com/ros-planning/navigation2/tree/crystal-\ndevel/nav2_bringup \"View source code on repository\")\n\n  * Overview \n  * 0  Assets \n  * 10  Dependencies \n  * 0  Tutorials \n  * 0  Q & A \n\n####  Package Summary\n\n**Tags** |  _No category tags._  \n---|---  \n**Version** |  0.1.7  \n**License** |  Apache License 2.0  \n**Build type** |  AMENT_CMAKE  \n**Use** |  RECOMMENDED  \n  \n###  Repository Summary\n\n**Checkout URI** |  [ https://github.com/ros-planning/navigation2.git\n](https://github.com/ros-planning/navigation2.git)  \n---|---  \n**VCS Type** |  git  \n**VCS Version** |  crystal-devel  \n**Last Updated**  \n  \n2019-03-13  |  **Dev Status** |  DEVELOPED  \n**CI status** |  No Continuous Integration  \n**Released** |  RELEASED  \n**Tags** |  _No category tags._  \n**Contributing** |  [ Help Wanted (  0  ) ](/r/navigation2/#crystal-\ncontribute-lists-help-wanted)  \n[ Good First Issues (  0  ) ](/r/navigation2/#crystal-contribute-lists-good-\nfirst-issue)  \n[ Pull Requests to Review (  0  ) ](/r/navigation2/#crystal-contribute-lists-\npull-requests)  \n  \n###  Package Description\n\nBringup scripts and configurations for the navigation2 stack\n\n####  Additional Links\n\n_No additional links._\n\n####  Maintainers\n\n  * Michael Jeronimo \n  * Steve Macenski \n\n####  Authors\n\n_No additional authors._\n\n[ nav2_bringup/README.md ](https://github.com/ros-\nplanning/navigation2/tree/crystal-devel/nav2_bringup/README.md \"Open in git\nrepository\")\n\n#  nav2_bringup\n\nThe ` nav2_bringup ` package is an example bringup system for navigation2\napplications.\n\nNotes: (December 2018, Crystal Release) * We recommend doing this on a Ubuntu\n18.04 installation. We\u2019re currently having build issues on 16.04. (see [\nhttps://github.com/ros-planning/navigation2/issues/353\n](https://github.com/ros-planning/navigation2/issues/353) ) * This stack and\nROS2 are still in heavy development and there are some bugs and stability\nissues being worked on, so please do not try this on a robot without taking\n_heavy_ safety precautions. THE ROBOT MAY CRASH! * It is recommended to start\nwith simulation using Gazebo before proceeding to run on a physical robot\n\nInstall and build our code by following this guide: [ https://github.com/ros-\nplanning/navigation2/blob/master/doc/BUILD.md ](https://github.com/ros-\nplanning/navigation2/blob/master/doc/BUILD.md)\n\n##  Launch Navigation2 in simulation with Gazebo (first time users)\n\n###  Pre-requisites:\n\n  * Gazebo installed on the system \n  * gazebo_ros_pkgs for ROS2 installed on the system \n  * A Gazebo world for simulating the robot (see Gazebo tutorials) \n  * A map of that world saved to a map.pgm and map.yaml (see ROS Navigation tutorials) \n\n###  Terminal 1: Launch Gazebo and Rviz2\n\nExample: See [ turtlebot3_gazebo models ](https://github.com/ROBOTIS-\nGIT/turtlebot3_simulations/tree/ros2/turtlebot3_gazebo/models) for details\n\n    \n    \n    export GAZEBO_MODEL_PATH=$GAZEBO_MODEL_PATH:<full/path/to/my_robot/models>\n    ros2 launch nav2_bringup gazebo_rviz2_launch.py world:=<full/path/to/gazebo.world>\n    \n    \n\n###  Terminal 2: Launch your robot specific transforms\n\nExample: See [ turtlebot3_gazebo ](https://github.com/ROBOTIS-\nGIT/turtlebot3_simulations/tree/ros2/turtlebot3_gazebo) for details\n\n` ros2 launch turtlebot3_bringup turtlebot3_robot.launch.py `\n\n###  Terminal 3: Launch map_server and AMCL\n\n    \n    \n    # Set the tf publisher node to use simulation time or AMCL won't get the transforms correctly\n    ros2 param set /robot_state_publisher use_sim_time True\n    # Launch map_server and AMCL, set map_type as \"occupancy\" by default.\n    ros2 launch nav2_bringup nav2_bringup_1st_launch.py map:=<full/path/to/map.yaml> map_type:=occupancy use_sim_time:=True\n    \n    \n\nIn RVIZ: * Make sure all transforms from odom are present.\n(odom->base_link->base_scan) * Localize the robot using \u201c2D Pose Estimate\u201d\nbutton.\n\n###  Terminal 4:\n\nRun the rest of the Navigation2 bringup\n\n` ros2 launch nav2_bringup nav2_bringup_2nd_launch.py use_sim_time:=True `\n\n###  Terminal 5:\n\nSet the World Model and the two costmap nodes to use simulation time\n\n    \n    \n    ros2 param set /world_model use_sim_time True\n    ros2 param set /global_costmap/global_costmap use_sim_time True\n    ros2 param set /local_costmap/local_costmap use_sim_time True\n    \n    \n\nNotes: * Setting use_sim_time has to be done dynamically after the nodes are\nup due to this bug: [ https://github.com/ros2/rclcpp/issues/595\n](https://github.com/ros2/rclcpp/issues/595) * Sim time needs to be set in\nevery namespace individually. * Sometimes setting use_sim_time a second time\nis required for all the nodes to get updated * IF you continue to see WARN\nmessages like the ones below, retry setting the use_sim_time parameter\n\n    \n    \n    [WARN] [world_model]: Costmap2DROS transform timeout. Current time: 1543616767.1026, global_pose stamp: 758.8040, tolerance: 0.3000, difference: 1543616008.2986\n    [WARN] [FollowPathNode]: Costmap2DROS transform timeout. Current time: 1543616767.2787, global_pose stamp: 759.0040, tolerance: 0.3000, difference: 1543616008.2747\n    \n    \n\nIn RVIZ: * Add \"map\" to subscribe topic \"/map\" * Add \"RobotModel\", set\n\"Description Source\" with \"File\", set \"Description File\" with the name of the\nurdf file for your robot (example: turtlebot3_burger.urdf)\" * Localize the\nrobot using \u201c2D Pose Estimate\u201d button. * Send the robot a goal using \u201c2D Nav\nGoal\u201d button.\n\n##  Launch Navigation2 on a Robot (first time users)\n\nPre-requisites: * Run SLAM or Cartographer with tele-op to drive the robot and\ngenerate a map of an area for testing first. The directions below assume this\nhas already been done. If not, it can be done in ROS1 before beginning to\ninstall our code. * Publish all the transforms from your robot from base_link\nto base_scan\n\nLaunch the code using this launch file and your map.yaml:\n\n` ros2 launch nav2_bringup nav2_bringup_1st_launch.py\nmap:=<full/path/to/map.yaml> map_type:=occupancy `\n\nIn another terminal, run RVIZ:\n\n` ros2 run rviz2 rviz2 `\n\nIn RVIZ: * Make sure all transforms from odom are present.\n(odom->base_link->base_scan) * Localize the robot using \u201c2D Pose Estimate\u201d\nbutton.\n\nRun the rest of the Navigation2 bringup\n\n` ros2 launch nav2_bringup nav2_bringup_2nd_launch.py `\n\nIn RVIZ: * Localize the robot using \u201c2D Pose Estimate\u201d button. * Send the\nrobot a goal using \u201c2D Nav Goal\u201d button.\n\n##  Advanced 1-step Launch for experienced users\n\nPre-requisites: * You've completed bringup of your robot successfully\nfollowing the 2-step process above * You know your transforms are being\npublished correctly and AMCL can localize\n\nFollow directions above _except_ * Instead of running the `\nnav2_bringup_1st_launch.py ` then the ` nav2_bringup_2nd_launch.py ` * You can\ndo it in one step like this:\n\n    \n    \n    ros2 launch nav2_bringup nav2_bringup_launch.py map:=<full/path/to/map.yaml>\n    \n    \n\nIf running in simulation:\n\n    \n    \n    ros2 launch nav2_bringup nav2_bringup_launch.py map:=<full/path/to/map.yaml> use_sim_time:=True\n    ros2 param set /world_model use_sim_time True; ros2 param set /global_costmap/global_costmap use_sim_time True; ros2 param set /local_costmap/local_costmap use_sim_time True\n    \n    \n\n##  Future Work\n\n  * adding configuration files for the example bringup \n  * a more complete map for system level testing \n\nCHANGELOG\n\n###  Wiki Tutorials\n\n_See[ ROS Wiki Tutorials ](http://wiki.ros.org/nav2_bringup/Tutorials) for\nmore details. _\n\n###  Source Tutorials\n\n_Not currently indexed._\n\n###  Package Dependencies\n\nDeps  |  |  Name  |  [ ](/p/nav2_common#crystal-deps) |  [ 1\n](/packages/nav2_common) |  [ nav2_common ](/p/nav2_common#crystal)  \n---|---|---  \n[ ](/p/navigation2#crystal-deps) |  [ 1 ](/packages/navigation2) |  [\nnavigation2 ](/p/navigation2#crystal)  \n[ ](/p/launch_ros#crystal-deps) |  [ 2 ](/packages/launch_ros) |  [ launch_ros\n](/p/launch_ros#crystal)  \n[ ](/p/ament_cmake#crystal-deps) |  [ 1 ](/packages/ament_cmake) |  [\nament_cmake ](/p/ament_cmake#crystal)  \n[ ](/p/ament_lint_common#crystal-deps) |  [ 1 ](/packages/ament_lint_common) |\n[ ament_lint_common ](/p/ament_lint_common#crystal)  \n[ ](/p/ament_lint_auto#crystal-deps) |  [ 1 ](/packages/ament_lint_auto) |  [\nament_lint_auto ](/p/ament_lint_auto#crystal)  \n[ ](/p/ament_cmake_gtest#crystal-deps) |  [ 1 ](/packages/ament_cmake_gtest) |\n[ ament_cmake_gtest ](/p/ament_cmake_gtest#crystal)  \n[ ](/p/ament_cmake_pytest#crystal-deps) |  [ 1 ](/packages/ament_cmake_pytest)\n|  [ ament_cmake_pytest ](/p/ament_cmake_pytest#crystal)  \n[ ](/p/launch#crystal-deps) |  [ 1 ](/packages/launch) |  [ launch\n](/p/launch#crystal)  \n[ ](/p/launch_testing#crystal-deps) |  [ 1 ](/packages/launch_testing) |  [\nlaunch_testing ](/p/launch_testing#crystal)  \n  \n###  System Dependencies\n\n_No direct system dependencies._\n\n###  Dependant Packages\n\n_No known dependants._\n\n###  Launch files\n\n_No launch files found_\n\n###  Messages\n\n_No message files found._\n\n###  Services\n\n_No service files found_\n\n###  Plugins\n\n_No plugins found._\n\n###  Recent questions tagged ` nav2_bringup ` at **[ Robotics Stack Exchange\n](https://robotics.stackexchange.com/) **\n\nNo questions yet, you can ask one [ here\n](https://robotics.stackexchange.com/questions/tagged/nav2_bringup+crystal) .\n\nFailed to get question list, you can ticket an issue [ here\n](https://github.com/ros-infrastructure/rosindex/issues/new)\n\n[ API Docs ](http://docs.ros.org/en/crystal/p/nav2_bringup \"View API\ndocumentation on docs.ros.org\") [ Browse Code ](https://github.com/ros-\nplanning/navigation2/tree/crystal-devel/nav2_bringup \"View source code on\nrepository\")\n\n![](/assets/package.png) |\n\n###  [ nav2_bringup ](/p/nav2_bringup) package from [ navigation2\n](/r/navigation2/github-ros-planning-navigation2) repo\n\n[ nav2_amcl ](/p/nav2_amcl/github-ros-planning-navigation2) [\nnav2_behavior_tree ](/p/nav2_behavior_tree/github-ros-planning-navigation2)\nnav2_bringup  [ nav2_gazebo_spawner ](/p/nav2_gazebo_spawner/github-ros-\nplanning-navigation2) [ nav2_bt_navigator ](/p/nav2_bt_navigator/github-ros-\nplanning-navigation2) [ nav2_common ](/p/nav2_common/github-ros-planning-\nnavigation2) [ nav2_controller ](/p/nav2_controller/github-ros-planning-\nnavigation2) [ nav2_core ](/p/nav2_core/github-ros-planning-navigation2) [\nnav2_costmap_2d ](/p/nav2_costmap_2d/github-ros-planning-navigation2) [\ncostmap_queue ](/p/costmap_queue/github-ros-planning-navigation2) [ dwb_core\n](/p/dwb_core/github-ros-planning-navigation2) [ dwb_critics\n](/p/dwb_critics/github-ros-planning-navigation2) [ dwb_msgs\n](/p/dwb_msgs/github-ros-planning-navigation2) [ dwb_plugins\n](/p/dwb_plugins/github-ros-planning-navigation2) [ nav2_dwb_controller\n](/p/nav2_dwb_controller/github-ros-planning-navigation2) [ nav_2d_msgs\n](/p/nav_2d_msgs/github-ros-planning-navigation2) [ nav_2d_utils\n](/p/nav_2d_utils/github-ros-planning-navigation2) [ nav2_turtlebot3_rl\n](/p/nav2_turtlebot3_rl/github-ros-planning-navigation2) [\nnav2_lifecycle_manager ](/p/nav2_lifecycle_manager/github-ros-planning-\nnavigation2) [ nav2_map_server ](/p/nav2_map_server/github-ros-planning-\nnavigation2) [ nav2_msgs ](/p/nav2_msgs/github-ros-planning-navigation2) [\nnav2_navfn_planner ](/p/nav2_navfn_planner/github-ros-planning-navigation2) [\nnav2_planner ](/p/nav2_planner/github-ros-planning-navigation2) [\nnav2_recoveries ](/p/nav2_recoveries/github-ros-planning-navigation2) [\nnav2_rviz_plugins ](/p/nav2_rviz_plugins/github-ros-planning-navigation2) [\nnav2_system_tests ](/p/nav2_system_tests/github-ros-planning-navigation2) [\nnav2_util ](/p/nav2_util/github-ros-planning-navigation2) [ nav2_voxel_grid\n](/p/nav2_voxel_grid/github-ros-planning-navigation2) [ nav2_waypoint_follower\n](/p/nav2_waypoint_follower/github-ros-planning-navigation2) [ navigation2\n](/p/navigation2/github-ros-planning-navigation2)  \n---|---  \n  \ngithub-ros-planning-navigation2\n\n  * [ github-paulbovbel-nav2_platform ](/p/nav2_bringup/github-paulbovbel-nav2_platform)\n  * [ github-ros-planning-navigation2 ](/p/nav2_bringup/github-ros-planning-navigation2)\n\n  \n  \n---  \n  \n[  \nAPI Docs ](http://docs.ros.org/en/eloquent/p/nav2_bringup \"View API\ndocumentation on docs.ros.org\") [  \nBrowse Code ](https://github.com/ros-planning/navigation2/tree/eloquent-\ndevel/nav2_bringup/bringup \"View source code on repository\")\n\n  * Overview \n  * 0  Assets \n  * 10  Dependencies \n  * 0  Tutorials \n  * 0  Q & A \n\n####  Package Summary\n\n**Tags** |  _No category tags._  \n---|---  \n**Version** |  0.3.5  \n**License** |  Apache-2.0  \n**Build type** |  AMENT_CMAKE  \n**Use** |  RECOMMENDED  \n  \n###  Repository Summary\n\n**Checkout URI** |  [ https://github.com/ros-planning/navigation2.git\n](https://github.com/ros-planning/navigation2.git)  \n---|---  \n**VCS Type** |  git  \n**VCS Version** |  eloquent-devel  \n**Last Updated**  \n  \n2021-01-04  |  **Dev Status** |  DEVELOPED  \n**CI status** |  No Continuous Integration  \n**Released** |  RELEASED  \n**Tags** |  _No category tags._  \n**Contributing** |  [ Help Wanted (  0  ) ](/r/navigation2/#eloquent-\ncontribute-lists-help-wanted)  \n[ Good First Issues (  0  ) ](/r/navigation2/#eloquent-contribute-lists-good-\nfirst-issue)  \n[ Pull Requests to Review (  0  ) ](/r/navigation2/#eloquent-contribute-lists-\npull-requests)  \n  \n###  Package Description\n\nBringup scripts and configurations for the navigation2 stack\n\n####  Additional Links\n\n_No additional links._\n\n####  Maintainers\n\n  * Michael Jeronimo \n  * Steve Macenski \n  * Carlos Orduno \n\n####  Authors\n\n_No additional authors._\n\n[ nav2_bringup/bringup/README.md ](https://github.com/ros-\nplanning/navigation2/tree/eloquent-devel/nav2_bringup/bringup/README.md \"Open\nin git repository\")\n\n#  nav2_bringup\n\nThe ` nav2_bringup ` package is an example bringup system for Navigation2\napplications.\n\n###  Pre-requisites:\n\n  * [ Install ROS 2 ](https://index.ros.org/doc/ros2/Installation/Dashing/)\n  * Install Navigation2 \n\n` sudo apt install ros-<ros2_distro>-navigation2 `\n\n  * Install Navigation2 Bringup \n\n` sudo apt install ros-<ros2_distro>-nav2-bringup `\n\n  * Install your robot specific package (ex: [ Turtlebot 3 ](http://emanual.robotis.com/docs/en/platform/turtlebot3/ros2/) ) \n\n##  Launch Navigation2 in _Simulation_ with Gazebo\n\n###  Pre-requisites:\n\n  * [ Install Gazebo ](http://gazebosim.org/tutorials?tut=install_ubuntu&cat=install)\n  * gazebo_ros_pkgs for ROS2 installed on the system \n\n` sudo apt-get install ros-<ros2-distro>-gazebo* ` * A Gazebo world for\nsimulating the robot ( [ Gazebo tutorials\n](http://gazebosim.org/tutorials?tut=quick_start) ) * A map of that world\nsaved to a map.pgm and map.yaml ( [ ROS Navigation Tutorials\n](https://github.com/ros-planning/navigation2/tree/master/doc/use_cases) )\n\n###  Terminal 1: Launch Gazebo\n\nExample: See [ turtlebot3_gazebo models ](https://github.com/ROBOTIS-\nGIT/turtlebot3_simulations/tree/ros2/turtlebot3_gazebo/models) for details\n\n    \n    \n    export GAZEBO_MODEL_PATH=$GAZEBO_MODEL_PATH:<full/path/to/my_robot/models>\n    gazebo --verbose -s libgazebo_ros_init.so <full/path/to/my_gazebo.world>\n    \n    \n\n###  Terminal 2: Launch your robot specific transforms\n\nExample: See [ turtlebot3_gazebo ](https://github.com/ROBOTIS-\nGIT/turtlebot3_simulations/tree/ros2/turtlebot3_gazebo) for details\n\n    \n    \n    source /opt/ros/dashing/setup.bash\n    export TURTLEBOT3_MODEL=waffle\n    ros2 launch turtlebot3_bringup turtlebot3_state_publisher.launch.py use_sim_time:=True\n    \n    \n\n###  Terminal 3: Launch Navigation2\n\n    \n    \n    source /opt/ros/dashing/setup.bash\n    ros2 launch nav2_bringup nav2_bringup_launch.py use_sim_time:=True autostart:=True \\\n    map:=<full/path/to/map.yaml>\n    \n    \n\n###  Terminal 4: Run RViz with Navigation2 config file\n\n    \n    \n    source /opt/ros/dashing/setup.bash\n    ros2 run rviz2 rviz2 -d $(ros2 pkg prefix nav2_bringup)/share/nav2_bringup/launch/nav2_default_view.rviz\n    \n    \n\nIn RViz: * You should see the map * Localize the robot using \u201c2D Pose\nEstimate\u201d button. * Make sure all transforms from odom are present.\n(odom->base_link->base_scan) * Send the robot a goal using \u201cNavigation2 Goal\u201d\nbutton. Note: this uses a ROS2 Action to send the goal, and a pop-up window\nwill appear on your screen with a 'cancel' button if you wish to cancel\n\nTo view the robot model in RViz: * Add \"RobotModel\", set \"Description Source\"\nwith \"File\", set \"Description File\" with the name of the urdf file for your\nrobot (example: turtlebot3_burger.urdf)\"\n\n###  Advanced: single-terminal launch\n\nA convenience file is provided to launch Gazebo, RVIZ and Navigation2 using a\nsingle command:\n\n    \n    \n    ros2 launch nav2_bringup nav2_tb3_simulation_launch.py <settings>\n    \n    \n\nWhere ` <settings> ` can used to replace any of the default options, for\nexample:\n\n    \n    \n    world:=<full/path/to/gazebo.world>\n    map:=<full/path/to/map.yaml>\n    rviz_config_file:=<full/path/to/rviz_config.rviz>\n    simulator:=<gzserver or gazebo>\n    bt_xml_file:=<full/path/to/bt_tree.xml>\n    \n    \n\nBefore running the command make sure you are sourcing the ` ROS2 ` workspace,\nsetting the path to the Gazebo model and defining the TB3 robot model to use.\n\n    \n    \n    source <full/path/to/ros2/setup.bash>\n    export GAZEBO_MODEL_PATH=$GAZEBO_MODEL_PATH:<full/path/to/my_robot/models>\n    export TURTLEBOT3_MODEL=waffle\n    \n    \n\nAlso, a file for launching **two** robots with **independent** navigation\nstacks is provided:\n\n    \n    \n    ros2 launch nav2_bringup nav2_multi_tb3_simulation_launch.py <settings>\n    \n    \n\n##  Launch Navigation2 on a _Robot_\n\n###  Pre-requisites:\n\n  * Run SLAM with Navigation 2 or tele-op to drive the robot and generate a map of an area for testing first. The directions below assume this has already been done or there is already a map of the area. \n\n  * Learn more about how to use Navigation 2 with SLAM to create maps; \n\n    * [ Navigation 2 with SLAM ](https://github.com/ros-planning/navigation2/blob/master/doc/use_cases/navigation_with_slam.md)\n  * _Please note that currently, nav2_bringup works if you provide a map file. However, providing a map is not required to use Navigation2. Navigation2 can be configured to use the costmaps to navigate in an area without using a map file_\n\n  * Publish all the transforms from your robot from base_link to base_scan \n\n###  Terminal 1 : Launch Navigation2 using your map.yaml\n\n    \n    \n    source /opt/ros/dashing/setup.bash\n    ros2 launch nav2_bringup nav2_bringup_launch.py map:=<full/path/to/map.yaml> map_type:=occupancy\n    \n    \n\n###  Terminal 2 : Launch RVIZ\n\n    \n    \n    source /opt/ros/dashing/setup.bash\n    ros2 run rviz2 rviz2 -d $(ros2 pkg prefix nav2_bringup)/share/nav2_bringup/launch/nav2_default_view.rviz\n    \n    \n\nIn RVIZ: * Make sure all transforms from odom are present.\n(odom->base_link->base_scan) * Localize the robot using \u201c2D Pose Estimate\u201d\nbutton. * Send the robot a goal pose using \u201c2D Nav Goal\u201d button.\n\nCHANGELOG\n\n###  Wiki Tutorials\n\n_See[ ROS Wiki Tutorials ](http://wiki.ros.org/nav2_bringup/Tutorials) for\nmore details. _\n\n###  Source Tutorials\n\n_Not currently indexed._\n\n###  Package Dependencies\n\nDeps  |  |  Name  |  [ ](/p/nav2_common#eloquent-deps) |  [ 1\n](/packages/nav2_common) |  [ nav2_common ](/p/nav2_common#eloquent)  \n---|---|---  \n[ ](/p/navigation2#eloquent-deps) |  [ 1 ](/packages/navigation2) |  [\nnavigation2 ](/p/navigation2#eloquent)  \n[ ](/p/launch_ros#eloquent-deps) |  [ 2 ](/packages/launch_ros) |  [\nlaunch_ros ](/p/launch_ros#eloquent)  \n[ ](/p/ament_cmake#eloquent-deps) |  [ 1 ](/packages/ament_cmake) |  [\nament_cmake ](/p/ament_cmake#eloquent)  \n[ ](/p/ament_lint_common#eloquent-deps) |  [ 1 ](/packages/ament_lint_common)\n|  [ ament_lint_common ](/p/ament_lint_common#eloquent)  \n[ ](/p/ament_lint_auto#eloquent-deps) |  [ 1 ](/packages/ament_lint_auto) |  [\nament_lint_auto ](/p/ament_lint_auto#eloquent)  \n[ ](/p/ament_cmake_gtest#eloquent-deps) |  [ 1 ](/packages/ament_cmake_gtest)\n|  [ ament_cmake_gtest ](/p/ament_cmake_gtest#eloquent)  \n[ ](/p/ament_cmake_pytest#eloquent-deps) |  [ 1\n](/packages/ament_cmake_pytest) |  [ ament_cmake_pytest\n](/p/ament_cmake_pytest#eloquent)  \n[ ](/p/launch#eloquent-deps) |  [ 1 ](/packages/launch) |  [ launch\n](/p/launch#eloquent)  \n[ ](/p/launch_testing#eloquent-deps) |  [ 1 ](/packages/launch_testing) |  [\nlaunch_testing ](/p/launch_testing#eloquent)  \n  \n###  System Dependencies\n\n_No direct system dependencies._\n\n###  Dependant Packages\n\nName  |  Repo  |  Deps  |  [ turtlebot3_navigation2\n](/p/turtlebot3_navigation2/github-ROBOTIS-GIT-turtlebot3#eloquent) |  [\ngithub-ROBOTIS-GIT-turtlebot3 ](/r/turtlebot3/github-ROBOTIS-GIT-turtlebot3) |\n[ ](/p/turtlebot3_navigation2/github-ROBOTIS-GIT-turtlebot3#eloquent-deps)  \n---|---|---  \n[ nav2_system_tests ](/p/nav2_system_tests/github-ros-planning-\nnavigation2#eloquent) |  [ github-ros-planning-navigation2\n](/r/navigation2/github-ros-planning-navigation2) |  [\n](/p/nav2_system_tests/github-ros-planning-navigation2#eloquent-deps)  \n  \n###  Launch files\n\n_No launch files found_\n\n###  Messages\n\n_No message files found._\n\n###  Services\n\n_No service files found_\n\n###  Plugins\n\n_No plugins found._\n\n###  Recent questions tagged ` nav2_bringup ` at **[ Robotics Stack Exchange\n](https://robotics.stackexchange.com/) **\n\nNo questions yet, you can ask one [ here\n](https://robotics.stackexchange.com/questions/tagged/nav2_bringup+eloquent) .\n\nFailed to get question list, you can ticket an issue [ here\n](https://github.com/ros-infrastructure/rosindex/issues/new)\n\n[ API Docs ](http://docs.ros.org/en/eloquent/p/nav2_bringup \"View API\ndocumentation on docs.ros.org\") [ Browse Code ](https://github.com/ros-\nplanning/navigation2/tree/eloquent-devel/nav2_bringup/bringup \"View source\ncode on repository\")\n\n![](/assets/package.png) |\n\n###  [ nav2_bringup ](/p/nav2_bringup) package from [ navigation2\n](/r/navigation2/github-ros-planning-navigation2) repo\n\n[ nav2_amcl ](/p/nav2_amcl/github-ros-planning-navigation2) [\nnav2_behavior_tree ](/p/nav2_behavior_tree/github-ros-planning-navigation2)\nnav2_bringup  [ nav2_bt_navigator ](/p/nav2_bt_navigator/github-ros-planning-\nnavigation2) [ nav2_common ](/p/nav2_common/github-ros-planning-navigation2) [\nnav2_costmap_2d ](/p/nav2_costmap_2d/github-ros-planning-navigation2) [\ncostmap_queue ](/p/costmap_queue/github-ros-planning-navigation2) [\ndwb_controller ](/p/dwb_controller/github-ros-planning-navigation2) [ dwb_core\n](/p/dwb_core/github-ros-planning-navigation2) [ dwb_critics\n](/p/dwb_critics/github-ros-planning-navigation2) [ dwb_msgs\n](/p/dwb_msgs/github-ros-planning-navigation2) [ dwb_plugins\n](/p/dwb_plugins/github-ros-planning-navigation2) [ nav2_dwb_controller\n](/p/nav2_dwb_controller/github-ros-planning-navigation2) [ nav_2d_msgs\n](/p/nav_2d_msgs/github-ros-planning-navigation2) [ nav_2d_utils\n](/p/nav_2d_utils/github-ros-planning-navigation2) [ nav2_dynamic_params\n](/p/nav2_dynamic_params/github-ros-planning-navigation2) [ nav2_turtlebot3_rl\n](/p/nav2_turtlebot3_rl/github-ros-planning-navigation2) [\nnav2_lifecycle_manager ](/p/nav2_lifecycle_manager/github-ros-planning-\nnavigation2) [ nav2_map_server ](/p/nav2_map_server/github-ros-planning-\nnavigation2) [ nav2_msgs ](/p/nav2_msgs/github-ros-planning-navigation2) [\nnav2_navfn_planner ](/p/nav2_navfn_planner/github-ros-planning-navigation2) [\nnav2_recoveries ](/p/nav2_recoveries/github-ros-planning-navigation2) [\nnav2_rviz_plugins ](/p/nav2_rviz_plugins/github-ros-planning-navigation2) [\nnav2_system_tests ](/p/nav2_system_tests/github-ros-planning-navigation2) [\nnav2_util ](/p/nav2_util/github-ros-planning-navigation2) [ nav2_voxel_grid\n](/p/nav2_voxel_grid/github-ros-planning-navigation2) [ nav2_world_model\n](/p/nav2_world_model/github-ros-planning-navigation2) [ navigation2\n](/p/navigation2/github-ros-planning-navigation2)  \n---|---  \n  \ngithub-ros-planning-navigation2\n\n  * [ github-paulbovbel-nav2_platform ](/p/nav2_bringup/github-paulbovbel-nav2_platform)\n  * [ github-ros-planning-navigation2 ](/p/nav2_bringup/github-ros-planning-navigation2)\n\n  \n  \n---  \n  \n[  \nAPI Docs ](http://docs.ros.org/en/dashing/p/nav2_bringup \"View API\ndocumentation on docs.ros.org\") [  \nBrowse Code ](https://github.com/ros-planning/navigation2/tree/dashing-\ndevel/nav2_bringup \"View source code on repository\")\n\n  * Overview \n  * 0  Assets \n  * 10  Dependencies \n  * 0  Tutorials \n  * 0  Q & A \n\n####  Package Summary\n\n**Tags** |  _No category tags._  \n---|---  \n**Version** |  0.2.6  \n**License** |  Apache-2.0  \n**Build type** |  AMENT_CMAKE  \n**Use** |  RECOMMENDED  \n  \n###  Repository Summary\n\n**Checkout URI** |  [ https://github.com/ros-planning/navigation2.git\n](https://github.com/ros-planning/navigation2.git)  \n---|---  \n**VCS Type** |  git  \n**VCS Version** |  dashing-devel  \n**Last Updated**  \n  \n2020-12-28  |  **Dev Status** |  DEVELOPED  \n**CI status** |  No Continuous Integration  \n**Released** |  RELEASED  \n**Tags** |  _No category tags._  \n**Contributing** |  [ Help Wanted (  0  ) ](/r/navigation2/#dashing-\ncontribute-lists-help-wanted)  \n[ Good First Issues (  0  ) ](/r/navigation2/#dashing-contribute-lists-good-\nfirst-issue)  \n[ Pull Requests to Review (  0  ) ](/r/navigation2/#dashing-contribute-lists-\npull-requests)  \n  \n###  Package Description\n\nBringup scripts and configurations for the navigation2 stack\n\n####  Additional Links\n\n_No additional links._\n\n####  Maintainers\n\n  * Michael Jeronimo \n  * Steve Macenski \n\n####  Authors\n\n_No additional authors._\n\n[ nav2_bringup/README.md ](https://github.com/ros-\nplanning/navigation2/tree/dashing-devel/nav2_bringup/README.md \"Open in git\nrepository\")\n\n#  nav2_bringup\n\nThe ` nav2_bringup ` package is an example bringup system for navigation2\napplications.\n\nNotes: (June 2019, Dashing Release) * We recommend doing this on a Ubuntu\n18.04 installation. We have build issues on 16.04. (see [\nhttps://github.com/ros-planning/navigation2/issues/353\n](https://github.com/ros-planning/navigation2/issues/353) ) * This stack and\nROS2 are still in heavy development and there are some bugs and stability\nissues being worked on, so please do not try this on a robot without taking\n_heavy_ safety precautions. THE ROBOT MAY CRASH! * It is recommended to start\nwith simulation using Gazebo before proceeding to run on a physical robot\n\nInstall and build our code by following this guide: [ https://github.com/ros-\nplanning/navigation2/blob/master/doc/BUILD.md ](https://github.com/ros-\nplanning/navigation2/blob/master/doc/BUILD.md)\n\n##  Launch Navigation2 in simulation with Gazebo\n\n###  Pre-requisites:\n\n  * Gazebo installed on the system \n  * gazebo_ros_pkgs for ROS2 installed on the system \n  * A Gazebo world for simulating the robot (see Gazebo tutorials) \n  * A map of that world saved to a map.pgm and map.yaml (see ROS Navigation tutorials) \n\n###  Terminal 1: Launch Gazebo\n\nExample: See [ turtlebot3_gazebo models ](https://github.com/ROBOTIS-\nGIT/turtlebot3_simulations/tree/ros2/turtlebot3_gazebo/models) for details\n\n    \n    \n    export GAZEBO_MODEL_PATH=$GAZEBO_MODEL_PATH:<full/path/to/my_robot/models>\n    gazebo --verbose -s libgazebo_ros_init.so <full/path/to/my_gazebo.world>\n    \n    \n\n###  Terminal 2: Launch your robot specific transforms\n\nExample: See [ turtlebot3_gazebo ](https://github.com/ROBOTIS-\nGIT/turtlebot3_simulations/tree/ros2/turtlebot3_gazebo) for details\n\n    \n    \n    source turtlebot3_ws/install/setup.bash\n    export TURTLEBOT3_MODEL=waffle\n    ros2 launch turtlebot3_bringup turtlebot3_state_publisher.launch.py use_sim_time:=True\n    \n    \n\n###  Terminal 3: Launch navigation2\n\n    \n    \n    source navigation2_ws/install/setup.bash\n    # Launch the nav2 system\n    ros2 launch nav2_bringup nav2_bringup_launch.py use_sim_time:=True autostart:=True \\\n    map:=<full/path/to/map.yaml>\n    \n    \n\n###  Terminal 4: Run RViz with navigation2 config file\n\n    \n    \n    source navigation2_ws/install/setup.bash\n    ros2 run rviz2 rviz2 -d $(ros2 pkg prefix nav2_bringup)/share/nav2_bringup/launch/nav2_default_view.rviz\n    \n    \n\nIn RViz: * You should see the map * Localize the robot using \u201c2D Pose\nEstimate\u201d button. * Make sure all transforms from odom are present.\n(odom->base_link->base_scan) * Send the robot a goal using \u201cNavigation2 Goal\u201d\nbutton. Note: this uses a ROS2 Action to send the goal, and a pop-up window\nwill appear on your screen with a 'cancel' button if you wish to cancel\n\nTo view the robot model in RViz: * Add \"RobotModel\", set \"Description Source\"\nwith \"File\", set \"Description File\" with the name of the urdf file for your\nrobot (example: turtlebot3_burger.urdf)\"\n\n##  Launch Navigation2 on a Robot\n\nPre-requisites: * Run SLAM or Cartographer with tele-op to drive the robot and\ngenerate a map of an area for testing first. The directions below assume this\nhas already been done. If not, it can be done in ROS1 before beginning to\ninstall our code. * Publish all the transforms from your robot from base_link\nto base_scan\n\nLaunch the code using this launch file and your map.yaml:\n\n` ros2 launch nav2_bringup nav2_bringup_launch.py map:=<full/path/to/map.yaml>\nmap_type:=occupancy `\n\nIn another terminal, run RVIZ:\n\n` ros2 run rviz2 rviz2 -d $(ros2 pkg prefix\nnav2_bringup)/share/nav2_bringup/launch/nav2_default_view.rviz `\n\nIn RVIZ: * Make sure all transforms from odom are present.\n(odom->base_link->base_scan) * Localize the robot using \u201c2D Pose Estimate\u201d\nbutton.\n\nIn RVIZ: * Localize the robot using \u201c2D Pose Estimate\u201d button. * Send the\nrobot a goal using \u201c2D Nav Goal\u201d button.\n\n##  Future Work\n\n  * Add instructions for running navigation2 with SLAM \n\nCHANGELOG\n\n###  Wiki Tutorials\n\n_See[ ROS Wiki Tutorials ](http://wiki.ros.org/nav2_bringup/Tutorials) for\nmore details. _\n\n###  Source Tutorials\n\n_Not currently indexed._\n\n###  Package Dependencies\n\nDeps  |  |  Name  |  [ ](/p/nav2_common#dashing-deps) |  [ 1\n](/packages/nav2_common) |  [ nav2_common ](/p/nav2_common#dashing)  \n---|---|---  \n[ ](/p/navigation2#dashing-deps) |  [ 1 ](/packages/navigation2) |  [\nnavigation2 ](/p/navigation2#dashing)  \n[ ](/p/launch_ros#dashing-deps) |  [ 2 ](/packages/launch_ros) |  [ launch_ros\n](/p/launch_ros#dashing)  \n[ ](/p/ament_cmake#dashing-deps) |  [ 1 ](/packages/ament_cmake) |  [\nament_cmake ](/p/ament_cmake#dashing)  \n[ ](/p/ament_lint_common#dashing-deps) |  [ 1 ](/packages/ament_lint_common) |\n[ ament_lint_common ](/p/ament_lint_common#dashing)  \n[ ](/p/ament_lint_auto#dashing-deps) |  [ 1 ](/packages/ament_lint_auto) |  [\nament_lint_auto ](/p/ament_lint_auto#dashing)  \n[ ](/p/ament_cmake_gtest#dashing-deps) |  [ 1 ](/packages/ament_cmake_gtest) |\n[ ament_cmake_gtest ](/p/ament_cmake_gtest#dashing)  \n[ ](/p/ament_cmake_pytest#dashing-deps) |  [ 1 ](/packages/ament_cmake_pytest)\n|  [ ament_cmake_pytest ](/p/ament_cmake_pytest#dashing)  \n[ ](/p/launch#dashing-deps) |  [ 1 ](/packages/launch) |  [ launch\n](/p/launch#dashing)  \n[ ](/p/launch_testing#dashing-deps) |  [ 1 ](/packages/launch_testing) |  [\nlaunch_testing ](/p/launch_testing#dashing)  \n  \n###  System Dependencies\n\n_No direct system dependencies._\n\n###  Dependant Packages\n\nName  |  Repo  |  Deps  |  [ turtlebot3_navigation2\n](/p/turtlebot3_navigation2/github-ROBOTIS-GIT-turtlebot3#dashing) |  [\ngithub-ROBOTIS-GIT-turtlebot3 ](/r/turtlebot3/github-ROBOTIS-GIT-turtlebot3) |\n[ ](/p/turtlebot3_navigation2/github-ROBOTIS-GIT-turtlebot3#dashing-deps)  \n---|---|---  \n[ nav2_system_tests ](/p/nav2_system_tests/github-ros-planning-\nnavigation2#dashing) |  [ github-ros-planning-navigation2\n](/r/navigation2/github-ros-planning-navigation2) |  [\n](/p/nav2_system_tests/github-ros-planning-navigation2#dashing-deps)  \n  \n###  Launch files\n\n_No launch files found_\n\n###  Messages\n\n_No message files found._\n\n###  Services\n\n_No service files found_\n\n###  Plugins\n\n_No plugins found._\n\n###  Recent questions tagged ` nav2_bringup ` at **[ Robotics Stack Exchange\n](https://robotics.stackexchange.com/) **\n\nNo questions yet, you can ask one [ here\n](https://robotics.stackexchange.com/questions/tagged/nav2_bringup+dashing) .\n\nFailed to get question list, you can ticket an issue [ here\n](https://github.com/ros-infrastructure/rosindex/issues/new)\n\n[ API Docs ](http://docs.ros.org/en/dashing/p/nav2_bringup \"View API\ndocumentation on docs.ros.org\") [ Browse Code ](https://github.com/ros-\nplanning/navigation2/tree/dashing-devel/nav2_bringup \"View source code on\nrepository\")\n\n![](/assets/package.png) |\n\n###  [ nav2_bringup ](/p/nav2_bringup) package from [ navigation2\n](/r/navigation2/github-ros-planning-navigation2) repo\n\n[ nav2_amcl ](/p/nav2_amcl/github-ros-planning-navigation2) [\nnav2_behavior_tree ](/p/nav2_behavior_tree/github-ros-planning-navigation2)\nnav2_bringup  [ nav2_gazebo_spawner ](/p/nav2_gazebo_spawner/github-ros-\nplanning-navigation2) [ nav2_bt_navigator ](/p/nav2_bt_navigator/github-ros-\nplanning-navigation2) [ nav2_common ](/p/nav2_common/github-ros-planning-\nnavigation2) [ nav2_controller ](/p/nav2_controller/github-ros-planning-\nnavigation2) [ nav2_core ](/p/nav2_core/github-ros-planning-navigation2) [\nnav2_costmap_2d ](/p/nav2_costmap_2d/github-ros-planning-navigation2) [\ncostmap_queue ](/p/costmap_queue/github-ros-planning-navigation2) [ dwb_core\n](/p/dwb_core/github-ros-planning-navigation2) [ dwb_critics\n](/p/dwb_critics/github-ros-planning-navigation2) [ dwb_msgs\n](/p/dwb_msgs/github-ros-planning-navigation2) [ dwb_plugins\n](/p/dwb_plugins/github-ros-planning-navigation2) [ nav2_dwb_controller\n](/p/nav2_dwb_controller/github-ros-planning-navigation2) [ nav_2d_msgs\n](/p/nav_2d_msgs/github-ros-planning-navigation2) [ nav_2d_utils\n](/p/nav_2d_utils/github-ros-planning-navigation2) [ nav2_lifecycle_manager\n](/p/nav2_lifecycle_manager/github-ros-planning-navigation2) [ nav2_map_server\n](/p/nav2_map_server/github-ros-planning-navigation2) [ nav2_msgs\n](/p/nav2_msgs/github-ros-planning-navigation2) [ nav2_navfn_planner\n](/p/nav2_navfn_planner/github-ros-planning-navigation2) [ nav2_planner\n](/p/nav2_planner/github-ros-planning-navigation2) [ nav2_recoveries\n](/p/nav2_recoveries/github-ros-planning-navigation2) [\nnav2_regulated_pure_pursuit_controller\n](/p/nav2_regulated_pure_pursuit_controller/github-ros-planning-navigation2) [\nnav2_rotation_shim_controller ](/p/nav2_rotation_shim_controller/github-ros-\nplanning-navigation2) [ nav2_rviz_plugins ](/p/nav2_rviz_plugins/github-ros-\nplanning-navigation2) [ nav2_simple_commander\n](/p/nav2_simple_commander/github-ros-planning-navigation2) [\nnav2_smac_planner ](/p/nav2_smac_planner/github-ros-planning-navigation2) [\nnav2_system_tests ](/p/nav2_system_tests/github-ros-planning-navigation2) [\nnav2_theta_star_planner ](/p/nav2_theta_star_planner/github-ros-planning-\nnavigation2) [ nav2_util ](/p/nav2_util/github-ros-planning-navigation2) [\nnav2_voxel_grid ](/p/nav2_voxel_grid/github-ros-planning-navigation2) [\nnav2_waypoint_follower ](/p/nav2_waypoint_follower/github-ros-planning-\nnavigation2) [ navigation2 ](/p/navigation2/github-ros-planning-navigation2)  \n---|---  \n  \ngithub-ros-planning-navigation2\n\n  * [ github-paulbovbel-nav2_platform ](/p/nav2_bringup/github-paulbovbel-nav2_platform)\n  * [ github-ros-planning-navigation2 ](/p/nav2_bringup/github-ros-planning-navigation2)\n\n  \n  \n---  \n  \n[  \nAPI Docs ](http://docs.ros.org/en/galactic/p/nav2_bringup \"View API\ndocumentation on docs.ros.org\") [  \nBrowse Code ](https://github.com/ros-\nplanning/navigation2/tree/galactic/nav2_bringup/bringup \"View source code on\nrepository\")\n\n  * Overview \n  * 0  Assets \n  * 11  Dependencies \n  * 0  Tutorials \n  * 0  Q & A \n\n####  Package Summary\n\n**Tags** |  _No category tags._  \n---|---  \n**Version** |  1.0.12  \n**License** |  Apache-2.0  \n**Build type** |  AMENT_CMAKE  \n**Use** |  RECOMMENDED  \n  \n###  Repository Summary\n\n**Checkout URI** |  [ https://github.com/ros-planning/navigation2.git\n](https://github.com/ros-planning/navigation2.git)  \n---|---  \n**VCS Type** |  git  \n**VCS Version** |  galactic  \n**Last Updated**  \n  \n2022-09-15  |  **Dev Status** |  DEVELOPED  \n**CI status** |  No Continuous Integration  \n**Released** |  RELEASED  \n**Tags** |  _No category tags._  \n**Contributing** |  [ Help Wanted (  0  ) ](/r/navigation2/#galactic-\ncontribute-lists-help-wanted)  \n[ Good First Issues (  0  ) ](/r/navigation2/#galactic-contribute-lists-good-\nfirst-issue)  \n[ Pull Requests to Review (  0  ) ](/r/navigation2/#galactic-contribute-lists-\npull-requests)  \n  \n###  Package Description\n\nBringup scripts and configurations for the Nav2 stack\n\n####  Additional Links\n\n_No additional links._\n\n####  Maintainers\n\n  * Michael Jeronimo \n  * Steve Macenski \n  * Carlos Orduno \n\n####  Authors\n\n_No additional authors._\n\n[ nav2_bringup/bringup/README.md ](https://github.com/ros-\nplanning/navigation2/tree/galactic/nav2_bringup/bringup/README.md \"Open in git\nrepository\")\n\n#  nav2_bringup\n\nThe ` nav2_bringup ` package is an example bringup system for Nav2\napplications.\n\n###  Pre-requisites:\n\n  * [ Install ROS 2 ](https://index.ros.org/doc/ros2/Installation/Dashing/)\n  * Install Nav2 \n\n` sudo apt install ros-<ros2_distro>-navigation2 `\n\n  * Install Nav2 Bringup \n\n` sudo apt install ros-<ros2_distro>-nav2-bringup `\n\n  * Install your robot specific package (ex: [ Turtlebot 3 ](http://emanual.robotis.com/docs/en/platform/turtlebot3/ros2/) ) \n\n##  Launch Nav2 in _Simulation_ with Gazebo\n\n###  Pre-requisites:\n\n  * [ Install Gazebo ](http://gazebosim.org/tutorials?tut=install_ubuntu&cat=install)\n  * gazebo_ros_pkgs for ROS2 installed on the system \n\n` sudo apt-get install ros-<ros2-distro>-gazebo* ` * A Gazebo world for\nsimulating the robot ( [ Gazebo tutorials\n](http://gazebosim.org/tutorials?tut=quick_start) ) * A map of that world\nsaved to a map.pgm and map.yaml ( [ ROS Navigation Tutorials\n](https://github.com/ros-planning/navigation2/tree/main/doc/use_cases) )\n\n###  Terminal 1: Launch Gazebo\n\nExample: See [ turtlebot3_gazebo models ](https://github.com/ROBOTIS-\nGIT/turtlebot3_simulations/tree/ros2/turtlebot3_gazebo/models) for details\n\n    \n    \n    export GAZEBO_MODEL_PATH=$GAZEBO_MODEL_PATH:<full/path/to/my_robot/models>\n    gazebo --verbose -s libgazebo_ros_init.so <full/path/to/my_gazebo.world>\n    \n    \n\n###  Terminal 2: Launch your robot specific transforms\n\nExample: See [ turtlebot3_gazebo ](https://github.com/ROBOTIS-\nGIT/turtlebot3_simulations/tree/ros2/turtlebot3_gazebo) for details\n\n    \n    \n    source /opt/ros/dashing/setup.bash\n    export TURTLEBOT3_MODEL=waffle\n    ros2 launch turtlebot3_bringup turtlebot3_state_publisher.launch.py use_sim_time:=True\n    \n    \n\n###  Terminal 3: Launch Nav2\n\n    \n    \n    source /opt/ros/dashing/setup.bash\n    ros2 launch nav2_bringup bringup_launch.py use_sim_time:=True autostart:=True \\\n    map:=<full/path/to/map.yaml>\n    \n    \n\n###  Terminal 4: Run RViz with Nav2 config file\n\n    \n    \n    source /opt/ros/dashing/setup.bash\n    ros2 run rviz2 rviz2 -d $(ros2 pkg prefix nav2_bringup)/share/nav2_bringup/launch/nav2_default_view.rviz\n    \n    \n\nIn RViz: * You should see the map * Localize the robot using \u201c2D Pose\nEstimate\u201d button. * Make sure all transforms from odom are present.\n(odom->base_link->base_scan) * Send the robot a goal using \"Nav2 Goal\u201d button.\nNote: this uses a ROS2 Action to send the goal, and a pop-up window will\nappear on your screen with a 'cancel' button if you wish to cancel\n\nTo view the robot model in RViz: * Add \"RobotModel\", set \"Description Source\"\nwith \"File\", set \"Description File\" with the name of the urdf file for your\nrobot (example: turtlebot3_burger.urdf)\"\n\n###  Advanced: single-terminal launch\n\nA convenience file is provided to launch Gazebo, RVIZ and Nav2 using a single\ncommand:\n\n    \n    \n    ros2 launch nav2_bringup tb3_simulation_launch.py <settings>\n    \n    \n\nWhere ` <settings> ` can used to replace any of the default options, for\nexample:\n\n    \n    \n    world:=<full/path/to/gazebo.world>\n    map:=<full/path/to/map.yaml>\n    rviz_config_file:=<full/path/to/rviz_config.rviz>\n    simulator:=<gzserver or gazebo>\n    bt_xml_file:=<full/path/to/bt_tree.xml>\n    \n    \n\nBefore running the command make sure you are sourcing the ` ROS2 ` workspace,\nsetting the path to the Gazebo model and defining the TB3 robot model to use.\n\n    \n    \n    source <full/path/to/ros2/setup.bash>\n    export GAZEBO_MODEL_PATH=$GAZEBO_MODEL_PATH:<full/path/to/my_robot/models>\n    export TURTLEBOT3_MODEL=waffle\n    \n    \n\nAlso, a file for launching **two** robots with **independent** navigation\nstacks is provided:\n\n    \n    \n    ros2 launch nav2_bringup multi_tb3_simulation_launch.py <settings>\n    \n    \n\n##  Launch Nav2 on a _Robot_\n\n###  Pre-requisites:\n\n  * Run SLAM with Navigation 2 or tele-op to drive the robot and generate a map of an area for testing first. The directions below assume this has already been done or there is already a map of the area. \n\n  * Learn more about how to use Navigation 2 with SLAM to create maps; \n\n    * [ Navigation 2 with SLAM ](https://github.com/ros-planning/navigation2/blob/main/doc/use_cases/navigation_with_slam.md)\n  * _Please note that currently, nav2_bringup works if you provide a map file. However, providing a map is not required to use Nav2. Nav2 can be configured to use the costmaps to navigate in an area without using a map file_\n\n  * Publish all the transforms from your robot from base_link to base_scan \n\n###  Terminal 1 : Launch Nav2 using your map.yaml\n\n    \n    \n    source /opt/ros/dashing/setup.bash\n    ros2 launch nav2_bringup bringup_launch.py map:=<full/path/to/map.yaml> map_type:=occupancy\n    \n    \n\n###  Terminal 2 : Launch RVIZ\n\n    \n    \n    source /opt/ros/dashing/setup.bash\n    ros2 run rviz2 rviz2 -d $(ros2 pkg prefix nav2_bringup)/share/nav2_bringup/launch/nav2_default_view.rviz\n    \n    \n\nIn RVIZ: * Make sure all transforms from odom are present.\n(odom->base_link->base_scan) * Localize the robot using \u201c2D Pose Estimate\u201d\nbutton. * Send the robot a goal pose using \u201c2D Nav Goal\u201d button.\n\nCHANGELOG\n\n###  Wiki Tutorials\n\n_See[ ROS Wiki Tutorials ](http://wiki.ros.org/nav2_bringup/Tutorials) for\nmore details. _\n\n###  Source Tutorials\n\n_Not currently indexed._\n\n###  Package Dependencies\n\nDeps  |  |  Name  |  [ ](/p/nav2_common#galactic-deps) |  [ 1\n](/packages/nav2_common) |  [ nav2_common ](/p/nav2_common#galactic)  \n---|---|---  \n[ ](/p/navigation2#galactic-deps) |  [ 1 ](/packages/navigation2) |  [\nnavigation2 ](/p/navigation2#galactic)  \n[ ](/p/launch_ros#galactic-deps) |  [ 2 ](/packages/launch_ros) |  [\nlaunch_ros ](/p/launch_ros#galactic)  \n[ ](/p/ament_cmake#galactic-deps) |  [ 1 ](/packages/ament_cmake) |  [\nament_cmake ](/p/ament_cmake#galactic)  \n[ ](/p/slam_toolbox#galactic-deps) |  [ 1 ](/packages/slam_toolbox) |  [\nslam_toolbox ](/p/slam_toolbox#galactic)  \n[ ](/p/ament_lint_common#galactic-deps) |  [ 1 ](/packages/ament_lint_common)\n|  [ ament_lint_common ](/p/ament_lint_common#galactic)  \n[ ](/p/ament_lint_auto#galactic-deps) |  [ 1 ](/packages/ament_lint_auto) |  [\nament_lint_auto ](/p/ament_lint_auto#galactic)  \n[ ](/p/ament_cmake_gtest#galactic-deps) |  [ 1 ](/packages/ament_cmake_gtest)\n|  [ ament_cmake_gtest ](/p/ament_cmake_gtest#galactic)  \n[ ](/p/ament_cmake_pytest#galactic-deps) |  [ 1\n](/packages/ament_cmake_pytest) |  [ ament_cmake_pytest\n](/p/ament_cmake_pytest#galactic)  \n[ ](/p/launch#galactic-deps) |  [ 1 ](/packages/launch) |  [ launch\n](/p/launch#galactic)  \n[ ](/p/launch_testing#galactic-deps) |  [ 1 ](/packages/launch_testing) |  [\nlaunch_testing ](/p/launch_testing#galactic)  \n  \n###  System Dependencies\n\n_No direct system dependencies._\n\n###  Dependant Packages\n\nName  |  Repo  |  Deps  |  [ turtlebot3_navigation2\n](/p/turtlebot3_navigation2/github-ROBOTIS-GIT-turtlebot3#galactic) |  [\ngithub-ROBOTIS-GIT-turtlebot3 ](/r/turtlebot3/github-ROBOTIS-GIT-turtlebot3) |\n[ ](/p/turtlebot3_navigation2/github-ROBOTIS-GIT-turtlebot3#galactic-deps)  \n---|---|---  \n[ nav2_system_tests ](/p/nav2_system_tests/github-ros-planning-\nnavigation2#galactic) |  [ github-ros-planning-navigation2\n](/r/navigation2/github-ros-planning-navigation2) |  [\n](/p/nav2_system_tests/github-ros-planning-navigation2#galactic-deps)  \n[ sm_dance_bot ](/p/sm_dance_bot/github-robosoft-ai-SMACC2#galactic) |  [\ngithub-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-ai-SMACC2) |  [\n](/p/sm_dance_bot/github-robosoft-ai-SMACC2#galactic-deps)  \n[ sm_dance_bot_strikes_back ](/p/sm_dance_bot_strikes_back/github-robosoft-ai-\nSMACC2#galactic) |  [ github-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-\nai-SMACC2) |  [ ](/p/sm_dance_bot_strikes_back/github-robosoft-ai-\nSMACC2#galactic-deps)  \n[ sm_dance_bot_warehouse ](/p/sm_dance_bot_warehouse/github-robosoft-ai-\nSMACC2#galactic) |  [ github-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-\nai-SMACC2) |  [ ](/p/sm_dance_bot_warehouse/github-robosoft-ai-\nSMACC2#galactic-deps)  \n[ sm_dance_bot_warehouse_2 ](/p/sm_dance_bot_warehouse_2/github-robosoft-ai-\nSMACC2#galactic) |  [ github-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-\nai-SMACC2) |  [ ](/p/sm_dance_bot_warehouse_2/github-robosoft-ai-\nSMACC2#galactic-deps)  \n[ sm_dance_bot_warehouse_3 ](/p/sm_dance_bot_warehouse_3/github-robosoft-ai-\nSMACC2#galactic) |  [ github-robosoft-ai-SMACC2 ](/r/smacc2/github-robosoft-\nai-SMACC2) |  [ ](/p/sm_dance_bot_warehouse_3/github-robosoft-ai-\nSMACC2#galactic-deps)  \n[ turtlebot4_navigation ](/p/turtlebot4_navigation/github-turtlebot-\nturtlebot4#galactic) |  [ github-turtlebot-turtlebot4 ](/r/turtlebot4/github-\nturtlebot-turtlebot4) |  [ ](/p/turtlebot4_navigation/github-turtlebot-\nturtlebot4#galactic-deps)  \n  \n###  Launch files\n\n_No launch files found_\n\n###  Messages\n\n_No message files found._\n\n###  Services\n\n_No service files found_\n\n###  Plugins\n\n_No plugins found._\n\n###  Recent questions tagged ` nav2_bringup ` at **[ Robotics Stack Exchange\n](https://robotics.stackexchange.com/) **\n\nNo questions yet, you can ask one [ here\n](https://robotics.stackexchange.com/questions/tagged/nav2_bringup+galactic) .\n\nFailed to get question list, you can ticket an issue [ here\n](https://github.com/ros-infrastructure/rosindex/issues/new)\n\n[ API Docs ](http://docs.ros.org/en/galactic/p/nav2_bringup \"View API\ndocumentation on docs.ros.org\") [ Browse Code ](https://github.com/ros-\nplanning/navigation2/tree/galactic/nav2_bringup/bringup \"View source code on\nrepository\")\n\n![](/assets/package.png) |\n\n###  [ nav2_bringup ](/p/nav2_bringup) package from [ navigation2\n](/r/navigation2/github-ros-planning-navigation2) repo\n\n[ nav2_amcl ](/p/nav2_amcl/github-ros-planning-navigation2) [\nnav2_behavior_tree ](/p/nav2_behavior_tree/github-ros-planning-navigation2)\nnav2_bringup  [ nav2_gazebo_spawner ](/p/nav2_gazebo_spawner/github-ros-\nplanning-navigation2) [ nav2_bt_navigator ](/p/nav2_bt_navigator/github-ros-\nplanning-navigation2) [ nav2_common ](/p/nav2_common/github-ros-planning-\nnavigation2) [ nav2_controller ](/p/nav2_controller/github-ros-planning-\nnavigation2) [ nav2_core ](/p/nav2_core/github-ros-planning-navigation2) [\nnav2_costmap_2d ](/p/nav2_costmap_2d/github-ros-planning-navigation2) [\ncostmap_queue ](/p/costmap_queue/github-ros-planning-navigation2) [ dwb_core\n](/p/dwb_core/github-ros-planning-navigation2) [ dwb_critics\n](/p/dwb_critics/github-ros-planning-navigation2) [ dwb_msgs\n](/p/dwb_msgs/github-ros-planning-navigation2) [ dwb_plugins\n](/p/dwb_plugins/github-ros-planning-navigation2) [ nav2_dwb_controller\n](/p/nav2_dwb_controller/github-ros-planning-navigation2) [ nav_2d_msgs\n](/p/nav_2d_msgs/github-ros-planning-navigation2) [ nav_2d_utils\n](/p/nav_2d_utils/github-ros-planning-navigation2) [ nav2_lifecycle_manager\n](/p/nav2_lifecycle_manager/github-ros-planning-navigation2) [ nav2_map_server\n](/p/nav2_map_server/github-ros-planning-navigation2) [ nav2_msgs\n](/p/nav2_msgs/github-ros-planning-navigation2) [ nav2_navfn_planner\n](/p/nav2_navfn_planner/github-ros-planning-navigation2) [ nav2_planner\n](/p/nav2_planner/github-ros-planning-navigation2) [ nav2_recoveries\n](/p/nav2_recoveries/github-ros-planning-navigation2) [\nnav2_regulated_pure_pursuit_controller\n](/p/nav2_regulated_pure_pursuit_controller/github-ros-planning-navigation2) [\nnav2_rviz_plugins ](/p/nav2_rviz_plugins/github-ros-planning-navigation2) [\nnav2_system_tests ](/p/nav2_system_tests/github-ros-planning-navigation2) [\nnav2_util ](/p/nav2_util/github-ros-planning-navigation2) [ nav2_voxel_grid\n](/p/nav2_voxel_grid/github-ros-planning-navigation2) [ nav2_waypoint_follower\n](/p/nav2_waypoint_follower/github-ros-planning-navigation2) [ navigation2\n](/p/navigation2/github-ros-planning-navigation2) [ smac_planner\n](/p/smac_planner/github-ros-planning-navigation2)  \n---|---  \n  \ngithub-ros-planning-navigation2\n\n  * [ github-paulbovbel-nav2_platform ](/p/nav2_bringup/github-paulbovbel-nav2_platform)\n  * [ github-ros-planning-navigation2 ](/p/nav2_bringup/github-ros-planning-navigation2)\n\n  \n  \n---  \n  \n[  \nAPI Docs ](http://docs.ros.org/en/foxy/p/nav2_bringup \"View API documentation\non docs.ros.org\") [  \nBrowse Code ](https://github.com/ros-planning/navigation2/tree/foxy-\ndevel/nav2_bringup/bringup \"View source code on repository\")\n\n  * Overview \n  * 0  Assets \n  * 11  Dependencies \n  * 0  Tutorials \n  * 0  Q & A \n\n####  Package Summary\n\n**Tags** |  _No category tags._  \n---|---  \n**Version** |  0.4.7  \n**License** |  Apache-2.0  \n**Build type** |  AMENT_CMAKE  \n**Use** |  RECOMMENDED  \n  \n###  Repository Summary\n\n**Checkout URI** |  [ https://github.com/ros-planning/navigation2.git\n](https://github.com/ros-planning/navigation2.git)  \n---|---  \n**VCS Type** |  git  \n**VCS Version** |  foxy-devel  \n**Last Updated**  \n  \n2022-08-31  |  **Dev Status** |  DEVELOPED  \n**CI status** |  No Continuous Integration  \n**Released** |  RELEASED  \n**Tags** |  _No category tags._  \n**Contributing** |  [ Help Wanted (  0  ) ](/r/navigation2/#foxy-contribute-\nlists-help-wanted)  \n[ Good First Issues (  0  ) ](/r/navigation2/#foxy-contribute-lists-good-\nfirst-issue)  \n[ Pull Requests to Review (  0  ) ](/r/navigation2/#foxy-contribute-lists-\npull-requests)  \n  \n###  Package Description\n\nBringup scripts and configurations for the navigation2 stack\n\n####  Additional Links\n\n_No additional links._\n\n####  Maintainers\n\n  * Michael Jeronimo \n  * Steve Macenski \n  * Carlos Orduno \n\n####  Authors\n\n_No additional authors._\n\n[ nav2_bringup/bringup/README.md ](https://github.com/ros-\nplanning/navigation2/tree/foxy-devel/nav2_bringup/bringup/README.md \"Open in\ngit repository\")\n\n#  nav2_bringup\n\nThe ` nav2_bringup ` package is an example bringup system for Navigation2\napplications.\n\n###  Pre-requisites:\n\n  * [ Install ROS 2 ](https://index.ros.org/doc/ros2/Installation/Dashing/)\n  * Install Navigation2 \n\n` sudo apt install ros-<ros2_distro>-navigation2 `\n\n  * Install Navigation2 Bringup \n\n` sudo apt install ros-<ros2_distro>-nav2-bringup `\n\n  * Install your robot specific package (ex: [ Turtlebot 3 ](http://emanual.robotis.com/docs/en/platform/turtlebot3/ros2/) ) \n\n##  Launch Navigation2 in _Simulation_ with Gazebo\n\n###  Pre-requisites:\n\n  * [ Install Gazebo ](http://gazebosim.org/tutorials?tut=install_ubuntu&cat=install)\n  * gazebo_ros_pkgs for ROS2 installed on the system \n\n` sudo apt-get install ros-<ros2-distro>-gazebo* ` * A Gazebo world for\nsimulating the robot ( [ Gazebo tutorials\n](http://gazebosim.org/tutorials?tut=quick_start) ) * A map of that world\nsaved to a map.pgm and map.yaml ( [ ROS Navigation Tutorials\n](https://github.com/ros-planning/navigation2/tree/master/doc/use_cases) )\n\n###  Terminal 1: Launch Gazebo\n\nExample: See [ turtlebot3_gazebo models ](https://github.com/ROBOTIS-\nGIT/turtlebot3_simulations/tree/ros2/turtlebot3_gazebo/models) for details\n\n    \n    \n    export GAZEBO_MODEL_PATH=$GAZEBO_MODEL_PATH:<full/path/to/my_robot/models>\n    gazebo --verbose -s libgazebo_ros_init.so <full/path/to/my_gazebo.world>\n    \n    \n\n###  Terminal 2: Launch your robot specific transforms\n\nExample: See [ turtlebot3_gazebo ](https://github.com/ROBOTIS-\nGIT/turtlebot3_simulations/tree/ros2/turtlebot3_gazebo) for details\n\n    \n    \n    source /opt/ros/dashing/setup.bash\n    export TURTLEBOT3_MODEL=waffle\n    ros2 launch turtlebot3_bringup turtlebot3_state_publisher.launch.py use_sim_time:=True\n    \n    \n\n###  Terminal 3: Launch Navigation2\n\n    \n    \n    source /opt/ros/dashing/setup.bash\n    ros2 launch nav2_bringup bringup_launch.py use_sim_time:=True autostart:=True \\\n    map:=<full/path/to/map.yaml>\n    \n    \n\n###  Terminal 4: Run RViz with Navigation2 config file\n\n    \n    \n    source /opt/ros/dashing/setup.bash\n    ros2 run rviz2 rviz2 -d $(ros2 pkg prefix nav2_bringup)/share/nav2_bringup/launch/nav2_default_view.rviz\n    \n    \n\nIn RViz: * You should see the map * Localize the robot using \u201c2D Pose\nEstimate\u201d button. * Make sure all transforms from odom are present.\n(odom->base_link->base_scan) * Send the robot a goal using \u201cNavigation2 Goal\u201d\nbutton. Note: this uses a ROS2 Action to send the goal, and a pop-up window\nwill appear on your screen with a 'cancel' button if you wish to cancel\n\nTo view the robot model in RViz: * Add \"RobotModel\", set \"Description Source\"\nwith \"File\", set \"Description File\" with the name of the urdf file for your\nrobot (example: turtlebot3_burger.urdf)\"\n\n###  Advanced: single-terminal launch\n\nA convenience file is provided to launch Gazebo, RVIZ and Navigation2 using a\nsingle command:\n\n    \n    \n    ros2 launch nav2_bringup tb3_simulation_launch.py <settings>\n    \n    \n\nWhere ` <settings> ` can used to replace any of the default options, for\nexample:\n\n    \n    \n    world:=<full/path/to/gazebo.world>\n    map:=<full/path/to/map.yaml>\n    rviz_config_file:=<full/path/to/rviz_config.rviz>\n    simulator:=<gzserver or gazebo>\n    bt_xml_file:=<full/path/to/bt_tree.xml>\n    \n    \n\nBefore running the command make sure you are sourcing the ` ROS2 ` workspace,\nsetting the path to the Gazebo model and defining the TB3 robot model to use.\n\n    \n    \n    source <full/path/to/ros2/setup.bash>\n    export GAZEBO_MODEL_PATH=$GAZEBO_MODEL_PATH:<full/path/to/my_robot/models>\n    export TURTLEBOT3_MODEL=waffle\n    \n    \n\nAlso, a file for launching **two** robots with **independent** navigation\nstacks is provided:\n\n    \n    \n    ros2 launch nav2_bringup multi_tb3_simulation_launch.py <settings>\n    \n    \n\n##  Launch Navigation2 on a _Robot_\n\n###  Pre-requisites:\n\n  * Run SLAM with Navigation 2 or tele-op to drive the robot and generate a map of an area for testing first. The directions below assume this has already been done or there is already a map of the area. \n\n  * Learn more about how to use Navigation 2 with SLAM to create maps; \n\n    * [ Navigation 2 with SLAM ](https://github.com/ros-planning/navigation2/blob/master/doc/use_cases/navigation_with_slam.md)\n  * _Please note that currently, nav2_bringup works if you provide a map file. However, providing a map is not required to use Navigation2. Navigation2 can be configured to use the costmaps to navigate in an area without using a map file_\n\n  * Publish all the transforms from your robot from base_link to base_scan \n\n###  Terminal 1 : Launch Navigation2 using your map.yaml\n\n    \n    \n    source /opt/ros/dashing/setup.bash\n    ros2 launch nav2_bringup bringup_launch.py map:=<full/path/to/map.yaml> map_type:=occupancy\n    \n    \n\n###  Terminal 2 : Launch RVIZ\n\n    \n    \n    source /opt/ros/dashing/setup.bash\n    ros2 run rviz2 rviz2 -d $(ros2 pkg prefix nav2_bringup)/share/nav2_bringup/launch/nav2_default_view.rviz\n    \n    \n\nIn RVIZ: * Make sure all transforms from odom are present.\n(odom->base_link->base_scan) * Localize the robot using \u201c2D Pose Estimate\u201d\nbutton. * Send the robot a goal pose using \u201c2D Nav Goal\u201d button.\n\nCHANGELOG\n\n###  Wiki Tutorials\n\n_See[ ROS Wiki Tutorials ](http://wiki.ros.org/nav2_bringup/Tutorials) for\nmore details. _\n\n###  Source Tutorials\n\n_Not currently indexed._\n\n###  Package Dependencies\n\nDeps  |  |  Name  |  [ ](/p/nav2_common#foxy-deps) |  [ 1\n](/packages/nav2_common) |  [ nav2_common ](/p/nav2_common#foxy)  \n---|---|---  \n[ ](/p/navigation2#foxy-deps) |  [ 1 ](/packages/navigation2) |  [ navigation2\n](/p/navigation2#foxy)  \n[ ](/p/launch_ros#foxy-deps) |  [ 2 ](/packages/launch_ros) |  [ launch_ros\n](/p/launch_ros#foxy)  \n[ ](/p/ament_cmake#foxy-deps) |  [ 1 ](/packages/ament_cmake) |  [ ament_cmake\n](/p/ament_cmake#foxy)  \n[ ](/p/slam_toolbox#foxy-deps) |  [ 1 ](/packages/slam_toolbox) |  [\nslam_toolbox ](/p/slam_toolbox#foxy)  \n[ ](/p/ament_lint_common#foxy-deps) |  [ 1 ](/packages/ament_lint_common) |  [\nament_lint_common ](/p/ament_lint_common#foxy)  \n[ ](/p/ament_lint_auto#foxy-deps) |  [ 1 ](/packages/ament_lint_auto) |  [\nament_lint_auto ](/p/ament_lint_auto#foxy)  \n[ ](/p/ament_cmake_gtest#foxy-deps) |  [ 1 ](/packages/ament_cmake_gtest) |  [\nament_cmake_gtest ](/p/ament_cmake_gtest#foxy)  \n[ ](/p/ament_cmake_pytest#foxy-deps) |  [ 1 ](/packages/ament_cmake_pytest) |\n[ ament_cmake_pytest ](/p/ament_cmake_pytest#foxy)  \n[ ](/p/launch#foxy-deps) |  [ 1 ](/packages/launch) |  [ launch\n](/p/launch#foxy)  \n[ ](/p/launch_testing#foxy-deps) |  [ 1 ](/packages/launch_testing) |  [\nlaunch_testing ](/p/launch_testing#foxy)  \n  \n###  System Dependencies\n\n_No direct system dependencies._\n\n###  Dependant Packages\n\nName  |  Repo  |  Deps  |  [ jackal_navigation ](/p/jackal_navigation/github-\njackal-jackal#foxy) |  [ github-jackal-jackal ](/r/jackal/github-jackal-\njackal) |  [ ](/p/jackal_navigation/github-jackal-jackal#foxy-deps)  \n---|---|---  \n[ rtabmap_demos ](/p/rtabmap_demos/github-introlab-rtabmap_ros#foxy) |  [\ngithub-introlab-rtabmap_ros ](/r/rtabmap_ros/github-introlab-rtabmap_ros) |  [\n](/p/rtabmap_demos/github-introlab-rtabmap_ros#foxy-deps)  \n[ turtlebot3_navigation2 ](/p/turtlebot3_navigation2/github-ROBOTIS-GIT-\nturtlebot3#foxy) |  [ github-ROBOTIS-GIT-turtlebot3 ](/r/turtlebot3/github-\nROBOTIS-GIT-turtlebot3) |  [ ](/p/turtlebot3_navigation2/github-ROBOTIS-GIT-\nturtlebot3#foxy-deps)  \n[ mppic ](/p/mppic/github-FastSense-mppic#foxy) |  [ github-FastSense-mppic\n](/r/mppic/github-FastSense-mppic) |  [ ](/p/mppic/github-FastSense-\nmppic#foxy-deps)  \n[ nav2_system_tests ](/p/nav2_system_tests/github-ros-planning-\nnavigation2#foxy) |  [ github-ros-planning-navigation2\n](/r/navigation2/github-ros-planning-navigation2) |  [\n](/p/nav2_system_tests/github-ros-planning-navigation2#foxy-deps)  \n[ raspimouse_navigation ](/p/raspimouse_navigation/github-rt-net-\nraspimouse_slam_navigation_ros2#foxy) |  [ github-rt-net-\nraspimouse_slam_navigation_ros2 ](/r/raspimouse_slam_navigation_ros2/github-\nrt-net-raspimouse_slam_navigation_ros2) |  [\n](/p/raspimouse_navigation/github-rt-net-raspimouse_slam_navigation_ros2#foxy-\ndeps)  \n  \n###  Launch files\n\n_No launch files found_\n\n###  Messages\n\n_No message files found._\n\n###  Services\n\n_No service files found_\n\n###  Plugins\n\n_No plugins found._\n\n###  Recent questions tagged ` nav2_bringup ` at **[ Robotics Stack Exchange\n](https://robotics.stackexchange.com/) **\n\nNo questions yet, you can ask one [ here\n](https://robotics.stackexchange.com/questions/tagged/nav2_bringup+foxy) .\n\nFailed to get question list, you can ticket an issue [ here\n](https://github.com/ros-infrastructure/rosindex/issues/new)\n\n[ API Docs ](http://docs.ros.org/en/foxy/p/nav2_bringup \"View API\ndocumentation on docs.ros.org\") [ Browse Code ](https://github.com/ros-\nplanning/navigation2/tree/foxy-devel/nav2_bringup/bringup \"View source code on\nrepository\")\n\nNo version for distro **lunar** . Known supported distros are highlighted in\nthe buttons above.\n\nNo version for distro **jade** . Known supported distros are highlighted in\nthe buttons above.\n\n![](/assets/package.png) |\n\n###  [ nav2_bringup ](/p/nav2_bringup) package from [ nav2_platform\n](/r/nav2_platform/github-paulbovbel-nav2_platform) repo\n\nnav2_bringup  [ nav2_driver ](/p/nav2_driver/github-paulbovbel-nav2_platform)\n[ nav2_navigation ](/p/nav2_navigation/github-paulbovbel-nav2_platform) [\nnav2_platform ](/p/nav2_platform/github-paulbovbel-nav2_platform)  \n---|---  \n  \ngithub-paulbovbel-nav2_platform\n\n  * [ github-paulbovbel-nav2_platform ](/p/nav2_bringup/github-paulbovbel-nav2_platform)\n  * [ github-ros-planning-navigation2 ](/p/nav2_bringup/github-ros-planning-navigation2)\n\n  \n  \n---  \n  \n[  \nAPI Docs ](http://docs.ros.org/en/indigo/api/nav2_bringup/html/ \"View API\ndocumentation on docs.ros.org\") [  \nBrowse Code ](https://github.com/paulbovbel/nav2_platform/tree/hydro-\ndevel/nav2_bringup \"View source code on repository\")\n\n  * Overview \n  * 3  Assets \n  * 5  Dependencies \n  * 0  Tutorials \n  * 0  Q & A \n\n####  Package Summary\n\n**Tags** |  _No category tags._  \n---|---  \n**Version** |  0.0.7  \n**License** |  GPLv3  \n**Build type** |  CATKIN  \n**Use** |  RECOMMENDED  \n  \n###  Repository Summary\n\n**Checkout URI** |  [ https://github.com/paulbovbel/nav2_platform.git\n](https://github.com/paulbovbel/nav2_platform.git)  \n---|---  \n**VCS Type** |  git  \n**VCS Version** |  hydro-devel  \n**Last Updated**  \n  \n2014-09-13  |  **Dev Status** |  MAINTAINED  \n**CI status** |  [ Continuous Integration\n](http://build.ros.org/view/Idev/job/Idev__nav2_platform__ubuntu_trusty_amd64\n\"Latest build information: Sun, 09 Jun 2019 03:23:12 GMT\n\nNo test statistics available for this package.\")  \n**Released** |  RELEASED  \n**Tags** |  _No category tags._  \n**Contributing** |  [ Help Wanted (  0  ) ](/r/nav2_platform/#indigo-\ncontribute-lists-help-wanted)  \n[ Good First Issues (  0  ) ](/r/nav2_platform/#indigo-contribute-lists-good-\nfirst-issue)  \n[ Pull Requests to Review (  0  ) ](/r/nav2_platform/#indigo-contribute-lists-\npull-requests)  \n  \n###  Package Description\n\nROS launch files for Nav2 Robot Platform bringup\n\n####  Additional Links\n\n_No additional links._\n\n####  Maintainers\n\n  * Paul Bovbel \n\n####  Authors\n\n  * Paul Bovbel \n\nREADME\n\n_No README found._ _[ See repository README. ](/r/nav2_platform/github-\npaulbovbel-nav2_platform/#indigo) _\n\nCHANGELOG\n\n#  Changelog for package nav2_bringup\n\n##  0.0.7 (2014-09-13)\n\n##  0.0.5 (2014-04-17)\n\n  * fix dependencies and building \n  * Contributors: Paul Bovbel \n\n##  0.0.4 (2014-04-16)\n\n  * fix dependencies \n  * Contributors: Paul Bovbel \n\n##  0.0.3 (2014-04-16)\n\n##  0.0.2 (2014-04-16)\n\n  * fix dependencies in nav2_bringup \n  * Contributors: Paul Bovbel \n\n##  0.0.1 (2014-04-15)\n\n  * add port argument \n  * refactor launch structure \n  * initial commit for support packages \n  * Contributors: Paul Bovbel \n\n###  Wiki Tutorials\n\n_See[ ROS Wiki Tutorials ](http://wiki.ros.org/nav2_bringup/Tutorials) for\nmore details. _\n\n###  Source Tutorials\n\n_Not currently indexed._\n\n###  Package Dependencies\n\nDeps  |  |  Name  |  [ ](/p/nav2_driver#indigo-deps) |  [ 1\n](/packages/nav2_driver) |  [ nav2_driver ](/p/nav2_driver#indigo)  \n---|---|---  \n[ ](/p/nav2_navigation#indigo-deps) |  [ 1 ](/packages/nav2_navigation) |  [\nnav2_navigation ](/p/nav2_navigation#indigo)  \n[ ](/p/catkin#indigo-deps) |  [ 1 ](/packages/catkin) |  [ catkin\n](/p/catkin#indigo)  \n[ ](/p/hokuyo_node#indigo-deps) |  [ 1 ](/packages/hokuyo_node) |  [\nhokuyo_node ](/p/hokuyo_node#indigo)  \n[ ](/p/depthimage_to_laserscan#indigo-deps) |  [ 2\n](/packages/depthimage_to_laserscan) |  [ depthimage_to_laserscan\n](/p/depthimage_to_laserscan#indigo)  \n  \n###  System Dependencies\n\n_No direct system dependencies._\n\n###  Dependant Packages\n\nName  |  Repo  |  Deps  |  [ nav2_platform ](/p/nav2_platform/github-\npaulbovbel-nav2_platform#indigo) |  [ github-paulbovbel-nav2_platform\n](/r/nav2_platform/github-paulbovbel-nav2_platform) |  [\n](/p/nav2_platform/github-paulbovbel-nav2_platform#indigo-deps)  \n---|---|---  \n  \n###  Launch files\n\n  * [ launch/nav2_amcl.launch ](https://github.com/paulbovbel/nav2_platform/tree/hydro-devel/nav2_bringup/launch/nav2_amcl.launch)\n    * __\n    *       * **map_path**\n      * **use_external_map** _[default: true]_\n  * [ launch/nav2_gmapping.launch ](https://github.com/paulbovbel/nav2_platform/tree/hydro-devel/nav2_bringup/launch/nav2_gmapping.launch)\n    * __\n    *       * **use_external_map** _[default: true]_\n  * [ launch/nav2_robot.launch ](https://github.com/paulbovbel/nav2_platform/tree/hydro-devel/nav2_bringup/launch/nav2_robot.launch)\n    * __\n    *       * **use_external_map** _[default: false]_\n      * **robot_address**\n      * **robot_port** _[default: 5010]_\n      * **use_external_map** _[default: $(arg use_external_map)]_\n\n###  Messages\n\n_No message files found._\n\n###  Services\n\n_No service files found_\n\n###  Plugins\n\n_No plugins found._\n\n###  Recent questions tagged ` nav2_bringup ` at **[ Robotics Stack Exchange\n](https://robotics.stackexchange.com/) **\n\nNo questions yet, you can ask one [ here\n](https://robotics.stackexchange.com/questions/tagged/nav2_bringup+indigo) .\n\nFailed to get question list, you can ticket an issue [ here\n](https://github.com/ros-infrastructure/rosindex/issues/new)\n\n[ API Docs ](http://docs.ros.org/en/indigo/api/nav2_bringup/html/ \"View API\ndocumentation on docs.ros.org\") [ Browse Code\n](https://github.com/paulbovbel/nav2_platform/tree/hydro-devel/nav2_bringup\n\"View source code on repository\")\n\n![](/assets/package.png) |\n\n###  [ nav2_bringup ](/p/nav2_bringup) package from [ nav2_platform\n](/r/nav2_platform/github-paulbovbel-nav2_platform) repo\n\nnav2_bringup  [ nav2_driver ](/p/nav2_driver/github-paulbovbel-nav2_platform)\n[ nav2_navigation ](/p/nav2_navigation/github-paulbovbel-nav2_platform) [\nnav2_platform ](/p/nav2_platform/github-paulbovbel-nav2_platform)  \n---|---  \n  \ngithub-paulbovbel-nav2_platform\n\n  * [ github-paulbovbel-nav2_platform ](/p/nav2_bringup/github-paulbovbel-nav2_platform)\n  * [ github-ros-planning-navigation2 ](/p/nav2_bringup/github-ros-planning-navigation2)\n\n  \n  \n---  \n  \n[  \nAPI Docs ](http://docs.ros.org/en/hydro/api/nav2_bringup/html/ \"View API\ndocumentation on docs.ros.org\") [  \nBrowse Code ](https://github.com/paulbovbel/nav2_platform/tree/hydro-\ndevel/nav2_bringup \"View source code on repository\")\n\n  * Overview \n  * 3  Assets \n  * 5  Dependencies \n  * 0  Tutorials \n  * 0  Q & A \n\n####  Package Summary\n\n**Tags** |  _No category tags._  \n---|---  \n**Version** |  0.0.7  \n**License** |  GPLv3  \n**Build type** |  CATKIN  \n**Use** |  RECOMMENDED  \n  \n###  Repository Summary\n\n**Checkout URI** |  [ https://github.com/paulbovbel/nav2_platform.git\n](https://github.com/paulbovbel/nav2_platform.git)  \n---|---  \n**VCS Type** |  git  \n**VCS Version** |  hydro-devel  \n**Last Updated**  \n  \n2014-09-13  |  **Dev Status** |  MAINTAINED  \n**CI status** |  [ Continuous Integration ](devel-hydro-nav2_platform \"Latest\nbuild information: Fri, 28 Aug 2015 11:45:28 GMT\n\nNo test statistics available for this package.\")  \n**Released** |  RELEASED  \n**Tags** |  _No category tags._  \n**Contributing** |  [ Help Wanted (  0  ) ](/r/nav2_platform/#hydro-\ncontribute-lists-help-wanted)  \n[ Good First Issues (  0  ) ](/r/nav2_platform/#hydro-contribute-lists-good-\nfirst-issue)  \n[ Pull Requests to Review (  0  ) ](/r/nav2_platform/#hydro-contribute-lists-\npull-requests)  \n  \n###  Package Description\n\nROS launch files for Nav2 Robot Platform bringup\n\n####  Additional Links\n\n_No additional links._\n\n####  Maintainers\n\n  * Paul Bovbel \n\n####  Authors\n\n  * Paul Bovbel \n\nREADME\n\n_No README found._ _[ See repository README. ](/r/nav2_platform/github-\npaulbovbel-nav2_platform/#hydro) _\n\nCHANGELOG\n\n#  Changelog for package nav2_bringup\n\n##  0.0.7 (2014-09-13)\n\n##  0.0.5 (2014-04-17)\n\n  * fix dependencies and building \n  * Contributors: Paul Bovbel \n\n##  0.0.4 (2014-04-16)\n\n  * fix dependencies \n  * Contributors: Paul Bovbel \n\n##  0.0.3 (2014-04-16)\n\n##  0.0.2 (2014-04-16)\n\n  * fix dependencies in nav2_bringup \n  * Contributors: Paul Bovbel \n\n##  0.0.1 (2014-04-15)\n\n  * add port argument \n  * refactor launch structure \n  * initial commit for support packages \n  * Contributors: Paul Bovbel \n\n###  Wiki Tutorials\n\n_See[ ROS Wiki Tutorials ](http://wiki.ros.org/nav2_bringup/Tutorials) for\nmore details. _\n\n###  Source Tutorials\n\n_Not currently indexed._\n\n###  Package Dependencies\n\nDeps  |  |  Name  |  [ ](/p/nav2_driver#hydro-deps) |  [ 1\n](/packages/nav2_driver) |  [ nav2_driver ](/p/nav2_driver#hydro)  \n---|---|---  \n[ ](/p/nav2_navigation#hydro-deps) |  [ 1 ](/packages/nav2_navigation) |  [\nnav2_navigation ](/p/nav2_navigation#hydro)  \n[ ](/p/catkin#hydro-deps) |  [ 1 ](/packages/catkin) |  [ catkin\n](/p/catkin#hydro)  \n[ ](/p/hokuyo_node#hydro-deps) |  [ 1 ](/packages/hokuyo_node) |  [\nhokuyo_node ](/p/hokuyo_node#hydro)  \n[ ](/p/depthimage_to_laserscan#hydro-deps) |  [ 2\n](/packages/depthimage_to_laserscan) |  [ depthimage_to_laserscan\n](/p/depthimage_to_laserscan#hydro)  \n  \n###  System Dependencies\n\n_No direct system dependencies._\n\n###  Dependant Packages\n\nName  |  Repo  |  Deps  |  [ nav2_platform ](/p/nav2_platform/github-\npaulbovbel-nav2_platform#hydro) |  [ github-paulbovbel-nav2_platform\n](/r/nav2_platform/github-paulbovbel-nav2_platform) |  [\n](/p/nav2_platform/github-paulbovbel-nav2_platform#hydro-deps)  \n---|---|---  \n  \n###  Launch files\n\n  * [ launch/nav2_amcl.launch ](https://github.com/paulbovbel/nav2_platform/tree/hydro-devel/nav2_bringup/launch/nav2_amcl.launch)\n    * __\n    *       * **map_path**\n      * **use_external_map** _[default: true]_\n  * [ launch/nav2_gmapping.launch ](https://github.com/paulbovbel/nav2_platform/tree/hydro-devel/nav2_bringup/launch/nav2_gmapping.launch)\n    * __\n    *       * **use_external_map** _[default: true]_\n  * [ launch/nav2_robot.launch ](https://github.com/paulbovbel/nav2_platform/tree/hydro-devel/nav2_bringup/launch/nav2_robot.launch)\n    * __\n    *       * **use_external_map** _[default: false]_\n      * **robot_address**\n      * **robot_port** _[default: 5010]_\n      * **use_external_map** _[default: $(arg use_external_map)]_\n\n###  Messages\n\n_No message files found._\n\n###  Services\n\n_No service files found_\n\n###  Plugins\n\n_No plugins found._\n\n###  Recent questions tagged ` nav2_bringup ` at **[ Robotics Stack Exchange\n](https://robotics.stackexchange.com/) **\n\nNo questions yet, you can ask one [ here\n](https://robotics.stackexchange.com/questions/tagged/nav2_bringup+hydro) .\n\nFailed to get question list, you can ticket an issue [ here\n](https://github.com/ros-infrastructure/rosindex/issues/new)\n\n[ API Docs ](http://docs.ros.org/en/hydro/api/nav2_bringup/html/ \"View API\ndocumentation on docs.ros.org\") [ Browse Code\n](https://github.com/paulbovbel/nav2_platform/tree/hydro-devel/nav2_bringup\n\"View source code on repository\")\n\nNo version for distro **kinetic** . Known supported distros are highlighted in\nthe buttons above.\n\nNo version for distro **melodic** . Known supported distros are highlighted in\nthe buttons above.\n\n[ ros-infrastructure/rosindex  ](https://github.com/ros-\ninfrastructure/rosindex \"Find rosindex in Github\") | _generated on 2024-04-16_\n\na community-maintained index of robotics software | [ privacy ](/privacy.txt)\n\n"
  },
  {
    "id": "galactic/buildsystem.txt",
    "content": "Toggle navigation  [ ![Logo](/img/logonav.png) micro-ROS ](/)\n\n  * [ Overview ](/docs/overview/)\n  * [ Concepts ](/docs/concepts/)\n  * [ Tutorials ](/docs/tutorials/)\n  * [ API ](/docs/api/)\n  * [ Blog ](/blog/2023/02/06/micro-ROS-book-chapter/)\n\n  *   * [ ](https://github.com/micro-ROS/micro-ros.github.io)\n\n####  Client Library\n\n[ Introduction to Client Library\n](/docs/concepts/client_library/introduction/) [ Feature List\n](/docs/concepts/client_library/features/) [ Execution Management\n](/docs/concepts/client_library/execution_management/) [ Lifecycle and System\nModes ](/docs/concepts/client_library/lifecycle_and_system_modes/) [\nDiagnostics ](/docs/concepts/client_library/diagnostics/)\n\n####  Middleware\n\n[ Micro XRCE-DDS ](/docs/concepts/middleware/Micro_XRCE-DDS/) [ Micro XRCE-DDS\nmemory profiling ](/docs/concepts/middleware/memo_prof/) [ Micro XRCE-DDS\ncompared to rosserial ](/docs/concepts/middleware/rosserial/) [ DDS-XRCE, MQTT\n& IoT ](/docs/concepts/middleware/IoT/)\n\n####  RTOSes\n\n[ Why a Real-Time Operating System? ](/docs/concepts/rtos/) [ Comparison\nbetween RTOSes ](/docs/concepts/rtos/comparison/)\n\n####  Build System\n\n[ micro-ROS Build System ](/docs/concepts/build_system/) [ External Build\nSystems ](/docs/concepts/build_system/external_build_systems/)\n\n####  Benchmarking\n\n[ Concepts ](/docs/concepts/benchmarking/concept/) [ Results\n](/docs/concepts/benchmarking/results/) [ Memory profiling\n](/docs/concepts/benchmarking/memo_prof/)\n\n####  Interoperability with FIWARE\n\n[ Interoperability with FIWARE ](/docs/concepts/fiware_interoperability/)\n\n#  micro-ROS Build System\n\nmicro-ROS provides two ways of building a micro-ROS application for embedded\nplatforms:\n\n  * _micro_ros_setup:_ integrates and hides the RTOS-specific build tools in few scripts provided as a ROS 2 package. \n  * _Platform-specific integrations:_ We have integrated micro-ROS with several platforms build tools. Click [ here ](/docs/concepts/build_system/external_build_systems/) to learn more. \n\n**micro_ros_setup** provides a standalone build system in the form of a ROS 2\npackage for use in any normal ROS 2 workspace. This tool is available in the [\nmicro-ROS/micro_ros_setup ](https://github.com/micro-ROS/micro_ros_setup)\nrepository.\n\nThe **micro_ros_setup** tool allows compiling and generating images that\ncontain micro-ROS apps for the [ supported hardware\n](/docs/overview/hardware/) boards and [ RTOSes ](/docs/concepts/rtos/) .\n\nAs the **micro_ros_setup** package can be installed like any other ROS 2\npackage, its usage will be through the ROS 2 CLI tool. Compiling, generating\nan image and flashing it on a board can be done just with four ROS 2 commands.\nA detailed description about the usage of this package can be found in the [\ntutorial section ](/docs/tutorials/core/first_application_rtos/) .\n\n###  micro-ROS client\n\nOnce installed, the build system tool provides some utilities that can be used\nin order to prepare, build, flash and use a micro-ROS application. The micro-\nROS build system is a four-step procedure. In the first step, the user can\ncreate a new micro-ROS application by configuring the target hardware and\nRTOS:\n\n    \n    \n    # Create step\n    ros2 run micro_ros_setup create_firmware_ws.sh [RTOS] [HARDWARE BOARD]\n    \n\nIt is possible to obtain a list of the supported hardware by running the\ncommand without any argument. By doing so, it is possible to see that along\nwith the RTOSes and hardware supported by micro-ROS this build system also\nprovides with three extra options:\n\n  * By using ` zephyr ` as RTOS and ` host ` as hardware name, it is possible to obtain a Zephyr RTOS image with your micro-ROS app that runs in your host computer. \n  * By using just ` host ` as RTOS, micro-ROS will build a set of [ micro-ROS demo applications ](https://github.com/micro-ROS/micro-ROS-demos) natively in your host machine. These applications behave just like micro-ROS apps (using the same abstraction layers and middleware implementation) and allow the user to debug and test the applications on a PC. \n  * By using ` generate_lib ` as RTOS it is possible to configure the build system for generating static libraries ( ` .a ` ) and a set of headers ( ` include ` ) that can be linked in any other external tool. This option requires a valid CMake toolchain. \n\nOnce the build system has created the new firmware project, it is possible to\nconfigure it using:\n\n    \n    \n    # Configure step\n    ros2 run micro_ros_setup configure_firmware.sh [APP] [OPTIONS]\n    \n\nBy running this command without any argument, it will output a list of example\napplications valid for the selected RTOS. Common options available at this\nconfiguration step are:\n\n  * ` --transport ` or ` -t ` : ` udp ` , ` serial ` or any hardware specific transport label \n  * ` --dev ` or ` -d ` : agent string descriptor in a serial-like transport \n  * ` --ip ` or ` -i ` : agent IP in a network-like transport \n  * ` --port ` or ` -p ` : agent port in a network-like transport \n\nFinally, it is possible to build and flash a micro-ROS app using:\n\n    \n    \n    # Build step\n    ros2 run micro_ros_setup build_firmware.sh\n    \n    # Flash step\n    ros2 run micro_ros_setup flash_firmware.sh\n    \n\n###  micro-ROS agent\n\nThe micro-ROS build system is also able to ease the compilation of the micro-\nROS Agent in a ROS 2 workspace by using these commands:\n\n    \n    \n    # Download micro-ROS-Agent packages\n    ros2 run micro_ros_setup create_agent_ws.sh\n    ros2 run micro_ros_setup build_agent.sh\n    source install/local_setup.bash\n    ros2 run micro_ros_agent micro_ros_agent [OPTIONS]\n    \n\n**Tip 1:** To learn use of the micro_ros_setup build system hands-on, please\nsee the [ core tutorials ](https://micro-\nros.github.io/docs/tutorials/core/first_application_rtos/) .\n\n**Tip 2 :** Remember that the micro-ROS Agent can be also be used with this\nsimple Docker command: ` docker run -it --rm -v /dev:/dev --privileged\n--net=host microros/micro-ros-agent:$ROS_DISTRO [OPTIONS] `\n\n  \n[ __ Improve this page ](https://github.com/micro-ROS/micro-\nros.github.io/blob/master/_docs/concepts/build_system/index.md)\n\n* * *\n\n  * [ \u2190  Previous ](/docs/concepts/rtos/comparison/)\n  * [ Next  \u2192  ](/docs/concepts/build_system/external_build_systems/)\n\nmicro-ROS 2024 | [ ![Creative Commons\nLicense](https://i.creativecommons.org/l/by-nd/4.0/80x15.png)\n](http://creativecommons.org/licenses/by-nd/4.0/) | Powered by [ Jekyll Doc\nTheme ](https://github.com/aksakalli/jekyll-doc-theme) | [ privacy ](/privacy)\n| [ imprint ](/docs/imprint)\n\nWe would like to use third party cookies and scripts to improve the\nfunctionality of this website.  Approve  [ More info ](/privacy)\n\n"
  },
  {
    "id": "arduino/howi2ccommunicationw.txt",
    "content": "Skip to content\n\n[ ![How To Mechatronics](https://howtomechatronics.com/wp-\ncontent/uploads/2021/09/Logo-2021.png) ](https://howtomechatronics.com/ \"How\nTo Mechatronics\")\n\n[ ![How To Mechatronics](https://howtomechatronics.com/wp-\ncontent/uploads/2021/09/Logo-2021.png) ](https://howtomechatronics.com/ \"How\nTo Mechatronics\")\n\nMenu\n\n  * [ Arduino Projects ](https://howtomechatronics.com/arduino-projects/)\n  * [ Tutorials ](https://howtomechatronics.com/category/tutorials/)\n  * [ How It Works ](https://howtomechatronics.com/category/how-it-works/)\n  * [ Projects ](https://howtomechatronics.com/category/projects/)\n  * [ Tools ](https://howtomechatronics.com/category/tools/)\n\n#  How I2C Communication Works? Arduino and I2C Tutorial\n\n![Photo of\nauthor](https://secure.gravatar.com/avatar/621eecb9a8464312efcb89cab61e974d?s=30&r=g)\n\nby [ Dejan ](https://howtomechatronics.com/author/howtom12_wp/)\n\n**\u2022**\n\n**\u2022**\n\n[ Arduino Tutorials\n](https://howtomechatronics.com/category/tutorials/arduino/)\n\nIn this tutorial we will learn how the I2C communication protocol works and\nalso we will make a practical example of it with the Arduino Board and a\nsensor which uses this protocol. You can watch the following video or read the\nwritten tutorial below.\n\n##  Overview\n\nThe I2C communication bus is very popular and broadly used by many electronic\ndevices because it can be easily implemented in many electronic designs which\nrequire communication between a master and multiple slave devices or even\nmultiple master devices. The easy implementations comes with the fact that\nonly two wires are required for communication between up to almost 128 (112)\ndevices when using 7 bits addressing and up to almost 1024 (1008) devices when\nusing 10 bits addressing.\n\n![I2C-Communication-Overview1](https://howtomechatronics.com/wp-\ncontent/uploads/2015/10/I2C-Communication-Overview1.png)\n\n##  How I2C Works\n\nHow is it possible, a communication between so many devices with just to\nwires? Well each device has a preset ID or a unique device address so the\nmaster can choose with which devices will be communicating.\n\nThe two wires, or lines are called Serial Clock (or SCL) and Serial Data (or\nSDA). The SCL line is the clock signal which synchronize the data transfer\nbetween the devices on the I2C bus and it\u2019s generated by the master device.\nThe other line is the SDA line which carries the data.\n\nThe two lines are \u201copen-drain\u201d which means that pull up resistors needs to be\nattached to them so that the lines are high because the devices on the I2C bus\nare active low. Commonly used values for the resistors are from 2K for higher\nspeeds at about 400 kbps, to 10K for lower speed at about 100 kbps.\n\n![I2C-Communication--How-It-Works](https://howtomechatronics.com/wp-\ncontent/uploads/2015/10/I2C-Communication-How-It-Works.png)\n\n##  I2C Protocol\n\n![I2C-Communcation-Protocol](https://howtomechatronics.com/wp-\ncontent/uploads/2015/10/I2C-Communcation-Protocol.jpg)\n\nThe data signal is transferred in sequences of 8 bits. So after a special\nstart condition occurs comes the first 8 bits sequence which indicates the\naddress of the slave to which the data is being sent. After each 8 bits\nsequence follows a bit called Acknowledge. After the first Acknowledge bit in\nmost cases comes another addressing sequence but this time for the internal\nregisters of the slave device. Right after the addressing sequences follows\nthe data sequences as many until the data is completely sent and it ends with\na special stop condition.  \n\nLet\u2019s take even closer look at these events. The start condition occurs when\ndata line drops low while the clock line is still high. After this the clock\nstarts and each data bit is transferred during each clock pulse.\n\nThe device addressing sequence stars with the most significant bit (MSB) first\nand ends with the least significant bit (LSB) and it\u2019s actually composed of 7\nbits because the 8  th  bit is used for indicating whether the master will\nwrite to the slave (logic low) or read from it (logic high).\n\n![I2C-Bits-Protocol](https://howtomechatronics.com/wp-\ncontent/uploads/2015/10/I2C-Bits-Protocol.jpg)\n\nThe next bit AKC/ NACK is used by the slave device to indicate whether it has\nsuccessfully received the previous sequence of bits. So at this time the\nmaster device hands the control of the SDA line over to the slave device and\nif the slave device has successfully received the previous sequence it will\npull the SDA line down to the condition called Acknowledge. If the slave does\nnot pull the SDA line down, the condition is called Not Acknowledge, and means\nthat it didn\u2019t successfully received the previous sequence which can be caused\nby several reasons. For example, the slave might be busy, might not understand\nthe received data or command, cannot receive any more data and so on. In such\na case the master device decides how it will proceed.\n\n![I2C-Bits-Protocol_ADXL-X-Axis-Example](https://howtomechatronics.com/wp-\ncontent/uploads/2015/10/I2C-Bits-Protocol_ADXL-X-Axis-Example.jpg)\n\nNext is the internal registers addressing. The internal registers are\nlocations in the slave\u2019s memory containing various information or data. For\nexample the ADX345 Accelerometer has a unique device address and addition\ninternal registers addresses for the X, Y and Z axis. So if we want to read\nthe data of the X-axis, first we need to send the device address and then the\nparticular internal register address for the X-axis. These addresses can be\nfound from [ datasheet of the sensor\n](https://www.analog.com/media/en/technical-documentation/data-\nsheets/ADXL345.pdf) .\n\nAfter the addressing, the data transfer sequences begin either from the master\nor the slave depending of the selected mode at the R/W bit. After the data is\ncompletely sent, the transfer will end with a stop condition which occurs when\nthe SDA line goes from low to high while the SCL line is high.\n\n##  Example\n\nAs an example I will use the GY-80 breakout board which consists 5 different\nsensors and the GY-521 breakout board which consists 3 different sensors. So\nwe can get data from 8 different sensors with just two wires with the I2C bus.\n\n![GY---80-and-GY---521-Addresses](https://howtomechatronics.com/wp-\ncontent/uploads/2015/10/GY-80-and-GY-521-Addresses.png)\n\nYou can get these components from any of the sites below:\n\n  * ADXL345 3-Axis Accelerator\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 **[ Amazon ](https://howtomechatronics.com/recommends/adxl345-amazon/ \"ADXL345 - Amazon\") / [ Banggood ](https://howtomechatronics.com/recommends/adxl345-banggood/ \"ADXL345 - Banggood\") / [ AliExpress ](https://howtomechatronics.com/recommends/adxl345-aliexpress/ \"ADXL345 \u2013 Aliexpress\") **\n  * 2 in 1: MPU6050 6-Axis Gyroscope & Accelerometer \u2026\u2026\u2026\u2026\u2026\u2026\u2026 **[ Amazon ](https://howtomechatronics.com/recommends/mpu6050-amazon/ \"MPU6050 - Amazon\") / [ Banggood ](https://howtomechatronics.com/recommends/mpu6050-banggood/ \"MPU6050 - Banggood\") / [ AliExpress ](https://howtomechatronics.com/recommends/mpu6050-aliexpress/ \"MPU6050 \u2013 Aliexpress\") **\n  * 3 in 1: GY-80 9-Axis Magnetic Field Acceleration Gyroscope\u2026\u2026\u2026 **[ Amazon ](https://howtomechatronics.com/recommends/gy-80-9-axis-magnetic-field-acceleration-gyroscope-amazon/ \"GY-80 9-Axis Magnetic Field Acceleration Gyroscope - Amazon\") **\n  * 3 in 1: GY-86 10DOF MS5611 HMC5883L MPU6050 Module\u2026\u2026\u2026 [ **Banggood** ](https://howtomechatronics.com/recommends/gy-86-10dof-ms5611-hmc5883l-mpu6050-banggood/ \"GY-86 10DOF MS5611 HMC5883L MPU6050 - Banggood\") **/[ AliExpress ](https://howtomechatronics.com/recommends/gy-86-10dof-ms5611-hmc5883l-mpu6050-aliexpress/ \"GY-86 10DOF MS5611 HMC5883L MPU6050 \u2013 Aliexpress\") **\n\n_Disclosure: These are affiliate links. As an Amazon Associate I earn from\nqualifying purchases._\n\nHere\u2019s how we will connect the boards. The Serial Clock pin of the Arduino\nBoard will be connected to the Serial Clock pins of the two breakout boards,\nthe same goes for the Serial Data pins and we will power the boards with the\nGnd and the 5V pin from the Arduino Board. Note here we are not using pull-up\nresistors because the breakout boards already have.\n\n![I2C-and-Arduino-Circuit-Schematics](https://howtomechatronics.com/wp-\ncontent/uploads/2015/10/I2C-and-Arduino-Circuit-Schematics.png)\n\nNow in order to communicate with these chips or sensors we need to know their\nunique addresses. We can find them from the datasheets of the sensors. For the\nGY-80 breakout board we have the following 4 addresses: a hexadecimal 0x53 for\nthe 3 Axis Accelerometer sensor, a hexadecimal 0x69 for the 3 Axis Gyro, a\nhexadecimal 0x1E for the 3 Axis Magnetometer and a hexadecimal 0x77 for the\nBarometer and Thermometer sensor.\n\n![](https://howtomechatronics.com/wp-content/uploads/2019/04/Arduino-and-\nMPU6050-Accelerometer-and-Gyroscope-Tutorial-300x169.jpg)\n\nSee Also  \n**[ Arduino and MPU6050 Accelerometer and Gyroscope Tutorial\n](https://howtomechatronics.com/tutorials/arduino/arduino-and-\nmpu6050-accelerometer-and-gyroscope-tutorial/) **\n\nFor the GY-521 breakout board we have only one address and that\u2019s a\nhexadecimal 0x68. We can also get or check the addresses using the Arduino I2C\nScanner sketch which can be found from the Arduino official website. So here\nif we upload and run that sketch, we will get the addresses of the connected\ndevices on the I2C bus.\n\n* * *\n\nSensor Part Number I2C Address\n\n3 Axis Accelerometer Analog Devices ADXL345 0x53 [ Datasheet\n](https://www.analog.com/media/en/technical-documentation/data-\nsheets/ADXL345.pdf)\n\n3 Axis GyroST Microelectronics L3G4200D 0x69 [ Datasheet\n](https://www.st.com/st-web-\nui/static/active/en/resource/technical/document/datasheet/CD00265057.pdf)\n\n3 Axis Magnetometer Honeywell MC5883L 0x1E [ Datasheet\n](https://www51.honeywell.com/aero/common/documents/myaerospacecatalog-\ndocuments/Defense_Brochures-documents/HMC5883L_3-Axis_Digital_Compass_IC.pdf)\n\nBarometer + Thermometer Bosch BMP085 0x77 [ Datasheet\n](https://howtomechatronics.com/wp-\ncontent/uploads/2015/10/BMP085_DataSheet_Rev.1.0_01July2008.pdf?6318e9&6318e9)\n\n* * *\n\nAfter we have found the addresses of the devices we also need to find the\naddresses of their internal registers in order to read the data from them. For\nexample if we want to read the data for the X axis from the 3 Axis\nAccelerometer sensor of the GY-80 breakout board, we need to find the internal\nregister address where the data of the X axis is stored. From the datasheet of\nthe sensor, we can see that data for the X axis is actually stored in two\nregisters, DATAX0 with a hexadecimal address 0x32 and DATAX1 with a\nhexadecimal address 0x33.\n\n##  Arduino I2C Code\n\nNow let\u2019s make the code that will get the data for the X axis. So we will use\nthe Arduino Wire Library which has to be include in the sketch. Here first we\nhave to define the sensor address and the two internal registers addresses\nthat we previously found. The _ Wire.begin()  _ function will initiate the\nWire library and also we need to initiate the serial communication because we\nwill use the Serial Monitor to show the data from the sensor.\n\nIn the  _loop()_ we will start with the _ Wire.beginTransmission()  _ function\nwhich will begin the transmission to the particular sensor, the 3 Axis\nAccelerometer in our case. Then with the  _Wire.write()_ function we will ask\nfor the particular data from the two registers of the X axis. The\n_Wire.endTransmission()_ will end the transmission and transmit the data from\nthe registers. Now with the _ Wire.requestFrom()  _ function we will request\nthe transmitted data or the two bytes from the two registers.\n\nThe  _Wire.available()_ function will return the number of bytes available for\nretrieval and if that number match with our requested bytes, in our case 2\nbytes, using the  _Wire.read()_ function we will read the bytes from the two\nregisters of the X axis. At the end we will print the data into the serial\nmonitor. Here\u2019s that data but keep in mind that this is raw data and some math\nis needed to be done in order to get the right values of the X axis. You can\nfind more details for that in my next tutorial for using accelerometers with\nthe Arduino Board because I don\u2019t want to overload this tutorial because its\nmain goal was to explain how the Arduino I2C communication works.\n\n    \n    \n    /*  \n     *  How I2C Communication Protocol Works - Arduino I2C Tutorial\n     *  \n     *   by Dejan, www.HowToMechatronics.com \n     *   \n     */\n    \n    #include <Wire.h>\n    \n    int ADXLAddress = 0x53; // Device address in which is also included the 8th bit for selecting the mode, read in this case.\n    \n    #define X_Axis_Register_DATAX0 0x32 // Hexadecima address for the DATAX0 internal register.\n    #define X_Axis_Register_DATAX1 0x33 // Hexadecima address for the DATAX1 internal register.\n    #define Power_Register 0x2D // Power Control Register\n    \n    int X0,X1,X_out;\n    \n    void setup() {\n      Wire.begin(); // Initiate the Wire library\n      Serial.begin(9600);\n      delay(100);\n      // Enable measurement\n      Wire.beginTransmission(ADXLAddress);\n      Wire.write(Power_Register);\n      // Bit D3 High for measuring enable (0000 1000)\n      Wire.write(8);  \n      Wire.endTransmission();\n    }\n    \n    void loop() {\n      Wire.beginTransmission(ADXLAddress); // Begin transmission to the Sensor \n      //Ask the particular registers for data\n      Wire.write(X_Axis_Register_DATAX0);\n      Wire.write(X_Axis_Register_DATAX1);\n      \n      Wire.endTransmission(); // Ends the transmission and transmits the data from the two registers\n      \n      Wire.requestFrom(ADXLAddress,2); // Request the transmitted two bytes from the two registers\n      \n      if(Wire.available()<=2) {  // \n        X0 = Wire.read(); // Reads the data from the register\n        X1 = Wire.read();   \n      }\n      \n      Serial.print(\"X0= \");\n      Serial.print(X0);\n      Serial.print(\"   X1= \");\n      Serial.println(X1);\n    }Code language: Arduino (arduino)\n\nCategories  [ Arduino Tutorials\n](https://howtomechatronics.com/category/tutorials/arduino/)\n\n[ ](https://howtomechatronics.com/tutorials/arduino/how-pir-sensor-works-and-\nhow-to-use-it-with-arduino/)\n\n[ How PIR Sensor Works and How To Use It with Arduino\n](https://howtomechatronics.com/tutorials/arduino/how-pir-sensor-works-and-\nhow-to-use-it-with-arduino/)\n\n[ What is MEMS? Accelerometer, Gyroscope & Magnetometer with Arduino\n](https://howtomechatronics.com/how-it-works/electrical-engineering/mems-\naccelerometer-gyrocope-magnetometer-arduino/)\n\n[ ](https://howtomechatronics.com/how-it-works/electrical-engineering/mems-\naccelerometer-gyrocope-magnetometer-arduino/)\n\n![Photo of\nauthor](https://secure.gravatar.com/avatar/621eecb9a8464312efcb89cab61e974d?s=100&r=g)\n\nHey I'm Dejan, a maker, a techie and a mechatronics engineer. I love making\nelectronics and robotics projects for you to learn and make something cool on\nyour own.\n\nDon't forget to check my 650K+ subs [ YouTube Channel\n](https://www.youtube.com/channel/UCmkP178NasnhR3TWQyyP4Gw) .\n\n  * [ YouTube  ](https://www.youtube.com/channel/UCmkP178NasnhR3TWQyyP4Gw)\n  * [ Facebook  ](https://www.facebook.com/howtomechatronics)\n  * [ Patreon  ](https://www.patreon.com/howtomechatronics)\n\n**Table of Contents**\n\n1\\.  Overview\n\n2\\.  How I2C Works\n\n3\\.  I2C Protocol\n\n4\\.  Example\n\n5\\.  Arduino I2C Code\n\n[ ![](https://howtomechatronics.com/wp-content/uploads/2022/08/PCBWay-\nbanner-2022.gif) ](https://www.pcbway.com/?from=howtomechatronics01)\n\nMy Tools recommendations\n\n[ ![Best Entry Level Oscilloscopes for Beginners and Hobbyists\n2023](https://howtomechatronics.com/wp-content/uploads/2019/06/Best-Entry-\nLevel-Oscilloscopes-for-Beginners-and-Hobbyists-2019.jpg)\n](https://howtomechatronics.com/tools/best-entry-level-oscilloscopes-for-\nbeginners-and-hobbyists-2019/) [ **Best Budget Oscilloscopes for Beginners and\nMakers** ](https://howtomechatronics.com/tools/best-entry-level-oscilloscopes-\nfor-beginners-and-hobbyists-2019/) [ ![Creality K1 Max Review - The Best 3D\nPrinter](https://howtomechatronics.com/wp-\ncontent/uploads/2024/03/Creality-K1-Max-Review-The-Best-3D-Printer.jpg)\n](https://howtomechatronics.com/tools/reviews/creality-k1-max-review-the-\nperfect-3d-printer/) [ **Creality K1 Max Review \u2013 The Perfect 3D Printer?**\n](https://howtomechatronics.com/tools/reviews/creality-k1-max-review-the-\nperfect-3d-printer/)\n\nMy favorite 3D printer\n\n[ ![](https://howtomechatronics.com/wp-content/uploads/2024/03/Creality-\nEnder-3-ve-se-promo-2-1024x1024.jpg)\n](https://howtomechatronics.com/recommends/creality-ender-3-v3-se-creality-\nstore/)\n\nFeatured Projects\n\n[ ![](https://howtomechatronics.com/wp-content/uploads/2021/08/Laser-\nEngraving-with-DIY-SCARA-Robot-Complete-Guide-1024x576.jpg)\n](https://howtomechatronics.com/projects/laser-engraving-with-diy-arduino-\nscara-robot-complete-guide/)\n\n[ ![DIY Air Quality Monitor - PM2.5, CO2, VOC, Ozone, Temp & Hum Arduino\nMeter](https://howtomechatronics.com/wp-content/uploads/2020/12/DIY-Air-\nQuality-Monitor-PM2.5-CO2-VOC-Ozone-Temp-Hum-Arduino-Meter-1024x576.jpg)\n](https://howtomechatronics.com/projects/diy-air-quality-monitor-\npm2-5-co2-voc-ozone-temp-hum-arduino-meter/)\n\n##  How To Mechatronics\n\nHowToMechatronics is an education website in the area of Mechanical,\nElectrical and Computer Engineering. Tutorials, Tips, Tricks, How It Works,\nProjects, Examples, Source Codes, Download files and much more can be found\nhere.\n\n##  Disclosure\n\nHowToMechatronics is a participant in the Amazon Services LLC Associates\nProgram, an affiliate advertising program designed to provide a means for\nsites to earn advertising fees by advertising and linking to Amazon.com\n\nCopyright \u00a9 2024 HowToMechatronics.com. All rights reserved. [ Terms and\nConditions ](https://howtomechatronics.com/disclaimer/) | [ Privacy Policy\n](https://howtomechatronics.com/privacy-policy-page/)\n\n![Quantcast](//pixel.quantserve.com/pixel/p-31iz6hfFutd16.gif?labels=Domain.howtomechatronics_com,DomainId.301186)\n\n"
  },
  {
    "id": "interface_name/2583.txt",
    "content": "  \nROS Resources: [ ROS Homepage ](http://ros.org/) | [ Media and Trademarks\n](https://www.ros.org/blog/media/) | [ Documentation ](http://docs.ros.org/) |\n[ ROS Index ](https://index.ros.org/) | [ How to Get Help\n](http://wiki.ros.org/Support) | [ Q&A Help Site\n](https://robotics.stackexchange.com/) | [ Discussion Forum\n](http://discourse.ros.org/) | [ Service Status ](http://status.ros.org/)  \n---  \n  \n[ ROS Discourse ](/)\n\n#  [ Naming conventions for ros2 msgs ](/t/naming-conventions-for-\nros2-msgs/2583)\n\n[ Next Generation ROS  ](/c/ng-ros/25)\n\n[ jsquare  ](https://discourse.ros.org/u/jsquare) September 7, 2017, 9:22am  1\n\nHi,\n\nWill it be allowed to put \u2018_\u2019 in the name of a ros2 msg?\n\nIn ros2 wiki it is not defined: [ https://github.com/ros2/ros2/wiki/About-ROS-\nInterfaces ](https://github.com/ros2/ros2/wiki/About-ROS-Interfaces)\n\nIn ros1 wiki it is mentioned to put the name in camelcase and therefore no\nunderscore seems to be allowed: [ http://wiki.ros.org/ROS/Patterns/Conventions\n](http://wiki.ros.org/ROS/Patterns/Conventions) under 2.3 Messages\n\nIs this also the case for ros2?\n\n[ dirk-thomas  ](https://discourse.ros.org/u/dirk-thomas) September 7, 2017,\n3:40pm  2\n\nFor ROS 2 the format of the interface files is specified in [\nhttp://design.ros2.org/articles/interface_definition.html#naming-of-messages-\nand-services\n](http://design.ros2.org/articles/interface_definition.html#naming-of-\nmessages-and-services) . The naming scheme for the filename hasn\u2019t changed\nsince ROS 1 and still only allows alphanumeric characters.\n\n1 Like\n\n[ togaen  ](https://discourse.ros.org/u/togaen) April 9, 2020, 1:03pm  3\n\nI realize this is an old thread, but (I hope) this is related: is there\ndocumentation somewhere about the naming conventions for the generated message\nheaders in ROS 2? The ` .msg ` files are all CamelCase, but the ` .hpp ` file\nnames all seem to be converted to snake_case, which was a bit confusing at\nfirst.\n\n[ christophebedard  ](https://discourse.ros.org/u/christophebedard) April 9,\n2020, 1:35pm  4\n\n[ @dirk-thomas ](/u/dirk-thomas) \u2019s link above mentions\n\n> Both file names must use an upper camel case name and only consist of\n> alphanumeric characters.\n\nSo that\u2019s for ` .msg ` & ` .srv ` files.\n\nAs for snake_case headers, that\u2019s just file naming convention. While it\ndoesn\u2019t explicitly talk about it, the _[ Introduction to msg and srv\ninterfaces ](https://index.ros.org/doc/ros2/Tutorials/Rosidl-Tutorial/) _\ntutorial (although it\u2019s a draft) does use snake_case headers.\n\n[ togaen  ](https://discourse.ros.org/u/togaen) April 9, 2020, 1:41pm  5\n\n[ @christophebedard ](/u/christophebedard) Thanks, yes, I realize that now. My\nconfusion was that, from the tutorial, I thought it just made the file names\nlower case (in the tutorial ` Num.msg ` becomes ` num.hpp ` ). So I had\ndefined a message file like ` Foo3D.msg ` and I tried including it as `\nfoo3D.hpp ` , which didn\u2019t work. I had to use ` foo3_d.hpp ` .\n\n[ BBelmar  ](https://discourse.ros.org/u/BBelmar) May 30, 2022, 4:06pm  6\n\nHey i know it\u2019s an old thread but I\u2019m learning ROS now and I\u2019ve been trying to\nfind info on precisely this.  \nSo what I gather is that the msg and or srv should be named with camel case\nand then it will become an .hpp of the form \"all lowercases and an underscore\nbefore every upercase in the the original camelcase name + .hpp?\n\nThanks for any clarification\n\n[ gbiggs  ](https://discourse.ros.org/u/gbiggs) May 30, 2022, 11:17pm  7\n\nYes, that\u2019s pretty much it.\n\n2 Likes\n\n[ gavanderhoorn  ](https://discourse.ros.org/u/gavanderhoorn) May 31, 2022,\n7:33am  8\n\n![](https://avatars.discourse-cdn.com/v4/letter/b/6f9a4e/48.png) BBelmar:\n\n> \u201call lowercases and an underscore before every upercase in the the original\n> camelcase name + .hpp\u201d\n\nSpecifically, this is called _snake case_ .\n\n![](https://avatars.discourse-cdn.com/v4/letter/b/6f9a4e/48.png) BBelmar:\n\n> the msg and or srv should be named with camel case\n\nIsn\u2019t this _pascal case_ ?\n\nCamel case would start the identifier with a lower-case letter.\n\n[ BBelmar  ](https://discourse.ros.org/u/BBelmar) May 31, 2022, 2:18pm  9\n\nthank you!  \nSo\u2026 if I named a .msg \u201cSensor3DState.msg\u201d what would the .hpp be?  \nsensor3_Dstate.hpp? sensor3_d_state.hpp?  \nOr I should I also never name anything that allows for 2 Caps to be together\u2026\nwhich i guess makes sense.  \nand also\u2026 why does it seem to be an obvious thing? i dont see it mentioned or\nexplained anywhere. Granted im a noob to it all but is like everyone\nunderstands it and is obvious. But I dont see it explained. Is it a C++ thing\nor a ROS thing?\n\nThanks!\n\n[ BBelmar  ](https://discourse.ros.org/u/BBelmar) May 31, 2022, 2:18pm  10\n\nI dont know\u2026 i know i know nothing. ![:confused:](https://emoji.discourse-\ncdn.com/twitter/confused.png?v=12)\n\n[ clalancette  ](https://discourse.ros.org/u/clalancette) May 31, 2022, 3:20pm\n11\n\n![](https://avatars.discourse-cdn.com/v4/letter/b/6f9a4e/48.png) BBelmar:\n\n> So\u2026 if I named a .msg \u201cSensor3DState.msg\u201d what would the .hpp be?  \n>  sensor3_Dstate.hpp? sensor3_d_state.hpp?\n\nI believe it will be the latter: ` sensor3_d_state.hpp ` (though I\u2019m not 100%\nsure of that). Easy enough to test.\n\n![](https://avatars.discourse-cdn.com/v4/letter/b/6f9a4e/48.png) BBelmar:\n\n> and also\u2026 why does it seem to be an obvious thing? i dont see it mentioned\n> or explained anywhere. Granted im a noob to it all but is like everyone\n> understands it and is obvious. But I dont see it explained. Is it a C++\n> thing or a ROS thing?\n\nIt\u2019s a ROS thing. And you are right, I don\u2019t see it anywhere explicitly\nmentioned in the documentation. I guess an obvious place to put it would be in\n[ Interface definition using .msg / .srv / .action files\n](http://design.ros2.org/articles/legacy_interface_definition.html) , though I\ncan see a case for putting it in the documentation on [ ROS 2 Documentation \u2014\nROS 2 Documentation: Rolling documentation ](https://docs.ros.org/en/rolling)\n(which is generated from [ GitHub - ros2/ros2_documentation: ROS 2 docs\nrepository ](https://github.com/ros2/ros2_documentation) ). If you\u2019d be\nwilling to open a PR explaining it, I\u2019d be happy to review.\n\n###  Related Topics\n\nTopic  |  |  Replies  |  Views  |  Activity  \n---|---|---|---|---  \n[ Relaxing ROS2 topic/service field name restrictions\n](https://discourse.ros.org/t/relaxing-ros2-topic-service-field-name-\nrestrictions/6371)\n\n[ Next Generation ROS  ](/c/ng-ros/25)\n\n[ ros2 ](https://discourse.ros.org/tag/ros2)\n\n|  8  |  1376  |  October 16, 2018  \n[ Why did ROS2 keep .msg interface definitions?\n](https://discourse.ros.org/t/why-did-ros2-keep-msg-interface-\ndefinitions/27631)\n\n|  1  |  725  |  October 4, 2022  \n[ Structured metadata for message files\n](https://discourse.ros.org/t/structured-metadata-for-message-files/20965)\n\n[ Next Generation ROS  ](/c/ng-ros/25)\n\n|  2  |  660  |  June 18, 2021  \n[ Use ros message in parameter interface ](https://discourse.ros.org/t/use-\nros-message-in-parameter-interface/31269)\n\n[ Next Generation ROS  ](/c/ng-ros/25)\n\n[ ros2 ](https://discourse.ros.org/tag/ros2)\n\n|  20  |  2086  |  June 20, 2023  \n[ Naming Convention for ROS 2 repositories\n](https://discourse.ros.org/t/naming-convention-for-ros-2-repositories/9838)\n\n[ Next Generation ROS  ](/c/ng-ros/25)\n\n|  6  |  1958  |  June 19, 2020  \n  \n  * [ Home ](/)\n  * [ Categories ](/categories)\n  * [ FAQ/Guidelines ](/guidelines)\n  * [ Terms of Service ](/tos)\n  * [ Privacy Policy ](/privacy)\n\nPowered by [ Discourse ](https://www.discourse.org) , best viewed with\nJavaScript enabled\n\n"
  },
  {
    "id": "robot_stop/usingcollisionmonito.txt",
    "content": "[ Nav2 ![Logo](../../_static/nav2_logo_powered.png) ](../../index.html)\n\nlatest\n\n  * [ Getting Started ](../../getting_started/index.html)\n    * [ Installation ](../../getting_started/index.html#installation)\n    * [ Running the Example ](../../getting_started/index.html#running-the-example)\n    * [ Navigating ](../../getting_started/index.html#navigating)\n  * [ Development Guides ](../../development_guides/index.html)\n    * [ Build and Install ](../../development_guides/build_docs/index.html)\n      * [ Install ](../../development_guides/build_docs/index.html#install)\n      * [ Build ](../../development_guides/build_docs/index.html#build)\n        * [ Released Distribution Binaries ](../../development_guides/build_docs/index.html#released-distribution-binaries)\n        * [ Rolling Development Source ](../../development_guides/build_docs/index.html#rolling-development-source)\n        * [ Docker Container Images ](../../development_guides/build_docs/index.html#docker-container-images)\n      * [ Generate Doxygen ](../../development_guides/build_docs/index.html#generate-doxygen)\n      * [ Help ](../../development_guides/build_docs/index.html#help)\n        * [ Build Troubleshooting Guide ](../../development_guides/build_docs/build_troubleshooting_guide.html)\n    * [ Dev Containers ](../../development_guides/devcontainer_docs/index.html)\n      * [ Dev Container Guide ](../../development_guides/devcontainer_docs/devcontainer_guide.html)\n        * [ Creating Dev Containers ](../../development_guides/devcontainer_docs/devcontainer_guide.html#creating-dev-containers)\n        * [ Using Dev Containers ](../../development_guides/devcontainer_docs/devcontainer_guide.html#using-dev-containers)\n      * [ What, Why, How? ](../../development_guides/devcontainer_docs/index.html#what-why-how)\n        * [ What is a Dev Container? ](../../development_guides/devcontainer_docs/index.html#what-is-a-dev-container)\n        * [ Why use a Dev Container? ](../../development_guides/devcontainer_docs/index.html#why-use-a-dev-container)\n        * [ How do Dev Containers work? ](../../development_guides/devcontainer_docs/index.html#how-do-dev-containers-work)\n      * [ Prerequisites ](../../development_guides/devcontainer_docs/index.html#prerequisites)\n      * [ Getting started ](../../development_guides/devcontainer_docs/index.html#getting-started)\n      * [ Security ](../../development_guides/devcontainer_docs/index.html#security)\n    * [ Getting Involved ](../../development_guides/involvement_docs/index.html)\n      * [ Getting Involved ](../../development_guides/involvement_docs/index.html#id1)\n      * [ Process ](../../development_guides/involvement_docs/index.html#process)\n      * [ Licensing ](../../development_guides/involvement_docs/index.html#licensing)\n      * [ Developer Certification of Origin (DCO) ](../../development_guides/involvement_docs/index.html#developer-certification-of-origin-dco)\n  * [ Navigation Concepts ](../../concepts/index.html)\n    * [ ROS 2 ](../../concepts/index.html#ros-2)\n      * [ Action Server ](../../concepts/index.html#action-server)\n      * [ Lifecycle Nodes and Bond ](../../concepts/index.html#lifecycle-nodes-and-bond)\n    * [ Behavior Trees ](../../concepts/index.html#behavior-trees)\n    * [ Navigation Servers ](../../concepts/index.html#navigation-servers)\n      * [ Planner, Controller, Smoother and Recovery Servers ](../../concepts/index.html#planner-controller-smoother-and-recovery-servers)\n      * [ Planners ](../../concepts/index.html#planners)\n      * [ Controllers ](../../concepts/index.html#controllers)\n      * [ Behaviors ](../../concepts/index.html#behaviors)\n      * [ Smoothers ](../../concepts/index.html#smoothers)\n      * [ Robot Footprints ](../../concepts/index.html#robot-footprints)\n      * [ Waypoint Following ](../../concepts/index.html#waypoint-following)\n    * [ State Estimation ](../../concepts/index.html#state-estimation)\n      * [ Standards ](../../concepts/index.html#standards)\n      * [ Global Positioning: Localization and SLAM ](../../concepts/index.html#global-positioning-localization-and-slam)\n      * [ Odometry ](../../concepts/index.html#odometry)\n    * [ Environmental Representation ](../../concepts/index.html#environmental-representation)\n      * [ Costmaps and Layers ](../../concepts/index.html#costmaps-and-layers)\n      * [ Costmap Filters ](../../concepts/index.html#costmap-filters)\n      * [ Other Forms ](../../concepts/index.html#other-forms)\n    * [ Nav2 Academic Overview ](../../concepts/index.html#nav2-academic-overview)\n  * [ First-Time Robot Setup Guide ](../../setup_guides/index.html)\n    * [ Setting Up Transformations ](../../setup_guides/transformation/setup_transforms.html)\n      * [ Transforms Introduction ](../../setup_guides/transformation/setup_transforms.html#transforms-introduction)\n      * [ Static Transform Publisher Demo ](../../setup_guides/transformation/setup_transforms.html#static-transform-publisher-demo)\n      * [ Transforms in Navigation2 ](../../setup_guides/transformation/setup_transforms.html#transforms-in-navigation2)\n      * [ Conclusion ](../../setup_guides/transformation/setup_transforms.html#conclusion)\n    * [ Setting Up The URDF ](../../setup_guides/urdf/setup_urdf.html)\n      * [ URDF and the Robot State Publisher ](../../setup_guides/urdf/setup_urdf.html#urdf-and-the-robot-state-publisher)\n      * [ Setting Up the Environment ](../../setup_guides/urdf/setup_urdf.html#setting-up-the-environment)\n      * [ Writing the URDF ](../../setup_guides/urdf/setup_urdf.html#writing-the-urdf)\n      * [ Build and Launch ](../../setup_guides/urdf/setup_urdf.html#build-and-launch)\n      * [ Visualization using RVIZ ](../../setup_guides/urdf/setup_urdf.html#visualization-using-rviz)\n      * [ Adding Physical Properties ](../../setup_guides/urdf/setup_urdf.html#adding-physical-properties)\n      * [ Conclusion ](../../setup_guides/urdf/setup_urdf.html#conclusion)\n    * [ Setting Up Odometry ](../../setup_guides/odom/setup_odom.html)\n      * [ Odometry Introduction ](../../setup_guides/odom/setup_odom.html#odometry-introduction)\n      * [ Setting Up Odometry on your Robot ](../../setup_guides/odom/setup_odom.html#setting-up-odometry-on-your-robot)\n      * [ Simulating an Odometry System using Gazebo ](../../setup_guides/odom/setup_odom.html#simulating-an-odometry-system-using-gazebo)\n        * [ Setup and Prerequisites ](../../setup_guides/odom/setup_odom.html#setup-and-prerequisites)\n        * [ Adding Gazebo Plugins to a URDF ](../../setup_guides/odom/setup_odom.html#adding-gazebo-plugins-to-a-urdf)\n        * [ Launch and Build Files ](../../setup_guides/odom/setup_odom.html#launch-and-build-files)\n        * [ Build, Run and Verification ](../../setup_guides/odom/setup_odom.html#build-run-and-verification)\n      * [ Robot Localization Demo ](../../setup_guides/odom/setup_odom.html#robot-localization-demo)\n        * [ Configuring Robot Localization ](../../setup_guides/odom/setup_odom.html#configuring-robot-localization)\n        * [ Launch and Build Files ](../../setup_guides/odom/setup_odom.html#id3)\n        * [ Build, Run and Verification ](../../setup_guides/odom/setup_odom.html#id4)\n      * [ Conclusion ](../../setup_guides/odom/setup_odom.html#conclusion)\n    * [ Setting Up Sensors ](../../setup_guides/sensors/setup_sensors.html)\n      * [ Sensor Introduction ](../../setup_guides/sensors/setup_sensors.html#sensor-introduction)\n        * [ Common Sensor Messages ](../../setup_guides/sensors/setup_sensors.html#common-sensor-messages)\n      * [ Simulating Sensors using Gazebo ](../../setup_guides/sensors/setup_sensors.html#simulating-sensors-using-gazebo)\n        * [ Adding Gazebo Plugins to a URDF ](../../setup_guides/sensors/setup_sensors.html#adding-gazebo-plugins-to-a-urdf)\n        * [ Launch and Build Files ](../../setup_guides/sensors/setup_sensors.html#launch-and-build-files)\n        * [ Build, Run and Verification ](../../setup_guides/sensors/setup_sensors.html#build-run-and-verification)\n      * [ Mapping and Localization ](../../setup_guides/sensors/setup_sensors.html#mapping-and-localization)\n      * [ Costmap 2D ](../../setup_guides/sensors/setup_sensors.html#costmap-2d)\n        * [ Configuring nav2_costmap_2d ](../../setup_guides/sensors/setup_sensors.html#configuring-nav2-costmap-2d)\n        * [ Build, Run and Verification ](../../setup_guides/sensors/setup_sensors.html#id2)\n      * [ Conclusion ](../../setup_guides/sensors/setup_sensors.html#conclusion)\n    * [ Setting Up the Robot\u2019s Footprint ](../../setup_guides/footprint/setup_footprint.html)\n      * [ Footprint Introduction ](../../setup_guides/footprint/setup_footprint.html#footprint-introduction)\n      * [ Configuring the Robot\u2019s Footprint ](../../setup_guides/footprint/setup_footprint.html#configuring-the-robot-s-footprint)\n      * [ Build, Run and Verification ](../../setup_guides/footprint/setup_footprint.html#build-run-and-verification)\n      * [ Visualizing Footprint in RViz ](../../setup_guides/footprint/setup_footprint.html#visualizing-footprint-in-rviz)\n      * [ Conclusion ](../../setup_guides/footprint/setup_footprint.html#conclusion)\n    * [ Setting Up Navigation Plugins ](../../setup_guides/algorithm/select_algorithm.html)\n      * [ Planner and Controller Servers ](../../setup_guides/algorithm/select_algorithm.html#planner-and-controller-servers)\n      * [ Selecting the Algorithm Plugins ](../../setup_guides/algorithm/select_algorithm.html#selecting-the-algorithm-plugins)\n        * [ Planner Server ](../../setup_guides/algorithm/select_algorithm.html#planner-server)\n        * [ Controller Server ](../../setup_guides/algorithm/select_algorithm.html#controller-server)\n      * [ Conclusion ](../../setup_guides/algorithm/select_algorithm.html#conclusion)\n  * [ Robots Using ](../../about/robots.html)\n  * [ General Tutorials ](../index.html)\n    * [ Navigating with a Physical Turtlebot 3 ](navigation2_on_real_turtlebot3.html)\n      * [ Overview ](navigation2_on_real_turtlebot3.html#overview)\n      * [ Requirements ](navigation2_on_real_turtlebot3.html#requirements)\n      * [ Tutorial Steps ](navigation2_on_real_turtlebot3.html#tutorial-steps)\n        * [ 0- Setup Your Enviroment Variables ](navigation2_on_real_turtlebot3.html#setup-your-enviroment-variables)\n        * [ 1- Launch Turtlebot 3 ](navigation2_on_real_turtlebot3.html#launch-turtlebot-3)\n        * [ 2- Launch Nav2 ](navigation2_on_real_turtlebot3.html#launch-nav2)\n        * [ 3- Launch RVIZ ](navigation2_on_real_turtlebot3.html#launch-rviz)\n        * [ 4- Initialize the Location of Turtlebot 3 ](navigation2_on_real_turtlebot3.html#initialize-the-location-of-turtlebot-3)\n        * [ 5- Send a Goal Pose ](navigation2_on_real_turtlebot3.html#send-a-goal-pose)\n    * [ (SLAM) Navigating While Mapping ](navigation2_with_slam.html)\n      * [ Overview ](navigation2_with_slam.html#overview)\n      * [ Requirements ](navigation2_with_slam.html#requirements)\n      * [ Tutorial Steps ](navigation2_with_slam.html#tutorial-steps)\n        * [ 0- Launch Robot Interfaces ](navigation2_with_slam.html#launch-robot-interfaces)\n        * [ 1- Launch Navigation2 ](navigation2_with_slam.html#launch-navigation2)\n        * [ 2- Launch SLAM ](navigation2_with_slam.html#launch-slam)\n        * [ 3- Working with SLAM ](navigation2_with_slam.html#working-with-slam)\n        * [ 4- Getting Started Simplification ](navigation2_with_slam.html#getting-started-simplification)\n    * [ (STVL) Using an External Costmap Plugin ](navigation2_with_stvl.html)\n      * [ Overview ](navigation2_with_stvl.html#overview)\n      * [ Costmap2D and STVL ](navigation2_with_stvl.html#costmap2d-and-stvl)\n      * [ Tutorial Steps ](navigation2_with_stvl.html#tutorial-steps)\n        * [ 0- Setup ](navigation2_with_stvl.html#setup)\n        * [ 1- Install STVL ](navigation2_with_stvl.html#install-stvl)\n        * [ 1- Modify Navigation2 Parameter ](navigation2_with_stvl.html#modify-navigation2-parameter)\n        * [ 2- Launch Navigation2 ](navigation2_with_stvl.html#launch-navigation2)\n        * [ 3- RVIZ ](navigation2_with_stvl.html#rviz)\n    * [ Navigating Using GPS Localization ](navigation2_with_gps.html)\n      * [ Overview ](navigation2_with_gps.html#overview)\n      * [ Requirements ](navigation2_with_gps.html#requirements)\n      * [ GPS Localization Overview ](navigation2_with_gps.html#gps-localization-overview)\n      * [ Tutorial Steps ](navigation2_with_gps.html#tutorial-steps)\n        * [ 0- Setup Gazebo World ](navigation2_with_gps.html#setup-gazebo-world)\n        * [ 1- Setup GPS Localization system ](navigation2_with_gps.html#setup-gps-localization-system)\n        * [ 2- Setup Navigation system ](navigation2_with_gps.html#setup-navigation-system)\n        * [ 3- Interactive GPS Waypoint Follower ](navigation2_with_gps.html#interactive-gps-waypoint-follower)\n        * [ 4- Logged GPS Waypoint Follower & Waypoint Logging ](navigation2_with_gps.html#logged-gps-waypoint-follower-waypoint-logging)\n      * [ Conclusion ](navigation2_with_gps.html#conclusion)\n    * [ Groot - Interacting with Behavior Trees ](using_groot.html)\n      * [ Overview ](using_groot.html#overview)\n      * [ Visualize Behavior Trees ](using_groot.html#visualize-behavior-trees)\n      * [ Edit Behavior Trees ](using_groot.html#edit-behavior-trees)\n      * [ Adding A Custom Node ](using_groot.html#adding-a-custom-node)\n    * [ Using VIO to Augment Robot Odometry ](integrating_vio.html)\n      * [ Overview ](integrating_vio.html#overview)\n      * [ Setting Up the ZED X Camera ](integrating_vio.html#setting-up-the-zed-x-camera)\n      * [ Setting Up ZED ROS ](integrating_vio.html#setting-up-zed-ros)\n      * [ Fusing VIO Into Local State Estimate ](integrating_vio.html#fusing-vio-into-local-state-estimate)\n        * [ Fusing VSLAM Into Global State Estimate ](integrating_vio.html#fusing-vslam-into-global-state-estimate)\n      * [ Testing it Out! ](integrating_vio.html#testing-it-out)\n    * [ Dynamic Object Following ](navigation2_dynamic_point_following.html)\n      * [ Overview ](navigation2_dynamic_point_following.html#overview)\n      * [ Tutorial Steps ](navigation2_dynamic_point_following.html#tutorial-steps)\n        * [ 0- Create the Behavior Tree ](navigation2_dynamic_point_following.html#create-the-behavior-tree)\n        * [ 1- Setup Rviz clicked point ](navigation2_dynamic_point_following.html#setup-rviz-clicked-point)\n        * [ 2- Run Dynamic Object Following in Nav2 Simulation ](navigation2_dynamic_point_following.html#run-dynamic-object-following-in-nav2-simulation)\n    * [ Navigating with Keepout Zones ](navigation2_with_keepout_filter.html)\n      * [ Overview ](navigation2_with_keepout_filter.html#overview)\n      * [ Requirements ](navigation2_with_keepout_filter.html#requirements)\n      * [ Tutorial Steps ](navigation2_with_keepout_filter.html#tutorial-steps)\n        * [ 1\\. Prepare filter mask ](navigation2_with_keepout_filter.html#prepare-filter-mask)\n        * [ 2\\. Configure Costmap Filter Info Publisher Server ](navigation2_with_keepout_filter.html#configure-costmap-filter-info-publisher-server)\n        * [ 3\\. Enable Keepout Filter ](navigation2_with_keepout_filter.html#enable-keepout-filter)\n        * [ 4\\. Run Nav2 stack ](navigation2_with_keepout_filter.html#run-nav2-stack)\n    * [ Navigating with Speed Limits ](navigation2_with_speed_filter.html)\n      * [ Overview ](navigation2_with_speed_filter.html#overview)\n      * [ Requirements ](navigation2_with_speed_filter.html#requirements)\n      * [ Tutorial Steps ](navigation2_with_speed_filter.html#tutorial-steps)\n        * [ 1\\. Prepare filter mask ](navigation2_with_speed_filter.html#prepare-filter-mask)\n        * [ 2\\. Configure Costmap Filter Info Publisher Server ](navigation2_with_speed_filter.html#configure-costmap-filter-info-publisher-server)\n        * [ 3\\. Enable Speed Filter ](navigation2_with_speed_filter.html#enable-speed-filter)\n        * [ 4\\. Run Nav2 stack ](navigation2_with_speed_filter.html#run-nav2-stack)\n    * [ Using Rotation Shim Controller ](using_shim_controller.html)\n      * [ Overview ](using_shim_controller.html#overview)\n      * [ What is the Rotation Shim Controller? ](using_shim_controller.html#what-is-the-rotation-shim-controller)\n      * [ Configuring Rotation Shim Controller ](using_shim_controller.html#configuring-rotation-shim-controller)\n      * [ Configuring Primary Controller ](using_shim_controller.html#configuring-primary-controller)\n      * [ Demo Execution ](using_shim_controller.html#demo-execution)\n    * [ Adding a Smoother to a BT ](adding_smoother.html)\n      * [ Overview ](adding_smoother.html#overview)\n      * [ Requirements ](adding_smoother.html#requirements)\n      * [ Tutorial Steps ](adding_smoother.html#tutorial-steps)\n        * [ 0- Familiarization with the Smoother BT Node ](adding_smoother.html#familiarization-with-the-smoother-bt-node)\n        * [ 1- Specifying a Smoother Plugin ](adding_smoother.html#specifying-a-smoother-plugin)\n        * [ 2- Modifying your BT XML ](adding_smoother.html#modifying-your-bt-xml)\n    * Using Collision Monitor \n      * Overview \n      * Requirements \n      * Configuring Collision Monitor \n      * Configuring Collision Monitor with VelocityPolygon \n      * Preparing Nav2 stack \n      * Demo Execution \n    * [ Adding a New Nav2 Task Server ](adding_a_nav2_task_server.html)\n      * [ Lifecycle Nodes ](adding_a_nav2_task_server.html#lifecycle-nodes)\n      * [ Composition ](adding_a_nav2_task_server.html#composition)\n      * [ Error codes ](adding_a_nav2_task_server.html#error-codes)\n      * [ Conclusion ](adding_a_nav2_task_server.html#conclusion)\n    * [ Filtering of Noise-Induced Obstacles ](filtering_of_noise-induced_obstacles.html)\n      * [ Overview ](filtering_of_noise-induced_obstacles.html#overview)\n      * [ Requirements ](filtering_of_noise-induced_obstacles.html#requirements)\n      * [ Tutorial Steps ](filtering_of_noise-induced_obstacles.html#tutorial-steps)\n        * [ 1\\. Enable Denoise Layer ](filtering_of_noise-induced_obstacles.html#enable-denoise-layer)\n        * [ 2\\. Run Nav2 stack ](filtering_of_noise-induced_obstacles.html#run-nav2-stack)\n      * [ How it works ](filtering_of_noise-induced_obstacles.html#how-it-works)\n    * [ Camera Calibration ](camera_calibration.html)\n      * [ Overview ](camera_calibration.html#overview)\n      * [ Requirements ](camera_calibration.html#requirements)\n      * [ Tutorial Steps ](camera_calibration.html#tutorial-steps)\n    * [ Get Backtrace in ROS 2 / Nav2 ](get_backtrace.html)\n      * [ Overview ](get_backtrace.html#overview)\n      * [ Preliminaries ](get_backtrace.html#preliminaries)\n      * [ From a Node ](get_backtrace.html#from-a-node)\n      * [ From a Launch File ](get_backtrace.html#from-a-launch-file)\n      * [ From Large Project ](get_backtrace.html#from-large-project)\n      * [ From Nav2 Bringup ](get_backtrace.html#from-nav2-bringup)\n      * [ Automatic backtrace on crash ](get_backtrace.html#automatic-backtrace-on-crash)\n    * [ Profiling in ROS 2 / Nav2 ](get_profile.html)\n      * [ Overview ](get_profile.html#overview)\n      * [ Preliminaries ](get_profile.html#preliminaries)\n      * [ Profile from a Node ](get_profile.html#profile-from-a-node)\n      * [ Profile from a Launch File ](get_profile.html#profile-from-a-launch-file)\n      * [ From Nav2 Bringup ](get_profile.html#from-nav2-bringup)\n      * [ Interpreting Results ](get_profile.html#interpreting-results)\n    * [ Docker for Development: Zero to Hero ](docker_dev.html)\n      * [ Overview ](docker_dev.html#overview)\n      * [ Preliminaries ](docker_dev.html#preliminaries)\n      * [ Important Docker Commands ](docker_dev.html#important-docker-commands)\n      * [ Exploring Your First Container ](docker_dev.html#exploring-your-first-container)\n      * [ Understanding ROS Docker Images ](docker_dev.html#understanding-ros-docker-images)\n      * [ For Docker-Based Development ](docker_dev.html#for-docker-based-development)\n        * [ Building a Development Image ](docker_dev.html#building-a-development-image)\n        * [ Visualizations from Docker ](docker_dev.html#visualizations-from-docker)\n      * [ For Docker-Based Deployment ](docker_dev.html#for-docker-based-deployment)\n      * [ Conclusion ](docker_dev.html#conclusion)\n      * [ Appendix ](docker_dev.html#appendix)\n        * [ Nav2 Development Image ](docker_dev.html#nav2-development-image)\n        * [ Nav2 Deployment Image ](docker_dev.html#nav2-deployment-image)\n  * [ Plugin Tutorials ](../../plugin_tutorials/index.html)\n    * [ Writing a New Costmap2D Plugin ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html)\n      * [ Overview ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#overview)\n      * [ Requirements ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#requirements)\n      * [ Tutorial Steps ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#tutorial-steps)\n        * [ 1- Write a new Costmap2D plugin ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#write-a-new-costmap2d-plugin)\n        * [ 2- Export and make GradientLayer plugin ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#export-and-make-gradientlayer-plugin)\n        * [ 3- Enable the plugin in Costmap2D ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#enable-the-plugin-in-costmap2d)\n        * [ 4- Run GradientLayer plugin ](../../plugin_tutorials/docs/writing_new_costmap2d_plugin.html#run-gradientlayer-plugin)\n    * [ Writing a New Planner Plugin ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html)\n      * [ Overview ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#overview)\n      * [ Requirements ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#requirements)\n      * [ Tutorial Steps ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#tutorial-steps)\n        * [ 1- Creating a new Planner Plugin ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#creating-a-new-planner-plugin)\n        * [ 2- Exporting the planner plugin ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#exporting-the-planner-plugin)\n        * [ 3- Pass the plugin name through params file ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#pass-the-plugin-name-through-params-file)\n        * [ 4- Run StraightLine plugin ](../../plugin_tutorials/docs/writing_new_nav2planner_plugin.html#run-straightline-plugin)\n    * [ Writing a New Controller Plugin ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html)\n      * [ Overview ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#overview)\n      * [ Requirements ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#requirements)\n      * [ Tutorial Steps ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#tutorial-steps)\n        * [ 1- Create a new Controller Plugin ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#create-a-new-controller-plugin)\n        * [ 2- Exporting the controller plugin ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#exporting-the-controller-plugin)\n        * [ 3- Pass the plugin name through the params file ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#pass-the-plugin-name-through-the-params-file)\n        * [ 4- Run Pure Pursuit Controller plugin ](../../plugin_tutorials/docs/writing_new_nav2controller_plugin.html#run-pure-pursuit-controller-plugin)\n    * [ Writing a New Behavior Tree Plugin ](../../plugin_tutorials/docs/writing_new_bt_plugin.html)\n      * [ Overview ](../../plugin_tutorials/docs/writing_new_bt_plugin.html#overview)\n      * [ Requirements ](../../plugin_tutorials/docs/writing_new_bt_plugin.html#requirements)\n      * [ Tutorial Steps ](../../plugin_tutorials/docs/writing_new_bt_plugin.html#tutorial-steps)\n        * [ 1- Creating a new BT Plugin ](../../plugin_tutorials/docs/writing_new_bt_plugin.html#creating-a-new-bt-plugin)\n        * [ 2- Exporting the planner plugin ](../../plugin_tutorials/docs/writing_new_bt_plugin.html#exporting-the-planner-plugin)\n        * [ 3- Add plugin library name to config ](../../plugin_tutorials/docs/writing_new_bt_plugin.html#add-plugin-library-name-to-config)\n        * [ 4- Run Your Custom plugin ](../../plugin_tutorials/docs/writing_new_bt_plugin.html#run-your-custom-plugin)\n    * [ Writing a New Behavior Plugin ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html)\n      * [ Overview ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html#overview)\n      * [ Requirements ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html#requirements)\n      * [ Tutorial Steps ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html#tutorial-steps)\n        * [ 1- Creating a new Behavior Plugin ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html#creating-a-new-behavior-plugin)\n        * [ 2- Exporting the Behavior Plugin ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html#exporting-the-behavior-plugin)\n        * [ 3- Pass the plugin name through params file ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html#pass-the-plugin-name-through-params-file)\n        * [ 4- Run Behavior Plugin ](../../plugin_tutorials/docs/writing_new_behavior_plugin.html#run-behavior-plugin)\n    * [ Writing a New Navigator Plugin ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html)\n      * [ Overview ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html#overview)\n      * [ Requirements ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html#requirements)\n      * [ Tutorial Steps ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html#tutorial-steps)\n        * [ 1- Create a new Navigator Plugin ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html#create-a-new-navigator-plugin)\n        * [ 2- Exporting the navigator plugin ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html#exporting-the-navigator-plugin)\n        * [ 3- Pass the plugin name through the params file ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html#pass-the-plugin-name-through-the-params-file)\n        * [ 4- Run plugin ](../../plugin_tutorials/docs/writing_new_navigator_plugin.html#run-plugin)\n  * [ Configuration Guide ](../../configuration/index.html)\n    * [ Behavior-Tree Navigator ](../../configuration/packages/configuring-bt-navigator.html)\n      * [ Parameters ](../../configuration/packages/configuring-bt-navigator.html#parameters)\n      * [ Example ](../../configuration/packages/configuring-bt-navigator.html#example)\n    * [ Behavior Tree XML Nodes ](../../configuration/packages/configuring-bt-xml.html)\n      * [ Action Plugins ](../../configuration/packages/configuring-bt-xml.html#action-plugins)\n        * [ Wait ](../../configuration/packages/bt-plugins/actions/Wait.html)\n        * [ Spin ](../../configuration/packages/bt-plugins/actions/Spin.html)\n        * [ BackUp ](../../configuration/packages/bt-plugins/actions/BackUp.html)\n        * [ DriveOnHeading ](../../configuration/packages/bt-plugins/actions/DriveOnHeading.html)\n        * [ AssistedTeleop ](../../configuration/packages/bt-plugins/actions/AssistedTeleop.html)\n        * [ ComputePathToPose ](../../configuration/packages/bt-plugins/actions/ComputePathToPose.html)\n        * [ FollowPath ](../../configuration/packages/bt-plugins/actions/FollowPath.html)\n        * [ NavigateToPose ](../../configuration/packages/bt-plugins/actions/NavigateToPose.html)\n        * [ ClearEntireCostmap ](../../configuration/packages/bt-plugins/actions/ClearEntireCostmap.html)\n        * [ ClearCostmapExceptRegion ](../../configuration/packages/bt-plugins/actions/ClearCostmapExceptRegion.html)\n        * [ ClearCostmapAroundRobot ](../../configuration/packages/bt-plugins/actions/ClearCostmapAroundRobot.html)\n        * [ ReinitializeGlobalLocalization ](../../configuration/packages/bt-plugins/actions/ReinitializeGlobalLocalization.html)\n        * [ TruncatePath ](../../configuration/packages/bt-plugins/actions/TruncatePath.html)\n        * [ TruncatePathLocal ](../../configuration/packages/bt-plugins/actions/TruncatePathLocal.html)\n        * [ PlannerSelector ](../../configuration/packages/bt-plugins/actions/PlannerSelector.html)\n        * [ ControllerSelector ](../../configuration/packages/bt-plugins/actions/ControllerSelector.html)\n        * [ SmootherSelector ](../../configuration/packages/bt-plugins/actions/SmootherSelector.html)\n        * [ GoalCheckerSelector ](../../configuration/packages/bt-plugins/actions/GoalCheckerSelector.html)\n        * [ ProgressCheckerSelector ](../../configuration/packages/bt-plugins/actions/ProgressCheckerSelector.html)\n        * [ NavigateThroughPoses ](../../configuration/packages/bt-plugins/actions/NavigateThroughPoses.html)\n        * [ ComputePathThroughPoses ](../../configuration/packages/bt-plugins/actions/ComputePathThroughPoses.html)\n        * [ ComputeCoveragePath ](../../configuration/packages/bt-plugins/actions/ComputeCoveragePath.html)\n        * [ CancelCoverage ](../../configuration/packages/bt-plugins/actions/CancelCoverage.html)\n        * [ RemovePassedGoals ](../../configuration/packages/bt-plugins/actions/RemovePassedGoals.html)\n        * [ CancelControl ](../../configuration/packages/bt-plugins/actions/CancelControl.html)\n        * [ CancelBackUp ](../../configuration/packages/bt-plugins/actions/CancelBackUp.html)\n        * [ CancelSpin ](../../configuration/packages/bt-plugins/actions/CancelSpin.html)\n        * [ CancelWait ](../../configuration/packages/bt-plugins/actions/CancelWait.html)\n        * [ CancelDriveOnHeading ](../../configuration/packages/bt-plugins/actions/CancelDriveOnHeading.html)\n        * [ CancelAssistedTeleop ](../../configuration/packages/bt-plugins/actions/CancelAssistedTeleop.html)\n        * [ SmoothPath ](../../configuration/packages/bt-plugins/actions/Smooth.html)\n      * [ Condition Plugins ](../../configuration/packages/configuring-bt-xml.html#condition-plugins)\n        * [ GoalReached ](../../configuration/packages/bt-plugins/conditions/GoalReached.html)\n        * [ TransformAvailable ](../../configuration/packages/bt-plugins/conditions/TransformAvailable.html)\n        * [ DistanceTraveled ](../../configuration/packages/bt-plugins/conditions/DistanceTraveled.html)\n        * [ GoalUpdated ](../../configuration/packages/bt-plugins/conditions/GoalUpdated.html)\n        * [ GloballyUpdatedGoal ](../../configuration/packages/bt-plugins/conditions/GloballyUpdatedGoal.html)\n        * [ InitialPoseReceived ](../../configuration/packages/bt-plugins/conditions/InitialPoseReceived.html)\n        * [ IsStuck ](../../configuration/packages/bt-plugins/conditions/IsStuck.html)\n        * [ TimeExpired ](../../configuration/packages/bt-plugins/conditions/TimeExpired.html)\n        * [ IsBatteryLow ](../../configuration/packages/bt-plugins/conditions/IsBatteryLow.html)\n        * [ IsPathValid ](../../configuration/packages/bt-plugins/conditions/IsPathValid.html)\n        * [ PathExpiringTimer ](../../configuration/packages/bt-plugins/conditions/PathExpiringTimer.html)\n        * [ AreErrorCodesPresent ](../../configuration/packages/bt-plugins/conditions/AreErrorCodesPresent.html)\n        * [ WouldAControllerRecoveryHelp ](../../configuration/packages/bt-plugins/conditions/WouldAControllerRecoveryHelp.html)\n        * [ WouldAPlannerRecoveryHelp ](../../configuration/packages/bt-plugins/conditions/WouldAPlannerRecoveryHelp.html)\n        * [ WouldASmootherRecoveryHelp ](../../configuration/packages/bt-plugins/conditions/WouldASmootherRecoveryHelp.html)\n        * [ IsBatteryCharging ](../../configuration/packages/bt-plugins/conditions/IsBatteryCharging.html)\n      * [ Control Plugins ](../../configuration/packages/configuring-bt-xml.html#control-plugins)\n        * [ PipelineSequence ](../../configuration/packages/bt-plugins/controls/PipelineSequence.html)\n        * [ RoundRobin ](../../configuration/packages/bt-plugins/controls/RoundRobin.html)\n        * [ RecoveryNode ](../../configuration/packages/bt-plugins/controls/RecoveryNode.html)\n      * [ Decorator Plugins ](../../configuration/packages/configuring-bt-xml.html#decorator-plugins)\n        * [ RateController ](../../configuration/packages/bt-plugins/decorators/RateController.html)\n        * [ DistanceController ](../../configuration/packages/bt-plugins/decorators/DistanceController.html)\n        * [ SpeedController ](../../configuration/packages/bt-plugins/decorators/SpeedController.html)\n        * [ GoalUpdater ](../../configuration/packages/bt-plugins/decorators/GoalUpdater.html)\n        * [ PathLongerOnApproach ](../../configuration/packages/bt-plugins/decorators/PathLongerOnApproach.html)\n        * [ SingleTrigger ](../../configuration/packages/bt-plugins/decorators/SingleTrigger.html)\n      * [ Example ](../../configuration/packages/configuring-bt-xml.html#example)\n    * [ Costmap 2D ](../../configuration/packages/configuring-costmaps.html)\n      * [ Costmap2D ROS Parameters ](../../configuration/packages/configuring-costmaps.html#costmap2d-ros-parameters)\n      * [ Default Plugins ](../../configuration/packages/configuring-costmaps.html#default-plugins)\n      * [ Plugin Parameters ](../../configuration/packages/configuring-costmaps.html#plugin-parameters)\n        * [ Static Layer Parameters ](../../configuration/packages/costmap-plugins/static.html)\n        * [ Inflation Layer Parameters ](../../configuration/packages/costmap-plugins/inflation.html)\n        * [ Obstacle Layer Parameters ](../../configuration/packages/costmap-plugins/obstacle.html)\n        * [ Voxel Layer Parameters ](../../configuration/packages/costmap-plugins/voxel.html)\n        * [ Range Sensor Parameters ](../../configuration/packages/costmap-plugins/range.html)\n        * [ Denoise Layer Parameters ](../../configuration/packages/costmap-plugins/denoise.html)\n      * [ Costmap Filters Parameters ](../../configuration/packages/configuring-costmaps.html#costmap-filters-parameters)\n        * [ Keepout Filter Parameters ](../../configuration/packages/costmap-plugins/keepout_filter.html)\n        * [ Speed Filter Parameters ](../../configuration/packages/costmap-plugins/speed_filter.html)\n        * [ Binary Filter Parameters ](../../configuration/packages/costmap-plugins/binary_filter.html)\n      * [ Example ](../../configuration/packages/configuring-costmaps.html#example)\n    * [ Lifecycle Manager ](../../configuration/packages/configuring-lifecycle.html)\n      * [ Parameters ](../../configuration/packages/configuring-lifecycle.html#parameters)\n      * [ Example ](../../configuration/packages/configuring-lifecycle.html#example)\n    * [ Planner Server ](../../configuration/packages/configuring-planner-server.html)\n      * [ Parameters ](../../configuration/packages/configuring-planner-server.html#parameters)\n      * [ Default Plugins ](../../configuration/packages/configuring-planner-server.html#default-plugins)\n      * [ Example ](../../configuration/packages/configuring-planner-server.html#example)\n    * [ Coverage Server ](../../configuration/packages/configuring-coverage-server.html)\n      * [ Parameters ](../../configuration/packages/configuring-coverage-server.html#parameters)\n      * [ Example ](../../configuration/packages/configuring-coverage-server.html#example)\n    * [ NavFn Planner ](../../configuration/packages/configuring-navfn.html)\n      * [ Parameters ](../../configuration/packages/configuring-navfn.html#parameters)\n      * [ Example ](../../configuration/packages/configuring-navfn.html#example)\n    * [ Smac Planner ](../../configuration/packages/configuring-smac-planner.html)\n      * [ Provided Plugins ](../../configuration/packages/configuring-smac-planner.html#provided-plugins)\n        * [ Smac 2D Planner ](../../configuration/packages/smac/configuring-smac-2d.html)\n        * [ Smac Hybrid-A* Planner ](../../configuration/packages/smac/configuring-smac-hybrid.html)\n        * [ Smac State Lattice Planner ](../../configuration/packages/smac/configuring-smac-lattice.html)\n      * [ Description ](../../configuration/packages/configuring-smac-planner.html#description)\n    * [ Theta Star Planner ](../../configuration/packages/configuring-thetastar.html)\n      * [ Parameters ](../../configuration/packages/configuring-thetastar.html#parameters)\n      * [ Example ](../../configuration/packages/configuring-thetastar.html#example)\n    * [ Controller Server ](../../configuration/packages/configuring-controller-server.html)\n      * [ Parameters ](../../configuration/packages/configuring-controller-server.html#parameters)\n      * [ Provided Plugins ](../../configuration/packages/configuring-controller-server.html#provided-plugins)\n        * [ SimpleProgressChecker ](../../configuration/packages/nav2_controller-plugins/simple_progress_checker.html)\n        * [ PoseProgressChecker ](../../configuration/packages/nav2_controller-plugins/pose_progress_checker.html)\n        * [ SimpleGoalChecker ](../../configuration/packages/nav2_controller-plugins/simple_goal_checker.html)\n        * [ StoppedGoalChecker ](../../configuration/packages/nav2_controller-plugins/stopped_goal_checker.html)\n      * [ Default Plugins ](../../configuration/packages/configuring-controller-server.html#default-plugins)\n      * [ Example ](../../configuration/packages/configuring-controller-server.html#example)\n    * [ DWB Controller ](../../configuration/packages/configuring-dwb-controller.html)\n      * [ Controller ](../../configuration/packages/configuring-dwb-controller.html#controller)\n        * [ DWB Controller ](../../configuration/packages/dwb-params/controller.html)\n        * [ XYTheta Iterator ](../../configuration/packages/dwb-params/iterator.html)\n        * [ Kinematic Parameters ](../../configuration/packages/dwb-params/kinematic.html)\n        * [ Publisher ](../../configuration/packages/dwb-params/visualization.html)\n      * [ Plugins ](../../configuration/packages/configuring-dwb-controller.html#plugins)\n        * [ LimitedAccelGenerator ](../../configuration/packages/dwb-plugins/limited_accel_generator.html)\n        * [ StandardTrajectoryGenerator ](../../configuration/packages/dwb-plugins/standard_traj_generator.html)\n      * [ Trajectory Critics ](../../configuration/packages/configuring-dwb-controller.html#trajectory-critics)\n        * [ BaseObstacleCritic ](../../configuration/packages/trajectory_critics/base_obstacle.html)\n        * [ GoalAlignCritic ](../../configuration/packages/trajectory_critics/goal_align.html)\n        * [ GoalDistCritic ](../../configuration/packages/trajectory_critics/goal_dist.html)\n        * [ ObstacleFootprintCritic ](../../configuration/packages/trajectory_critics/obstacle_footprint.html)\n        * [ OscillationCritic ](../../configuration/packages/trajectory_critics/oscillation.html)\n        * [ PathAlignCritic ](../../configuration/packages/trajectory_critics/path_align.html)\n        * [ PathDistCritic ](../../configuration/packages/trajectory_critics/path_dist.html)\n        * [ PreferForwardCritic ](../../configuration/packages/trajectory_critics/prefer_forward.html)\n        * [ RotateToGoalCritic ](../../configuration/packages/trajectory_critics/rotate_to_goal.html)\n        * [ TwirlingCritic ](../../configuration/packages/trajectory_critics/twirling.html)\n      * [ Example ](../../configuration/packages/configuring-dwb-controller.html#example)\n    * [ Regulated Pure Pursuit ](../../configuration/packages/configuring-regulated-pp.html)\n      * [ Regulated Pure Pursuit Parameters ](../../configuration/packages/configuring-regulated-pp.html#regulated-pure-pursuit-parameters)\n      * [ Example ](../../configuration/packages/configuring-regulated-pp.html#example)\n    * [ Model Predictive Path Integral Controller ](../../configuration/packages/configuring-mppic.html)\n      * [ MPPI Parameters ](../../configuration/packages/configuring-mppic.html#mppi-parameters)\n        * [ Trajectory Visualization ](../../configuration/packages/configuring-mppic.html#trajectory-visualization)\n        * [ Path Handler ](../../configuration/packages/configuring-mppic.html#path-handler)\n        * [ Ackermann Motion Model ](../../configuration/packages/configuring-mppic.html#ackermann-motion-model)\n        * [ Constraint Critic ](../../configuration/packages/configuring-mppic.html#constraint-critic)\n        * [ Goal Angle Critic ](../../configuration/packages/configuring-mppic.html#goal-angle-critic)\n        * [ Goal Critic ](../../configuration/packages/configuring-mppic.html#goal-critic)\n        * [ Obstacles Critic ](../../configuration/packages/configuring-mppic.html#obstacles-critic)\n        * [ Cost Critic ](../../configuration/packages/configuring-mppic.html#cost-critic)\n        * [ Path Align Critic ](../../configuration/packages/configuring-mppic.html#path-align-critic)\n        * [ Path Angle Critic ](../../configuration/packages/configuring-mppic.html#path-angle-critic)\n        * [ Path Follow Critic ](../../configuration/packages/configuring-mppic.html#path-follow-critic)\n        * [ Prefer Forward Critic ](../../configuration/packages/configuring-mppic.html#prefer-forward-critic)\n        * [ Twirling Critic ](../../configuration/packages/configuring-mppic.html#twirling-critic)\n        * [ Velocity Deadband Critic ](../../configuration/packages/configuring-mppic.html#velocity-deadband-critic)\n      * [ Example ](../../configuration/packages/configuring-mppic.html#example)\n      * [ Notes to Users ](../../configuration/packages/configuring-mppic.html#notes-to-users)\n        * [ General Words of Wisdom ](../../configuration/packages/configuring-mppic.html#general-words-of-wisdom)\n        * [ Prediction Horizon, Costmap Sizing, and Offsets ](../../configuration/packages/configuring-mppic.html#prediction-horizon-costmap-sizing-and-offsets)\n        * [ Obstacle, Inflation Layer, and Path Following ](../../configuration/packages/configuring-mppic.html#obstacle-inflation-layer-and-path-following)\n    * [ Rotation Shim Controller ](../../configuration/packages/configuring-rotation-shim-controller.html)\n      * [ Rotation Shim Controller Parameters ](../../configuration/packages/configuring-rotation-shim-controller.html#rotation-shim-controller-parameters)\n      * [ Example ](../../configuration/packages/configuring-rotation-shim-controller.html#example)\n    * [ Graceful Controller ](../../configuration/packages/configuring-graceful-motion-controller.html)\n      * [ Graceful Controller Parameters ](../../configuration/packages/configuring-graceful-motion-controller.html#graceful-controller-parameters)\n      * [ Example ](../../configuration/packages/configuring-graceful-motion-controller.html#example)\n    * [ Map Server / Saver ](../../configuration/packages/configuring-map-server.html)\n      * [ Map Saver Parameters ](../../configuration/packages/configuring-map-server.html#map-saver-parameters)\n      * [ Map Server Parameters ](../../configuration/packages/configuring-map-server.html#map-server-parameters)\n      * [ Costmap Filter Info Server Parameters ](../../configuration/packages/configuring-map-server.html#costmap-filter-info-server-parameters)\n      * [ Example ](../../configuration/packages/configuring-map-server.html#example)\n    * [ AMCL ](../../configuration/packages/configuring-amcl.html)\n      * [ Parameters ](../../configuration/packages/configuring-amcl.html#parameters)\n      * [ Example ](../../configuration/packages/configuring-amcl.html#example)\n    * [ Behavior Server ](../../configuration/packages/configuring-behavior-server.html)\n      * [ Behavior Server Parameters ](../../configuration/packages/configuring-behavior-server.html#behavior-server-parameters)\n      * [ Default Plugins ](../../configuration/packages/configuring-behavior-server.html#default-plugins)\n      * [ Spin Behavior Parameters ](../../configuration/packages/configuring-behavior-server.html#spin-behavior-parameters)\n      * [ BackUp Behavior Parameters ](../../configuration/packages/configuring-behavior-server.html#backup-behavior-parameters)\n      * [ DriveOnHeading Behavior Parameters ](../../configuration/packages/configuring-behavior-server.html#driveonheading-behavior-parameters)\n      * [ AssistedTeleop Behavior Parameters ](../../configuration/packages/configuring-behavior-server.html#assistedteleop-behavior-parameters)\n      * [ Example ](../../configuration/packages/configuring-behavior-server.html#example)\n    * [ Smoother Server ](../../configuration/packages/configuring-smoother-server.html)\n      * [ Smoother Server Parameters ](../../configuration/packages/configuring-smoother-server.html#smoother-server-parameters)\n      * [ Example ](../../configuration/packages/configuring-smoother-server.html#example)\n    * [ Simple Smoother ](../../configuration/packages/configuring-simple-smoother.html)\n      * [ Simple Smoother Parameters ](../../configuration/packages/configuring-simple-smoother.html#simple-smoother-parameters)\n      * [ Example ](../../configuration/packages/configuring-simple-smoother.html#example)\n    * [ Savitzky-Golay Smoother ](../../configuration/packages/configuring-savitzky-golay-smoother.html)\n      * [ Savitzky-Golay Smoother Parameters ](../../configuration/packages/configuring-savitzky-golay-smoother.html#savitzky-golay-smoother-parameters)\n      * [ Example ](../../configuration/packages/configuring-savitzky-golay-smoother.html#example)\n    * [ Constrained smoother ](../../configuration/packages/configuring-constrained-smoother.html)\n      * [ Smoother Server Parameters ](../../configuration/packages/configuring-constrained-smoother.html#smoother-server-parameters)\n      * [ Example ](../../configuration/packages/configuring-constrained-smoother.html#example)\n    * [ Velocity Smoother ](../../configuration/packages/configuring-velocity-smoother.html)\n      * [ Velocity Smoother Parameters ](../../configuration/packages/configuring-velocity-smoother.html#velocity-smoother-parameters)\n      * [ Example ](../../configuration/packages/configuring-velocity-smoother.html#example)\n    * [ Collision Monitor ](../../configuration/packages/configuring-collision-monitor.html)\n      * [ Provided Nodes ](../../configuration/packages/configuring-collision-monitor.html#provided-nodes)\n        * [ Collision Monitor Node ](../../configuration/packages/collision_monitor/configuring-collision-monitor-node.html)\n        * [ Collision Detector Node ](../../configuration/packages/collision_monitor/configuring-collision-detector-node.html)\n    * [ Waypoint Follower ](../../configuration/packages/configuring-waypoint-follower.html)\n      * [ Parameters ](../../configuration/packages/configuring-waypoint-follower.html#parameters)\n      * [ Provided Plugins ](../../configuration/packages/configuring-waypoint-follower.html#provided-plugins)\n        * [ WaitAtWaypoint ](../../configuration/packages/nav2_waypoint_follower-plugins/wait_at_waypoint.html)\n        * [ PhotoAtWaypoint ](../../configuration/packages/nav2_waypoint_follower-plugins/photo_at_waypoint.html)\n        * [ InputAtWaypoint ](../../configuration/packages/nav2_waypoint_follower-plugins/input_at_waypoint.html)\n      * [ Default Plugin ](../../configuration/packages/configuring-waypoint-follower.html#default-plugin)\n      * [ Example ](../../configuration/packages/configuring-waypoint-follower.html#example)\n  * [ Tuning Guide ](../../tuning/index.html)\n    * [ Inflation Potential Fields ](../../tuning/index.html#inflation-potential-fields)\n    * [ Robot Footprint vs Radius ](../../tuning/index.html#robot-footprint-vs-radius)\n    * [ Rotate in Place Behavior ](../../tuning/index.html#rotate-in-place-behavior)\n    * [ Planner Plugin Selection ](../../tuning/index.html#planner-plugin-selection)\n    * [ Controller Plugin Selection ](../../tuning/index.html#controller-plugin-selection)\n    * [ Caching Obstacle Heuristic in Smac Planners ](../../tuning/index.html#caching-obstacle-heuristic-in-smac-planners)\n    * [ Costmap2D Plugins ](../../tuning/index.html#costmap2d-plugins)\n    * [ Nav2 Launch Options ](../../tuning/index.html#nav2-launch-options)\n    * [ Other Pages We\u2019d Love To Offer ](../../tuning/index.html#other-pages-we-d-love-to-offer)\n  * [ Nav2 Behavior Trees ](../../behavior_trees/index.html)\n    * [ Introduction To Nav2 Specific Nodes ](../../behavior_trees/overview/nav2_specific_nodes.html)\n      * [ Action Nodes ](../../behavior_trees/overview/nav2_specific_nodes.html#action-nodes)\n      * [ Condition Nodes ](../../behavior_trees/overview/nav2_specific_nodes.html#condition-nodes)\n      * [ Decorator Nodes ](../../behavior_trees/overview/nav2_specific_nodes.html#decorator-nodes)\n      * [ Control: PipelineSequence ](../../behavior_trees/overview/nav2_specific_nodes.html#control-pipelinesequence)\n      * [ Control: Recovery ](../../behavior_trees/overview/nav2_specific_nodes.html#control-recovery)\n      * [ Control: RoundRobin ](../../behavior_trees/overview/nav2_specific_nodes.html#control-roundrobin)\n    * [ Detailed Behavior Tree Walkthrough ](../../behavior_trees/overview/detailed_behavior_tree_walkthrough.html)\n      * [ Overview ](../../behavior_trees/overview/detailed_behavior_tree_walkthrough.html#overview)\n      * [ Prerequisites ](../../behavior_trees/overview/detailed_behavior_tree_walkthrough.html#prerequisites)\n      * [ Navigate To Pose With Replanning and Recovery ](../../behavior_trees/overview/detailed_behavior_tree_walkthrough.html#navigate-to-pose-with-replanning-and-recovery)\n      * [ Navigation Subtree ](../../behavior_trees/overview/detailed_behavior_tree_walkthrough.html#navigation-subtree)\n      * [ Recovery Subtree ](../../behavior_trees/overview/detailed_behavior_tree_walkthrough.html#recovery-subtree)\n    * [ Navigate To Pose ](../../behavior_trees/trees/nav_to_pose_recovery.html)\n    * [ Navigate Through Poses ](../../behavior_trees/trees/nav_through_poses_recovery.html)\n    * [ Navigate To Pose and Pause Near Goal-Obstacle ](../../behavior_trees/trees/nav_to_pose_and_pause_near_goal_obstacle.html)\n    * [ Navigate To Pose With Consistent Replanning And If Path Becomes Invalid ](../../behavior_trees/trees/nav_to_pose_with_consistent_replanning_and_if_path_becomes_invalid.html)\n    * [ Follow Dynamic Point ](../../behavior_trees/trees/follow_point.html)\n    * [ Odometry Calibration ](../../behavior_trees/trees/odometry_calibration.html)\n  * [ Navigation Plugins ](../../plugins/index.html)\n    * [ Behavior-Tree Navigators ](../../plugins/index.html#behavior-tree-navigators)\n    * [ Costmap Layers ](../../plugins/index.html#costmap-layers)\n    * [ Costmap Filters ](../../plugins/index.html#costmap-filters)\n    * [ Controllers ](../../plugins/index.html#controllers)\n    * [ Planners ](../../plugins/index.html#planners)\n    * [ Smoothers ](../../plugins/index.html#smoothers)\n    * [ Behaviors ](../../plugins/index.html#behaviors)\n    * [ Waypoint Task Executors ](../../plugins/index.html#waypoint-task-executors)\n    * [ Goal Checkers ](../../plugins/index.html#goal-checkers)\n    * [ Progress Checkers ](../../plugins/index.html#progress-checkers)\n    * [ Behavior Tree Nodes ](../../plugins/index.html#behavior-tree-nodes)\n  * [ Migration Guides ](../../migration/index.html)\n    * [ Dashing to Eloquent ](../../migration/Dashing.html)\n      * [ New Packages ](../../migration/Dashing.html#new-packages)\n      * [ New Plugins ](../../migration/Dashing.html#new-plugins)\n      * [ Navigation2 Architectural Changes ](../../migration/Dashing.html#navigation2-architectural-changes)\n    * [ Eloquent to Foxy ](../../migration/Eloquent.html)\n      * [ General ](../../migration/Eloquent.html#general)\n      * [ Server Updates ](../../migration/Eloquent.html#server-updates)\n      * [ New Plugins ](../../migration/Eloquent.html#new-plugins)\n      * [ Map Server Re-Work ](../../migration/Eloquent.html#map-server-re-work)\n      * [ New Particle Filter Messages ](../../migration/Eloquent.html#new-particle-filter-messages)\n      * [ Selection of Behavior Tree in each navigation action ](../../migration/Eloquent.html#selection-of-behavior-tree-in-each-navigation-action)\n      * [ FollowPoint Capability ](../../migration/Eloquent.html#followpoint-capability)\n      * [ New Costmap Layer ](../../migration/Eloquent.html#new-costmap-layer)\n    * [ Foxy to Galactic ](../../migration/Foxy.html)\n      * [ NavigateToPose Action Feedback updates ](../../migration/Foxy.html#navigatetopose-action-feedback-updates)\n      * [ NavigateToPose BT-node Interface Changes ](../../migration/Foxy.html#navigatetopose-bt-node-interface-changes)\n      * [ NavigateThroughPoses and ComputePathThroughPoses Actions Added ](../../migration/Foxy.html#navigatethroughposes-and-computepaththroughposes-actions-added)\n      * [ ComputePathToPose BT-node Interface Changes ](../../migration/Foxy.html#computepathtopose-bt-node-interface-changes)\n      * [ ComputePathToPose Action Interface Changes ](../../migration/Foxy.html#computepathtopose-action-interface-changes)\n      * [ BackUp BT-node Interface Changes ](../../migration/Foxy.html#backup-bt-node-interface-changes)\n      * [ BackUp Recovery Interface Changes ](../../migration/Foxy.html#backup-recovery-interface-changes)\n      * [ Nav2 Controllers and Goal Checker Plugin Interface Changes ](../../migration/Foxy.html#nav2-controllers-and-goal-checker-plugin-interface-changes)\n      * [ FollowPath goal_checker_id attribute ](../../migration/Foxy.html#followpath-goal-checker-id-attribute)\n      * [ Groot Support ](../../migration/Foxy.html#groot-support)\n      * [ New Plugins ](../../migration/Foxy.html#new-plugins)\n      * [ Costmap Filters ](../../migration/Foxy.html#costmap-filters)\n      * [ SmacPlanner ](../../migration/Foxy.html#smacplanner)\n      * [ ThetaStarPlanner ](../../migration/Foxy.html#thetastarplanner)\n      * [ RegulatedPurePursuitController ](../../migration/Foxy.html#regulatedpurepursuitcontroller)\n      * [ Costmap2D ` current_  ` Usage ](../../migration/Foxy.html#costmap2d-current-usage)\n      * [ Standard time units in parameters ](../../migration/Foxy.html#standard-time-units-in-parameters)\n      * [ Ray Tracing Parameters ](../../migration/Foxy.html#ray-tracing-parameters)\n      * [ Obstacle Marking Parameters ](../../migration/Foxy.html#obstacle-marking-parameters)\n      * [ Recovery Action Changes ](../../migration/Foxy.html#recovery-action-changes)\n      * [ Default Behavior Tree Changes ](../../migration/Foxy.html#default-behavior-tree-changes)\n      * [ NavFn Planner Parameters ](../../migration/Foxy.html#navfn-planner-parameters)\n      * [ New ClearCostmapExceptRegion and ClearCostmapAroundRobot BT-nodes ](../../migration/Foxy.html#new-clearcostmapexceptregion-and-clearcostmaparoundrobot-bt-nodes)\n      * [ New Behavior Tree Nodes ](../../migration/Foxy.html#new-behavior-tree-nodes)\n      * [ sensor_msgs/PointCloud to sensor_msgs/PointCloud2 Change ](../../migration/Foxy.html#sensor-msgs-pointcloud-to-sensor-msgs-pointcloud2-change)\n      * [ ControllerServer New Parameter failure_tolerance ](../../migration/Foxy.html#controllerserver-new-parameter-failure-tolerance)\n      * [ Removed BT XML Launch Configurations ](../../migration/Foxy.html#removed-bt-xml-launch-configurations)\n      * [ Nav2 RViz Panel Action Feedback Information ](../../migration/Foxy.html#nav2-rviz-panel-action-feedback-information)\n    * [ Galactic to Humble ](../../migration/Galactic.html)\n      * [ Major improvements to Smac Planners ](../../migration/Galactic.html#major-improvements-to-smac-planners)\n      * [ Simple (Python) Commander ](../../migration/Galactic.html#simple-python-commander)\n      * [ Reduce Nodes and Executors ](../../migration/Galactic.html#reduce-nodes-and-executors)\n      * [ API Change for nav2_core ](../../migration/Galactic.html#api-change-for-nav2-core)\n      * [ Extending the BtServiceNode to process Service-Results ](../../migration/Galactic.html#extending-the-btservicenode-to-process-service-results)\n      * [ Including new Rotation Shim Controller Plugin ](../../migration/Galactic.html#including-new-rotation-shim-controller-plugin)\n      * [ Spawning the robot in Gazebo ](../../migration/Galactic.html#spawning-the-robot-in-gazebo)\n      * [ Recovery Behavior Timeout ](../../migration/Galactic.html#recovery-behavior-timeout)\n      * [ New parameter ` use_final_approach_orientation  ` for the 3 2D planners ](../../migration/Galactic.html#new-parameter-use-final-approach-orientation-for-the-3-2d-planners)\n      * [ SmacPlanner2D and Theta*: fix goal orientation being ignored ](../../migration/Galactic.html#smacplanner2d-and-theta-fix-goal-orientation-being-ignored)\n      * [ SmacPlanner2D, NavFn and Theta*: fix small path corner cases ](../../migration/Galactic.html#smacplanner2d-navfn-and-theta-fix-small-path-corner-cases)\n      * [ Change and fix behavior of dynamic parameter change detection ](../../migration/Galactic.html#change-and-fix-behavior-of-dynamic-parameter-change-detection)\n      * [ Dynamic Parameters ](../../migration/Galactic.html#dynamic-parameters)\n      * [ BT Action Nodes Exception Changes ](../../migration/Galactic.html#bt-action-nodes-exception-changes)\n      * [ BT Navigator Groot Multiple Navigators ](../../migration/Galactic.html#bt-navigator-groot-multiple-navigators)\n      * [ Removed Kinematic Limiting in RPP ](../../migration/Galactic.html#removed-kinematic-limiting-in-rpp)\n      * [ Added Smoother Task Server ](../../migration/Galactic.html#added-smoother-task-server)\n      * [ Removed Use Approach Velocity Scaling Param in RPP ](../../migration/Galactic.html#removed-use-approach-velocity-scaling-param-in-rpp)\n      * [ Refactored AMCL motion models as plugins ](../../migration/Galactic.html#refactored-amcl-motion-models-as-plugins)\n      * [ Dropping Support for Live Groot Monitoring of Nav2 ](../../migration/Galactic.html#dropping-support-for-live-groot-monitoring-of-nav2)\n      * [ Replanning Only if Path is Invalid ](../../migration/Galactic.html#replanning-only-if-path-is-invalid)\n      * [ Fix CostmapLayer clearArea invert param logic ](../../migration/Galactic.html#fix-costmaplayer-cleararea-invert-param-logic)\n      * [ Dynamic Composition ](../../migration/Galactic.html#dynamic-composition)\n      * [ BT Cancel Node ](../../migration/Galactic.html#bt-cancel-node)\n      * [ BT PathLongerOnApproach Node ](../../migration/Galactic.html#bt-pathlongeronapproach-node)\n      * [ BT TruncatePathLocal Node ](../../migration/Galactic.html#bt-truncatepathlocal-node)\n      * [ Constrained Smoother ](../../migration/Galactic.html#constrained-smoother)\n      * [ Replanning at a Constant Rate and if the Path is Invalid ](../../migration/Galactic.html#replanning-at-a-constant-rate-and-if-the-path-is-invalid)\n      * [ Euclidean Distance 2D ](../../migration/Galactic.html#euclidean-distance-2d)\n      * [ Recovery To Behavior ](../../migration/Galactic.html#recovery-to-behavior)\n      * [ Respawn Support in Launch and Lifecycle Manager ](../../migration/Galactic.html#respawn-support-in-launch-and-lifecycle-manager)\n      * [ New Nav2 Velocity Smoother ](../../migration/Galactic.html#new-nav2-velocity-smoother)\n      * [ Goal Checker API Changed ](../../migration/Galactic.html#goal-checker-api-changed)\n      * [ Added Assisted Teleop ](../../migration/Galactic.html#added-assisted-teleop)\n    * [ Humble to Iron ](../../migration/Humble.html)\n      * [ New Behavior-Tree Navigator Plugins ](../../migration/Humble.html#new-behavior-tree-navigator-plugins)\n      * [ Added Collision Monitor ](../../migration/Humble.html#added-collision-monitor)\n      * [ Removed use_sim_time from yaml ](../../migration/Humble.html#removed-use-sim-time-from-yaml)\n      * [ Run-time Speed up of Smac Planner ](../../migration/Humble.html#run-time-speed-up-of-smac-planner)\n      * [ Recursive Refinement of Smac and Simple Smoothers ](../../migration/Humble.html#recursive-refinement-of-smac-and-simple-smoothers)\n      * [ Simple Commander Python API ](../../migration/Humble.html#simple-commander-python-api)\n      * [ Smac Planner Start Pose Included in Path ](../../migration/Humble.html#smac-planner-start-pose-included-in-path)\n      * [ Parameterizable Collision Checking in RPP ](../../migration/Humble.html#parameterizable-collision-checking-in-rpp)\n      * [ Expanded Planner Benchmark Tests ](../../migration/Humble.html#expanded-planner-benchmark-tests)\n      * [ Smac Planner Path Tolerances ](../../migration/Humble.html#smac-planner-path-tolerances)\n      * [ costmap_2d_node default constructor ](../../migration/Humble.html#costmap-2d-node-default-constructor)\n      * [ Feedback for Navigation Failures ](../../migration/Humble.html#feedback-for-navigation-failures)\n      * [ Costmap Filters ](../../migration/Humble.html#costmap-filters)\n      * [ Savitzky-Golay Smoother ](../../migration/Humble.html#savitzky-golay-smoother)\n      * [ Changes to Map yaml file path for map_server node in Launch ](../../migration/Humble.html#changes-to-map-yaml-file-path-for-map-server-node-in-launch)\n      * [ SmootherSelector BT Node ](../../migration/Humble.html#smootherselector-bt-node)\n      * [ Publish Costmap Layers ](../../migration/Humble.html#publish-costmap-layers)\n      * [ Give Behavior Server Access to Both Costmaps ](../../migration/Humble.html#give-behavior-server-access-to-both-costmaps)\n      * [ New Model Predictive Path Integral Controller ](../../migration/Humble.html#new-model-predictive-path-integral-controller)\n      * [ Behavior Tree Uses Error Codes ](../../migration/Humble.html#behavior-tree-uses-error-codes)\n      * [ Load, Save and Loop Waypoints from the Nav2 Panel in RViz ](../../migration/Humble.html#load-save-and-loop-waypoints-from-the-nav2-panel-in-rviz)\n      * [ DWB Forward vs Reverse Pruning ](../../migration/Humble.html#dwb-forward-vs-reverse-pruning)\n      * [ More stable regulation on curves for long lookahead distances ](../../migration/Humble.html#more-stable-regulation-on-curves-for-long-lookahead-distances)\n      * [ Publish Collision Monitor State ](../../migration/Humble.html#publish-collision-monitor-state)\n      * [ Renamed ROS-parameter in Collision Monitor ](../../migration/Humble.html#renamed-ros-parameter-in-collision-monitor)\n      * [ New safety behavior model \u201climit\u201d in Collision Monitor ](../../migration/Humble.html#new-safety-behavior-model-limit-in-collision-monitor)\n      * [ Velocity smoother applies deceleration when timeout ](../../migration/Humble.html#velocity-smoother-applies-deceleration-when-timeout)\n      * [ PoseProgressChecker plugin ](../../migration/Humble.html#poseprogresschecker-plugin)\n      * [ Allow multiple goal checkers and change parameter progress_checker_plugin(s) name and type ](../../migration/Humble.html#allow-multiple-goal-checkers-and-change-parameter-progress-checker-plugin-s-name-and-type)\n      * [ IsBatteryChargingCondition BT Node ](../../migration/Humble.html#isbatterychargingcondition-bt-node)\n      * [ Behavior Server Error Codes ](../../migration/Humble.html#behavior-server-error-codes)\n      * [ New Denoise Costmap Layer Plugin ](../../migration/Humble.html#new-denoise-costmap-layer-plugin)\n      * [ SmacPlannerHybrid viz_expansions parameter ](../../migration/Humble.html#smacplannerhybrid-viz-expansions-parameter)\n    * [ Iron to Jazzy ](../../migration/Iron.html)\n      * [ Added TwistStamped Option for Commands ](../../migration/Iron.html#added-twiststamped-option-for-commands)\n      * [ Add VelocityPolygon in Collision Monitor ](../../migration/Iron.html#add-velocitypolygon-in-collision-monitor)\n      * [ Change polygon points parameter format in Collision Monitor ](../../migration/Iron.html#change-polygon-points-parameter-format-in-collision-monitor)\n      * [ Introduction of Soft-Real Time Action Servers ](../../migration/Iron.html#introduction-of-soft-real-time-action-servers)\n      * [ ` opennav_coverage  ` Project ](../../migration/Iron.html#opennav-coverage-project)\n      * [ Introduce a new Multi-Robot Bringup Launch ](../../migration/Iron.html#introduce-a-new-multi-robot-bringup-launch)\n      * [ New option for the Voxel and Obstacle Layers ](../../migration/Iron.html#new-option-for-the-voxel-and-obstacle-layers)\n      * [ use_interpolation RPP Parameter Depreciated ](../../migration/Iron.html#use-interpolation-rpp-parameter-depreciated)\n      * [ Changes to MPPI Goal Critic ](../../migration/Iron.html#changes-to-mppi-goal-critic)\n      * [ Changes to MPPI Path Angle Critic ](../../migration/Iron.html#changes-to-mppi-path-angle-critic)\n      * [ Changes to MPPI Path Handling For Directionality ](../../migration/Iron.html#changes-to-mppi-path-handling-for-directionality)\n      * [ Addition of new MPPI Cost Critic ](../../migration/Iron.html#addition-of-new-mppi-cost-critic)\n      * [ MPPI Acceleration ](../../migration/Iron.html#mppi-acceleration)\n      * [ Move Error Code Enumerations ](../../migration/Iron.html#move-error-code-enumerations)\n      * [ Substitution in parameter file ](../../migration/Iron.html#substitution-in-parameter-file)\n      * [ Allow Behavior Server Plugins to Access The Action Result ](../../migration/Iron.html#allow-behavior-server-plugins-to-access-the-action-result)\n      * [ Smac Planner Debug Param Name Change ](../../migration/Iron.html#smac-planner-debug-param-name-change)\n      * [ Smac Planner On Approach to Goal Shortcutting Solutions ](../../migration/Iron.html#smac-planner-on-approach-to-goal-shortcutting-solutions)\n      * [ Added GPS Waypoint Follower Server ](../../migration/Iron.html#added-gps-waypoint-follower-server)\n      * [ Smac Planner Hybrid-A* New Features ](../../migration/Iron.html#smac-planner-hybrid-a-new-features)\n      * [ New node in nav2_collision_monitor: Collision Detector ](../../migration/Iron.html#new-node-in-nav2-collision-monitor-collision-detector)\n      * [ Dynamic enabling/disabling of sources/polygons in Collision Monitor/Detector ](../../migration/Iron.html#dynamic-enabling-disabling-of-sources-polygons-in-collision-monitor-detector)\n      * [ Expose action server\u2019s result timeout ](../../migration/Iron.html#expose-action-server-s-result-timeout)\n      * [ RewrittenYaml could add new parameters to YAMLs ](../../migration/Iron.html#rewrittenyaml-could-add-new-parameters-to-yamls)\n      * [ Simple Commander API Allows Multi-Robot Namespacing ](../../migration/Iron.html#simple-commander-api-allows-multi-robot-namespacing)\n      * [ Change duration type in wait_action node ](../../migration/Iron.html#change-duration-type-in-wait-action-node)\n      * [ The costmap activation fails when required transforms are not available ](../../migration/Iron.html#the-costmap-activation-fails-when-required-transforms-are-not-available)\n      * [ Subtrees Obtain Shared Resources ](../../migration/Iron.html#subtrees-obtain-shared-resources)\n      * [ Collision Monitor: added watchdog mechanism based on ` source_timeout  ` parameter with default blocking behavior ](../../migration/Iron.html#collision-monitor-added-watchdog-mechanism-based-on-source-timeout-parameter-with-default-blocking-behavior)\n      * [ BtActionServer: use native library haltTree() ](../../migration/Iron.html#btactionserver-use-native-library-halttree)\n      * [ Global Frame Removed from 2 BT Nodes ](../../migration/Iron.html#global-frame-removed-from-2-bt-nodes)\n      * [ Introduction of ` CostmapUpdate.msg  ` ](../../migration/Iron.html#introduction-of-costmapupdate-msg)\n      * [ Full Stack Uses Node Clocks ](../../migration/Iron.html#full-stack-uses-node-clocks)\n      * [ New Graceful Motion Controller ](../../migration/Iron.html#new-graceful-motion-controller)\n      * [ Plugin Libraries in BT Navigator Only Includes Custom Nodes ](../../migration/Iron.html#plugin-libraries-in-bt-navigator-only-includes-custom-nodes)\n      * [ New RViz Plugin for selecting Planners, Controllers, Goal Checkers, Progress Checkers and Smoothers ](../../migration/Iron.html#new-rviz-plugin-for-selecting-planners-controllers-goal-checkers-progress-checkers-and-smoothers)\n      * [ RPP new optional ` interpolate_curvature_after_goal  ` behavior and fix conflict between ` use_rotate_to_heading  ` and ` allow_reversing  ` ](../../migration/Iron.html#rpp-new-optional-interpolate-curvature-after-goal-behavior-and-fix-conflict-between-use-rotate-to-heading-and-allow-reversing)\n      * [ Cancel Checker Interface For GlobalPlanner ](../../migration/Iron.html#cancel-checker-interface-for-globalplanner)\n      * [ New BtActionServer/BtNavigator parameter ](../../migration/Iron.html#new-btactionserver-btnavigator-parameter)\n      * [ New collision monitor parameter ](../../migration/Iron.html#new-collision-monitor-parameter)\n      * [ New graceful cancellation API for Controllers ](../../migration/Iron.html#new-graceful-cancellation-api-for-controllers)\n      * [ Standardization of Plugin Naming with Double Colons (::) ](../../migration/Iron.html#standardization-of-plugin-naming-with-double-colons)\n      * [ Collision monitor: dynamic radius for circle type polygons ](../../migration/Iron.html#collision-monitor-dynamic-radius-for-circle-type-polygons)\n  * [ Simple Commander API ](../../commander_api/index.html)\n    * [ Overview ](../../commander_api/index.html#overview)\n    * [ Commander API ](../../commander_api/index.html#id1)\n    * [ Costmap API ](../../commander_api/index.html#costmap-api)\n    * [ Footprint Collision Checker API ](../../commander_api/index.html#footprint-collision-checker-api)\n    * [ Examples and Demos ](../../commander_api/index.html#examples-and-demos)\n  * [ Roadmaps ](../../roadmap/roadmap.html)\n    * [ Jazzy Roadmap ](../../roadmap/roadmap.html#jazzy-roadmap)\n    * [ Iron Roadmap ](../../roadmap/roadmap.html#iron-roadmap)\n    * [ Humble Roadmap ](../../roadmap/roadmap.html#humble-roadmap)\n  * [ About and Contact ](../../about/index.html)\n    * [ Related Projects ](../../about/related_projects.html)\n    * [ About ](../../about/index.html#id1)\n    * [ Contact ](../../about/index.html#contact)\n\n__ [ Nav2 ](../../index.html)\n\n[ Edit ](https://github.com/ros-planning/navigation.ros.org)\n\n  * [ ](../../index.html)\n  * [ General Tutorials ](../index.html)\n  * Using Collision Monitor \n  * \n\n* * *\n\n#  Using Collision Monitor  \u00b6\n\n  * Overview \n\n  * Requirements \n\n  * Preparing Nav2 stack \n\n  * Configuring Collision Monitor \n\n  * Configuring Collision Monitor with VelocityPolygon \n\n  * Demo Execution \n\n[ ![../../_images/collision_monitor.gif](../../_images/collision_monitor.gif)\n](../../_images/collision_monitor.gif)\n\n##  Overview  \u00b6\n\nThis tutorial shows how to use a Collision Monitor with Nav2 stack. Based on\nthis tutorial, you can setup it for your environment and needs.\n\n##  Requirements  \u00b6\n\nIt is assumed ROS2 and Nav2 dependent packages are installed or built locally.\nPlease make sure that Nav2 project is also built locally as it was made in [\nBuild and Install  ](../../development_guides/build_docs/index.html#build-\ninstructions) .\n\n##  Configuring Collision Monitor  \u00b6\n\nThe Collision Monitor node has its own ` collision_monitor_node.launch.py  `\nlaunch-file and preset parameters in the ` collision_monitor_params.yaml  `\nfile for demonstration, though its trivial to add this to Nav2\u2019s main launch\nfile if being used in practice. For the demonstration, two shapes will be\ncreated - an inner stop and a larger slowdown bounding boxes placed in the\nfront of the robot:\n\n[ ![../../_images/polygons.png](../../_images/polygons.png)\n](../../_images/polygons.png)\n\nIf more than 3 points will appear inside a slowdown box, the robot will\ndecrease its speed to ` 30%  ` from its value. For the cases when obstacles\nare dangerously close to the robot, inner stop zone will work. For this setup,\nthe following lines should be added into ` collision_monitor_params.yaml  `\nparameters file. Stop box is named as ` PolygonStop  ` and slowdown bounding\nbox - as ` PolygonSlow  ` :\n\n    \n    \n    polygons: [\"PolygonStop\", \"PolygonSlow\"]\n    PolygonStop:\n      type: \"polygon\"\n      points: \"[[0.4, 0.3], [0.4, -0.3], [0.0, -0.3], [0.0, 0.3]]\"\n      action_type: \"stop\"\n      min_points: 4  # max_points: 3 for Humble\n      visualize: True\n      polygon_pub_topic: \"polygon_stop\"\n    PolygonSlow:\n      type: \"polygon\"\n      points: \"[[0.6, 0.4], [0.6, -0.4], [0.0, -0.4], [0.0, 0.4]]\"\n      action_type: \"slowdown\"\n      min_points: 4  # max_points: 3 for Humble\n      slowdown_ratio: 0.3\n      visualize: True\n      polygon_pub_topic: \"polygon_slowdown\"\n    \n\nNote\n\nThe circle shape could be used instead of polygon, e.g. for the case of omni-\ndirectional robots where the collision can occur from any direction. However,\nfor the tutorial needs, let\u2019s focus our view on polygons. For the same reason,\nwe leave out of scope the Approach model. Both of these cases could be easily\nenabled by referencing to the [ Collision Monitor\n](../../configuration/packages/configuring-collision-monitor.html#configuring-\ncollision-monitor) configuration guide.\n\nNote\n\nBoth polygon shapes in the tutorial were set statically. However, there is an\nability to dynamically adjust them over time using topic messages containing\nvertices points for polygons or footprints. For more information, please refer\nto the configuration guide.\n\nFor the working configuration, at least one data source should be added. In\ncurrent demonstration, it is used laser scanner (though ` PointCloud2  ` and\nRange/Sonar/IR sensors are also possible), which is described by the following\nlines for Collision Monitor node:\n\n    \n    \n    observation_sources: [\"scan\"]\n    scan:\n      type: \"scan\"\n      topic: \"scan\"\n    \n\nSet topic names, frame ID-s and timeouts to work correctly with a default Nav2\nsetup. The whole ` nav2_collision_monitor/params/collision_monitor_params.yaml\n` file in this case will look as follows:\n\n    \n    \n    collision_monitor:\n      ros__parameters:\n        use_sim_time: True\n        base_frame_id: \"base_footprint\"\n        odom_frame_id: \"odom\"\n        cmd_vel_in_topic: \"cmd_vel_smoothed\"\n        cmd_vel_out_topic: \"cmd_vel\"\n        transform_tolerance: 0.5\n        source_timeout: 5.0\n        stop_pub_timeout: 2.0\n        enable_stamped_cmd_vel: False\n        polygons: [\"PolygonStop\", \"PolygonSlow\"]\n        PolygonStop:\n          type: \"polygon\"\n          points: \"[[0.4, 0.3], [0.4, -0.3], [0.0, -0.3], [0.0, 0.3]]\"\n          action_type: \"stop\"\n          min_points: 4  # max_points: 3 for Humble\n          visualize: True\n          polygon_pub_topic: \"polygon_stop\"\n        PolygonSlow:\n          type: \"polygon\"\n          points: \"[[0.6, 0.4], [0.6, -0.4], [0.0, -0.4], [0.0, 0.4]]\"\n          action_type: \"slowdown\"\n          min_points: 4  # max_points: 3 for Humble\n          slowdown_ratio: 0.3\n          visualize: True\n          polygon_pub_topic: \"polygon_slowdown\"\n        observation_sources: [\"scan\"]\n        scan:\n          type: \"scan\"\n          topic: \"scan\"\n    \n\n##  Configuring Collision Monitor with VelocityPolygon  \u00b6\n\n[\n![../../_images/dexory_velocity_polygon.gif](../../_images/dexory_velocity_polygon.gif)\n](../../_images/dexory_velocity_polygon.gif)\n\nFor this part of tutorial, we will set up the Collision Monitor with `\nVelocityPolygon  ` type for a ` stop  ` action. ` VelocityPolygon  ` allows\nthe user to setup multiple polygons to cover the range of the robot\u2019s velocity\nlimits. For example, the user can configure different polygons for rotation,\nmoving forward, or moving backward. The Collision Monitor will check the\nrobot\u2019s velocity against each sub polygon to determine the approriate polygon\nto be used for collision checking.\n\nIn general, here are the steps to configure the Collision Monitor with `\nVelocityPolygon  ` type:\n\n  1. Add a ` VelocityPolygon  ` to the ` polygons  ` param list \n\n  2. Configure the ` VelocityPolygon  `\n\n  3. Specify the ` holonomic  ` property of the polygon (default is ` false  ` ) \n\n  4. Start by adding a ` stopped  ` sub polygon to cover the full range of the robot\u2019s velocity limits in ` velocity_polygons  ` list \n\n  5. Add additional sub polygons to the front of the ` velocity_polygons  ` list to cover the range of the robot\u2019s velocity limits for each type of motion (e.g. rotation, moving forward, moving backward) \n\nIn this example, we will consider a **non-holonomic** robot with linear\nvelocity limits of ` -1.0  ` to ` 1.0  ` m/s and angular velocity limits of `\n-1.0  ` to ` 1.0  ` rad/s. The ` linear_min  ` and ` linear_max  ` parameters\nof the sub polygons should be set to the robot\u2019s linear velocity limits, while\nthe ` theta_min  ` and ` theta_max  ` parameters should be set to the robot\u2019s\nangular velocity limits.\n\nBelow is the example configuration using 4 sub-polygons to cover the full\nrange of the robot\u2019s velocity limits:\n\n    \n    \n    polygons: [\"VelocityPolygonStop\"]\n    VelocityPolygonStop:\n      type: \"velocity_polygon\"\n      action_type: \"stop\"\n      min_points: 6\n      visualize: True\n      enabled: True\n      polygon_pub_topic: \"velocity_polygon_stop\"\n      velocity_polygons: [\"rotation\", \"translation_forward\", \"translation_backward\", \"stopped\"]\n      holonomic: false\n      rotation:\n        points: \"[[0.3, 0.3], [0.3, -0.3], [-0.3, -0.3], [-0.3, 0.3]]\"\n        linear_min: 0.0\n        linear_max: 0.05\n        theta_min: -1.0\n        theta_max: 1.0\n      translation_forward:\n        points: \"[[0.35, 0.3], [0.35, -0.3], [-0.2, -0.3], [-0.2, 0.3]]\"\n        linear_min: 0.0\n        linear_max: 1.0\n        theta_min: -1.0\n        theta_max: 1.0\n      translation_backward:\n        points: \"[[0.2, 0.3], [0.2, -0.3], [-0.35, -0.3], [-0.35, 0.3]]\"\n        linear_min: -1.0\n        linear_max: 0.0\n        theta_min: -1.0\n        theta_max: 1.0\n      # This is the last polygon to be checked, it should cover the entire range of robot's velocities\n      # It is used as the stopped polygon when the robot is not moving and as a fallback if the velocity\n      # is not covered by any of the other sub-polygons\n      stopped:\n        points: \"[[0.25, 0.25], [0.25, -0.25], [-0.25, -0.25], [-0.25, 0.25]]\"\n        linear_min: -1.0\n        linear_max: 1.0\n        theta_min: -1.0\n        theta_max: 1.0\n    \n\nNote\n\nIt is recommended to include a ` stopped  ` sub polygon as the last entry in\nthe ` velocity_polygons  ` list to cover the entire range of the robot\u2019s\nvelocity limits. In cases where the velocity is not within the scope of any\nsub polygons, the Collision Monitor will log a warning message and continue\nwith the previously matched polygon.\n\nNote\n\nWhen velocity is covered by multiple sub polygons, the first sub polygon in\nthe list will be used.\n\n**For holomic robots:**\n\nFor holomic robots, the ` holonomic  ` property should be set to ` true  ` .\nIn this scenario, the ` linear_min  ` and ` linear_max  ` parameters should\ncover the robot\u2019s resultant velocity limits, while the ` theta_min  ` and `\ntheta_max  ` parameters should cover the robot\u2019s angular velocity limits.\nAdditionally, there will be 2 more parameters, ` direction_start_angle  ` and\n` direction_end_angle  ` , to specify the resultant velocity direction. The\ncovered direction will always span from ` direction_start_angle  ` to `\ndirection_end_angle  ` in the **counter-clockwise** direction.\n\n[\n![../../_images/holonomic_direction.png](../../_images/holonomic_direction.png)\n](../../_images/holonomic_direction.png)\n\nBelow shows some common configurations for holonomic robots that cover\nmultiple directions of the resultant velocity:\n\n[\n![../../_images/holonomic_examples1.png](../../_images/holonomic_examples1.png)\n](../../_images/holonomic_examples1.png)\n\n##  Preparing Nav2 stack  \u00b6\n\nThe Collision Monitor is designed to operate below Nav2 as an independent\nsafety node. It acts as a filter for the ` cmd_vel  ` messages from the\ncontroller to avoid potential collisions. If no such zone is triggered, then\nthe ` cmd_vel  ` message is used. Else, it is scaled or set to stop as\nappropriate.\n\nBy default, the Collision Monitor is configured for usage with the Nav2\nbringup package, running in parallel with the ` navigation_launch.py  ` launch\nfile. For correct operation of the Collision Monitor with the Velocity\nSmoother, it is required to remove the Velocity Smoother\u2019s ` cmd_vel_smoothed\n` remapping in the ` navigation_launch.py  ` bringup script as presented\nbelow. This will make the output topic of the Velocity Smoother to be\nuntouched, which will be the input to the newly added Collision Monitor:\n\n    \n    \n    Node(\n        package='nav2_velocity_smoother',\n        executable='velocity_smoother',\n        name='velocity_smoother',\n        output='screen',\n        respawn=use_respawn,\n        respawn_delay=2.0,\n        parameters=[configured_params],\n        arguments=['--ros-args', '--log-level', log_level],\n        remappings=remappings +\n    -           [('cmd_vel', 'cmd_vel_nav'), ('cmd_vel_smoothed', 'cmd_vel')]),\n    +           [('cmd_vel', 'cmd_vel_nav')]),\n    ...\n    ComposableNode(\n        package='nav2_velocity_smoother',\n        plugin='nav2_velocity_smoother::VelocitySmoother',\n        name='velocity_smoother',\n        parameters=[configured_params],\n        remappings=remappings +\n    -              [('cmd_vel', 'cmd_vel_nav'), ('cmd_vel_smoothed', 'cmd_vel')]),\n    +              [('cmd_vel', 'cmd_vel_nav')]),\n    \n\nIf you have changed Collision Monitor\u2019s default ` cmd_vel_in_topic  ` and `\ncmd_vel_out_topic  ` configuration, make sure Velocity Smoother\u2019s default\noutput topic ` cmd_vel_smoothed  ` should match to the input velocity `\ncmd_vel_in_topic  ` parameter value of the Collision Monitor node, and the\noutput velocity ` cmd_vel_out_topic  ` parameter value should be actual `\ncmd_vel  ` to fit the replacement.\n\nNote\n\nAs the Collision Monitor acts as a safety node, it must be the last link in\nthe velocity message post-processing chain, making it the node that publishes\nto the ` cmd_vel  ` topic. It could be placed after smoothed velocity, as in\nour demonstration, or after non-smoothed velocity from Controller Server, e.g.\nif Velocity Smoother was not enabled in the system, or going after any other\nmodule in custom configuration producing the end-velocity. Therefore, in any\ncustom Nav2 launch configuration, the last node publishing to the ` cmd_vel  `\ntopic, should be remapped to publish to the Collision Monitor input topic\nconfigured by ` cmd_vel_in_topic  ` ROS-parameter ( ` cmd_vel_smoothed  ` by\ndefault).\n\n##  Demo Execution  \u00b6\n\nOnce Collision Monitor node has been tuned and ` cmd_vel  ` topics adjusted,\nCollision Monitor node is ready to run. For that, run Nav2 stack as written in\n[ Getting Started  ](../../getting_started/index.html#getting-started) :\n\n    \n    \n    ros2 launch nav2_bringup tb3_simulation_launch.py headless:=False\n    \n\nIn parallel console, launch Collision Monitor node by using its launch-file:\n\n    \n    \n    ros2 launch nav2_collision_monitor collision_monitor_node.launch.py\n    \n\nSince both ` PolygonStop  ` and ` PolygonSlow  ` polygons will have their own\npublishers, they could be added to visualization as shown at the picture\nbelow:\n\n[\n![../../_images/polygons_visualization.png](../../_images/polygons_visualization.png)\n](../../_images/polygons_visualization.png)\n\nSet the initial pose and then put Nav2 goal on map. The robot will start its\nmovement, slowing down while running near the obstacles, and stopping in close\nproximity to them:\n\n[ ![../../_images/collision.png](../../_images/collision.png)\n](../../_images/collision.png)\n\n* * *\n\n\u00a9 Copyright 2023.\n\n"
  },
  {
    "id": "ackermann/userdochtml.txt",
    "content": "[ ![Logo](../../../../_static/logo_ros-controls.png) ](../../../../index.html)\n  * [ Getting Started ](../../../getting_started/getting_started.html)\n  * [ ros2_control ](../../../ros2_control/doc/index.html)\n  * [ ros2_controllers ](../../doc/controllers_index.html)\n    * [ Guidelines and Best Practices ](../../doc/controllers_index.html#guidelines-and-best-practices)\n    * [ Controllers for Mobile Robots ](../../doc/controllers_index.html#controllers-for-mobile-robots)\n      * Ackermann Steering Controller \n        * Parameters \n      * [ Bicycle Steering Controller ](../../bicycle_steering_controller/doc/userdoc.html)\n      * [ Differential Drive Controller ](../../diff_drive_controller/doc/userdoc.html)\n      * [ Steering Controllers Library ](../../steering_controllers_library/doc/userdoc.html)\n      * [ Tricycle Controller ](../../tricycle_controller/doc/userdoc.html)\n      * [ Tricycle Steering Controller ](../../tricycle_steering_controller/doc/userdoc.html)\n    * [ Controllers for Manipulators and Other Robots ](../../doc/controllers_index.html#controllers-for-manipulators-and-other-robots)\n    * [ Broadcasters ](../../doc/controllers_index.html#broadcasters)\n    * [ Common Controller Parameters ](../../doc/controllers_index.html#common-controller-parameters)\n  * [ Demos ](../../../ros2_control_demos/doc/index.html)\n  * [ Command Line Interface ](../../../ros2_control/ros2controlcli/doc/userdoc.html)\n  * [ Simulator Integrations ](../../../simulators/simulators.html)\n  * [ Migration Guides ](../../../migration/migration.html)\n  * [ Supported Robots ](../../../supported_robots/supported_robots.html)\n  * [ Resources ](../../../resources/resources.html)\n  * [ Contributing ](../../../contributing/contributing.html)\n  * [ Project Ideas for GSoC 2024 ](../../../project_ideas.html)\n  * [ Acknowledgements ](../../../acknowledgements/acknowledgements.html)\n__ [ ROS2_Control: Rolling ](../../../../index.html)\n  * [ ](../../../../index.html)\n  * [ ros2_controllers ](../../doc/controllers_index.html)\n  * ackermann_steering_controller \n  * [ Edit on GitHub ](https://github.com/ros-controls/ros2_controllers/blob/master/ackermann_steering_controller/doc/userdoc.rst)\n* * *\n**You're reading the documentation for a development version. For the latest\nreleased version, please have a look at[ Iron\n](../../../../../iron/doc/ros2_controllers/ackermann_steering_controller/doc/userdoc.html)\n. **\n#  ackermann_steering_controller  \uf0c1\nThis controller implements the kinematics with two axes and four wheels, where\nthe wheels on one axis are fixed (traction/drive) wheels, and the wheels on\nthe other axis are steerable.\nThe controller expects to have two commanding joints for traction, one for\n\n\n\neach fixed wheel and two commanding joints for steering, one for each wheel.\nFor more details on controller\u2019s execution and interfaces check the [ Steering\nController Library\n](../../steering_controllers_library/doc/userdoc.html#steering-controllers-\nlibrary-userdoc) .\n##  Parameters  \uf0c1\nThis controller uses the [ generate_parameter_library\n](https://github.com/PickNikRobotics/generate_parameter_library) to handle its\nparameters.\nFor an exemplary parameterization see the ` test  ` folder of the controller\u2019s\npackage.\nAdditionally to the parameters of the [ Steering Controller Library\n](../../steering_controllers_library/doc/userdoc.html#parameters) , this\ncontroller adds the following parameters:\nfront_wheel_track (double)\n    \nFront wheel track length. For details see: [\nhttps://en.wikipedia.org/wiki/Wheelbase\n](https://en.wikipedia.org/wiki/Wheelbase)\nDefault: 0.0\nrear_wheel_track (double)\n    \nRear wheel track length. For details see: [\nhttps://en.wikipedia.org/wiki/Wheelbase\n](https://en.wikipedia.org/wiki/Wheelbase)\nDefault: 0.0\nwheelbase (double)\n    \nDistance between front and rear wheels. For details see: [\nhttps://en.wikipedia.org/wiki/Wheelbase\n](https://en.wikipedia.org/wiki/Wheelbase)\nDefault: 0.0\nfront_wheels_radius (double)\n    \nFront wheels radius.\nDefault: 0.0\nrear_wheels_radius (double)\n    \nRear wheels radius.\nDefault: 0.0\n\n\n\n[ Previous ](../../doc/writing_new_controller.html \"Writing a new controller\")\n[ Next  ](../../bicycle_steering_controller/doc/userdoc.html\n\"bicycle_steering_controller\")\n* * *\n\u00a9 Copyright 2024, ros2_control Development Team.\nBuilt with [ Sphinx ](https://www.sphinx-doc.org/) using a [ theme\n](https://github.com/readthedocs/sphinx_rtd_theme) provided by [ Read the Docs\n](https://readthedocs.org) .\nOther Versions  v: master\nReleases\n     [ Iron (latest) ](../../../../../iron/doc/ros2_controllers/ackermann_steering_controller/doc/userdoc.html)\n  \n     [ Humble ](../../../../../humble/doc/ros2_controllers/ackermann_steering_controller/doc/userdoc.html)\n  \n     [ Galactic (EOL) ](../../../../../galactic/index.html)\n  \n     [ Foxy (EOL) ](../../../../../foxy/index.html)\n  \nIn Development\n     [ Master ](userdoc.html)\n\n\n"
  },
  {
    "id": "message_type/indexmsghtml.txt",
    "content": "#  geometry_msgs Msg/Srv Documentation\nSee also:\n  * [ Website ](http://wiki.ros.org/geometry_msgs)\n  * [ Code API Documentation ](index.html)\n##  Message types\n  * [ Accel ](msg/Accel.html)\n  * [ AccelStamped ](msg/AccelStamped.html)\n  * [ AccelWithCovariance ](msg/AccelWithCovariance.html)\n  * [ AccelWithCovarianceStamped ](msg/AccelWithCovarianceStamped.html)\n  * [ Inertia ](msg/Inertia.html)\n  * [ InertiaStamped ](msg/InertiaStamped.html)\n  * [ Point ](msg/Point.html)\n  * [ Point32 ](msg/Point32.html)\n  * [ PointStamped ](msg/PointStamped.html)\n  * [ Polygon ](msg/Polygon.html)\n  * [ PolygonStamped ](msg/PolygonStamped.html)\n  * [ Pose ](msg/Pose.html)\n  * [ Pose2D ](msg/Pose2D.html)\n  * [ PoseArray ](msg/PoseArray.html)\n  * [ PoseStamped ](msg/PoseStamped.html)\n  * [ PoseWithCovariance ](msg/PoseWithCovariance.html)\n  * [ PoseWithCovarianceStamped ](msg/PoseWithCovarianceStamped.html)\n  * [ Quaternion ](msg/Quaternion.html)\n  * [ QuaternionStamped ](msg/QuaternionStamped.html)\n  * [ Transform ](msg/Transform.html)\n  * [ TransformStamped ](msg/TransformStamped.html)\n  * [ Twist ](msg/Twist.html)\n  * [ TwistStamped ](msg/TwistStamped.html)\n  * [ TwistWithCovariance ](msg/TwistWithCovariance.html)\n  * [ TwistWithCovarianceStamped ](msg/TwistWithCovarianceStamped.html)\n  * [ Vector3 ](msg/Vector3.html)\n  * [ Vector3Stamped ](msg/Vector3Stamped.html)\n  * [ Wrench ](msg/Wrench.html)\n  * [ WrenchStamped ](msg/WrenchStamped.html)\n_autogenerated on Wed, 02 Mar 2022 00:06:53_\n\n\n"
  },
  {
    "id": "path_planning/p113.txt",
    "content": "Permission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed for\nprofit or commercial advantage and that copies bear this notice and the full citation on the\nfirst page. Copyrights for components of this work owned by others than ACM must be\nhonored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on\nservers or to redistribute to lists, requires prior specific permission and/or a fee.\nRequest permissions from Permissions@acm.org.\nMIG '15, November 16 \u2013 18, 2015, Paris, France.\n\u00a9 2015 ACM. ISBN 978-1-4503-3991-9/15/11\u2026$15.00\nDOI: http://dx.doi.org/10.1145/2822013.2822036\nRT-RRT*: A Real-Time Path Planning Algorithm Based On RRT*\nKourosh Naderi\u2217\nJoose Rajamaki \u00a8\n\u2020 Perttu Ham\u00a8 al\u00a8 ainen \u00a8\n\u2021\nAalto University\nFigure 1: Bold lines and shaded circles denote paths from the agent to different goals and dynamic obstacles, respectively. In Figure (a) the\ntree is growing and a path to the goal point is found. In Figures (b) and (c) the goal point is changed on the fly. In both cases since the tree\nroot moves with the agent and the tree covers most of the environment, the paths to the changed goals are returned quickly. In Figure (d) the\nagent has reached the goal point and rewiring of the nodes based on the current location of the tree root has generated the minimum length\npaths to others nodes of the tree. The crossed points denote the Rewiring Circle.\nAbstract\nThis paper presents a novel algorithm for real-time path-planning in\na dynamic environment such as a computer game. We utilize a realtime sampling approach based on the Rapidly Exploring Random\nTree (RRT) algorithm that has enjoyed wide success in robotics.\nMore specifically, our algorithm is based on the RRT* and informed RRT* variants. We contribute by introducing an online tree\nrewiring strategy that allows the tree root to move with the agent\nwithout discarding previously sampled paths. Our method also does\nnot have to wait for the tree to be fully built, as tree expansion and\ntaking actions are interleaved. To our knowledge, this is the first\nreal-time variant of RRT*.\nWe demonstrate our method, dubbed Real-Time RRT* (RT-RRT*),\nin navigating a maze with moving enemies that the controlled agent\nis required to avoid within a predefined radius. Our method finds\npaths to new targets considerably faster when compared to CL-RRT,\na previously proposed real-time RRT variant.\nCR Categories: I.2.8 [Computing methodologies]: Artificial\nIntelligence\u2014Problem Solving, Control Methods, and Search I.2.9\n[Computing methodologies]: Artificial Intelligence\u2014Robotics\nKeywords: Real-time path planning, RRT*, dynamic environment, multiple-query planning\n\n\n\n\u2217e-mail:kourosh.naderi@aalto.fi\n\u2020\ne-mail:joose.rajamaki@aalto.fi\n\u2021\ne-mail:perttu.hamalainen@aalto.fi\n1 Introduction\nPath planning in dynamic environments is a demanding problem\nencountered in many robotic tasks and computer games [Rastgoo\net al. 2014; Sud et al. 2008]. Real-time path planning algorithms\nare used to react to the changes in the environment as well as to\nconstantly look for a better path to the goal point. These algorithms\nhave to balance with the trade-off of the goodness of the path versus\nhaving a short search time. The path planning problem gets even\nmore challenging when changing the goal point is allowed, which\nis the case in many multiple-query tasks [Kavraki et al. 1996], e.g.\ncomputer games. Difficulty in path planning arises also when the\nstructure of the agent gets more sophisticated and controlling the\nagent is not trivial [Sud et al. 2008], e.g. planning a path for a\nhumanoid agent [Gutmann et al. 2005].\nMany of the current approaches for solving the real-time path planning problem fall into the categories of heuristic methods [Gutmann et al. 2005], potential field methods [Khatib 1986] and sampling methods like rapidly exploring random trees (RRTs) [LaValle\n1998]. A survey of approaches to real-time path planning in dynamic environment can be found in [Rastgoo et al. 2014]. Most\nof the algorithms used in the games industry stem from the A\u2217\nalgorithm. The A\u2217\nalgorithm, however, faces prolonged search time\nin an environment that has many complex obstacles. The real-time\nversions of A\u2217\nalgorithm inherit this problem and try to solve it using various methods [Cannon et al. 2012; Sturtevant et al. 2010].\nFurthermore, A\u2217\nneeds discretization of the environment whose\nresolution has a strong effect on the search time. Although in [Cannon et al. 2012] the algorithm samples for building a graph, the\nnumber of samples for finding a path between nodes increases such\nthat it may affect the real-time response time of the algorithm for\ntaking an action. The response time of the potential field algorithms\nis in real-time, however they suffer from trapping into local minima.\nRapidly exploring random trees (RRTs) quickly expand a search\ntree in an environment. They are efficient for single-query tasks in\na continuous environment, i.e. when the goal point is fixed. The\ndifferent real time variants of RRT path planning either regrow the\nwhole tree with guidance of the previous iteration for a limited time\n113\n\n\n\n[Bruce and Veloso 2002] or prune infeasible branches of the tree after changing its root [Luders et al. 2010]. Unlike these algorithms,\nour proposed algorithm retains the whole tree in the environment\nand rewires the nodes of the tree based on the location of the tree\nroot and changes in the dynamic obstacles. Consequently, our algorithm enables the user to rapidly switch the goal point around\n(multiple-query task) by efficiently using the expanded tree in the\nenvironment (see Fig 1). To the best of our knowledge, our algorithm is the first real-time RRT-based algorithm that retains the\nwhole tree, gradually rewires different parts of the tree, and works\nefficiently in multiple query tasks.\nIn the following, we first provide a brief review of the relevant literature on real-time path planning algorithms in Section 2. Section\n3 formally defines the real-time path planning problem and introduces the related notation. A description of our proposed RT-RRT*\nmethod and our simulation experiments then follow in Sections 4\nand 5. The simulations indicate that our method outperforms CLRRT which can be considered the state-of-the-art of real-time RRTbased path planning methods.\n2 Related Work\nIn this section we first review the relevant literature regarding tree\nbased algorithms for path planning and in the latter subsection we\nintroduce the currently used approaches to real-time path planning.\n2.1 RRTs and their extensions\nRRTs sample points in the space and add them to a tree which\ngrows to the whole planning space. RRTs [LaValle 1998] have the\nuseful properties of: 1) covering the whole space efficiently and\nquickly; 2) probabilistic completeness i.e. as the number of nodes\nin the tree increases, the probability of finding a solution approaches\none. However, RRTs are not asymptotically optimal and rewiring is\nnot performed in the RRT algorithm, i.e. the connections between\nnodes are set once. The emergence of RRT* [Karaman and Frazzoli 2011] changed this as it allows to rewire the tree connections\nsuch that the path length from the root to a leaf is reduced. RRT*\nis asymptotically optimal, but its convergence is slow especially in\nlarge environments. Informed RRT* [Gammell et al. 2014] introduced a focused sampling method that samples new nodes inside an\nellipsoid. The focal points of the ellipsoid are the starting and goal\npoints. This method increased the convergence rate of RRT* especially in large environments. In this paper, we combine the good\naspects of RRT variants and we introduce real-time path planning\nthat is based on RRT* and Informed RRT*.\n2.2 Real-time Path Planning methods\nTree Based Path Planning methods mostly stem from RRTs.\nTwo of these methods are ERRT [Bruce and Veloso 2002] and CLRRT [Luders et al. 2010]. The tree of these algorithms covers a\nsmall portion of the environment. Therefore, they only use the tree\nas a look-ahead in their path planning, which reduces the search\ntime but increases the length of the path to the goal. At each iteration ERRT creates a tree using some way-points of the previous\niteration. CL-RRT on the other hand ensures that the agent will not\ndeviate from the planned path and prunes infeasible branches when\n\n\n\nthe agent moves on the tree. Contrary to these methods, we retain\nthe tree between the iterations and change the tree root when the\nagent moves. Also, we rewire the tree when the tree root changes\nor a dynamic obstacle blocks a node. As a result, our method needs\nvery few iterations to search for a path to various goal points as\nthe tree grows, and the paths to those goal points are shorter compared to CL-RRT (see Section 5). This also makes our method\nsuitable for multi-query tasks, i.e. querying paths to multiple goals,\nwhich is highly preferable algorithm quality e.g. in games. The first\nreal-time motion re-planning on RRT* is RRTX [Otte and Frazzoli\n2015]. As opposed to RRTX, our method is designed for multiquery tasks, which plans paths from agent to goals, and interleaves\ntree expansion and rewiring with taking actions.\nPotential Based Path Planning methods treat the environment\nas a potential field such that the goal point attracts and the obstacles\nrepulse the agent. These methods stem from the original Artificial\nPotential Field (APF) introduced in [Khatib 1986]. In spite of being useful as a real-time path planning, these methods suffer from\ntrapping into local minima. Thus, potential field methods need additional effort to overcome the problem of local minima as well as\nto find a minimum length path to the goal point.\nGraph Based Path Planning methods usually make a grid of\nthe environment and apply real-time versions of A\u2217\nto it. Some\nof the methods simply divide the environment into simple polygonal grids [Sturtevant et al. 2010; Gutmann et al. 2005]. On the\nother hand, there are some methods that use Voronoi diagram [Sud\net al. 2008] or sampling [Cannon et al. 2012] to build a graph representing the environment. One disadvantage of graph based over\ntree based path planning is that even though the environment is explored and a graph representing it is constructed, one needs further processing, such as A\u2217\n, to extract the path from the graph. In\nmulti-query tasks, graph based path planning methods may need to\nsearch the entire graph to find a path to different goal points. Unlike\nthis, our proposed algorithm needs fewer iterations for finding goal\npoints as the tree grows in the environment. Besides, RT-RRT* utilizes the efficient tree structure to return a path to possibly multiple\ngoal points by backtracking the ancestors from the goal.\n3 Problem Statement and Notations\nLet us denote the work space, where path planning is done, by X .\nIn our algorithm X can be subset of R\n2\nor R\n3\n. However, without\nloss of generality in this paper we only consider X \u2286 R\n2\n. Also,\n\n\n\nX is considered to be bounded. Besides spaces such as X , the\ncalligraphy alphabet is used to refer to sets. X contains obstacles,\nwhich may be dynamic. Xobs ( X denotes the set of all obstacles in\nthe environment, and we assume it is known. Thus, the free space\nis denoted by Xfree = X \\ Xobs. The tree is denoted by T and each\nnode inside it is represented by xi \u2208 Xfree. The current tree root\nis denoted by x0 which is changed when the agent moves. In the\npath planning algorithm the set of planned nodes is represented by\n(x0, x1, ..., xk) in which k is the user-defined limit for planning a\npath ahead from x0. Besides nodes, x is used in our algorithm to\ndenote any positions in the environment. For example, xgoal \u2208 Xfree\nrepresents the goal point, which can be changed by the user. xa \u2208\nXfree is the position of the agent.\nWe formulate the problem of real-time path planning in dynamic\nenvironments as follows. We want to find a path, i.e. (x0, x1,\n..., xgoal), from the agent to xgoal where xgoal can be changed on\nthe fly (see Fig 1). Also, the path to xgoal should be of minimum\nlength. For finding a minimal length path, we use cost-to-reach values (denoted by ci) which are computed using the Euclidean length\nof the path from x0 to xi. Furthermore, we restrict our algorithm\nto be real-time. This means that we have a limited amount of time\nfor Tree Expansion-and-Rewiring and Path Planning with the expanded tree. In real-time path planning it is important to have a\nreal-time response whether or not we have a path to the goal. When\nthe tree is growing and xgoal is not found, we use the cost function\nfi = ci + hi to plan a path from x0 to a point close to xgoal. hi\n114\ndenotes cost-to-go values from xi to xgoal and is computed using\nEuclidean distance between these two nodes. Note that, when time\nfor path planning is up, next immediate node after x0 in the planned\npath, x1, is committed and should be followed.\nIn multi-query tasks, each point in Xfree of the environment has the\npotential of being xgoal while dynamic obstacles are moving around\nand may block some paths. In our algorithm we change x0 when the\nagent moves to keep the agent near the tree root, and by retaining\nthe whole tree between iterations we can return a path to any point\nin the environment (see Fig 1). Therefore, our main problem is,\nhow to rewire the tree really fast and in a real-time manner to react\nto the changes in the environment (changes in Xobs) as well as to\nreturn a minimal length path to xgoal while xgoal can be any point in\nthe environment.\n4 Method\n\n\n\nOur method, which is introduced in Algorithm 1, interleaves path\nplanning with tree expansion and rewiring. We initialize the tree\nwith xa as its root (line 2). At each iteration, we expand and rewire\nthe tree for a limited user-defined time (lines 5-6). Then we plan a\npath from the current tree root for a limited user-defined amount of\nsteps further (k in line 7). The planned path is a set of nodes starting\nfrom the tree root, (x0, x1, ..., xk). At each iteration we move the\nagent for a limited time to keep it close to the tree root, x0 (line\n10). When path planning is done and the agent is at the tree root,\nwe change the tree root to the next immediate node after x0 in the\nplanned path, x1 (lines 8-9). Hence, we enable the agent to move\non the planned path on the tree towards the goal.\nAlgorithm 1 RT-RRT*: Our Real-Time Path Planning\n1: Input: xa, Xobs, xgoal\n2: Initialize T with xa, Qr, Qs\n3: loop\n4: Update xgoal, xa, Xfree and Xobs\n5: while time is left for Expansion and Rewiring do\n6: Expand and Rewire T using Algorithm 2\n7: Plan (x0, x1, ..., xk) to the goal using Algorithm 6\n8: if xa is close to x0 then\n9: x0 \u2190 x1\n10: Move the agent toward x0 for a limited time\n11: end loop\nAlgorithm 2 Tree Expansion-and-Rewiring\n1: Input: T , Qr, Qs, kmax, rs\n2: Sample xrand using (1)\n3: xclosest = arg minx\u2208XSI dist(x, xrand)\n4: if line(xclosest, xrand) \u2282 Xfree then\n5: Xnear = FindNodesNear(xrand, XSI)\n6: if |Xnear| < kmax or |xclosest \u2212 xrand| > rs then\n7: AddNodeToTree(T , xrand, xclosest, Xnear)\n8: Push xrand to the first of Qr\n9: else\n10: Push xclosest to the first of Qr\n11: RewireRandomNode(Qr, T )\n12: RewireFromRoot(Qs, T )\nQr, Qs are two different queues initialized in line 2 to be used for\nRewiring in Algorithm 2. Line 4 of Algorithm 1 updates the goal\npoint, position of the agent and the obstacles in the environment\n\n\n\nthat is used later in the Path Planning and the Tree Expansion-andRewiring algorithms. We use control particle belief propagation\nalgorithm (C-PBP) [Ham\u00a8 al\u00a8 ainen et al. 2015] in line 10 for mov- \u00a8\ning the agent to separate path planning and synthesizing the motions of the agent, a practice bearing resemblance to [Song et al.\n2014][Gutmann et al. 2005]. However, any other control algorithm\ncan be used for moving the agent. Sections 4.1 and 4.2 explain the\npreviously used Tree Expansion-and-Rewiring and Path Planning\nalgorithms, respectively.\n4.1 Tree Expansion and Rewiring\nTree Expansion-and-Rewiring is introduced in Algorithm 2. Sampled nodes, xrand in line 2, are added to the tree until it completely\ncovers the environment (line 7). The sampled node xrand is always\nused in rewiring random parts of the tree either around itself or\naround its closest node, xclosest (lines 8, 10, 11). This is needed because of the changes in the tree root and dynamic obstacles. Fig 1d\nshows the situation when the tree has stopped adding nodes. Line\n6 states the condition for this. kmax denotes maximum number of\nneighbors around a node such as xrand and rs is used for the maximum Euclidean distance allowed between the nodes in the tree.\nThese two values together control the density of the tree. Same as\nwith RRT*, Xnear in line 5 is the set of nodes neighboring xrand.\nLine 4 checks whether the path between xrand and xclosest is collision free or not. Lines 11 and 12 perform the two different rewiring\nmethods in a large tree with a changing tree root. Their operation is\nexplained in further depth in Section 4.1.2. What happens in line 7\nis explored in Section 4.1.1.\nRandom sampling: Sampling in line 2 of Algorithm 2 uses the\nfollowing equation. Pr is a random number between [0, 1] and \u03b1\nis a small user-given constant, e.g. 0.1. \u03b2 \u2208 R is for dividing the\nsampling between Uniform(X ) and Ellipsis(x0, xgoal) samplings.\nxrand =\n\uf8f1\n\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\nLineTo(xgoal) if Pr > 1 \u2212 \u03b1\nUniform(X ) if\n\uf8f1\n\uf8f2\n\uf8f3\nPr \u2264\n1 \u2212 \u03b1\n\u03b2\nor\n@path(x0, xgoal)\nEllipsis(x0, xgoal) otherwise\n\n\n\n(1)\nIn (1), LineTo(xgoal) samples randomly in the line between xgoal\nand the node of the tree that is closest to xgoal. Uniform(X ) samples the environment uniformly. Finally, Ellipsis(x0, xgoal) samples\ninside an ellipsis so that the path from x0 to xgoal is inside it. Same\nas Informed RRT* we need to sample the environment uniformly\nuntil we find a path to xgoal. Due to the changes in the tree root and\nxgoal in our algorithm, we constantly need to rewire random parts of\nthe tree and explore the environment for later queries in multi-query\ntasks. Thus, as opposed to Informed RRT*, when a path to xgoal is\nfound, we focus part of the sampling inside the Ellipsis instead of\nall of it. Therefore, we can efficiently rewire the paths to xgoal and\nto the other parts of the tree as well. To sample in the Ellipsis,\n[Gammell et al. 2014] sets x0 and xgoal as focal points of the ellipsis where its transverse and conjugate diameters equal to\np cbest and\nc\n2\nbest \u2212 c\n2\nmin. cbest is the length of the path from x0 to xgoal, and\ncmin is kx0 \u2212xgoalk2. One should notice that unlike Informed RRT*\nwe update the rotation of the ellipsis at every iteration because of\nthe changing tree root and goal point.\nTree Largeness: By retaining T between iterations, the tree\ngrows too large (but with a limited number of the nodes) to be handled wholly in real-time path planning. Instead, we use a subset of\nthe nodes, denoted by XSI. For the sake of simplicity and saving\nmemory we use grid-based spatial indexing (Fig 2 left), however\none might use KD-Tree spatial indexing to gain even more speed\nup. XSI is used to find xclosest and Xnear of xrand in Algorithm 2.\n115\nAlso, XSI is used in Algorithms 4 and 5 to search for Xnear around\nxr and xs, respectively. In addition, XSI is used to search for a node\ninside the goal region (rg) as well as to block every node inside the\nobstacle regions (rb) of the dynamic obstacles that are within the\ndistance of ro from the agent (see Fig 2).\nFigure 2: Adjacent grid squares for gu and for gi (Left). Obstacle\nand goal regions are denoted by rb and rg, respectively (Right).\nOnly effects of dynamic obstacles within the distance of ro from the\nagent are considered.\nIn order to work with XSI instead of the whole T , we divide the\nenvironment with a square grid (Fig 2 left). To find XSI around one\n\n\n\nnode (e.g. xu), we find the grid square gu, where xu is located.\nThen, we return all nodes of the tree that are inside gu and in its\nadjacent squares. A grid square gj is considered adjacent to other\ngrid square gi when gj is the closest grid square to gi which has at\nleast one node of the tree inside it. Fig 2 illustrates the difference\nbetween adjacent grid squares for gi and gu. Note that, the size of\nthe grid affects strongly the processing time and the size of XSI.\nAlso, each grid should be big enough to contain the obstacle region\naround each dynamic obstacle (see Section 5 for our obstacle and\ngrid details).\nBlocking Nodes by Dynamic Obstacles: When a dynamic obstacle blocks nodes inside itself, we set their cost-to-reach values\nci to infinity. As a result, all of the nodes of the branches which\nstem from nodes in the obstacle region get infinity ci value. Thus,\nwhen Rewiring algorithms are gradually and continuously connecting nodes with high ci to their neighbors to reduce their ci, rewiring\nwill create another path for nodes with infinite ci. Section 4.1.2\nexplains how rewiring the nodes in large trees is done. The computation of ci is explained in Section 4.1.1.\nNeighbor Radius: FindNodesNear in Algorithm 2, same as\nRRT*, returns the nodes in XSI that are at most at distance of \u03b5 from\nxrand. We want to have control over the expected amount of nodes\nthat FindNodesNear returns which should be kmax in Algorithm\n2. We know that kmax : ntotal equals \u00b5(B\u03b5) : \u00b5(X ) where A : B\nmeans ratio of A to B. ntotal denotes total number of the nodes\nin the tree. \u00b5(B\u03b5) is the volume/area of \u03b5-radius ball, in 2D this\nwould be \u03c0\u03b52\n. \u00b5(X ) is the volume/area of the search space. Thus,\n\u03b5 is calculated as follows:\n\u03b5 =\nr\n\u00b5(X )kmax\n\u03c0ntotal\n(2)\nIf \u03b5 in (2) becomes smaller than rs in Algorithm 2, we set \u03b5 to rs\nsince rs controls the closeness of the nodes. In Section 4.1.2 we use\nFindNodesNear to find Xnear of different nodes, and gradually\nspread rewiring through the entire tree. Spreading the rewiring is\ndirectly related to the closeness of nodes and the selection of the\nneighbor nodes Xnear. Thus, setting \u03b5 smaller than rs obstructs\nspreading the rewiring.\n4.1.1 Adding a Node to the Tree\nWhen we want to add xnew to the tree, same as with RRT*, Algorithm 3 finds the parent with the minimum cost-to-reach (ci) value\n\n\n\ninside Xnear (lines 2-6). One should note that the computation of ci\nis related to the length of the path from x0 to xi. Thus, cost(xi)\nneeds to compute ci whenever cj for any intermediate node in the\npath to xi is changed. Therefore, when cost(xi) is called, it will\nrecompute ci from xi up to x0 if a new node has been added to the\npath to xi (same as RRT*) or any changes in x0 or dynamic obstacles inside ro (see Fig 2) have happened (as opposed to RRT*).\nNote that whenever cost(xi) is called, if one of the ancestors of\nxi is blocked by a dynamic obstacle, i.e. ci = \u221e, we block that\nnode as well. The introduced cost(xi) is used in Algorithms 3-6.\nVT and ET denote sets of nodes and edges in the tree, respectively.\nNote that, when a node is added to the tree, 1) it expands the tree;\n2) if it is inside the goal region (Fig 2), a path to x0 is found (See\nSection 4.2); 3) we have to update the adjacent grid squares used\nfor grid based spatial indexing (See Section 4.1). Also, it should be\nnoted that we are using a tree structure to build the tree and each\nnode has access to its children and its parent. In other words, we\nuse ET only in the explanation.\nAlgorithm 3 Add Node To Tree\n1: Input: T , xnew, xclosest, Xnear\n2: xmin = xclosest, cmin = cost(xclosest) + dist(xclosest, xnew)\n3: for xnear \u2208 Xnear do\n4: cnew = cost(xnear) + dist(xnear, xnew)\n5: if cnew < cmin and line(xnear,xnew) \u2208 Xfree then\n6: cmin = cnew, xmin = xnear\n7: VT \u2190 VT \u222a {xnew}, ET \u2190 ET \u222a {xmin, xnew}\nAlgorithm 4 Rewire Random Nodes\n1: Input: Qr, T\n2: repeat\n3: xr=PopFirst(Qr), Xnear=FindNodesNear(xr, XSI)\n4: for xnear \u2208 Xnear do\n5: cold=cost(xnear), cnew=cost(xr)+dist(xr, xnear)\n6: if cnew < cold and line(xr, xnear) \u2208 Xfree then\n7: ET \u2190 (ET \\{Parent(xnear), xnear})\u222a{xr, xnear}\n8: Push xnear to the end of Qr\n9: until Time is up or Qr is empty.\nAlgorithm 5 Rewire From the Tree Root\n1: Input: Qs, T\n2: if Qs is empty then\n3: Push x0 to Qs\n4: repeat\n\n\n\n5: xs=PopFirst(Qs), Xnear=FindNodesNear(xs, XSI)\n6: for xnear \u2208 Xnear do\n7: cold=cost(xnear), cnew=cost(xs)+dist(xs, xnear)\n8: if cnew < cold and line(xs, xnear) \u2208 Xfree then\n9: ET \u2190 (ET \\{Parent(xnear), xnear})\u222a{xs, xnear}\n10: if xnear is not pushed to Qs after restarting Qs then\n11: Push xnear to the end of Qs\n12: until Time is up or Qs is empty.\n4.1.2 Rewiring The Tree\nRewiring is done when a node (xi) gets a lower cost-to-reach ci\nvalue by passing from another node instead of its parent. Thus, in\nour algorithm rewiring should be done around the new node (xnew)\nthat is added (same as RRT*) as well as around the already added\nnodes (as opposed to RRT*) due to changing the tree root (x0) and\n116\ndynamic obstacles. When x0 or any dynamic obstacle inside ro (see\nFig 2) changes, we need to rewire large portion of the tree which is\ndone by: 1) Rewiring a random part of the tree (Algorithm 4); 2)\nRewiring starting from the tree root (Algorithm 5).\nLines 3-7 and lines 5-9 of Algorithms 4 and 5 rewire neighbor nodes\n(Xnear) of xr and xs, respectively. Thus, rewiring is done in xnear if\nby changing its current parent to xj, ci for xnear reduces where xj is\nxr and xs in Algorithms 4 and 5, respectively. The difference between these algorithms is the focus point of the rewiring. Algorithm\n4 rewires random part of the tree starting from nodes around xrand\nor xclosest that are added to Qr in Algorithm 2. Then if rewiring happens to any xnear, Algorithm 4 adds xnear to Qr since nodes around\nxnear have the potential to get rewired (line 8). However, Algorithm\n5 focuses rewiring the tree around x0 and thus around the agent.\nHence, it starts rewiring from x0 (line 3) and pushes all its neighbor\nnodes to Qs. Then, it continues to push nodes with greater distance\nfrom x0 by popping nodes (xs) from Qs (line 5) and pushing xnear\naround xs (line 11) when the condition in line 10 is met. Using Qs\nallows us to rewire the neighbor nodes with the same ci values from\nx0. We refer to the nodes with the same cis as Rewiring Circle from\nx0 (see crossed points in Fig 1). Rewiring continues at each iteration until the condition in lines 9 and 12 of Algorithms 4 and 5 is\nmet, respectively. If time is up and there are still nodes in Qr or Qs\nthat should get rewired, we can continue rewiring in the upcoming\niterations.\nBy pushing nodes with the potential need of rewiring their neighbors to Qr, Algorithm 4 intensifies the effect of random sampling\nin line 2 of Algorithm 2. Also, by the combination of using Qr\nfor random rewiring with focusing sampling inside the Ellipsis that\n\n\n\ncontains the path from x0 to xgoal, we made it possible to rewire the\npath to xgoal very quickly. Note that, when rewiring is done on the\npath from x0 to xgoal, we need to update the path again (see Section 4.2). Using Qs in Algorithm 5, allows us to grow the Rewiring\nCircle between iterations. As the Rewiring Circle grows (supplemental video 00:40) every node inside this circle is rewired. Thus,\non the already expanded tree, a minimum path to every node in the\ncircle is created due to the circle that grows from x0. Note that,\nAlgorithm 5 only rewires on the already expanded tree and since\nthe tree is not complete in the beginning, it is possible that when a\nnew node is added to the tree, Algorithm 4 creates paths with lower\ncis to the nodes in the circle. Qs gets restarted when x0 is changed\nor a dynamic obstacle blocks a node with lower ci than cis of the\nnodes on the Rewiring Circle. In Algorithm 5, restarting Qs means\nwe need to rewire nodes from x0 again (line 10).\n4.2 Path Planning\nLine 7 in Algorithm 1 uses Algorithm 6 to plan a k-step path from\nx0. Algorithm 6 plans the path in two ways: 1) when tree reaches\nxgoal (lines 2-4) which happens when we expand the tree using Algorithm 3; 2) when the tree has not reached xgoal (lines 6-10). In\nthe first way, the path from xgoal up to x0 is in the tree and thus we\nonly need to update the path (line 3) when rewiring the path is done\nusing rewiring algorithms in Section 4.1.2. In the second way, we\nplan a path to get as close as possible to xgoal on the tree. We use\ncost function fi = ci + hi to get close to xgoal as well as to take\na short path on the growing tree. Thus, using fi can trap us in local minima. To prevent trapping in local minima and enable path\nplanning to visit other branches, we plan a k-step path using fi at\neach iteration (lines 6,7) and block the already seen nodes (line 10)\nby setting their his to infinity. When path planning reaches a node\nthat could not go any further (line 8), we return the planned path\nand block that node (lines 9,10). Then, we update the best already\nfound path if the planned path leads us to a location closer to xgoal\n(line 11). However, the agent follows the best path if it leads to\nsome place closer than the current place of the agent (line 12).\nAlgorithm 6 Plan a Path for k Steps\n1: Input: T , xgoal\n2: if Tree has reached xgoal then\n3: Update path from xgoal to x0 if the path is rewired\n4: (x0, ..., xk) \u2190 (x0, ..., xgoal)\n5: else\n6: for xi \u2208 (x1, x2, ..., xk) do\n7: xi=child of xi-1 with minimum fc=cost(xc)+H(xc)\n8: if xi is leaf or its children are blocked then\n\n\n\n9: (x\n0\n0\n, ..., x\n0\nk) \u2190 (x0, ..., xi)\n10: Block xi and Break;\n11: Update best path with (x\n0\n0\n, ..., x\n0\nk) if necessary\n12: (x0, ..., xk) \u2190 choose to stay in x0 or follow best path\n13: return (x0, ..., xk)\nNote that, H(xi) returns infinity if xi is blocked and xgoal has not\nbeen changed, i.e. xi is already visited for the current xgoal. Otherwise, if xgoal has been changed or xi has not been visited for the\ncurrent xgoal, H(xi) = kxi \u2212 xgoalk2. Every node has a chance to\nget visited again, i.e. all its ancestors get unblocked, when another\nunblocked node is added as its child by rewiring or adding a node.\nIt should be noted that when the tree has reached xgoal and the path\ngets blocked by an obstacle, we follow the path up to the obstacle\nuntil rewiring finds another path or the path gets cleared.\n5 Simulations\nFigure 3: Simulation environment (left) and the tree expanded by\nRT-RRT* to cover this environment (right). The numbered circles\ndenote different goal areas in the environment.\nIn this section we compare our algorithm, RT-RRT*, with CL-RRT\n[Luders et al. 2010] in two different scenarios. First, we find out the\nnumber of iterations (planning step and taking an action) needed to\nfind a path to the various goals in Fig 3. Secondly, we find out\nthe length of the paths taken between the consecutive goal points\nof Fig 3. The dynamic obstacles are motionless in the simulation to\nmake a fair comparison with CL-RRT. However, our supplementary\nvideo shows how RT-RRT* reacts to the movements of the dynamic\nobstacles (supplemental video 00:15). The agent and dynamic obstacles have the relatively small radii of 0.5m. The tree expanded\nby RT-RRT* is demonstrated in Fig 3. This tree covers the whole\nenvironment with approximately 7000 nodes. We had a grid of size\n2m \u00d7 2m which divides the environment into 225 squares. The\nkmax and rs in Algorithm 2 are set to 5 and 0.5 m respectively. \u03b1\n\n\n\nand \u03b2 in (1) are 0.1 and 2, correspondingly. Also, we set ro, rb\nand rg of Fig 2 to 10m, 1.5m and 0.5m, respectively. The limited\ntime for Tree Expansion-and-Rewiring is set to 10 ms and we set\nk in Algorithm 1 to 100. In order to have a fair comparison with\n117\nCL-RRT, we had a disturbance free model and used C-PBP as the\nclosed loop controller of the CL-RRT algorithm as well. This way\nthe differences in the sampling schemes become evident. In CLRRT, The number of the nodes is limited to 1000 for real-time use.\nAlso, We plan 10 steps ahead with CL-RRT and use 5 as the nearest\nneighbor parameter.\nWe ran each algorithm for each scenario 10 times and averaged the\nresults. The average number of iterations required to find the path\nto each goal was 8.26 for our method and 87.54 for CL-RRT. The\naverage number of the iterations needed to find the path to G1 was\napproximately the same for both of the algorithms since both of\nthem start growing the tree from a scratch. However, as opposed\nto CL-RRT, our method needs fewer iterations as the tree grows in\nthe environment. Particularly, in RT-RRT* when the tree is grown\nto the whole area, the path is fast to find, e.g. the average number\nof the iterations for finding paths to G4, G5 and G6 are 1.00, 4.27\nand 1.00 for RT-RRT*, respectively, whereas for CL-RRT they are\nof the order of 100. This happens because nothing is pruned from\nthe tree unlike in CL-RRT (supplemental video 1:30). In addition,\nthe average length of a path taken to the different goals was 27.12\nfor our method and 72.67 for CL-RRT. We can see that RT-RRT*\nneeds less iterations and produces paths with smaller length. The\nsmaller length of the path is caused by the rewiring operation which\nis present only in RRT* based algorithms. We also observed that using 500 iterations CL-RRT failed to find the path to G5 with 65 %\nchance and to G3 with 10 % chance because of the narrow passages, whereas RT-RRT* never fails to find a path as the tree is\nexpanding.\n6 Conclusions\nIn this paper we introduced the first real-time version of RRT* and\ninformed RRT*. The real-time capability was achieved by interleaving the path planning with the tree expansion and rewiring.\nFurthermore, we move the tree root with the agent to retain the\ntree instead of building it anew at every iteration. The tree continues to grow until it covers the environment. We also introduced two\nmodes of rewiring for having shorter paths in the large tree with a\nlimited number of the nodes. These are: 1) rewiring starting from\nthe root, and 2) rewiring random parts of the tree. The first one\ncreates a growing circle centered at the agent. In this process every node inside the circle is rewired, and this circle most frequently\nrewires nodes around the agent and thus the tree root. The second one is done using both focused and uniform sampling, but in\n\n\n\npatches instead of just one node. We tested our algorithm against\nCL-RRT which can be considered the state-of-the-art in RRT-based\nreal-time path planning. Our simulations show that the combination\nof retaining the tree with the two methods of rewiring the large tree\nin RT-RRT* enables the algorithm to find shorter paths with less\niterations to one or multiple goal points. One should note that, for\nthe sake of simplicity and memory, we used a grid to speed up our\nneighboring node search. Some more sophisticated spatial index\nsuch as a KD-tree would speed up the search even more and allow\nusing bigger sampling budgets.\nRT-RRT* has its limitations, e.g. it requires a large memory capacity because the whole tree is stored at all times. One of the major\nlimitations of our algorithm is that it only works in a bounded environment. The focused sampling inside an ellipsoid works somewhat in an unrestricted environment but the rewiring suffers if the\ndistances are large. Thus, the challenges of unbounded and large\ndistance environments remain to be addressed.\nWe used C-PBP to move the agent on the planned path and separate the path planning from the motion planning. Although C-PBP\nenables the agent to follow the planned path smoothly and plan motions around the obstacles, it regrettably does not provide us with\na model of the obstacles. That is why we made assumptions about\nwhich objects are obstacles and resorted to circumventing the obstacles with a given minimum distance. We deem extracting an\nobstacle model a fruitful research direction for the future.\nAcknowledgements\nThis work has been supported by TEKES (The Finnish Funding\nAgency For Innovation).\nReferences\nBRUCE, J., AND VELOSO, M. 2002. Real-time randomized path\nplanning for robot navigation. In IROS, IEEE.\nCANNON, J., ROSE, K., AND RUML, W. 2012. Real-Time Motion\nPlanning with Dynamic Obstacles. In Symposium on Combinatorial Search.\nGAMMELL, D, J., SRINIVASA, S, S., BARFOOT, AND D, T. 2014.\nInformed RRT*: Optimal Sampling-based Path Planning Focused via Direct Sampling of an Admissible Ellipsoidal Heuristic. In IROS, IEEE.\nGUTMANN, J.-S., FUKUCHI, M., AND FUJITA, M. 2005. Realtime path planning for humanoid robot navigation. In IJCAI.\nHAM\u00a8 AL\u00a8 AINEN \u00a8 , P., RAJAMAKI \u00a8 , J., AND LIU, C. K. 2015. Online\nControl of Simulated Humanoids Using Particle Belief Propagation. In Proc. SIGGRAPH \u201915, ACM.\nKARAMAN, S., AND FRAZZOLI, E. 2011. Sampling-based Algorithms for Optimal Motion Planning. Int. J. Rob. Res..\nKAVRAKI, L. E., S\u02c7 VESTKA, P., LATOMBE, J.-C., AND OVERMARS, M. H. 1996. Probabilistic roadmaps for path planning\nin high-dimensional configuration spaces. IEEE Trans. Robot.\nAutom..\nKHATIB, O. 1986. Real-time obstacle avoidance for manipulators and mobile robots. The International Journal of Robotics\nResearch.\nLAVALLE, S. M. 1998. Rapidly-Exploring Random Trees: A new\nTool for Path Planning.\n\n\n\nLUDERS, B. D., KARAMAN, S., FRAZZOLI, E., AND HOW,\nJ. P. 2010. Bounds on tracking error using closed-loop rapidlyexploring random trees. In American Control Conference, IEEE.\nOTTE, M., AND FRAZZOLI, E. 2015. RRTX: Real-time motion\nplanning/replanning for environments with unpredictable obstacles. In Algorithmic Foundations of Robotics XI. Springer.\nRASTGOO, M. N., NAKISA, B., NASRUDIN, M. F., NAZRI, A.,\nAND ZAKREE, M. 2014. A critical evaluation of literature on\nrobot path planning in dynamic environment. Journal of Theoretical & Applied Information Technology.\nSONG, S., LIU, W., WEI, R., XING, W., AND REN, C. 2014. Path\nplanning directed motion control of virtual humans in complex\nenvironments. Journal of Visual Languages & Computing.\nSTURTEVANT, N. R., BULITKO, V., AND BJORNSSON \u00a8 , Y. 2010.\nOn learning in agent-centered search. In AAMAS.\nSUD, A., ANDERSEN, E., CURTIS, S., LIN, M., AND MANOCHA,\nD. 2008. Real-time path planning for virtual agents in dynamic\nenvironments. In ACM SIGGRAPH 2008 Classes, ACM.\n118\n\n\n"
  }
]