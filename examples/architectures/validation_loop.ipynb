{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf905d81",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8879a84e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27560c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import railtracks as rt\n",
    "from dotenv import load_dotenv\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "_ = load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONDER_SYSTEM_MESSAGE = \"\"\n",
    "\n",
    "CRITIQUER_SYSTEM_MESSAGE = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3840123",
   "metadata": {},
   "source": [
    "Of course we need to set up some tools for our agents to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf54145",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackEntry(BaseModel):\n",
    "    section_of_interest: str | None\n",
    "    feedback: str\n",
    "    feedback_type: Literal[\"positive\", \"negative\", \"neutral\"]\n",
    "    identifier: int\n",
    "    action_taken: str | None = None\n",
    "    accepted: bool | None = None\n",
    "\n",
    "    def present_to_llm(self):\n",
    "        return f\"Feedback Type: {self.feedback_type}\\nSection of Interest: {self.section_of_interest}\\nFeedback: {self.feedback}\\nAction Taken: {self.action_taken}\\nAccepted: {self.accepted}\"\n",
    "\n",
    "\n",
    "@rt.function_node\n",
    "async def add_feedback(text_ref: str | None, feedback: str, feedback_type: Literal[\"positive\", \"negative\", \"neutral\"]) -> str:\n",
    "    \"\"\"\n",
    "    Adds feedback to the feedback log for the current entry.\n",
    "    \n",
    "    Args:\n",
    "        text_ref (str | None): The section of the entry the feedback is about. If general feedback, this can be None.\n",
    "        feedback (str): The feedback you would like to provide.\n",
    "        feedback_type (Literal[\"positive\", \"negative\", \"neutral\"]): The type of feedback.\n",
    "    \"\"\"\n",
    "    entry_id: str = rt.context.get(\"entry_id\")\n",
    "    feedback_log: list[FeedbackEntry] = rt.context.get(\"feedback_log\")[entry_id]\n",
    "\n",
    "    if text_ref not in rt.context.get(\"current_entry\")[entry_id]:\n",
    "        raise ValueError(f\"Section {text_ref} not found in current entry.\")\n",
    "    \n",
    "    current_entry = rt.context.get(\"feedback_counter\")\n",
    "\n",
    "    feedback_log.append(FeedbackEntry(section_of_interest=text_ref, feedback=feedback, feedback_type=feedback_type, identifier=current_entry))\n",
    "    current_entry += 1\n",
    "\n",
    "    rt.context.put(\"feedback_counter\", current_entry)\n",
    "\n",
    "\n",
    "    return \"Feedback Submitted Successfully.\"\n",
    "\n",
    "\n",
    "@rt.function_node\n",
    "async def complete_feedback(feedback_id: int, action_taken: str, accepted: bool):\n",
    "    feedback_log: list[FeedbackEntry] = rt.context.get(\"feedback_log\")\n",
    "\n",
    "    id_list = [x.identifier for x in feedback_log]\n",
    "\n",
    "\n",
    "    if feedback_id not in id_list:\n",
    "        raise ValueError(\"Your feedback identifier does not exist\")\n",
    "    feedback = None\n",
    "    for i in id_list:\n",
    "        if feedback_id == i:\n",
    "            feedback = feedback_log[i]\n",
    "            break\n",
    "\n",
    "    assert feedback is not None\n",
    "\n",
    "    if feedback.accepted is not None:\n",
    "        raise ValueError(\"Action has already been taken on this feedback. \")\n",
    "\n",
    "    feedback.action_taken = action_taken\n",
    "    feedback.accepted = accepted\n",
    "\n",
    "    return f\"You succesfully have closed the feedback:\\n{feedback.feedback}\\nWith resolution: {feedback.accepted} - {feedback.action_taken}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef6ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Responder = rt.agent_node(\n",
    "    name=\"Responder\",\n",
    "    system_message=RESPONDER_SYSTEM_MESSAGE,\n",
    "    llm=rt.llm.OpenAILLM('gpt-4o'),\n",
    "\n",
    ")\n",
    "\n",
    "Critique = rt.agent_node(\n",
    "    name=\"Critique\",\n",
    "    system_message=\"You are an expert at critiquing answers for correctness and completeness.\",\n",
    "    llm=rt.llm.OpenAILLM('gpt-5'),\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ff5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_log = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
