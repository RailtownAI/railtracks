{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import railtracks as rt\n",
    "from pydantic import BaseModel, Field\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4o = rt.llm.OpenAILLM(\"gpt-4o\")\n",
    "\n",
    "\n",
    "class AnswerPrediction(BaseModel):\n",
    "    quality_answer: bool = Field(\n",
    "        ..., description=\"The quality of the answer that was provided by the model.\"\n",
    "    )\n",
    "\n",
    "\n",
    "system_c_o_t = rt.llm.SystemMessage(\n",
    "    \"You are extremley intellegnt reviewer of information that ponders the provided question and context to provide a simple one paragraph plan where you discuss you thinking process and how you would go about answering the question, without explictely answer the question.\"\n",
    ")\n",
    "system_answer = rt.llm.SystemMessage(\n",
    "    \"You are a helpful assistant that works tirelessly to answer a question using the provided context as a guide to answer the question.\"\n",
    ")\n",
    "system_answer_reviewer = rt.llm.SystemMessage(\n",
    "    \"You are a reviewer of the plan that was provided by the model and will determine if the plan is feasible and if it will accomplish the task that was asked of you. Be harsh and clear when the plan is not adequete.\"\n",
    ")\n",
    "\n",
    "\n",
    "COTNode = rt.library.terminal_llm(\"COT\", system_message=system_c_o_t, llm_model=gpt_4o)\n",
    "AnswerNode = rt.library.terminal_llm(\n",
    "    \"Answerer\", system_message=system_answer, llm_model=gpt_4o\n",
    ")\n",
    "ReviewerNode = rt.library.structured_llm(\n",
    "    output_schema=AnswerPrediction,\n",
    "    name=\"AnswerReviewer\",\n",
    "    system_message=system_answer_reviewer,\n",
    "    llm_model=gpt_4o,\n",
    ")\n",
    "\n",
    "\n",
    "async def COTLLM(message_history: rt.llm.MessageHistory, number_trails: int = 4):\n",
    "    original_message_history = deepcopy(message_history)\n",
    "    for _ in range(number_trails):\n",
    "        cot_response = await rt.call(COTNode, user_input=message_history)\n",
    "\n",
    "        message_history.append(rt.llm.AssistantMessage(\"My plan:\" + cot_response))\n",
    "\n",
    "        answer_response = await rt.call(ReviewerNode, user_input=message_history)\n",
    "        if not answer_response.quality_answer:\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    original_message_history.append(\n",
    "        rt.llm.UserMessage(\"Contextual Plan: \" + cot_response)\n",
    "    )\n",
    "    response = await rt.call(AnswerNode, user_input=original_message_history)\n",
    "\n",
    "    return cot_response, response\n",
    "\n",
    "\n",
    "ChainOfThought = rt.library.function_node(COTLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[+2.300  s] RT          : INFO     - START CREATED COTLLM\n",
      "[+2.301  s] RT          : INFO     - COTLLM CREATED COT\n",
      "[+8.928  s] RT          : INFO     - COT DONE\n",
      "[+8.928  s] RT          : INFO     - COTLLM CREATED AnswerReviewer\n",
      "[+9.603  s] RT          : INFO     - AnswerReviewer DONE\n",
      "[+9.606  s] RT          : INFO     - COTLLM CREATED COT\n",
      "[+13.462 s] RT          : INFO     - COT DONE\n",
      "[+13.478 s] RT          : INFO     - COTLLM CREATED AnswerReviewer\n",
      "[+13.995 s] RT          : INFO     - AnswerReviewer DONE\n",
      "[+14.011 s] RT          : INFO     - COTLLM CREATED COT\n",
      "[+17.657 s] RT          : INFO     - COT DONE\n",
      "[+17.659 s] RT          : INFO     - COTLLM CREATED AnswerReviewer\n",
      "[+18.230 s] RT          : INFO     - AnswerReviewer DONE\n",
      "[+18.230 s] RT          : INFO     - COTLLM CREATED COT\n",
      "[+22.074 s] RT          : INFO     - COT DONE\n",
      "[+22.076 s] RT          : INFO     - COTLLM CREATED AnswerReviewer\n",
      "[+22.875 s] RT          : INFO     - AnswerReviewer DONE\n",
      "[+22.878 s] RT          : INFO     - COTLLM CREATED Answerer\n",
      "[+29.534 s] RT          : INFO     - Answerer DONE\n",
      "[+29.536 s] RT          : INFO     - COTLLM DONE\n",
      "[+29.538 s] RT.Runner   : INFO     - Saving execution info to .railtracks\\b0d1c49c-e6be-40a9-bea0-ad99c109e2f6.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COT plan: My plan: When posed with a question absent of explicit context, my approach is to systematically decipher potential meanings and domains it might pertain to. Initially, I'd pinpoint any key phrases or vocabulary that could suggest specific themes or fields of study, such as technology, culture, or economics. Based on these clues, I'd map out various interpretations or scenarios the question might address, evaluating them through diverse lenses. This would involve drawing from a broad spectrum of knowledge — historical precedents, theoretical frameworks, or recent advancements — to create a cohesive narrative. By integrating different perspectives, my objective is to offer a thoughtful answer that encompasses the underlying complexities and nuances, ensuring the response is both comprehensive and adaptable to various contexts.\n",
      "-------------------\n",
      "Answer: Your plan outlines a structured approach to tackle questions that lack explicit context. Here's a step-by-step breakdown of how you might implement this strategy:\n",
      "\n",
      "1. **Identify Key Phrases:** Start by analyzing the question for any words or phrases that stand out. These could be technical terms, names, or concepts that hint at a particular topic or field.\n",
      "\n",
      "2. **Determine Potential Themes:** Based on the key phrases, identify possible themes or domains such as technology, culture, economics, science, etc.\n",
      "\n",
      "3. **Explore Different Interpretations:** For each theme, think about various ways the question could be understood. This could involve considering different scenarios, perspectives, or assumptions.\n",
      "\n",
      "4. **Leverage Broad Knowledge:** Utilize your general knowledge, including historical events, theoretical frameworks, and current trends, to support different interpretations of the question.\n",
      "\n",
      "5. **Create a Cohesive Narrative:** As you analyze the question, try to weave together a comprehensive response that takes into account the different angles you've explored.\n",
      "\n",
      "6. **Offer a Multifaceted Answer:** Provide an answer that is adaptable and acknowledges the complexities of the question, allowing for varying interpretations and contexts.\n",
      "\n",
      "By following this plan, you'll be better equipped to provide insightful and well-rounded answers to questions, even when they initially seem vague or unclear.\n"
     ]
    }
   ],
   "source": [
    "message_history = rt.llm.MessageHistory([rt.llm.UserMessage(\"\")])\n",
    "with rt.Session() as runner:\n",
    "    response = await rt.call(ChainOfThought, message_history=message_history)\n",
    "\n",
    "print(\"COT plan: \" + response.answer[0])\n",
    "print(\"-------------------\")\n",
    "print(\"Answer: \" + response.answer[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
